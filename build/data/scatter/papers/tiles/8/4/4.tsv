id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
8de425d27794fdc3aff8699ee158966224b01693	a case study of multi-agent interoperability in iec 61850 environments	multiagent system;elektroteknik och elektronik;multi agent system;operant conditioning;agent based;industrial applicationa multi agent systems power systems control and protection industrial application multi agent systems power systems control and protection;electrical engineering electronic engineering information engineering;industrial application multi agent systems;fault currents;substation automation;information needs;common information model;industrial applicationa;substation automation control engineering computing decision making electricity supply industry information needs multi agent systems open systems power engineering computing;semantic model;multi agent systems;power engineering computing;access to information;iec standards;monitoring;information exchange need multiagent interoperability iec 61850 environment substation communication substation automation systems stake holders decision making logic optimal operational condition power system boundary condition horizontal interoperability common information model function control power system architecture utility automation;boundary condition;power system;information exchange;substations;iec standards relays multiagent systems monitoring substations fault currents;industrial application;control engineering computing;electricity supply industry;relays;open systems;use case;power system control;multiagent systems;power systems control and protection	The IEC 61850 is the most promising standard for design of substation communication and automation systems. On the other hand multi-agents systems are attracting growing interest for different applications of substation automation systems. In multiagent systems agents represent different stake holders in the power system and based on implemented decision making logic they determine optimal operational conditions for the power system's given boundary conditions. Interoperability is of course a necessary pre-requisite for such architectures. Here we identify two aspects of interoperability; horizontal and vertical. Horizontal interoperability is relies on common semantic models of the power system that the agents can use to make decisions. One such semantic model is presented in the IEC 61970 Common Information Model (CIM). At this level, the IEC 61850 standard provides a model for access to information and control functions that has the necessary flexibility needed. In this paper we discuss the mapping between a multi-agent based architecture for power system control and the IEC 61850 standard for utility automation. The mapping is based on a use-case drive approach, in which the information exchange need is defined by the multi-agent system.	agent-based model;best practice;best, worst and average case;computer-integrated manufacturing;control function (econometrics);distributed control system;freedom of information laws by country;high- and low-level;ibm power systems;information and computation;information exchange;information model;intelligent control;interoperability;multi-agent system;robustness (computer science);sas;scalability;seamless3d;semantic data model;traction substation	Arshad Saleem;Nicholas Honeth;Lars Nordström	2010	2010 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT Europe)	10.1109/ISGTEUROPE.2010.5638876	control engineering;semantic interoperability;embedded system;interoperability;systems engineering;engineering	AI	0.19001553625278744	6.797417544673037	14556
791eeb7f2442c91e1f8e405e0a6dbc1fe299cfdd	solving 8×8 domineering	solving games;transposition tables;game theory;solving game;domineering;table transposition;replacement schemes;juego suma nula;teoria juego;intelligence artificielle;theorie jeu;jeu 2 personnes;resolucion problema;combinatorial game;juego 2 personas;resolution jeu;two person game;artificial intelligence;inteligencia artificial;transposition table;jeu somme nulle;zero sum game;problem solving;resolution probleme;jeu combinatoire	Abstract   So far the game of Domineering has mainly been investigated by combinatorial-games researchers. Yet, it is a genuine two-player zero-sum game with perfect information, of which the general formulation is a topic of AI research. In that domain, many techniques have been developed for two-person games, especially for chess. In this article we show that one such technique, i.e., transposition tables, is fit for solving standard Domineering (i.e., on an 8×8 board). The game turns out to be a win for the player first to move. This result coincides with a result obtained independently by Morita Kazuro. Moreover, the technique of transposition tables is also applied to differently sized   m×n   boards,   m   ranging from 2 to 8, and   n   from   m   to 9. The results are given in tabular form. Finally, some conclusions on replacement schemes are drawn. In an appendix an analysis of four tournament games is provided.		Dennis M. Breuker;Jos W. H. M. Uiterwijk;H. Jaap van den Herik	2000	Theor. Comput. Sci.	10.1016/S0304-3975(99)00082-1	combinatorial game theory;game theory;transposition table;combinatorics;computer science;artificial intelligence;mathematics;algorithm	ECom	13.58453053505843	18.620470995490713	14561
86d3dcbdb9c3423fb020f4650bc952515d36f46c	compression of low entropy strings with lempel-ziv algorithms	lempel ziv;68p20;data compression;lempel ziv parsing;empirical entropy;68q25	We compare the compression ratio of the Lempel--Ziv algorithms with the empirical entropy of the input string. This approach makes it possible to analyze the performance of these algorithms without any assumption on the input and to obtain worst case results. We show that in this setting the standard definition of optimal compression algorithm is not satisfactory. In fact, although Lempel--Ziv algorithms are optimal according to the standard definition, there exist families of low entropy strings which are not compressed optimally. More precisely, the compression ratio achieved by LZ78 (resp., LZ77) can be much higher than the zeroth order entropy H0 (resp., the first order entropy H1).#R##N#For this reason we introduce the concept of $\lambda$-optimal algorithm. An algorithm is $\lambda$-optimal with respect to Hk if, loosely speaking, its compression ratio is asymptotically bounded by $\lambda$ times the kth order empirical entropy Hk. We prove that LZ78 cannot be $\lambda$-optimal with respect to any Hk with $k\geq 0$. Then, we describe a new algorithm which combines LZ78 with run length encoding (RLE) and is 3-optimal with respect to H0. Finally, we prove that LZ77 is 8-optimal with respect to H0, and that it cannot be $\lambda$-optimal with respect to Hk for any $k\geq 1$.	approximation algorithm;lempel–ziv–stac	S. Rao Kosaraju;Giovanni Manzini	1999	SIAM J. Comput.	10.1137/S0097539797331105	data compression;combinatorics;theoretical computer science;mathematics;algorithm;statistics	Theory	11.226009561640213	26.54045172980729	14576
267ef47e58bb4d049761ce1d93fa2a17cab4b49a	computing representative networks for braided rivers		Drainage networks on terrains have been studied extensively from an algorithmic perspective. However, in drainage networks water flow cannot bifurcate and hence they do not model braided rivers (multiple channels which split and join, separated by sediment bars). We initiate the algorithmic study of braided rivers by employing the descending quasi Morse-Smale complex on the river bed (a polyhedral terrain), and extending it with a certain ordering of bars from the one river bank to the other. This allows us to compute a graph that models a representative channel network, consisting of lowest paths. To ensure that channels in this network are sufficiently different we define a sand function that represents the volume of sediment separating them. We show that in general the problem of computing a maximum network of non-crossing channels which are δ-different from each other (as measured by the sand function) is NP-hard. However, using our ordering between the river banks, we can compute a maximum δ-different network that respects this order in polynomial time. We implemented our approach and applied it to simulated and real-world braided rivers. 1998 ACM Subject Classification F.2.2 Analysis of Algorithms and Problem Complexity		Maarten Kleinhans;Marc J. van Kreveld;Tim Ophelders;Willem Sonke;Bettina Speckmann;Kevin Verbeek	2017		10.4230/LIPIcs.SoCG.2017.48	discrete mathematics;polyhedral terrain;bank;time complexity;terrain;drainage;computer science;sediment;graph;communication channel	Theory	24.458821524746067	23.595516976613634	14585
41cce93f12dbbf226abc854baeb1728b0b21ba7e	design by measure and conquer, a faster exact algorithm for dominating set	design of algorithms;004;independent set;combinatorial problems;mathematical analysis;dominating set;exact algorithm;exact algorithms exponential time algorithms branch and reduce measure and conquer dominating set computer aided algorithm design;data structure;set cover;algorithm design	The measure and conquer approach has proven to be a powerful tool to analyse exact algorithms for combinatorial problems, like Dominating Set and Independent Set. In this paper, we propose to use measure and conquer also as a tool in the design of algorithms. In an iterative process, we can obtain a series of branch and reduce algorithms. A mathematical analysis of an algorithm in the series with measure and conquer results in a quasiconvex programming problem. The solution by computer to this problem not only gives a bound on the running time, but also can give a new reduction rule, thus giving a new, possibly faster algorithm. This makes design by measure and conquer a form of computer aided algorithm design. When we apply the methodology to a Set Cover modelling of the Dominating Set problem, we obtain the currently fastest known exact algorithms for Dominating Set: an algorithm that uses O(1.5134) time and polynomial space, and an algorithm that uses O(1.5063) time.	algorithm design;dominating set;exact algorithm;fastest;independent set (graph theory);iteration;pspace;polynomial;quasiconvex function;set cover problem;theory;time complexity	Johan M. M. van Rooij;Hans L. Bodlaender	2008		10.4230/LIPIcs.STACS.2008.1329	algorithm design;mathematical optimization;combinatorics;discrete mathematics;divide and conquer algorithms;independent set;data structure;dominating set;hybrid algorithm;computer science;mathematics;set cover problem;algorithm	Theory	17.147724928243672	19.899559549683993	14612
58212104e8171ee403ff3aa88d40217065c2f6ed	practical and flexible pattern matching over ziv–lempel compressed text	ziv lempel compression;compressed pattern matching;lzw;general techniques;lz78;text database;pattern matching;lz77;bit parallelism;string matching	We address the problem of string matching on Ziv–Lempel compressed text. The goal is to search for a pattern in a text without uncompressing it. This is a highly relevant issue to keep compressed text databases where efficient searching is still possible. We develop a general technique for string matching when the text comes as a sequence of blocks. This abstracts the essential features of Ziv–Lempel compression. We then apply the scheme to each particular type of compression. We present an algorithm to find all the matches of a pattern in a text compressed using LZ77. When we apply our scheme to LZ78, we obtain a much more efficient search algorithm, which is faster than uncompressing the text and then searching it. Finally, we propose a new hybrid compression scheme which is between LZ77 and LZ78, being in practice as good to compress as LZ77 and as fast to search as LZ78. We show also how to search for some extended patterns on Ziv–Lempel compressed text, such as classes of characters and approximate string matching.		Gonzalo Navarro;Mathieu Raffinot	2004	J. Discrete Algorithms	10.1016/j.jda.2003.12.002	commentz-walter algorithm;computer science;lz77 and lz78;theoretical computer science;pattern matching;boyer–moore string search algorithm;pattern recognition;data mining;compressed suffix array;programming language;algorithm	Theory	12.032615989399499	27.822138507105727	14669
426d57faf087619e6dfcc94c1288ed1d16411ead	equivalence and discretisation in bio-pepa	state space;biological systems;process algebra	Bio-PEPA is a process algebra for modelling biological systems. An important aspect of Bio-PEPA is the ability it provides to discretise concentrations resulting in a smaller, more manageable state space. The discretisation is based on a step size which determines the size of each discrete level and also the maximum number of levels. This paper considers the relationship between two discretisations of the same Bio-PEPA model that differ only in the step size and hence the maximum number of levels, by using the idea of equivalence from concurrency and process algebra. We present a novel behavioural semantic equivalence, compression bisimulation, that equates two discretisations of the same model and we show that this equivalence is a congruence with respect to the synchronisation operator.	acoustic radiation force;biological system;bisimulation;british informatics olympiad;concurrency (computer science);congruence of squares;discretization;expectation propagation;jane (software);modelling biological systems;pepa;process calculus;state space;systems biology;turing completeness	Vashti Galpin;Jane Hillston	2009		10.1007/978-3-642-03845-7_13	combinatorics;process calculus;discrete mathematics;computer science;state space;mathematics;programming language	AI	0.615909769797208	24.709182769684652	14707
cdeb8f5a2ad683dcfe806e2298fec135bb97fcbd	a branch-and-price algorithm for parallel machine scheduling using zdds and generic branching	weighted completion times;stabilization;parallel machine scheduling;zdd;branch and price	We study the parallel machine scheduling problem to minimize the sum of the weighted completion times of the jobs to be scheduled (problem P m||P wjCj in the standard three-field notation). We use the set covering formulation that was introduced by van den Akker et al. (1999) for this problem, and we improve the computational performance of their branch-and-price (B&P) algorithm by a number of techniques, including a different generic branching scheme, zero-suppressed binary decision diagrams (ZDDs) to solve the pricing problem, dual-price smoothing as a stabilization method, and Farkas pricing to handle infeasibilities. We report computational results that show the effectiveness of the algorithmic enhancements, which depends on the characteristics of the instances. To the best of our knowledge, we are also the first to use ZDDs to solve the pricing problem in a B&P algorithm for a scheduling problem.		Daniel Kowalczyk;Roel Leus	2018	INFORMS Journal on Computing	10.1287/ijoc.2018.0809	mathematical optimization;computer science;theoretical computer science;distributed computing	HPC	20.613642960290793	10.383623483567295	14722
b3b0c103ab91eb62130fe11a44475c7e266eca20	a note on three-dimensional alternating turing machines with space smaller than log m	machine turing;automata estado finito;turing machine;three dimensional;arbol binario;arbre binaire;finite automaton;automate fini;maquina turing;binary tree	This paper deals with the accepting powers of five-way three-dimensional alternating machines and six-way three-dimensional alternating machines whose input tapes are restricted to cubic ones. We first show that for space smaller than log m, five-way three-dimensional alternating Turing machines are less powerful than six-way three-dimensional alternating Turing machines. We then show that the set of all the three-dimensional connected tapes can be accepted by a six-way three-dimensional alternating finite automaton, but not accepted by any o(log m) space-bounded five-way three-dimensional alternating Turing machine. Finally, we show that there exists a language accepted by a five-way three-dimensional alternating finite automaton, but not accepted by any o(log m) space-bounded six-way three-dimensional nondeterministic Turing machine.	alternating turing machine	Makoto Sakamoto;Katsushi Inoue;Itsuo Takanami	1993	Inf. Sci.	10.1016/0020-0255(93)90092-Z	linear speedup theorem;three-dimensional space;combinatorics;discrete mathematics;turing reduction;time hierarchy theorem;pspace;alternating turing machine;binary tree;turing machine examples;nspace;computer science;turing machine;two-way deterministic finite automaton;universal turing machine;turing completeness;2-exptime;description number;multitape turing machine;finite-state machine;probabilistic turing machine;linear bounded automaton;algorithm;quantum turing machine;register machine;super-recursive algorithm	Theory	0.09714842600693468	22.705741029694114	14723
93a17ca397c07f7676e4d6818c35c48d8cb8a794	the use of knuth-bendix methods to solve the word problem in automatic groups	topology;theorie groupe;metodo reduccion;groupe infini;reduction;topologie;geometry;geometrie;automatic group;word problem;group theory;topologia;resolucion problema;complecion;reduccion;methode reduction;geometria;reduction method;completion;teoria grupo;problem solving;resolution probleme;probleme mot	Certain classes of infinite groups arising from geometry and topology are known to have solvable word problem. We describe the development of practical methods for the solution of the word problem based on the reduction of words in the generators to a normal form. The Knuth-Bendix completion procedure is the principal tool used but, in the case that this process does not halt, we use alternative methods involving the construction of finite-state automata. A computer implementation of these procedures together with some performance statistics on some simple examples are also described.	knuth–bendix completion algorithm	David B. A. Epstein;Derek F. Holt;Sarah Rees	1991	J. Symb. Comput.	10.1016/S0747-7171(08)80093-4	word problem;completion;reduction;calculus;mathematics;group theory;algorithm;algebra	Logic	0.36252971238476206	17.96501899203206	14760
8b7571df44dba35364815425904ffe7fff9aaa1f	a comparison of traditional and constraint-based heuristic methods on vehicle routing problems with side constraints	programmation logique avec contrainte;evaluation performance;sequencage;programmation;performance evaluation;routing;vehicle routing problem;travelling salesman problem;evaluacion prestacion;heuristic method;time window;programacion logica con restriccion;routage;vehicle routing;metodo heuristico;probleme tournee vehicule;problema ruta vehiculo;programacion;problema viajante comercio;resolucion problema;sequencing;probleme commis voyageur;constraint programming;travelling salesperson problem;encaminamiento;constraint logic programming;methode heuristique;programming;problem solving;resolution probleme;acheminement	The vehicle routing problem (VRP) is a variantof the familiar travelling salesperson problem (TSP). In theVRP we are to perform a number of visits, using a number of vehiclesof limited capacity, while typically minimizing the distancetravelled. VRPs can be complicated by imposing time windows ordeadlines on visits, sequencing constraints between visits, andso on. In this paper, we use a constraint-based toolkit for solvingvehicle routing problems to study the effect of different heuristictechniques. We investigate the performance of a number of constructionand improvement techniques, and show that as the size of thesolution space is decreased through addition of side constraints,certain conventional techniques fail while constraint directedtechniques continue to perform acceptably. This suggests thatconstraint programming techniques are particularly suited toVRPs with side constraints.	heuristic;microsoft windows;travelling salesman problem;vehicle routing problem	Philip Kilby;Patrick Prosser;Paul Shaw	2000	Constraints	10.1023/A:1009808327381	constraint logic programming;programming;mathematical optimization;constraint programming;routing;computer science;vehicle routing problem;sequencing;mathematics;constraint;travelling salesman problem;algorithm	AI	20.45174412489201	6.653223323539627	14809
0880aee988039919e6f750f014afec6425f86032	longest increasing subsequence computation over streaming sequences		"""In this paper, we propose a data structure, a quadruple neighbor list (QN-list, for short), to support real time queries of all <underline>l</underline>ongest <underline>i</underline>ncreasing <underline>s</underline>ubsequence (LIS) and LIS with constraints over sequential data streams. The QN-List built by our algorithm requires <inline-formula><tex-math notation=""""LaTeX"""">$O(w)$</tex-math><alternatives> <inline-graphic xlink:href=""""zou-ieq1-2761345.gif""""/></alternatives></inline-formula> space, where <inline-formula> <tex-math notation=""""LaTeX"""">$w$</tex-math><alternatives><inline-graphic xlink:href=""""zou-ieq2-2761345.gif""""/> </alternatives></inline-formula> is the time window size. The running time for building the initial QN-List takes <inline-formula><tex-math notation=""""LaTeX"""">$O(w\ \log w)$</tex-math><alternatives><inline-graphic xlink:href=""""zou-ieq3-2761345.gif""""/></alternatives></inline-formula> time. Applying the QN-List, insertion of the new item takes <inline-formula><tex-math notation=""""LaTeX"""">$O(\log w)$ </tex-math><alternatives><inline-graphic xlink:href=""""zou-ieq4-2761345.gif""""/></alternatives></inline-formula> time and deletion of the first item takes <inline-formula><tex-math notation=""""LaTeX"""">$O(w)$</tex-math><alternatives> <inline-graphic xlink:href=""""zou-ieq5-2761345.gif""""/></alternatives></inline-formula> time. To the best of our knowledge, this is the first work to support both LIS enumeration and LIS with constraints computation by using a single uniform data structure for real time sequential data streams. Our method outperforms the state-of-the-art methods in both time and space cost, not only theoretically, but also empirically."""	algorithm;computation;dspace;data structure;insertion sort;lis;longest increasing subsequence;maxima and minima;multistage interconnection networks;quadruple-precision floating-point format;time complexity;verlet list;xlink	Youhuan Li;Lei Zou;Huaming Zhang;Dongyan Zhao	2018	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2017.2761345	machine learning;discrete mathematics;artificial intelligence;spacetime;computer science;longest alternating subsequence;longest common subsequence problem;data stream mining;computation;enumeration;longest increasing subsequence;data structure	DB	13.527366995283328	25.36728260149123	14869
5687baddaf987483b0437a585896402f55fb2ffb	on the formal aspects of approximation algorithms	approximate algorithm;complexity class;approximate solution;model of computation;formal language	`Macbedgf\hif\j@f%k\l j@mnaobJkqp m\r s f\hut jebTv wxmys tzf\hBd|{y}e~ Ms!f\}e~r s!f\hut  b@hB~Hm\d|hif!l s f  hu~  ud|}Ts+j@d|~bedgf|mys!~ PTEo!+ hu~>E~Hm\r s bz PP!zz+!T+P. ¢¡£J¤! e+¥¦§¡c ̈z¥ ©«aTs+{y}P¬>~Hm\~hu{y} @e­®~H}@m\dgf\je}@® ̄  b@hB~Hm\d|hif!l s f °p m|f\r$jebev ± s!m\p2>~Hm°3Pf|mys!~ ́+JμeE£Pμ Ep+m|f\r$j@bTv¶JE~Hm\r s+bz ez¦z· ̧1¡|o·1¡£@¤+ ̈P !J ̈x¡c ̈z¥	approximation algorithm	José D. P. Rolim	1990		10.1007/3-540-53504-7_58	combinatorics;discrete mathematics;regular language;theoretical computer science;sparse language;mathematics	Theory	16.459505605975437	19.92850443900123	14898
06001ea7dc98e896fd9aaa83005ddcd685d866c5	extended multi bottom–up tree transducers	theoretical model;syntax;bottom up;left hand side;tree;composition;composicion;05c05;top down;metodo descomposicion;arbol;methode decomposition;syntaxe;input;modele theorique;decomposition method;terme;translation;informatique theorique;transformation lineaire;entree ordinateur;characterization;arbre;linear transformation;transductor;translacion;caracterisation;entrada ordenador;sintaxis;transducer;15404;transducteur;caracterizacion;decomposition arbre;machine translation;transformacion lineal;modelo teorico;computer theory;informatica teorica	Extended multi bottom–up tree transducers are defined and investigated. They are an extension of multi bottom–up tree transducers by arbitrary, not just shallow, left-hand sides of rules; this includes rules that do not consume input. It is shown that such transducers, even linear ones, can compute all transformations that are computed by linear extended top–down tree transducers, which are a theoretical model for syntax-based machine translation. Moreover, the classical composition results for bottom–up tree transducers are generalized to extended multi bottom–up tree transducers. Finally, characterizations in terms of extended top–down tree transducers and tree bimorphisms are presented.	abstract syntax tree;bottom-up parsing;emoticon;machine translation;theory;top-down and bottom-up design;transducer	Joost Engelfriet;Eric Lilin;Andreas Maletti	2009	Acta Informatica	10.1007/s00236-009-0105-8	computer science;top-down and bottom-up design;mathematics;machine translation;algorithm	DB	-2.732708223021194	20.238148459683032	14979
db620e29c501251c074d166da3b13ab23a520263	modifying a graph using vertex elimination	parameterized complexity;graph modification problems;vertex elimination;linear kernel	Vertex elimination is a graph operation that turns the neighborhood of a vertex into a clique and removes the vertex itself. It has widely known applications within sparse matrix computations. We define the Elimination problem as follows: given two graphs G and H, decide whether H can be obtained from G by |V(G)|−|V(H)| vertex eliminations. We show that Elimination is $\mathsf {W[1]} $ -hard when parameterized by |V(H)|, even if both input graphs are split graphs, and $\mathsf {W[2]} $ -hard when parameterized by |V(G)|−|V(H)|, even if H is a complete graph. On the positive side, we show that Elimination admits a kernel with at most 5|V(H)| vertices in the case when G is connected and H is a complete graph, which is in sharp contrast to the $\mathsf {W[1]} $ -hardness of the related Clique problem. We also study the case when either G or H is tree. The computational complexity of the problem depends on which graph is assumed to be a tree: we show that Elimination can be solved in polynomial time when H is a tree, whereas it remains NP-complete when G is a tree.	clique problem;computation;computational complexity theory;graph operations;polynomial;sparse matrix;time complexity	Petr A. Golovach;Pinar Heggernes;Pim van 't Hof;Fredrik Manne;Daniël Paulusma;Michal Pilipczuk	2013	Algorithmica	10.1007/s00453-013-9848-2	graph power;parameterized complexity;vertex separator;combinatorics;discrete mathematics;topology;feedback vertex set;vertex cover;degree;computer science;regular graph;simplex graph;cycle graph;vertex;mathematics;tree-depth;bound graph;complement graph;neighbourhood;algorithm;new digraph reconstruction conjecture;circulant graph;shortest-path tree	Theory	22.705507995993177	23.541508432290957	15060
2dbac364f2979b7656cc5795d33dfad30ad8bab1	new bounds and algorithms for on-line scheduling: two identical processors, known sum and upper bound on the tasks	upper bound;competitive analysis;semi on line scheduling;parallel processors	In this paper we study a semi on-line version of the classical multiprocessor scheduling problem on two identical processors. We assume that the sum of the tasks and an upper bound γ on the size of each task are known. Each task has to be assigned upon arrival and the assignment cannot be changed later. The objective is the minimization of the maximum completion time on the processors. In this paper we propose new algorithms and improve known lower and upper bounds on the competitive ratio. Algorithms and bounds depend on the value of γ. An optimal algorithm, with respect to the competitive ratio, is obtained for γ ∈ [ 1 n , 2(n+1) n(2n+1) ] ∪{ 2n−1 2n(n−1)}, where n is any integer value, n ≥ 2.	algorithm;assignment (computer science);central processing unit;competitive analysis (online algorithm);multiprocessing;multiprocessor scheduling;online and offline;scheduling (computing);semiconductor industry	Enrico Angelelli;Maria Grazia Speranza;Zsolt Tuza	2006	Discrete Mathematics & Theoretical Computer Science		competitive analysis;mathematical optimization;combinatorics;mathematics;upper and lower bounds	Theory	15.863070686060748	11.036484387644554	15071
4b70e2087b8fbeca897476f6888c8b5563e7a8f5	an analysis of acceptance policies for blockchain transactions		The standard acceptance policy for a cryptocurrency transaction at most exchanges is to wait until the transaction is placed in the blockchain and followed by a certain number of blocks. However, as noted by Sompolinsky and Zohar [16], the amount of time for blocks to arrive should also be taken into account as it affects the probability of double spending. Specifically, they propose a dynamic policy for transaction acceptance that depends on both the number of confirmations and the amount of time since transaction broadcast. In this work we study the implications of using such a policy compared with the standard option that ignores block timing information. Using an exact expression for the probability of double spend, via numerical results, we analyze time to transaction acceptance (performance) as well as the time and cost to perform a double spend attack (security). We show that while expected time required for transaction acceptance is improved using a dynamic policy, the time and cost to perform a double spend attack for a particular transaction is reduced.	average-case complexity;bitcoin;cryptocurrency;double-spending;numerical analysis	Seb Neumayer;Mayank Varia;Ittay Eyal	2018	IACR Cryptology ePrint Archive			Security	5.688318595035261	11.208768229065015	15083
6963014b810dba8941ee94d73db1c6012b85964f	improving the robustness of the smart grid using a multi-objective key player identification approach	communication networks;multi objective optimization;smart grid;power system faults;smart grids;network robustness;robustness;power system protection;peer to peer computing;key player identification	The smart grid interconnects a power grid (network) and a communication network, and enables bi-directional flow of electricity and information. To prevent the cascading failures which occur when the disruptions in one network cause disruptions in the other network, robustness should be enhanced by increasing the number of links (edges) between the power grid and the information flow network. Given a budget which constrains the number of new links that can be added to `strengthen' the network, the best strategy to determine where to add those new links remains an open research problem. This paper presents a multi-objective approach to identify the best locations in the power network where new links can be added, to improve the overall robustness of the smart grid when constrained by resource limitations. Simulation results show that substantially greater robustness is obtained by using this approach, when compared to other link addition algorithms.	algorithm;electrical connection;flow network;open research;simulation;social network;sparse matrix;telecommunications network	R. Chulaka Gunasekara;Kishan G. Mehrotra;Chilukuri K. Mohan	2016	2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)	10.1109/ASONAM.2016.7752392	real-time computing;simulation;computer science;network simulation;distributed computing;smart grid	HPC	-2.785771690494618	7.064957042534959	15268
6512f62b6ee144484fe4ffebd2188819781269c2	accelerated simulation of membrane computing to solve the n-queens problem on multi-core	n queens;multi core processing;membrane computing;active membrane systems	Membrane computing or P Systems are distributed and parallel computing device that inspired their computation from cell biology. In this study, a new model of membrane computing with active membranes is defined for solving the N-queens problem. The model contains two membranes, but the inclusion of several objects and rules within each membrane. This model increases the parallelism of previous Membrane computing with active membranes because several rules can evolve concurrently and more than one queen can be exchanged during each step. Number of communication rules are also decreased. Communication rules decrease speed on multi-core processing because communications and synchronizations between threads and cores that are necessary for communication rules are very time consuming process. Multi-core processing is used to exploit the parallelism of membrane computing for solving N-queens problem.	membrane computing;multi-core processor;simulation	Ali Maroosi;Ravie Chandren Muniyandi	2013		10.1007/978-3-319-03756-1_23	computer science;membrane computing;artificial intelligence;theoretical computer science;machine learning;eight queens puzzle;distributed computing;algorithm	EDA	1.5738713466786634	24.93295409667821	15290
15c8414de2db0938667631b556387b97a37c6a14	on the possible patterns of inputs for block sorting in the burrows-wheeler transformation	sufijo;68w40;decalaje;suffix arrays;procesamiento informacion;algorithm analysis;data compression;sorting;suffix;burrows wheeler transformation;68p10;tria;decalage;analysis of algorithm;input;red;suffix array;analysis of algorithms;informatique theorique;reseau arrangement;triage;information processing;entree ordinateur;array;largeur;burrows wheeler transform;68q25;analyse algorithme;shift;compresion dato;width;suffixe;entrada ordenador;ancho;traitement information;block sorting;analisis algoritmo;compression donnee;computer theory;informatica teorica	Block sorting in the Burrows-Wheeler transformation is to sort all of the n circular shifts of a string of length n lexicographically. We introduce a notion called the width of a sequence of n strings of length n and show that the values of widths are very different between the two types of sequences of strings; (1) a sequence of n randomly generated strings of length n, and (2) the sequence of n circular shifts of a randomly generated string of length n.	burrows–wheeler transform;sorting	Takashi Saso;Kojiro Kobayashi;Atsuyoshi Nakamura	2011	Inf. Process. Lett.	10.1016/j.ipl.2011.03.010	data compression;arithmetic;combinatorics;information processing;computer science;sorting;analysis of algorithms;length;burrows–wheeler transform;mathematics;algorithm	DB	14.63196928392887	27.028998620799168	15318
d6c233d54e33e18dcec5090dcbac7cac3d168f95	probability and computing: randomized algorithms and probabilistic analysis	randomized algorithm;probabilistic analysis	Randomized algorithms (making random choices during their execution) play an important role in modern computer science, with applications ranging from combinatorial optimization and machine learning to communications networks and secure protocols. Two advantages of randomization over determinism are crucial in the design of algorithms: simplicity and speed. For many applications, a randomized algorithm is often the simplest algorithm available, the fastest, or both.	combinatorial optimization;computer science;fastest;machine learning;mathematical optimization;probabilistic analysis of algorithms;randomized algorithm;telecommunications network	Harald Niederreiter	2006	Math. Comput.		stochastic process;combinatorics;discrete mathematics;mathematics;statistics;variable-order markov model	Theory	8.722411199865796	26.148818873244437	15328
27c05921dcef4fd1849845fb91c6439514b2906c	errors detection and correction in large scale data collecting	error detection and correction;codificacion binaria;detection erreur;satisfactoriabilidad;deteccion error;statistical data;base donnee;medicion automatica;range data;recoleccion dato;redundancia;data gathering;correction erreur;data collection;database;base dato;logique propositionnelle;automatic measurement;valeur consigne;set covering problem;correction automatique;mesure automatique;satisfiability;resolucion problema;large scale;automatic correction;binary coding;redundancy;propositional logic;error correction;valor consigna;correccion automatica;set point;donnee statistique;satisfaisabilite;correccion error;error detection;logica proposicional;dato estadistico;escala grande;collecte donnee;redondance;problem solving;resolution probleme;echelle grande;codage binaire	The paper is concerned with the problem of automatic detection and correction of inconsistent or out of range data in a general process of statistical data collecting. Under such circumstances, errors are usually detected by formulating a set of rules which the data records must respect in order to be declared correct. As a first relevant point, the set of rules itself is checked for inconsistency or redundancy, by encoding it into a propositional logic formula, and solving a sequence of Satisfiability problems. This set of rules is then used to detect erroneous data. In the subsequent phase of error correction, the above set of rules must be satisfied, but the erroneous records should be altered as little as possible, and frequency distributions of correct data should be preserved. As a second relevant point, error correction is modeled by encoding the rules with linear inequalities, and solving a sequence of set covering problems. The proposed procedure is tested on a real-world case of Census.	algorithm;artificial intelligence;automated theorem proving;binary file;boolean satisfiability problem;combinatorial optimization;computational problem;computers and intractability: a guide to the theory of np-completeness;constraint programming;covering problems;de morgan's laws;electrical engineering;error detection and correction;geo-imputation;ibm research;john d. wiley;l.a. noire;lecture notes in computer science;level of measurement;linear algebra;linear inequality;mathematical optimization;michael garey;problem solving;propositional calculus;redundancy (engineering);representation oligonucleotide microarray analysis;row hammer;springer (tank);subgradient method	Renato Bruni;Antonio Sassano	2001		10.1007/3-540-44816-0_9	error detection and correction;computer science;data mining;mathematics;algorithm;statistics	AI	2.359331767341235	14.734369424536197	15430
843fc7fd02f9e61c9a575fef58f044cb6bf07fde	a note on the survivable network design problem		In this note we consider the survivable network design problem (SNDP) in undirected graphs. We make two contributions. The first is a new counting argument in the iterated rounding based 2-approximation for edge-connectivity SNDP (EC-SNDP) originally due to Jain [Jai01]. The second is to make some additional connections between hypergraphic version of SNDP (Hypergraph-SNDP) introduced in [ZNI03] and edge and node-weighted versions of EC-SNDP and element-connectivity SNDP (Elem-SNDP). One useful consequence of this connection is a 2-approximation for Elem-SNDP that avoids the use of set-pair based relaxation and analysis.	graph (discrete mathematics);iteration;k-edge-connected graph;linear programming relaxation;network planning and design;rounding	Chandra Chekuri;Thapanapong Rukkanchanunt	2016	CoRR		mathematical optimization;combinatorics;mathematics;algorithm	Theory	22.752217562614934	19.711698828872745	15447
c1adc4e3f14bd74d2aa83ffa7ef2572e96b0ac15	optimal covering designs: complexity results and new bounds	settore inf 01 informatica;optimal design statistics;approximate algorithm;combinatorics;complexite calcul;combinatoria;approximation algorithm;combinatoire;calculo automatico;computing;calcul automatique;upper bound;covering design;complejidad computacion;probleme recouvrement;problema recubrimiento;computational complexity;informatique theorique;plan combinatoire;algoritmo aproximacion;recouvrement ensemble;combinatorial design;plan optimal;set covering;cardinalite;cubierta conjunto;covering problem;point of view;algorithme approximation;borne superieure;05b40;cota superior;computer theory;informatica teorica	In this paper we investigate the problem of computing optimal lottery schemes. From a computational complexity point of view, we prove that the variation of this problem in which the sets to be covered are specified in the input is log |I|-approximable (where I denotes the collection of sets to be covered) and it cannot be approximated within a factor smaller than log |I|, unless P = NP. From a combinatorial point of view, we propose new constructions based on the combination of the partitioning technique and of known results regarding the construction of sets of coverings. By means of this combination we will be able to improve several upper bounds on the cardinality of optimal lottery schemes.		Pierluigi Crescenzi;Federico Montecalvo;Gianluca Rossi	2004	Discrete Applied Mathematics	10.1016/j.dam.2003.11.006	mathematical optimization;combinatorial design;combinatorics;computing;computer science;mathematics;approximation algorithm;algorithm	Theory	17.59275545193705	25.296944651858812	15515
11847f9e021e675cd8406414668ddd3150199800	secret linear congruential generators are not cryptographically secure	prediction algorithms;polynomials;cryptography;cryptography leg polynomials prediction algorithms;leg	This paper discusses the predictability of the sequence given by outputing a constant proportion α of the leading bits of the numbers produced by a linear congruential generator. First, we make the assumption that the modulus of the generator is the only known parameter and we prove that, almost surely, a significant proportion of the bits can be predicted from the previous ones, once the generator has been used K times successively where K is O(√log m). Next, we assume that all parameters of the generator are secret and we show how repeated observations of sequences of outputs of length K will probably allow an opponent to cryptanalyze the full sequence.	linear congruential generator;modulus of continuity	Jacques Stern	1987	28th Annual Symposium on Foundations of Computer Science (sfcs 1987)	10.1109/SFCS.1987.51	arithmetic;linear congruential generator;combinatorics;cryptography;theoretical computer science;mathematics;pseudorandom number generator;algorithm;lagged fibonacci generator;statistics	Theory	10.550853506425268	24.207321122824393	15583
de4f467e85429c8ff8dab46dcbf27ba6ca54a9b7	finding common rna pseudoknot structures in polynomial time	metodo polinomial;temps polynomial;analisis datos;estructura terciaria;bioinformatique;problema np duro;upper bound;polynomial time algorithm;combinatorial problem;np hard problem;data analysis;rna structure;probleme combinatoire;problema combinatorio;rna;probleme np difficile;polynomial method;polynomial time;pattern recognition;analyse donnee;reconnaissance forme;bioinformatica;reconocimiento patron;borne superieure;methode polynomiale;structure tertiaire;cota superior;tertiary structure;bioinformatics;tiempo polinomial	This paper presents the first polynomial time algorithm for finding common RNA substructures that include pseudoknots and similar structures. While a more general problem is known to be NP-hard, this algorithm exploits special features of RNA structures to match RNA bonds correctly in polynomial time. Although the theoretical upper bound on the algorithm's time and space usage is high, the data-driven nature of its computation enables it to avoid computing unnecessary cases, dramatically reducing the actual running time. The algorithm works well in practice, and has been tested on sample RNA structures that include pseudoknots and pseudoknot-like tertiary structures.	time complexity	Patricia A. Evans	2006		10.1007/11780441_21	time complexity;nucleic acid structure;combinatorics;rna;protein tertiary structure;computer science;calculus;np-hard;mathematics;upper and lower bounds;data analysis;genetics;algorithm	Crypto	16.503556959764836	24.13404997263461	15633
6b143786030d7cad60cb2fed89bab04614b3b8fa	algorithmic blockchain channel design		Payment networks, also known as channels, are a most promising solution to the throughput problem of cryptocurrencies. In this paper we study the design of capital-efficient payment networks, offline as well as online variants. We want to know how to compute an efficient payment network topology, how capital should be assigned to the individual edges, and how to decide which transactions to accept. Towards this end, we present a flurry of interesting results, basic but generally applicable insights on the one hand, and hardness results and approximation algorithms on the other hand. 2012 ACM Subject Classification Theory of computation → Graph algorithms analysis	approximation algorithm;bitcoin;cryptocurrency;network topology;online and offline;theory of computation;throughput	Georgia Avarikioti;Yuyi Wang;Roger Wattenhofer	2018	CoRR		throughput;discrete mathematics;approximation algorithm;cryptocurrency;blockchain;payment;network topology;mathematics;know-how;distributed computing;communication channel	ECom	18.369419509247145	16.226821385787225	15634
245f609f96b458582dd19e17dbe487895913ff2c	learning probabilistic read-once formulas on product distributions	computational learning theory;pac-learning;learning with noise;read-once formulas;product distributions	This paper presents a polynomial-time algorithm for inferring a probabilistic generalization of the class of read-once Boolean formulas over the usual basis {AND, OR, NOT}. The algorithm effectively infers a good approximation of the target formula when provided with random examples which are chosen according to anyproduct distribution, i.e., any distribution in which the setting of each input bit is chosen independently of the settings of the other bits. Since the class of formulas considered includes ordinary read-once Boolean formulas, our result shows that such formulas are PAC learnable (in the sense of Valiant) against any product distribution (for instance, against the uniform distribution). Further, this class of probabilistic formulas includes read-once formulas whose behavior has been corrupted by large amounts of random noise. Such noise may affect the formula's output (“misclassification noise”), the input bits (“attribute noise”), or it may affect the behavior of individual gates of the formula. Thus, in this setting, we show that read-once formula's can be inferred (approximately), despite large amounts of noise affecting the formula's behavior.	algorithm;approximation;boolean algebra;noise (electronics);polynomial;probably approximately correct learning;time complexity	Robert E. Schapire	1991	Machine Learning	10.1007/BF00993162	combinatorics;discrete mathematics;product distribution;computer science;artificial intelligence;machine learning;mathematics;uniform distribution;computational learning theory;probably approximately correct learning;statistics	Theory	10.146887925021737	20.012302836543665	15681
5c7dbcda6f343f8f919920ada4225b4b0b2ad865	a parallel 2-approximation nc-algorithm for range assignment problem in packet radio networks		Given a set of sensors in a plane or in higher dimension, the strong minimum energy topology problem is to assign transmission range to each of the sensor nodes, so as to minimize the total power consumption. Here the constraint is that the network must be strongly connected. This problem is known to be NP-hard. As this problem has lot of practical application, several approximation algorithms and heuristics has been proposed. There exist a MST based 2-approximation algorithm for this problem having running time complexity of O(n 2 logn). In this paper we propose a simple parallel version of the 2-approximation algorithm. We prove that this parallel algorithm is a NC-algorithm and is also cost optimal for a dense graph. We prove that the algorithm has a time complexity O(logn) and work complexity O(n 2) when the number of processor used is O(n 2).	algorithm;assignment problem	Bijaya Kishor Bhatta;D. Pushparaj Shetty	2013		10.1007/978-3-642-36071-8_10	q15x25;distributed computing	Theory	24.292914869032252	20.592777925573145	15771
4bb85569e5eaf22f770081df257f630866e91cb4	the complexity of deciding statistical properties of samplable distributions		We consider the problems of deciding whether the joint distribution sampled by a given circuit satisfies certain statistical properties such as being i.i.d., being exchangeable, being pairwise independent, having two coordinates with identical marginals, having two uncorrelated coordinates, and many other variants. We give a proof that simultaneously shows all these problems are C=Pcomplete, by showing that the following promise problem (which is a restriction of all the above problems) is C=P-complete: Given a circuit, distinguish the case where the output distribution is uniform and the case where every pair of coordinates is neither uncorrelated nor identically distributed. This completeness result holds even for samplers that are depth-3 circuits. We also consider circuits that are d-local, in the sense that each output bit depends on at most d input bits. We give linear-time algorithms for deciding whether a 2-local sampler’s joint distribution is fully independent, and whether it is exchangeable. We also show that for general circuits, certain approximation versions of the problems of deciding full independence and exchangeability are SZK-complete. We also introduce a bounded-error version of C=P, which we call BC=P, and we investigate its structural properties. 1998 ACM Subject Classification F.1.3 Complexity Measures and Classes	algorithm;approximation;emoticon;p-complete;promise problem;sampling (signal processing);time complexity	Thomas Watson	2013	Theory of Computing	10.4086/toc.2015.v011a001	combinatorics;completeness (statistics);mathematics;discrete mathematics;joint probability distribution;uncorrelated;complexity class;independent and identically distributed random variables;promise problem;pairwise independence	Theory	19.191825124604744	18.53502648526353	15811
a7c81fdfd7251b6693dbf3cf5f8083c7bcc6f610	recognition of q-horn formulae in linear time	linear time	The class of q-Horn Boolean expressions, generalizing the important classes of quadratic, Horn, and disguised Horn formulae, has been introduced in Boros et al. (1990). It has been shown there that the satisfiability problem corresponding to a disjunctive normal form CJ is solvable in time, linear in the size of 4, if C$ is known to be q-Horn. However, the recognition of such formulae was based on the solution of a linear programming problem, and had therefore a much higher (although still polynomial) complexity. In this paper a linear-time combinatorial algorithm is presented for recognizing q-Horn formulae, and reducing in this way the overall complexity of the corresponding satisfiability problem to a linear one.	algorithm;boolean expression;boolean satisfiability problem;combinatorial optimization;decision problem;disjunctive normal form;horn clause;linear programming;polynomial;time complexity;word lists by frequency	Endre Boros;Peter L. Hammer;Xiaorong Sun	1994	Discrete Applied Mathematics	10.1016/0166-218X(94)90033-7	time complexity;mathematical optimization;combinatorics;discrete mathematics;mathematics;algorithm	Theory	6.3764555964902625	19.255172653811343	15852
698a38ab6cf10ea601b818bc1059c923cc0c3617	(co)algebraic characterizations of signal flow graphs	part of book or chapter of book	One of the first publications of Prakash Panangaden is about compositional semantics of digital networks, back in 1984. Digital networks transform streams of input signals to streams of output signals. If the output streams of the components of the network are functions of their input streams, then the behavior of the entire network can be nicely characterized by a recursive stream function. In this paper we consider signal flow graphs, i.e., open synchronous digital networks with feedbacks, obtained by composing amplifiers, mergers, copiers, and delayers. We give two characterizations of the recursive stream functions computed by signal flow graphs: one algebraic in terms of localization of modules of polynomials, and another coalgebraic in terms of Mealy machines. Our main result is that the two characterizations coincide. “Tell all the truth but tell it slant success in circuit lies.” — Emily Dickinson	algebraic equation;amplifier;digital electronics;emily howell;feedback;mealy machine;photocopier;polynomial;recursion	Henning Basold;Marcello M. Bonsangue;Helle Hvid Hansen;Jan J. M. M. Rutten	2014		10.1007/978-3-319-06880-0_6	discrete mathematics;computer science;theoretical computer science;algorithm	Theory	-3.4795518857637626	22.08546254218773	15918
851fa0f5cba637b7dede5cdb2e1556eae6287551	rank bounds and integrality gaps for cutting planes procedures joshua	integer linear programming linear programming polynomials councils integral equations ellipsoids optimization methods instruments computer science;integer linear programming integrality gaps cutting planes procedures rank bound proving proof systems unsatisfiability near optimal rank bounds lovasz schrijver proofs unsatisfiable cnf examples random kcnf formulas tseitin graph formulas integer linear programs integrality gap linear rank resolution proofs cp rank o log n size versus rank polynomial size cp ls proofs;cutting plane;computability;computational complexity integer programming linear programming boundary integral equations theorem proving computability;theorem proving;integer programming;computational complexity;linear programming;integer linear program;lower bound;boundary integral equations	We present a new method for proving rank lower bounds for Cutting Planes (CP) and several procedures based on lifting due to Lovasz and Schrijver (LS), when viewed as proof systems for unsatisfiability. We apply this method to obtain the following new results: first, we prove near-optimal rank bounds for Cutting Planes and Lovasz-Schrijver proofs for several prominent unsatisfiable CNF examples, including random kCNF formulas and the Tseitin graph formulas. It follows from these lower bounds that a linear number of rounds of CP or LS procedures when applied to relaxations of integer linear programs is not sufficient for reducing the integrality gap. Secondly, we give unsatisfiable examples that have constant rank CP and LS proofs but that require linear rank resolution proofs. Thirdly, we give examples where the CP rank is O(log n) but the LS rank is linear. Finally, we address the question of size versus rank: we show that, for both proof systems, rank does not accurately reflect proof size. Specifically, there are examples with polynomial-size CP/LS proofs, but requiring linear rank.		Joshua Buresh-Oppenheim;Nicola Galesi;Shlomo Hoory;Avner Magen;Toniann Pitassi	2003		10.1109/SFCS.2003.1238206	mathematical optimization;combinatorics;discrete mathematics;rank;integer programming;computer science;linear programming;mathematics;automated theorem proving;computability;upper and lower bounds;computational complexity theory;algorithm;cutting-plane method;algebra	Theory	8.894828567650546	17.98975436206326	15956
2305ac1bbf1e28d3e47b051635838078255178db	non-permutation flowshop scheduling with dual resources	non permutation flowshop;sequence dependent setup time;scheduling;mixed integer programming;dual resources	Typically, in order to process jobs in a flowshop both machines and labor are required. However, in traditional scheduling problems, labor is assumed to be plentiful and only machine is considered to be a constraint. This assumption could be due to the lower cost of labor compared to machines or the complexity of dual-resource constrained problems. In this paper a mathematical model is developed to minimize the work-in-process inventory while maximizing the service level in a flowshop with dual resources. The model focuses on optimizing a non-permutation flowshop. There are different skill levels considered for labor and the setup times on machines are sequence-dependent. Jobs are allowed to skip one or more stages in the flowshop. Job release and machine availability times are considered to be dynamic. The problem is solved in two layers. The outer layer is a search algorithm to find the schedule of jobs on the machine (traditional flowshop scheduling problem) and the inner layer is a three-step heuristic to find a schedule of jobs on labor in accordance to the machine schedule. Three different search algorithms are developed to solve the proposed NP-hard problem. First algorithm can solve a permutation flowshop while the other two are developed to solve a non-permutation flowshop. The comparison between the optimal solution and the search algorithms in small examples shows a good performance of the algorithms with an average deviation of only 2.00%. An experimental design analyzes the effectiveness and efficiency of the algorithms statistically. The results show that non-permutation algorithms perform better than the permutation algorithm, although the former are less efficient. The effectiveness and efficiency in all three algorithms have an inverse relation. To the best of our knowledge, this research is the first of its kind to provide a comprehensive mathematical model for dual resource flowshop scheduling problem.	scheduling (computing)	Yasaman Mehravaran;Rasaratnam Logendran	2013	Expert Syst. Appl.	10.1016/j.eswa.2013.03.007	mathematical optimization;real-time computing;integer programming;computer science;scheduling	Arch	15.581284138204806	7.087764273516266	15985
93902ba568d7c0e9de5b3173a2670cc08fa6514c	robust network design in telecommunications under polytope demand uncertainty	network design;telecommunication network design;polyhedral uncertainty;robust optimization;65k05 90c25 90c27 telecommunication network design polyhedral uncertainty robust optimization min max min problems;min max min problems;upper bound;it value;65k05;convex function;90c27;90c25;lower bound;column generation;demand uncertainty;supply and demand	We consider a model for robust network design in telecommunications, in which we minimize the cost of the maximum mismatch between supply and demand. In the present study, the demand is uncertain and takes its values in a polytope defined by constraints. This problem is hardly tractable, so we limit ourselves to computing lower bounds (by a column-generation mechanism) and upper bounds (using an algorithm due to Falk and Soland for maximizing a separable convex function over a polytope). The experimental gap obtained turns out to be large, and this seems to be mainly due to poor upper bounds. Two possible solutions are suggested for further research aimed at improving them: dc optimization (to minimize the difference of two convex functions) and AARC modeling (affinely adjustable robust counterpart).	ieee 802.11i-2004;network planning and design	Claude Lemaréchal;Adam Ouorou;Georgios Petrou	2010	European Journal of Operational Research	10.1016/j.ejor.2010.03.007	mathematical optimization;combinatorics;robust optimization;mathematics;mathematical economics;upper and lower bounds	Robotics	21.831636057909705	14.480402300855218	16030
582429e4e03ec235c8c981a14b53acf564199679	wind turbine condition monitoring and fault diagnosis in china	vibrations;wind turbines;wind turbines condition monitoring fault diagnosis wind power;condition monitoring;monitoring;power 114763 mw wind turbine condition monitoring fault diagnosis china energy crisis environment contamination wind energy renewable energy resources statistics global wind energy council gwec wind power development power 360000 mw;wind turbines vibrations fault diagnosis monitoring condition monitoring wind farms wind power generation;wind farms;fault diagnosis	With the advent of a more severe energy crisis and environment contamination, wind energy, as one of the green and renewable energy resources, has attracted more and more attention worldwide [1], [2]. According to statistics issued by the Global Wind Energy Council (GWEC), by the end of 2014, the global installed capacity had reached 360,000 MW, while the installed capacity in China accounted for 114,763 MW, nearly one third of the total, as illustrated in Fig. 1. Meanwhile, it is envisioned in 2050 Blueprint of Wind Power Development in China that by the years 2030 and 2050, the scale of installed capacity will exceed 4 × 105 MW and 106 MW, respectively, so as to meet 8.4% and 17% of the demand for electricity nationwide, enabling wind energy to be one of five main energy resources.	blueprint;capability maturity model;microwave;sparse matrix	Xuefeng Chen;Ruqiang Yan;Yanmeng Liu	2016	IEEE Instrumentation & Measurement Magazine	10.1109/MIM.2016.7462789	wind power;meteorology;power station;offshore wind power;engineering;wind hybrid power systems;electrical engineering;vibration;forensic engineering;physics	Arch	2.6220927384355397	7.771334522577315	16050
7c7e1d3aa152ae43610cb82824995bc0d159e6b8	an operation partitioning problem for automated assembly system design	fabrication;assemblage;inventory production manufacturing and automated systems;ensamble;fabricacion;heuristic method;atelier flexible;circuit vlsi;automatisation;metodo heuristico;automatizacion;simulated annealing;vlsi circuit;recuit simule;networks graphs heuristics;flexible manufacturing system;system design;methode lagrange;metodo lagrange;manufacturing;lagrangian method;sistema flexible produccion;recocido simulado;methode heuristique;joining;circuito vlsi;automation	This paper presents an operation partitioning problem OPP that arises from the design of an automated assembly system. To reduce the traffic flow of the system, the OPP assigns operations to machines so that the total number of movements of jobs between machines is minimized. This problem has applications in flexible manufacturing and VLSI design. In flexible manufacturing, OPP relates to a part grouping problem in which different parts are grouped into families. In VLSI design, this problem is related to a VLSI design problem in which a large circuit is partitioned into layers of small circuits. In this paper, we develop a simulated annealing heuristic that finds a near-optimal solution. Random problems are generated for examining the effectiveness of this heuristic.	partition problem	Reza H. Ahmadi;Christopher S. Tang	1991	Operations Research	10.1287/opre.39.5.824	mathematical optimization;simulation;simulated annealing;operations management;automation;manufacturing;fabrication;algorithm;systems design	Robotics	18.70244493201782	7.101337434147092	16083
54a1d6a261db8efc030b70c6efd0355b38b6b6c5	deterministic polynomial-time equivalence of computing the rsa secret key and factoring	public key cryptography;metodo polinomial;cryptographie cle publique;cle secrete;coppersmith s theorem;temps polynomial;factor calidad;rsa;cle publique;algorithme deterministe;probabilistic approach;securite donnee;cryptage rsa;approche deterministe;rsa ciphering;deterministic approach;polynomial time algorithm;temps calcul;factorization;deterministic algorithms;public key;factorizacion;cifrado rsa;polynomial method;secret key;clave secreta;enfoque probabilista;approche probabiliste;facteur qualite;enfoque determinista;polynomial time;llave publica;factorisation;rsa cryptosystem;tiempo computacion;computation time;methode polynomiale;security of data;q factor;tiempo polinomial	We address one of the most fundamental problems concerning the RSA cryptosystem: does the knowledge of the RSA public and secret key pair (e,d) yield the factorization of N = pq in polynomial time? It is well known that there is a probabilistic polynomial-time algorithm that on input (N,e,d) outputs the factors p and q. We present the first deterministic polynomial-time algorithm that factors N given (e,d) provided that e,d < φ(N). Our approach is an application of Coppersmith's technique for finding small roots of univariate modular polynomials.	algorithm;cryptosystem;integer factorization;key (cryptography);modulus of continuity;pp (complexity);polynomial;public-key cryptography;rsa (cryptosystem);time complexity;turing completeness;unbalanced circuit	Jean-Sébastien Coron;Alexander May	2004	Journal of Cryptology	10.1007/s00145-006-0433-6	discrete mathematics;computer science;theoretical computer science;mathematics;public-key cryptography;factorization;algorithm;algebra	Crypto	9.968669642179886	23.713766647487912	16087
38442751685ca147c483d28dcb5665b8b759f949	the two dimensional bin packing problem with side constraints		We propose a new variant of Bin Packing Problem, where rectangular items of different types need to be placed on a two-dimensional surface. This new problem type is denoted as two-dimensional Bin Packing with side constraints. Each bin may consist of different two-dimensional sides, and items of different types may not overlap on different sides of the same bin. By different parameter settings, our model may be reduced to either a two- or three-dimensional Bin Packing Problem. We propose practical applications of this problem in production and logistics. We further introduce lower bounds, and heuristics for upper bounds. We can demonstrate for a variety of instance classes proposed in literature that the GAP between those bounds is rather low. Additionally, we introduce a Column-Generation based algorithm that is able to further improve the lower bounds and comes up with good solutions. For a total of 400 instances, extended from previous literature, the final relative gap was just 6.8%.	bin packing problem;set packing	Markus Seizinger	2017		10.1007/978-3-319-89920-6_7	mathematical optimization;bin;mathematics;discrete mathematics;heuristics;bin packing problem	Theory	16.42300127915848	6.86140162948088	16107
82346ff16d08e017615c2fd6a16c5415fa551048	an smart stochastic approach to model plug-in hybrid electric vehicles charging effect in the optimal operation of micro-grids	plug in hybrid electric vehicles phevs;modified clonal selection mcs;micro grid mg	This paper proposes a sufficient stochastic framework to assess the influence of charging demand of plug-in hybrid electric vehicles (PHEVs) on the operation of renewable micro-grids (MGs). In this regard, an intelligent charging approach is proposed to shift the charging demand of PHEVs to off-peak load hours. In order to reduce the total cost of the MG, battery as the storage device is incorporated in the MG. Since the problem investigated is a hard complicated optimization problem, a new optimization method called Modified Clonal Selection algorithm (MCSA) is utilized too. The proposed MCSA employs two modification techniques to improve the position of antibodies in the face of local optima. For modeling the uncertainty of parameters, 2m-point estimate method (2m-PEM) is utilized as the stochastic framework. The feasibility and appropriate performance of the proposed method are examined on a standard MG.	clonal selection algorithm;genetic algorithm;load profile;local optimum;mathematical optimization;mg (editor);optimization problem;plug-in (computing);privacy-enhanced electronic mail;simulation;uncontrolled format string	Abdollah Kavousi-Fard;Reza Khorram-Nia;Mohammad-Ali Rostami;Alireza Abbasi	2015	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-141365	simulation	Robotics	4.940727190530489	4.763620462274926	16127
bab31f7a4288af5d3f88723ed2f333df68458c37	stack automata and compiling	mathematics;compilers;computer programming;automata;context sensitive grammars;mathematical model;patterns;memory devices;machine translation	Compilation consists of two parts, recognition and translation. A mathematical model is presented which embodies salient features of many modern compiling techniques. The model, called the stack automaton, has the desirable feature of being deterministic in nature. This deterministic device is generalized to a nondeterministic device (nondeterministic stack automaton) and particular instances of this more general device are noted. Sets accepted by nondeterministic stack automata are recursive. Each set accepted by a deterministic linear bounded automaton is accepted by some nonerasing stack automaton. Each context-sensitive language is accepted by some (deterministic) stack automaton.	automata theory;compiler;context-sensitive language;linear bounded automaton;mathematical model;pushdown automaton;recursion	Seymour Ginsburg;Sheila A. Greibach;Michael A. Harrison	1967	J. ACM	10.1145/321371.321385	powerset construction;deterministic context-free language;deterministic pushdown automaton;nondeterministic finite automaton with ε-moves;nested stack automaton;discrete mathematics;büchi automaton;nondeterministic finite automaton;call stack;computer science;nested word;theoretical computer science;two-way deterministic finite automaton;deterministic finite automaton;probabilistic automaton;continuous automaton;deterministic automaton;mathematical model;ω-automaton;computer programming;machine translation;programming language;linear bounded automaton;mobile automaton;timed automaton;pushdown automaton;embedded pushdown automaton;algorithm	Logic	-1.9570035836487119	22.06046636584414	16152
d2c560f904a431b0cf2b96d2b19e4395f3adfc9d	on the complexity of trial and error for constraint satisfaction problems		In a recent work of Bei, Chen and Zhang (STOC 2013), a trial and error model of computing was introduced, and applied to some constraint satisfaction problems. In this model the input is hidden by an oracle which, for a candidate assignment, reveals some information about a violated constraint if the assignment is not satisfying. In this paper we initiate a systematic study of constraint satisfaction problems in the trial and error model. To achieve this, we first adopt a formal framework for CSPs, and based on this framework we define several types of revealing oracles. Our main contribution is to develop a transfer theorem for each type of the revealing oracle, under a broad class of parameters. To any hidden CSP with a specific type of revealing oracle, the transfer theorem associates another, potentially harder CSP in the normal setting, such that their complexities are polynomial time equivalent. This in principle transfers the study of a large class of hidden CSPs, possibly with a promise on the instances, to the study of CSPs in the normal setting. We then apply the transfer theorems to get polynomialtime algorithms or hardness results for hidden CSPs, including satisfaction problems, monotone graph properties, isomorphism problems, and the exact version of the Unique Games problem. Most of the proofs of these results are short and straightforward, which exhibits the power of the transfer theorems. Institute for Computer Science and Control, Hungarian Academy of Sciences, Budapest, Hungary (Gabor.Ivanyos@sztaki.mta.hu). Centre for Quantum Technologies, National University of Singapore, Singapore 117543 (kulraghav@gmail.com). Centre for Quantum Technologies, National University of Singapore, Singapore 117543 (cqtqy@nus.edu.sg). LIAFA, Univ. Paris 7, CNRS, 75205 Paris, France; and Centre for Quantum Technologies, National University of Singapore, Singapore 117543 (miklos.santha@liafa.jussieu.fr). Centre for Quantum Technologies, National University of Singapore, Singapore 117543 (aarthims@nus.edu.sg). ISSN 1433-8092 Electronic Colloquium on Computational Complexity, Report No. 34 (2014)	academy;algorithm;computer science;constraint satisfaction problem;cryptographic service provider;electronic colloquium on computational complexity;entity–relationship model;graph property;international standard serial number;oracle database;polynomial;polynomial-time reduction;quantum;symposium on theory of computing;transfer function;monotone	Gábor Ivanyos;Raghav Kulkarni;Youming Qiao;Miklos Santha;Aarthi Sundaram	2014	J. Comput. Syst. Sci.	10.1016/j.jcss.2017.07.005	mathematical optimization;combinatorics;mathematics;constraint satisfaction problem;algorithm	Theory	12.015851653902976	21.214477538933846	16175
6582f638aaedae3fe6a38d382dff12347c3b3119	multiple-project scheduling with controllable project duration and hard resource constraint: some solvable cases	resource constraint;controllable duration;service provider;resource allocation;data processing;data mining;customer relations;large scale;project scheduling;transaction processing;application service provider;resource constraints	In many large-scale project scheduling problems, multiple projects are either taking place at the same time or scheduled into a tight sequence in order to efficiently share a common resource. One example of this is the computing resource allocation at an Application Service Provider (ASP) which provides data processing services for multiple paying customers. Typical services provided by ASPs are data mining, payroll processing, internet-based storage backup services and Customer Relation Management (CRM) services. The processing mode of an ASP can be either batch or concurrent, depending on the type service rendered. For example, for CPU intensive or long processing time required services, it would be more economical to processes one customer request at a time in order to minimize the context switching overhead. While the data transaction processes within a service request are subject to certain precedence relationships, the requests from different customers to an ASP are independent of each other, and the total time required to process a service request depends on the computing resource allocated to that request. The related issue of achieving an optimal use of resources at ASPs leads to problem of project scheduling with controllable project duration. In this paper, we present efficient algorithms for solving several special cases of such multi-project scheduling problems with controllable project duration and hard resource constraints. Two types of problems are considered. In type I, the duration of each project includes a constant and a term that is inversely proportional to the amount of resource allocated. In type II, the duration of each individual project is a continuous decreasing function of the amount of resource allocated.	algorithm;backup;batch processing;central processing unit;concurrent computing;context switch;data mining;decision problem;emoticon;heuristic (computer science);internet;np-hardness;overhead (computing);real life;requirement;schedule (project management);scheduling (computing)	Chung-Yee Lee;Lei Lei	2001	Annals OR	10.1023/A:1010918518726	service provider;service level requirement;real-time computing;data processing;transaction processing;application service provider;resource allocation;computer science;operations management;database;schedule	DB	14.42701150442905	9.876996370981955	16193
6ae336acd99bdd4edbd05f69825a89bece1470bb	waiting time in an (s - 1, s) inventory system	waiting time	Steady-state distribution functions are derived for waiting time in an S-1, S inventory system in which arrivals are governed by members of the geometric Poisson family, resupply times are independently and identically distributed negative exponential variates, and service is on a first-come-first-served basis. For small values of S, probabilities can be computed readily from the final forms of the distribution functions using gamma and exponential function tables.		Isamu Higa;Arlin M. Feyerherm;Arlette L. Machado	1975	Operations Research	10.1287/opre.23.4.674	simulation;operations management;mathematics;operations research	Robotics	8.903554342289034	10.855920988908645	16210
a3de80c742c38ae657cbeacb4a7b15f97d9ad9ec	genetic based distribution service restoration with minimum average energy not supplied	distributed system;customer service;genetics;objective function;electricity distribution;electric power;fault isolation	This paper presents optimal planning of tie-switch operation in an electric power distribution system under an emergency feed condition, i.e. operation during a post-fault condition. A heuristic fault isolation algorithm and a genetic-based service restoration algorithm are proposed and compared. With the proposed restoration algorithm, high reliable service of electric distribution systems is expected. To ensure a small number of customer interruption, average energy not supplied (AENS) is used as the objective function to be minimized. 25-node and 118-node distribution test feeders were employed for test. Satisfactory results show that the genetic approach is appropriate to a kind of tie-switch operation planning in order to minimize effects of a permanent fault on customer service interruption.	circuit restoration	Thitipong Charuwat;Thanatchai Kulworawanichpong	2007		10.1007/978-3-540-71618-1_26	electric power;computer science;fault detection and isolation	HPC	6.174418398903623	4.961599937411405	16234
f5926367b7f37c0d5aca854284ef06f57d77229c	semantic complexity of classes of relational queries and query independent data partitioning	random sampling;relational database;satisfiability;data partitioning;uniform convergence;hash function	Complexity of Classes of Relational Queries and Query Independent Data Partitioning Shaibal Roy * Department of Computer Science, Stanford University We introduce a measure of the semantic complexity of classes of selection queries in relational databases. This measure allows us to extend certain probabilistic bounds hitherto provable only for individual queries to an entire class of queries. Two applications follow immediately from well known results in the theory of uniform convergence. The first addresses the issue of using a single set of random samples to estimate selectivities of an entire class of queries. The second application finds a small set of tuples such that all expensive queries in our class are represented in the sample. The issue of horizontal partitioning of relations in a parallel relational database is addressed. It is shown that for any class of queries having finite complexity, any partitioning scheme satisfying a certain query independent combinatorial constraint has the property that for every query in this class the workload is distributed evenly among all partitions. A common family of hash functions is shown to satisfy this constraint.	computer science;hash function;partition (database);provable security;relational database	Shaibal Roy	1991		10.1145/113413.113437	sampling;query optimization;uniform convergence;discrete mathematics;relational model;hash function;relational database;computer science;theoretical computer science;database;mathematics;conjunctive query;satisfiability	DB	13.740728577948904	21.287032858533344	16294
193c6f6e7a5a13f97db73641460a8201ff6cf2a6	fast demand response with datacenter loads		This paper shows how datacenters can provide value to the electric grid by functioning as fast and precisely-controllable loads. We discuss the substantial grid-side benefits available from high-penetration, finely-controllable, and fast controllable loads like datacenters. We then measure the power ramp rate and power control precision of an example compute cluster, and last experimentally demonstrate realtime power setpoint tracking with a simple distributed algorithm. These results are an important step toward implementing datacenter demand response at a sub-minute timescale.	computer cluster;data center;distributed algorithm;distributed control system;electric power quality;experiment;image scaling;ramp simulation software for modelling reliability, availability and maintainability;server (computing);setpoint (control system);total harmonic distortion	Josiah McClurg;Raghuraman Mudumbai;Joseph Hall	2016	2016 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT)	10.1109/ISGT.2016.7781219	embedded system;real-time computing;simulation;engineering	HPC	4.106190283953835	5.948249461117342	16386
93ea893ac8cb73c6c30152cecc41e6c069f8e0ba	heuristics for hybrid flow shops with controllable processing times and assignable due dates	insertion heuristics;flow shop scheduling;hybrid flow shop;operations research;decision maker;iterative algorithm;objective function;computer experiment;tabu search algorithm;scheduling;scheduling problem;assignable due dates;controllable processing times;branch and bound;local search;heuristic algorithm;management development	This paper considers a generalization of the permutation flow shop problem that combines the scheduling function with the planning stage. In this problem, each work center consists of parallel identical machines. Each job has a different release date and consists of ordered operations that have to be processed on machines from different machine centers in the same order. In addition, the processing times of the operations on some machines may vary between a minimum and a maximum value depending on the use of a continuously divisible resource. We consider a nonregular optimization criterion based on due dates which are not a priori given but can be fixed by a decision-maker. A due date assignment cost is included into the objective function. For this type of problems, we generalize well-known approaches for the heuristic solution of classical problems and propose constructive algorithms based on job insertion techniques and iterative algorithms based on local search. For the latter, we deal with the design of appropriate neighborhoods to find better quality solution. Computational results for problems with up to 20 jobs and 10 machine centers are given.	heuristic (computer science)	Jatinder N. D. Gupta;Karin Krüger;Volker Lauff;Frank Werner;Yuri N. Sotskov	2002	Computers & OR	10.1016/S0305-0548(01)00040-5	heuristic;job shop scheduling;decision-making;mathematical optimization;computer experiment;flow shop scheduling;computer science;local search;mathematics;iterative method;scheduling;branch and bound;algorithm	AI	15.884571800812202	7.930632542739785	16410
170353889542b579ab00389c0ea82ad3ba770270	highway dimension, shortest paths, and provably efficient algorithms	shortest path;half integral disjoint odd cycles packing;efficient algorithm;nearly linear time algorithm;s posa property;erd odblac	Computing driving directions has motivated many shortest path heuristics that answer queries on continental scale networks, with tens of millions of intersections, literally instantly, and with very low storage overhead. In this paper we complement the experimental evidence with the first rigorous proofs of efficiency for many of the heuristics suggested over the past decade. We introduce the notion of highway dimension and show how low highway dimension gives a unified explanation for several seemingly different algorithms.	algorithm;heuristic (computer science);köppen climate classification;overhead (computing);shortest path problem	Ittai Abraham;Amos Fiat;Andrew V. Goldberg;Renato F. Werneck	2010		10.1137/1.9781611973075.64	mathematical optimization;combinatorics;discrete mathematics;mathematics;shortest path problem;k shortest path routing;algorithm	Theory	21.743466805274586	21.839207808122477	16456
91bc48a14e355f6332758e3455620001ec494702	a job scheduling model for a flexible manufacturing machine	automatic control;pulp manufacturing;job shop scheduling flexible manufacturing systems virtual manufacturing switches pulp manufacturing manufacturing industries production planning manufacturing automation automatic control service robots;flexible manufacturing systems;job shop scheduling;manufacturing automation;service robots;manufacturing industries;flexible manufacturing;production planning;switches;job scheduling;virtual manufacturing	The problems addressed in this paper arise in industry when flexible, automated machines are used to manufacture parts (jobs). These machines include numerically controlled (N/C) tools, robots,...etc. The goal is to avoid unnecessary set-up operations in order to effectively utilize the michines. In this paper we focus on developing a job scheduling model that considers the tool requirement of each job in an explicit fashion.	job scheduler;scheduling (computing)	C. S. Tang	1986		10.1109/ROBOT.1986.1087633	manufacturing execution system;job shop scheduling;integrated computer-aided manufacturing;flow shop scheduling;process development execution system;network switch;computer science;engineering;job scheduler;industrial engineering;automatic control;scheduling;computer-integrated manufacturing;manufacturing;advanced manufacturing;manufacturing engineering	Robotics	10.466631247163217	4.698181344706956	16543
bfb9ef1dea4464ef7e0fabc3226e47a89fb6ffeb	simulation-based performance assessment of tool requalification strategies in wafer fabs		In this paper, we discuss requalification strategies for stepper tools in semiconductor wafer fabrication facilities (wafer fabs). Before processing lots on steppers, the steppers have to be qualified. A mathematical programming formulation is used periodically to determine appropriate qualification plans. These plans will be implemented at the shop-floor. During consecutive planning epochs, certain already established qualifications of steppers can be canceled, for instance, due to stepper breakdowns. We study the performance of several requalification strategies in this situation. Therefore, we use a discrete-event simulation framework that allows for applying the mathematical programming formulation in a rolling horizon manner and for performing the requalification strategies while the production is executed in the simulation. We demonstrate by designed simulation experiments that some of the proposed strategies perform well with respect to throughput and cycle time while requiring only a low additional qualification effort.		Denny Kopp;Lars Mönch;Detlef Pabst;Marcel Stehli	2018	2018 IEEE 14th International Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2018.8560476	throughput;real-time computing;wafer;computer science;stepper	Robotics	10.823998427938506	4.59643999828893	16559
6bd81b28da69bd48d99d9b4478452333cccbbf19	reflections for quantum query algorithms	continuous time;information spreading;randomized algorithms;error reduction;distributed computing;boolean function;semi definite program;query complexity;quantum physics;quantum algorithm;leader election;weak conductance;lower bound	We show that any boolean function can be evaluated optimally by a quantum query algorithm that alternates a certain fixed, input-independent reflection with a second reflection that coherently queries the input string. Originally introduced for solving the unstructured search problem, this two-reflections structure is therefore a universal feature of quantum algorithms.  Our proof goes via the general adversary bound, a semi-definite program (SDP) that lower-bounds the quantum query complexity of a function. By a quantum algorithm for evaluating span programs, this lower bound is known to be tight up to a sub-logarithmic factor. The extra factor comes from converting a continuous-time query algorithm into a discrete-query algorithm. We give a direct and simplified quantum algorithm based on the dual SDP, with a bounded-error query complexity that matches the general adversary bound.  Therefore, the general adversary lower bound is tight; it is in fact an SDP for quantum query complexity. This implies that the quantum query complexity of the composition f o (g,..., g) of two boolean functions f and g matches the product of the query complexities of f and g, without a logarithmic factor for error reduction. It efficiently characterizes the quantum query complexity of a read-once formula over any finite gate set. It further shows that span programs are equivalent to quantum query algorithms.	adversary (cryptography);decision tree model;quantum algorithm;reflection (computer graphics);search problem;semiconductor industry	Ben Reichardt	2011			quantum fourier transform;query optimization;combinatorics;discrete mathematics;boolean conjunctive query;quantum complexity theory;computer science;theoretical computer science;quantum capacity;leader election;mathematics;boolean function;upper and lower bounds;randomized algorithm;quantum computer;quantum algorithm;algorithm;quantum phase estimation algorithm;quantum sort	Theory	10.005630733065892	23.136907978017963	16607
36c88b7d0594dd923b788c5ca189cc6d3d06a0e3	restricted path consistency revisited		Restricted path consistency (RPC) is a strong local consistency for binary constraints that was proposed 20 years ago and was identified as a promising alternative to arc consistency (AC) in an early experimental study of local consistencies for binary constraints. However, and in contrast to other strong local consistencies such as SAC and maxRPC, it has been neglected since then. In this paper we revisit RPC. First, we propose RPC3, a new lightweight RPC algorithm that is very easy to implement and can be efficiently applied throughout search. Then we perform a wide experimental study of RPC3 and a light version that achieves an approximation of RPC, comparing them to state-of-theart AC and maxRPC algorithms. Experimental results clearly show that restricted RPC is by far more efficient than both AC and maxRPC when applied throughout search. These results strongly suggest that it is time to reconsider the established perception that MAC is the best general purpose method for solving binary CSPs.	algorithm;approximation;cryptographic service provider;experiment;local consistency;remote procedure call;sac;solver	Kostas Stergiou	2015		10.1007/978-3-319-23219-5_30	mathematical optimization;real-time computing;mathematics;algorithm	AI	8.123535150650262	15.952030912577309	16668
d1cb60181570a5fa9fd6d28ce0e86f73934499b7	computing abstract decorations of parse forests using dynamic programming and algebraic power series	power series;dynamic programming;regle inference;reconocimiento lenguaje;programacion dinamica;stochastic process;reconnaissance langage;complexite calcul;canonical form;language theory;context free language;forme canonique;non commutative;gramatica cf;dynamic program;teoria lenguaje;isomorphism;serie algebrique;language recognition;isomorfismo;algorithme;inference rule;lenguaje cf;grammaire cf;algorithm;automate a pile;parsing;complejidad computacion;analyse syntaxique;semiring;computational linguistic;analisis sintaxico;computational complexity;context free grammar;syntactic analysis;polymorphism;programmation dynamique;processus stochastique;forma canonica;polymorphisme;polimorfismo;isomorphisme;algebraic series;proceso estocastico;push down automaton;algebraic power series;lenguaje formal;theorie langage;langage cf;formal language;automata a pila;regla inferencia;algoritmo;langage formel	Algebraic power series provide a very generic parsing paradigm: an abstract semiring plays the role of the parse forest domain as well as the role of a decoration domain. We use the formalism of algebraic power series over non-commuting variables to show how to apply dynamic programming techniques to compute decorations in an abstract semiring, i.e. without specializing for a particular interpretation such as booleans (for recognition), forests (for parsing), or any decoration domain with more practical purposes, such as probabilities or a variety of feature structures for computational linguistics.	dynamic programming	Frédéric Tendeau	1998	Theor. Comput. Sci.	10.1016/S0304-3975(97)00271-5	stochastic process;combinatorics;computer science;artificial intelligence;parsing;mathematics;programming language;algorithm	Theory	-2.5937412643392666	19.771010178155752	16723
66dbc347db140f4897999972f6dba2ab2e5a7c04	a moderately exponential time algorithm for full degree spanning tree	likefeedback vertex set;spanning tree problem;non-local problem;exponential time;fluid network;time o;exponential time algorithm;graph g;connected dominating set;full degree spanning tree;full degree;exact algorithm	We consider the well studied Full Degree Spanning Tree problem, a NP-complete variant of the Spanning Tree problem, in the realm of moderately exponential time exact algorithms. In this problem, given a graph G, the objective is to find a spanning tree T of G which maximizes the number of vertices that have the same degree in T as in G. This problem is motivated by its application in fluid networks and is basically a graph-theoretic abstraction of the problem of placing flow meters in fluid networks. We give an exact algorithm for Full Degree Spanning Tree running in time O(1.9172). This adds Full Degree Spanning Tree to a very small list of “non-local problems”, like Feedback Vertex Set and Connected Dominating Set, for which non-trivial (non brute force enumeration) exact algorithms are known.	best, worst and average case;brute-force search;circa;computation;connected dominating set;exptime;exact algorithm;feedback vertex set;file spanning;graph coloring;graph theory;hamiltonian path problem;heuristic (computer science);information processing letters;interpolation;kruskal's algorithm;lecture notes in computer science;memorandum;np-completeness;nonlocal lagrangian;recursion;spanning tree;time complexity;travelling salesman problem;whole earth 'lectronic link	Serge Gaspers;Saket Saurabh;Alexey A. Stepanov	2008		10.1007/978-3-540-79228-4_42	segment tree;euclidean minimum spanning tree;mathematical optimization;combinatorics;discrete mathematics;kruskal's algorithm;exponential tree;minimum degree spanning tree;spanning tree;steiner tree problem;prim's algorithm;minimum spanning tree;loop-erased random walk;k-ary tree;interval tree;connected dominating set;k-minimum spanning tree;mathematics;fractal tree index;tree structure;reverse-delete algorithm;distributed minimum spanning tree;shortest-path tree	Theory	22.68821335520152	25.56752701627477	16763
fbd52f8bb8f03e370e015608724e619c587c0ce8	the minimum connected dominating set problem: formulation, valid inequalities and a branch-and-cut algorithm	computational result;integer programming formulation;branchand-cut algorithm;best result;branch-and-cut algorithm;new valid inequality;strongest known formulation;lower bound;exact algorithm;current computational result;specific separation algorithm	computational result;integer programming formulation;branchand-cut algorithm;best result;branch-and-cut algorithm;new valid inequality;strongest known formulation;lower bound;exact algorithm;current computational result;specific separation algorithm	algorithm;branch and cut;connected dominating set	Luidi Simonetti;Alexandre Salles da Cunha;Abilio Lucena	2011		10.1007/978-3-642-21527-8_21	mathematical optimization;combinatorics;discrete mathematics;mathematics	Logic	23.521737286910675	15.677171028493632	16810
5935e31dd44660ddd99cbe3951ff154e8fbb5d15	nondeterministically selective sets	lowness;nonuniform complexity;computational complexity;selectivity	"""In this note, we study NP-selective sets (formally, sets that are selective via NPSVt functions) as a natural generalization of P-selective sets. We show that, assuming P 6 = NP \coNP, the class of NP-selective sets properly contains the class of P-selective sets. We study several properties of NP-selective sets such as self-reducibility, hardness under various reductions, lowness, and nonuniform complexity. We prove many of our results via a \relativization technique,"""" by using the known properties of P-selective sets. Using this technique, we strengthen a result of Longpr e and Selman on hard promise problems and show that the result \NP (NP \coNP)=poly) PH = NP NP """" is implicit in Karp and Lipton's seminal result on nonuniform classes. Some of these results appeared in preliminary form in \Selectivity"""" (a 1993 ICCI Conference"""	ibm ssec;nondeterministic algorithm;p versus np problem;random self-reducibility	Lane A. Hemaspaandra;Albrecht Hoene;Ashish V. Naik;Mitsunori Ogihara;Alan L. Selman;Thomas Thierauf;Jie Wang	1995	Int. J. Found. Comput. Sci.	10.1142/S0129054195000214	combinatorics;discrete mathematics;selectivity;computer science;mathematics;computational complexity theory;algorithm	Theory	8.92482448908508	20.27472876429757	16818
fa80ea36279ff1dcfa1146bd3d6c8c6d82115df2	on dynamic resource allocation in systems with bursty sources	dynamic resource allocation	There is a trend to use computing resources in a way that is more removed from the technical constraints. Users buy compute time on machines that they do not control or necessarily know the specifics of. Conversely this means the providers of such resources have more freedom in allocating them amongst different tasks. They can use this freedom to provide more, or better, service by reallocating resources as demand for them changes. However deciding when to reallocate resources is not trivial. In order to make good reallocation decisions, this thesis constructs a series of models. Each of the models concerns a resource allocation problem in the presence of bursty sources. The focus of the modelling, however, varies. In its most basic form it considers several different job types competing over the allocation of a limited number of servers. The goal there is to minimize the (weighted) mean time jobs spend in the system. The weighting can reflect the relative importance of the different job types. Reallocation of servers between job types is in general considered to be neither free nor instantaneous. We then show how to find the optimal static allocation of servers over job types. Finding the optimal dynamic allocation of servers is formulated as solving a Markov decision process. We show that this is practically unfeasible for all but the most simple systems. Instead a number of heuristics are introduced. Some are fluid-approximation based and some are parameterless, i.e. do not require the a priori knowledge of parameters of the system. The performance of these heuristic policies is then explored in a series of simulations. A slightly different model is formulated next. Its goal is not to optimize allocation of servers over several job types, but rather between powered up and powered down states. In the powered up state servers can provide service for incoming jobs. In the powered down state servers cannot service incoming jobs but incur a profit due to power savings. Balancing power and performance is again formulated as a Markov decision process. This is not explicitly solved but instead some of the heuristics considered earlier are adapted to give dynamic policies for powering servers up and v down. Their performance is again tested in a number of simulations, including some where the arrival process is not only bursty but also non-Markovian. The third and final model considers allocation of servers over different job types again. This time the servers experience breakdowns and subsequent repairs. During a repair period the servers cannot process any incoming jobs. To reduce the complexity of this model, it is assumed that switches of servers between job types are instantaneous, albeit not necessarily free. This is modeled as a Markov decision process and we show how to find the optimal static allocation of servers. For the dynamic allocation previously considered heuristics are adapted again. Simulations then show the performance of these heuristics and the optimal static allocation in a number of scenarios.	approximation;computer simulation;heuristic (computer science);job stream;markov chain;markov decision process;memory management;network switch	Joris Slegers	2009			resource allocation	Metrics	12.222018225664787	10.660492761957311	16848
ccae146ee77e9cf6a14f3d8b7e27b9e64f0cb2ad	computer search for large trees with minimal abc index		Abstract The atom-bond connectivity ( ABC ) index of a graph G  = ( V, E ) is defined as A B C ( G ) = ∑ v i v j ∈ E ( d i + d j − 2 ) / ( d i d j ) , where V  = { v 0 , v 1 ,⋅⋅⋅, v n  − 1 } and d i denotes the degree of vertex v i of G . This molecular structure descriptor found interesting applications in chemistry, and has become one of the most actively studied vertex-degree-based graph invariants. However, the problem of characterizing n -vertex tree(s) with minimal ABC index remains open and was coined as the “ ABC index conundrum”. In attempts to guess the general structure of such trees, several computer search algorithms were developed and tested up to n  = 800. However, for large n , all current search programs seem too powerless. For example, the fastest one up to date reported recently in [30] costs 2.2 h for n  = 800 on a single PC with two CPU cores. In this paper, we significantly refine the known features of the degree sequence of a tree with minimal ABC index. With the refined features a search program was implemented with OpenMP. Our program was tested on a single PC with 4 CPU cores, and identified all n -vertex tree(s) with minimal ABC index up to n  = 1100 within 207.1 h. Some observations are made based on the search results, which indicate some possible directions in further investigation of the problem of characterizing n -vertex tree(s) with minimal ABC index.		Wenshui Lin;Jianfeng Chen;Zhixi Wu;Darko Dimitrov;Linshan Huang	2018	Applied Mathematics and Computation	10.1016/j.amc.2018.06.012	combinatorics;degree (graph theory);mathematical optimization;vertex (geometry);multi-core processor;invariant (mathematics);search algorithm;mathematics;graph	Vision	23.070327625107428	25.204147460965135	16901
5100cdfc48139476d798fe6d61132a509bae6a54	loading constraints in vehicle routing problems: a focus on axle weight limits		This work is supported by the Interuniversity Attraction Poles Programme initiated by the Belgian Science Policy Office (COMEX project: Combinatorial Optimization: Metaheuristics and Exact methods). The computational resources and services used in this work were provided by the VSC (Flemish Supercomputer Center), funded by the Research Foundation - Flanders (FWO) and the Flemish Government - department EWI.	vehicle routing problem	Hanne Pollaris	2018	4OR	10.1007/s10288-017-0352-4	mathematics;mathematical optimization;science policy;simulation;vehicle routing problem;metaheuristic;government;combinatorial optimization;axle;supercomputer;flemish	Theory	18.89778337873452	4.4250229727272705	16942
79e965a7fdbab9d3f89bf2f43883fcd3f98d40e7	lz77-like compression with fast random access	database indexing;lempel ziv;individual sequence;data compression;sequences entropy databases indexing data mining data compression computer science data structures bioinformatics dna;text analysis data compression database indexing grammars;construction industry;text analysis;fast random access;grammars;text decompression;indexing;lz77 like compression;data structures;feature extraction;indexation;entropy;repetitive sequence;encoding;indexing scheme compression;random access;highly repetitive sequence databases;lempel ziv text parsing;indexing scheme compression lz77 like compression fast random access lempel ziv text parsing entropy text decompression highly repetitive sequence databases	We introduce an alternative Lempel-Ziv text parsing, LZ-End, that converges to the entropy and in practice gets very close to LZ77. LZ-End forces sources to finish at the end of a previous phrase. Most Lempel-Ziv parsings can decompress the text only from the beginning. LZ-End is the only parsing we know of able of decompressing arbitrary phrases in optimal time, while staying closely competitive with LZ77, especially on highly repetitive collections, where LZ77 excells. Thus LZ-End is ideal as a compression format for highly repetitive sequence databases, where access to individual sequences is required, and it also opens the door to compressed indexing schemes for such collections.	database;lz77 and lz78;lempel–ziv–stac;parsing expression grammar;random access	Sebastian Kreft;Gonzalo Navarro	2010	2010 Data Compression Conference	10.1109/DCC.2010.29	data compression;database index;search engine indexing;entropy;text mining;data structure;feature extraction;computer science;theoretical computer science;pattern recognition;data mining;random access;encoding	DB	11.788906419291072	27.7029217192472	16946
4bf2d15815f61e11011f05068fb0b604bfaa0c5d	optimal paths in probabilistic networks: a case with temporary preferences	shortest path;reseau probabiliste;preference theory;transportation problem;probleme transport;fonction utilite;utility function;reseau;red;chemin optimal;algorithme;algorithm;algorritmo;optimal path;theorie utilite;theorie preference;fonction utilite quadratique;chemin plus court;network;probabilistic network;utility theory	The classical shortest route problem in networks assumes deterministic arc weights and a utility (or cost) function that is linear over path weights for route evaluation. When the environment is stochastic and the “traveler’s” utility function for travel attributes is nonlinear, we define “optimal paths” that maximize the expected utility. We review the concepts of remporary and ~r~u~e~r prcfcences for ~rn~ring a traveler’s preference for available subpaths. It has been shown before that when the utility function is linear or exponential, permanent preferences prevail and an efficient Dijkstra-type algorithm [31 is available that determines the optimal path. In this paper an exact procedure is developed for determining an optimal path when the utility function isquadratic-a case where permanent preferences do not always prevail. Thealgorithm uses subpath comparison rules to establish permanent preferences, when possible, among subpaths of the given network. Although in the worst case the algorithm implicitly enumerates all paths (:he number of optrations increasing exponentially with the size of the network), we find, from the ~m~tationai experience reported, that the number of porenrioily optimal paths to evaluate is generally managcable.	best, worst and average case;computation;dijkstra's algorithm;expected utility hypothesis;heuristic;loss function;nonlinear system;quadratic function;risk aversion;shortest path problem;the times;time complexity;uniform resource identifier	Pitu B. Mirchandani;Hossein Soroush	1985	Computers & OR	10.1016/0305-0548(85)90034-6	transportation theory;mathematical optimization;computer science;mathematics;mathematical economics;shortest path problem;utility	AI	23.438014899894025	16.863010564895845	16950
9c73b5c2d8e44388fd382871f75d251597c2ca06	fast detection of unsolvable planning instances using local consistency	automated planning;local consistency;unsolvable instances;algorithm;datavetenskap datalogi;computer science	There has been a tremendous advance in domain-independent planning over the past decades, and planners have become increasingly efficient at finding plans. However, this has not been paired by any corresponding improvement in detecting unsolvable instances. Such instances are obviously important but largely neglected in planning. In other areas, such as constraint solving and model checking, much effort has been spent on devising methods for detecting unsolvability. We introduce a method for detecting unsolvable planning instances that is loosely based on consistency checking in constraint programming. Our method balances completeness against efficiency through a parameter k: the algorithm identifies more unsolvable instances but takes more time for increasing values ofk. We present empirical data for our algorithm and some standard planners on a number of unsolvable instances, demonstrating that our method can be very efficient where the planners fail to detect unsolvability within reasonable resource bounds. We observe that planners based on the h m heuristic or pattern databases are better than other planners for detecting unsolvability. This is not a coincidence since there are similarities (but also significant differences) between our algorithm and these two heuristic methods.	admissible heuristic;anytime algorithm;artificial intelligence;automated planning and scheduling;benchmark (computing);bitbucket;boolean satisfiability problem;causal graph;complex systems;computational complexity theory;constraint programming;constraint satisfaction problem;cost efficiency;database;european association for theoretical computer science;graph property;heuristic (computer science);indirection;local consistency;model checking;penetration test;problem solving;refinement (computing);scheduling (computing);sensor;springer (tank);state space	Christer Bäckström;Peter Jonsson;Simon Ståhlberg	2013			mathematical optimization;machine learning;mathematics;algorithm	AI	12.87710229701881	16.85071872756606	16965
a9819a2e249bf8e830668dcef848871473d9a993	applications of complex network theory on power grids	security complex network theory power grids statistical analysis tools global cascade failure ieee 118 polish 2383 bus systems power network reliability;statistical analysis;transmission line measurements complex networks power grids level measurement power transmission;statistical analysis power grids power system reliability power system security;power system reliability;power grids;power system security	Complex network statistical analysis tools are helpful to understand silent features of complex systems. One of the most important system growing intentions in recent days is power grid. Complex system like power system with specific topology can undergo a local or global cascade failure. Prediction and prevention of these cascade failures or blackouts is obligatory. In this paper some of the most important properties of power grids infrastructure are investigated using Complex Network Theory (CNT) techniques and methodologies. Discussions are conducted on different measures of network structures of IEEE 118 and Polish 2383 bus systems. These results and structure of power network has important implication on reliability and security.	cascading failure;complex network;complex system;complex systems;network theory	Muhammad Jawad;Bei Gou	2013	IEEE International Conference on Electro-Information Technology , EIT 2013	10.1109/EIT.2013.6632712	power-flow study;electronic engineering;engineering;electrical engineering;theoretical computer science;computer security;power optimization;statistics	HPC	-2.5808972179996865	7.708574740839154	16966
4eee20e53ec118586f8b2bb236d25092598d38f5	on the density of languages accepted by turing machines and other machine models		A language is dense if the set of all infixes (or subwords) of the language is the set of all words. Here, it is shown that it is decidable whether the language accepted by a nondeterministic Turing machine with a one-way read-only input and a reversal-bounded read/write worktape (the read/write head changes direction at most some fixed number of times) is dense. From this, it is implied that it is also decidable for one-way reversal-bounded queue automata, one-way reversal-bounded stack automata, and one-way reversal-bounded $k$-flip pushdown automata (machines that can flip their pushdowns up to $k$ times). However, it is undecidable for deterministic Turing machines with two 1-reversal-bounded worktapes (even when the two tapes are restricted to operate as 1-reversal-bounded pushdown stacks).	turing machine	Oscar H. Ibarra;Ian McQuillan	2018	Journal of Automata, Languages and Combinatorics	10.25596/jalc-2018-189	non-deterministic turing machine;discrete mathematics;automaton;pushdown automaton;undecidable problem;stack (abstract data type);turing machine;decidability;mathematics;queue	Theory	-0.8343809911202468	22.368660891570194	17004
43b4aee8c254412fee7653a6d6a477e0eb8e9928	concentrated differential privacy: simplifications, extensions, and lower bounds		Concentrated differential privacy” was recently introduced by Dwork and Rothblum as a relaxation of differential privacy, which permits sharper analyses of many privacy-preserving computations. We present an alternative formulation of the concept of concentrated differential privacy in terms of the Rényi divergence between the distributions obtained by running an algorithm on neighboring inputs. With this reformulation in hand, we prove sharper quantitative results, establish lower bounds, and raise a few new questions. We also unify this approach with approximate differential privacy by giving an appropriate definition of “approximate concentrated differential privacy.” ∗Supported by an NDSEG Fellowship and NSF grant CNS-1237235. †Supported by NSF grants CCF-1116616, CCF-1420938, and CNS-1237235. 1 ar X iv :1 60 5. 02 06 5v 1 [ cs .C R ] 6 M ay 2 01 6	approximation algorithm;computation;cynthia dwork;differential privacy;ibm notes;linear programming relaxation;rényi entropy	Mark Bun;Thomas Steinke	2016		10.1007/978-3-662-53641-4_24	mathematical optimization;discrete mathematics;theoretical computer science;mathematics	Theory	15.754240889260965	18.566767007788528	17133
32de652889ad64efa60ca397da0589399df37556	the generalized terminal backup problem	05c40;polynomial time algorithm;survivable network design problem;skew supermodular function;90c27;connectivity augmentation problem;68r10;05c85	We consider the following network design problem, that we call the Generalized Terminal Backup Problem: given a graph (or a hypergraph) G0 = (V,E0), a set of (at least 2) terminals T ⊆ V and a requirement r(t) for every t ∈ T , nd a multigraph G = (V,E) such that λG0+G(t, T − t) ≥ r(t) for any t ∈ T . In theminimum cost version the objective is to nd G minimizing the total cost c(E) = ∑ uv∈E c(uv), given also costs c(uv) ≥ 0 for every pair u, v ∈ V . In the degree-speci ed version the question is to decide whether such a G exists, satisfying that the number of edges is a prescribed value m(v) at each node v ∈ V . The Terminal Backup Problem solved in [1] is the special case where G0 is the empty graph and r(t) = 1 for every terminal t ∈ T . We solve the Generalized Terminal Backup Problem in the following two cases. In the rst case we solve the degree-speci ed version by a splitting-o theorem. This splitting-o theorem in turn provides the solution for the minimum cost version in the case when c is node-induced, that is c(uv) = w(u) + w(v) for some node weights w : V → R+. In the second solved case we turn to the general minimum cost version, and we are able to solve it when G0 is the empty graph. This includes the Terminal Backup Problem [1] (r ≡ 1) and the Maximum-Weight b-matching Problem (T = V ). The solution depends on an interesting new variant of a theorem of Lovász and Cherkassky, and on the solution of the so-called Simplex Matching problem [1]. Our algorithms run in strongly polynomial time for both problems.	algorithm;backup;multigraph;network planning and design;time complexity	Attila Bernáth;Yusuke Kobayashi;Tatsuya Matsuoka	2015	SIAM J. Discrete Math.	10.1137/140972858	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	23.180390864677975	18.582878632817128	17141
1e4bc455d3d164af09c1ac646d1b902ddd42629d	on local transformation of polygons with visibility properties	use;objet;visibilite;optimisation;enumeration;visibilidad;combinatorics;optimizacion;enumeracion;propiedad;geometrie algorithmique;bord;combinatoria;virgule fixe;combinatoire;computational geometry;polygone;transformacion;object;estrategia;punto fijo;taille;simulated annealing;utilizacion;coma fija;monotonie;fixed point;borde;strategy;polygon;upper bound;minimo;utilisation;recuit simule;visibility;edge;point fixe;random walk;minimum;monotonicity;talla;modificacion;xed point;flip;propriete;poligono;number;recocido simulado;geometria computacional;optimization;transformation locale;monotonia;local transformation;transformation;marcha aleatoria;properties;borne superieure;nombre;size;strategie;objeto;fix point;constante;marche aleatoire;numero;cota superior;modification;constant	One strategy for the enumeration of a class of objects is local transformation, in whch new objects of the class are produced by means of a small modification of a previously-visited object in the same class. When local transformation is possible, the operation can be used to generate objects of the class via random walks, and as the basis for such optimization heuristics as simulated annealing.For general simple polygons on fixed point sets, it is still not known whether the class of polygons on the set is connected via a constant-size local transformation. In this paper, we exhibit a simple local transformation for which the following polygon classes are connected: monotone, x-monotone, star-shaped, (weakly) edge-visible and (weakly) externally visible. The latter class is particularly interesting as it is the most general polygon class known to be connected under local transformation. For each of the polygon classes, we also provide asymptotically-tight worst-case upper bounds on the minimum number of operations required to transform one member of the class to any other.		M. Carmen Hernando;Michael E. Houle;Ferran Hurtado	2002	Theor. Comput. Sci.	10.1016/S0304-3975(01)00409-1	combinatorics;point in polygon;topology;computational geometry;star-shaped polygon;polygon;mathematics;geometry;polygon covering	ECom	22.194806496431692	30.63517858816523	17178
43e42103342da7118eb9c0c06c67f3cd9f8899d1	graph design for secure multiparty computation over non-abelian groups	abelian group;graph coloring;non abelian groups;passive adversary;percolation theory;multiparty computation;secure multiparty computation	Recently, Desmedt et al. studied the problem of achieving secure n-party computation over non-Abelian groups. They considered the passive adversary model and they assumed tha t the parties were only allowed to perform blackbox operations over the finite group G. They showed three results for the n-product functionfG(x1, . . . , xn) := x1 · x2 · . . . · xn, where the input of partyPi is xi ∈ G for i ∈ {1, . . . , n}. First, if t ≥ ⌈n2 ⌉ then it is impossible to have at-private protocol computingfG. Second, they demonstrated that one could t-privately computefG for any t ≤ ⌈ 2 ⌉−1 in exponential communication cost. Third, they constructed a randomized algorithm withO(n t) communication complexity for anyt < n 2.948 . In this paper, we extend these results in two directions. First, we use perco lation theory to show that for any fixed ǫ > 0, one can design a randomized algorithm for any t ≤ n 2+ǫ usingO(n) communication complexity, thus nearly matching the known upper bound ⌈ 2 ⌉− 1. This is the first time that percolation theory is used for multiparty computation . Second, we exhibit a deterministic construction having polynomial communication cos t for anyt = O(n) (again for any fixed ǫ > 0). Our results extend to the more general function f̃G(x1, . . . , xm) := x1 · x2 · . . . · xm wherem ≥ n and each of then parties holds one or more input values.	adversary model;communication complexity;percolation theory;polynomial;randomized algorithm;secure multi-party computation;time complexity	Xiaoming Sun;Andrew Chi-Chih Yao;Christophe Tartary	2008		10.1007/978-3-540-89255-7_3	combinatorics;discrete mathematics;non-abelian group;theoretical computer science;graph coloring;mathematics;abelian group;secure multi-party computation;percolation theory;algebra	Theory	8.244969478477826	25.174571945631964	17194
597819ce31eb82990d6c51d77fbbc42b91c5ade5	an optimal algorithm for the indirect covering subtree problem	location problem;efficient algorithm;graph algorithm;optimal algorithm;lower bound	We consider the indirect covering subtree problem (Kim et al., 1996). The input is an edge weighted tree graph along with customers located at the nodes. Each customer is associated with a radius and a penalty. The goal is to locate a tree-shaped facility such that the sum of setup and penalty cost is minimized. The setup cost equals the sum of edge lengths taken by the facility and the penalty cost is the sum of penalties of all customers whose distance to the facility exceeds their radius. The indirect covering subtree problem generalizes the single maximum coverage location problem on trees where the facility is a node rather than a subtree. Indirect covering subtree can be solved in O(n log n) time (Kim et al., 1996). A slightly faster algorithm for single maximum coverage location with a running time of O(n log n/ log log n) has been provided (Spoerhase and Wirth, 2009). We achieve time O(n log n) for indirect covering subtree thereby providing the fastest known algorithm for both problems. Our result implies also faster algorithms for competitive location problems such as (1,X)-medianoid and (1, p)-centroid on trees. We complement our result by a lower bound of Ω(n log n) for single maximum coverage location and (1,X)-medianoid on a real-number RAM model showing that our algorithm is optimal in running time.	algorithm;fastest;radius;random-access memory;time complexity;tree (data structure)	Joachim Spoerhase	2010			mathematical optimization;combinatorics;mathematics;upper and lower bounds;algorithm	Theory	24.513376907415903	18.983580098270426	17204
7369c572104a33e97750ca68d6c3d77a1d34a807	on emulating interactive proofs with public coins		The known emulation of interactive proof systems by public-coins interactive proof systems proceeds by selecting, at each round, a message such that each message is selected with probability that is at most polynomially larger than its probability in the original protocol. Specifically, the possible messages are essentially clustered according to the probability that they are selected in the original protocol, and the emulation selects a message at random among those that belong to the heaviest cluster. We consider the natural alternative in which, at each round, if the parties play honestly, then each message is selected with probability that approximately equals the probability that it is selected in the original protocol. This is done by selecting a cluster with probability that is proportional to its weight, and picking a message at random in this cluster. The crux of this paper is showing that, essentially, no matter how the prover behaves, it cannot increase the probability that a message is selected by more than a constant factor (as compared to the original protocol). We also show that such a constant loss is inevitable. ∗This research was partially supported by the Minerva Foundation with funds from the Federal German Ministry for Education and Research.	approximation;computer cluster;emulator;interactive proof system	Oded Goldreich;Maya Leshkowitz	2016	Electronic Colloquium on Computational Complexity (ECCC)		mathematics;discrete mathematics;calculus;management science;mathematical proof	Crypto	7.755921999225154	25.018050568627586	17273
784a082dfde15a2d4c317f18110f6be04216a03b	improved approximation algorithms for a capacitated facility location problem	optimal solution;approximate algorithm;cost function;approximation algorithm;triangle inequality;capacitated facility location problem;worst case analysis;polynomial time algorithm;setup time;scheduling;polynomial time;approximation scheme;local search	The study of the location of facilities to serve clients at minimum cost has been one of the most studied themes in the field of Operations Research (see, e.g., the textbook edited by Mirchandani & Francis [S]). We investigate algorithms for a variant of the capacitated fucility location problem, that can be described as follows. There is a set of potential facility locations J= and a set of clients V that require service. Building a facility at location i E 3 has an associated nonnegative fixed cost fi, and each facility installed at this location can service at most u clients. Client j E D must be assigned to one of the open facilities. If a facility at location i E 3 is used to satisfy the demand of client j E D, the service cost incurred is equal to the distance from i to j, cij. The goal is to determine the (integer) number of facilities to install at each potential facility location and an assignment of each client to these facilities so as to minimize the overall total cost, that is, the cost of installing the facilities plus the total service cost. We will only consider the metric variant of the problem in which the distance function c is nonnegative, symmetric and satisfies the triangle inequality. The main result of this paper is a 3-approximation algorithm for the metric capacitated facility location problem, improving on the 5.69-approximation algorithm of [7]. Our work builds on recent results on approximation algorithms for facility location problems that rely on rounding the fractional solution to a linear programming relaxation. Shmoys, Tardos, & Aardal [7] gave the first approximation algorithms with constant performance guarantee for a number of NP-hard metric facility location problems. For the uncapacitated facility location problem (where u = +oo), they gave a	approximation algorithm;francis;facility location problem;linear programming relaxation;operations research;order of approximation;rounding;social inequality	Fabián A. Chudak;David B. Shmoys	1999			time complexity;mathematical optimization;combinatorics;discrete mathematics;polynomial-time approximation scheme;computer science;local search;facility location problem;triangle inequality;mathematics;scheduling;minimax approximation algorithm;approximation algorithm;algorithm	Theory	21.43013168412551	14.405245665410423	17306
e70e28fc8143ba5d13c6d9c7096ca54890add1da	on the parameterized complexity of colorful components and related problems		The colorful components framework is motivated by applications emerging from computational biology. A vertex-colored graph G is said to be colorful if every color appears exactly once. The general goal is to remove a collection of edges from an undirected vertex-colored graph G such that in the resulting graph H all the connected components are colorful. We want H to optimize an appropriate objective function. Two natural functions involve deleting the smallest number of edges (which we refer to as Colorful Components) and maximizing the number of edges in the transitive closure of the remaining components (which we refer to as MEC).	parameterized complexity	Neeldhara Misra	2018		10.1007/978-3-319-94667-2_20	transitive closure;discrete mathematics;mathematics;parameterized complexity;graph;connected component	Theory	24.487063524636536	22.80148582607761	17315
b4abdd3b1b3eff2c381a39b58e26b85d38292dea	graph theoretic interpretation of bangla traditional grammar		The paper is an investigation into the graph theoretic interpretation of the Bangla traditional grammar to understand the way grammatical information is structurally encoded in language. The hierarchical and the linear structural principles of grammatical compositionality is discussed in terms of certain graph theoretic concepts like tree, subtree, inverse tree etc. Translating linguistic structure into the tree structure is not new. In fact, the Transformational-Generative grammar, Tree adjoining grammar etc. have shown quite successfully how syntacto-semantic principles can be talked about in terms of tree structures. The present work differs in certain respects from the assumptions of TG grammarians, primarily because of the type of grammar and language it is dealing with.	generative grammar;theory;transformational grammar;tree (data structure);tree structure;tree-adjoining grammar	Samir Karmakar;Sayantani Banerjee;Soumya Ghosh	2016			bengali;theoretical computer science;computer science;distributed computing;graph;traditional grammar	NLP	-3.1654052847685024	14.738209886277671	17417
d0970bc59ff72a8eed76dad8bedcffcd2aab5e49	a fast and simple local search for graph coloring	algorithme rapide;random graph;coloracion grafo;algoritmo busqueda;algorithm performance;algorithm analysis;local search algorithm;algorithme recherche;search algorithm;graph coloring;optimisation combinatoire;coloration graphe;resultado algoritmo;informatique theorique;fast algorithm;performance algorithme;settore mat 09 ricerca operativa;analyse algorithme;combinatorial optimization;local search;algoritmo rapido;analisis algoritmo;graph colouring;optimizacion combinatoria;computer theory;informatica teorica	In this paper a fast and simple local search algorithm for graph coloring is presented. The algorithm is easy to implement and requires the storage of only one solution. Experimental results on benchmark instances of the DIMACS Challenge and on random graphs are given.		Massimiliano Caramia;Paolo Dell'Olmo	1999		10.1007/3-540-48318-7_25	1-planar graph;graph power;mathematical optimization;factor-critical graph;combinatorics;fractional coloring;combinatorial optimization;local search;edge coloring;comparability graph;graph coloring;mathematics;voltage graph;distance-hereditary graph;best-first search;list coloring;greedy coloring;algorithm	AI	19.413198174210553	26.909028503752864	17420
8d17bf78c7ed943a0ba5f74eb769ef186c4adf10	algorithms for compressed inputs	data compression;compression aware algorithms;web graph framework compressed inputs compression aware algorithms compressed data string algorithms numeric sequences lz77 grammar based compression repair graph interpretation;data compression compression aware algorithms graph compression;graph compression;grammar sorting data compression computer science educational institutions abstracts standards	We study compression-aware algorithms, i.e. algorithms that can exploit regularity in their input data by directly operating on compressed data. While popular with string algorithms, we consider this idea for algorithms operating on numeric sequences and graphs that have been compressed using a variety of schemes including LZ77, grammar-based compression, a graph interpretation of Re-Pair, and a method presented by Boldi and Vigna in The Web Graph Framework. In all cases, we discover algorithms outperforming a trivial approach: to decompress the input and run a standard algorithm. We aim to develop an algorithmic toolkit for basic tasks to operate on a variety of compression inputs.	algorithm;data compression;lz77 and lz78;string (computer science);webgraph;world wide web	Nathan Brunelle;Gabriel Robins;Abhi Shelat	2013	2013 Data Compression Conference	10.1109/DCC.2013.60	data compression;s3 texture compression;computer science;theoretical computer science;machine learning;data mining;mathematics;lossless compression;grammar-based code;statistics	Theory	11.889888535203417	27.642809922520968	17474
098a58725e8aff21df8f2b81d2e13b58837a9262	a hashed schema for similarity search in metric spaces (invited talk)	metric space;similarity search	A novel access structure for similarity search in metric data, called Similarity Hashing (SH), is proposed. Its multi-level hash structure of separable buckets on each level supports easy insertion and bounded search costs, because at most one bucket needs to be accessed at each level for range queries up to a pre-de ned value of search radius. At the same time, the number of distance computations is always signi cantly reduced by use of pre-computed distances obtained at insertion time. Buckets of static les can be arranged in such a way that the I/O costs never exceed the costs to scan a compressed sequential le. Experimental results demonstrate that the performance of SH is superior to the available tree-based structures. Contrary to tree organizations, the SH structure is suitable for distributed and parallel implementations.	access structure;computation;input/output;insertion sort;precomputation;range query (data structures);similarity search;spaces	Pavel Zezula	2000			discrete mathematics;combinatorics;metric space;schema (psychology);nearest neighbor search;mathematics	DB	13.68536228233067	28.747357437222302	17490
bf3eb916a71d78d55372369d8ee07a3399ac08f8	on optimal graphs embedded into path and rings, with analysis using l1-spheres	graph theory;reseau communication;teoria grafo;camino grafo;lower and upper bound;graph path;ring network;layout problem;linear arrangement;probleme agencement;lattice points;satisfiability;theorie graphe;combinatorial problem;probleme combinatoire;problema combinatorio;community networks;chemin graphe;problema disposicion;graph embedding;algoritmo optimo;algorithme optimal;optimal algorithm;red de comunicacion;communication network	Abs t r ac t . In this paper we study path layouts in communication networks. Stated in graph-theoretic terms, these layouts are translated into embeddings (or linear arral~gelnents) of the vertices of a graph with N nodes onto the points 1, 2 , . . . , N of the x-axis. We look for a graph with minimum diameter DL(N), for which such an embedding is possible, given a bound col, the cutwidth of the embedding. We develop a technique to embed the nodes of such graphs into the integral lattice points in the c-dimensional/l-sphere. Using this technique, we show that the minimum diameter DL(N) satisfies 7¢c(N) _< DL(N) _< 27g~(N), where ~ ( N ) is the minimum radius of a c-dimensional/i-sphere that conrains N points. Extensions of the results to augmented paths and ring networks are also presented. Using geometric arguments, we derive analytical bounds for ~ ( N ) , which result in substantial improvements on some known lower and upper bounds.	apache axis;embedded system;graph theory;telecommunications network	Yefim Dinitz;Marcelo Feighelstein;Shmuel Zaks	1997		10.1007/BFb0024497	ring network;combinatorics;discrete mathematics;graph embedding;graph theory;mathematics;lattice;algorithm;telecommunications network;satisfiability	Theory	23.590643158298768	29.240347573044488	17640
9889585fa74986f862295f4f653c6c4397e115eb	novel c-its support for electric buses with opportunity charging		Electric buses with opportunity (on-route) charging are one of the emerging types of “clean” buses. However, the technology brings new challenges as battery-related requirements might interfere with the revenue service — operator's primary concern. The emerging Cooperative Intelligent Transportation Systems (C-ITS) paradigm holds promise to provide an effective support to e-bus based operations and replace older ITS methods designed for buses with internal combustion engines. In this paper we demonstrate how charging operations can be supported with a novel type of Green Light Optimal Dwell Time Advisory (GLODTA) system dedicated to electric buses. It not only can support on-route battery charging so that charging operations are integrated into schedule constraints but it can also replace existing holding strategies used to regulate punctuality of bus services. A simulations-based analysis shows that system performance is positively correlated with maximum additional dwell time available to a bus and negatively correlated with cycle length of traffic signals.	battery charger;bus (computing);pro tools;programming paradigm;requirement;simulation;vehicle-to-vehicle	Marcin Seredynski;Francesco Viti	2017	2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2017.8317906	simulation;real-time computing;operator (computer programming);battery (electricity);punctuality;green-light;engineering;dwell time;intelligent transportation system;revenue	Robotics	4.632800418904589	7.252043201335851	17683
d3acad377fa364a9315167c9e1fbd06b9aae7832	an fpt algorithm for tree deletion set		We give a 5 k n O(1) time xed-parameter algorithm for determining whether a given undirected graph on n vertices has a subset of at most k vertices whose deletion results in a tree. Such a subset is a restricted form of a feedback vertex set. While parameterized complexity of feedback vertex set problem and several of its variations have been well studied, to the best of our knowledge, this is the rst xed-parameter algorithm for this version of feedback vertex set.	algorithm;parameterized complexity	Venkatesh Raman;Saket Saurabh;Ondrej Suchý	2013		10.1007/978-3-642-36065-7_27	vertex separator;mathematical optimization;combinatorics;discrete mathematics;feedback arc set;independent set;feedback vertex set;level structure;vertex cover;prim's algorithm;cycle graph;vertex;mathematics;neighbourhood	Theory	23.2217808841995	25.645888723910605	17737
dac033554aa5dc157ba661db3e81730bbaccdac3	demonstration of the universality of a new cellular automaton	game of life;rule r;nand gate.;glider gun;evolutionary algorithms;cellular automata;eater;computational universality	This paper make a contribution to the theory of cellular automata. In this theory, a central issue is classification and search of universality of cellular automata. The problem of search of universality is asked by Wolfram in Twenty Problems in the Theory of Cellular Automata by the question ”How common are computational universality and undecidability [are] in cellular automata?”. This paper describes how universal automata can be sought and found using evolutionary algorithms. A demonstration showing that a new automaton (called R) can implement the Game of Life (which is universal in the Turing sense) is described. All the elements of the evolutionary algorithms that were used to find R are provided for replicability, as well as the analytical description in R of a cell of the Game of Life.	cellular automaton;universality probability	Emmanuel Sapin;Olivier Bailleux;Jean-Jacques Chabrier;Pierre Collet	2007	IJUC		stochastic cellular automaton;mobile automaton	Crypto	1.0912166914259274	24.025862366975232	17765
882b6be0dae3ca487720c14249bd2029fe3f6371	on the solvability of the six degrees of kevin bacon game - a faster graph diameter and radius computation method		In this paper, we will propose a new algorithm that computes the radius and the diameter of a graph G = (V,E), by finding bounds through heuristics and improving them until exact values can be guaranteed. Although the worst-case running time is O(|V | · |E|), we will experimentally show that, in the case of real-world networks, it performs much better, finding the correct radius and diameter value after 10–100 BFSes instead of |V | BFSes (independent of the value of |V |), and thus having running time O(|E|). Apart from efficiency, compared to other similar methods, the one proposed in this paper has three other advantages. It is more robust (even in the worst cases, the number of BFSes performed is not very high), it is able to simultaneously compute radius and diameter (halving the total running time whenever both values are needed), and it works both on directed and undirected graphs with very few modifications. As an application example, we use our new algorithm in order to determine the solvability over time of the “six degrees of Kevin Bacon” game.	algorithm;best, worst and average case;computation;distance (graph theory);division by two;experiment;graph (discrete mathematics);heuristic (computer science);six degrees of separation;time complexity	Michele Borassi;Pierluigi Crescenzi;Michel Habib;Walter A. Kosters;Andrea Marino;Frank W. Takes	2014		10.1007/978-3-319-07890-8_5	artificial intelligence;mathematical economics	AI	22.73254239110872	20.440031193050412	17769
d11224eced9d46fd59c8e817f3049e319c681385	on truncations for a class of finite markovian queuing models		We consider a class of finite Markovian queueing models and obtain uniform approximation bounds of truncations. INTRODUCTION It is well known that explicit expressions for the probability characteristics of stochastic models can be found only in a few special cases, moreover, if we deal with an inhomogeneous Markovian model, then we must approximately calculate the limiting probability characteristics of the process. The problem of calculation of the limiting characteristics for inhomogeneous birth-death process via truncations was firstly mentioned in (Zeifman 1991) and was considered in details in (Zeifman et al. 2006). In (Zeifman et al. 2014b) we have proved uniform (in time) error bounds of truncation this class of Markov chains. First uniform bounds of truncations for the class of Markovian time-inhomogeneous queueing models with batch arrivals and group services (SZK models) introduced and studied in our recent papers (Satin et al. 2013, Zeifman et al. 2014a), were obtained in (Zeifman et al. 2014c). In this note we deal with approximations of finite SZK model via the same models with smaller state space and obtain the correspondent bounds of error of truncation bounds. Consider a time-inhomogeneous continuous-time Markovian queueing model on the state space E = {0, 1, . . . , r} with possible batch arrivals and group services. Let X(t), t ≥ 0 be the queue-length process for the queue, pij(s, t) = P {X(t) = j |X(s) = i}, i, j ≥ 0, 0 ≤ s ≤ t, be transition probabilities for X = X(t), and pi(t) = P {X(t) = i} be its state probabilities. Throughout the paper we assume that P (X (t+ h) = j|X (t) = i) = = { qij (t)h+ αij (t, h) , if j 6= i, 1− ∑ k 6=i qik (t)h+ αi (t, h) , if j = i, (1) where all αi(t, h) are o(h) uniformly in i, i. e., supi |αi(t, h)| = o(h). We also assume qi,i+k (t) = λk(t), qi,i−k (t) = μk(t) for any k > 0. In other words, we suppose that the arrival rates λk(t) and the service rates μk(t) do not depend on the queue length. In addition, we assume that λk+1(t) ≤ λk(t) and μk+1(t) ≤ μk(t) for any k and almost all t ≥ 0. Hence, X(t) is a so-called SZK model, which was studied in (Satin et al. 2013, Zeifman et al. 2014a, 2014c). We suppose that all intensity functions are locally integrable on [0,∞), and λk(t) ≤ λk, μk(t) ≤ μk, (2) for any k and almost all t ≥ 0, and put	approximation;markov chain;queueing theory;state space;stochastic process;truncation	Yacov Satin;Alexander I. Zeifman;Anna Korotysheva;Ksenia Kiseleva;Victor Korolev	2015		10.7148/2015-0626	mathematical analysis;pi;queueing theory;minimax approximation algorithm;state space;markov process;integrable system;markov chain;expression (mathematics);mathematics	ML	9.0010801268313	11.309098844862202	17809
472ca43d38e3cf1db0753baff702ef8d1bb7a5ac	discounted reward tsp	approximation algorithm;routing problems	Consider a rescue plan after a major disaster such as an earthquake, where the objective is to find and rescue as many survivors as possible. The rescue team has to decide where to search for survivors, and as time progress the number of survivors in each location decreases. This problem can be modeled as Discounted Reward TSP on a graph $$G=(V,E)$$ G=(V,E) where each node $$v\in V$$ v∈V represents a potential place for searching survivors, and the length of an edge represents the time it takes to travel from one place to another. Each node has an initial prize $$\pi (v)$$ π(v) (that represents the number of survivors in it) and this prize deteriorates exponentially. Therefore, the prize collected from node $$v\in V$$ v∈V is $$\pi (v) \lambda ^t$$ π(v)λt , where $$\lambda $$ λ is the deterioration rate and t is the first time v was visited. The objective is to find a path that maximizes the total prize collected from the nodes of G. We present two different algorithms for Discounted Reward TSP, each improves the previously best known approximation ratio of $$0.1481-\delta $$ 0.1481-δ shown by Blum et al. (SIAM J Comput 37(2):653–670, 2007). Our better algorithm is a $$(0.1929-\delta )$$ (0.1929-δ) -approximation algorithm.	approximation algorithm;blum axioms;emoticon	Boaz Farbstein;Asaf Levin	2016	Algorithmica	10.1007/s00453-016-0264-2	artificial intelligence;operations research	Theory	19.894798694354126	17.20201471891197	17824
095e187592c58f2f1a1a9fa91309327b641706ae	an algorithm to enumerate all cutsets of a graph in linear time per cutset	time complexity;linear time;space complexity	"""Thts paper deals wRh the problem of enumerating all the cutsets or all the s-t cutsets separatmg two spectfied verttces s and t m an undirected graph A vanety of approaches have been proposed for this problem, among which one based on the partmon e ra set of veruces rote two sets is the most effi¢ienL It is first shown that an algorithm of this type has time complexity O((n + m)(n log2#)#), and two new algorithms with ume complexity O((n + m)O + I)) are then proposed One of these new algorithms has space complexity O(nZ), and the other has space complexity O(n + m), where n and m are the numbers of veraces and edges, respectively, and ta ts the number ofs-t cutsets m a given graph The results of some computatmnal experiments are also described. An mvest~gaUon ~s made of the extent to whtch the new algorithms are better, and how good the performance of the old algorithm is, especmlly when a given graph is """"dense,"""" t e , 2m/(n(n 1)) _> 0.4."""	algorithm;analysis of algorithms;binary logarithm;computation;computational complexity theory;cut (graph theory);dspace;enumerated type;experiment;graph (discrete mathematics);sparse matrix;time complexity	Shuji Tsukiyama;Isao Shirakawa;Hiroshi Ozaki;Hiromu Ariyoshi	1980	J. ACM	10.1145/322217.322220	time complexity;combinatorics;discrete mathematics;computer science;mathematics;algorithm	Theory	21.729230024435186	24.527402903753547	17857
9290ce9d48f7c9fe775afe42388964606b965561	on sequential and 1-deterministic p systems	modelizacion;sistema operativo;reachability;systeme cooperatif;calcul membrane;blind;membrane system;systeme deterministe;modelisation;combinatorial problem;probleme combinatoire;problema combinatorio;cooperative systems;operating system;sistema determinista;calculo membrana;p system;asequibilidad;atteignabilite;systeme exploitation;modeling;ciego;deterministic system;aveugle	The original definition of P-systems calls for rules to be applied in a maximally parallel fashion. However, in some cases a sequential model may be a more reasonable assumption. Here we study the computational power of different variants of sequential P-systems. Initially we look at cooperative systems operating on symbol objects and without prioritized rules, but which allow membrane dissolution and bounded creation rules. We show that they are equivalent to vector addition systems and, hence, nonuniversal. When these systems are used as language acceptors, they are equivalent to communicating P systems which, in turn, are equivalent to partially blind multicounter machines. In contrast, if such cooperative systems are allowed to create an unbounded number of new membranes (i.e., with unbounded membrane creation rules) during the course of the computation, then they become universal. We then consider systems with prioritized rules operating on symbol objects. We show two types of results: there are sequential P systems that are universal and sequential P systems that are nonuniversal. In particular, both communicating and cooperative P systems are universal, even if restricted to 1-deterministic systems with one membrane. However, multi-membrane catalytic P systems with prioritized rules have NP-complete reachability problem and, hence, nonuniversal.	computation;consensus dynamics;np-completeness;p system;reachability problem;vector addition system	Oscar H. Ibarra;Sara Woodworth;Hsu-Chun Yen;Zhe Dang	2005		10.1007/11533719_91	combinatorics;discrete mathematics;systems modeling;computer science;artificial intelligence;operating system;deterministic system;mathematics;reachability;algorithm;p system	Logic	-0.5932642743721764	24.852924789076877	17914
0e3369b72b79670aa125ebfe764aebf1f1a3e409	génération aléatoire et uniforme de mots	lower and upper bound;general methods;coding theory;linear space	Resume   Le but de cet article est d'etudier une generalisation de la methode employee par Barcucci, Pinzani et Sprugnoli pour tirer aleatoirement des mots facteurs gauches de Motzkin en temps et espace lineaires en moyenne. Nous donnons un encadrement de sa complexite moyenne lorsqu'elle est appliquee a un langage quelconque, puis definissons la classe des  fg-langages , langages pour lesquels elle peut etre calculee exactement. Il apparait un lien entre les proprietes des fg-langages et des notions issues de la Theorie des Codes. Nous terminons par l'etude de la methode appliquee a quelques fg-langages particuliers.		A. Denise	1996	Discrete Mathematics	10.1016/0012-365X(95)00129-K	mathematics;linear space;coding theory	Logic	0.8295763994280547	17.236870816165336	17954
c9d0318c2fb451b135418ca61fd3cc58b1cd5754	dynamic rank/select structures with applications to run-length encoded texts	pire cas;comptage;succinct data structures;succinct data structure;full text index;rango;alfabeto;index;contaje;dynamic rank select structures;indice;informatique theorique;indexation;estructura datos;rang;run length encoding;counting;68p05;structure donnee;data structure;text indexing;alphabet;rank;computer theory;informatica teorica	Given an n-length text over a σ-size alphabet, we propose a dynamic rank-select structure that supports O((1 + log σ log log n ) log n) time operations in n log σ + o(n log σ) bits space. If σ < log n, then the operation time is O(log n). In addition, we consider both static and dynamic rank-select structures on the run-length encoding (RLE) of a text. For an n′-length RLE of an n-length text, we present a static structure that gives O(1) time select and O(log log σ) time rank using n′ log σ + O(n) bits and a dynamic structure that provides O((1 + log σ log log n ) log n) time operations in n′ log σ + o(n′ log σ) + O(n) bits.		Sunho Lee;Kunsoo Park	2009	Theor. Comput. Sci.	10.1016/j.tcs.2009.07.021	succinct data structure;combinatorics;data structure;computer science;theoretical computer science;mathematics;programming language;algorithm	Theory	12.625358294401883	27.26136966751951	17964
f8015c94ec837d6723bc019c418c6a46803f9345	city-friendly smart network technologies and infrastructures: the spanish experience		Efficient, resilient, and sustainable electricity delivery is a key cornerstone in increasingly large and complex urban environments, where citizens expect to keep or rise their living standards. In this context, cost-effective and ubiquitous digital technologies are driving the transformation of existing electrical infrastructures into truly smart systems capable of better providing the services a low-carbon society is demanding. The goal of this paper is twofold: 1) to review the dramatically evolving landscape of power systems, from the old framework based on centralized generation and control, aimed at serving inelastic customers through alternating current (ac) transmission networks and one-way distribution feeders, to a new paradigm centered mainly around two main axes: renewable generation, both centralized and distributed, and active customers (prosumers), interacting with each other through hybrid ac/dc smart grids; 2) to illustrate, through featured success stories, how several smart grid concepts and technologies have been put into practice in Spain over the last few years to optimize the performance of urban electrical assets.	centralized computing;ibm power systems;interaction;one-way function;programming paradigm;smart system	Antonio G&#x00F3;mez-Exp&#x00F3;sito;Angel Arcos-Vargas;Jos&#x00E9; Mar&#x00ED;a Maza-Ortega;Jos&#x00E9;. A. Rosendo-Mac&#x00ED;as;Gabriel Alvarez-Cordero;Susana Carillo-Aparicio;Juan Gonz&#x00E1;lez-Lara;Daniel Morales-Wagner;Tom&#x00E1;s Gonz&#x00E1;lez-Garc&#x00ED;a	2018	Proceedings of the IEEE	10.1109/JPROC.2018.2793461	electric power system;renewable energy;smart grid;transport engineering;sustainable development;energy management;asset management;electricity delivery;smart system;business	Visualization	1.4397295570926243	7.285745217592961	17984
5ee2895e6653f9cffa4630b26d72e3fe86b345c7	learning locally testable even linear languages from positive data	learning process;inference grammaticale;language class;learning algorithm;data locality;testabilite;regular language;algorithme apprentissage;grammaire lineaire;linear grammar;testability;lenguaje racional;inferencia gramatical;local testability;even linear languages;gramatica lineal;classe langage;langage lineaire;langage rationnel;testabilidad;grammatical inference;learning from positive data;learning artificial intelligence;algoritmo aprendizaje;clase lenguaje;apprentissage intelligence artificielle	Learning from positive data is a center goal in grammatical inference. Some language classes have been characterized in order to allow its learning from text. There are two different approaches to this topic: (i) reducing the new classes to well known ones, and (ii) designing new learning algorithms for the new classes. In this work we will use reduction techniques to define new classes of even linear languages which can be inferred from positive data only. We will center our attention to inferable classes based on local testability features. So, the learning processes for such classes of even linear languages can be performed by using algorithms for locally testable regular languages.		José M. Sempere;Pedro García	2002		10.1007/3-540-45790-9_18	testability;regular language;computer science;artificial intelligence;machine learning;mathematics;programming language;algorithm	Theory	3.5229316466112635	17.56429146709801	18005
ba39cd1c128328aa623ccb34c071ef996ca8fece	random access machines with multi-dimensional memories	multi dimensional;random access machine	The purpose is to describe a method of implementing two-dimensional arrays without multiplications which does have the property that the total time taken by an execution of a program exceeds by only a linear factor the time which would be obtained if the cost of access to a two-dimensional array element was simply constant or the sum of the logarithms of the subscripts and of the element value.	random access	John Michael Robson	1990	Inf. Process. Lett.	10.1016/0020-0190(90)90133-I	real-time computing;computer science;theoretical computer science;distributed computing;algorithm	DB	12.765668591764737	30.738209687367362	18046
8f9ed4e41f20355d644f4e752ea0f2dd023746d7	tight bounds for testing bipartiteness in general graphs	densite;algorithm complexity;image processing;grado grafo;complejidad algoritmo;speech processing;tratamiento palabra;procesamiento imagen;traitement parole;densidad;traitement image;complexite algorithme;edge graph;borne inferieure;pattern recognition;arete graphe;number;degre graphe;reconnaissance forme;density;reconocimiento patron;nombre;lower bound;numero;arista grafico;graph degree;cota inferior	In this paper we consider the problem of testing bipartiteness of general graphs. The problem has previously been studied in two models, one most suitable for dense graphs and one most suitable for bounded-degree graphs. Roughly speaking, dense graphs can be tested for bipartiteness with constant complexity, while the complexity of testing bounded-degree graphs is $\tilde{\Theta}(\sqrt{n})$, where $n$ is the number of vertices in the graph (and $\tilde{\Theta}(f(n))$ means $\Theta(f(n)\cdot{\rm polylog}(f(n)))$). Thus there is a large gap between the complexity of testing in the two cases.#R##N#In this work we bridge the gap described above. In particular, we study the problem of testing bipartiteness in a model that is suitable for all densities. We present an algorithm whose complexity is $\tilde{O}(\min(\sqrt{n},n^2/m))$, where $m$ is the number of edges in the graph, and we match it with an almost tight lower bound.		Tali Kaufman;Michael Krivelevich;Dana Ron	2004	SIAM J. Comput.	10.1137/S0097539703436424	pathwidth;combinatorics;numero sign;dense graph;image processing;density;computer science;speech processing;mathematics;upper and lower bounds;grammatical number;chordal graph;indifference graph;algorithm	Theory	21.928235232619333	27.907098472888343	18085
4dd38e8fc5c4fd662ab0fdaba156770854124f7a	a note on asynchronous pc systems of pushdown automata (preliminary report)			deterministic pushdown automaton;stack (abstract data type)	Holger Petersen	2013	CoRR		deterministic pushdown automaton;pushdown automaton	Theory	-3.0597502659199733	22.215672727532265	18086
e8bab3759e86fafa62edcc80a1ec1fe4ed3d5677	the linear arrangement problem parameterized above guaranteed value	complexite calcul;probleme np complet;temps lineaire;linear arrangement;tiempo lineal;algorithme;connected graph;upper bound;algorithm;complejidad computacion;computational complexity;linear time;edge graph;arete graphe;problema np completo;borne superieure;graphe connexe;arista grafico;np complete problem;cota superior;algoritmo;grafo conexo	A linear arrangement (LA) is an assignment of distinct integers to the vertices of a graph. The cost of an LA is the sum of lengths of the edges of the graph, where the length of an edge is defined as the absolute value of the difference of the integers assigned to its ends. For many application one hopes to find an LA with small cost. However, it is a classical NP-complete problem to decide whether a given graph G admits an LA of cost bounded by a given integer. Since every edge of G contributes at least one to the cost of any LA, the problem becomes trivially fixed-parameter tractable (FPT) if parameterized by the upper bound of the cost. Fernau asked whether the problem remains FPT if parameterized by the upper bound of the cost minus the number of edges of the given graph; thus whether the problem is FPT “parameterized above guaranteed value.” We answer this question positively by deriving an algorithm which decides in time O(m + n + 5.88k) whether a given graph with m edges and n vertices admits an LA of cost at most m + k (the algorithm computes such an LA if it exists). Our algorithm is based on a procedure which generates a problem kernel of linear size in linear time for a connected graph G. We also prove that more general parameterized LA problems stated by Serna and Thilikos are not FPT, unless P = NP.		Gregory Gutin;Arash Rafiey;Stefan Szeider;Anders Yeo	2006		10.1007/11758471_34	time complexity;combinatorics;discrete mathematics;topological graph;np-complete;graph bandwidth;graph labeling;computer science;connectivity;cycle graph;path graph;mathematics;path;upper and lower bounds;computational complexity theory;bound graph;complement graph;algorithm;strength of a graph	Theory	22.107726198821883	25.891026687175387	18112
4aa3f427a7f64e476478bd8cab5f2e36a9b19b32	transition and halting modes in (tissue) p systems	generic model;articulo;transition and halting modes in tissue p systems;p system;transition and halting modes for tissue p systems;membrane computing	A variety of different transition modes for tissue P systems as well as several halting modes currently are used in the area of membrane computing. In this paper, the definitions of the most important transition modes and halting modes are explained based on networks of cells, a general model for tissue P systems. Moreover, some results for specific variants of tissue P systems working on multisets of objects are recalled.	clara oswald;gheorghe păun;halting problem;membrane computing;p system	Rudolf Freund	2009		10.1007/978-3-642-11467-0_3	real-time computing;computer science;distributed computing;algorithm	AI	1.2936194920341475	24.70245023422774	18141
8ecd64e6fa2d9610354d552fd070f4b3e1ca5b83	mapreduce parallel cuckoo hashing and oblivious ram simulations	cs ds;asymptotic optimality;efficient algorithm;parallel models;cs cr;cs dc;external memory;sorting algorithm	We present an efficient algorithm for performing cuckoo hashing in the MapReduce parallel model of computation and we show how this result in turn leads to improved methods for performing data-oblivious RAM simulations. Our contributions involve a number of seemingly unrelated new results, including: a parallel MapReduce cuckoo hashing algorithm that runs in O(log n) time and uses O(n) total work, with very high probability a reduction of data-oblivious simulation of sparse-streaming MapReduce algorithms to oblivious sorting an external-memory data-oblivious sorting algorithm using O((N/B) log^2_(M/B) (N/B)) I/Os constant-memory data-oblivious RAM simulation with O(log^2 n) amortized time overhead, with very high probability, or with expected O(log2 n) amortized time overhead and better constant factors sublinear-memory data-oblivious RAM simulation with O(n^nu) private memory and O(log n) amortized time overhead, with very high probability, for constant nu > 0.   This last result is, in fact, the main result of this paper, since it is asymptotically optimal and is for the more realistic setting with respect to private memory size.		Michael T. Goodrich;Michael Mitzenmacher	2010	CoRR		parallel computing;computer science;theoretical computer science;distributed computing	Crypto	11.05122936657817	31.0972925994309	18142
cfc2064fe34e395973bc60db0da7b33100203c74	solving variants of the job shop scheduling problem through conflict-directed search	adaptive search heuristics;scheduling;disjunctive unary resource;constraint programming;combinatorial optimization	Authors are encouraged to submit new papers to INFORMS journals by means of a style file template, which includes the journal title. However, use of a template does not certify that the paper has been accepted for publication in the named journal. INFORMS journal templates are for the exclusive purpose of submitting to an INFORMS journal and should not be used to distribute the papers in print or online or to submit the papers to another publication.	algorithm;constraint programming;disjunctive normal form;emoticon;functional dependency;heuristic (computer science);institute for operations research and the management sciences;job shop scheduling;metaheuristic;netware;schedule (project management);scheduling (computing);tandy 1000;transform, clipping, and lighting;unary operation	Diarmuid Grimes;Emmanuel Hebrard	2015	INFORMS Journal on Computing	10.1287/ijoc.2014.0625	job shop scheduling;mathematical optimization;constraint programming;flow shop scheduling;combinatorial optimization;computer science;theoretical computer science;mathematics;scheduling;algorithm	HPC	22.02201980465909	9.008510324016509	18146
d65a0402bbf0d11ebea46e264a8bc89ed4a9912a	size and variable ordering of obdds representing treshold functions	grafo aciclico;fonction booleenne;total order;logic design;boolean function;graphe acyclique;fonction seuil;acyclic graph;ordered binary decision diagram;funcion umbral;funcion booliana;estructura datos;branching program;graph representation;structure donnee;threshold function;data structure;lower bound	An ordered binary decision diagram (OBDD) is a graph representation of a Boolean function, and it is considered as a restricted branching program. According to its good properties, an OBDD is widely used in computer aided logic design. In this paper, the size of ordered binary decision diagrams representing threshold functions is discussed. First, we prove an Ω(n2 Cn1-c ) lower bound on the OBDD size necessary to represent any threshold function when the variable ordering can be chosen adaptively to minimize the OBDD size. Next, we show that it is not possible to find a good variable ordering only from the total order of weights, that is, for any variable ordering of this kind, there exists a threshold function that requires an exponential size OBDD, but is represented in polynomial size by the optimal variable ordering.		Yasuhiko Takenaga;Mitsushi Nouzoe;Shuzo Yajima	1997		10.1007/BFb0045076	combinatorics;discrete mathematics;logic synthesis;data structure;computer science;mathematics;graph;boolean function;upper and lower bounds;directed acyclic graph;total order;algorithm	EDA	17.204311015077685	26.517145731375038	18173
8c49713e08bcb0e28d96247d2ba140e39600f546	semi-commutations and partial commutations	switching;rairo ita;maquina estado finito;language theory;regular language;informatique theorique et applications;teoria lenguaje;journal;rairo;lenguaje racional;theoretical informatics and applications;fonction commutation;necessary and sufficient condition;conmutacion;langage rationnel;semi commutation;edp sciences;machine etat fini;commutation function;commutation;finite state machine;theorie langage;ita	The aim of this paper is to show that a semi-commutation function can be expressed as the compound of a sequential transformation, a partial commutation function, and the reverse transformation. Moreover, we give a necessary and sufncient condition for the image of a regular language to be computed by the compound of two sequential functions and a partial commutation function. AMS Subject Classification. 68Q45, 68Q85.	regular language;semiconductor industry;vhdl-ams	Mireille Clerbout;Yves Roos;Isabelle Simplot-Ryl	2000	ITA	10.1051/ita:2000119	regular language;computer science;philosophy of language;calculus;mathematics;finite-state machine;algorithm	ML	-2.825510998807157	20.407555907838308	18182
32025cbc182d3e4bc9f679619f6b9006a19f03f3	derivation of near-optimal pump schedules for water distribution by simulated annealing	forecasting;optimisation;reliability;bomba;distribucion agua;project management;information systems;optimizacion;maintenance;water pumps;soft or;information technology;packing;eau;pompe;hydraulique;operations research;location;simulated annealing;hydraulics;investment;journal;simulator;journal of the operational research society;inventory;purchasing;pump;linearisation reseau hydraulique;history of or;research paper;recuit simule;distribution eau;programacion lineal;simulador;logistics;marketing;scheduling;pompe eau;linear programming;simulateur;programmation lineaire;production;linear program;communications technology;recocido simulado;optimization;water distribution;agua;water networks;computer science;operational research;hidraulica;water;ordonnancement;applications of operational research;or society;reglamento;jors;management science;infrastructure	The scheduling of pumps for clean water distribution is a partially discrete non-linear problem with many variables. The scheduling method described in this paper typically produces costs within 1% of a linear program-based solution, and can incorporate realistic non-linear costs that may be hard to incorporate in linear programming formulations. These costs include pump switching and maximum demand charges. A simplified model is derived from a standard hydraulic simulator. An initial schedule is produced by a descent method. Two-stage simulated annealing then produces solutions in a few minutes. Iterative recalibration ensures that the solution agrees closely with the results from a full hydraulic simulation. Journal of the Operational Research Society (2004) 55, 728–736. doi:10.1057/palgrave.jors.2601718	iterative method;linear programming;nonlinear system;scheduling (computing);simulated annealing;simulation	G. McCormick;R. S. Powell	2004	JORS	10.1057/palgrave.jors.2601718	logistics;water;simulation;hydraulics;inventory;simulated annealing;economics;forecasting;investment;computer science;linear programming;marketing;operations management;reliability;mathematics;location;management;operations research;scheduling	Robotics	17.645394735205375	5.7805670105582125	18206
12e604406aa56dc2fc2c6e641873036adf75859e	relaxations of the satisfiability problem using semidefinite programming	semidefinite programming;automated reasoning;satisfiability;objective function;propositional logic;polynomial algorithm;polynomial time;relaxation;semidenite programming;pigeon;eigenvalue optimization;satisfiability problem;semidefinite relaxation;semidefinite program	"""We derive a semidefinite relaxation of the satisfiability (SAT) problem and discuss its strength. We give both the primal and dual formulation of the relaxation. The primal formulation is an eigenvalue optimization problem, while the dual formulation is a semidefinite feasibility problem. We show that using the relaxation, a proof of the unsatisfiability of the notorious pigeonhole and mutilated chessboard problems can be computed in polynomial time. As a byproduct we find a new `sandwich"""" theorem that is similar to the sandwich theorem for Lovász' ϑ-function. Furthermore, the semidefinite relaxation gives a certificate of (un)satisfiability for 2SAT problems in polynomial time. By adding an objective function to the dual formulation, a specific class of polynomially solvable 3SAT instances can be identified. We conclude with discussing how the relaxation can be used to solve more general SAT problems and with some empirical observations."""	2-satisfiability;boolean satisfiability problem;decision problem;lagrangian relaxation;linear programming relaxation;mathematical optimization;optimization problem;pigeonhole sort;polynomial;semidefinite programming;time complexity	Etienne de Klerk;Hans van Maaren;Joost P. Warners	2000	Journal of Automated Reasoning	10.1023/A:1006362203438	time complexity;mathematical optimization;combinatorics;discrete mathematics;computer science;relaxation;quadratically constrained quadratic program;mathematics;semidefinite embedding;propositional calculus;automated reasoning;boolean satisfiability problem;semidefinite programming;satisfiability	ML	23.611543682731458	14.902683295873402	18261
fadbfa9eaf3f92892098be887180de5d6cef0d25	symmetric and economical solutions to the mutual exclusion problem in a distributed system (extended abstract)	distributed system;systeme reparti;symetrie;symmetry;mutual exclusion;economic aspect;aspect economique;exclusion mutuelle;aspecto economico;problem solving;resolution probleme	iire mutual exclusii?n problem in a distributed system, in which each process has a memory of i!s own, into whtch it has exclusive write privileges but from which others may read, is reconsidered. Symmt iric solutions are looked for. It is shown that, though no such solution may be deterministic, there are Probabilistic solutions. DiIferent solutions are provided for two processes. and then a solution is proposed for any number of processes. The solutions offered are amenable to a formal proof of their correctness with a small effort. The solutions are correct zven against a verv well infarmed scheduler, unlike Rabin's probabilistic solution to the mutual e~lusion p ;3blern ir, a centralized system. Some of the solutions are correct even against an evil scheduler th rr' knows in advance the results of the future random draws, in sharp contrast with the algorithms of Lehmann and Rabin ( 1951). T :AC solutions are economical: mutual exclusion bctn,een tL4.o processes may be achieved with variables capable of holding four different values (tt, be compared with Peterson and Fischer's three), mutua! exclusion between n processes may bc achieved with variables capable oi' holding ten different values (to be compared with Peterson and Fischer's fourteen !. .A& solutions have been attained by careful reasoning and not by an exhaustive computer search: they exhibit general principles of design that may be usefu1 in solving other similar prcMzrr.s. 1. The mutual exchsian problem in a distributed environment	distributed computing;mutual exclusion	Shimon Cohen;Daniel J. Lehmann;Amir Pnueli	1983		10.1007/BFb0036903	mathematical optimization;combinatorics;mutual exclusion;computer science;artificial intelligence;calculus;mathematics;symmetry;programming language;algorithm;statistics	Theory	6.166038553830926	25.387702627621614	18263
78d64b61c643e728e13ad46e2854d4c593b13225	efficient algorithm for scalable event-based demand response management in microgrids	integer variables demand response management microgrids approximation algorithms;power demand load management microgrids approximation algorithms linear programming heuristic algorithms	Demand response (DR) management has become one of the key enabling technologies for smart grids. Motivated by the increasing DR incentives offered by service operators, more customers are subscribing to various DR programs. However, with growing customer participation, the problem of determining the optimal loads to be curtailed in a microgrid (MG) during contingencies within a feasible time frame becomes computationally hard. This paper proposes an efficient approximation algorithm for event-based DR management in MGs. In event-based management, it is important to curtail loads as fast as possible to maintain the stability of an MG during the islanded mode in a scalable manner. A simple greedy approach is presented that can rapidly determine a close-to-optimal load curtailment scheme to maximize the aggregate customer utility in milliseconds for a large number of customers. This paper further derives a novel theoretical guarantee of the gap between the proposed efficient algorithm and the optimal solution (that may be computationally hard to obtain). The performance of algorithm is corroborated extensively by simulations with up to thousands of customers. For the sake of practicality, the proposed event-based DR management algorithm is applied to a feeder from the Canadian benchmark distribution system. The simulation results demonstrate that the proposed approach efficiently optimizes MG operation during islanded mode while maintaining appropriate voltage levels and network constrains.	aggregate data;approximation algorithm;benchmark (computing);greedy algorithm;mg (editor);microgrid;scalability;simulation	Areg Karapetyan;Majid Khonji;Chi-Kin Chau;Khaled M. Elbassioni;Hatem H. Zeineldin	2018	IEEE Transactions on Smart Grid	10.1109/TSG.2016.2616945	mathematical optimization;simulation;computer science;engineering;operations management	Metrics	2.9741720345880207	4.1934111575011475	18277
d49804f55199956673229eb8c6bd4b6650234998	design, proof and analysis of new efficient algorithms for incremental attribute evaluation	efficient algorithm	Without Abstract	algorithm	Qi Lu;Jiahua Qian	1988		10.1007/BFb0017171	mathematical optimization;computer science;theoretical computer science;data mining;mathematics	PL	16.143664225313707	20.43085710769286	18283
c03567c43db9712cfa2346da854d1fdc4e7ce04f	real-time modeling and control of electric vehicles charging processes	scheduling centralized control load flow analysis power distribution road vehicles;scheduling distribution networks electric vehicles load flow control;cascading style sheets batteries system on chip schedules optimization power systems load modeling;rechargeable ev real time modeling electric vehicle charging processes control ev charging process real time management power distribution system power flow evaluation procedure scheduling algorithm electricity distribution system medium sized italian city	This paper presents a method for the real-time management of electric vehicles (EVs) charging processes. The proposed method aims to limit the peak load and to increase the number of rechargeable EVs with respect to the scenario in which no coordination action is performed, while achieving given constraints on the power distribution system. The approach is based on a tight interaction between a scheduling algorithm and a power-flow evaluation procedure. The scheduling algorithm finds the best charging periods for each EV. The power flow procedure checks the achievement of electrical constraints and evaluates the operational parameters of the grid. Simulations are carried out on a real electricity distribution system of a medium-sized Italian city. The results show that the proposed approach increases the number of rechargeable EVs up to 33%. At the same time, the peak load is reduced by 25%. The scheduling algorithm requires an average of 50 ms to evaluate each charge request on an ordinary computer, therefore allowing its use in real-time conditions.	algorithm;computation;computer simulation;data-flow analysis;extended validation certificate;library (computing);load management;load profile;mathematical model;quality of service;real life;real-time clock;real-time computing;real-time transcription;rechargeable battery;scheduling (computing);time complexity	Guido Benetti;Maurizio Delfanti;Tullio Facchinetti;Davide Falabretti;Marco Merlo	2015	IEEE Transactions on Smart Grid	10.1109/TSG.2014.2376573	control engineering;embedded system;engineering;operations management	Embedded	5.042406031242952	5.54165962480102	18319
137fab748eefb2cdaf64554fdb2f369fc67bf7e6	towards optimally solving the longest common subsequence problem for sequences with nested arc annotations in linear time	sous sequence commune la plus longue;probleme np complet;fixed parameter tractable;chaine caractere;longest common subsquence;algorithme;algorithm;longest common subsequence;structure comparison;exact algorithm;linear time;cadena caracter;distancia;time factor;problema np completo;polynomial time approximation scheme;distance;np complete problem;character string;algoritmo	We present exact algorithms for the NP-complete Longest Common Subsequence problem for sequences with nested arc annotations, a problem occurring in structure comparison of RNA. Given two sequences of length at most n and nested arc structure, our algorithm determines (if existent) in time O(3.3112 ·n) an arc-preserving subsequence of both sequences, which can be obtained by deleting (together with corresponding arcs) k1 letters from the first and k2 letters from the second sequence. Thus, the problem is fixed-parameter tractable when parameterized by the number of deletions. This complements known approximation results which give a quadratic time factor-2-approximation for the general and polynomial time approximation schemes for restricted versions of the problem. In addition, we obtain further fixed-parameter tractability results for these restricted versions.	algorithm;approximation;best, worst and average case;cobham's thesis;experiment;longest common subsequence problem;np-completeness;parameterized complexity;polynomial;time complexity	Jochen Alber;Jens Gramm;Jiong Guo;Rolf Niedermeier	2002		10.1007/3-540-45452-7_10	time complexity;subsequence;combinatorics;discrete mathematics;polynomial-time approximation scheme;np-complete;longest increasing subsequence;string;computer science;longest common subsequence problem;mathematics;distance;longest alternating subsequence;algorithm	Theory	16.20738441630446	24.044214148589457	18331
196ac95a45a982cd17d086675a7af17db81edfe1	a sat approach to branchwidth		Branch decomposition is a prominent method for structurally decomposing a graph, hypergraph or CNF formula. The width of a branch decomposition provides a measure of how well the object is decomposed. For many applications it is crucial to compute a branch decomposition whose width is as small as possible. We propose a SAT approach to finding branch decompositions of small width. The core of our approach is an efficient SAT encoding which determines with a single SAT-call whether a given hypergraph admits a branch decomposition of certain width. For our encoding we developed a novel partition-based characterization of branch decomposition. The encoding size imposes a limit on the size of the given hypergraph. In order to break through this barrier and to scale the SAT approach to larger instances, we developed a new heuristic approach where the SAT encoding is used to locally improve a given candidate decomposition until a fixed-point is reached. This new method scales now to instances with several thousands of vertices and edges.	boolean satisfiability problem;branch-decomposition;conjunctive normal form;heuristic;vertex (graph theory)	Neha Lodha;Sebastian Ordyniak;Stefan Szeider	2017		10.24963/ijcai.2017/689	machine learning;artificial intelligence;computer science	AI	22.312690558971163	23.083955343089066	18444
29a72e5c0cee52c377900b0af431976b91f6c8d4	the identification of a set by successive intersections		This paper is concerned with the identification of an unknown subset  S  of a known set  A  by selecting a sequence  A  1 ,  A  2 ,  A  3 ,…, of subsets of  A  and establishing, after each selection, whether or not  S  ∩  A k   is empty. The central problem is to devise a selection algorithm which would result in correct identification of  S  with the least expected number of  A k  's. The main result of this paper is a selection algorithm which, under certain conditions, is considerably superior to the “naive selection algorithm” (where each  A k   consists of a different element of  A ), and whose performance is quite close to an upper bound arrived at via information-theoretic consideration. The conditions for this high performance are: Small value of  p  (the probability of any element of  A  being in  S ), say  p  ⩽ 0.1, and a large cardinality  n  of  A , say  n  ⩾ 10/ p .		Arthur Gill;Doron Gottlieb	1974	Information and Control	10.1016/S0019-9958(74)80020-3	mathematical optimization;combinatorics;mathematics;algorithm	Robotics	16.271146526964596	20.869384927149806	18491
6a274dc2870010a099e545a2846d162d40be19ef	non-commutative formulas and frege lower bounds: a new characterization of propositional proofs	non commutative formulas;004;proof complexity;ideal proof system;frege proofs;proof complexity algebraic complexity arithmetic circuits frege non commutative formulas;algebraic complexity	Does every Boolean tautology have a short propositional-calculus proof? Here, a propositionalcalculus (i.e. Frege) proof is any proof starting from a set of axioms and deriving new Boolean formulas using a fixed set of sound derivation rules. Establishing any super-polynomial size lower bound on Frege proofs (in terms of the size of the formula proved) is a major open problem in proof complexity, and among a handful of fundamental hardness questions in complexity theory by and large. Non-commutative arithmetic formulas, on the other hand, constitute a quite weak computational model, for which exponential-size lower bounds were shown already back in 1991 by Nisan [20], using a particularly transparent argument. In this work we show that Frege lower bounds in fact follow from corresponding size lower bounds on non-commutative formulas computing certain polynomials (and that such lower bounds on non-commutative formulas must exist, unless NP=coNP). More precisely, we demonstrate a natural association between tautologies T to non-commutative polynomials p, such that: if T has a polynomial-size Frege proof then p has a polynomial-size non-commutative arithmetic formula; and conversely, when T is a DNF, if p has a polynomial-size non-commutative arithmetic formula over GF (2) then T has a Frege proof of quasi-polynomial size. The argument is a characterization of Frege proofs as non-commutative formulas: we show that the Frege system is (quasi-) polynomially equivalent to a non-commutative Ideal Proof System (IPS), following the recent work of Grochow and Pitassi [10] that introduced a propositional proof system in which proofs are arithmetic circuits, and the work in [35] that considered adding the commutator as an axiom in algebraic propositional proof systems. This gives a characterization of propositional Frege proofs in terms of (non-commutative) arithmetic formulas that is tighter than (the formula version of IPS) in Grochow and Pitassi [10], in the following sense: (i) The non-commutative IPS is polynomial-time checkable – whereas the original IPS was checkable in probabilistic polynomial-time; and (ii) Frege proofs unconditionally quasi-polynomially simulate the non-commutative IPS – whereas Frege was shown to efficiently simulate IPS only assuming that the decidability of PIT for (commutative) arithmetic formulas by polynomial-size circuits is efficiently provable in Frege. 1998 ACM Subject Classification F.2.2 [Analysis of Algorithms and Problem Complexity] Nonnumerical Algorithms and Problems – Complexity of proof procedures	algorithm;analysis of algorithms;co-np;computation;computational complexity theory;computational model;frege system;grammatical framework;lieb-robinson bounds;linear algebra;pp (complexity);peano axioms;polynomial;proof calculus;proof complexity;propositional calculus;propositional proof system;provable prime;quasi-polynomial;simulation;time complexity	Fu Li;Iddo Tzameret;Zhengyu Wang	2015		10.4230/LIPIcs.CCC.2015.412	discrete mathematics;probabilistically checkable proof;computer science;mathematics;proof complexity;algorithm	Theory	7.802755297583964	21.31645027927463	18510
0d0afc75cd1e5a18d185a6668b0b5707366095f5	time-space tradeoff in derandomizing probabilistic logspace	metodo polinomial;complejidad espacio;algoritmo aleatorizado;temps polynomial;ejecucion programa;plan randomise;algorithme deterministe;algorithme randomise;probabilistic approach;space time;espacio tiempo;approche deterministe;program execution;deterministic approach;funcion logaritmica;deterministic algorithms;plan aleatorizado;logarithmic function;polynomial method;randomized design;enfoque probabilista;execution programme;approche probabiliste;fonction logarithmique;enfoque determinista;polynomial time;randomized algorithm;space complexity;complexite espace;methode polynomiale;espace temps;tiempo polinomial	Nisan [6] showed that any randomized logarithmic space algorithm (running in polynomial time and with two-sided error) can be simulated by a deterministic algorithm that runs simultaneously in polynomial time and Θ(log 2 n) space. Subsequently Saks and Zhou [9] improved the space complexity and showed that a deterministic simulation can be carried out in space θ(log 1.5 n). However, their simulation runs in time n θ(log0.5n ). We prove a time-space tradeoff that interpolates these two simulations. Specifically, we prove that, for any 0 < a < 0.5, any randomized logarithmic space algorithm (running in polynomial time and with two-sided error) can be simulated deterministically in time n θ(log0.5-αn ) and space O(log 1.5+α n). That is, we prove that BPL ⊆ DTISP[n O(log0.5-αn) , O(log 1.5+α n)].	l (complexity);randomized algorithm;space–time tradeoff	Jin-Yi Cai;Venkatesan T. Chakaravarthy;Dieter van Melkebeek	2004		10.1007/978-3-540-24749-4_50	time complexity;logarithm;combinatorics;computer science;space time;mathematics;dspace;randomized algorithm;deterministic system;completely randomized design;algorithm	Theory	9.283010758949759	26.285568151407176	18550
49a9c3ce6e3d86c511c7d53e2026a331b2776a81	scheduling reentrant jobs on parallel machines with a remote server	workload;parallel identical machines;hg finance;logistique;gestion labor;heuristic method;machine parallele;combinatorial problems;fase reentrante;problema np duro;metodo heuristico;maquina paralelas;microbiology laboratory;optimisation combinatoire;combinatorial problem;np hard problem;probleme combinatoire;problema combinatorio;gestion tâche;logistics;probleme np difficile;scheduling;reentrant phase;charge travail;microbiology;remote server;parallel machines;methode heuristique;task scheduling;carga trabajo;combinatorial optimization;reentrant jobs;ordonnancement;reglamento;structural properties;phase reentrante;logistica;optimizacion combinatoria	This paper explores a specific combinatorial problem relating to re-entrant jobs on parallel primary machines, with a remote server machine. A middle operation is required by each job on the server before it returns to its primary processing machine. The problem is inspired by the logistics of a semi-automated micro-biology laboratory. The testing programme in the laboratory corresponds roughly to a hybrid flowshop, whose bottleneck stage is the subject of study. We demonstrate the NP-hard nature of the problem, and provide various structural features. A heuristic is developed and tested on randomly generated benchmark data. Results indicate solutions reliably within 1.5% of optimum. We also provide a greedy 2-approximation algorithm. Test on real-life data from the microbiology laboratory indicate a 20% saving relative to current practice, which is more than can be achieved currently with 3 instead of 2 people staffing the primary machines.	benchmark (computing);greedy algorithm;heuristic;job stream;logistics;np-hardness;open-shop scheduling;procedural generation;randomness;real life;reentrancy (computing);scheduling (computing);semiconductor industry;server (computing)	Konstantin Chakhlevitch;Celia A. Glass	2009	Computers & OR	10.1016/j.cor.2008.11.007	logistics;mathematical optimization;combinatorial optimization;computer science;artificial intelligence;np-hard;mathematics;scheduling;algorithm	ML	17.281466632763415	9.491760970340554	18598
7557c0cce702e9cb20ba96eec0cd689f60787c19	higher order analysis of random 1-2 brother trees	higher order	We analyse the average behavior of the insertion scheme for 1–2 brother trees by modifying it in such a way that Yao's technique becomes applicable.		Thomas Ottmann;Wolffried Stucky	1980	BIT			Theory	13.516846476775209	22.824656123486243	18636
cfde3d3e152fe51c41e6e4f26ad516b505e152ec	discrete and dynamic versus continuous and static loading policy for a multi-compartment vehicle	metodo relajacion;continuous time;assignment problem;cycle time;cargamento;time scale;echelle temps;probleme affectation;temps continu;loading;discrete time;tiempo continuo;chargement;satisfiability;methode relaxation;delai livraison;loading problem;relaxation method;escala tiempo;literature review;plazo entrega;problema asignacion;politique chargement dynamique;shipping plan;plan transport;delivery lead time	In this paper, we address the problem of loading non-intermixable products in a vehicle consisting of compartments of different sizes. The demands of the products are different but uniform over time. The objective is to meet product demands and minimize setup rate (that is, the number of deliveries per unit time). Two approaches, namely, dynamic and static, are investigated and their performances are compared with each other. In the dynamic approach, deliveries are made in several discrete periods and, then, repeated in a cyclic fashion. In each of these deliveries, the allocation of products to compartments can be different. The static approach, on the other hand, assumes a continuous time scale and determines a single assignment of products to compartments that maximizes the time in which the product demands are fully satisfied by this single delivery. The comparison between the two approaches shows that the dynamic approach is superior to the static approach when a discrete time scale is considered. However, even when the discrete time scale constraint is relaxed, the dynamic approach still provides better results for relatively long cycle times. 2005 Elsevier B.V. All rights reserved.	assignment (computer science);lagrangian relaxation;multi-compartment model;performance	Yossi Bukchin;Subhash C. Sarin	2006	European Journal of Operational Research	10.1016/j.ejor.2005.03.035	mathematical optimization;discrete time and continuous time;simulation;cycle time variation;operations management;mathematics;assignment problem;operations research;relaxation;satisfiability	SE	13.832527605572222	4.99369909595349	18697
e7777d2c8c44b3a49db4140ed58e62f1f14bfd21	a fast compact prefix encoding for pattern matching in limited resources devices	limited resources devices fast compact prefix encoding pattern matching;data compression;decoding;fast compact prefix encoding;data processing;compressed string matching;smart cards;pattern matching;xml;limited resources devices;computer science;encoding pattern matching decoding data compression computer science data processing handheld computers xml smart cards;compressed string matching univeral codes;string matching;pattern matching decoding encoding;encoding;univeral codes;handheld computers	This paper shows how to compress (encode) losslessly, search and decompress (decode) textual data in a machine/device that has a limited memory (several kilobytes).	pattern matching	S. Harrusi;Amir Averbuch;Neta Rabin	2010	2010 Data Compression Conference	10.1109/DCC.2010.80	data compression;smart card;xml;data processing;computer science;theoretical computer science;pattern matching;database;programming language;encoding;string searching algorithm	EDA	11.5774704960127	27.766851793578784	18733
4c6d3c72fa37248c71132a10e3537b5997b3ae9f	quasi-product forms for lévy-driven fluid networks	quasi product form;tree fluid network;levy driven fluid network;laplace transform;levy process;splitting time;buffer content;priority queue;busy period;n dimensional levy process;idle period;multidimensional skorokhod problem;steady state	We study stochastic tree fluid networks driven by a multidimensional Lévy process. We are interested in (the joint distribution of) the steady-state content in each of the buffers, the busy periods, and the idle periods. To investigate these fluid networks, we relate the above three quantities to fluctuations of the input Lévy process by solving a multidimensional Skorokhod problem. This leads to the analysis of the distribution of the componentwise maximums, the corresponding epochs at which they are attained, and the beginning of the first last-passage excursion. Using the notion of splitting times, we are able to find their Laplace transforms. It turns out that, if the components of the Lévy process are ‘ordered’, the Laplace transform has a so-called quasi-product form. The theory is illustrated by working out special cases, such as tandem networks and priority queues. 2000 Mathematics Subject Classification: 60J30, 60K25, 60K30	mathematics subject classification;priority queue;steady state;tandem computers	Krzysztof Debicki;A. B. Dieker;Tomasz Rolski	2007	Math. Oper. Res.	10.1287/moor.1070.0259	mathematical optimization;combinatorics;lévy process;mathematics;steady state;priority queue;laplace transform;statistics	Metrics	9.379290971787258	11.105557292658153	18752
bd0c01f7c82d9d34c966950ae032b7cbe630ad2c	on rough concept lattices	domain theory;galois connection;concept;algebraic lattice;rough set theory;data analysis;concept lattice;object oriented;necessary and sufficient condition;point of view;definable set;formal concept analysis;rough	Formal concept analysis and rough set theory provide two different methods for data analysis and knowledge processing. Given a context K, one can get the concept lattice L(K) in Wille’s sense and the object-oriented rough concept lattice RO-L(K) (resp., attribute-oriented RA-L(K)). We study relations of the three kinds of lattices and their properties from the domain theory point of view. The concept of definable sets is introduced. It is proved that the family Def (K) of the definable sets in set-inclusion order is a complete sublattice of RO-L(K) and is a complete field of sets under some reasonable conditions. A necessary and sufficient condition for Def (K) to be equal to RO-L(K) is given. A necessary and sufficient condition is also given for the complete distributivity of RO-L(K). We also study algebraicity of RO-L(K) and several sufficient conditions are given for RO-L(K) to be algebraic.	domain theory;formal concept analysis;linear algebra;rough set;set theory	Lingyun Yang;Luoshan Xu	2009	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2009.11.030	combinatorics;discrete mathematics;rough set;definable set;computer science;formal concept analysis;domain theory;mathematics;data analysis;programming language;object-oriented programming;concept	Logic	-4.444980568601886	10.22692259622382	18779
8a156172266fbd41ac6a3deadcb868306cf003da	optimal sequencing via modular decomposition: characterization of sequencing functions	planificacion integral;produccion;gestion production;tache;integrated planning;sequencing functions;stain;sequencing;production control;least cost fault detection problem;modular decomposition;gestion produccion;production;total weighted completion time problem;ordonnancement;mancha	With the recent development of efficient algorithms for locating modules in a precedence network, a new class of sequencing algorithms has become promising. These algorithms obtain optimal sequences by finding optimal subsequences of progressively larger modules, until all jobs are sequenced. To guarantee optimality of resulting sequences, the sequencing (objective) function must satisfy the “job module property” defined herein. In this paper, three properties of sequencing functions are defined, and it is shown that a sequencing function satisfying these properties possesses the job module property; many other decomposition results previously shown by the second author to hold for the total weighted completion time problem follow as well. Moreover, the class of problems defined by these sequencing functions includes the total weighted completion time problem, the least-cost fault detection problem, and the total weighted exponential completion time problem.	modular decomposition	Clyde L. Monma;Jeffrey B. Sidney	1987	Math. Oper. Res.	10.1287/moor.12.1.22	mathematical optimization;bioinformatics;sequencing;mathematics;modular decomposition;integrated business planning	Theory	15.901988699602258	9.580487147885329	18788
88c7ea73e1b24419e9c6c8cc24eec295c6dc980a	distribution free learning with local queries		The model of learning with local membership queries interpolates between the PAC model and the membership queries model by allowing the learner to query the label of any example that is similar to an example in the training set. This model, recently proposed and studied by Awasthi et al. [5], aims to facilitate practical use of membership queries. We continue this line of work, proving both positive and negative results in the distribution free setting. We restrict to the boolean cube {−1, 1}n, and say that a query is q-local if it is of a hamming distance ≤ q from some training example. On the positive side, we show that 1-local queries already give an additional strength, and allow to learn a certain type of DNF formulas. On the negative side, we show that even ( n0.99 ) -local queries cannot help to learn various classes including Automata, DNFs and more. Likewise, q-local queries for any constant q cannot help to learn Juntas, Decision Trees, Sparse Polynomials and more. Moreover, for these classes, an algorithm that uses ( log(n) ) -local queries would lead to a breakthrough in the best known running times. ∗This paper is based on the M.Sc. thesis [6] of the first author. The thesis offers a more elaborated discussion, as well as experiments. †Matific inc. Most work was done while the author was an M.Sc. student at the Hebrew University, Jerusalem, Israel ‡Google inc. Most work was done while the author was a Ph.D. student at the Hebrew University, Jerusalem, Israel §School of Computer Science and Engineering, The Hebrew University, Jerusalem, Israel	algorithm;automaton;boolean algebra;decision tree;experiment;hamming distance;interpolation;newton–cotes formulas;sparse;test set	Galit Bary-Weisberg;Amit Daniely;Shai Shalev-Shwartz	2016	CoRR		machine learning;data mining;mathematics;algorithm	Theory	9.782395599110732	19.422469402500578	18825
5a592666adbbb3dfde858d306c7ea12bdfee48bc	complexity theoretic aspects of some cryptographic functions	desciframiento;fonction booleenne;decodage;decoding;complexite calcul;boolean function;cle publique;m matrix;cryptage rsa;rsa ciphering;condition suffisante;upper bound;least significant bit;complejidad computacion;public key;condicion suficiente;cifrado rsa;computational complexity;criptografia;funcion booliana;cryptography;llave publica;matriz m;cryptographie;sufficient condition;model of computation;matrice m;borne superieure;cota superior;spectral norm	In this work, we are interested in non-trivial upper bounds on the spectral norm of binary matrices M from {−1, 1} . It is known that the distributed Boolean function represented by M is hard to compute in various restricted models of computation if the spectral norm is bounded from above by N, where ε > 0 denotes a fixed constant. For instance, the size of a two-layer threshold circuit (with polynomially bounded weights for the gates in the hidden layer, but unbounded weights for the output gate) grows exponentially fast with n := log N . We prove sufficient conditions on M that imply small spectral norms (and thus high computational complexity in restricted models). Our general results cover specific cases, where the matrix M represents a bit (the least significant bit or other fixed bits) of a cryptographic decoding function. For instance, the decoding functions of the Pointcheval [9], the El Gamal [6], and the RSA-Paillier [2] cryptosystems can be addressed by our technique. In order to obtain our results, we make a detour on exponential sums and on spectral norms of matrices with complex entries. This method might be considered interesting in its own right.	characteristic function (convex analysis);commutation theorem;computational complexity theory;cryptographic hash function;cryptography;cryptosystem;least significant bit;model of computation;most significant bit;rsa (cryptosystem);t-norm;the matrix;time complexity	Eike Kiltz;Hans Ulrich Simon	2003		10.1007/3-540-45071-8_31	model of computation;least significant bit;combinatorics;discrete mathematics;computer science;cryptography;artificial intelligence;machine learning;mathematics;distributed computing;boolean function;algorithm;statistics	Theory	10.168628894397681	24.361337248092173	18856
7a1284d6b41773afbd82f04e7378c64edf9c6ff1	earthmover resilience and testing in ordered structures		One of the main challenges in property testing is to characterize those properties that are testable with a constant number of queries. For unordered structures such as graphs and hypergraphs this task has been mostly settled. However, for ordered structures such as strings, images, and ordered graphs, the characterization problem seems very difficult in general. In this paper, we identify a wide class of properties of ordered structures – the earthmover resilient (ER) properties – and show that the “good behavior” of such properties allows us to obtain general testability results that are similar to (and more general than) those of unordered graphs. A property P is ER if, roughly speaking, slight changes in the order of the elements in an object satisfying P cannot make this object far from P. The class of ER properties includes, e.g., all unordered graph properties, many natural visual properties of images, such as convexity, and all hereditary properties of ordered graphs and images. A special case of our results implies, building on a recent result of Alon and the authors, that the distance of a given image or ordered graph from any hereditary property can be estimated (with good probability) up to a constant additive error, using a constant number of queries. 2012 ACM Subject Classification Theory of computation → Streaming, sublinear and near linear time algorithms	algorithm;convex function;cyber resilience;erdős–rényi model;graph (discrete mathematics);graph property;hereditary property;ordered graph;property testing;string (computer science);theory of computation;time complexity;utility functions on indivisible goods	Omri Ben-Eliezer;Eldar Fischer	2018		10.4230/LIPIcs.CCC.2018.18	testability;combinatorics;discrete mathematics;ordered graph;graph property;hereditary property;constraint graph;computer science;special case;property testing;convexity	Theory	20.91673734414264	22.561816775242786	18889
4167a0940d5bba280d35edfc082a857f812ead68	09511 open problems - parameterized complexity and approximation algorithms			approximation algorithm;parameterized complexity	Erik D. Demaine;Mohammad Taghi Hajiaghayi;Dániel Marx	2009			probabilistic analysis of algorithms;approximation algorithm;mathematics;apx;l-reduction;hardness of approximation;parameterized complexity;mathematical optimization;asymptotic computational complexity	Theory	17.121938139616244	19.979251690529992	18916
2d58720ab6ffafe69a1a1d0449d26c3d9698193c	dynamic facility location with generalized modular capacities	modular capacities;industrial location;mixed integer programming;facilities;capacity;facility location	Authors are encouraged to submit new papers to INFORMS journals by means of a style file template, which includes the journal title. However, use of a template does not certify that the paper has been accepted for publication in the named journal. INFORMS journal templates are for the exclusive purpose of submitting to an INFORMS journal and should not be used to distribute the papers in print or online or to submit the papers to another publication.	branch and cut;cplex;closing (morphology);computation;experiment;facility location problem;global motion compensation;institute for operations research and the management sciences;lagrangian relaxation;linear programming relaxation;reduction (complexity)	Sanjay Dominik Jena;Jean-François Cordeau;Bernard Gendron	2015	Transportation Science	10.1287/trsc.2014.0575	mathematical optimization;integer programming;engineering;operations management;facility location problem;mathematics;welfare economics;1-center problem	Theory	22.029647597137604	8.94094333225029	18993
a9f55abaf8b109d5ab70b5827d7ed8724a499bbc	queueing network map-k(gi/∞) with high-rate arrivals	queueing network;asymptotic analysis;markovian arrival process;infinite number of servers	An analysis of the open queueing network MAP−(GI/∞)K is presented in this paper. The MAP−(GI/∞)K network implements Markov routing, general service time distribution, and an infinite number of servers at each node. Analysis is performed under the condition of a growing fundamental rate for the Markovian arrival process. It is shown that the stationary probability distribution of the number of customers at the nodes can be approximated by multi-dimensional Gaussian distribution. Parameters of this distribution are presented in the paper. Numerical results validate the applicability of the obtained approximations under relevant conditions. The results of the approximations are applied to estimate the optimal number of servers for a network with finite-server nodes. In addition, an approximation of higher-order accuracy is derived.	queueing theory	Alexander N. Moiseev;Anatoly A. Nazarov	2016	European Journal of Operational Research	10.1016/j.ejor.2016.04.011	mathematical optimization;combinatorics;discrete mathematics;asymptotic analysis;m/m/∞ queue;kelly network;layered queueing network;mathematics;markovian arrival process	Networks	8.51587287765019	11.872005328179197	19003
fbccdc994ae8c165159e3f644d90579cc0cf823b	an exact solution framework for the minimum cost dominating tree problem		The minimum cost dominating tree problem is a recently introduced NP-hard problem, which consists of finding a tree of minimal cost in a given graph, such that for every node of the graph, the node or one of its neighbours is in the tree. We present an exact solution framework combining a primal–dual heuristic with a branch-and-cut approach based on a transformation of the problem into a Steiner arborescence problem with an additional constraint. The effectiveness of our approach is evaluated on testbeds proposed in literature containing instances with up to 500 nodes. Our framework manages to solve all but four instances from literature to proven optimality within 3 h (most of them in a few seconds). We provide optimal solution values for 69 instances from literature for which the optimal solution was previously unknown.		Eduardo Álvarez-Miranda;Martin Luipersbeck;Markus Sinnl	2018	Optimization Letters	10.1007/s11590-018-1252-z	mathematical optimization;branch and cut;exact solutions in general relativity;arborescence;heuristic;mathematics;graph	Theory	24.506531268037048	7.335609821436579	19080
7444d47f35a935d2af25481c29491ff0e2088a18	the effect of structural branching on the efficiency of clause learning sat solving: an experimental study	heuristique;learning;heuristica;problem structure;etude experimentale;search space;efficiency;branching;resolution math;satisfiabilite;prise de decision;backdoor sets;restriction;satisfiability;input;68t05;algorithme;aprendizaje;etat actuel;sat;algorithm;eficacia;apprentissage;estudio caso;ramificacion;state of the art;entree ordinateur;etude cas;decision;efficacite;learning problems;resolucion matematica;ramification;completitud;estado actual;branching heuristics;evaluation;heuristics;evaluacion;completeness;entrada ordenador;sat solver;toma decision;completude;estudio experimental;solving;clause learning;propositional satisfiability;algoritmo	The techniques for making decisions (branching) play a central role in complete methods for solving structured instances of propositional satisfiability (SAT). Experimental case studies in specific problem domains have shown that in some cases SAT solvers can determine satisfiability faster if branching in the solver is restricted to a subset of the variables at hand. The underlying idea in these approaches is to prune the search space substantially by restricting branching to strong backdoor sets of variables which guarantee completeness of the search. In this paper we present an extensive experimental evaluation of the effects of structurebased branching restrictions on the efficiency of solving structural SAT instances. Previous work is extended in a number of ways. We study state-of-the-art solver techniques, including clause learning and related heuristics. We provide a thorough analysis of the effect of branching restrictions on the inner workings of the solver, going deeper than merely measuring the solution time. Extending previous studies which have focused on input-restricted branching, we also consider relaxed branching restrictions that are based on underlying structural properties of the variables. © 2008 Elsevier Inc. All rights reserved.	backdoor (computing);boolean circuit;boolean satisfiability problem;conjunctive normal form;constraint learning;experiment;heuristic (computer science);problem domain;solver	Matti Järvisalo;Ilkka Niemelä	2008	J. Algorithms	10.1016/j.jalgor.2008.02.005	combinatorics;branching;completeness;evaluation;mathematics;efficiency;boolean satisfiability problem;algorithm	AI	12.967532015815735	16.251337999042725	19107
398eaf6c2b239d13336aebb518dc70e51d1a5b77	a decomposition algorithm for locating a shortest path between two nodes in a network	shortest path;decomposition algorithm	Abstract#R##N##R##N#A decomposition algorithm for locating a shortest path between two nodes of a network with circuits (directed cycles) and arbitrary arc distances (with the customary assumption of no negative circuits) is introduced. Unlike similar decomposition algorithms by Hu [12, 13], Yen [23], and Glover, Klingman, and Napier [10], this algorithm finds only the shortest distance between two specified nodes. Computational complexity of this algorithm is shown to be better than the previous decomposition algorithms.	algorithm;shortest path problem	John J. Jarvis;Süleyman Tüfekci	1982	Networks	10.1002/net.3230120207	mathematical optimization;combinatorics;constrained shortest path first;average path length;computer science;pathfinding;euclidean shortest path;machine learning;yen's algorithm;mathematics;shortest path problem;distance;k shortest path routing;shortest path faster algorithm;algorithm	Theory	20.900971883060862	24.755445202468398	19230
2c3b2f2ae2b1309460c1c1d16cdee91ad2df3e0b	vehicle routing problems with road-network information: state of the art			vehicle routing problem	Hamza Ben Ticha;Nabil Absi;Dominique Feillet;Alain Quilliot	2018	Networks	10.1002/net.21808	mathematical optimization;theoretical computer science;mathematics;vehicle routing problem;multigraph	Robotics	22.62083278224448	8.228715942331668	19239
8200e56013c40288109839bde3c04a395c409121	dynamic programming based approximation algorithms for sequence alignment with constraints	dynamic programming;normalized local alignment;approximate algorithm;approximation algorithm;dynamic program;length restricted local alignment;fractional programming;cyclic sequence comparison;sequence alignment;local alignment;ratio maximization	Pairwise local alignment is one of the most important problems in sequence analysis in computational biology. Classical dynamic programming solution to this problem searches for two segments with maximum similarity score by discarding poorly conserved initial and terminal fragments. As a consequence, an alignment returned as optimal may contain a mosaic of well-conserved fragments arti cially connected by poorly-conserved or even unrelated fragments. In an attempt to solve the problems associated with the classical de nition of local similarity, several approaches have rede ned the objective of local alignment to incorporate segment lengths. These approaches give rise to problems with varying objective functions and constraints. When direct dynamic programming solutions exist for the constrained versions, the time complexity of the resulting exact algorithm is prohibitive. We present a survey of approximation algorithms and complexity results for each of these problems.	approximation algorithm;blast;best, worst and average case;binary search algorithm;computational biology;dynamic programming;exact algorithm;existential quantification;experiment;fasta;fast fourier transform;fractional programming;heuristic;iteration;mathematical optimization;ncsa mosaic;provable security;sequence alignment;sequence analysis;smith–waterman algorithm;time complexity	Abdullah N. Arslan;Ömer Egecioglu	2004	INFORMS Journal on Computing	10.1287/ijoc.1040.0097	fractional programming;mathematical optimization;combinatorics;computer science;theoretical computer science;dynamic programming;smith–waterman algorithm;sequence alignment;mathematics;approximation algorithm	Theory	16.157351004290682	23.751761951396983	19246
17f34a04a87c6e963d4c0df72e98930c2a446d1f	new results on next fit and first fit on-line algorithms for square and rectangle packing		Rectangle packing is a well studied NP-complete problem in which smaller rectangles are packed in an enclosing larger rectangle to minimize wastage of space. Rectangle packing is used in many applications such as scheduling of jobs, allocating memory, VLSI floor planning, pixel art and mobile components packing. In this paper, we study and analyze two online rectangle packing algorithms such as Next Fit and Fit Fit. We obtain interesting constant competitive ratios for square and rectangle packing. Our analytical results shows that FF performs better than NF for both square and rectangle packing for special classes of inputs.	competitive analysis (online algorithm);floorplan (microelectronics);new foundations;online algorithm;online and offline;pixel art;scheduling (computing);set packing;very-large-scale integration	Rakesh Mohanty;Pankhuri Kiran	2017	2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2017.8126172	rectangle;computer science;algorithm;noise measurement;scheduling (computing);pixel;algorithm design;very-large-scale integration;upper and lower bounds	Robotics	16.88775316290873	14.729233473209078	19282
00dea14b18a3c83f459b0b88311ef509ae1f54bf	applying convex integer programming: sum multicoloring and bounded neighborhood diversity		In the past 30 years, results regarding special classes of integer linear (and, more generally, convex) programs flourished. Applications in the field of parameterized complexity were called for and the call has been answered, demonstrating the importance of connecting the two fields. The classical result due to Lenstra states that solving Integer Linear Programming in fixed dimension is polynomial. Later, Khachiyan and Porkolab has extended this result to optimizing a quasiconvex function over a convex set. While applications of the former result have been known for over 10 years, it seems the latter result has not been applied much in the parameterized setting yet. We give one such application. Specifically, we deal with the Sum Coloring problem and a generalization thereof called Sum-Total Multicoloring, which is similar to the preemptive Sum Multicoloring problem. In Sum Coloring, we are given a graph G = (V,E) and the goal is to find a proper coloring c : V → N minimizing ∑ v∈V c(v). By formulating these problems as convex integer programming in small dimension, we show fixed-parameter tractability results for these problems when parameterized by the neighborhood diversity of G, a parameter generalizing the vertex cover number of G.	color;convex function;convex optimization;convex set;dynamic programming;graph (discrete mathematics);graph coloring;integer programming;linear programming;loss function;nonlinear system;optimization problem;parameterized complexity;polynomial;quasiconvex function;semidefinite programming;time complexity;traction substation;vertex cover	Tomas Gavenciak;Dusan Knop;Martin Koutecký	2017	CoRR		vertex cover;parameterized complexity;quasiconvex function;bounded function;polynomial;mathematical optimization;integer programming;convex set;mathematics;integer	Theory	22.779223447696808	16.08845286874385	19349
ddf23420d830dacc5be962798989d22411b8d8c4	electricity load forecasting in a smart grid system				Chia-Yu Shen;Hsiao-Fan Wang	2016	Intell. Data Anal.	10.3233/IDA-160864	load balancing;stand-alone power system;smart grid	Robotics	1.2819322606701025	6.263926188352739	19351
41711711576b101210d440845565a81edb3de174	one-dimensional staged self-assembly	complexity;wang tile;context free grammar;dna computing	We introduce the problem of staged self-assembly of one-dimensional nanostructures, which becomes interesting when the elements are labeled (e.g., representing functional units that must be placed at specific locations). In a restricted model in which each operation has a single terminal assembly, we prove that assembling a given string of labels with the fewest steps is equivalent, up to constant factors, to compressing the string to be uniquely derived from the smallest possible context-free grammar (a well-studied O(log n)-approximable problem) and that the problem is NP-hard. Without this restriction, we show that the optimal assembly can be substantially smaller than the optimal context-free grammar, by a factor of $$\Omega(\sqrt{n/\log n})$$ even for binary strings of length n. Fortunately, we can bound this separation in model power by a quadratic function in the number of distinct glues or tiles allowed in the assembly, which is typically small in practice.	context-free grammar;context-free language;np-hardness;quadratic function;self-assembly;travelling salesman problem	Erik D. Demaine;Sarah Eisenstat;Mashhood Ishaque;Andrew Winslow	2012	Natural Computing	10.1007/s11047-012-9359-0	mathematical optimization;combinatorics;discrete mathematics;complexity;wang tile;computer science;artificial intelligence;machine learning;mathematics;context-free grammar;dna computing;algorithm	Theory	19.918154212475702	17.61100609469747	19378
73ce92197d9977a16502a2177522fd1c8ed39492	pseudorandom generators from regular one-way functions: new constructions with improved parameters	期刊论文	We revisit the problem of basing pseudorandom generators on regular one-way functions, and present the following constructions: - For any known-regular one-way function (on n-bit inputs) that is known to be ε-hard to invert, we give a neat (and tighter) proof for the folklore construction of pseudorandom generator of seed length Θ(n) by making a single call to the underlying one-way function. - For any unknown-regular one-way function with known ε-hardness, we give a new construction with seed length Θ(n) and O(n/log(1/ε)) calls. Here the number of calls is also optimal by matching the lower bounds of Holenstein and Sinha (FOCS 2012). Both constructions require the knowledge about ε, but the dependency can be removed while keeping nearly the same parameters. In the latter case, we get a construction of pseudo-random generator from any unknown-regular one-way function using seed length Õ(n) and Õ(n/log n) calls, where Õ omits a factor that can be made arbitrarily close to constant (e.g. log log log n or even less). This improves the randomized iterate approach by Haitner, Harnik and Reingold (CRYPTO 2006) which requires seed length O(n·log n) and O(n/log n) calls. © 2013 Springer-Verlag.	pseudorandom number generator	Yu Yu;Xiangxue Li;Jian Weng	2013		10.1007/978-3-642-42045-0_14	pseudorandom generators for polynomials;computer science;pseudorandom function family;pseudorandom generator;pseudorandomness;pseudorandom generator theorem	Crypto	11.115526412221543	23.790922574767592	19439
da52fb83b139df04bccf9800c5613b61530290dd	a note on bandits with a twist	proceso bandido;90c40;game theory;stochastic process;mathematiques discretes;matematicas discretas;discrete mathematics;teoria juego;theorie jeu;priority rule;gittins rule;68wxx;processus bandit;game 60j10;regle gittins;90b35;gittins index;scheduling;bandit process;processus stochastique;game;60g40;60j10;stochastic scheduling;regle priorite;proceso estocastico;66c99;multi armed bandit problem;ordonnancement;generalized bandit problem;reglamento;multiarmed bandit problem	A variant of the multi-armed bandit problem was recently introduced by Dimitriu, Tetali and Winkler. For this model (and a mild generalization) we propose faster algorithms to compute the Gittins index. The indexability of such models follows from earlier work of Nash on generalized bandits.	algorithm;multi-armed bandit;nash equilibrium	Akshay-Kumar Katta;Jay Sethuraman	2004	SIAM J. Discrete Math.	10.1137/S0895480103433549	stochastic process;games;game theory;mathematical optimization;multi-armed bandit;gittins index;mathematics;mathematical economics;scheduling	ML	10.730007342273257	10.50664174901518	19463
ec14de56d090acf5bc44053745d21235b3f5f88b	optimal integer solutions to industrial cutting-stock problems: part 2, benchmark results	decomposition;cutting stock trim;cutting stock problem;integer programming;dantzig wolfe;production scheduling;branch and price	In this paper we present a state-of-the-art version of the branch-and-price procedure of Degraeve and Schrage (1999) for the exact solution of the cutting-stock problem. The average solution time is reduced by a factor of more than 300. This allows us to solve problems twice as large as the largest problems solved in the literature today. The two most important improvements are (1) a hybrid simplex method/subgradient-optimization procedure to find the LP relaxation, and (2) a branching scheme that first focuses on the residual problem throughout the enumeration tree. In addition, the strength of our algorithm is the integration of different components into one comprehensive procedure. The other components are using heuristics intensively, a pruning rule, and the use of a dominance rule. We validate our methodology with both industrial and generated data sets. The performance of our algorithm is compared extensively with other implementations and various heuristics for the problem. The proposed algorithm is very efficient for solving the bin-packing problem as well. The major implication of our methodology is that we solve industrial sizes of an NP-hard problem practically in a time to solve its LP relaxation.	benchmark (computing);cutting stock problem	Zeger Degraeve;Marc Peeters	2003	INFORMS Journal on Computing	10.1287/ijoc.15.1.58.15156	mathematical optimization;integer programming;branch and price;cutting stock problem;mathematics;scheduling;mathematical economics;decomposition;algorithm	Theory	17.425146374470348	4.269884394423966	19467
5645eab64d0af77a35d04dc4c81225eb0e3c4804	computing forbidden words of regular languages	sofic shift;anti factorial language;factorial language;formal languages;regular language;factor automaton;failure function;forbidden word;linear time;symbolic dynamics;formal language	We give a quadratic-time algorithm to compute the set of mini al forbidden words of a factorial regular language. We give a linear-time algorith m to compute the minimal forbidden words of a finite set of words. This extends a previous result given f or the case of a single word only. We also give quadratic-time algorithms to check whether a re gular language is factorial or antifactorial.	algorithm;regular language;time complexity	Marie-Pierre Béal;Maxime Crochemore;Filippo Mignosi;Antonio Restivo;Marinella Sciortino	2003	Fundam. Inform.		arithmetic;formal language;discrete mathematics;pumping lemma for regular languages;nondeterministic finite automaton;regular language;regular grammar;computer science;mathematics;algorithm;context-sensitive language;algebra	Theory	-1.2956663558039534	20.685757199323955	19487
bedf958940fa27d7be2fe877413703cbe06696f4	learning n-ary node selecting tree transducers from completely annotated examples	extraction information;inference grammaticale;learning algorithm;red www;temps polynomial;automate arbre;information extraction;interrogation base donnee;reseau web;interrogacion base datos;logica monadica;intelligence artificielle;algorithme apprentissage;approche deterministe;monadic second order;inferencia gramatical;deterministic approach;second order logic;logica orden 2;logique ordre 2;internet;tree automaton;automata arbol;logique monadique;enfoque determinista;tree automata;polynomial time;artificial intelligence;world wide web;monadic logic;grammatical inference;inteligencia artificial;algoritmo aprendizaje;database query;extraccion informacion;web information extraction;tiempo polinomial	We present the first algorithm for learning n-ary node selection queries in trees from completely annotated examples by methods of grammatical inference. We propose to represent n-ary queries by deterministic n-ary node selecting tree transducers (n-NSTTs). These are tree automata that capture the class of monadic second-order definable nary queries. We show that n-NSTT defined polynomially bounded n-ary queries can be learned from polynomial time and data. An application in Web information extraction yields encouraging results.	algorithm;automata theory;grammar induction;information extraction;monadic predicate calculus;time complexity;transducer;tree automaton	Aurélien Lemay;Joachim Niehren;Rémi Gilleron	2006		10.1007/11872436_21	time complexity;the internet;computer science;artificial intelligence;theoretical computer science;machine learning;database;mathematics;linguistics;monadic predicate calculus;deterministic system;information extraction;second-order logic;algorithm	NLP	3.0768643762531536	17.731342414727045	19494
d210332216a14b5ef9bbd694c835398cd89be700	a low-cost gps logger for cyclest group trajectory data collection		This paper Presents the design of a low-cost GPS logger that logs GPS coordinates of a group of cyclists throughout certain trip. The main goal is to eliminate the communication cost by replacing cellular connection by Wi-Fi. Therefore, the system is equipped with a Wi-Fi transceiver that allows transferring the trip data from the moving logger to a stationary off-road host station. Mathematical models for data size, transfer time, location logging resolution are proposed. System design and implantation are reported. The paper also presents the a practical field test case of a full data transfer cycle at velocity of 40 km/h. results show the feasibility of the proposed system in serving groups of touring cyclists who move in moderate speeds.	data logger;gps tracking unit;global positioning system;ion implantation;keystroke logging;stationary process;test case;transceiver;velocity (software development)	Omar Alharthi;Mohammed Alsuliman;Mohammad Alsharif;Yasser Seddiq;Muteb Alsaqhan;Mohanna Al Enazi	2017	2017 UKSim-AMSS 19th International Conference on Computer Modelling & Simulation (UKSim)	10.1109/UKSim.2017.36	microcontroller;data collection;transceiver;mathematical model;data transmission;real-time computing;global positioning system;logging;systems design;computer science	Robotics	-0.0654403582878654	30.0462982511721	19497
e772d0817e4e5c2f2f032671008df38bd1230f0f	storage schemes for boundedly extendible arrays	willing to pay	The high costs of extendibility in array realizations can be reduced dramatically by placing a bound on how big the arrays of interest will grow. Whereas extendible array realizations require order of p · log p storage locations to store two-dimensional arrays having p or fewer positions, boundedly extendible array realizations (with a bound of p) can store these same arrays in precisely p locations. Moreover, boundedly extendible realizations can be designed to afford one additive traversal of both the rows and columns of the stored arrays, albeit at the cost of very inefficient storage utilization (order of p 3/2 locations are needed to store arrays having p or fewer positions); extendible array realizations cannot yield such bidirectional additive traversal, irrespective of the price one is willing to pay. Moreover, if one can specify that the smallest array of interest is of shape h × w, then the p 3/2 cost of storage utilization can be improved to roughly p · (p/hw)1/2 but no further.	column (database);extensibility;tree traversal;utility functions on indivisible goods	Arnold L. Rosenberg;Larry J. Stockmeyer	1977	Acta Informatica	10.1007/BF00290338	discrete mathematics;real-time computing;computer science;mathematics;algorithm	Theory	12.03375321426876	30.03952356124107	19525
256cefe4fe3f0d83ec1a19e26fbb997431530a34	college admissions with stable score-limits	hb5 mathematical economics matematikai kozgazdasagtan;lb2300 higher education felsőoktatas;stable matching;college admissions;обобщенные паросочетания;mechanism design;hb economic theory kozgazdasagtudomany	A common feature of the Hungarian, Irish, Spanish and Turkish higher education admission systems is that the students apply for programmes and they are ranked according to their scores. Students who apply for a programme with the same score are in a tie. Ties are broken by lottery in Ireland, by objective factors in Turkey (such as date of birth) and other precisely defined rules in Spain. In Hungary, however, an equal treatment policy is used, students applying for a programme with the same score are all accepted or rejected together. In such a situation there is only one question to decide, whether or not to admit the last group of applicants with the same score who are at the boundary of the quota. Both concepts can be described in terms of stable score-limits. The strict rejection of the last group with whom a quota would be violated corresponds to the concept of H-stable (i.e. higher-stable) score-limits that is currently used in Hungary. We call the other solutions based on the less strict admission policy as L-stable (i.e. lower-stable) score-limits. We show that the natural extensions of the Gale-Shapley algorithms produce stable score-limits, moreover, the applicant-oriented versions result in the lowest score-limits (thus optimal for students) and the college-oriented versions result in the highest score-limits with regard to each concept. When comparing the applicant-optimal H-stable and L-stable score-limits we prove that the former limits are always higher for every college. Furthermore, these two solutions provide upper and lower bounds for any solution arising from a tie-breaking strategy. Finally we show that both the H-stable and the L-stable applicant-proposing scorelimit algorithms are manipulable.	algorithm;rejection sampling;stable marriage problem	Péter Biró;Sofya G. Kiselgof	2015	CEJOR	10.1007/s10100-013-0320-9	mathematics education;mechanism design;stable marriage problem;economics;computer science;operations management;mathematics;operations research	Web+IR	19.5273737756437	11.033636674386049	19550
0d485e8d28a0e91f0c5f145f052a42d104b421f1	sorting by distributive partitioning		Sorting seems to be one of the most investigated problems in algorithm design. After a tremendous development in the 1960’s it looks like the complexity of known sorting algorithms differs from the theoretical complexity by only a small fraction. Recent results ([ 11) gave only a very marginal improvement so it appears that the sorting problem is already closed. A more careful investigation shows that until now only comparison-oriented sorting methods have been taken into consideration in most studies. It is therefore reasonable to inspect the possibilities of other sorting methods, mainly distributive methods. The present state of art in distributive sorting could be summed up as follows: “distributive methods will sort a set of numbers uniformly distributed over some (small) range in time O(n), but the worst case is o(n2) and we know that uniform distribution does not always happen in reality”. This paper describes a new sorting method with a worst-case time complexity of O(n log n) and an expected time of O(n) for uniform distribution. A more detailed study of the behaviour of the presented algorithm is in preparation.	algorithm design;average-case complexity;best, worst and average case;marginal model;sorting algorithm;time complexity	Wlodzimierz Dobosiewicz	1978	Inf. Process. Lett.	10.1016/0020-0190(78)90028-5	mathematics;combinatorics;discrete mathematics;distributive property;sorting	Theory	17.12350962234287	16.93549947117569	19564
0dd80a61dfb11b9c13f242d3c5bcc48d10f6c025	a polynomial-time algorithm to approximately count contingency tables when the number of rows is constant	randomized algorithms;approximate algorithm;van den berg kesten conjecture;polynomial time algorithm;decision tree complexity;correlation inequalities;weighted sums;convex body;polynomial time;certificate complexity;randomized algorithm;approximation scheme;contingency tables;approximate counting;contingency table;reimer s inequality	"""We consider the problem of counting the number of contingency tables with given row and column sums. This problem is known to be #P-complete, even when there are only two rows [7]. In this paper we present the first fully-polynomial randomized approximation scheme for counting contingency tables when the number of rows is constant. A novel feature of our algorithm is that it is a hybrid of an exact counting technique with an approximation algorithm, giving two distinct phases. In the first, the columns are partitioned into """"small"""" and """"large"""". We show that the number of contingency tables can be expressed as the weighted sum of a polynomial number of new instances of the problem, where each instance consists of some new row sums and the original large column sums. In the second phase, we show how to approximately count contingency tables when all the column sums are large. In this case, we show that the solution lies in approximating the volume of a single convex body, a problem which is known to be solvable in polynomial time [5]."""	approximation algorithm;column (database);contingency table;decision problem;p-complete;polynomial;polynomial-time approximation scheme;randomized algorithm;sharp-p-complete;time complexity;weight function	Mary Cryan;Martin E. Dyer	2002		10.1145/509907.509946	mathematical optimization;combinatorics;discrete mathematics;contingency table;computer science;mathematics;randomized algorithm;algorithm	Theory	18.15819690008859	14.423040903552033	19581
72b287fe1e171e3654596f29249c57fe2ff19523	numerical analysis of queues with batch arrivals	bath arrivals;quasi birth death processes;numerical analysis;quasi birth death;batch arrival;matrix geometric methods;batch arrivals;steady state	The steady state distribution of quasi-birth–death processes can be efficiently obtained by matrix geometric (MG) methods. Since a number of telecommunication problems are modelled by processes with batch arrivals, the extension of MG methods for these processes has practical importance. This paper presents an extension of MG methods which is effective for the analysis of quasi-birth–death processes with batch arrivals. The proposed method is compared with one of the well-known methods.	numerical analysis	György Wolfner;Miklós Telek	2000	Perform. Eval.	10.1016/S0166-5316(00)00012-2	mathematical optimization;real-time computing;numerical analysis;computer science;mathematics;steady state	ML	8.394162687554752	11.944603750545015	19628
e8828670c3c6f8fdce9b309fa686e40dba75acee	théorème de transversale rationnelle pour les automates à pile déterministes		Sans résumé		Jacques Sakarovitch	1979		10.1007/3-540-09118-1_29	combinatorics;mathematics;combinatorial group theory;pile;context-free language	Crypto	0.5541603239634365	17.26798874554517	19735
9b46d11bbdef9757f4d2c64f70fc6bda5aa1ff0d	improved algorithms for the k simple shortest paths and the replacement paths problems	camino mas corto;graphe non oriente;lenguaje programacion;shortest path;shortest paths;replacement;problema reemplazo;non directed graph;procesamiento informacion;remplacement;programmation;digraph;camino grafo;algorithm analysis;programming language;congres international;graph path;probleme chemin;congreso internacional;replacement problem;all pairs shortest path;digrafo;plus court chemin;05c20;automaton;international conference;68wxx;probleme remplacement;programacion;algorithme;algorithm;weighted directed graphs;automata;graphe pondere;iteraccion;apsp;grafo pondero;grafo no orientado;informatique theorique;directed graph;automate;68r10;graphe oriente;information processing;chemin graphe;chemin plus court;time use;iteration;langage programmation;algorithms;grafo orientado;reemplazo;analyse algorithme;weighted graph;68n15;traitement information;replacement paths;programming;analisis algoritmo;k simple shortest paths;shortest path problem;computer theory;algoritmo;informatica teorica;digraphe	Given a directed, non-negatively weighted graph G=(V,E) and s,t@?V, we consider two problems. In the k simple shortest paths problem, we want to find the k simple paths from s to t with the k smallest weights. In the replacement paths problem, we want the shortest path from s to t that avoids e, for every edge e in the original shortest path from s to t. The best known algorithm for the k simple shortest paths problem has a running of O(k(mn+n^2logn)). For the replacement paths problem the best known result is the trivial one running in time O(mn+n^2logn). In this paper we present two simple algorithms for the replacement paths problem and the k simple shortest paths problem in weighted directed graphs (using a solution of the All Pairs Shortest Paths problem). The running time of our algorithm for the replacement paths problem is O(mn+n^2loglogn). For the k simple shortest paths we will perform O(k) iterations of the second simple shortest path (each in O(mn+n^2loglogn) running time) using a useful property of Roditty and Zwick [L. Roditty, U. Zwick, Replacement paths and k simple shortest paths in unweighted directed graphs, in: Proc. of International Conference on Automata, Languages and Programming (ICALP), 2005, pp. 249-260]. These running times immediately improve the best known results for both problems over sparse graphs. Moreover, we prove that both the replacement paths and the k simple shortest paths (for constant k) problems are not harder than APSP (All Pairs Shortest Paths) in weighted directed graphs.		Zvi Gotthilf;Moshe Lewenstein	2009	Inf. Process. Lett.	10.1016/j.ipl.2008.12.015	combinatorics;information processing;floyd–warshall algorithm;computer science;yen's algorithm;mathematics;shortest path problem;k shortest path routing;shortest path faster algorithm;algorithm	Theory	20.019615278971248	26.48982945382058	19765
5ce175060464a27512975a26a2ae3a92c5da8184	perfect matchings via uniform sampling in regular bipartite graphs	regular bipartite graphs;perfect matching;ost;maximum matching;bipartite graph;sampling theorem;perfect match	In this article we further investigate the well-studied problem of finding a perfect matching in a regular bipartite graph. The first nontrivial algorithm, with running time <i>O</i>(<i>mn</i>), dates back to König's work in 1916 (here <i>m</i>=<i>nd</i> is the number of edges in the graph, 2<i>n</i> is the number of vertices, and <i>d</i> is the degree of each node). The currently most efficient algorithm takes time <i>O(m)</i>, and is due to Cole et al. [2001]. We improve this running time to <i>O</i>(min{<i>m</i>, <i>n</i><sup>2.5</sup>ln <i>n</i>/<i>d</i>}); this minimum can never be larger than <i>O</i>(<i>n</i><sup>1.75</sup>&sqrt;ln <i>n</i>). We obtain this improvement by proving a uniform sampling theorem: if we sample each edge in a <i>d</i>-regular bipartite graph independently with a probability <i>p</i> = <i>O</i>(<i>n</i> ln <i>n</i>/<i>d</i><sup>2</sup>) then the resulting graph has a perfect matching with high probability. The proof involves a decomposition of the graph into pieces which are guaranteed to have many perfect matchings but do not have any small cuts. We then establish a correspondence between potential witnesses to nonexistence of a matching (after sampling) in any piece and cuts of comparable size in that same piece. Karger's sampling theorem [1994a, 1994b] for preserving cuts in a graph can now be adapted to prove our uniform sampling theorem for preserving perfect matchings. Using the <i>O</i>(<i>m</i>&sqrt;<i>n</i>) algorithm (due to Hopcroft and Karp [1973]) for finding maximum matchings in bipartite graphs on the sampled graph then yields the stated running time. We also provide an infinite family of instances to show that our uniform sampling result is tight up to polylogarithmic factors (in fact, up to ln<sup>2</sup> <i>n</i>).	algorithm;degree (graph theory);könig's lemma;matching (graph theory);nyquist–shannon sampling theorem;polylogarithmic function;sampling (signal processing);time complexity;vertex (graph theory);whole earth 'lectronic link;with high probability	Ashish Goel;Mikhail Kapralov;Sanjeev Khanna	2009		10.1145/1721837.1721843	strong perfect graph theorem;claw-free graph;perfect graph theorem;folded cube graph;mathematical optimization;complete bipartite graph;factor-critical graph;combinatorics;discrete mathematics;bipartite graph;perfect graph;3-dimensional matching;trivially perfect graph;edge coloring;cubic graph;graph coloring;graph factorization;mathematics;distance-hereditary graph;blossom algorithm;complete graph;biregular graph;line graph;matching	Theory	21.253899165223114	22.269891237203936	19804
e5ff688bd8f5ebc5ad07e1f1ba7da72feeb1dd61	do there exist complete sets for promise classes?	msc 2010 03f20;promise classes;computational complexity;ciencias basicas y experimentales;matematicas;68q15;optimal proof systems;grupo a	For concrete languages L (such as TAUT or SAT) and concrete promise classes C (such as NP ∩ coNP, UP, BPP, disjoint NP-pairs etc.), these questions have been intensively studied during the last years, and a number of characterizations have been obtained. Here we provide new characterizations for Q1 and Q2 that apply to almost all promise classes C and languages L, thus creating a unifying framework for the study of these practically relevant questions. While questions Q1 and Q2 are left open by our results, we show that they receive affirmative answers when a small amount of advice is available in the underlying machine model. For promise classes with promise condition in coNP, the advice can replaced by a tally NP-oracle.	advice (programming);bpp (complexity);boolean satisfiability problem;co-np;existential quantification;l (complexity);oracle machine	Olaf Beyersdorff;Zenon Sadowski	2011	Math. Log. Q.	10.1002/malq.201010021	computer science;mathematics;computational complexity theory;algorithm	Logic	7.664895136573157	19.667058319910154	19888
c3030b9a544f187d76b75991ce82144bca983ddb	unambiguity of circuits	no determinismo;logica booleana;machine turing;memoria acceso directo;multiprocessor;automate deterministe;sistema informatico;clase complejidad;computer system;circuito logico;turing machine;non determinism;classe complexite;deterministic automaton;complexity class;circuit logique;non determinisme;informatique theorique;memoire acces direct;automata determinista;random access memory ram;logique booleenne;ambiguity;systeme informatique;systeme parallele;parallel system;multiprocesador;boolean logic;ambiguedad;logic circuit;maquina turing;sistema paralelo;ambiguite;computer theory;multiprocesseur;informatica teorica	Lange, K.-J., Unambiguity of circuits, Theoretical Computer Science 107 (1993) 77-94. The concept of unambiguity of circuits is considered. Several classes of unambiguous circuit families within the NC-hierarchy are introduced and related to unambiguous automata and to PRAMS with exclusive write access. In particular, we show CREW-TIME(logk n)= UnambAC” for each positive integer k.	automata theory;crew scheduling;file system permissions;nc (complexity);theoretical computer science;unambiguous finite automaton	Klaus-Jörn Lange	1993	Theor. Comput. Sci.	10.1016/0304-3975(93)90255-R	complexity class;boolean algebra;multiprocessing;logic gate;computer science;turing machine;artificial intelligence;theoretical computer science;deterministic automaton;algorithm	Theory	5.118101166602152	23.8146654919894	19910
d2dcc4fb6ef389a0c51b6befa7f5c18badbcf0d8	"""traffic signal optimization in """"la almozara"""" district in saragossa under congestion conditions, using genetic algorithms, traffic microsimulation, and cluster computing"""	modelizacion;distributed system;traffic modeling cellular automata ca genetic algorithms gas intelligent transportation systems microsimulation traffic congestion;optimisation;cluster computing;congestion trafic;sistema de transporte;systeme intelligent;systeme reparti;traffic signal optimization;optimizacion;congestion trafico;intelligent transport system;calculator cluster;road traffic;traffic light programming traffic signal optimization la almozara district saragossa genetic algorithm traffic microsimulation cluster computing urban traffic congestion cellular automata beowulf cluster multiple instruction multiple data;intelligent transportation systems;gestion trafic;sistema inteligente;trafic urbain;traffic microsimulation;distributed computing;traffic control;la almozara district;cellular automata ca;urban traffic congestion;road signalling;traffic model;urban traffic;testing;intelligence artificielle;senalizacion trafico;traffic management;algoritmo genetico;signalisation routiere;traffic modeling;genetic algorithms gas;trafico urbano;modelisation;automata;large scale;telecommunication traffic;grappe calculateur;sistema repartido;calculateur mimd;trafic routier;feu signalisation;traffic congestion;automate cellulaire;intelligent system;saragossa;traffic lights;statistics;algorithme genetique;gestion trafico;calculo repartido;systeme transport;cities and towns;artificial intelligence;traffic engineering computing;genetic algorithm;genetic algorithms;trafico carretera;optimization;beowulf cluster;multiple instruction multiple data;vehicles;inteligencia artificial;semaforo;microsimulation;performance ratio;cellular automata;modeling;transportation system;calcul reparti;cellular automaton;traffic light programming;mimd computer;racimo calculadora;large scale systems;traffic engineering computing cellular automata genetic algorithms road traffic road vehicles;fitness function	Urban traffic congestion is a pandemic illness affecting many cities around the world. We have developed and tested a new model for traffic signal optimization based on the combination of three key techniques: 1) genetic algorithms (GAs) for the optimization task; 2) cellular-automata-based microsimulators for evaluating every possible solution for traffic-light programming times; and 3) a Beowulf Cluster, which is a multiple-instruction-multiple-data (MIMD) multicomputer of excellent price/performance ratio. This paper presents the results of applying this architecture to a large-scale real-world test case in a congestion situation, using four different variables as fitness function of the GA. We have simulated a set of congested scenarios for ?La Almozara? in Saragossa, Spain. Our results in this extreme case are encouraging: As we increase the incoming volume of vehicles entering the traffic network - from 36 up to 3600 vehicles per hour - we get better performance from our architecture. Finally, we present new research directions in this area.	computer cluster;genetic algorithm;linear algebra;network congestion	Javier J. Sánchez Medina;Manuel J. Galán Moreno;Enrique Rubio Royo	2010	IEEE Trans. Intelligent Transportation Systems	10.1109/TITS.2009.2034383	cellular automaton;simulation;genetic algorithm;telecommunications;computer science;artificial intelligence;traffic congestion reconstruction with kerner's three-phase theory;transport engineering	HPC	11.06612768587198	7.806850414010569	19989
c0467599550b5e8c1d53d4e5c2866d1a10bb0f80	approximation algorithms for the maximum induced planar and outerplanar subgraph problems	maximum degree;lower bound;outerplanar graph	The task of finding the largest subset of vertices of a graph that induces a planar subgraph is known as the Maximum Induced Planar Subgraph problem (MIPS). In this paper, some new approximation algorithms for MIPS are introduced. The results of an extensive study of the performance of these and existing MIPS approximation algorithms on randomly generated graphs are presented. Efficient algorithms for finding large induced outerplanar graphs are also given. One of these algorithms is shown to find an induced outerplanar subgraph with at least 3n/(d + 5/3) vertices. The results presented in this paper indicate that most existing algorithms perform substantially better than the existing lower bounds indicate.	approximation algorithm;emoticon;experiment;horseland;independent set (graph theory);induced subgraph;maximal independent set;maximal set;outerplanar graph;planar graph;procedural generation;random graph	Kerri Morgan;Graham Farr	2007	J. Graph Algorithms Appl.		mathematics;induced subgraph isomorphism problem;pancyclic graph;combinatorics;degeneracy (graph theory);universal graph;induced path;forbidden graph characterization;discrete mathematics;factor-critical graph;subgraph isomorphism problem	Theory	23.420183862887683	23.392667169054455	20012
8b62ad07d41f5680004fe1e5b38e77514b8ebdad	compression with the tudocomp framework		We present a framework facilitating the implementation and comparison of text compression algorithms. We evaluate its features by a case study on two novel compression algorithms based on the Lempel-Ziv compression schemes that perform well on highly repetitive texts. 1998 ACM Subject Classification D.3.3 Frameworks, D.2.2 Software Libraries	algorithm;data compression;lz77 and lz78;library (computing)	Patrick Dinklage;Johannes H Fischer;Dominik Köppl;Marvin Löbel;Kunihiko Sadakane	2017		10.4230/LIPIcs.SEA.2017.13	discrete mathematics;theoretical computer science;computer science;data compression;compression (physics)	Comp.	11.964571956349983	27.829915156841306	20043
31a7f573019eaef2c484a2fb8bb3eea14143f2c2	longest unbordered factor in quasilinear time		A border u of a word w is a proper factor of w occurring both as a prefix and as a suffix. The maximal unbordered factor of w is the longest factor of w which does not have a border. Here an O(n log n)-time with high probability (or O(n log n log log n)-time deterministic) algorithm to compute the Longest Unbordered Factor Array of w for general alphabets is presented, where n is the length of w. This array specifies the length of the maximal unbordered factor starting at each position of w. This is a major improvement on the running time of the currently best worst-case algorithm working in O(n) time for integer alphabets [Gawrychowski et al., 2015].	best, worst and average case;deterministic algorithm;maximal set;time complexity;with high probability	Tomasz Kociumaka;Ritu Kundu;Manal Mohamed;Solon P. Pissis	2018		10.4230/LIPIcs.ISAAC.2018.70	combinatorics;discrete mathematics;time complexity;mathematics;suffix;binary logarithm;integer;prefix	Theory	13.845629484229063	26.15937162734608	20113
b95c147c1648b02b262c0c7667071f39a7890d36	stable set and multiset operations in optimal time and space	complexite;optimisation;optimizacion;performance;complejidad;data management;complexity;stability;algorithme;analysis of algorithms;algorithm;computational complexity;stable set;optimization;systeme gestion base donnee;rendimiento;stabilite;sistema gestion base datos;database management system;estabilidad;algoritmo	Abstract   We devise time-space optimal methods for stably performing set and multiset operations on sorted files of data. For the sake of complete generality, our techniques neither modify records nor require any information other than a record's key.		Bing-Chao Huang;Michael A. Langston	1991	Inf. Process. Lett.	10.1016/0020-0190(91)90108-T	complexity;stability;performance;data management;computer science;artificial intelligence;analysis of algorithms;mathematics;computational complexity theory;algorithm	DB	16.080360488071975	27.20943449143261	20122
ac754ae69164a30db33af66639cdf254e8506fbd	faster algorithms for testing under conditional sampling		There has been considerable recent interest in distribution-tests whose run-time and sample requirements are sublinear in the domain-size k. We study two of the most important tests under the conditional-sampling model where each query specifies a subset S of the domain, and the response is a sample drawn from S according to the underlying distribution. For identity testing, which asks whether the underlying distribution equals a specific given distribution or ǫ-differs from it, we reduce the known time and sample complexities from Õ(ǫ−4) to Õ(ǫ−2), thereby matching the information theoretic lower bound. For closeness testing, which asks whether two distributions underlying observed data sets are equal or different, we reduce existing complexity from Õ(ǫ−4 log k) to an even sub-logarithmic Õ(ǫ−5 log log k) thus providing a better bound to an open problem in Bertinoro Workshop on Sublinear Algorithms [Fisher, 2014].	algorithm;centrality;gibbs sampling;requirement;sampling (signal processing);theory	Moein Falahatgar;Ashkan Jafarpour;Alon Orlitsky;Venkatadheeraj Pichapati;Ananda Theertha Suresh	2015			theoretical computer science;mathematics;algorithm;statistics	ML	14.016054960051077	20.30004389924897	20208
aaef7455eaa872488e8b6700ba12447176649592	a parameterized study of maximum generalized pattern matching problems	(maximum) generalized pattern matching;string morphisms;parameterized complexity	The generalized function matching (GFM) problem has been intensively studied starting with Ehrenfreucht and Rozenberg (Inf Process Lett 9(2):86---88, 1979). Given a pattern p and a text t, the goal is to find a mapping from the letters of p to non-empty substrings of t, such that applying the mapping to p results in t. Very recently, the problem has been investigated within the framework of parameterized complexity (Fernau et al. in FSTTCS, 2013). In this paper we study the parameterized complexity of the optimization variant of GFM (called Max-GFM), which has been introduced in Amir and Amihood (J Discrete Algorithms 5(3):514---523, 2007). Here, one is allowed to replace some of the pattern letters with some special symbols ?, termed wildcards or donu0027t cares, which can be mapped to an arbitrary substring of the text. The goal is to minimize the number of wildcards used. We give a complete classification of the parameterized complexity of Max-GFM and its variants under a wide range of parameterizations, such as, the number of occurrences of a letter in the text, the size of the text alphabet, the number of occurrences of a letter in the pattern, the size of the pattern alphabet, the maximum length of a string matched to any pattern letter, the number of wildcards and the maximum size of a string that a wildcard can be mapped to.	pattern matching	Sebastian Ordyniak;Alexandru Popa	2014		10.1007/978-3-319-13524-3_23	theoretical computer science;machine learning	Theory	13.549457658243238	26.608509616911764	20233
02926166932fdf5c219d70258317d97dc20f53cd	systolic tree omega-languages: the operational and the logical view	complexite;calcul logique second ordre;automata on ω words;temps polynomial;bchi automaton;automate arbre;equation ordre 2;automate deterministe;logic;decidable monadic second order logic;complejidad;second order equation;complexity;algorithme;algorithm;automate systolique;second order logic;deterministic automaton;monadic second order logic;tree automaton;omega language;langage omega;automata arbol;automata determinista;polynomial time;automate bchi;decidibilidad;ecuacion orden 2;decidabilite;systolic automaton;logique;logica;systolic automata;decidability;algoritmo;tiempo polinomial	Abstract   The class of   ω  -languages recognized by systolic (binary) tree automata is introduced. This class extends the class of Buchi   ω  -languages though maintaining the closure under union, intersection and complement and the decidability of emptiness. The class of systolic tree   ω  -languages is characterized in terms of a (suitable) concatenation of (finitary) systolic tree languages. A generalization of Buc̈hi Theorem is provided which establishes a correspondence between systolic tree   ω  -languages and a suitable extension of the sequential calculus   S1S  .	chaitin's constant	Angelo Monti;Adriano Peron	2000	Theor. Comput. Sci.	10.1016/S0304-3975(97)00257-0	decidability;combinatorics;discrete mathematics;complexity;computer science;deterministic automaton;mathematics;logic;algorithm;algebra	ECom	-2.9350898411666826	20.183307450139946	20248
00da42c4100759e0702d1184d0c1368b781f099b	a new traffic aggregation technique based on markov modulated poisson processes	eigenvalues and eigenfunctions;cluster algorithm;pattern clustering;time constant;pattern clustering telecommunication traffic markov processes eigenvalues and eigenfunctions matrix algebra;matrix algebra;transition matrix;telecommunication traffic;traffic control telecommunication traffic state space methods clustering algorithms time measurement eigenvalues and eigenfunctions data communication packet switching communication switching mathematical model;markov modulated poisson process;arrival rate traffic aggregation technique markov modulated poisson processes decaying time constants eigenvalues transition matrix representative time constants clustering algorithm rate limit algorithm;state space;rate limiting;markov processes	In this paper, we propose a technique to approximate the traffic aggregation processes described by Markov modulated Poisson processes (MMPP) models. It is found that the decaying time constants of the aggregated traffic process are the product of the eigenvalues of the transition matrix of the individual traffic. If the time constants are well clustered around some representative time constants (RTC's), the corresponding states can be merged in the state space. In the worst case, if the time constants are uniformly distributed over the log-scale, we prove that there exist a minimum number of states that can approximate the traffic aggregation. We develop a clustering algorithm to search for the RTC's and extend the rate limit algorithm to the case that the limit of the arrival rate is unknown.	approximation algorithm;best, worst and average case;cluster analysis;existential quantification;markov chain;modulation;numerical analysis;queueing theory;rate limiting;state space;stochastic matrix	Ming Yu;David G. Daut	2005	GLOBECOM '05. IEEE Global Telecommunications Conference, 2005.	10.1109/GLOCOM.2005.1577945	mathematical optimization;markov kernel;combinatorics;discrete mathematics;computer science;state space;rate limiting;stochastic matrix;mathematics;markov process;time constant;statistics	Metrics	10.214009833643534	12.652112664740615	20262
0142e17acf7ce3f9e45387278088b74d5e641358	an o(n2.75) algorithm for incremental topological ordering	directed acyclic graph;online algorithm;topological order;dynamic algorithms;graphs;insertion sequence;online algorithms	We present a simple algorithm which maintains the topological order of a directed acyclic graph (DAG) with <i>n</i> nodes, under an online edge insertion sequence, in <i>O</i>(<i>n</i><sup>2.75</sup>) time, independent of the number <i>m</i> of edges inserted. For dense DAGs, this is an improvement over the previous best result of <i>O</i>(min{<i>m</i><sup>3/2</sup> log <i>n</i>, <i>m</i><sup>3/2</sup> + <i>n</i><sup>2</sup> log <i>n</i>}) by Katriel and Bodlaender [2006]. We also provide an empirical comparison of our algorithm with other algorithms for incremental topological sorting.	algorithm;directed acyclic graph;topological sorting	Deepak Ajwani;Tobias Friedrich;Ulrich Meyer	2008	ACM Trans. Algorithms	10.1145/1383369.1383370	online algorithm;combinatorics;discrete mathematics;computer science;machine learning;mathematics;topological sorting;directed acyclic graph	Theory	20.189415860288097	23.61282678854582	20283
57582d3a00690c5bed96cb7c53e9e3d9266a86dc	unifying sat-based and graph-based planning	benchmark problem;satisfiability;polynomial time	TheBlackbox planning system unifies the planning as satisfiability framework (Kautz and Selman 1992, 1996) with the plan graph approach to STRIPS planning (Blum and Furst 1995). We show that STRIPS problems can be directly translated into SAT and efficiently solved using new randomized systematic solvers. For certain computationally challenging benchmark problems this unified approach outperforms both SATPLAN and Graphplan alone. We also demonstrate that polynomialtime SAT simplification algorithms applied to the encoded problem instances are a powerful complement to the “mutex” propagation algorithm that works directly on the plan graph.	benchmark (computing);blum axioms;boolean satisfiability problem;graphplan;heuristic (computer science);level of detail;mutual exclusion;randomized algorithm;strips;satplan;software propagation	Henry A. Kautz;Bart Selman	1999			time complexity;mathematical optimization;combinatorics;computer science;machine learning;mathematics;algorithm;satisfiability	AI	13.549410496802142	16.569389142721818	20290
b5e1cea62c0da9f0a1beef6cccf4f61b0f174900	recording and minimizing nogoods from restarts	time complexity;search algorithm;generalized arc consistency;search trees	In this paper, nogood recording is investigated for CSP within the randomization and restart framework. Our goal is to avoid the same situations to occur from one run to the next ones. More precisely, nogoods are recorded when the current cutoff value is reached, i.e. before restarting the search algorithm. Such a set of nogoods is extracted from the last branch of the current search tree and exploited using the structure of watched literals originally proposed for SAT. We prove that the worst-case time complexity of extracting such nogoods at the end of each run is only O(nd) where n is the number of variables of the constraint network and d the size of the greatest domain, whereas for any node of the search tree, the worst-case time complexity of exploiting these nogoods to enforce Generalized Arc Consistency (GAC) is O(n|B|) where |B| denotes the number of recorded nogoods. As the number of nogoods recorded before each new run is bounded by the length of the last branch, the total number of recorded nogoods is polynomial in the number of restarts. Interestingly, we show that when the minimization of the nogoods is envisioned with respect to an inference operator φ, it is possible to directly identify some nogoods that cannot be minimized. For φ = AC (i.e. for MAC), the worst-case time complexity of extracting minimal nogoods is slightly increased to O(end) where e is the number of constraints of the network. Experimentation over a wide range of CSP instances using a generic stateof-the-art CSP solver demonstrates the effectiveness of this approach. Recording nogoods (and in particular, minimal nogoods) from restarts significantly improves the robustness of the solver.	best, worst and average case;embedded system;local consistency;polynomial;propagator;search algorithm;search tree;software propagation;solver;time complexity;visual intercept	Christophe Lecoutre;Lakhdar Sais;Sébastien Tabary;Vincent Vidal	2007	JSAT		time complexity;mathematical optimization;computer science;theoretical computer science;mathematics;algorithm;search algorithm	AI	22.326208268721818	5.172860287075524	20346
e013d10d370cdebf39df31a766472f1012e0523d	an iot based 6lowpan enabled experiment for water management	sensors;6lowpan contiki iot ipv6 water wireless;wireless communication;gateway iot based 6lowpan water management india water supply climatic change wasteful usage urbanization resource depletion resource management resource conservation human survival clean water access safe water access real time water flow metering quality monitoring ipv6 network connected iot design prototype implementation internet based data collection fair billing water consumption water wastage curbing leakage automatic detection water quality ph sensor deployment orp sensor deployment wireless system ubiquitous usage smart water flow metering quality monitoring cc2538 mote contikios;monitoring;zigbee;water supply chemical sensors climate mitigation internet of things internetworking invoicing ip networks personal area networks quality management water meters water quality;water pollution;sensors water conservation water pollution monitoring wireless communication wireless sensor networks zigbee;wireless sensor networks;water conservation	During the past decade, water needs have risen exponentially to an unprecedented scale in India. The demand for water supply is ever increasing and satisfying this requirement has been a major challenge for many countries around the world. Urbanization, climatic changes and wasteful usage has further depleted the resource. Water being one of the major requirements for human survival, conservation and management of the resource must be given utmost importance. Ensuring access to safe and clean water is another issue that requires attention. In this paper, we present an IPv6 network connected IoT design for real-time water flow metering and quality monitoring. Our prototype implementation uses CoAP for monitoring and control approach which supports internet based data collection. The system addresses new challenges in the water sector - ease of billing, fair billing and the need for a study of supply versus consumption of water in order to create awareness to curb water wastage and encourage its conservation. Automatic detection of leakage through any of the outlets is notified to the user. We also measure the quality of water distributed to every household by deploying pH and ORP sensors. The traditional water metering systems require periodic manual intervention for both metering and maintenance making it inconvenient and often least effective. Shortcomings of the existing models call for a ubiquitous usage of wireless systems for smart water flow metering and quality monitoring. We propose to do this with the aid of CC2538 motes programmed using ContikiOS to monitor the water consumption and communicate the data to a gateway wirelessly.	collision detection;constrained application protocol;electronic billing;internet;mesh networking;prototype;real-time clock;requirement;sensor;smartwater;spectral leakage;stored-value card	S Anjana;N M. SahanaM.;S Ankith;K. Natarajan;K. R. Shobha;Arumugam Paventhan	2015	2015 IEEE International Conference on Advanced Networks and Telecommuncations Systems (ANTS)	10.1109/ANTS.2015.7413654	environmental engineering;engineering;computer security;automatic meter reading;computer network	Embedded	2.400860309120731	31.33365073860183	20352
0b28736a2cc69c18bbc2952f4aab61c47ec1dce5	on the one-sided crossing minimization in a bipartite graph with large degrees	minimisation;minimization;algoritmo aleatorizado;graphe biparti;approximate algorithm;grado grafo;graph drawing;grafo bipartido;approximation algorithm;minimizacion;algorithme randomise;68wxx;2 layered drawing;etirage graphe;informatique theorique;edge crossing;68r10;algoritmo aproximacion;borne inferieure;randomized algorithm;degre graphe;algorithme approximation;crossing number;bipartite graph;68w25;68w20;minimum degree;lower bound;graph degree;cota inferior;computer theory;informatica teorica	Given a bipartite graph G = (V, W, E), a 2-layered drawing consists of placing nodes in the first node set V on a straight line L1 and placing nodes in the second node set W on a parallel line L2. For a given ordering of nodes in W on L2, the one-sided crossing minimization problem asks to find an ordering of nodes in V on L1 so that the number of arc crossings is minimized. A well-known lower bound LB on the minimum number of crossings is obtained by summing up min{cuv, cvu} over all node pairs u, v ∈ V, where cuv denotes the number of crossings generated by arcs incident to u and v when u precedes v in an ordering. In this paper, we prove that there always exists a solution whose crossing number is at most (1.2964 + 12/(δ - 4))LB if the minimum degree δ of a node in V is at least 5.	crossing number (graph theory)	Hiroshi Nagamochi	2005	Theor. Comput. Sci.	10.1016/j.tcs.2004.10.042	minimisation;combinatorics;bipartite graph;mathematics;geometry;upper and lower bounds;graph drawing;randomized algorithm;crossing number;approximation algorithm;algorithm	ECom	22.425024335669608	27.34616457621943	20397
49c52de05df44471207a4ad8acd68a1102e9d647	narrowing power vs. efficiency in synchronous set agreement	crash failure;consensus;efficiency;synchronous system;t resilience;agreement problem;set agreement;lower bound;round based algorithm;consensus problem	The k-set agreement problem is a generalization of the uniform consensus problem: each process proposes a value, and each non-faulty process has to decide a value such that a decided value is a proposed value, and at most k different values are decided. It has been shown that any algorithm that solves the k-set agreement problem in synchronous systems that can suffer up to t crash failures requires ⌊t/k⌋ + 1 rounds in the worst case. It has also been shown that it is possible to design early deciding algorithms where no process decides and halts after min (⌊f/k⌋ + 2, ⌊t/k⌋ + 1) rounds, where f is the number of actual crashes in a run (0 ≤ f ≤ t).#R##N##R##N#This paper explores a new direction to solve the k-set agreement problem in a synchronous system. It considers that the system is enriched with base objects (denoted [m, l]-SA objects) that allow solving the l-set agreement problem in a set of mprocesses (m < n). The paper has several contributions. It first proposes a synchronous k-set agreement algorithm that benefits from such underlying base objects. This algorithm requires O(tl/mk ) rounds, more precisely, Rt = ⌊t/Δ⌋ + 1 rounds, where Δ = m⌊k/l⌋ + (k mod l). The paper then shows that this bound, that involves all the parameters that characterize both the problem (k) and its environment (t, m and l), is a lower bound. The proof of this lower bound sheds additional light on the deep connection between synchronous efficiency and asynchronous computability. Finally, the paper extends its investigation to the early deciding case. It presents a k-set agreement algorithm that directs the processes to decide and stop by round Rf = min ⌊f/Δ⌋ + 2, ⌊t/Δ⌋ + 1). These bounds generalize the bounds previously established for solving the k-set problem in pure synchronous systems.		Achour Mostéfaoui;Michel Raynal;Corentin Travers	2008		10.1007/978-3-540-77444-0_8	consensus;computer science;artificial intelligence;distributed computing;computer security;algorithm	Arch	5.822553386321151	25.652478288563934	20407
918671427d1ef12e8b3705b4b537a94aa95d480e	algorithms for multi-level graph planarity testing and layout	programacion entera;integer p;estiramiento;programmation en nombres entiers;etirage;level graph layout;programacion lineal;drawing;integer programming;informatique theorique;graphe planaire;vertex graph;68r10;graph layout;linear programming;programmation lineaire;level graphs;level planarity testing;grafo planario;vertice grafo;integer linear program;planar graph;sommet graphe;computer theory;informatica teorica	In this paper we consider the problems of testing a multi-level graph for planarity and laying out or, drawing, a multi-level graph in a clear way. We introduce a new abstraction of a common integer linear programming formulation of the problems that we call a vertex-exchange graph. We demonstrate how this concept can be used to solve the problems by providing clear and simple algorithms for testing a multi-level graph for planarity and laying out a multi-level graph when planar.	algorithm;planar graph;planarity testing	Patrick Healy;Ago Kuusik	2004	Theor. Comput. Sci.	10.1016/j.tcs.2004.02.033	outerplanar graph;factor-critical graph;combinatorics;discrete mathematics;integer programming;graph bandwidth;null graph;planarity testing;graph property;linear programming;clique-width;mathematics;voltage graph;distance-hereditary graph;graph;butterfly graph;quartic graph;complement graph;book embedding;drawing;algorithm;strength of a graph;planar graph	ECom	22.298444369783383	29.315752257365563	20446
11850796044c898c69dfa1a4afecfa3bea8634bb	on the computational complexity of infinite words	sequential machine;espacio;palabra infinita;complejidad espacio;problem;secuencial;language class;sequential;complexite calcul;mot infini;automate deterministe;sistema;lenguaje;machine sequentielle;langage;espace;68q05;probleme;maquina secuencial;infinite word;double and triple d0l tag systems;funcion logaritmica;sequentiel;complejidad computacion;logarithmic function;deterministic automaton;computational complexity;system;classe langage;automata determinista;theory;dgsm;fonction logarithmique;teoria;palabra;space complexity;68q15;infinite words;68q30;space;word;problema;systeme;language;complexite espace;theorie;mot;clase lenguaje	This paper contains answers to several problems in the theory of the computational complexity of infinite words. We show that the problem whether all infinite words generated by iterating dgsm’s have logarithmic space complexity is equivalent to the open problem asking whether the unary classes of languages in P and in DLOG are equivalent. Similarly, the problem to find a concrete infinite word which cannot be generated in logarithmic space is equivalent to the problem to find a concrete language which does not belong to DSPACE(n). Finally, we separate classes of infinite words generated by double and triple D0L TAG systems.	computational complexity theory;dspace;discrete logarithm;l (complexity);nl (complexity);omega language;tag system;unary operation	Pavol Duris;Ján Manuch	2003	Theor. Comput. Sci.	10.1016/S0304-3975(02)00400-0	logarithm;combinatorics;discrete mathematics;computer science;space;deterministic automaton;word;system;mathematics;language;dspace;computational complexity theory;theory;algorithm	Theory	-0.8038361992694788	19.582520646279416	20488
cee5b1c2955ed0a469494cba50bb665a1502294a	regular extended h systems are computationally universal	splicing;turing machines;descriptional complexity;h systems;dna computing;dna recombination		turing completeness	Gheorghe Paun	1996	Journal of Automata, Languages and Combinatorics	10.25596/jalc-1996-027	discrete mathematics;recombinant dna;computer science;turing machine;theoretical computer science;mathematics;rna splicing;dna computing;algorithm	Theory	1.5719356176866457	23.885855062901804	20493
7dea66fd343fb47696c7a3ab99024511079680d8	efficient approximation algorithms for tiling and packing problems with rectangles	base donnee;approximate algorithm;efficiency;approximation algorithm;packing;database;base dato;tiling;teoria decision;eficacia;theorie decision;decision theory;pavage;algoritmo aproximacion;efficacite;algorithme approximation;garnissage;relleno	We provide improved approximation algorithms for several rectangle tiling and packing problems RTILE DRTILE and d RPACK studied in the literature Most of our algorithms are highly e cient since their running times are near linear in the sparse input size rather than in the domain size In addition we improve the best known approximation ratios	approximation algorithm;information;set packing;sparse matrix;tiling window manager	Piotr Berman;Bhaskar DasGupta;S. Muthukrishnan;Suneeta Ramaswami	2001	J. Algorithms	10.1006/jagm.2001.1188	mathematical optimization;combinatorics;discrete mathematics;apx;decision theory;computer science;mathematics;efficiency;approximation algorithm;algorithm	Theory	17.62658877115085	25.782784874335725	20513
8f0e3389bfe470f6489ec825b4bd822ebe514e04	reactive power pricing based on ftr in the deregulated power market		Today, with the movement of power systems towards competition and breaking the monopoly, the importance of ancillary services like reactive power and voltage control has increased. One of the most important services is power reactive service. Independent System Operator (ISO)has to provide reactive power in deregulated environments which are considered one of the six ancillary services of power system which should be provided by the ISO to improve system security. ISO is responsible to provide reactive power in deregulated environments. Purpose of this paper is to present a method for pricing reactive power. In this method, reactive power pricing is performed based on Financial Transmission Rights (FTRs). The novelty of this study is that it has offered a new method for pricing reactive power based on FTR. Reactive power pricing methods presented so far have not considered congestion costs of the transmission system but this method considers congestions costs also through considering FTR. In this paper, results of this method are evaluated on a standard IEEE-30 bus test system and compared with current pricing method used for pricing reactive power in Iran.		Mahmood Hosseini Imani;Saeed Shahmiri;Kamran Yousefpour;Majid Taheri Andani	2018	IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2018.8591709		HPC	-0.7747466783559248	6.012793556614496	20525
1b90942a7661d956115716f33bd23deb4632266e	the string b-tree: a new data structure for string search in external memory and its applications	suffix array;suffix tree;prefix and range search;text index;external memory data structure;b tree;external memory;patricia trie;string searching and sorting;string matching;data structure;text indexing	We introduce a new text-indexing data structure, the String B-Tree, that can be seen as a link between some traditional external-memory and string-matching data structures. In a short phrase, it is a combination of B-trees and Patricia tries for internal-node indices that is made more effective by adding extra pointers to speed up search and update operations. Consequently, the String B-Tree overcomes the theoretical limitations of inverted files, B-trees, prefix B-trees, suffix arrays, compacted tries and suffix trees. String B-trees have the same worst-case performance as B-trees but they manage unbounded-length strings and perform much more powerful search operations such as the ones supported by suffix trees. String B-trees are also effective in main memory (RAM model) because they improve the online suffix tree search on a dynamic set of strings. They also can be successfully applied to database indexing and software duplication.	b-tree;best, worst and average case;computer data storage;data striping;data structure;empty string;experiment;floppy disk;inverted index;raid;random-access memory;range query (database);search algorithm;string (computer science);string searching algorithm;suffix array;suffix tree;tree (data structure)	Paolo Ferragina;Roberto Grossi	1999	J. ACM	10.1145/301970.301973	b-tree;generalized suffix tree;string interpolation;longest common substring problem;approximate string matching;commentz-walter algorithm;empty string;data structure;string;radix tree;string interning;computer science;substring;trie;theoretical computer science;boyer–moore string search algorithm;database;compressed suffix array;ternary search tree;programming language;scanf format string;string metric;algorithm;string searching algorithm	DB	11.636565118579615	28.25726592448471	20528
52712625ba8c1766394aa51b23ed8c9ed672bd65	on power of p systems using sequential and parallel rewriting	analyse sequentielle;machine turing;cooperation;generacion lenguaje;distributed computing;priorite;forma normal;sequential analysis;computationally universal;classical mechanics;turing machine;biology;biologia;rewriting p systems;cooperacion;parallel computation;cooperation and priorities;membranes of variable thickness;systeme p;calculo paralelo;rewriting systems;p system;normal form;external output;forme normale;generation langage;priority;prioridad;calcul parallele;analisis secuencial;systeme reecriture;maquina turing;biologie;language generation	A new class of distributed computing models inspired from biology, that of P Systems, was recently introduced by Gh. P[acaron]un. Several variants of P Systems were already shown to be computationally universal, equal in power to Turing Machines. We investigate in this paper the power of computability of P Systems based on rewriting, with cooperation, priorities and external output. It is established that rewriting P Systems with priorities and two membranes is computationally universal, thereby making an improvement in the existing result that RE⊆RP 3(Pri). We give a new model in P Systems stressing the importance of parallelism. The power of computability of such models is investigated by comparing them with classic mechanisms in L-Systems: TOL, EOL and ETOL Systems		Shankara Narayanan Krishna;Raghavan Rama	2001	Int. J. Comput. Math.	10.1080/00207160108805028	computer science;turing machine;theoretical computer science;sequential analysis;calculus;mathematics;programming language;cooperation;algorithm;p system	Logic	1.3778888446993152	24.667179774518498	20538
85ac2e9d0c9fd362eba760f9e6d1999a1b450316	worst case analysis of non-local games		Non-local games are studied in quantum information because they provide a simple way for proving the difference between the classical world and the quantum world. A non-local game is a cooperative game played by 2 or more players against a referee. The players cannot communicate but may share common random bits or a common quantum state. A referee sends an input xi to the i th player who then responds by sending an answer ai to the referee. The players win if the answers ai satisfy a condition that may depend on the inputs xi. Typically, non-local games are studied in a framework where the referee picks the inputs from a known probability distribution. We initiate the study of non-local games in a worst-case scenario when the referee’s probability distribution is unknown and study several non-local games in this scenario.	best, worst and average case;quantum information;quantum state;worst-case scenario	Andris Ambainis;Arturs Backurs;Kaspars Balodis;Agnis Skuskovniks;Juris Smotrovs;Madars Virza	2013		10.1007/978-3-642-35843-2_12	mathematics	Theory	8.694128281106048	25.09709961687772	20555
8fc4791fbd757a0bffc8633567be1320fb29125d	sensitivity analysis of reliability and performability measures for multiprocessor systems	performance measure;system reliability;system modeling;multiprocessor systems;mean time to failure;network performance;multistage interconnection network;indexing terms;markov model;sensitivity analysis;network model;memory systems;failure rate;markov reward model;markov chain	Traditional evaluation techniques for multiprocessor systems use Markov chains and Markov reward models to compute measures such as mean time to failure, reliability, performance, and performability. In this paper, we discuss the extension of Markov models to include parametric sensitivity analysis. Using such analysis, we can guide system optimization, identify parts of a system model sensitive to error, and find system reliability and performability bottlenecks. As an example we consider three models of a 16 processor. 16 memory system. A network provides communication between the processors and the memories. Two crossbar-network models and the Omega network are considered. For these models, we examine the sensitivity of the mean time to failure, unreliability, and performability to changes in component failure rates. We use the sensitivities to identify bottlenecks in the three system models.	central processing unit;crossbar switch;failure cause;markov chain;markov model;mathematical optimization;mean time between failures;multiprocessing;omega network;program optimization	James T. Blake;Andrew L. Reibman;Kishor S. Trivedi	1988		10.1145/55595.55616	markov chain;real-time computing;mean time between failures;systems modeling;index term;variable-order bayesian network;computer science;network model;failure rate;distributed computing;markov model;network performance;sensitivity analysis;statistics;variable-order markov model	Metrics	5.793016240535543	12.654861660488004	20574
37720d82f2c9a13e0dd7f8f61858ee954b61eff9	finding minimal unsatisfiable subformulae in satisfiability instances	arbre recherche;subformulae;algoritmo busqueda;sous formule;algorithme recherche;heuristic method;search algorithm;satisfiabilite;metodo heuristico;satisfiability;constraint satisfaction;satisfaction contrainte;arbol investigacion;automatic detection;methode heuristique;satisfaccion restriccion;resolubilite;search tree;solvability;resolubilidad	A minimal unsatisfiable subformula (MUS) of a given CNF is a set of clauses which is unsatisfiable, but becomes satisfiable as soon as we remove any of its clauses. In practical scenarios it is often useful to know, in addition to the unsolvability of an instance, which parts of the instance cause the unsolvability. An approach is here proposed to the problem of automatic detection of such a subformula, with the double aim of finding quickly a small-sized one. We make use of an adaptive technique in order to rapidly select an unsatisfiable subformula which is a good approximation of a MUS. Hard unsatisfiable instances can be reduced to remarkably smaller problems, and hence efficiently solved, through this approach.		Renato Bruni;Antonio Sassano	2000		10.1007/3-540-45349-0_37	mathematical optimization;combinatorics;discrete mathematics;constraint satisfaction;computer science;artificial intelligence;mathematics;search tree;programming language;algorithm;satisfiability;search algorithm	AI	10.976503498973287	17.241314496785947	20591
dcca2d44617368ce3465d69be22b0fafe58afd9a	on one-way cellular arrays	computers;digital computers;data transmission;computer program;reconocimiento lenguaje;general and miscellaneous mathematics computing and information science;reconnaissance langage;programming language;simulation 990210 supercomputers 1987 1989;complexite calcul;complejidad calculo;logique mathematique;real time;68q80;logica matematica;one way cellular array;computing complexity;mathematical logic;data transmission systems;language recognition;computer architecture;left to right;computational complexity;automate cellulaire;array processors;linear time;computerized simulation;68q45;68q15;one way iterative array;alternating turing machine;parallel languages;programming;cellular automaton;supercomputers;finite state machine;parallel processing;programming languages;automata celular;automation	There are two simple models of a parallel language recognizer: one-way cellular array (OCA) and one-way iterative array (OIA). For inputs of length n, both arrays consist of n identical finite-state machines (cells). The communication between cells is one way, from left to right. The difference in the two models is in the manner in which the input is applied. For the OCA, the input is applied to the cells in parallel. For the OIA, the input is applied serially to the leftmost processor. An input string is accepted if the rightmost cell eventually enters an accepting state. The authors show that OCA's accept exactly the same class of languages as OIA's. It is relatively easy to show that OIA's can simulate OCA's. The difficult part is the converse, i.e., that OCA's can simulate OIA's. This is rather surprising, since in an OIA, every cell of the array has access to each symbol of the input string, whereas in an OCA, the ith cell can only access the first i symbols of the input. This result, when combined with known results concerning OIA's, answers some open questions concerning the computational complexity of OCA's. They also prove some new results concerningmore » linear-time OCA's and OIA's. For example, they show: (a) linear-time OCA's are equivalent to 2n-time OIA's (note that 2n-time is optimal for OIA's); (2) the concatenation of a linear-time OCA language with a real-time (i.e. n-time) OCA language is a linear-time OCA language; (3) every bounded language accepted by a one-way multihead nondeterministic pushdown automation is a linear-time OCA language.« less		Oscar H. Ibarra;Tao Jiang	1987	SIAM J. Comput.	10.1137/0216072	cellular automaton;time complexity;parallel processing;programming;mathematical optimization;combinatorics;mathematical logic;alternating turing machine;computer science;theoretical computer science;automation;mathematics;programming language;computational complexity theory;algorithm;data transmission;algebra	Theory	-0.6432649439469311	25.565442991312057	20608
f8f95ea0939d6cc6529ea49449abbc91aac4b32e	2-c6: an fine-grained algorithm to achieve 2-consistency	constraint handling algorithm theory;constraint satisfaction problems filtering techniques consistency techniques;2 c3 coarse grained algorithm 2 c6 fine grained algorithm arc consistency algorithms csp constraint satisfaction problems propagation mechanisms coarse grained algorithm non normalized constraints empirical evaluations ac3 arc consistency algorithm ac6 arc consistency algorithm ac7 arc consistency algorithm;silicon compounds silicon electronic mail filtering conferences benchmark testing random access memory;algorithm theory;constraint handling	Most arc-consistency algorithms take for granted that CSPs are binary (all constraints involve two variables) and normalized (two different constraints do not involve exactly the same variables). When these algorithms perform pruning of values, propagation mechanisms are activated at both levels: value (fine-grained), and constraint (coarse-grained). Thus, values that might become inconsistent because of the pruning are re-checked to ensure their consistency. In this paper, we relax the assumption that the constraints are normalized and we work on problems with non-normalized constraints (there may be more than one constraint that involves the same two variables). In this type of problems, arc consistency techniques are not able to perform the same amount of pruning as 2-consistency techniques, unless a normalization process is performed previously. In this paper we propose the Algorithm 2-C6, which is a reformulation of AC6. The algorithm 2-C6 achieves 2-consistency and performs the finegrained propagations. In empirical evaluations, we compare the performance of the proposed algorithm 2-C6 with the following arc-consistency algorithms: AC3, AC6 and AC7 (coarse-grained and fine-grained, respectively) and with 2-C3, which is a 2-consistency coarse-grained algorithm. From these evaluations, we conclude that the 2-consistency techniques are more appropriated for this type of problem.	algorithm;fino;linear algebra;lo que tú quieras oír;local consistency;naruto shippuden: clash of ninja revolution 3;power-on reset;software propagation;unique name assumption	Marlene Arangú;Miguel A. Salido	2013	2013 XXXIX Latin American Computing Conference (CLEI)	10.1109/CLEI.2013.6670595	constraint logic programming;mathematical optimization;constraint programming;ac-3 algorithm;weighted majority algorithm;theoretical computer science;consistency model;mathematics;constraint satisfaction problem;algorithm;difference-map algorithm;hybrid algorithm;local consistency	AI	11.55975291603543	15.29305750253046	20622
9f19c99a8c1add88b670e487c4ed4650a949e27c	on the cardinality of the pareto set in bicriteria shortest path problems	shortest path;shortest paths;multi criteria optimization;travel time;pareto set;multi dimensional;optimality criteria;single source shortest path;pareto search;railway networks;pareto optimal solution;shortest path problem	Computing shortest paths with two or more conflicting optimization criteria is a fundamental problem in transportation and logistics. We study the problem of finding all Pareto-optimal solutions for the multi-criteria single-source shortest-path problem with nonnegative edge lengths. The standard approaches are generalizations of label-setting (Dijkstra) and label-correcting algorithms, in which the distance labels are multi-dimensional and more than one distance label is maintained for each node. The crucial parameter for the run time and space consumption is the total number of Pareto optima. In general, this value can be exponentially large in the input size. However, in various practical applications one can observe that the input data has certain characteristics, which may lead to a much smaller number—small enough to make the problem efficiently tractable from a practical viewpoint. For typical characteristics which occur in various applications we study in this paper whether we can bound the size of the Pareto set to a polynomial size or not. These characteristics are also evaluated (1) on a concrete application scenario (computing the set of best train connections in view of travel time, fare, and number of train changes) and (2) on a simplified randomized model. It will turn out that the number of Pareto optima on each visited node is restricted by a small constant in our concrete application, and that the size of the Pareto set is much smaller than our worst case bounds in the randomized model. Copyright Springer Science + Business Media, LLC 2006	pareto efficiency;shortest path problem	Matthias Müller-Hannemann;Karsten Weihe	2006	Annals OR	10.1007/s10479-006-0072-1	pareto analysis;mathematical optimization;bayesian efficiency;combinatorics;discrete mathematics;constrained shortest path first;euclidean shortest path;mathematics;shortest path problem;pareto interpolation;k shortest path routing	Theory	21.45899377310306	15.385195851221386	20716
24d4905f95d91caf4b99d095c899a75e721057be	on a two-stage birth and death queueing process	sistema fila espera;file attente;systeme attente;tiempo espera;population;probability;blocage;fertility measurements;tandem two infinite queues in tandem;loi probabilite;ley probabilidad;queuing system;statistical studies;processus depart;processus naissance mort;proceso llegada;series system;queue;bloqueo;demographic factors;blocking;arrival process;temps attente;processus arrivee;probability law;birth death arrivals and departures of birth death type;single server queue;time factors;proceso nacimiento muerte;research methodology;fila 1 servidor;mortality;studies;systeme serie;sistema serie;file 1 serveur;waiting time;queues birth death arrivals and departures of birth death type;birth rate;mathematical model;population dynamics;departure process;fertility;birth death process;queues tandem two infinite queues in tandem;death rate;fila espera;queues;theoretical models;proceso salida	A sequential two-stage service system with a single server at each stage and finite waiting space in both stages is considered. If the second stage is full, upon a service completion in stage 1, then the customer is unable to emerge from the first stage channel and this channel is blocked. An additional feature of the model is the provision of state-dependent arrival and service rates. The state probabilities pij and all moments of the waiting time of a customer in stage 1 and in the whole system are obtained. Finally, various characteristics of state-dependent tandem systems are evaluated and conclusions are drawn from numerical calculations.		Christos Langaris	1989	Operations Research	10.1287/opre.37.3.488	simulation;telecommunications;operations management;mathematics;population dynamics;queue;statistics	Theory	7.974467703486655	10.804375713088584	20735
6e6ba49ed5d56af69a6a50363d6bc24c4e51983a	time and parallelizability results for parity games with bounded treewidth	liverpool;repository;university	Parity games are a much researched class of games in NP ∩ CoNP that are not known to be in P. Consequently, researchers have considered specialised algorithms for the case where certain graph parameters are small. In this paper, we show that, if a tree decomposition is provided, then parity games with bounded treewidth can be solved in O(k · n · (d + 1)) time, where n, k, and d are the size, treewidth, and number of priorities in the parity game. This significantly improves over previously best algorithm, given by Obdržálek, which runs in O(n ·d2(k+1)2 ) time. Our techniques can also be adapted to show that the problem lies in the complexity class NC, which is the class of problems that can be efficiently parallelized. This is in stark contrast to the general parity game problem, which is known to be P-hard, and thus unlikely to be contained in NC.	algorithm;co-np;complexity class;nc (complexity);p (complexity);parallel computing;tree decomposition;treewidth	John Fearnley;Sven Schewe	2012		10.1007/978-3-642-31585-5_20	mathematical optimization;combinatorics;discrete mathematics;mathematics;algorithm	Theory	19.975418237396255	21.223263088015123	20748
7e00d54874b2c98388a72044df27a5c4887e7d26	complexity of finitely presented algebras	dynamic programming;exponential time;decomposition;optimal algorithms;word problem;satisfiability;principle of optimality;comparison algorithms;graph isomorphism;interaction complexity;polynomial time;nondeterministic algorithm;technical report;computer science;free algebra;nonserial dynamic programming;lower bound	An algebra <italic>A</italic> is finitely presented if there is a finite set G of generator symbols, a finite set O of operator symbols, and a finite set Γ of defining relations x&Xgr;y where x and y are well-formed terms over G and O, such that <italic>A</italic> is isomorphic to the free algebra on G and O modulo the congruence induced by Γ.  The uniform word problem, the finiteness problem, the triviality problem (whether <italic>A</italic> is the one element algebra), and the subalgebra membership problem (whether a given element of <italic>A</italic> is contained in a finitely generated subalgebra of <italic>A</italic>) for finitely presented algebras are shown to be ≤<supscrpt>m</supscrpt><subscrpt>log</subscrpt>-complete for P. The schema satisfiability problem and schema validity problem are shown to be ≤<supscrpt>m</supscrpt><subscrpt>log</subscrpt>-complete for NP and co-NP, respectively. Finally, the problem of isomorphism of finitely presented algebras is shown to be polynomial time many-one equivalent to the problem of graph isomorphism.	boolean satisfiability problem;co-np;congruence of squares;graph isomorphism;many-one reduction;modulo operation;polynomial;time complexity;well-formed formula	Dexter Kozen	1977		10.1145/800105.803406	word problem for groups;time complexity;free algebra;mathematical optimization;word problem;combinatorics;discrete mathematics;technical report;dynamic programming;mathematics;word problem;graph isomorphism;bellman equation;upper and lower bounds;decomposition;stallings theorem about ends of groups;nondeterministic algorithm;algorithm;algebra;satisfiability	Theory	6.414408329657791	19.603314583085886	20797
728ea61f9be3f3cb55d89a7e0ce1742b298da285	the regular viewpoint on pa-processes	parallel composition;generic model;verification of infinite state systems;tree automata;polynomial time;regular tree language;process algebra;word processing	To appear in Theoretical Computer Science The Regular Viewpoint on PA-Pro esses D. Lugiez Lab. d'Informatique de Marseille, Univ. Aix-Marseille & CNRS URA 1787, 39, r. Joliot-Curie, 13453 Marseille Cedex 13, FRANCE and Ph. S hnoebelen Lab. Spe i ation and Veri ation, ENS de Ca han & CNRS UMR 8643, 61 av. Pdt Wilson, 94235 Ca han Cedex, FRANCE Abstra t PA is the pro ess algebra allowing non-determinism, sequential and parallel ompositions, and re ursion. We suggest viewing PA-pro esses as trees, and using treeautomata te hniques for veri ation problems on PA. Our main result is that the set of iterated prede essors of a regular set of PApro esses is a regular tree language, and similarly for iterated su essors. Furthermore, the orresponding tree-automata an be built e e tively in polynomial-time. This has many immediate appli ations to veri ation problems for PA-pro esses, among whi h a simple and general modelhe king algorithm.	algorithm;automata theory;coded aperture;emoticon;han unification;iteration;regular tree grammar;solid modeling;theoretical computer science;time complexity;tree automaton;viewpoint	Denis Lugiez;Philippe Schnoebelen	2002	Theor. Comput. Sci.	10.1016/S0304-3975(00)00306-6	time complexity;combinatorics;process calculus;discrete mathematics;computer science;regular tree grammar;mathematics;programming language;algorithm;algebra	Theory	-2.302468471258097	21.652211816018802	20799
db962f756bc0c0f283ae98ca16fed69023264d3a	an efficient parallel strategy for the perfect domination problem on distance-hereditary graphs	graph theory;algoritmo paralelo;teoria grafo;distance hereditary graphs;parallel algorithm;subgrafo;temps lineaire;distributed computing;the perfect domination problem;supercomputer;tiempo lineal;theorie graphe;parallel random access machine;algorithme parallele;dominating set;supercomputador;parallel algorithms parallel random access machine pram;sous graphe;linear time;calculo repartido;conjunto dominando;subgraph;parallel random access machine pram;calcul reparti;superordinateur;ensemble dominant;distance hereditary graphs the perfect domination problem;parallel algorithms	A graph is distance-hereditary if the distance stays the same between any of two vertices in every connected induced subgraph containing both. Two well-known classes of graphs, trees and cographs, both belong to distance-hereditary graphs. In this paper, we first show that the perfect domination problem can be solved in sequential linear-time on distance-hereditary graphs. By sketching some regular property of the problem, we also show that it can be easily parallelized on distance-hereditary graphs.	cograph;dominating set;induced subgraph;parallel computing;time complexity	Sun-Yuan Hsieh	2006	The Journal of Supercomputing	10.1007/s11227-006-0003-6	strong perfect graph theorem;1-planar graph;pathwidth;split graph;supercomputer;parallel computing;cograph;independent set;graph product;longest path problem;computer science;graph theory;metric dimension;trivially perfect graph;permutation graph;clique-sum;trapezoid graph;distance-hereditary graph;distributed computing;parallel algorithm;maximal independent set;induced subgraph isomorphism problem;modular decomposition;partial k-tree;chordal graph;indifference graph;algorithm	Theory	18.950116807484008	28.56369105001824	20823
d4f805dfa89f3a6650d4ba4f19be6035f25ac1ad	an approximation guarantee of the greedy descent algorithm for minimizing a supermodular set function	approximate algorithm;fonction ensembles;algorithme glouton;approximation algorithm;heuristic method;metodo heuristico;greedy heuristic;programacion lineal;algoritmo aproximacion;linear programming;programmation lineaire;greedy algorithm;algoritmo gloton;methode heuristique;set function;p median problem;algorithme approximation;algorithme heuristique;heuristic algorithm;steepest descent	We consider the problem of minimizing a supermodular set function whose special case is the well-known NP-hard p-median problem. The main result of the paper is a tight bound on the approximation ratio of a greedy heuristic (discrete analog of the steepest descent algorithm) for this problem. ? 2001 Elsevier Science B.V. All rights reserved.	approximation algorithm;greedy algorithm;heuristic;np-hardness;stochastic gradient descent;supermodular function;whole earth 'lectronic link	Victor P. Il'ev	2001	Discrete Applied Mathematics	10.1016/S0166-218X(00)00366-8	greedy randomized adaptive search procedure;mathematical optimization;combinatorics;greedy algorithm;linear programming;mathematics;approximation algorithm;algorithm	Theory	21.73100337647492	13.401795363736612	20856
6d9193238b2e014c8b04266122224624fed8f948	the techniques of komolgorov and bardzin for three-dimensional orthogonal graph drawings	graph drawing;geometrie algorithmique;computational geometry;trace graphe;three dimensional;algorithme;graph algorithm;algorithms;graph algorithms			Peter Eades;Charles Stirk;Sue Whitesides	1996	Inf. Process. Lett.	10.1016/S0020-0190(96)00133-0	outerplanar graph;lattice graph;graph power;three-dimensional space;factor-critical graph;combinatorics;geometric graph theory;discrete mathematics;graph bandwidth;null graph;graph property;computational geometry;distance-regular graph;simplex graph;cubic graph;mathematics;voltage graph;geometry;graph;graph drawing;butterfly graph;crossing number;quartic graph;line graph;algorithm;coxeter graph	DB	23.800350178417727	29.353573054878996	20910
afb25c7579fa56e5dc03f6bc05723b01f415f5e1	path partitions of almost regular graphs	path partition;bepress selected works;path partition paths partition path partition number;partition;paths;path partition number	The path partition number of a graph is the minimum number of paths required to partition the vertices. We consider upper bounds on the path partition number under minimum and maximum degree assumptions.		Colton Magnant;Hua Wang;Shuai Yuan	2016	Australasian J. Combinatorics		partition refinement;longest path problem;graph partition;frequency partition of a graph	Theory	24.30879956147857	26.98345994593967	21013
8ca5a49672d5dd18d623baf4d3c22f900f24bd04	on binary searching with non-uniform costs	edge coloring;edge dominating set;coloring;search strategy;clique width;suffix array;dominating set;text database;approximate solution;indexation;linear time;search cost;binary search;polynomial algorithms;linear space	Let us consider an ordered vector A[1 : n]. If the cost of testing each position is similar, then the standard binary search is the best strategy to search the vector. This is true in both average and worst case. However, if the costs are non-uniform, then the best strategy is not necessarily the standard binary search. The best algorithm to construct a strategy that minimizes the expected search cost runs in &Ogr;(n3) time and requires &Ogr;(n2) space. The same complexities hold for the best algorithm to construct a strategy that minimizes the worst case search cost. Here, we show how to efficiently construct search strategies that are at most at a constant factor from the optimal one. These constructions take linear time and use only linear space. For the problem of minimizing the expected search cost, we present an algorithm that requires &Ogr;(n) space and gives a (2 + ∈ + &Ogr;(1))-approximated solution in &Ogr;(n) time, for any fixed value of ∈ > 0. On the other hand, for the problem of minimizing the worst case search cost, we describe an algorithm that requires &Ogr;(n) space and gives a (2 + ∈ + &Ogr;(1))- approximated solution in &Ogr;(n) time, for any fixed value of ∈ > 0. These two problems arise when processing a query in a distributed text database indexed by a suffix array.	approximation algorithm;best practice;best, worst and average case;binary search algorithm;regular expression;suffix array;time complexity;tree traversal	Eduardo Sany Laber;Ruy Luiz Milidiú;Artur Alves Pessoa	2001			linear search;interpolation search;beam search;time complexity;mathematical optimization;combinatorics;discrete mathematics;dominating set;clique-width;edge coloring;search cost;jump search;mathematics;linear space;exponential search;binary search algorithm	Theory	14.37986898890183	27.776818801545318	21016
dc5e088a097220899b3345bebf526e15d6be8da7	parallel communicating pushdown automata with filters in communication			deterministic pushdown automaton;stack (abstract data type)	M. Sakthi Balan	2001			nested word;discrete mathematics;embedded pushdown automaton;theoretical computer science;deterministic pushdown automaton;pushdown automaton;mathematics	Theory	-2.761439770694762	21.911138645090055	21042
1639d0d533b00cacd4fec9085f9ba1d6ccd81eba	percolation of localized attack on complex networks		The robustness of complex networks against node failure andmalicious attack has been of interest for decades, whilemost of the research has focused on randomattack or hub-targeted attack. Inmany real-world scenarios, however, attacks are neither randomnor hub-targeted, but localized, where a group of neighboring nodes in a network are attacked and fail. In this paper we develop a percolation framework to analytically and numerically study the robustness of complex networks against such localized attack. In particular, we investigate this robustness in Erdős–Rényi networks, random-regular networks, and scale-free networks. Our results provide insight into how to better protect networks, enhance cybersecurity, and facilitate the design ofmore robust infrastructures. The functioning of complex networks such as the internet, airline routes, and social networks is crucially dependent upon the interconnections between network nodes. These interconnections are such thatwhen some nodes in the network fail, others connected through them to the networkwill also be disabled and the entire networkmay collapse. In order to understand network robustness and design resilient complex systems, one needs to knowwhether a complex network can continue to function after a fraction of its nodes have been removed either through node failure ormalicious attack [1–21]. This question is dealt within percolation theory [21–24] inwhich the percolation phase transition occurs at some critical occupation probability pc. Above pc, a giant component, defined as a cluster whose size is proportional to that of the entire network, exists; below pc the giant component is absent and the entire network collapses. Only nodes in the giant component continue to function after the node-removal process. The robustness of complex networks under attack is dependent upon the structure of the underlying network and the nature of the attack. Previous research has focused on two types of initial attack: randomattack and hub-targeted attack. In a randomattack each node in the network is attackedwith the same probability [1– 3, 8, 10, 21]. In a hub-targeted attack the probability that high-degree nodes will be attacked is higher than that for low-degree nodes [1, 3, 4, 7, 12]. An important feature of the network structure is its degree distribution,P(k), which describes the probability that a node has a specific degree k. Networkswithdifferent degree distributions behave very differently under different types of attack. For instance, the internet,which shows a power lawdegree distribution, is extremely robust against randomattack but vulnerable to hub-targeted attack [1, 4]. However these two types of attack—random attack and hub-targeted attack—do not adequately describe many real-world scenarios inwhich complex networks suffer fromdamage that is localized, i.e., a node is affected, then its neighbors, and then their neighbors, and so on (seefigure 1). Examples include the effects of earthquakes,floods, ormilitary attacks on infrastructure networks and the effects of a computer virus or malware on computer networks. Recent occurrences of the latter include attacks carried out by cybercriminals who create a ‘botnet’, a cluster of neighboring ‘zombie computers’ in a computer network and, by using them, are able to damage the entire network. An understanding of the effect of this kind of attack on the functioning of a network is still lacking. Here wewill analyze the robustness of complex networks sustaining this kind of localized attack in order to determine howmuch damage a network can sustain before it collapses, i.e., tofind the percolation threshold pc. OPEN ACCESS	botnet;complex network;complex systems;computer cluster;computer security;computer virus;degree distribution;erdős number;erdős–rényi model;giant component;internet;malware;numerical analysis;percolation theory;percolation threshold;robustness of complex networks;social network;usb hub	Shuai Shao;Xuqing Huang;Harry Eugene Stanley;Shlomo Havlin	2014	CoRR	10.1088/1367-2630/17/2/023049	interdependent networks	Security	-3.612461109035967	6.413682238600462	21063
6f5ca0303056ade028d79005fcde10a9403db2da	neuro-fuzzy models of thermoelectric power station installations	energy conservation;hydroelectric power stations;fuzzy neural nets;thermal power stations energy conservation fuzzy neural nets fuzzy reasoning heat systems hydroelectric power stations power engineering computing power generation economics power plants;fuzzy reasoning;heat production cost reduction;soft computing;power efficiency;power production cost reduction;cost reduction;soft computing theory;fuel consumption;neuro fuzzy model;power plant;power engineering computing;power plants;fuel consumption reduction;neuro fuzzy;combined heat and power;heat systems;normal operator;heat plant;thermal power stations;heat production cost reduction neuro fuzzy model thermoelectric power station installation soft computing theory heat plant power plant fuel consumption reduction power efficiency energy services power production cost reduction;heat production;thermoelectric power station installation;thermoelectricity power generation boilers cogeneration feeds fires water heating fuels turbines gases;scientific research;power generation economics;thermoelectric power;energy services	Taking into account the technical and economical problems with which the combined heat and power plants are confronted, after the reorganization of this domain in Romania, in order to improve the normal operation with small-efficiency when these centralized units are maintained in function, the paper proposes the implementation of a modeling method based on the soft computing theory. The main objective of the research team is in connection with the improvement of the performance and competitive of a combined heat and power plant total activity, through the fuel consumption reduction, the power efficiency increase and guaranteeing the supply with energy services by means of measures relating to the offer and demand, the power and heat production cost reduction. With that end in view the scientific research is focused on the theoretical and practical implementation of new hybrid neuro-fuzzy method to model the technological processes from a combined heat and power plant	adaptive neuro fuzzy inference system;central pattern generator;centralized computing;council for educational technology;mathematical optimization;neuro-fuzzy;performance per watt;soft computing;steam;test set	Lucian Mastacan;Iosif Olah;Catalin Constantin Dosoftei;Dorin Ivana	2005	International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)	10.1109/CIMCA.2005.1631378	power station;computer science;soft computing	Robotics	1.360986792406633	6.205925608608647	21117
598ac5b5622647897bdfb06e440ac5643c36cc8b	the power of parallel pointer manipulation	parallel pointer manipulation	An HMM is a very simple parallel machine consisting of finite s tate devices that can manipulate pointers to each other. The more commonly studied P R A M is a much richer parallel machine with a shared global memory and ar i thmetic capabilities. We define a natural restriction of the P R A M that is shown to be equivalent to the HMM to within a constant factor in bo th t ime and hardware simultaneously. Basically, the restricted PRAM is a Concurrent Read, Owner Write (CROW) PRAM, stripped of ar i thmetic capabilities, except for successor (+1) a doubling (x2) operations. 1 I n t r o d u c t i o n and S u m m a r y of R e s u l t s Many sequential Mgorithms spend the bulk of their t ime doing pointer manipula t ion, as opposed to, say, ar i thmetic operations. The Storage Modification Machine (SMM) or Pointer Machine is a formal model that captures the notion of computat ion by pointer manipulat ion. Considerable in*Part of this research performed while the second author visited the EECS Department, UC San Diego, whose hospitality is gratefully acknowledged, as is the financiM support provided to the first author by an IBM Graduate Fellowship, and to both authors by NSF grants ECS-8306622, and CCR-8703196. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of ~he Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. © 1989 ACM 0-89791-323-X/89 /0006 /0092 $1.50 tui t ion for the power of such machines is provided by Schhnhage's demonst ra t ion of the equivalence of SMM's and unit-cost successor RAM's, i.e. ordinary unit cost RAM's str ipped of all arithmetic capabilities except for the successor, or +1 operation [16]. (See also [17, 9, 8, 12, 1].) Various kinds of parallel random access machines or PRAM's are popular and convenient as models of parallel computers. PRAM's consist of a col lection of ordinary sequential RAM's with shared access to a common global memory. Like their sequential counterparts , many PRAM algorithms spend a considerable proport ion of their t ime manipulat ing pointers in global memory, indeed~ since interprocessor communicat ion is so fundamental to most parallel algorithms, pointer manipulation in PRAM's may be even more pervasive than in RAM's. The notion of parMlel computat ion by pointer manipula t ion is formally captured by the Hardware Modification Machine (HMM), introduced by Cook and studied by Dymond and Cook [2, 3, 6]. In this paper we prove tile equivalence of HMM's and a restricted version of the PRAM, which is s tr ipped of ar i thmetic capabilities except for the successor (+1) and doubling (x2) operations, and which observes a certMn very naturM restriction on writes to global memory, the turnerwrite restriction, deta~iled below. Our simulations show that both t ime and hardware resources of the two models, simultaneously, are the same to within a constant factor. This is an unusually tight correspondence between two parallel models. Indeed, we are aware of no other similarly t ight correspondence between parallel models that are more than	call of duty: black ops;computer science;database engine tuning advisor;formal language;hidden markov model;ibm notes;like button;parallel algorithm;parallel computing;parallel random-access machine;period-doubling bifurcation;pointer (computer programming);pointer machine;random access;random-access memory;simulation;turing completeness;uc browser	Tak Wah Lam;Walter L. Ruzzo	1989		10.1145/72935.72946	escape analysis	Theory	8.158420964433596	27.093797785784822	21132
7f4303596df9958d6a7b64a6fd0aa5da2ff35c84	real-time matching of local generation and demand: the use of high resolution load modeling	energy resolution;wind turbines;indexes;batteries;load management;load modeling;buildings	In most studies, the lowest temporal resolution data used in addressing the problem of matching local generation and demand is hourly. There are very few attempts that use minute level temporal resolution capturing the highly stochastic nature. This study utilizes high-resolution household load modelling platform called Suricatta to assess the potential for matching in real-time. In this study, 1-minute and 1-hour resolutions data is used to evaluate load matching index of PVs and wind turbines along with storage battery and demand response solutions. The results demonstrate the relatively high relevance of 1-minute data resolution in case of demand response planning and also for wind turbine generations. Besides, the diurnal nature of weather variables together with their negative correlation to the typical Finnish household seasonal consumption emphasizes the need for storage systems and/or demand response plans to enhance matching of distribution system level wind turbine and PV generations.	image resolution;linear matrix inequality;log management;page view;real-time clock;real-time transcription;rechargeable battery;relevance;simulation	Merkebu Z. Degefa;Matti Lehtonen;Malcolm McCulloch;Ken Nixon	2016	2016 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)	10.1109/ISGTEurope.2016.7856186	simulation;load balancing;engineering;operations management;forensic engineering	Robotics	3.2272944387930123	6.433349934034432	21141
680963d6fd3af1d0693c3c8764a0a8202641d450	fast approximation algorithms for bi-criteria scheduling with machine assignment costs	total completion time;maximum machine cost;makespan;bi criteria scheduling;期刊论文;heuristics;article;total machine cost	We consider parallel machine scheduling problems where the processing of the jobs on the machines involves two types of objectives. The first type is one of two classical objective functions in scheduling theory: either the total completion time or the makespan. The second type involves an actual cost associated with the processing of a specific job on a given machine; each job-machine combination may have a different cost. Two bi-criteria scheduling problems are considered: (1) minimize the maximum machine cost subject to the total completion time being at its minimum, and (2) minimize the total machine cost subject to the makespan being at its minimum. Since both problems are strongly NP-hard, we propose fast heuristics and establish their worst-case performance bounds.	approximation algorithm;best, worst and average case;dummy variable (statistics);hall-effect thruster;heuristic (computer science);job shop scheduling;job stream;makespan;memory management controller;network service provider;polynomial;rank (graph theory);schedule (computer science);scheduling (computing);shortest path problem;time complexity;traffic message channel	Kangbok Lee;Joseph Y.-T. Leung;Zhao-Hong Jia;Wenhua Li;Michael Pinedo;Bertrand M. T. Lin	2014	European Journal of Operational Research	10.1016/j.ejor.2014.03.026	job shop scheduling;mathematical optimization;real-time computing;computer science;operations management;heuristics;mathematics	ECom	15.44101899937514	9.852454157348534	21183
3646cfa97a79b9234f848d526db8ad857721c663	an effective neighborhood search algorithm for scheduling a flow shop of batch processing machines	batch processing machines;flow shop scheduling;journal;permutation;neighborhood search	This paper considers scheduling problem of flow shop with many batch processing machines and objective of maximum lateness. An effective neighborhood search algorithm (NSA) is proposed for the problem, in which a job permutation and a batch permutation are used to indicate the solution of two sub-problems, respectively. Each job permutation consists of several family-permutations for the representation of jobs from the same family. Two swaps are applied to two permutations to produce new solutions. NSA is applied to a number of instances and compared with some methods, and computational results validate the good performance of NSA.	batch processing;scheduling (computing);search algorithm	Deming Lei;Tao Wang	2011	Computers & Industrial Engineering	10.1016/j.cie.2011.05.005	mathematical optimization;flow shop scheduling;computer science;operations management;job scheduler;machine learning;mathematics;distributed computing;permutation	AI	16.33783722245036	7.921279916847863	21195
563ac996ce3ec0173f9e8830eab44337bac2a062	passes and paths of attributive grammars	time complexity;top down;dependence graph;attribute grammar;left to right;polynomial time	An attribute grammar is pure (left-to-right) multi-pass if a bounded number of left-to-right passes over the derivation tree suffice to compute all its attributes. There is no requirement, as for the usual multi-pass attribute grammars, that all occurrences of the same attribute are computed in the same pass, R is shown that the problem of determining whether an arbitrary attribute grammar is pure multipass, is of inherently exponential time complexity, For fixed k > 0, it can be decided in polynomial time whether an attribute grammar is pure k-pass. The proofs are based on a characterization of pure multi-pass attribute grammars in terms of paths through their dependency graphs. A general result on dependency paths of attribute grammars relates them to (finite-copying) top-down tree transducers. The formal power of k-pass attribute grammars increases with increasing k. Formally, multi-pass attribute grammars are less powerful than arbitrary attribute grammars.	attribute grammar;parse tree;polynomial;time complexity;top-down and bottom-up design;transducer	Joost Engelfriet;Gilberto Filé	1981	Information and Control	10.1016/S0019-9958(81)90466-6	context-sensitive grammar;time complexity;tree-adjoining grammar;discrete mathematics;l-attributed grammar;attribute domain;computer science;machine learning;s-attributed grammar;mathematics;context-free grammar;attribute grammar;algorithm	PL	-4.456791664849812	21.124407493196657	21232
aa565b552a33ed9c4312ae27f74e0eefff213fdd	compact navigation and distance oracles for graphs with small treewidth	graph decomposition;treewidth;navigation oracles;distance oracles	Given an unlabeled, unweighted, and undirected graph with n vertices and small (but not necessarily constant) treewidth k, we consider the problem of preprocessing the graph to build space-efficient encodings (oracles) to perform various queries efficiently. We assume the word RAM model where the size of a word is Ω(logn) bits. The first oracle, we present, is the navigation oracle which facilitates primitive navigation operations of adjacency, neighborhood, and degree queries. By way of an enumeration argument, which is of interest in its own right, we show the space requirement of the oracle is optimal to within lower order terms for all graphs with n vertices and treewidth k. The oracle supports the mentioned queries all in constant worst-case time. The second oracle, we present, is an exact distance oracle which facilitates distance queries between any pair of vertices (i.e., an all-pairs shortest-path oracle). The space requirement of the oracle is also optimal to within lower order terms. Moreover, the distance queries perform in O(k 3log3 k) time. Particularly, for the class of graphs of popular interest, graphs of bounded treewidth (where k is constant), the distances are reported in constant worst-case time.	best, worst and average case;distance oracle;graph (discrete mathematics);oracle machine;preprocessor;requirement;shortest path problem;time complexity;treewidth;vertex (geometry)	Arash Farzan;Shahin Kamali	2012	Algorithmica	10.1007/s00453-012-9712-9	combinatorics;discrete mathematics;mathematics;tree-depth;partial k-tree;algorithm	Theory	19.664063632554456	23.60232033638228	21280
78ce48680b681c4eb6c6612d2f767c252fc1da67	product form and local balance in queueing networks	queueing network;differentiated service;satisfiability;distribution function	A new property of queueing discipline, station balance, seems to explain why some disciplines yield product form solutions for queues and networks using nonexponential service disciplines and other disciplines do not. A queueing discipline satisfies station balance if rates at which customers receive service at each position of the queue are proportional to the probability that a customer arrives at that position. Station and local balance in queues and networks of queues are investigated. In addition to characterizing local balance and product form, the results of the paper generalize previous results on local balance to arbitrary differentiable service distribution functions.	active queue management;network scheduler	K. Mani Chandy;John H. Howard;Donald F. Towsley	1976		10.1145/322003.322009	g-network;mean value analysis;real-time computing;simulation;differentiated service;distribution function;layered queueing network;fork–join queue;satisfiability	Metrics	8.483549773765244	10.872971593992427	21291
5d4a02328a33224864e23de1bee9c63796e8ff95	an improved approximation algorithm for the complementary maximal strip recovery problem	approximation algorithm;re weighting scheme;maximal strip recovery;local amortized analysis	Given two genomic maps G1 and G2 each represented as a sequence of n gene markers, the maximal strip recovery (MSR) problem is to retain the maximum number of markers in both G1 and G2 such that the resultant subsequences, denoted as G ∗ 1 and G ∗ 2, can be partitioned into the same set of maximal strips, which are common substrings of length greater than or equal to two. The complementary maximal strip recovery (CMSR) problem has the complementary goal to delete the minimum number of markers. Both MSR and CMSR have been shown NP-hard and APX-complete, and they admit a 4-approximation and a 3-approximation respectively. In this paper, we present an improved 7 3 -approximation algorithm for the CMSR problem, with its worst-case performance analysis done through a sequential amortization.	apx;amortized analysis;approximation algorithm;best, worst and average case;greedy algorithm;map;maximal set;profiling (computer programming);resultant;strips;substring;z1 (computer);z2 (computer);z3 (computer)	Guohui Lin;Randy Goebel;Zhongqiao Li;Lusheng Wang	2012	J. Comput. Syst. Sci.	10.1016/j.jcss.2011.10.014	mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;approximation algorithm	Theory	15.732636037615132	24.431868281136776	21450
20132cf60827573c65a5128661b562a30724a22e	new results on computability of recurrence equations	turing machines;computability;system of affine recurrence equations;parametrized recurrent systems;systems of uniform recurrence equations;unbounded domains	Systems of uniform recurrence equations were proposed by Karp et al. as a mean of automatically deriving programs for parallel architectures. Extensions of this formalism are used by many authors in systolic array synthesis. The computability of a system of recurrence equations is therefore of primary importance, and is considered as the first point to be examined when trying to implement an algorithm. This paper investigates the computability of recurrence equations and especially new results obtained in this area. We first recall the definitions of computability proposed by Karp et al., Rao, Joinnault and Saouter et al. Then we correct and generalize those results. Finally, we give a new original proof for the undecidability of computability of non-uniform, non-conditional systems of recurrence equations.	computability;rabin–karp algorithm;recurrence relation;semantics (computer science);systolic array	Hervé Le Verge;Yannick Saouter	1998	Int. J. Found. Comput. Sci.	10.1142/S0129054198000179	combinatorics;discrete mathematics;effective method;computer science;turing machine;computability logic;mathematics;computability;algorithm	AI	-3.3650251105828124	25.711673933104137	21479
be08bd08b37a07fe272e56963c3e57a7f9128794	an improved estimation of the rsa quantum breaking success rate	number theory;quantum computation;factorization;quantum computer;random parameters;linear time;success rate;success factor;rsa cryptosystem;point of view;numerical simulation	The security of RSA cryptosystem is based on the assump- tion that factorization is a difficult problem from the number theoretic point of view. But that statement does not hold with regard to quan- tum computers where massive parallelization of computations leads to qualitative speedup. The Shor's quantum factorization algorithm is one the most famous algorithms ever proposed. That algorithm has linear time complexity but is of probabilistic nature. It succeeds only when some random parameter fed at algorithm input has desired properties. It is well known that such parameters are found with probability not less than 1/2. However, the described in the paper numerical simulations prove that probability of such event exhibits grouping at some discrete levels above that limit. Thus, one may conclude that usage of the common bound leads to underestimation of the successful factorization probability. Em- pirical formulas on expected success probability introduced in the paper give rise to the more profound analysis of the Shor's algorithm classic part behaviour. The observed grouping still awaits for explanations based on number theory.	quantum	Piotr Zawadzki	2010		10.1007/978-3-642-14292-5_25	number theory;computer science;artificial intelligence;integer factorization;theoretical computer science;machine learning;quantum computer;computer security;statistics	Crypto	7.213238419896278	26.03921374023643	21507
6bd365ced18bbecca44e32e6823441b266227c77	bounds for online bin packing with cardinality constraints		We study a bin packing problem in which a bin can contain at most k items of total size at most 1, where k ≥ 2 is a given parameter. Items are presented one by one in an online fashion. We analyze the best absolute competitive ratio of the problem and prove tight bounds of 2 for any k ≥ 4. Additionally, we present bounds for relatively small values of k with respect to the asymptotic competitive ratio and the absolute competitive ratio. In particular, we provide tight bounds on the absolute competitive ratio of First Fit for k = 2, 3, 4, and improve the known lower bounds on asymptotic competitive ratios for multiple values of k. Our method for obtaining a lower bound on the asymptotic competitive ratio using a certain type of an input is general, and we also use it to obtain an alternative proof of the known lower bound on the asymptotic competitive ratio of standard online bin packing.	bin packing problem;cardinality (data modeling);competitive analysis (online algorithm);set packing	József Békési;György Dósa;Leah Epstein	2016	Inf. Comput.	10.1016/j.ic.2016.06.001	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	17.428518244534406	15.375689019402236	21518
607b898910d2974e1e1cf5dd5a2c2d11671eba16	on some variants of post's correspondence problem	index words;correspondence problem;infinite word;formal language;langage formel	A variant of Post's Correspondence Problem is considered where two different index words are allowed provided that one of them can be obtained from the other by permuting a fixed number of subwords. It is shown that this variant is undecidable. Post's Correspondence Problem is also extended to circular words, doubly infinite words and doubly infinite powers of words, and shown to be undecidable in all these extensions.	post correspondence problem;undecidable problem	Keijo Ruohonen	1983	Acta Informatica	10.1007/BF00290732	combinatorics;formal language;discrete mathematics;computer science;post correspondence problem;mathematics;correspondence problem;algorithm;combinatorics on words	Theory	-1.8576473567970024	19.280096087182088	21531
9a65ac07a5e2ff4f1ec58efad970dfb89aa7dd75	scheduling unit length jobs on parallel machines with lookahead information	multipurpose machine scheduling;online algorithms;lookahead information;stochastic dynamic programming;eligibility constraint	This paper studies two closely related online-list scheduling problems of a set of n jobs with unit processing times on a set of m multipurpose machines. It is assumed that there are k different job types, where each job type can be processed on a unique subset of machines. In the classical definition of online-list scheduling, the scheduler has all the information about the next job to be scheduled in the list while there is uncertainty about all the other jobs in the list not yet scheduled. We extend this classical definition to include lookahead abilities, i.e., at each decision point, in addition to the information about the next job in the list, the scheduler has all the information about the next h jobs beyond the current one in the list. We show that for the problem of minimizing the makespan there exists an optimal (1-competitive) algorithm for the online problem when there are two job types. That is, the online algorithm gives the same minimal makespan as the optimal offline algorithm for any instance of the problem. Furthermore, we show that for more than two job types no such online algorithm exists. We also develop several dynamic programming algorithms to solve a stochastic version of the problem, where the probability distribution of the job types is known and the objective is to minimize the expected makespan.	best, worst and average case;competitive analysis (online algorithm);dynamic programming;eisenstein's criterion;job stream;list scheduling;makespan;online algorithm;online and offline;parsing;programming paradigm;rendering (computer graphics);robotics;scheduling (computing);stochastic process;stochastic programming	Marvin Mandelbaum;Dvir Shabtay	2011	J. Scheduling	10.1007/s10951-010-0192-y	stochastic programming;job shop scheduling;online algorithm;mathematical optimization;real-time computing;computer science;job scheduler;job stream;mathematics;distributed computing;job queue	Theory	15.251339887689024	10.9127766192978	21562
f434e71bf38ec2cbe641f19d74244f22720bce54	beating brute force for polynomial identity testing of general depth-3 circuits		Let C be a depth-3 ΣΠΣ arithmetic circuit of size s, computing a polynomial f ∈ F[x1, . . . , xn] (where F = Q or C) with fan-in of product gates bounded by d. We give a deterministic time 2 poly(n, s) polynomial identity testing algorithm to check whether f ≡ 0 or not. In the case of finite fields, for Char(F) > d we obtain a deterministic algorithm of running time 2γ·d poly(n, s), whereas for Char(F) ≤ d, we obtain a deterministic algorithm of running time 2(γ+2)·d log d poly(n, s) where γ ≤ 5.	arithmetic circuit complexity;brute force;dtime;deterministic algorithm;fan-in;polynomial identity testing;time complexity	Vikraman Arvind;Abhranil Chatterjee;Rajit Datta;Partha Mukhopadhyay	2018	Electronic Colloquium on Computational Complexity (ECCC)		discrete mathematics;combinatorics;electronic circuit;polynomial identity testing;mathematics;beat (acoustics)	Theory	10.152857211027849	22.52525168283001	21575
074a7f3a0f34b724781451cfc5b30c1f76ff4034	a smart neighbourhood simulation tool for shared energy storage and exchange		Funding policies and legislation by the European Union for the installation of photovoltaic (PV) arrays in the residential sector have led to a steady and successful increase in renewable energy generation by small-scale private producers. In Germany, even the installation of local storage systems is being subsidised. Differing feed-in tariffs, as well as variable production and demand profiles result in very dissimilar amortisation curves for such investments. This paper presents a software tool which allows for the computation of such curves by means of simulation in MATLAB/Simulink. It enables the exploration of a wide search space by manipulating settings on the levels of individual houses, as well as entire neighbourhoods which might want to share in (the cost of) local energy storage. Additionally, a case study underlines the tool’s potential, as well as benefits of shared energy storage systems.	simulation	Michael Biech;Timo Bigdon;Christian Dielitz;Georg Fromme;Anne Remke	2016		10.1007/978-3-319-43904-4_6	embedded system;simulation;computer hardware	Logic	2.9124537593993374	7.217517326785503	21593
800c49b9f6f8af49cb411668498156c909769c5d	optimal extraction of motif patterns in 2d	alphabet binaire;design of algorithms;procesamiento informacion;algorithm analysis;05bxx;2d motifs;extraction forme;space time;espacio tiempo;68wxx;input;red;pattern discovery;conception algorithme;extraccion forma;explosion combinatoire;informatique theorique;reseau arrangement;information processing;entree ordinateur;basis extraction;array;analyse algorithme;entrada ordenador;traitement information;algoritmo optimo;algorithme optimal;optimal algorithm;irredundant motifs;pattern extraction;analisis algoritmo;espace temps;computer theory;informatica teorica	The combinatorial explosion of motif patterns occurring in 1D and 2D arrays leads to the consideration of special classes of motifs growing linearly with the size of the input array. Such motifs, called irredundant motifs, are able to succinctly represent all of the other motifs occurring in the same array within reasonable time and space bounds. In previous work irredundant motifs were extracted from 2D arrays in O(N2 log n log log n) and O(N3) time, where N is the size of the 2D input array and n is its largest dimension. In this paper, we present an algorithm to extract irredundant motifs from 2D arrays that is quadratic in the size of the input. The input is defined on a binary alphabet. It is shown that the algorithm is optimal and practically faster than the previous ones.	algorithm;sequence motif	Simona E. Rombo	2009	Inf. Process. Lett.	10.1016/j.ipl.2009.06.007	information processing;computer science;artificial intelligence;space time;mathematics;algorithm	Theory	15.357087441186176	26.151039711624517	21611
325a73ba93a347fef2c55d1347a8cc6747b1ad7f	a characterization of the rau class of sequential problems	characterization;functional equations;rau class;search theory	Rau (Rau, J. G. 1971. Minimizing a function of permutations of n integers. Oper. Res. 19 237–240.) presents a class of sequential problems including two important special cases from the search literature. Rau's class is presented there in terms of conditions that certain functions must satisfy. Here those conditions are reformulated to show what Rau's restrictions imply. A subclass of Rau's class is discussed that contains both of the important special cases, and which was used for further analysis in the paper of Kadane and Simon (Kadane, J. B., H. A. Simon. 1977. Optimal strategies for a class of constrained sequential problems. Ann. Statist. 5 237–255.).		Joseph B. Kadane	1978	Math. Oper. Res.	10.1287/moor.3.1.42	search theory;functional equation;mathematical optimization;discrete mathematics;mathematics;algorithm	Theory	20.01056825469338	13.063174968030166	21615
0cbc0acd31aab4119bab974b17dd9a0f2561b444	a practical fpt algorithm for flow decomposition and transcript assembly		The Flow Decomposition problem, which asks for the smallest set of weighted paths that “covers” a flow on a DAG, has recently been used as an important computational step in transcript assembly. We prove the problem is in FPT when parameterized by the number of paths by giving a practical linear fpt algorithm. Further, we implement and engineer a Flow Decomposition solver based on this algorithm, and evaluate its performance on RNA-sequence data. Crucially, our solver finds exact solutions while achieving runtimes competitive with a state-of-the-art heuristic. Finally, we contextualize our design choices with two hardness results related to preprocessing and weight recovery. Specifically, k-Flow Decomposition does not admit polynomial kernels under standard complexity assumptions, and the related problem of assigning (known) weights to a given set of paths is NP-hard.	algorithm;computational complexity theory;heuristic;np-hardness;parameterized complexity;polynomial;preprocessor;runtime system;solver	Kyle Kloster;Philipp Kuinke;Michael P. O'Brien;Felix Reidl;Fernando Sánchez Villaamil;Blair D. Sullivan;Andrew van der Poel	2018		10.1137/1.9781611975055.7	combinatorics;discrete mathematics;mathematical optimization;mathematics;polynomial;heuristic;preprocessor;algorithm;parameterized complexity;solver	ML	20.800004141746474	20.478374687615307	21646
9468d2f0d9c64673b91a71cbe7d70f84e7d04ce0	interleaving two-phased jobs on a single machine	continuous time;discrete time;single machine;mixed integer program;integer programming;pulse interleaving;scheduling;integer program	In this paper, we consider a single machine that processes a set of jobs having two (ordered) phases. After processing the first phase of a job, this job must be removed from the machine for some exact amount of time, after which the machine must immediately begin processing its second phase. During this “dead time” between job phases, the machine may be used to process other similar jobs. We first prove that the problem of interleaving these jobs in order to minimize the makespan (or to process as many jobs as possible by a given deadline) is strongly NP-hard. Next, we compare the effectiveness of a mixed-integer programming formulation based on a continuous time domain to that of a discrete-time integer programming model for solving problems having different data characteristics. These comparisons are performed on a set of realistic synthetic problems based on different scenarios arising in radar pulsing applications. © 2005 Elsevier B.V. All rights reserved.	best, worst and average case;computation;critical pair (logic);discretization;forward error correction;heuristic (computer science);inbetweening;integer programming;job stream;linear function;linear programming;linear programming relaxation;makespan;minimax;np-hardness;numerical analysis;programming model;radar;strong np-completeness;synthetic intelligence;two-phase commit protocol;weight function;worst-case complexity	Hanif D. Sherali;Jonathan Cole Smith	2005	Discrete Optimization	10.1016/j.disopt.2005.08.002	mathematical optimization;discrete time and continuous time;real-time computing;integer programming;computer science;mathematics;distributed computing;scheduling	AI	16.045465368192147	9.448645379117195	21658
099f6aa342bde0ca9d2464e6bf513230e821d263	a pattern for a sensor node	sensors;pattern;wireless communication;architecture	Sensors are widely used in everyday life in household appliances, fire alarms, traffic control systems, battlefields, banks, and museums. Sensors are used either as standalone devices or in networks. Understanding the basic structure of a sensor node is essential to be able to use the sensors in different types of devices and different kinds of environments. Many applications require different types of sensor nodes that communicate with each other to perform a specific function. We present a pattern that describes an abstract view of the architecture of a sensor node. This description would help the application designer to choose from different types of sensor nodes for his application and to integrate it with other functional units. Moreover, this model also helps the designer to reuse, combine, or modify the architecture of a node to suit more complex needs.	control system;sensor node	Anupama Sahu;Eduardo B. Fernández;Mihaela Cardei;Michael VanHilst	2010		10.1145/2493288.2493295	embedded system;simulation;telecommunications;engineering;key distribution in wireless sensor networks	ML	0.753107253727564	31.58805868532417	21672
4bf7cc972095863c4addb7b330fc1b7f0d0267a2	application of a micro-genetic algorithm in optimal design of a diffractive optical element	optimal design;micro-genetic algorithm;diffractive optical element;diffractive optics;genetic algorithm	This study is motivated by a need to design a diiractive optical element arising in an application. Under realistic manufacturing constraints, it can be shown that the design problem is an optimization calculation with integer variables. We consider an optimization strategy based on Genetic Algorithms. We show that for a particular variant, called a Micro-Genetic Algorithm, the algorithm converges in a probabilistic sense to the global optimum. We demonstrate the use of the algorithm in the design of a diiractive optical element.	genetic algorithm;global optimization;linear temporal logic to büchi automaton;mathematical optimization;optimal design	Svetlana Rudnaya;Fadil Santosa	1999			optics	EDA	24.434271576732268	7.913346187559065	21702
f08340a2b487bc777afdb608399d616b42ec0552	maximizing the minimum voter satisfaction on spanning trees	fairness;approval voting;minimal spanning tree;computational complexity;voting rule;social choice;spanning tree;minimal spanning tree social choice fairness	This paper analyzes the computational complexity involved in solving fairness issues on graphs, e.g., in the installation of networks such as water networks or oil pipelines. Based on individual rankings of the edges of a graph, we will show under which conditions solutions, i.e., spanning trees, can be determined efficiently given the goal of maximin voter satisfaction. In particular, we show that computing spanning trees for maximin voter satisfaction under voting rules such as approval voting or the Borda count is -complete for a variable number of voters whereas it remains polynomially solvable for a constant number of voters.	file spanning	Andreas Darmann;Christian Klamler;Ulrich Pferschy	2009	Mathematical Social Sciences	10.1016/j.mathsocsci.2009.05.002	mathematical optimization;combinatorics;social choice theory;spanning tree;minimum spanning tree;approval voting;mathematics;cardinal voting systems;computational complexity theory;welfare economics	Theory	22.182923628137374	17.11961173633424	21720
25f93c8f6126f64c849a749c0f9356e82a61a333	parameterized complexity: the main ideas and connections to practical computing	parameterized complexity;approximate algorithm	The purposes of this paper are two: (1) To give an exposition of the main ideas of parameterized complexity, (2) To discuss the connections of parameterized complexity to the systematic design of heuristics and approximation algorithms.	approximation algorithm;heuristic (computer science);parameterized complexity	Michael R. Fellows	2002	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(04)00301-9	parameterized complexity;combinatorics;discrete mathematics;average-case complexity;computer science;theoretical computer science;worst-case complexity	Theory	16.624850783955136	19.9398586764402	21725
601d490f4e8fd1833865c26c1c5cb902d91025c2	the multi-period optimisation of an amine-based co2 capture process integrated with a super-critical coal-fired power station for flexible operation	post combustion co 2 capture;saft vr;multi scale modelling;flexible ccs;dynamic process modelling;dynamic optimisation	In this work, we present a model of a super-critical coal-fired power plant integrated with an amine-based CO 2  capture process. We use this model to solve a multi-period dynamic optimisation problem aimed at decoupling the operation of the power plant from the efficiency penalty imposed by the CO 2  capture plant, thus providing the power plant sufficient flexibility to exploit price variation within an electricity market. We evaluate four distinct scenarios: load following, solvent storage, exhaust gas by-pass and time-varying solvent regeneration. The objective is to maximise the decarbonised power plant's short run marginal cost profitability. It is found that while the solvent storage option provides a marginal improvement of 4% in comparison to the load following scenario, the exhaust gas bypass scenario results in a profit reduction of 17% whereas the time-varying solvent regeneration option increases the profitability of the power plant by 16% in comparison to the reference scenario.	mathematical optimization	Niall Mac Dowell;N. Shah	2015	Computers & Chemical Engineering	10.1016/j.compchemeng.2015.01.006	control engineering;simulation;engineering	EDA	3.6038463041410806	4.258223447233441	21742
a98845d6938785a21eec3b4243797d8cc4e283f2	palm calculus for a process with a stationary random measure and its applications to fluid queues	file attente;probabilite palm;formule mecke;residence time;stochastic process;sojourn time;point process;random measure;levy process;queue;modelo fluido;fluid model;temps sejour;single server queue;digital communication;fila 1 servidor;continuous flow;file 1 serveur;probability distribution;indexation;conservation law;processus stochastique;fluid queue;modele fluide;formule little;proceso estocastico;loi conservation;tiempo estancia;fila espera;probability measure;high speed;mesure aleatoire stationnaire;ley conservacion;processus levy	We consider a process associated with a stationary random measure, which may have infinitely many jumps in a finite interval. Such a process is a generalization of a process with a stationary embedded point process, and is applicable to fluid queues. Here, fluid queue means that customers are modeled as a continuous flow. Such models naturally arise in the study of high speed digital communication networks. We first derive the rate conservation law (RCL) for them, and then introduce a process indexed by the level of the accumulated input. This indexed process can be viewed as a continuous version of a customer characteristic of an ordinary queue, e.g., of the sojourn time. It is shown that the indexed process is stationary under a certain kind of Palm probability measure, called detailed Palm. By using this result, we consider the sojourn time processes in fluid queues. We derive the continuous version of Little's formula in our framework. We give a distributional relationship between the buffer content and the sojourn time in a fluid queue with a constant release rate.	stationary process	Masakiyo Miyazawa	1994	Queueing Syst.	10.1007/BF01158694	stochastic process;calculus;mathematics;fluid queue;statistics	Metrics	9.450604941439467	12.084604329932473	21748
4ee3e07d768f884fae798840024f78a2cd6016b4	p systems with shuffle operation and catalytic-like rules	membrane computing;p system;picture language;shuffle on trajectories	Shuffle operation on trajectories is useful in modeling parallel composition of words and languages. In this work, a new class of P systems with shuffle operation and catalytic-like rules is presented. Such a system has a membrane structure, where language-objects and shuffleoperation rules are placed in its regions. It can be used as a language generator. In this study, we propose a variant P system with shuffle operation on string-language objects. Some comparison results are obtained, which show that the power of shuffle operation is enlarged in the framework of P systems. Moreover, string-language objects are extended to array-language objects, and another variant P system with shuffle operation on picture-language objects is introduced. We also illustrate how to generate picture languages by using this kind of devices.	delimiter;multi-compartment model;p system;picture language;rewriting	Yunyun Niu;Jinbang Xu;K. G. Subramanian;Rosni Abdullah	2012	J. UCS	10.3217/jucs-018-13-1782	theoretical computer science;algorithm	DB	1.06028101332903	24.466296935247176	21751
4a6bfc15be289238e661f053d148c703fedb10f4	evaluating the effect of upgrade, control and development strategies on robustness and failure risk of the power transmission grid	reliability;probability;development strategy;risk analysis;implementation;power transmission and distribution;robust control;power transmission;failure analysis;redundancy;complex system;hawaii;load flow;power grid;power transmission control;power grids;power transmission reliability;cascade systems;outages	We use the OPA complex systems model of the power transmission system to investigate the effect of a series of different network upgrade scenarios on the long time dynamics and the probability of large cascading failures. The OPA model represents the power grid at the level of DC load flow and LP generation dispatch and represents blackouts caused by randomly triggered cascading line outages and overloads. We examine the effect of increased component reliability on the long-term risks, the effect of changing operational margins and the effect of redundancy on those same long-term risks. The general result is that while increased reliability of the components decreases the probability of small blackouts, depending on the implementation, it actually can increase the probability of large blackouts. When we instead increase some types of redundancy of the system there is an overall decrease in the large blackouts. As some of these results are counter intuitive these studies suggest that care must be taken when making what seem to be logical upgrade decisions.	complex systems;dynamic dispatch;opa;randomness;redundancy (engineering)	David E. Newman;Benjamin A. Carreras;Vickie E. Lynch;Ian Dobson	2008	Proceedings of the 41st Annual Hawaii International Conference on System Sciences (HICSS 2008)	10.1109/HICSS.2008.152	robust control;failure analysis;complex systems;power-flow study;real-time computing;risk analysis;power transmission;probability;reliability;redundancy;implementation;statistics	HPC	-2.0054918533202564	8.172933193972067	21772
936d96db940670b52e1838c14fdcb9800fbcba67	simultaneous scheduling of jobs, machines and tools considering tool transfer times in multi-machine fms using new nature-inspired algorithms		This paper addresses simultaneous scheduling of jobs, machines and tools considering tool transfer times (TTTs) between machines, to generate best optimal sequences that minimise makespan in a multi-machine flexible manufacturing system (FMS). Performance of FMS is expected to improve by effective utilisation of its resources, by proper integration and synchronisation of their scheduling. Aim of this paper is to address joint scheduling of jobs, machine and tools in an FMS consisting of machines, central tool magazine and tool transporter considering TTTs. Three nature-inspired algorithms namely Symbiotic Organisms Search algorithm, Crow search algorithm and Flower pollination algorithm, are proposed for solving joint jobs, machine and tool scheduling problems considering TTTs between machines with minimum makespan as objective. The proposed algorithms are numerically tested on various problems and results are compared. The results show that FPA algorithm yields better results for simultaneous scheduling ...	algorithm;scheduling (computing)	N. Sivarami Reddy;D. V. Ramamurthy;K. Prahlada Rao	2018	IJISTA	10.1504/IJISTA.2018.10012883	engineering;job shop scheduling;synchronization;scheduling (computing);algorithm;search algorithm;flexible manufacturing system	Theory	13.767717634948625	5.565424095540786	21786
80d9e45fe8255a989a89705da8d1f50732c9d121	an enhanced theory of infinite time register machines	hypercomputation;ordinal computability;infinitary computation;register machine	Infinite time register machines (ITRMs) are register machines which act on natural numbers and which are allowed to run for arbitrarily many ordinal steps. Successor steps are determined by standard register machine commands. At limit times a register content is defined as a lim inf of previous register contents, if that limit is finite; otherwise the register is reset to 0. (A previous weaker version of infinitary register machines, in [6], would halt without a result in case of such an overflow.) The theory of infinite time register machines has similarities to the infinite time Turing machines (ITTMs) of Hamkins and Lewis. Indeed ITRMs can decide all Π 1 sets, yet they are strictly weaker than ITTMs.	expanded memory;halting problem;ordinal data;register machine;turing machine	Peter Koepke;Russell G. Miller	2008		10.1007/978-3-540-69407-6_34	discrete mathematics;computer science;theoretical computer science;mathematics;hypercomputation;register allocation;algorithm;register machine	Theory	-1.4119242923326445	16.153085175143804	21790
40466716a8df801e22b7d59d7acf6f77d180fb1d	approximate counting scheme for m x n contingency tables	tecnologia electronica telecomunicaciones;fpras;approximation;counting;mcmc method;contingency table;tecnologias;grupo a;p completeness	In this paper, we propose a new counting scheme for m × n contingency tables. Our scheme is a modification of Dyer and Greenhill’s scheme for two rowed contingency tables [5]. We can estimate not only the sizes of error, but also the sizes of the bias of the number of tables obtained by our scheme, on the assumption that we have an approximate sampler. key words: counting, approximation, #P-completeness, fpras, MCMC method, contingency table	approximation algorithm;contingency table;markov chain monte carlo;np-completeness;sampling (signal processing)	Shuji Kijima;Tomomi Matsui	2004	IEICE Transactions		combinatorics;contingency table;approximation;mathematics;counting;algorithm;statistics	DB	14.215609900684129	22.72499394082748	21806
2af844ba50ad30d55008180cf88ec50f09e45705	multiparty communication complexity	boolean functions;complexity theory decision trees boolean functions distributed computing scholarships very large scale integration polynomials;communication complexity;boolean function;nondeterministic communication complexity communication complexity boolean function information lower bound;computational complexity;nondeterministic communication complexity;information lower bound;computational complexity boolean functions;lower bound	A given Boolean function has its input distributed among ma,ny parties. The aim is to determine which parties t o talk t o and what information t o exchange with each of them in order to evduate the function while minimizing the total communication. This paper shows t1ia.t it is possible to obta.in the Boolean answer deterministically with only a polynomial increase in communication with respect to the inforiliatioil lower bound given by the nondet.erniinistic communica.tion complexity of the function.	multiparty communication complexity;polynomial	Danny Dolev;Tomás Feder	1989		10.1109/SFCS.1989.63514	circuit complexity;boolean circuit;combinatorics;max-3sat;discrete mathematics;boolean network;average-case complexity;decision tree model;boolean expression;standard boolean model;#sat;computer science;maximum satisfiability problem;theoretical computer science;karp–lipton theorem;worst-case complexity;cook–levin theorem;communication complexity;complexity index;mathematics;boolean function;boolean satisfiability problem;asymptotic computational complexity;algorithm;parity function	Theory	9.432443440311244	23.058645319977316	21928
098d5cf4cd26f4b75b991b272038ae9c82360477	opportunistic communication in extreme wireless sensor networks: a step back towards the smart dust dream				Marco Cattani	2016				Mobile	4.753921940626263	31.621315082763836	21944
a3f343661eb6dd128fcb0192db22a5be14fa87d8	hierarchical extraction of a spanning planar subgraph maintaining clockwise directedness of cycles	directed graphs;clocks very large scale integration planarization algorithm design and analysis iterative algorithms turning maintenance engineering wiring circuits process design;vlsi layout spanning planar subgraph subgraph hierarchical extraction cycle clockwise directedness maintenance directed cycles plan divide one sided elements one sided modules pwb layout design;integrated circuit layout;printed circuit layout;integrated circuit layout directed graphs printed circuit layout	The subject of the paper is to propose algorithms of high capability for extracting a spanning planar subgraph G/sub p/=(V, E/sub p/) of a given graph G=(V,E) containing several directed cycles such that there is a plane embedding G/spl tilde//sub p/ in which all directed cycles are embedded as clockwise directed ones. Experimental results provided for comparison of capability show that PLAN-DIVIDE is superior to other existing ones. These algorithms have important and useful applications such as hierarchical extraction of a large spanning planar subgraph for a huge graph that cannot be handled by conventional algorithms, handling one-sided elements or modules in layout design of PWB or VLSI, and iterative improvement of layouts for PWB or VLSI.	algorithm;embedded system;file spanning;iteration;very-large-scale integration	Daisuke Takafuji;Toshimasa Watanabe	2005	2005 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2005.1464552	combinatorics;directed graph;computer science;electrical engineering;mathematics;integrated circuit layout;engineering drawing;algorithm	Arch	20.553412609322425	31.293686558047643	21953
2c2d0f3dbf44a5626a8ffaf129edeefd3c2d8225	loopless generation of schröder trees		The well-known Schröder numbers have appeared in different combinatorial contexts, including Schröder trees and well-weighted binary trees. The only loopless algorithm for generating Schröder trees actually generated representations for their well-weighted binary tree counterparts. This paper presents the first loopless algorithms for directly generating Schröder tree representations. They use a new loopless algorithm for generating k-compositions of n in inverse lexicographic order.	binary tree;lexicographical order;loopless algorithm;whole earth 'lectronic link	James F. Korsh;Paul LaFollette	2003	Comput. J.	10.1093/comjnl/46.1.106	theoretical computer science;computer science	Theory	15.50839385788945	28.75356894201696	22019
7b949c10f0955cb5c2c90aa19e6be82ebd51d845	the (generalized) post correspondence problem with lists consisting of two words is decidable	correspondence problem		post correspondence problem	Andrzej Ehrenfeucht;Juhani Karhumäki;Grzegorz Rozenberg	1982	Theor. Comput. Sci.	10.1016/0304-3975(89)90080-7	combinatorics;discrete mathematics;computer science;mathematics;correspondence problem;algorithm	ECom	-2.3022407044313002	19.03192396628495	22046
ecc45073b0804fca7199cb80d535e639ce7ca996	a model for asynchronous shared memory parallel computation	asynchrony;algoritmo paralelo;parallel algorithm;shared memory;complexite calcul;memoria compartida;models of parallel computation;68q05;parallel computation;algorithme parallele;complejidad computacion;calculo paralelo;68q22;computational complexity;parallel computer;asynchronous regime;regimen asincrono;68q10;68q25;regime asynchrone;calcul parallele;memoire partagee;parallel algorithms	Traditional theoretical shared memory parallel models have been based on a number of assumptions which simultaneously simplify solutions to problems and distance the models from actual parallel machines. One such assumption is that processors work together in a synchronous fashion. Recent work has focused on finding a model that captures the essence of computation by processors communicating asynchronously through shared memory. In this paper, a general framework and set of criteria used to analyze these models, including the complexity analysis of several fundamental algorithmic paradigms, are considered. A general asynchronous model is introduced and how it satisfies these criteria is demonstrated. In this model, O (log p) algorithms are demonstrated for solving p-input versions of the problems of AND, OR, parity, maximum, minimum, and list ranking. To handle list ranking, a technique of analyzing algorithms is developed in which the set of tasks that are to be executed depends on the processor schedules. Key words, asynchrony, parallel computation, models of parallel computation, computational complexity, parallel algorithms AMS subject classifications. 68Q05, 68Q10, 68Q22, 68Q25	algorithm design;analysis of algorithms;asynchronous i/o;boolean algebra;central processing unit;computation;computational complexity theory;existential quantification;list ranking;parallel algorithm;parallel computing;pointer (computer programming);pointer jumping;programming paradigm;schedule (computer science);shared memory;simulation;synchronization (computer science);time complexity;vhdl-ams	Naomi Nishimura	1994	SIAM J. Comput.	10.1137/S0097539791219670	distributed shared memory;mathematical optimization;combinatorics;parallel computing;distributed memory;computer science;theoretical computer science;parallel algorithm;algorithm	Theory	10.581909903468565	31.693263706292182	22074
c922b4e0f19b1a907fb4af49020345363085b294	an efficient deadlock prevention policy for noncyclic scheduling of multicluster tools		Scheduling of multicluster tools has received much attention due to its complexity of interaction among cluster tools. A cluster tool comprises several modules such as processing modules, a transfer module with a single or dual-armed handling robot, and loadlock modules. A multicluster tool comprises two, three, or more cluster tools that are interconnected with each other. In this paper, we propose a deadlock prevention policy for noncyclic scheduling of dual-armed multicluster tools. The proposed deadlock prevention policy is effective for generating an efficient schedule for two or three-connected multicluster tools with a single or a dual-path flow. This is proven by analyzing the strict minimal siphon of the Petri net model. The performance of the proposed method is compared with that of a maximal permissible deadlock prevention policy. The results demonstrate that the proposed method is computationally efficient for larger state spaces and more suitable than conventional deadlock prevention policies for generating effective schedules for noncyclic scheduling of multicluster tools. Note to Practitioners—Scheduling of multicluster tools has recently attracted attention in the growing semiconductor manufacturing industry. Most conventional studies on multicluster tools focus on cyclic scheduling to minimize cycle time with swap strategy. The challenge addressed by this paper is to derive a deadlock-free schedule for multicluster tools with noncyclic operations. We propose a simple deadlock prevention policy that can be applied to large-scale timed Petri net (PN) model of general multicluster tools without enumeration of siphon computations or solution of mixed integer programming. A timed PN model is developed for noncyclic operations of dual-armed multicluster tools with a dual ath. The computational results show that the approximately 10% of the total throughput of the proposed method is better than those of the conventional methods. It enables more efficient operations for noncyclic scheduling under transient periods including cleaning operations.	algorithm;algorithmic efficiency;computation;computer cluster;deadlock;embedded system;emoticon;family computer disk system;feasible region;integer programming;item unique identification;linear programming;maximal set;multidimensional digital pre-distortion;paging;petri net;plasma cleaning;scheduling (computing);semiconductor device fabrication;sensor;simulation;social inequality;throughput	Tatsushi Nishi;Yushin Watanabe;Masaru Sakai	2018	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2017.2771751	computer science;job shop scheduling;mathematical optimization;throughput;petri net;deadlock prevention algorithms;scheduling (computing);integer programming;schedule;distributed computing	Robotics	12.773451220271548	5.9257938929895895	22131
169844fdf00db3b7b9c6711530b63c6392a81698	heuristics for job scheduling reoptimization	approximation algorithms;job shop scheduling;processor scheduling;virtual machining;out of order;optimal scheduling;schedules	Many real-life applications involve systems that change dynamically over time. Thus, throughout the continuous operation of such a system, it is required to compute solutions for new problem instances, derived from previous instances. Since the transition from one solution to another incurs some cost, a natural goal is to have the solution for the new instance close to the original one (under a certain distance measure). We study reoptimization problems arising in scheduling systems. Formally, due to changes in the environment (out-of-order or new machines, modified jobs' processing requirements, etc.), the schedule needs to be modified. That is, jobs might be migrated from their current machine to a different one. Migrations are associated with a cost - due to relocation overhead and machine set-up times. In some systems, a migration is also associated with job extension. The goal is to find a good modified schedule, with a low transition cost from the initial one. We consider reoptimization with respect to the classical objectives of minimum makespan and minimum total flowtime. We first prove that the reoptimization variants of both problems are NP-hard, already for very restricted classes. We then develop and present several heuristics for each objective, implement these heuristics, compare their performance on various classes of instances and analyze the results.	approximation algorithm;branch and bound;brute-force search;code refactoring;continuous operation;converge;experiment;flow network;fractal dimension;genetic algorithm;greedy algorithm;heuristic (computer science);job scheduler;job stream;makespan;matching (graph theory);np-completeness;np-hardness;overhead (computing);parallel port;polynomial;preprocessor;real life;relocation (computing);requirement;schedule (computer science);scheduling (computing);solver;time complexity	Elad Iwanir;Tami Tamir	2016	2016 Federated Conference on Computer Science and Information Systems (FedCSIS)	10.15439/2016F201	job shop scheduling;mathematical optimization;real-time computing;flow shop scheduling;schedule;computer science;out-of-order execution	Theory	16.002154706905603	8.737607858878736	22147
84fd1355479dd9383077522aed58490f54cd4215	grasp. extending graph separators for the single-source shortest-path problem		Many existing solutions focus on point-to-point shortest-path queries in road networks. In contrast, only few contributions address the related singlesource shortest-path problem, i.e., finding shortest-path distances from a single source s to all other graph vertices. This work extends graph separator methods to handle this specific problem and its one-to-many variant, i.e., calculating the shortest path distances from a single source to a set of targets T⊆V . This novel family of so-called GRASP algorithms provides exceptional preprocessing times, making them suitable for dynamic travel time scenarios. GRASP algorithms also efficiently solve range / isochrone queries not handled by previous approaches.	algorithm;grasp;one-to-many (data model);point-to-point protocol;preprocessor;shortest path problem;vertex separator	Alexandros Efentakis;Dieter Pfoser	2014		10.1007/978-3-662-44777-2_30	combinatorics;machine learning	DB	23.488852894832235	7.369676000000365	22196
70cbb452b39c1a8b61f5b112d067079ac6bdb807	pku-straw-l: a simulative platform evaluate the power-saving rate of the intelligent street lamp system	energy conservation;control systems;lighting control;power saving;turning;lamps;intelligent control;dsrc;engines;vehicular ad hoc networks digital simulation energy conservation environmental economics intelligent control java lamps lighting control power consumption street lighting;roads;vehicular ad hoc networks;jist;environmental economics;street lamp system;street lamp system power saving dsrc straw jist;straw;street lighting;vehicles;lighting;power consumption;prelighting pku straw l power saving rate evaluation intelligent street lamp system low carbon economy lce large energy consumption system energy saving simulation platform java simulator jist straw test bed system design peking university intelligent lamp control system vanet dsrc communication lamp lighting strategies straight road cross road;vehicles roads lighting turning educational institutions engines control systems;digital simulation;java	A Low-Carbon Economy (LCE) has been a heated economy topic throughout the world. The street lamp system is a large energy consumption system although it is indispensable part of the basic facilities of a city. So it is important for many scientific researchers to provide many solutions to save energy efficiently. In this paper, we design a simulation platform named PKU-STRAW-L that evaluates the energy consumption based on famous Java simulator JiST/STRAW. We also design a test bed system that intelligently controls the street lamp based on Peking University STRAW. The intelligent lamp control system is based on the VANET's DSRC communication and focuses on some lamp-lighting strategies when vehicle drives on cross road, straight road and pre-lighting. By using this platform we can evaluate the power-saving rate of this intelligent street lamp system.	benchmark (computing);computer cluster;control system;design of experiments;intelligent street;java;lamp (software bundle);performance per watt;server (computing);simulation;test case;testbed	Tao Yang;Lingbo Kong;Yinyang Wang;Jian-bin Hu;Zhong Chen	2012	2012 9th International Conference on Ubiquitous Intelligence and Computing and 9th International Conference on Autonomic and Trusted Computing	10.1109/UIC-ATC.2012.116	embedded system;simulation;energy conservation;telecommunications;computer science;dedicated short-range communications;lighting;java;computer security;intelligent control	Robotics	3.3086800538916536	9.236745338106964	22256
c368e303a493a8d5bbb49ff587c1480a6eb250d2	describing parameterized complexity classes	regularite;complexite;complet;problem;hierarchy;parameterized complexity;complexity theory;temps polynomial;regularidad;parametre;fixed parameter tractable;clase complejidad;complejidad;regularity;refinement;complexity;polynomial;probleme;afinamiento;parametro;parameter;completo;descripcion;classe complexite;complexity class;polinomio;theory;jerarquia;teoria;polynomial time;affinement;problema;hierarchie;polynome;description;theorie;complete;tiempo polinomial	We describe parameterized complexity classes by means of classical complexity theory and descriptive complexity theory. For every classical complexity class we introduce a parameterized analogue in a natural way. In particular, the analogue of polynomial time is the class of all fixed-parameter tractable problems. We develop a basic complexity theory for the parameterized analogues of classical complexity classes and give, among other things, complete problems and logical descriptions. We then show that most of the well-known intractable parameterized complexity classes are not analogues of classical classes. Nevertheless, for all these classes we can provide natural logical descriptions.	complexity class;parameterized complexity	Jörg Flum;Martin Grohe	2003	Inf. Comput.	10.1016/S0890-5401(03)00161-5	complete;complexity class;parameterized complexity;combinatorics;discrete mathematics;complexity;polynomial-time reduction;average-case complexity;ph;quantum complexity theory;computer science;structural complexity theory;sparse language;mathematics;up;parameter;game complexity;algorithm;descriptive complexity theory;algebra	Theory	5.807909437516737	20.737538287566824	22265
0957147e631082711e51d05f5960f27f69586cc5	parameterized complexity of secluded connectivity problems	parameterized complexity;conference object;secluded steiner tree;secluded path	The Secluded Path problem models a situation where sensitive information has to be transmitted between a pair of nodes along a path in a network. The measure of the quality of a selected path is its exposure cost, which is the total cost of vertices in its closed neighborhood. The task is to select a secluded path, i.e., a path with a small exposure cost. Similarly, the Secluded Steiner Tree problem is to find a tree in a graph connecting a given set of terminals such that the exposure cost of the tree is minimized. In this paper we present a systematic study of the parameterized complexity of Secluded Steiner Tree. In particular, we establish the tractability of Secluded Path being parameterized by “above guarantee” value, which in this case is the length of a shortest path between vertices. We also show how to extend this result for Secluded Steiner Tree, in this case we parameterize above the size of an optimal Steiner tree and the number of terminals. We also consider various parameterization of the problems such as by the treewidth, the size of a vertex cover, feedback vertex set, or the maximum vertex degree and establish kernelization complexity of the problem subject to different choices of parameters.	degree (graph theory);feedback vertex set;information sensitivity;kernelization;parameterized complexity;shortest path problem;steiner tree problem;treewidth;vertex (geometry);vertex cover	Fedor V. Fomin;Petr A. Golovach;Nikolay Karpov;Alexander S. Kulikov	2016	Theory of Computing Systems	10.1007/s00224-016-9717-x	parameterized complexity;mathematical optimization;combinatorics;discrete mathematics;steiner tree problem;computer science;mathematics;algorithm	Theory	24.13449061517284	20.50730593198762	22285
31dc354a90b414598e265879d2e19b2b83fd9ca1	the one-dimensional cutting stock problem with due dates	modelizacion;agregacion;horizon roulant;optimisation;programacion entera;horizonte rodante;optimizacion;cutting;date echeance;geometria variable;geometrie variable;cutting stock problem;cutting integer programming scheduling;aggregation;programmation en nombres entiers;rolling horizon;modelisation;industrie metallurgique;probleme decoupe;integer programming;scheduling;retard;variable geometry;due date;agregation;fecha vencimiento;industria metalurgica;optimization;problema troquelado;integer program;retraso;modeling;metallurgical industry;ordonnancement;optimization model;reglamento	The one-dimensional cutting stock problem is the problem of cutting stock material into shorter lengths, in order to meet demand for these shorter lengths while minimizing waste. In industrial cutting operations, it may also be necessary to fill the orders for these shorter lengths before a given due date. We propose new optimization models and solution procedures which solve the cutting stock problem when orders have due dates. We evaluate our approach using data from a large manufacturer of reinforcement steel and show that we are able to solve industrial-size problems, while also addressing common cutting considerations such as aggregation of orders, multiple stock lengths and cutting different types of material on the same machine. In addition, we evaluate operational performance in terms of resulting waste and tardiness of orders using our model in a rolling horizon framework.	cutting stock problem	Harald Reinertsen;Thomas W. M. Vossen	2010	European Journal of Operational Research	10.1016/j.ejor.2009.03.042	mathematical optimization;systems modeling;integer programming;computer science;operations management;cutting stock problem;mathematics;cutting;scheduling	Theory	17.487173781198322	6.781498191554422	22304
0cac2e5672a6e6ca7f530128b01b2e1f4c15e0a4	from bandits to experts: a tale of domination and independence		We consider the partial observability model for multi-armed bandits, introduced by Mannor and Shamir [14]. Our main result is a characterization of regret in the directed observability model in terms of the dominating and independence numbers of the observability graph (which must be accessible before selecting an action). In the undirected case, we show that the learner can achieve optimal regret without even accessing the observability graph before selecting an action. Both results are shown using variants of the Exp3 algorithm operating on the observability graph in a time-efficient manner.	adversary (cryptography);algorithm;best, worst and average case;dominating set;graph (discrete mathematics);graph theory;interpolation;linear algebra;loss function;multi-agent system;multi-armed bandit;observable;regret (decision theory)	Noga Alon;Nicolò Cesa-Bianchi;Claudio Gentile;Yishay Mansour	2013			mathematical optimization;combinatorics;mathematics	ML	18.96097522732105	23.072132419967808	22344
06f39e1110d3b9c41069ad1937ccb7497057c984	the concept of duality for automata over a changing alphabet and generation of a free group by such automata	mealy automaton;group generated by an automaton;free group	In the paper, we deal with the notion of an automaton over a changing alphabet, which generalizes the concept of a Mealy-type automaton. We modify the methods based on the idea of a dual automaton and its action used by B. Steinberg et al. (2011) and M. Vorobets and Ya. Vorobets (2007, 2010) [16–18] and adapt them to automata over a changing alphabet. We show that this modification provides some naturally defined automaton representations of a free nonabelian group by a 2-state automaton over a changing alphabet. © 2011 Elsevier B.V. All rights reserved.	automaton;mealy machine;sql	Adam Woryna	2011	Theor. Comput. Sci.	10.1016/j.tcs.2011.08.017	powerset construction;stochastic cellular automaton;deterministic pushdown automaton;nondeterministic finite automaton with ε-moves;reversible cellular automaton;block cellular automaton;combinatorics;nested stack automaton;discrete mathematics;büchi automaton;elementary cellular automaton;nondeterministic finite automaton;life-like cellular automaton;two-way deterministic finite automaton;probabilistic automaton;continuous automaton;deterministic automaton;ω-automaton;free group;mathematics;mobile automaton;timed automaton;pushdown automaton;algorithm	Logic	-1.703397648559977	22.158468658411902	22345
9d08ee17b6283a3176bb0ee829b3a76102e200c9	on minimal pairs of enumeration degrees				Kevin McEvoy;S. Barry Cooper	1985	J. Symb. Log.		maximal set;recursion;combinatorics;mathematical logic;discrete mathematics;recursively enumerable set;mathematics;enumeration;recursively enumerable language;algorithm	Logic	-2.271687805016149	19.387755773577737	22347
fb8a3ed3dfc949b008cd4d6562498527b4de7e2e	characterization of real time iterative array by alternating device	iterative method;automata estado finito;real time;simulation;simulacion;red;counter automaton;metodo iterativo;alternating counter automata;reseau itere;methode iterative;reseau arrangement;automate cellulaire;temps reel;characterization;automate conteur;tiempo real;computation tree;array;finite automaton;automate fini;caracterisation;cellular automata;iterative array;iterated array;cellular automaton;caracterizacion;arbre calcul;automata celular	In this paper, we show that real time k-dimensional iterative arrays are equivalent through reverse to real time one-way alternating k-counter automata.	iterative method	Véronique Terrier	2003	Theor. Comput. Sci.	10.1016/S0304-3975(02)00489-9	cellular automaton;computer science;artificial intelligence;mathematics;iterative method;algorithm	AI	-1.0739910717985868	24.743877867982594	22395
50cd6914d664b2066a8abf96310abbad8f208e95	extending and solving a multiperiod congested network flow model	modelizacion;optimisation;reseau traitement pur;optimizacion;reseau;red;modelisation;funcion penalidad;mathematical programming;optimization;network flow;fonction penalite;modeling;programmation mathematique;programacion matematica;flot reseau;network;penalty function	Abstract   We consider an existing model for optimizing time-varying flows on a congested network, and extend it so as to improve its accuracy while  reducing  computation. The model has been developed in a series of articles and has a variety of applications. Solving the model is a significant problem, since it is a non-linear program and can be very large for even small or medium size applications. Hitherto the model has been solved by taking a piecewise linear approximation and solving this as a linear program, perhaps taking advantage of the staircase structure of the constraints. However, this staircase is not available in the extended model. Further, the existing solution methods do not take advantage of the network structure of the problem. Here we show that a piecewise linear version of the model can be stated as a pure processing network (PPN); this allows algorithms for PPNs to be used to solve the model. We also propose a penalty (or barrier) function solution method. This reduces the problem to successively reoptimizing a program equivalent to the well-known static traffic assignment model. The latter is a convex cost, linearly constrained,  un capacitated network flow problem. The above solution methods apply both to the basic model and the extended model.	flow network	Malachy Carey	1990	Computers & OR	10.1016/0305-0548(90)90054-B	mathematical optimization;flow network;systems modeling;computer science;artificial intelligence;penalty method;mathematics;algorithm	Logic	20.66821093876449	8.032203143511287	22408
3c3913b531034b8566a400b47b930ed967f50f21	bilevel programming approach applied to the flow shop scheduling problem under fuzziness	decision models;flow shop scheduling;decision maker;membership function;fuzzy decision model;bilevel programming;job scheduling;flow shop	This paper presents a fuzzy bilevel programming approach to solve the flow shop scheduling problem. The problem considered here differs from the standard form in that operators are assigned to the machines and imposing a hierarchy of two decision makers with fuzzy processing times. The shop owner considered higher level and assigns the jobs to the machines in order to minimize the flow time while the customer is the lower level and decides on a job schedule in order to minimize the makespan. In this paper, we use the concepts of tolerance membership function at each level to define a fuzzy decision model for generating optimal (satisfactory) solution for bilevel flow shop scheduling problem. A solution algorithm for solving this problem is given.	algorithm;flow shop scheduling;fuzzy logic;fuzzy set;job stream;makespan;membership function (mathematics);scheduling (computing);set theory;time complexity	Samir A. Abass	2005	Comput. Manag. Science	10.1007/s10287-005-0035-z	job shop scheduling;mathematical optimization;flow shop scheduling;computer science;artificial intelligence;operations management;mathematics;bilevel optimization	AI	12.842159217916493	6.945704112114532	22423
e09e237842a19cfdb1b3de4143d928e5fa59a1e6	towards optimal multi-level checkpointing	optimal pattern resilience fail stop errors multi level checkpointing;checkpointing protocols error analysis shape optimized production technology dynamic programming heuristic algorithms	"""We provide a framework to analyze multi-level checkpointing protocols, by formally defining a <inline-formula> <tex-math notation=""""LaTeX"""">$k$</tex-math><alternatives><inline-graphic xlink:href=""""benoit-ieq1-2643660.gif""""/> </alternatives></inline-formula>-level checkpointing pattern. We provide a first-order approximation to the optimal checkpointing period, and show that the corresponding overhead is in the order of <inline-formula> <tex-math notation=""""LaTeX"""">$\sum _{\ell =1}^{k}\sqrt{2\lambda _\ell C_\ell}$</tex-math><alternatives> <inline-graphic xlink:href=""""benoit-ieq2-2643660.gif""""/></alternatives></inline-formula>, where <inline-formula> <tex-math notation=""""LaTeX"""">$\lambda _\ell$</tex-math><alternatives> <inline-graphic xlink:href=""""benoit-ieq3-2643660.gif""""/></alternatives></inline-formula> is the error rate at level  <inline-formula><tex-math notation=""""LaTeX"""">$\ell$</tex-math><alternatives> <inline-graphic xlink:href=""""benoit-ieq4-2643660.gif""""/></alternatives></inline-formula>, and <inline-formula> <tex-math notation=""""LaTeX"""">$C_\ell$</tex-math><alternatives><inline-graphic xlink:href=""""benoit-ieq5-2643660.gif""""/> </alternatives></inline-formula> the checkpointing cost at level <inline-formula><tex-math notation=""""LaTeX"""">$\ell$ </tex-math><alternatives><inline-graphic xlink:href=""""benoit-ieq6-2643660.gif""""/></alternatives></inline-formula>. This nicely extends the classical Young/Daly formula on single-level checkpointing. Furthermore, we are able to fully characterize the shape of the optimal pattern (number and positions of checkpoints), and we provide a dynamic programming algorithm to determine the optimal subset of levels to be used. Finally, we perform simulations to check the accuracy of the theoretical study and to confirm the optimality of the subset of levels returned by the dynamic programming algorithm. The results nicely corroborate the theoretical study, and demonstrate the usefulness of multi-level checkpointing with the optimal subset of levels."""	algorithm;application checkpointing;dynamic programming;first-order predicate;multi-level cell;multi-level governance;order of approximation;overhead (computing);simulation;xlink	Anne Benoit;Aurélien Cavelan;Valentin Le Fèvre;Yves Robert;Hongyang Sun	2017	IEEE Transactions on Computers	10.1109/TC.2016.2643660	computer science;real-time computing;parallel computing;word error rate;dynamic programming	ML	7.109716195628557	29.689738025238924	22455
3d3daa35df172cc2805f17b9295ae79e178df6f0	non-uniform random spanning trees on weighted graphs	arbre graphe;graphe non oriente;graph theory;systeme equation;teoria grafo;non directed graph;algorithm complexity;tree graph;automata estado finito;complejidad algoritmo;arbre maximal;regular language;theorie graphe;lenguaje racional;sistema ecuacion;complexite algorithme;arbol maximo;grafo no orientado;random walk;equation system;finite automata;langage rationnel;finite automaton;spanning tree;automate fini;weighted graph;marcha aleatoria;linear equations;arbol grafo;regular expression;marche aleatoire	We study random walks on undirected graphs with weighted edges. Our main result shows that any spanning tree deened by the edges corresponding to a rst visit of a vertex, appears with a probability proportional to its weight, which is the product of the weights of its edges. This provides an algorithm for generating non uniform random spanning trees in a weighted graph. The technique used here is based on linear equations over regular expressions and nite automata theory. R esum e Nous etudions les marches al eatoires sur les graphes pond er es non orient es. Nous d emontrons, en particulier, que la probabilit e d'engendrer un arbre couvrant est proportionnelle a son poids, qui est le produit des poids de ses ar^ etes. Ce r esultat fournit un algorithme pour g en erer des arbres couvrants non uniformes dans un graphe pond er e. Les techniques utilis ees sont fond ees sur les syst emes d' equations sur les langages rationnels et la th eorie des automates nis.	algorithm;automata theory;average-case complexity;computable function;cycle (graph theory);file spanning;graph (discrete mathematics);linear algebra;linear equation;regular expression;sensitivity index;spanning tree;vertex (geometry)	Mohamed Mosbah;Nasser Saheb-Djahromi	1999	Theor. Comput. Sci.	10.1016/S0304-3975(98)00325-9	combinatorics;regular language;spanning tree;computer science;mathematics;linear equation;finite-state machine;random walk;tree;regular expression;algorithm	Theory	23.404838636775274	31.533230502316716	22506
c37ad15e3995ee29ae9962b7a867dac2b678fd3b	performance analysis of the bmap/g/1 queue with gated servicing and adaptive vacations	adaptive vacations;batch markovian arrival process;matrix analytic method;stationary distribution;queueing model;waiting time;performance analysis;gated servicing;matrix analytic methods;performance modelling	A queueing model of the BMAP/G/1BMAP/G/1 type with gated servicing and vacations depending on the state of the system is analysed. The queue stationary distributions at the instants of gate switching on and at arbitrary time as well as of a customer waiting time are computed. This model may prove useful for tuning the parameters of the adaptive polling mechanism applicable in the broadband wireless Wi-Fi and WiMax networks.		Vladimir M. Vishnevsky;Alexander N. Dudin;Olga V. Semenova;Valentina I. Klimenok	2011	Perform. Eval.	10.1016/j.peva.2011.02.003	matrix analytic method;stationary distribution;real-time computing;simulation;mathematics;statistics	HPC	8.10091325589868	11.144709845122673	22558
e8be675ea56a73b57f74e7fae9c023a59607fdd8	superlinear bounds for matrix searching problems	dynamic programming;matrice staircase;programacion dinamica;algoritmo busqueda;algorithm analysis;execution time;limite inferior;geometrie algorithmique;algorithme recherche;sistema informatico;search algorithm;computational geometry;computer system;matrice monotone;estructura datos;programmation dynamique;matrice skyline;geometria algoritmica;temps execution;analyse algorithme;structure donnee;systeme informatique;tiempo ejecucion;data structure;limite inferieure;analisis algoritmo;lower bound	Abstract   Matrix searching in classes of totally monotone partial matrices has many applications in computer science, operations research, and other areas. This paper gives the first superlinear lower bound for matrix searching in classes of totally monotone partial matrices and also contains some new upper bounds for a class with applications in computational geometry and dynamic programming. The precise results of this paper are as follows. We show that any algorithm for finding row maxima or minima in totally monotone partial 2 n  ×  n  matrices with the property that the non-blank entries in each column form a contiguous segment, can be forced to evaluate   Ω(nα(n))   entries of the matrix in order to find the row maxima or minima, where  α ( n ) denotes the very slowly growing inverse of Ackermann's function. A similar result is obtained for  n  × 2 n  matrices with contiguous non-blank segments in each row. The lower bounds are proved by introducing the concept of an independence set in a partial matrix and showing that any matrix searching algorithm for these types of partial matrices can be forced to evaluate every element in the independence set. A result involving lower bounds for Davenport-Schinzel sequences is then used to construct an independence set of size   Ω(nα(n))   in the matrices of size 2 n  ×  n  and  n  × 2 n . We also give two algorithms to find row maxima and minima in totally monotone partial  n  ×  m  matrices with the property that the non-blank entries in each column form a continuous segment ending at the bottom row. The first algorithm evaluates at most  O ( mα ( n ) +  n ) entries of the skyline matrix and performs at most that many comparisons, but may have  O ( mα ( n )log log  n  +  n ) total running time. The second algorithm is simpler and has  O ( m  log log  n  +  n ) total running time, but makes more comparisons, namely  O ( m  log log  n  +  n ), than the first.		Maria M. Klawe	1992	J. Algorithms	10.1016/0196-6774(92)90005-W	mathematical optimization;combinatorics;data structure;computational geometry;computer science;dynamic programming;calculus;mathematics;upper and lower bounds;programming language;algorithm;search algorithm	Theory	16.159590136701947	27.766661778310468	22660
c848c48488e7314b336ce5314f414a4373bda668	a new approach for solving the minimum cost flow problem with interval and fuzzy data	minimum cost flow problem;fuzzy data;network flows;interval and fuzzy numbers	In particular, imprecise observations or possible perturbations mean that data in a network flows may well be better represented by intervals or fuzzy numbers than crisp quantities. In this paper we first consider the minimum cost flow problem with compact interval-valued lower and upper bounds, flows, and costs. We present a new method that shows this problem is solved using two minimum cost flow problems with crisp data. Then this result is extended to networks with fuzzy lower and upper bounds, flows, and costs. One of the best algorithms to solve the minimum cost flow problem with crisp data is the cost scaling algorithm of Goldberg and Tarjan.17 In this paper, the cost scaling algorithm is modified for fuzzy lower and upper bounds, flows and costs. The running time of the modified algorithm is equal to the running time of the cost scaling algorithm with crisp data.	fuzzy logic;minimum-cost flow problem	Mehdi Ghiyasvand	2011	International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems	10.1142/S0218488511006897	mathematical optimization;combinatorics;discrete mathematics;flow network;minimum-cost flow problem;multi-commodity flow problem;fuzzy transportation;mathematics;fuzzy set operations	Robotics	21.30601610516552	9.524444822698245	22661
378a7e94ff4f4400e82212c448c2acb463a5ef29	separating regular languages by piecewise testable and unambiguous languages		Separation is a classical problem asking whether, given two sets belonging to some class, it is possible to separate them by a set from another class. We discuss the separation problem for regular languages. We give a Ptime algorithm to check whether two given regular languages are separable by a piecewise testable language, that is, whether a BΣ1(<) sentence can witness that the languages are disjoint. The proof refines an algebraic argument from Almeida and the third author. When separation is possible, we also express a separator by saturating one of the original languages by a suitable congruence. Following the same line, we show that one can as well decide whether two regular languages can be separated by an unambiguous language, albeit with a higher complexity.	algorithm;congruence of squares;first-order logic;first-order predicate;hoc (programming language);linear algebra;linear separability;p (complexity);regular language	Thomas Place;Lorijn van Rooijen;Marc Zeitoun	2013		10.1007/978-3-642-40313-2_64	combinatorics;formal language;discrete mathematics;pumping lemma for regular languages;mathematics;cone;abstract family of languages;programming language;generalized star height problem;algorithm	PL	-4.041401198591105	18.09635758251806	22667
202bd35f29d375a456035432c14f760d9ce9c9fe	finding independent sets in a graph using continuous multivariable polynomial formulations	independent set;continuous approach;dominating set;objective function;polynomial time algorithm;multivariate polynomial;maximal independent set;computer experiment;global optimization;maximum independent set	Two continuous formulations of the maximum independent set problem on a graph G = (V ,E) are considered. Both cases involve the maximization of an n-variable polynomial over the n-dimensional hypercube, where n is the number of nodes in G. Two (polynomial) objective functions F(x) and H(x) are considered. Given any solution to x0 in the hypercube, we propose two polynomial-time algorithms based on these formulations, for finding maximal independent sets with cardinality greater than or equal to F(x0) and H(x0), respectively. A relation between the two approaches is studied and a more general statement for dominating sets is proved. Results of preliminary computational experiments for some of the DIMACS clique benchmark graphs are presented.	benchmark (computing);clique problem;computation;dominating set;expectation–maximization algorithm;experiment;graph (discrete mathematics);independent set (graph theory);maximal set;polynomial;time complexity;universal quantification	James Abello;Sergiy Butenko;Panos M. Pardalos;Mauricio G. C. Resende	2001	J. Global Optimization	10.1023/A:1011968411281	mathematical optimization;combinatorics;discrete mathematics;independent set;dominating set;homogeneous polynomial;alternating polynomial;stable polynomial;wilkinson's polynomial;degree of a polynomial;mathematics;monic polynomial;maximal independent set;zero of a function;matrix polynomial;minimal polynomial;minimal polynomial;square-free polynomial;global optimization	Theory	23.39720005564494	15.900801134269013	22709
4b4c9b2ea6e2353c9cc176d04da914aa52e3e3d3	an approximation framework for bounded facility location problems		We study the bounded metric uncapacitated facility location (bUFL) problem and its two variants, the bounded fault-tolerant facility location (bFTFL) problem and the bounded fault-tolerant facility placement (bFTFP) problem. We propose a unified approximation framework built on the state-of-the-art approximation algorithms for the three unbounded counterparts, leading to a ((2.488 + epsilon ))-approximation algorithm for the bUFL problem in the Euclidean plane, a ((1.488+H(n)))-approximation algorithm for the bUFL problem, a ((1.725+H(n)))-approximation algorithm for the bFTFL problem, and a ((1.515+H(n)))-approximation algorithm for the bFTFP problem in a general metric space. We also prove an inapproximability result for all the three bounded facility location problems in a general metric space.	approximation;facility location problem	Wenchang Luo;Bing Su;Yao Xu;Guohui Lin	2018		10.1007/978-3-319-94776-1_30	discrete mathematics;facility location problem;metric space;approximation algorithm;bounded function;euclidean geometry;computer science	Theory	22.817521389315385	15.74564864685214	22722
496b7334ba3d24c621794ab0ab8bb8e6e073b4c4	optimal thresholds of an infinite buffer discrete-time two-server system with triadic policy		This paper analyzes a discrete-time infinite-buffer Geo/Geo/2 queue, in which the number of servers can be adjusted depending on the number of customers in the system one at a time at arrival or at service completion epoch. Analytical closed-form solutions of the infinite-buffer Geo/Geo/2 queueing system operating under the triadic (0, Q N, M) policy are derived. The total expected cost function is developed to obtain the optimal operating (0, Q N, M) policy and the optimal service rate at minimum cost using direct search method. Some performance measures and sensitivity analysis have been presented.	line search;loss function;queueing theory	Veena Goswami;G. B. Mund	2011	IJSDS	10.4018/jsds.2011100105	mathematical optimization;real-time computing;simulation;operations management	Metrics	8.803928762871196	9.67776759663423	22741
4997fc4b5b247b5a2a70ac634be47583418bf4c7	queueing models for computer systems with general service time distributions	queueing model		queueing theory	Annie W. Shum	1976			g-network;mean value analysis;m/d/c queue;bulk queue;layered queueing network;queueing theory;bcmp network	Theory	8.453654776210762	11.929553479234546	22743
b4aed9fc70687b9e44e8a45216cd412e4da0c531	the use of smart grids to increase the resilience of brazilian power sector to climate change effects		Climate change has been a much-commented subject in the last years. The energy sector is a major responsible for this event and one of the most affected by it. Increasing the participation of renewable is a way to mitigate these effects. However, a system with large share of renewables (like Brazil) is more vulnerable to climate phenomena. This article analyzes the implementation of smart grids as a strategy to mitigate and adapt the electricity sector to climate change. Different climate and energy sector scenarios were simulated using a bottom-up approach with an accounting model. The results show that smart grids can help save energy, increase network resilience to natural hazards and reduce operational, maintenance costs and investments in new utilities. It would also allow tariffs diminution because of generation and losses costs reductions.		Débora de São José;J. Nuno Fidalgo	2018		10.1007/978-3-319-78574-5_13	control engineering;renewable energy;psychological resilience;smart grid;natural hazard;environmental resource management;engineering;climate change	HCI	2.2742394552851803	6.954089426620588	22784
0d0599202561f2ca6d8d56008d29c1ad96c8238f	stochastic lot-sizing problem with deterministic demands and wagner-whitin costs	optimisation sous contrainte;dynamic programming;constrained optimization;programacion dinamica;polyhedral combinatorics;programacion entera;polyedre;matriz unimodular;poliedro;demande deterministe;programmation stochastique;polyhedron;unimodular matrix;programmation en nombres entiers;administracion deposito;optimisation combinatoire;optimizacion con restriccion;deterministic demand;integer programming;tamano lote;extended formulation;taille lot;demanda determinista;programmation dynamique;coste;gestion stock;lot sizing;matrice unimodulaire;integer program;combinatorial optimization;stochastic programming;inventory control;programacion estocastica;optimizacion combinatoria;cout	In this paper, we consider a two-stage stochastic uncapacitated lot-sizing problem with deterministic demands and Wagner-Whitin costs. We develop an extended formulation in the higher dimensional space that provides integral solutions by showing that its constraint matrix is totally unimodular. We also provide the integral polyhedron of the problem in the original space by projecting the extended formulation to the original space.		Zhili Zhou;Yongpei Guan	2010	Oper. Res. Lett.	10.1016/j.orl.2010.05.007	inventory control;stochastic programming;mathematical optimization;constrained optimization;combinatorics;integer programming;input/output;polyhedral combinatorics;combinatorial optimization;unimodular matrix;dynamic programming;calculus;mathematics;polyhedron	Theory	23.351525043853844	11.109762354871409	22851
6510203356894353215d5d50ab299e2df47031c5	defining cps challenges in a sustainable electricity grid	distributed system;distributed elements;solar asset;renewable energy;reconstituted supply portfolio;biomass production;duration curves;distribution network;iso;distributed networks;real time;energy network;renewable production;grid balancing;smart grid;cyber physical systems;power system management energy storage power grids power system economics;cps challenges;sustainable electricity grid;complex distributed systems;wind electricity iso biomass production wind power generation power grids;weather effects;power system management;california 2050 ghg target;power system economics;cyber physical system;market opportunities;energy storage;biomass;wind asset;power grid;production;electricity;renewable energy electricity cyber physical systems smart grid;power grids;demand shaping;load shifting;wind power generation;renewable penetration;resources demand management;resources demand management cps challenges sustainable electricity grid cyber physical system complex distributed systems distribution network transmission network fluctuating renewable supplies distributed elements solar asset wind asset weather effects california 2050 ghg target demand shaping reconstituted supply portfolio duration curves market opportunities energy network renewable production load shifting energy storage renewable penetration grid balancing resources supply management;resources supply management;wind;distributed control;fluctuating renewable supplies;supply and demand;transmission network	Cyber-Physical Systems (CPS) are characterized as complex distributed systems exhibiting substantial uncertainty due to interactions with the physical world. Today's electric grids are often described as CPS because a portfolio of distributed supplies must be dispatched in real-time to match uncontrolled, uncertain demand while adhering to constraints imposed by the intervening transmission and distribution network. With the increased control complexity required by deep penetration of fluctuating renewable supplies, the grid becomes more profoundly a CPS and needs to be addressed as a system. In this evolving CPS, a large fraction of supply is under-actuated, a substantial portion of demand needs to become dispatch able, interactions among distributed elements are no longer unidirectional, and operating requirements of elements are more dynamic. To more sharply define these CPS challenges, we obtain a yearlong, detailed measurement of the real-time blend of supplies on the primary California grid dispatched to meet current demand and then scale the solar and wind assets, preserving uncontrolled weather effects, to a level of penetration associated with California's 2050 GHG targets. In this representation of a future sustainable grid, we assess the impact of demand shaping, storage, and agility on the reconstituted supply portfolio, characterize resulting duration curves and ramping, and investigate the distributed control and management regime. We articulate new operational and market opportunities and challenges that may materialize from intermittent periods of abundance and scarcity in the overall energy network. We find that in a sustainable grid, lulls in renewable production during winter are more critical than peaks in demand during summer, capacity for load shifting and energy storage are more valuable as renewables penetration increases, and that grid balancing requires integrated management of supply and demand resources.	adobe air;agile software development;computer science;conference on embedded networked sensor systems;cyber-physical system;distributed computing;distributed control system;distributed element model;dvorak simplified keyboard;dynamic dispatch;embedded system;heart rate variability;hypertext transfer protocol;interaction;lu decomposition;noise shaping;proceedings of the ieee;real-time clock;real-time transcription;requirement;server farm;smart thermostat;uncontrolled format string	Jay Taneja;Randy H. Katz;David E. Culler	2012	2012 IEEE/ACM Third International Conference on Cyber-Physical Systems	10.1109/ICCPS.2012.20	computer science;electrical engineering;cyber-physical system	HPC	1.9975394976392207	6.445296171700707	22926
7c8a95354708d04b7825fcab5b97b7c2f09835ab	pursuing a superfast robber in an interval graph	approximate algorithm;interval graph;game playing	We consider a variant of Cops and Robbers game played on a connected interval graph G, where the robber has infinite speed but cannot run through a cop. It is shown that the number of cops needed to capture the robber is $O(|V(G)|^0.5)$. A graph is provided in which this many cops is indeed necessary. A 3-approximation algorithm for computing the cop number of an interval graph is also presented.		Abbas Mehrabian	2010	CoRR		mathematical optimization;factor-critical graph;combinatorics;discrete mathematics;interval graph;graph bandwidth;mathematics;distance-hereditary graph;circle graph	NLP	24.54546508891132	22.06904988998908	22935
e90ed3d469462368b6aef86db9e6835ccf5488bf	sat for pedestrians		The aim of this short note is mainly pedagogical. It summarizes some knowledge about Boolean satisfiability (SAT) and the P=NP? problem in an elementary mathematical language. A convenient scheme to visualize and manipulate CNF formulae is introduced. Also some results like the formulae for the number of unsatisfied clauses and the number of solutions might be unknown. Introduction. Specifically, I will formulate the problem of finding solutions for SAT in fairly elementary terms. Ordinary school calculus will be sufficient to do most of the calculations. One will see how the exponential character of the assignment space undermines any straightforward attempt of finding an efficient algorithm for the problem. Some new necessary conditions (“checks”) for a formula to be satisfiable (or not) will be deduced. Most checks can be calculated in polynomial time(“p.t.”). Their usefulness has not yet been tested for large formulae. The search for “efficient algorithms” (i.e. polynomial time procedures), is important for settling the “P=NP?” problem, one of the outstanding problems of 21 century mathematics. For a definition of complexity classes P and NP a vast amount of literature, both in print and online is available. A simple Google search will do more than necessary. The essence is: problems in class P can be solved on a classical Turing computer, and their running times are bounded by a polynomial in the length of the problem (suitably defined). The definition of NP, on the other hand, does not address the solution of	algorithm;boolean satisfiability problem;complexity class;conjunctive normal form;elementary;google search;np (complexity);p (complexity);p versus np problem;polynomial;time complexity;turing	Bernd R. Schuh	2014	CoRR		arithmetic;discrete mathematics;#sat;mathematics;algorithm	Theory	8.440027837709579	18.09378316333109	22971
3c148ef35cb9a8f0a919d53f5ceb3a6af4f5ab17	operation strategies and performance of air-conditioning systems with thermal energy storages in power systems	frequency regulation;cooling energy storage thermal energy power systems frequency control schedules minimization;conference_paper;frequency regulation capacity operation strategies air conditioning systems thermal energy storages power systems renewable energy sources res cost minimization load shifting;thermal energy storage air conditioning frequency control power systems renewable energy sources;load management;air conditioning system;frequency regulation thermal energy storage air conditioning system load management;thermal energy storage	Energy storage is one of the most effective measures to overcome the challenges from the massive integration of renewable energy sources (RESs) with high uncertainty. However, there still lacks inexpensive and feasible choices of energy storage for power systems. In this paper, a promising measure of energy storage, namely air-conditioning systems with thermal energy storage, is studied. Different operation strategies are proposed for this type of storage system considering the characteristics and needs of power systems, and the objective of the strategies includes cost minimization, load shifting and providing frequency regulation capacity. Simulation results demonstrate the feasibility and advantage of the storage system, and illustrate the performance of different operation strategies.	computer cooling;computer data storage;ibm power systems;load profile;operation payback;scheduling (computing);simulation	Yuchen Tang;Jin Zhong	2016	2016 Power Systems Computation Conference (PSCC)	10.1109/PSCC.2016.7540853	control engineering;energy recovery;energy technology;engineering;electrical engineering;operations management;distributed generation;pumped-storage hydroelectricity;intermittent energy source;grid energy storage	HPC	3.518075098249948	6.029811677314561	23001
2be41ad85c5a6fb994d2ff63eb96c47842a9b9e0	neural analysis of mobile radio access network	pattern clustering;call quality information;land mobile radio data mining clustering algorithms data visualization data analysis multiaccess communication laboratories information science prototypes data engineering;telecommunication computing self organising feature maps mobile radio data mining pattern clustering radio access networks;base stations;neural analysis;information science;multidimensional data visualization;spatiotemporal data;prototypes;one cell model;multidimensional data;telecommunication computing;data engineering;data mining;radio access network;data analysis;spatio temporal data;state vectors;land mobile radio;base sta tion;self organising feature maps;mobile radio;data visualization;self organizing map;operational states self organizing map multidimensional data clustering multidimensional data visualization neural analysis input vector transformation 2d prototype vector grid mobile radio access network spatiotemporal data base stations call quality information data analysis one cell model state vectors;clustering algorithms;2d prototype vector grid;self organized map;operational states;data consistency;input vector transformation;mobile network;mobile radio access network;multiaccess communication;radio access networks;multidimensional data clustering	The Self-Organizing Map (SOM) is an efficient tool for visualization and clustering of multidimensional data. It transforms the input vectors on two-dimensional grid of prototype vectors and orders them. The ordered prototype vectors are easier to visualize and explore than the original data. Mobile networks produce a huge amount of spatiotemporal data. The data consists of parameters of base stations (BS) and quality information of calls. There are two alternatives in starting the data analysis. We can build either a general one-cell-model trained using state vectors from all cells, or a model of the network using state vectors with parameters from all mobile cells. In both methods, further analysis is needed to understand the reasons for various operational states of the entire network.	cluster analysis;prototype;radio access network;self-organizing map	Kimmo Raivio;Olli Simula;Jaana Laiho	2001		10.1109/ICDM.2001.989552	radio access network;cellular network;self-organizing map;information science;computer science;data science;base station;machine learning;data mining;prototype;cluster analysis;data analysis;data consistency;data visualization	ML	-1.7511467607130555	28.734667888320484	23006
0b966192f7f5a553224d5c8bec8aa406f3e2008f	from ebnf to peg	linear systems;computer systems;language;programming languages	Parsing Expression Grammar (PEG) is a way to define a recursive-descent parser with limited backtracking. Its properties are useful in many applications. In spite of its apparent similarity to Extended Backus-Naur Form (EBNF), PEG often defines quite a different language, sometimes difficult to describe exactly. However, a recent result by Medeiros shows that an EBNF grammar having the LL(1) property can be transcribed verbatim into a PEG that not only defines the same language, but also parses the input in exactly the same way. We show that such transcription is possible for a wider class of EBNF grammars, which is interesting because the backtracking of PEG is often a convenient way to circumvent just the LL(1) restriction.	backtracking;parsing expression grammar;recursion;recursive descent parser;transcription (software)	Roman R. Redziejowski	2012	Fundam. Inform.	10.3233/FI-2013-940	natural language processing;parser combinator;ll grammar;parsing expression grammar;operator-precedence grammar;top-down parsing language;computer science;parsing;glr parser;language;linear system;programming language;attribute grammar;recursive descent parser;top-down parsing;algorithm	PL	-2.2618927852453847	17.47132380506149	23056
f1dccd388206870b3cff0c9b718a911d6f4ef7ee	the problem of assigning students to course sections in a large engineering school	assignment;universite;planificacion integral;integrated planning;algorithme;algorithm;algorritmo;planificacion;probleme combinatoire;problema combinatorio;afectacion;planning;affectation;university;combinatory problem;planification;universidad;ordonnancement	Abstract   In some universities, complete course schedules are made available to students at the time of registration. Typically these schedules give the room number, instructor and time for each session. Students use this information to select their courses. A computer program then allocates students to course sections so as to provide students with satisfactory schedules, to equalize roughly the number of students in all sections of the same course and to respect room capacities. The authors designed and implemented such a program at the Ecole Polytechnique de Montreal, one of Canada's leading Engineering Schools.		Gilbert Laporte;Sylvain Desroches	1986	Computers & OR	10.1016/0305-0548(86)90025-0	mathematics education;planning;simulation;computer science;artificial intelligence;assignment;mathematics;integrated business planning	DB	18.067774102768666	8.116038318165863	23102
960bfa0d55f723c3adc143d90088946d686137fb	distributed real-time pricing control for large-scale unidirectional v2g with multiple energy suppliers	pricing;pricing battery powered vehicles power grids power markets;greedy behavior distributed real time pricing control large scale unidirectional v2g multiple energy suppliers plug in hybrid vehicles plug in electric vehicles electric energy market responsive load grid stability renewable integration controllable devices central vehicle to grid management central v2g management distributed approach optimal management unidirectional v2g charging station energy supplier local price regulator charging rates energy suppliers;unidirectional v2g consensus networks demand response distributed control distributed optimization karush kuhn tucker kkt conditions;vehicles indexes optimization pricing regulators real time systems linear programming;indexes;linear programming;optimization;vehicles;regulators;real time systems	With the increasing trend in adoption of plug-in hybrid and plug-in electric vehicles, they will play a prominent role in the future electric energy market by acting as responsive loads to increase the grid stability and facilitate the integration of renewables. However, due to the large number of controllable devices in the future grid, central vehicle to grid (V2G) management would be challenging and vulnerable to single points of failure. This paper introduces a novel distributed approach for optimal management of unidirectional V2G considering multiple energy suppliers. Each charging station as well as each energy supplier is equipped with a local price regulator to control the price paid to the energy suppliers and the price paid by the vehicles through coordination with their neighbors. In response to the updated prices, the vehicles adjust their charging rates and energy suppliers adjust their production to maximize their benefit. The main advantages of the proposed approach are that it manages unidirectional V2G in a fully distributed way considering multiple energy suppliers and vehicles, and it converges to the global optimum despite the greedy behavior of the individuals.	global optimization;greedy algorithm;plug-in (computing);real-time clock;reliability engineering;single point of failure	Navid Rahbari Asr;Mo-Yuen Chow;Jiming Chen;Ruilong Deng	2016	IEEE Transactions on Industrial Informatics	10.1109/TII.2016.2569584	pricing;database index;mathematical optimization;simulation;computer science;linear programming	Robotics	2.2536991517809963	4.73649202678585	23111
6d248d20660602f34b87b2e9a597dbc3be06cd3a	densest subgraph in dynamic graph streams		In this paper, we consider the problem of approximating the densest subgraph in the dynamic graph stream model. In this model of computation, the input graph is defined by an arbitrary sequence of edge insertions and deletions and the goal is to analyze properties of the resulting graph given memory that is sub-linear in the size of the stream. We present a single-pass algorithm that returns a (1 + ) approximation of the maximum density with high probability; the algorithm uses O( −2npolylog n) space, processes each stream update in polylog(n) time, and uses poly(n) post-processing time where n is the number of nodes. The space used by our algorithm matches the lower bound of Bahmani et al. (PVLDB 2012) up to a poly-logarithmic factor for constant . The best existing results for this problem were established recently by Bhattacharya et al. (STOC 2015). They presented a (2 + ) approximation algorithm using similar space and another algorithm that both processed each update and maintained a (4 + ) approximation of the current maximum density in polylog(n) time per-update.	approximation algorithm;model of computation;symposium on theory of computing;video post-processing;with high probability	Andrew McGregor;David Tench;Sofya Vorotnikova;Hoa T. Vu	2015		10.1007/978-3-662-48054-0_39	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	20.904077650296852	22.201726533709998	23118
f5b7d0bde33e7fb468202a57f0d08b7d8375c4de	minimizing total completion time in a two-machine flow shop with deteriorating jobs	optimal solution;total completion time;methode branch and bound;solution optimale;matematicas aplicadas;simple linear deterioration;mathematiques appliquees;execution time;branch and bound algorithm;flow shop scheduling;temps completion totale;processing time;atelier multigamme;deterioration lineaire simple;scheduling;solucion optima;timing optimization;borne inferieure;temps traitement;temps execution;job shop;tiempo ejecucion;applied mathematics;atelier monogamme;tiempo proceso;ordonnancement;flow shop;lower bound;algorithme heuristique;heuristic algorithm;reglamento;cota inferior	This paper considers a two-machine flow shop scheduling problem with deteriorating jobs. By a deteriorating job, we mean that the processing time of a job is an increasing function of its execution start time. A simple linear deterioration function is assumed. The objective is to find a sequence that minimizes total completion time. Optimal solutions are obtained for some special cases. For the general case, several dominance properties and two lower bounds are derived to speed up the elimination process of a branch-and-bound algorithm. A heuristic algorithm is also proposed to overcome the inefficiency of the branch-and-bound algorithm. Computational results show that the proposed heuristic algorithm performs effectively and efficiently.	job stream	Ji-Bo Wang;Cai Tong Ng;T. C. Edwin Cheng;Li-Li Liu	2006	Applied Mathematics and Computation	10.1016/j.amc.2005.11.162	mathematical optimization;flow shop scheduling;artificial intelligence;mathematics;algorithm	Theory	17.32076855648703	9.54177744361092	23122
31146d49035e0bcd38ad1a658495415fdc38e185	optimization of wind power producer participation in electricity markets with energy storage in a way of energy 4.0		This paper proposes a problem formulation to aid as a support information management system of a wind power producer having energy storage devices and participating in electricity markets. Energy storage can play an important role in the reduction of uncertainties faced by a wind power producer. Excess of conversion of wind energy into electric energy can be stored and then released at favorable hours. Energy storage provides capability for arbitrage and increases the revenue of the wind power producers participating in electricity markets. The formulation models the wind power and the market prices as stochastic processes represented by a set of convenient scenarios. The problem is solved by a powerful stochastic mixed integer linear programming problem. A case study using data from the Iberian Electricity Market is presented to show the aid of the formulation.		Isaías L. R. Gomes;Hugo M. I. Pousinho;Rui Melício;Victor M. F. Mendes	2017		10.1007/978-3-319-67180-2_9	stand-alone power system;renewable energy;wind power;electricity retailing;electricity market;pumped-storage hydroelectricity;distributed generation;business;microeconomics;energy development	Mobile	3.2396667545096958	4.785242826424673	23135
ee4a4d5fb85dc6327ff50ca5877066636b9f535d	on infinite words determined by stack automata	004;stack automaton infinite word pumping lemma prefix language multihead finite automaton	We characterize the infinite words determined by one-way stack automata. An infinite language L determines an infinite word α if every string in L is a prefix of α. If L is regular or context-free, it is known that α must be ultimately periodic. We extend this result to the class of languages recognized by one-way nondeterministic checking stack automata (1-NCSA). We then consider stronger classes of stack automata and show that they determine a class of infinite words which we call multilinear. We show that every multilinear word can be written in a form which is amenable to parsing. Finally, we consider the class of one-way multihead deterministic finite automata (1:multi-DFA). We show that every multilinear word can be determined by some 1:multi-DFA, but that there exist infinite words determined by 1:multi-DFA which are not multilinear. 1998 ACM Subject Classification F.1.1 Models of Computation, F.4.3 Formal Languages	automata theory;computation;context-free language;deterministic finite automaton;existential quantification;finite-state machine;omega language;one-way function;parsing;pushdown automaton	Tim Smith	2013		10.4230/LIPIcs.FSTTCS.2013.413	combinatorics;nested stack automaton;discrete mathematics;computer science;nested word;ω-automaton;mathematics;algorithm	Theory	-1.3687275934900938	20.675596843950046	23283
3e79666bb215b2007765d31ab4648e00f9d4e43d	an average analysis of backtracking on random constraint satisfaction problems	asymptotic estimates;average complexity;backtracking algorithms;satisfiability;analysis of algorithm;artificial intelligent;analysis of algorithms;search trees;standard model;computational complexity;csp;constraint satisfaction problem	In this paper we propose a random CSP model, called Model GB, which is a natural generalization of standard Model B. This paper considers Model GB in the case where each constraint is easy to satisfy. In this case Model GB exhibits non-trivial behaviour (not trivially satisfiable or unsatisfiable) as the number of variables approaches infinity. A detailed analysis to obtain an asymptotic estimate (good to 1+o(1)) of the average number of nodes in a search tree used by the backtracking algorithm on Model GB is also presented. It is shown that the average number of nodes required for finding all solutions or proving that no solution exists grows exponentially with the number of variables. So this model might be an interesting distribution for studying the nature of hard instances and evaluating the performance of CSP algorithms. In addition, we further investigate the behaviour of the average number of nodes as r (the ratio of constraints to variables) varies. The results indicate that as r increases, random CSP instances get easier and easier to solve, and the base for the average number of nodes that is exponential in n tends to 1 as r approaches infinity. Therefore, although the average number of nodes used by the backtracking algorithm on random CSP is exponential, many CSP instances will be very easy to solve when r is sufficiently large.	algorithm;backtracking;communicating sequential processes;constraint satisfaction;search tree;time complexity	Ke Xu;Wei Li	2001	Annals of Mathematics and Artificial Intelligence	10.1023/A:1012328830929	standard model;mathematical optimization;combinatorics;discrete mathematics;computer science;analysis of algorithms;machine learning;communicating sequential processes;mathematics;computational complexity theory;constraint satisfaction problem;algorithm;satisfiability	AI	11.560575565522397	18.47894191100615	23318
d621b94116845c94743fe5996eda2803f0fe1263	real-world applications of shortest path algorithms			algorithm;shortest path problem	Jose L. Santos	2006			mathematical optimization;euclidean shortest path;longest path problem;shortest path faster algorithm;k shortest path routing;yen's algorithm;widest path problem;shortest path problem;computer science;constrained shortest path first	Theory	20.458143094450477	29.711775789303168	23335
ed8374a13697cfaeddd079d9c7e509718ba59ac4	an extended earley's algorithm for petri net controlled grammars without λ rules and cyclic rules	context sensitive grammar;context free grammar;earley s algorithm;petri net;controlled grammar	In this paper we introduce an algorithm which solves the membership problem of Petri net controlled grammars without @l-rules and cyclic rules. We define a conditional tree which is a modified derivation tree of a context-free grammar with information about control by a Petri net. It is shown that a conditional tree is cancelled to a derivation tree without conditions if and only if there is a derivation under the control of the Petri net from the start symbol to a word which is the yielding of the conditional tree. Then the Earley's algorithm is extended to make a conditional tree in addition to parse a word. Thus the word is generated by a given Petri net controlled grammar if and only if the resulting conditional tree is cancelled to a tree of no condition. The time complexity of the algorithm is nondeterministic polynomial of the length of an input word. Therefore the class of languages generated by Petri net controlled grammars without @l-rules and cyclic rules is included in the class of context-sensitive languages.	algorithm;earley parser;petri net	Taishin Y. Nishida	2012	Theor. Comput. Sci.	10.1016/j.tcs.2012.04.043	natural language processing;context-sensitive grammar;computer science;regular tree grammar;context-free grammar;programming language;petri net;algorithm	ECom	-1.8460824079357152	19.251682648817592	23337
fa519179f042c9b75a957a2f7b739f6a8b48001b	efficient algorithms for vertex arboricity of planar graphs	efficient algorithm;linear time algorithm;graph coloring;planar graph	Acyclic-coloring of a graph G = (V,E) is a partitioning of V, such that the induced subgraph of each partition is acyclic. The minimum number of such partitions of V is defined as the vertex arboricity of G. A linear time algorithm for acyclic-coloring of planar graphs with 3 colors is presented. Next, an O(n2) algorithm is proposed which produces a valid acyclic-2-coloring of a planar graph, if one exists, since there are planar graphs with arboricity 3.	arboricity	Abhik Roychoudhury;Susmita Sur-Kolay	1995		10.1007/3-540-60692-0_39	degeneracy;1-planar graph;outerplanar graph;graph power;pathwidth;mathematical optimization;combinatorics;arboricity;discrete mathematics;polyhedral graph;graph bandwidth;dense graph;edge coloring;nowhere-zero flow;graph coloring;planar straight-line graph;mathematics;voltage graph;butterfly graph;list coloring;graph minor;book embedding;line graph;planar graph	Theory	24.427825795089632	27.521369526632967	23356
c81dfdb087ab847e1a9b1a07dfa31b58727ec408	sublinear merging and natural merge sort	sorting algorithm	"""The complexity of merging two sorted sequences into one is linear in the worst case as well as in the average case. There are, however, instances for which a sublinear number of comparisons is sufficient. We consider the problem of measuring and exploiting such instance easiness. The merging algorithm presented, Adaptmerge, is shown to optimally adapt to different kinds of measures of instance easiness. In the sorting problem, the concept of instance easiness has received a lot of attention and is interpreted by a measure of presortedhess. We apply Adaptmerge in the already adaptive sorting algorithm Natural Merge Sort. The resulting algorithm optimally adapts to several, known and new, measures of presortedness. We also prove some interesting results concerning the relation between measures of presortedness proposed in the literature. 1 In troduc t ion It is well known that, in the worst case, ~(mlog((n + m)/m)) time is necessary for merging two sorted sequences X and Y of length n and m, respectively, m < n, into one, in a comparisonbased model of computation [3]. This lower bound is based on the assumption that X is a randomly chosen subsequence of length n out of a sorted sequence of length m + n. In many applications this is not the situation. For example, it might be enough to merge a small portion in the end of X with a small portion in the beginning of Y, that is, there is just a small """"overlap"""" between X and Y, or the sorted output might be obtained by simply splitting X into a small number of parts amt inserting parts of Y in between. Such instances of the merging problem are in some sense easier and can be computed faster than the above lower bound indicates. Most worst-case optimal merging algorithms do not take this into account. In order to be able to take advantage of such """"instance easiness"""", or preorder, we must be more precise by what it means. We examine two different approaches for measuring preorder for the merging problem. The first, Maz, measures the maximum distance that an element is from its correct position. The second, NS, tells how many elements in X and Y that receive a new successor in the merged sequence. Further, we provide an algorithm, Adaptmerge, which adapts to these measures. Intuitively, a merging algorithm is adaptive with respect to a measure of preorder if it merges all instances but performs particularly well on those that have a high degree of preorder (without knowing the value of the measure beforehand). Adaptmerge completes the merge in time the minimum of O(Max(X,Y)) and O(NS(X,Y)log((n + m)/gs(x,Y))), which is optimal with respect to Max and NS. Here, optimality with respect to a measure means maximum adaptation (in an asymptotic sense). In the worst case Adaptmerge performs O(mlog((n + m)/m)) comparisons which matches the aforementioned lower bound. The main idea in Adaptmerge is to use exponential and binary search [7] iteratively to locate the positions in which the two sequences have to be split. *Algorithm Theory Group, Department of Computer Science, Lund University, Box 118, S-221 00 Lund, Sweden."""	best, worst and average case;binary search algorithm;computer science;in the beginning... was the command line;merge algorithm;merge sort;model of computation;randomness;sorting algorithm;time complexity	Svante Carlsson;Christos Levcopoulos;Ola Petersson	1990		10.1007/3-540-52921-7_74	adaptive sort;discrete mathematics;machine learning;mathematics;algorithm	Theory	16.823476027098707	16.90310341011149	23365
5cb2d8c902805fc819ad34a9d7176c344e264e4b	a potential-based amortized analysis of the union-find data structure	potential functions;amortized analysis;disjoint sets;ackermann s function;tarjan s multiple partitioning;potential function;data structure	We present a simple, new potential-based amortized analysis for the standard union-find data structure.	amortized analysis;disjoint-set data structure	Gregory C. Harfst;Edward M. Reingold	2000	SIGACT News	10.1145/356458.356463	potential method;combinatorics;discrete mathematics;amortized analysis;data structure;computer science;disjoint sets;splay tree;disjoint-set;mathematics;programming language;algorithm	Theory	16.885499119637444	28.123180378139708	23413
ed8462cd006124f4ce6ecc82846391808a86b0df	a benders decomposition approach for the robust spanning tree problem with interval data	metodo descomposicion;arbre maximal;methode decomposition;interval data;optimisation combinatoire;benders decomposition;decomposition method;cost minimization;telecomunicacion;arbol maximo;model uncertainty;robustesse;telecommunication;minimum spanning tree;arbre recouvrant minimal;minimum spanning tree mst;robustness;spanning tree;combinatorial optimization;high light;optimizacion combinatoria;robustez	The robust spanning tree problem is a variation, motivated by telecommunications applications, of the classic minimum spanning tree problem. In the robust spanning tree problem edge costs lie in an interval instead of having a fixed value. Interval numbers model uncertainty about the exact cost values. A robust spanning tree is a spanning tree whose total cost minimizes the maximum deviation from the optimal spanning tree over all realizations of the edge costs. This robustness concept is formalized in mathematical terms and is used to drive optimization. This paper describes a new exact method, based on Benders decomposition, for the robust spanning tree problem with interval data. Computational results highlight the efficiency of the new method, which is shown to be very fast on all the benchmarks considered, and in particular on those that were harder to solve for the methods previously known.	benchmark (computing);benders decomposition;computation;exact algorithm;experiment;fastest;file spanning;mathematical optimization;minimum spanning tree	Roberto Montemanni	2006	European Journal of Operational Research	10.1016/j.ejor.2005.02.060	benders' decomposition;segment tree;euclidean minimum spanning tree;mathematical optimization;combinatorics;discrete mathematics;kruskal's algorithm;decomposition method;minimum degree spanning tree;spanning tree;prim's algorithm;combinatorial optimization;minimum spanning tree;gomory–hu tree;incremental decision tree;interval tree;connected dominating set;k-minimum spanning tree;mathematics;reverse-delete algorithm;distributed minimum spanning tree;robustness	Theory	23.39809675200437	16.886173298724028	23508
0b83665a4ebfb6abd153ebdf516cf2c2566a269a	kernelization and complexity results for connectivity augmentation problems	combinatorial problems;satisfiability;connected graph;polynomial time;data reduction;np complete problem	Connectivity augmentation problems ask for adding a set of at most k edges whose insertion makes a given graph satisfy a specified connectivity property, such as bridge-connectivity or biconnectivity. We show that, for bridge-connectivity and biconnectivity, the respective connectivity augmentation problems admit problem kernels with O(k) vertices and links. Moreover, we study partial connectivity augmentation problems, naturally generalizing connectivity augmentation problems. Here, we do not require that, after adding the edges, the entire graph should satisfy the connectivity property, but a large subgraph. In this setting, two polynomial-time solvable connectivity augmentation problems behave differently, namely, the partial biconnectivity augmentation problem remains polynomial-time solvable whereas the partial strong connectivity augmentation problem becomes W[2]-hard with respect to k.	biconnected graph;decision problem;induced subgraph;kernelization;polynomial;time complexity	Jiong Guo;Johannes Uhlmann	2007		10.1007/978-3-540-73951-7_42	time complexity;mathematical optimization;combinatorics;data reduction;discrete mathematics;np-complete;computer science;connectivity;mathematics;algorithm;satisfiability	Theory	23.41414412200546	23.606275722327975	23530
a18e7d1b65e9f6c21295574353a623e49be6502e	handle-rewriting hypergraph grammars	hipergrafico;gramatica grafo;punto fijo;gramatica cf;grammaire cf;grafo;grammaire graphe;graph grammar;context free grammar;point fixe;informatique theorique;reecriture;graph;graphe;hypergraph;rewriting;fix point;reescritura;hypergraphe;computer theory;informatica teorica	We introduce the handle-rewriting hypergraph grammars (HH grammars), based on the replacement of handles, i.e., of subhypergraphs consisting of one hyperedge together with its incident vertices. This extends hyperedge replacement, where only the hyperedge is replaced. A HH grammar is separated (an S-HH grammar) if nonterminal handles do not overlap. The S-HH grammars are context-free, and the sets they generate can be characterized as the least solutions of certain systems of equations. They generate the same sets of graphs as the NLC-like vertex-rewriting C-edNCE graph grammars that are also context-free.	rewriting	Bruno Courcelle;Joost Engelfriet;Grzegorz Rozenberg	1993	J. Comput. Syst. Sci.	10.1016/0022-0000(93)90004-G	context-sensitive grammar;tree-adjoining grammar;indexed grammar;combinatorics;discrete mathematics;l-attributed grammar;deterministic context-free grammar;rewriting;computer science;mathematics;graph;context-free grammar;programming language;embedded pushdown automaton;algorithm	Theory	-4.073083930680427	20.776469125613385	23541
ecaa0d5a6369bec41487f76b402829c128c30343	a deterministic truthful ptas for scheduling related machines	algorithmic game theory;90d;algorithmic mechanism design;related machine scheduling;truthful scheduling mechanisms;68w	Scheduling on related machines (Q||Cmax) is one of the most important problems in the field of Algorithmic Mechanism Design. Each machine is controlled by a selfish agent and her valuation function can be expressed via a single parameter, her speed. Archer and Tardos [3] showed that, in contrast to other similar problems, a (non-polynomial) allocation that minimizes the makespan can be truthfully implemented. On the other hand, if we leave out the gametheoretic issues, the complexity of the problem has been completely settled — the problem is strongly NP-hard, while there exists a PTAS [9, 8]. This problem is the most well-studied in single-parameter Algorithmic Mechanism Design. It gives an excellent ground to explore the boundary between truthfulness and efficient computation. Since the work of Archer and Tardos, quite a lot of deterministic and randomized mechanisms have been suggested. Recently, a breakthrough result [7] showed that a randomized, truthful-in-expectation PTAS exists. On the other hand, for the deterministic case, the best known approximation factor is 2.8 [10, 11]. It has been a major open question whether there exists a deterministic truthful PTAS, or whether truthfulness has an essential, negative impact on the computational complexity of the problem. In this paper we give a definitive answer to this important question by providing a truthful deterministic PTAS.	approximation;computation;computational complexity theory;makespan;np-hardness;ptas reduction;polynomial;randomized algorithm;scheduling (computing);strong np-completeness;value (ethics)	George Christodoulou;Annamária Kovács	2013	SIAM J. Comput.	10.1137/120866038	algorithmic mechanism design;mathematical optimization;combinatorics;computer science;theoretical computer science;mathematics;distributed computing;algorithmic game theory;algorithm	Theory	14.734175241427407	12.260902873727703	23555
762c4774c424d70c0f535086fac09b43e718a125	daily clearness index profiles cluster analysis for photovoltaic system		Due to various weather perturbation effects, the stochastic nature of real-life solar irradiance has been a major issue for solar photovoltaic (PV) system planning and performance evaluation. This paper aims to discover clearness index (CI) patterns and to construct centroids for the daily CI profiles. This will be useful in being able to provide a standardized methodology for PV system design and analysis. Four years of solar irradiance data collected from Johannesburg (26.21 S, 28.05 E), South Africa are used for the case study. The variation in CI could be significant in different seasons. In this paper, cluster analysis with Gaussian mixture models (GMM), K-Means with Euclidean distance (ED), K-Means with Manhattan distance, Fuzzy C-Means (FCM) with ED, and FCM with dynamic time warping (FCM DTW) are performed for the four seasons. A case study based on sizing a stand-alone solar PV and storage system with anaerobic digestion biogas power plants is used to examine the usefulness of the clustering results. It concludes that FCM DTW and GMM can determine the correct PV farm rated capacity with an acceptable energy storage capacity, with 36 and 46 rather than 1457 solar irradiance profiles, respectively.	cluster analysis;computer data storage;dynamic time warping;euclidean distance;fuzzy clustering;fuzzy cognitive map;google map maker;k-means clustering;mixture model;performance evaluation;real life;server farm;systems design;taxicab geometry	Chun Sing Lai;Youwei Jia;Malcolm D. McCulloch;Zhao Xu	2017	IEEE Transactions on Industrial Informatics	10.1109/TII.2017.2683519	statistics;real-time computing;computer science;mixture model;solar irradiance;nameplate capacity;euclidean distance;cluster analysis;dynamic time warping;photovoltaic system	SE	2.870718722432901	8.770314736580087	23565
4033b226f0a87d72ec4b700b0eff97df124ba13a	prams over integers do not compute maxflow efficiently		Finding lower bounds in complexity theory has proven to be an extremely difficult task. In this article, we analyze two proofs of complexity lower bound: Ben-Or’s proof of minimal height of algebraic computational trees deciding certain problems and Mulmuley’s proof that restricted Parallel Random Access Machines (prams) over integers can not decide P-complete problems efficiently. We present the aforementioned models of computation in a framework inspired by dynamical systems and models of linear logic : graphings. This interpretation allows to connect the classical proofs to topological entropy, an invariant of these systems; to devise an algebraic formulation of parallelism of computational models; and finally to strengthen Mulmuley’s result by separating the geometrical insights of the proof from the ones related to the computation and blending these with Ben-Or’s proof. Looking forward, the interpretation of algebraic complexity theory as dynamical system might shed a new light on research programs such as Geometric Complexity Theory.	alpha compositing;complex adaptive system;computational complexity theory;computational model;dynamical system;geometric complexity theory;ketan mulmuley;linear algebra;linear logic;maximum flow problem;model of computation;p-complete;parallel computing;random access;topological entropy	Luc Pellissier;Thomas Seiller	2018	CoRR			Theory	3.887072492020211	19.7692898170909	23583
be5a33dd5f429d04d42982c5f38b672cdb42d289	the density of weakly complete problems under adaptive reductions	polynomial reductions;circuits lifting equipment computer science computational complexity polynomials;sparse languages;polynomials;computational complexity weakly complete problems adaptive reductions real number;weakly complete problems;computational complexity;resource bounded measure;complexity classes;lifting equipment;circuits;computer science;dense languages;real number;adaptive reductions;weak completeness	Given a real number /spl alpha/<1, every language that is weakly /spl les//sub n/spl alpha//2-T//sup P/-hard for E or weakly /spl les//sub n/spl alpha/-T//sup P/-hard for E/sub 2/ is shown to be exponentially dense. This simultaneously strengthens results of J.H. Lutz and E. Mayordomo (1994) and B. Fu (1995).		Jack H. Lutz;Yong Zhao	1997		10.1109/CCC.1997.612306	complexity class;electronic circuit;combinatorics;discrete mathematics;computer science;theoretical computer science;machine learning;mathematics;computational complexity theory;algorithm;real number;polynomial;lifting equipment	Theory	7.507716880617551	21.218102993115846	23666
119a5b3c44fbe5ab0553df660588d67da8a1876b	parameterized algorithms for graph partitioning problems	parameterized algorithm;graph partitioning;representative family;random separation	We study a broad class of graph partitioning problems. Each problem is defined by two constants, α 1 and α 2. The input is a graph G, an integer k and a number p, and the objective is to find a subset U ⊆ V $U\subseteq V$ of size k, such that α 1 m 1 + α 2 m 2 is at most (or at least) p, where m 1, m 2 are the cardinalities of the edge sets having both endpoints, and exactly one endpoint, in U, respectively. This class of fixed-cardinality graph partitioning problems (FGPPs) encompasses Max (k, n − k)-Cut, Min k-Vertex Cover, k-Densest Subgraph, and k-Sparsest Subgraph. Our main result is a 4 k + o(k)Δ k ⋅n O(1) time algorithm for any problem in this class, where Δ ≥ 1 is the maximum degree in the input graph. This resolves an open question posed by Bonnet et al. (Proc. International Symposium on Parameterized and Exact Computation, 2013). We obtain faster algorithms for certain subclasses of FGPPs, parameterized by p, or by (k + p). In particular, we give a 4 p + o(p)⋅n O(1) time algorithm for Max (k, n − k)-Cut, thus improving significantly the best known p p ⋅n O(1) time algorithm by Bonnet et al.	algorithm;communication endpoint;computation;esa;graph (discrete mathematics);graph partition;vertex cover	Hadas Shachnai;Meirav Zehavi	2016	Theory of Computing Systems	10.1007/s00224-016-9706-0	mathematical optimization;factor-critical graph;combinatorics;discrete mathematics;graph factorization;mathematics;algorithm	Theory	23.555198038046033	22.908913160168463	23704
22f5ef2c28641d15ac1321c3d53942b43e50bd75	finding an optimal path without growing the tree	camino mas corto;dynamic programming;graph theory;shortest path;complejidad espacio;programacion dinamica;probleme sac a dos;algorithm complexity;algorithm analysis;geometrie algorithmique;efficient algorithm;complejidad algoritmo;space efficient algorithm;computational geometry;plus court chemin;dynamic program;tree data structures;problema mochila;camino optimo;structure donnee arborescente;chemin optimal;optimisation combinatoire;knapsack problem;optimal path;complexite algorithme;algorithme espace efficace;informatique theorique;scheduling;programmation dynamique;arreglo;space complexity;geometria computacional;analyse algorithme;arrangement;complexite espace;combinatorial optimization;data structure;analisis algoritmo;ordonnancement;reglamento;optimizacion combinatoria;computer theory;informatica teorica	"""In this paper, we study a class of optimal path problems with the following phenomenon: The space complexity of the algorithms for reporting the lengths of single-source optimal paths for these problems is asymptotically smaller than the space complexity of the """"standard"""" treegrowing algorithms for finding actual optimal paths. We present a general and efficient algorithmic paradigm for finding an actual optimal path for such problems without having to grow a single-source optimal path tree. Our paradigm is based on the """"marriage-before-conquer"""" strategy, the prune-and-search technique, and a data structure called clipped trees. The paradigm enables us to compute an actual path for a number of optimal path problems and dynamic programming problems in computational geometry, graph theory, and combinatorial optimization. Our algorithmic solutions improve the space bounds (in certain cases, the time bounds as well) of the previously best known algorithms, and settle some open problems. Our techniques are likely to be applicable to other problems."""		Danny Ziyi Chen;Ovidiu Daescu;Xiaobo Sharon Hu;Jinhui Xu	1998		10.1007/3-540-68530-8_30	mathematical optimization;combinatorics;fast path;data structure;any-angle path planning;longest path problem;computational geometry;combinatorial optimization;computer science;graph theory;dynamic programming;mathematics;tree;dspace;shortest path problem;knapsack problem;scheduling;algorithm	HPC	17.288938385160527	27.12950427957857	23729
a0c82b48e89775a0b444c6d2e8fd937b9c43600b	impossibility results for weak threshold networks	tratamiento paralelo;traitement parallele;distributed computing;impossibility results;distributed computer systems;systeme informatique reparti;parallel processing;lower bound	It is shown that a weak threshold network in particular threshold network of width w and depth d cannot be constructed from balancers of width p p pm if w does not divide P d where P is the least common multiple of p p pm This holds regardless of the size of the network as long as it is nite and it implies a lower bound of logP w on its depth More strongly a lower bound of logpmax w is shown on the length of every path from an input wire to any output wire that exhibits the threshold property where pmax is the maximum among p p pm	decstation;logp machine	Costas Busch;Marios Mavronicolas	1997	Inf. Process. Lett.	10.1016/S0020-0190(97)00096-3	parallel processing;combinatorics;discrete mathematics;computer science;mathematics;upper and lower bounds;algorithm	Theory	6.772481299351126	24.815947128138102	23737
509dc1f3f71627efd215a13541c23ce7a4106911	randomized approximation schemes for scheduling unrelated parallel machines	randomized rounding;linear time;approximation scheme;parallel machines	The problem of Scheduling n Independent Jobs on m Unrelated Parallel Machines, when the number of machines m is xed, is considered. The standard problem of minimizing the makespan of the schedule (SUM) and the bicriteria problem of scheduling with bounded makespan and cost (SUMC) are addressed, and randomized fully linear time approximation schemes are shown for both of them. While matching the approximation guarantee and the complexity of the best known sequential results of Jansen and Porkolab ((12]), the proposed algorithms exhibit a signiicantly simpler and more general rounding scheme, especially for the bicriteria SUMC problem, and admit simple optimal work parallelizations 1 of O(log n){time complexity. The core of the algorithms, which also draw techniques from other related works ((12], 11], 1]), is an interesting new randomized rounding procedure, the Filtered Randomized Rounding (FRR). In the settings of the problems considered, FRR boosts the deviation bounds of the rounded linear packing constraints to any given constant ratio. Finally, the notion of poly{bottleneck combinatorial optimization problems is deened and used to build O(n log n log log n) time approximation schemes for two natural optimization versions of SUMC, that is minimizing the makespan when the cost of the schedule is bounded (SUMCoptT) and minimizing the cost when the makespan is bounded (SUMCoptC). These algorithms too, admit simple optimal work parallelizations. 1 Optimal work parallelization means that the parallel work (product of running time and number of processors) is equal to the sequential running time.	approximation;central processing unit;combinatorial optimization;makespan;mathematical optimization;parallel computing;randomized algorithm;randomized rounding;scheduling (computing);set packing;time complexity	Pavlos S. Efraimidis;Paul G. Spirakis	2000	Electronic Colloquium on Computational Complexity (ECCC)		time complexity;mathematical optimization;randomized rounding;computer science;theoretical computer science;mathematics;distributed computing;algorithm	Theory	15.616639852055082	11.482101159012759	23751
87376f3be348b25e411a22dbc1f10df39877f39f	the binding number of halin graphs	graph theory;teoria grafo;algoritmo busqueda;algorithm complexity;algorithme recherche;complejidad algoritmo;search algorithm;theorie graphe;complexite algorithme;cycle graphe;vertex graph;cycle graph;cuspide grafico;sommet graphe;ciclo diagrama	Abstract   Following Woodall the binding number of a graph  G , bind( G ), is the minimum value of   |Γ     G   (X)|  |X|   taken over all sets  X ⊂ V ( G ) such that  X ≠0 and  Γ   G  ( X )≠ V ( G ). We show that, for a Halin graph  H  with  n  vertices, bind  (H)=  (n−1)  (n−3)   or   (n+1)  (n−1)   and give a linear-time algorithm which recognizes when bind( H ) is the first and the second value.		Miroslawa Skowronska	1988	Discrete Applied Mathematics	10.1016/0166-218X(88)90126-6	combinatorics;graph theory;cycle graph;vertex;mathematics;algorithm;search algorithm	ML	21.557164971318976	27.375922967617992	23809
5be52be9ac53981ea621b6c0ef01859c127ba3d2	an information-theoretic lower bound for the longest common subsequence problem	longest common subsequence;information theoretic;lower bound	"""Aigxithm , comparison The longest common subsequence (LCS) problem is the problem of determining a sequence C of maximum length that is a subsequence of (can be obtained by deleting zero or more symbols from) each of two given strings A and B [ I]. The best algorithms known for the IAS problem are, in the worst case, only s@htly faster than qua-dratic in the length of the input [3,5] although, for some special cases, there are algorithms known that require only O(n log n) time [3,4]. Lower bounds on the complexity of the LCS problem have been determined for algorithms that are restricted to making """" equal,-unequal """" comparisons of posit;ons in the two strings. A """" comparison of two positions """" means a comparison of the valuec ;f the symbols Ilocated at those positions. It 'has been shown [ 1 ] that 0(rt2) such comparisons are required to solve the LCS problem for unrestricted alphabet size and O(M) such comparisons are required for alphabet size restricted to s. We shall prove that n log II is a lower bound on the nunber of """" less thanequal-greater than """" comparisons requi't. d to solve the LCS problem, assuming unrestrictzc: alphabet size., Let Y'(n) be the minimum number of comparisons (resulti 'rg in """" less than """" , """" greater than """" , of """" equal """") requf::.l %J solve the LCS problem with two input strings of length n. WC &J use a decision tree model (see [ 11) alld shall demonst:ate a lower bound on T(n) by exhibit-*. 40 ing a path of sufficient length in each possible deci-:ion tree. A basic configuration is an assignment of values to strings A and B such that there are no vahes common to strings A and B. Thus a basic configuration has an I CS $'length 0. A wlid configuration (for a particular sequence of comparisons) is an assignment of values to positions that is consistent with the results of all comparisons. We now define an """" oracle """" or decision rule by which a r ath, P,, is distinguished in each decision tree for the LCS problem. Let fi!) be the prefix of length i of?,, (starting at the root of the decision tree). Incision rule. Let the comparison p 1 : p2 be the ith on P,. If p1 and p2 are both positions in A (say, a,, …"""	algorithm;best, worst and average case;decision tree model;internet authentication service;longest common subsequence problem;theory;writing commons	Daniel S. Hirschberg	1978	Inf. Process. Lett.	10.1016/0020-0190(78)90037-6	longest increasing subsequence;computer science;longest common subsequence problem;mathematics;upper and lower bounds;longest alternating subsequence	Theory	13.689122988635097	25.7635334886142	23864
222aeabbd24932ec28d199622be2fb5f7402039e	an intelligent driver alerting system for real-time range indicator embedded in electric vehicles	state of charge estimation;real time range estimation model;electric vehicle;charging recommendation system;energy management	This paper proposes a state-of-the-art algorithm for a real-time charging recommendation for an electric vehicle driver based on an accurate real-time range indicator system to avoid range anxiety. The charging recommendation algorithm alerts the driver when charging is deemed required for the selected route. This algorithm determines the nearest charging location obtained using GPS based on an accurate estimation of state of charge (SoC) at the destination and when charging determines the optimum charging time required by the battery to have sufficient energy to reach the destination. The graphical user interface of the real-time range indicator system is also used to show the driver an accurate estimation of the remaining range to destination and the current SoC. The results from simulations of a range of routes validate the proposed algorithm.	algorithm;embedded system;global positioning system;graphical user interface;real-time clock;real-time transcription;simulation;state of charge	Kaveh Sarrafan;Kashem M. Muttaqi;Danny Sutanto;Graham. E. Town	2016	IEEE Transactions on Industry Applications	10.1109/IAS.2016.7731820	embedded system;electronic engineering;simulation;engineering	Embedded	5.647328132213369	7.609041085707806	23913
e676fea5fb11f7e2d03ffeeb683bbc344a3d6208	learning cover context-free grammars from structural data		We consider the problem of learning an unknown context-free grammar when the only knowledge available and of interest to the learner is about its structural descriptions with depth at most l. The goal is to learn a cover context-free grammar (CCFG) with respect to l, that is, a CFG whose structural descriptions with depth at most l agree with those of the unknown CFG. We propose an algorithm, called LA l, that efficiently learns a CCFG using two types of queries: structural equivalence and structural membership. We show that LA l runs in time polynomial in the number of states of a minimal deterministic finite cover tree automaton (DCTA) with respect to l. This number is often much smaller than the number of states of a minimum deterministic finite tree automaton for the structural descriptions of the unknown grammar.		Mircea Marin;Gabriel Istrate	2014	Sci. Ann. Comp. Sci.	10.7561/SACS.2014.2.253	natural language processing;l-attributed grammar;machine learning;pattern recognition;stochastic context-free grammar	Theory	3.0815647904972496	18.38980656885172	23937
1c1797bf9680c304f86a92acfcc09c388f202b52	on multiparty communication with large versus unbounded error		The communication complexity of F with unbounded error is the limit of the ε-error randomized complexity of F as ε → 1/2. Communication complexity with weakly unbounded error is defined similarly but with an additive penalty term that depends on 1/2− ε . Explicit functions are known whose two-party communication complexity with unbounded error is exponentially smaller than with weakly unbounded error. Chattopadhyay and Mande (ECCC Report TR16-095) recently generalized this exponential separation to the number-on-the-forehead multiparty model, with a rather technical proof from first principles. We show how to derive such an exponential separation from known two-party work, achieving stronger parameters along the way. We present several proofs for this result, some as short as half a page. Our strongest separation is a k-party communication problem F : ({0,1}n)k → {0,1} that has complexity O(logn) with unbounded error and Ω(n/4k) with weakly unbounded error. ∗The author was supported in part by NSF CAREER award CCF-1149018 and an Alfred P. Sloan Foundation Research Fellowship. ACM Classification: F.1.3, F.2.3 AMS Classification: 68Q17, 68Q15	acm computing classification system;communication complexity;electronic colloquium on computational complexity;exponential time hypothesis;ibm notes;randomized algorithm;time complexity;utility functions on indivisible goods	Alexander A. Sherstov	2016	Electronic Colloquium on Computational Complexity (ECCC)		discrete mathematics;theoretical computer science;computer science	Theory	11.383073134804059	21.87413202839494	23988
9b1550909b16c17d727bd316dca68b2fddc1f46e	a finiteness condition for semigroups	finiteness condition	The most natural requirement is that the semigroup is finitely generated. Finiteness conditions for finitely generated semigroups are very important both in algebra and automata theory. Indeed if one supposes that the semigroup is also periodic the study of this finiteness conditions for semigroups (and groups ) is called the Burnside problem for semigroups (and groups ) (cf.[8],[9]).The relation with automata is based on the fact that a language L on a finite alphabet is recognizable if and only if the syntactic semigroup S(L) of L is finite. Hence, in principle, any finiteness condition for finitely generated semigroups can be translated in a regularity condition for languages. The study of finiteness conditions for periodic languages (i.e. such that S(L) is periodic) has been called the Burnside problem for languages (cf.[3],[14]).		Aldo de Luca;Stefano Varricchio	1988		10.1007/BFb0013117	topology;mathematics;regular semigroup;maximal subgroup	DB	-3.24634013274698	17.854845538744268	24056
43d2dff96b2a6f40ed553168a5ef334a21384064	a theorem on the expected complexity of dijkstra's shortest path algorithm	shortest path algorithm	Abstract   The expected number of times of updating the values of tentative distances assigned to nodes in Dijkstra's algorithm for the single-source shortest path problem is proved to be at most   n  log     e   (  2m  n  )  , where  m  and  n  are the number of edges and nodes respectively of a given graph. The assumption on probability distributions is as general as Spira's for the all-pair shortest path problem. As a corollary of this result, an efficient method for implementing the algorithm by means of a   [  log     e   (  2m  n  )-  ary   heap is presented, which has the upper bound of   m + 2n  log     2   n  log     e   (  2m  n  )  log     2   log     e   (  2m  n  )   binary comparisons in average on the decision tree model.	dijkstra's algorithm;shortest path problem	Kohei Noshita	1985	J. Algorithms	10.1016/0196-6774(85)90009-4	mathematical optimization;suurballe's algorithm;combinatorics;discrete mathematics;dijkstra's algorithm;constrained shortest path first;computer science;pathfinding;euclidean shortest path;yen's algorithm;mathematics;shortest path problem;k shortest path routing;shortest path faster algorithm;algorithm	Theory	19.376082500523317	25.197324275974108	24085
7a6c06d7393a9863445e2cb020d4eaf70b8eccdb	time-space tradeoffs for sat on nonuniform machines	turing machine;circuit complexity;time space trade offs;nonuniform complexity;computational complexity;rational number;random access;lower bound	The arguments used by R. Kannan (1984, Math. Systems Theory17, 29?45), L. Fortnow (1997, in “Proceedings, Twelfth Annual IEEE Conference on Computational Complexity, Ulm, Germany, 24?27 June, 1997,” pp. 52?60), and R. J. Lipton and A. Viglas (1999, in “40th Annual Symposium on Foundations of Computer Science, New York, 17?19 Oct. 1999,” pp. 459?469) are generalized and combined with an argument for diagonalizing over machines taking n bits of advice on inputs of length n to obtain the first nontrivial time?space lower bounds for SAT on nonuniform machines. In particular, we show that for any a 0, SAT cannot be computed by a random access deterministic Turing machine using na time, no(1) space, and o(n2/2??) advice nor by a random access deterministic Turing machine using n1+o(1) time, n1?? space, and n1?? advice. More generally, we show that if for some ?>0 there exists a random access deterministic Turing machine solving SAT using na time, nb space, and o(n(a+b)/2??) advice, then a?12(b2+8?b). Lower bounds for computing \overline{{\bfSAT}} on random access nondeterministic Turing machines taking sublinear advice are also obtained. Moreover, we show that SAT does not have NC1 circuits of size nl+o(1) generated by a nondeterministic log?space machine taking no(1) advice. Additionally, new separations of uniform classes are obtained. We show that for all ?>0 and all rational numbers r?1, DTISP(nr, n1??) is properly contained in NTIME(nr).		Iannis Tourlakis	2001	J. Comput. Syst. Sci.	10.1006/jcss.2001.1767	circuit complexity;combinatorics;discrete mathematics;time hierarchy theorem;computer science;turing machine;theoretical computer science;2-exptime;ntime;mathematics;dspace;upper and lower bounds;programming language;computational complexity theory;algorithm;random access;rational number;dtime	Theory	11.593452113538067	21.983760414279214	24102
8498ed815055b12eb31f3e9b4d800e8a6d6ae54e	optimizing energy consumption of hot water system in buildings with solar thermal systems		This paper investigates the operation of a solar thermal system in a building, and seeks to craft a solution that would reduce the cost of electricity to the building manager, while concurrently ensuring that the water demand and the temperature of water are conform to the requirement of the building occupants. In particular, two energy management mechanisms are studies for controlling the multiple heat pumps that are connected to the solar thermal system for providing the system with heat when there is not enough solar energy. In this context, two control strategies are proposed, on-demanding control (ODC) and optimal day-ahead scheduling (ODS) with different degrees of information such as the water demand, weather, and so on. Moreover, three different types of scenarios are considered based on solar energy generation pattern and hot water demand of a commercial facility, and optimal number and operation schedules of heat pumps are identified for each of the scenario. It is shown that the ODS approach is more effective in saving energy and related costs in comparison with the systems ODC approach if the information of the weather conditions and hot demands are available for next 24 hours, and the performance improvement is corroborated numerically.	data center;heat pipe;numerical analysis;operational data store;optimizing compiler;orthogonal defect classification;scheduling (computing)	Wen-Tai Li;Kannan Thirugnanam;Wayes Tushar;Chau Yuen;Kristin L. Wood	2017		10.5220/0006309402660273	energy recovery;photovoltaic thermal hybrid solar collector;solar air conditioning;passive solar building design	AI	4.187498709198929	6.295271884593459	24130
942f8bd623affd804888f59b58671c34d304ff02	threat from being social: vulnerability analysis of social network coupled smart grid		Social networks (SNs) have been gradually applied by utility companies as an addition to smart grid and are proved to be helpful in smoothing load curves and reducing energy usage. However, SNs also bring in new threats to smart grid: misinformation in SNs may cause smart grid users to alter their demand, resulting in transmission line overloading and in turn leading to catastrophic impact to the grid. In this paper, we discuss the interdependence in the SN coupled smart grid and focus on its vulnerability. That is, how much can the smart grid be damaged when misinformation related to it diffuses in SNs? To analytically study the problem, we propose the misinformation attack problem in social-smart grid that identifies the top critical nodes in the SN, such that the smart grid can be greatly damaged when misinformation propagates from those nodes. This problem is challenging as we have to incorporate the complexity of the two networks concurrently. Nevertheless, we propose a technique that can explicitly take into account information diffusion in SN, power flow balance, and cascading failure in smart grid integratedly when evaluating node criticality, based on which we propose various strategies in selecting the most critical nodes. Also, we introduce controlled load shedding as a protection strategy to reduce the impact of cascading failure. The effectiveness of our algorithms is demonstrated by experiments on the IEEE bus test cases as well as the Pegase data set.	algorithm;cascading failure;criticality matrix;experiment;interdependence;load shedding;operator overloading;smoothing;social network;test case;transmission line	Tianyi Pan;Subhankar Mishra;Lan N. Nguyen;Gunhee Lee;Jungmin Kang;Jungtaek Seo;My T. Thai	2017	IEEE Access	10.1109/ACCESS.2017.2738565	computer network;grid;electric power transmission;cascading failure;distributed computing;computer science;smart grid;misinformation;smoothing;vulnerability;social vulnerability	HPC	-2.8951051749733074	7.195280607201165	24201
28f55b2b937b49216580f00604285d2eee22e44e	on the inapproximability of maximum intersection problems	maximum intersection;approximation algorithm;disclosure control;theory of computation;inapproximability;article	Given u sets, we want to choose exactly k sets such that the cardinality of their intersection is maximized. This is the so-called MAX-k-INTERSECT problem. We prove that MAX-k-INTERSECT cannot be approximated within an absolute error of 12n^1^-^2^@e+O(n^1^-^3^@e) unless P=NP. This answers an open question about its hardness. We also give a correct proof of an inapproximable result by Clifford and Popa (2011) [3] by proving that MAX-INTERSECT problem is equivalent to the MAX-CLIQUE problem.	approximation algorithm;approximation error;clique problem;hardness of approximation;max;p versus np problem	Min-Zheng Shieh;Shi-Chun Tsai;Mingchuan Yang	2012	Inf. Process. Lett.	10.1016/j.ipl.2012.06.014	combinatorics;discrete mathematics;theory of computation;computer science;mathematics;approximation algorithm;algorithm	DB	17.537459528098566	19.223718718753254	24213
50ee58d5ad59d4fe5252490ecc38b0daa99f0f37	efficient probabilistically checkable proofs and applications to approximations	graph minors;chromatic number;dominating set;maximum clique;probabilistically checkable proofs;treewidth;pathwidth;graph algorithms;set cover;partial k trees	Efficient Probabilistically Checkable Proofs and Applications to Approximation M. BELLARE* S. GOLDWASSERt C. LUNDi A. RUSSELL$ We construct multi-prover proof systems for NP which use only a constant number of provers to simultaneously achieve low error, low randomness and low answer size. As a consequence, we obtain asymptotic improvements to approximation hardness results for a wide range of optimization problems including minimum set cover, dominating set, maximum clique, chromatic number, and quartic programming; and constant factor improvements on the hardness results for MAXSNP problems. In particular, we show that approximating minimum set cover within any constant is NP-complete; approximating minimum set cover within c log n, for c < 1/8, implies NP C DTIME(nlOglOgn); approximat— ing the maximum of a quartic program within any constant is NP-complete; approximating maximum clique or chromatic number within nl/29 implies NP ~ BPP; and approximating MAX-3 SAT within 113/112 is NPcomplete. * High Performance Computing and Communications, IBM T.J. Watson Research Center, PO Box 704, Yorktown Heights, NY 10598, USA. e-mail: mihirf.Qwatson. ibm. corn. t MIT Laboratory for Computer Science, 545 Technology Square, Cambridge, MA 02139, USA. e-mail: shaf i@theory. lcs. init. edu. Partially supported by NSF FAW grant No. 9023312-CCR, DARPA g-rant No. NOO014-92-J-1799, and grant No. 89-00312 from the United States Israel Binationsl Science Foundation (BSF), Jerusalem, Israel. $ AT&T Bell Laboratories, Room 2C324, 600 Momtain Avenue, P. O. Box 636, Murray Hill, NJ 07974-0636, USA. email: lund@resesrch. att. corn. $ MIT Laboratory for Computer Science, 545 Technology Square, Cambridge, MA 02139, USA. e-mail: acrtttheory. lcs. mit . edn. Supported by a NSF Graduate Fellowship and by NSF grant 92-12184, AFOSR 89-0271, and DARPA NOO014-92-J-1799. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 25th ACM STOC ‘93-51931CA,USA	approximation algorithm;bpp (complexity);bean scripting framework;clique (graph theory);dominating set;email;graph coloring;ibm notes;init;mit computer science and artificial intelligence laboratory;mathematical optimization;mihir bellare;np-completeness;probabilistically checkable proof;randomness;snp (complexity);set cover problem;symposium on theory of computing;thomas j. watson research center	Mihir Bellare;Shafi Goldwasser;Carsten Lund;A. Russeli	1993		10.1145/167088.167174	pathwidth;mathematical optimization;combinatorics;discrete mathematics;dominating set;probabilistically checkable proof;pcp theorem;mathematics;set cover problem;nexptime;treewidth	Theory	12.715747299330781	21.59914205763097	24244
28700174bda49df4685866659524a5146e378c07	a formalism for the description of protein interaction dedicated to jerzy tiuryn on the occasion of his 60th birthday	systems biology;predictive modelling;type theories;protein interaction;term rewriting	The Calculus of Looping Sequences is a formalism for describing evolution of biological systems by means of term rewriting rules. We propose to enrich this calculus by labelling elements of sequences. Since two elements with the same label are considered to be linked, this allows us to represent protein interaction at the domain level. Well-formedness of terms are ensured by both a syntactic constraint and a type system: we discuss the differences between these approaches through the description of a biological system, namely the EGF pathway.	biological system;rainbows end;rewriting;semantics (computer science);type system	Roberto Barbuti;Andrea Maggiolo-Schettini;Angelo Troina;Mariangiola Dezani-Ciancaglini;Paolo Milazzo	2010	Fundam. Inform.	10.3233/FI-2010-316	computer science;machine learning;pure mathematics;mathematics;predictive modelling;systems biology;algorithm	AI	-3.8399040200239196	16.787326736260415	24281
65f808b9ea7078bbc23351487d17f88cac944020	exact perfect matching in complete graphs	perfect matching;computational complexity;exact perfect matching;complete graphs	A red-blue graph is a graph where every edge is colored either red or blue. The exact perfect matching problem asks for a perfect matching in a red-blue graph that has exactly a given number of red edges. We show that for complete and bipartite complete graphs, the exact perfect matching problem is logspace equivalent to the perfect matching problem. Hence, an efficient parallel algorithm for perfect matching would carry over to the exact perfect matching problem for this class of graphs. We also report some progress in extending the result to arbitrary graphs.	graph (discrete mathematics);l (complexity);matching (graph theory);parallel algorithm	Rohit Gurjar;Arpita Korwar;Jochen Messner;Thomas Thierauf	2013	TOCT	10.1145/3041402	strong perfect graph theorem;1-planar graph;claw-free graph;perfect graph theorem;folded cube graph;mathematical optimization;factor-critical graph;combinatorics;discrete mathematics;cograph;bipartite graph;perfect graph;perfect set property;3-dimensional matching;edge cover;trivially perfect graph;mathematics;distance-hereditary graph;computational complexity theory;perfect power;chordal graph;line graph;algorithm;matching	Theory	23.959958591308958	25.521423616161364	24319
8188a7fdb9e53fc2b3a08fca694d4e888d95ebd4	on the hierarchy of functioning rules in distributed computing	second order;optimisation sous contrainte;constrained optimization;distributed system;evaluation performance;optimisation;hierarchy;systeme reparti;chaine markov;cadena markov;performance evaluation;optimizacion;evaluacion prestacion;ordre 1;distributed computing;orden 2;optimizacion con restriccion;optimization problem;sistema repartido;first order;optimal operation;jerarquia;funcionamiento optimo;optimization;ordre 2;distributed systems;hierarchie;orden 1;fonctionnement optimal;markov chains;markov chain	– In previous papers, we used a Markovian model to determine the optimal functioning rules of a distributed system in various settings. Searching optimal functioning rules amounts to solve an optimization problem under constraints. The hierarchy of solutions arising from the above problem is called the “ first order hierarchy”, and may possibly yield equivalent solutions. The present paper emphasizes a specific technique for deciding between two equivalent solutions, which establishes the “ second order hierarchy ”.	constraint (mathematics);distributed computing;mathematical optimization;optimization problem	Alain Bui;M. P. Bui;Christian Lavault	1999	RAIRO - Operations Research	10.1051/ro:1999102	markov chain;mathematical optimization;constrained optimization;combinatorics;artificial intelligence;mathematics;analytical hierarchy;algorithm	DB	19.980956834237215	8.72710453554269	24359
1e21fdf136f4a16a4010d2c4ebe8ae12224dcb16	dual-based local search for the connected facility location and related problems	network design;virtual private network design;dual ascent;data management;local search;steiner tree;connected facility location;facility location	T connected facility location (ConFL) problem arises in a number of applications that relate to the design of telecommunication networks as well as data distribution and management problems on networks. It combines features of the uncapacitated facility location problem with the Steiner tree problem and is known to be NP-complete. In this setting, we wish to install a set of facilities on a communication network and assign customers to the installed facilities. In addition, the set of selected facilities needs to be connected by a Steiner tree. In this paper, we propose a dual-based local search heuristic that combines dual ascent and local search, which together yield strong lower and upper bounds to the optimal solution. Our procedure is applied to a slightly more general version of the ConFL problem that embraces a family of four different problems— the Steiner tree-star problem, the general Steiner tree-star problem, the ConFL problem, and the rent-or-buy problem—that combine facility location decisions with connectivity requirements. Consequently, our solution methodology successfully applies to all of them. We discuss a wide range of computational experiments that indicate that our heuristic is a very effective procedure that finds high-quality solutions very rapidly.		M. Gisela Bardossy;S. Raghavan	2010	INFORMS Journal on Computing	10.1287/ijoc.1090.0375	mathematical optimization;network planning and design;combinatorics;steiner tree problem;data management;computer science;local search;facility location problem;mathematics;1-center problem	Theory	21.641556213427062	14.0728670187005	24360
58a1b70d839e952fbfe96509f77788a1b49e1226	routing and network design with robustness to changing or uncertain traffic demands	oblivious routing;phishing;network design;oblivious transfer;static diffie hellman;robust optimization;decisional;polyhedral model;polynomial time;password authenticated key exchange;user interfaces;doppelganger	A new class of network design problems were introduced by Fingerhut et al. [26], and independently by Duffield et al. [20], to address, among other things, the issue of uncertainty in the demand matrix. The so-called hose model (the term was coined in [20]) for demand matrices from [26, 20] was subsequently generalized to the polyhedral model by Ben-Ameur and Kerivin [11, 10]. In a different direction, Räacke [51] showed the existence of good randomized oblivious routings in all undirected graphs. This was followed by a proof of the polynomial time solvability of an optimal oblivious routing scheme [7].  One can view the above developments in a common framework of robust optimization. We give a survey of these developments and related work with the aim of providing a unified picture. We also highlight the remaining open problems.	cache-oblivious algorithm;graph (discrete mathematics);graph coloring;mathematical optimization;network planning and design;polynomial;polynomial-time approximation scheme;polytope model;randomized algorithm;robust optimization;routing;time complexity	Chandra Chekuri	2007	SIGACT News	10.1145/1324215.1324236	time complexity;mathematical optimization;network planning and design;combinatorics;robust optimization;phishing;computer science;theoretical computer science;oblivious transfer;distributed computing;user interface;computer security	Theory	19.52106513080965	17.563628812610283	24407
6587f6386890b2d7544daf46db56661c1a10cf65	on learning multiple concepts in parallel	algoritmo paralelo;learning algorithm;parallel algorithm;team learning;apprentissage conceptuel;algorithme parallele;recursive function;aprendizaje conceptual;necessary and sufficient condition;identification;inferencia;funcion recursiva;concept learning;fonction recursive;identificacion;is success;inference	A class U of recursive functions is said to be finitely (a, b) learnable if and only if for any b tuple of pairwise distinct functions from U at least a of the b functions have been learned correctly from examples of their behavior after some finite amount of time. It is shown that this approach, called learning in parallel, is more powerful than nonparallel learning. Furthermore, it is shown that imposing the restriction (called parallel super learning) on parallel learning that the learning algorithm also identiy on which of the input functions it is successful is still more powerful than nonparallel learning, A necessary and sufficient condition is derived for (a, b) superlearning and (c, d) superlearning being the same power. Our new notion of parallel learning is compared with other, previously defined notions of learning in parallel. Finally, we synthesize our notion of learning in parallel with the concept of team learning and obtain some interesting trade-offs and comparisons.		Efim B. Kinber;Carl H. Smith;Mahendran Velauthapillai;Rolf Wiehagen	1995	J. Comput. Syst. Sci.	10.1006/jcss.1995.1005	semi-supervised learning;identification;multi-task learning;instance-based learning;combinatorics;algorithmic learning theory;team learning;concept learning;double loop learning;computer science;artificial intelligence;online machine learning;machine learning;mathematics;parallel algorithm;stability;competitive learning;active learning;algorithm	Theory	3.6755178852885924	17.523128407476765	24416
9f6cc9d967c12ae67795ec4fc174cc3d756018a0	a linear algebra approach to olap	data science;haslab haslab uminho;formal methods;software engineering	Inspired by the relational algebra of data processing, this paper addresses the foundations of data analytical processing from a linear algebra perspective. The paper investigates, in particular, how aggregation operations such as cross tabulations and data cubes essential to quantitative analysis of data can be expressed solely in terms of matrix multiplication, transposition and the Khatri–Rao variant of the Kronecker product. The approach offers a basis for deriving an algebraic theory of data consolidation, handling the quantitative as well as qualitative sides of data science in a natural, elegant and typed way. It also shows potential for parallel analytical processing, as the parallelization theory of such matrix operations is well acknowledged.	contingency table;data cube;data science;linear algebra;matrix multiplication;online analytical processing;parallel computing;relational algebra;semiconductor consolidation	Hugo Daniel Macedo;José Nuno Oliveira	2014	Formal Aspects of Computing	10.1007/s00165-014-0316-9	discrete mathematics;formal methods;computer science;theoretical computer science;mathematics;numerical linear algebra;programming language;algorithm	DB	-2.954777043152252	32.12064655699487	24446
2c19dc6f5fed08dc2e37f345be8518a40d06e41f	aupcr maximizing matchings : towards a pragmatic notion of optimality for one-sided preference matchings		We consider the problem of computing a matching in a bipartite graph in the presence of one-sided preferences. There are several well studied notions of optimality which include pareto optimality, rank maximality, fairness and popularity. In this paper, we conduct an in-depth experimental study comparing different notions of optimality based on a variety of metrics like cardinality, number of rank-1 edges, popularity, to name a few. Observing certain shortcomings in the standard notions of optimality, we propose an algorithm which maximizes an alternative metric called the Area under Profile Curve ratio (AUPCR). To the best of our knowledge, the AUPCR metric was used earlier but there is no known algorithm to compute an AUPCR maximizing matching. Finally, we illustrate the superiority of the AUPCR-maximizing matching by comparing its performance against other optimal matchings on synthetic instances modeling real-world data.		J GirishRaguvir;Rahul Ramesh;Sachin Sridhar;Vignesh Manoharan	2017	CoRR		computer science;theoretical computer science;management science;cardinality;welfare economics;pareto principle;popularity;bipartite graph	AI	17.808776337650716	16.965440397781844	24496
b6694a95121c4725b2a812cef3676726eb191784	maximizing expected utility for stochastic combinatorial optimization problems	shortest path;optimisation;stochastic shortest path;stochastic knapsack stochastic combinatorial optimization combinatorial problems polynomial time approximation algorithm stochastic shortest path stochastic spanning tree;approximate algorithm;fourier series;knapsack problems;polynomial approximation knapsack problems optimisation;minimum weight spanning tree;approximation algorithms;approximation method;risk aversion;expected utility;combinatorial optimization problem;combinatorial problems;utility function;random variables;polynomial optimization;approximation methods approximation algorithms polynomials optimization vectors random variables fourier series;polynomials;utility maximization;stochastic optimization;expected value;vectors;random variable;exponential utility;optimization;approximation methods;spanning tree;data structure;polynomial approximation	We study the stochastic versions of a broad class of combinatorial problems where the weights of the elements in the input dataset are uncertain. The class of problems that we study includes shortest paths, minimum weight spanning trees, and minimum weight matchings over probabilistic graphs, and other combinatorial problems like knapsack. We observe that the expected value is inadequate in capturing different types of {\em risk-averse} or {\em risk-prone} behaviors, and instead we consider a more general objective which is to maximize the {\em expected utility} of the solution for some given utility function, rather than the expected weight (expected weight becomes a special case). We show that we can obtain a polynomial time approximation algorithm with {\em additive error} $\epsilon$ for any $\epsilon>0$, if there is a pseudopolynomial time algorithm for the {\em exact} version of the problem (This is true for the problems mentioned above)and the maximum value of the utility function is bounded by a constant. Our result generalizes several prior results on stochastic shortest path, stochastic spanning tree, and stochastic knapsack. Our algorithm for utility maximization makes use of the separability of exponential utility and a technique to decompose a general utility function into exponential utility functions, which may be useful in other stochastic optimization problems.	approximation algorithm;combinatorial optimization;expectation–maximization algorithm;expected utility hypothesis;exponential utility;file spanning;knapsack problem;linear separability;mathematical optimization;minimum weight;minimum-weight triangulation;polynomial;pseudo-polynomial time;risk aversion;shortest path problem;spanning tree;stochastic gradient descent;stochastic optimization;stochastic process;time complexity;utility functions on indivisible goods	Jian Li;Amol Deshpande	2011	2011 IEEE 52nd Annual Symposium on Foundations of Computer Science	10.1109/FOCS.2011.33	random variable;mathematical optimization;combinatorics;discrete mathematics;data structure;stochastic optimization;mathematics;approximation algorithm;statistics	Theory	22.185466871226218	15.888719444537228	24532
ff14bb0d84ec972356af2a40aedb2bd5795d3e62	a dijkstra-like method computing all extreme supported non-dominated solutions of the biobjective shortest path problem	biobjective path problems;journal article;supported efficient paths;label setting algorithm	We address the problem of determining all extreme supported solutions of the biobjective shortest path problem. A novel Dijkstra-like method generalizing Dijkstra׳s algorithm to this biobjective case is proposed. The algorithm runs in O( N ( m + n  log  n )) time to solve one-to-one and one-to-all biobjective shortest path problems determining all extreme supported non-dominated points in the outcome space and one supported efficient path associated with each one of them. Here  n  is the number of nodes,  m  is the number of arcs and  N  is the number of extreme supported points in outcome space for the one-to-all biobjective shortest path problem. The memory space required by the algorithm is O( n + m ) for the one-to-one problem and O( N + m ) for the one-to-all problem. A computational experiment comparing the performance of the proposed methods and state-of-the-art methods is included.	shortest path problem	Antonio Sedeño-Noda;Andrea Raith	2015	Computers & OR	10.1016/j.cor.2014.11.010	mathematical optimization;combinatorics;yen's algorithm;mathematics;shortest path problem;k shortest path routing;algorithm	EDA	24.415044478361413	7.643207717605255	24569
94a299a58541b64643f2f29b9070bfa85a62d1d5	efficient probabilistic algorithm for estimating the algebraic properties of boolean functions for large n		Although several methods for estimating the resistance of a random Boolean function against (fast) algebraic attacks were proposed, these methods are usually infeasible in practice for relative large input variables n (for instance n ≥ 30) due to increased computational complexity. An efficient estimation the resistance of Boolean function (with relative large input variables n) against (fast) algebraic attacks appears to be a rather difficult task. In this paper, the concept of partial linear relations decomposition is introduced, which decomposes any given nonlinear Boolean function into many linear (affine) subfunctions by using the disjoint sets of input variables. Based on this result, a general probabilistic decomposition algorithm for nonlinear Boolean functions is presented which gives a new framework for estimating the resistance of Boolean function against (fast) algebraic attacks. It is shown that our new probabilistic method gives very tight estimates (lower and upper bound) and it only requires about O(n2) operations for a random Boolean function with n variables, thus having much less time complexity than previously known algorithms.	computational complexity theory;linear algebra;nonlinear system;randomized algorithm;time complexity	Yongzhuang Wei;Enes Pasalic;Fengrong Zhang;Samir Hodzic	2016	IACR Cryptology ePrint Archive	10.1016/j.ins.2017.03.025	boolean algebra;boolean circuit;and-inverter graph;mathematical optimization;combinatorics;circuit minimization for boolean functions;discrete mathematics;boolean network;boolean domain;majority function;boolean expression;standard boolean model;maximum satisfiability problem;karp–lipton theorem;machine learning;complexity index;mathematics;boolean function;algorithm;parity function	Theory	10.122361708620595	21.957713561885694	24599
ce54e293df3fd8e874d6e9c0287dc2e1e59b1005	almost k-wise vs. k-wise independent permutations, and uniformity for general group actions	group action	A family of permutations in Sn is k-wise independent if a uniform permutation chosen from the family maps any distinct k elements to any distinct k elements equally likely. Efficient constructions of k-wise independent permutations are known for k = 2 and k = 3, but are unknown for k ≥ 4. In fact, it is known that there are no nontrivial subgroups of Sn for n ≥ 25 which are 4-wise independent. Faced with this adversity, research has turned towards constructing almost k-wise independent families, where small errors are allowed. Optimal constructions of almost k-wise independent families of permutations were achieved by several authors. Our first result is that any such family with small enough error is statistically close to a distribution which is perfectly k-wise. This allows for a simplified analysis of algorithms: an algorithm which uses randomized permutations can be analyzed assuming perfect k-wise independence, and then applied to an almost k-wise independent family. In particular, it allows for an oblivious derandomization of two-sided randomized algorithms which work correctly given any k-wise independent distribution of permutations. Another model is that of weighted families of permutations, or equivalently distributions of small support. We establish two results in this model. First, we show that a small random set of nO(k) permutations w.h.p supports a k-wise independent distribution. We then derandomize this by showing that any almost 2k-wise independent family supports a k-wise independent distribution. This allows for oblivious derandomization of algorithms for search problems which work correctly given perfect k-wise independent distributions. These results are all in fact special cases of a general framework where a group acts on a set. In the aforementioned case, the group of permutations acting on tuples of k elements. We prove all the above results in the general setting of the action of a finite group on a finite set. ∗Supported in part by an ERC advanced grant †Supported in part by NSF grant DMS-0835373.	analysis of algorithms;circuit complexity;ibm notes;map;randomized algorithm;statistically close;universal quantification	Noga Alon;Shachar Lovett	2013	Theory of Computing	10.4086/toc.2013.v009a015	combinatorics;discrete mathematics;parity of a permutation;mathematics;golomb–dickman constant	Theory	11.163889969850024	22.852295310732625	24618
e769e592cc4c31a379f26654ff9724738c4d4285	efficient algorithms for reconstructing zero-recombinant haplotypes on a pedigree based on fast elimination of redundant linear equations	sistema lineal;pedigree analysis;systeme equation;eliminacion;65f05;05c05;efficient algorithm;arbre maximal;ecuacion lineal;11txx;biology;biologia;corps fini;linear system;68wxx;mutacion;algorithme;finite field;algorithm;14c20;sistema ecuacion;low stretch spanning tree;construccion;arbol maximo;equation system;68r10;champ fini;campo finito;haplotype inference;spanning tree;elimination;11d04;linear equations;systeme lineaire;system of linear equations;linear equation;construction;mutation;equation lineaire;biologie;68w05;algoritmo	Computational inference of haplotypes from genotypes has attracted a great deal of attention in the computational biology community recently, partially driven by the international HapMap project. In this paper, we study the question of how to efficiently infer haplotypes from genotypes of individuals related by a pedigree, assuming that the hereditary process was free of mutations (i.e., the Mendelian law of inheritance) and recombinants. The problem has recently been formulated as a system of linear equations over the finite field of F (2) and solved in O(m3n3) time by using standard Gaussian elimination, where m is the number of loci (or markers) in a genotype and n the number of individuals in the pedigree. We give a much faster algorithm with running time O(mn2 + n3 log n log log n). The key ingredients of our construction are (i) a new system of linear equations based on some spanning tree of the pedigree graph and (ii) an efficient method for eliminating redundant equations in a system of O(mn) linear equations over O(n) variables. Although such a fast elimination method is not known for general systems of linear equations, we take advantage of the underlying pedigree graph structure and recent progress on low-stretch spanning trees.	algorithm;computation;computational biology;file spanning;gaussian elimination;international hapmap project;linear equation;recombinant dna;spanning tree;system of linear equations;time complexity	Jing Xiao;Lan Liu;Lirong Xia;Tao Jiang	2009	SIAM J. Comput.	10.1137/070687591	combinatorics;mathematics;linear equation;algorithm;algebra	Theory	16.968940648635083	22.743715664083823	24619
6fb2dc4e786a606d17dfb6ac7ac7b7f19afe6ed9	heuristic approximation and computational algorithms for closed networks: a case study in open-pit mining		Abstract We investigate a fundamental model from open-pit mining which is a cyclic system consisting of an (unreliable) shovel, trucks travelling loaded, unloading facility, and trucks travelling back empty. The interaction of these subsystems determines the mean number of trucks loaded per time unit — the capacity of the shovel, which is a fundamental quantity of interest. To determine this capacity we need the stationary probability that the shovel is idle. Because an exact analysis of the performance of the system is out of reach, besides of simulations there are various approximation algorithms proposed in the literature, which stem from computer science and can be characterized as general purpose algorithms. We propose for solving the special problem under mining conditions an extremely simple alternative algorithm. Comparison with several general purpose algorithms shows that for realistic situations in the open-pit mining application the special algorithm outperforms the precision of general purpose algorithms. This holds even if the general purpose algorithms incorporate more details of the underlying models than our simple algorithm, which is based on a strongly reduced model. The comparison and assessment is done with extensive simulations on a level of detail which the general purpose algorithms are able to cover. We discuss the application of our proposed algorithms to other applications. It turns out that our algorithms are analogues to Norton’s Theorem for a large class of general transportation systems.	algorithm;approximation;heuristic	Hans Daduna;Ruslan K. Krenzler;Robert Ritter;Dietrich Stoyan	2018	Perform. Eval.	10.1016/j.peva.2017.12.002	shovel;stationary distribution;algorithm;simple algorithm;approximation algorithm;computer science;truck;heuristic;level of detail;idle	ML	10.646805569035221	8.421687376993466	24637
01ed4a0acfea0763fa6da85388f4bcb69d5b4833	circuit complexity before the dawn of the new millennium	circuit complexity;lower bound	"""The 1980's saw rapid and exciting development of techniques for proving lower bounds in circuit complexity. This pace has slowed recently, and there has even been work indicating that quite di erent proof techniques must be employed to advance beyond the current frontier of circuit lower bounds. Although this has engendered pessimism in some quarters, there have in fact been many positive developments in the past few years showing that signi cant progress is possible on many fronts. This paper is a (necessarily incomplete) survey of the state of circuit complexity as we await the dawn of the new millennium. 1 Superpolynomial Size Lower Bounds Complexity theory long ago achieved its goal of presenting interesting and important computational problems that, although computable, nonetheless require such huge circuits to compute that they are computationally intractable. In fact, in Stockmeyer's thesis, the unusual step was taken of translating an asymptotic result into concrete terms: Theorem 1.1 [Sto74] Any circuit that takes as input a formula (in the language of WS1S) with up to 616 symbols and produces as output a correct answer saying whether the formula is valid or not, requires at least 10123 gates. To quote from [Sto87]: Even if gates were the size of a proton and were connected by in nitely thin wires, the network would densely ll the known universe. In the intervening years complexity theory has made some progress proving that other problems A require circuits of superpolynomial size (in symbols: A 62 P/poly), but no such A has been shown to exist in nondeterministic exponential time (NTIME(2nO(1))) or even in the potentially larger class DTIME(2nO(1))NP. Where can we nd sets that are not in P/poly? A straightforward diagonalization shows that for any superpolynomial time-bound T , there is a problem in DSPACE(T (n)) P/poly. Recall that deterministic space complexity is roughly the same as alternating time complexity [CKS81]. It turns out that the full power of alternation is not needed to obtain sets outside of P/poly { two alternations su ce, as can be shown using techniques of [Kan82] (see also [BH92]). Combined with Toda's theorem [Tod91] we obtain the following. Theorem 1.2 [Kan82, BH92, Tod91] Let T be a time-constructible superpolynomial function. Then NTIME(T (n))NP 6 P/poly. DTIME(T (n))PP 6 P/poly. A further improvement was reported by K obler and Watanabe, who showed that even ZPTIME(T (n))NP is not contained in P/poly [KW]. (Here, ZPTIME(T (n)) is zero-error probabilistic time T (n).) Is this the best that we can do? To the best of my knowledge, it is not known if the classes PrTIME(2logO(1)n) (unbounded error probabilistic quasipolynomial time) and DTIME(2nO(1))C=P are contained in P/poly (even relative to an oracle). There are oracles relative to which DTIME(2nO(1))NP has polynomial-size circuits [Hel86, Wil85], thus showing that relativizable techniques cannot be used to present superpolynomial circuit size bounds for NTIME(2nO(1)). Note, however that nonrelativizing techniques have been used on closely-related problems [BFNW93]. More to the point, as reported in [KW], Buhrman and Fortnow and also Thierauf have shown that the exponential-time version of the complexity { 2 { class MA contains problems outside of P/poly, although this is false relative to some oracles. (In particular, this shows that PrTIME(2nO(1)) is not contained P/poly.) One can hope that further insights will lead to more progress on this front. In the mean time, it has turned out to be very worthwhile to consider some important subclasses of P/poly. 2 Smaller Circuit Classes We will focus our attention on ve important circuit complexity classes:1 1. AC0 is the class of problems solvable by polynomial-size, constant-depth circuits of AND, OR, and NOT gates of unbounded fan-in. AC0 corresponds to O(1)-time computation on a parallel computer, and it also consists exactly of the languages that can be speci ed in rst-order logic [Imm89, BIS90]. AC0 circuits are powerful enough to add and subtract n-bit numbers. 2. NC1 is the class of problems solvable by circuits of AND, OR, and NOT gates of fan-in two and depth O(log n). NC1 circuits capture exactly the circuit complexity required to evaluate a Boolean formula [Bus93], and to recognize a regular set [Bar89]. There are deep connections between circuit complexity and algebra, and NC1 corresponds to computation over any non-solvable algebra [Bar89]. 3. ACC0 is the class of problems solvable by polynomial-size, constant-depth circuits of unbounded fan-in AND, OR, NOT, and MODm gates. (A MODm gate takes inputs x1; : : : ; xn and determines if the number of 1's among these inputs is a multiple of m.) To be more precise, AC0(m) is the class of problems solvable by polynomial-size, constant-depth circuits of unbounded fan-in AND, OR, NOT, and MODm gates, and ACC0 = Sm AC0(m). In the algebraic theory mentioned above, ACC0 corresponds to computation over any solvable algebra [BT88]. Thus in the algebraic theory, ACC0 is the most natural subclass of NC1. 4. TC0 is the class of problems solvable by polynomial-size, constant-depth threshold circuits. TC0 captures exactly the complexity of integer multiplication and division, and sorting [CSV84]. Also, TC0 is a good complexity-theoretic model for \neural net"""" computation [PS88, PS89]. 5. NC0 is the class of problems solvable by circuits of AND, OR, and NOT gates of fan-in two and depth O(1). Note that each output bit can only depend on O(1) input bits in such a circuit. Thus any function in NC0 is computed by depth two AC0 circuits, merely using DNF or CNF expansion. 1Thus this survey will ignore the large body of beautiful work on the circuit complexity of larger subclasses of P and NC. { 3 { NC0 is obviously extremely limited; such circuits cannot even compute the logical OR of n input bits. One of the surprises of circuit complexity is that, in spite of its severe limitations, NC0 is in some sense quite \close"""" to AC0 in computational power. Quite a few powerful techniques are known for proving lower bounds for AC0 circuits; it is known that AC0 is properly contained in ACC0. It is not hard to see that ACC0 TC0 NC1. As we shall see below, weak lower bounds have been proven for ACC0 and TC0, whereas almost nothing is known for NC1. 3 AC0 A dramatic series of papers in the 1980's [Ajt83, FSS84, Cai89, Yao85, H as87] gave us a proof that AC0 circuits require exponential size even to determine if the number of 1's in the input is odd or even. (See also the excellent tutorial [BS90].) The main tool in proving this and other lower bounds for AC0 is H astad's Switching Lemma, one version of which states that most of the \sub-functions"""" of any AC0 function f are in NC0. (A sub-function of f is obtained by setting most of the n input bits to 0 or 1, leaving a function of the n remaining unset bits. Such a sub-function is called a restriction of f .) An interesting new proof of the Switching Lemma was presented by [Raz95] (see also [FL95, AAR]), and further extensions were presented by [Bea], the latter motivated in particular by the usefulness of the Switching Lemma as a tool in proving bounds on the length of propositional proofs. Although the switching lemma is the most powerful tool we have for proving lower bounds for AC0, it is not the only one. Lower bound arguments were presented in [Rad94, HJP93] for depth three circuits, and a notion of deterministic restriction was presented in [CR96] that is useful for proving nonlinear size bounds. It is important to note that, although the Switching Lemma tells us that any function f in AC0 is \close to"""" functions computed by depth two circuits (since most restrictions of f are computed in depth two), it also provides the tools to show that for all k, there are depth k + 1 circuits of linear size that require exponential size to simulate with depth k circuits [H as87]. This is in sharp contrast to the class of circuits considered in the next section, where e cient depth reduction is possible. The Switching Lemma also provides extremely strong bounds on the di culty of approximating the parity function (in the sense of giving the correct answer more than half of the time). This enabled Nisan and Wigderson [NW94] to construct, for any k, a pseudorandom generator that is (a) computable in AC0, and (b) takes logO(1) n bits of input and produces n bits of output, and (c) is secure against statistical tests computed by depth k AC0 circuits. (That is, any depth k circuit has essentially the same probability of accepting when the input is the \pseudorandom"""" output of f , as when the input is a random string of length n.) This has many applications in derandomization. For instance, given a depth k circuit Cn, the Switching Lemma tells us that a randomly-chosen restriction will simplify Cn to a depth two circuit. Can such a be found quickly deterministically? The Nisan-Wigderson generator easily provides an algorithm running in time 2logO(1) n: Note that the set f(C; ) : C is a depth k circuit and C is a depth two circuitg is in AC0. Set C to Cn and letting { 4 { be random; with high probability the AC0 circuit accepts. Thus with high probability the circuit also accepts when is pseudorandom. Since there are only 2logO(1) n pseudorandom strings, this set can be searched exhaustively. It is important to note that, although strong \non-approximability"""" bounds are known for some other classes of circuits (as we will see below), as of yet the AC0 lower bounds are the only ones that are strong enough to allow use of the Nisan-Wigderson construction. Pseudorandomness for AC0 was further studied by Sitharam [Sit95], who related pseudorandomness to polylog(n)-wise independence. Although AC0 circuits can produce output that looks pseudorandom to other AC0 circuits, AC0 lacks the ability to compute pseudorandom function generators for general polynomialtime computations; this was proved in [LMN93] as a corollary to"""	ac0;acc0;and gate;approximation algorithm;association for automated reasoning;carrier-to-noise ratio;circuit complexity;complex adaptive system;computable function;computation;computational complexity theory;computational problem;conjunctive normal form;constructible function;dspace;decision problem;deterministic algorithm;exptime;emoticon;environment variable;fan-in;larry stockmeyer;linear algebra;nonlinear system;oracle machine;p (complexity);p/poly;parallel computing;parity function;polynomial;pseudorandom function family;pseudorandom generator;pseudorandomness;quasi-polynomial;randomized algorithm;randomness;simulation;solid modeling;sorting;switching lemma;tc0;time complexity;toda's theorem;with high probability	Eric Allender	1996		10.1007/3-540-62034-6_33	circuit complexity;computer science;upper and lower bounds;algorithm	Theory	9.338046420710873	20.890068630533467	24639
e1926a08f3636d0ff52b44b945e804c1597e1459	a genetic algorithm for solving a production and delivery scheduling problem with time windows	algoritmo busqueda;ordered set;algorithme recherche;manufacturing process;search algorithm;time window;ensemble ordonne;algoritmo genetico;delai livraison;production process;procedimiento fabricacion;scheduling;processus fabrication;plazo entrega;algorithme genetique;scheduling problem;genetic algorithm;ordonamiento;tabu search;procede fabrication;delivery lead time;ordonnancement;busqueda tabu;proceso fabricacion;recherche tabou;conjunto ordenado	This paper deals with the problem of selecting and scheduling a set of orders to be processed by a manufacturing plant and immediately delivered to the customer site. Constraints to be considered are the limited production capacity, the available number of vehicles and the time windows within which orders must be served. We describe the problem relating it to similar problems studied in the literature. A genetic algorithm to solve the problem is developed and tested empirically with randomly generated problems. Comparisons with an exact procedure and a tabu search procedure show that the method finds very good-quality solutions.	computation;genetic algorithm;microsoft windows;optimization problem;procedural generation;scheduling (computing);software release life cycle;tabu search	José M. García;Sebastián Lozano;Fernando Guerrero;Ignacio Eguia	2002		10.1007/3-540-36131-6_38	nurse scheduling problem;job shop scheduling;mathematical optimization;genetic algorithm;tabu search;computer science;artificial intelligence;scheduling;scheduling;algorithm;search algorithm	AI	18.557716945100218	6.205212862581477	24651
1115ad1f148f0e8a8d95a1b40defe2d5e7f53011	research of automatic monitoring system of reservoir based on embedded system	data transmission;data collection;data management;embedded system;monitoring system;transmission mechanism;mobile communication;mixed mode;hardware design;software design	The automatic monitoring system of reservoir is an important means to realize modernization of reservoir management. This paper expounds the structure of automatic monitoring system of reservoir firstly. The system consists of three subsystems, which are acquisition subsystem transmission subsystem and data management subsystem. Secondly the design of the data collection terminal is studied, which realized the design of hydrological data collection terminal including hardware design based on embedded system and software design. The reason that affects data collection is analyzed and anti-jamming measures are given. And then the system structure of data transmission is offered, and the transmission mechanism of mixed-mode network, in which the elementary channel is wireless mobile communication and the backup channel is wire communication, is achieved. Finally, the data management subsystem is briefly introduced. The system is proved to be useful and efficient by the application on Xueye Reservoir.	backup;electronic counter-countermeasure;embedded system;mixed-signal integrated circuit;radio jamming;real-time data;software design	Chengming Zhang;Jixian Zhang;Yong Liang;Yan Zhang;Guitang Yin	2007		10.1007/978-0-387-77251-6_55	embedded system;real-time computing;engineering;operating system	Mobile	1.2671917972905302	30.78948698410999	24778
d7d146992cb79dba7e989c370660788d5f2b800a	a necessary condition for the rationality of the zeta function of a regular language	language theory;regular language;fonction zeta;teoria lenguaje;lenguaje racional;informatique theorique;langage rationnel;lenguaje formal;theorie langage;formal language;zeta function;computer theory;informatica teorica;langage formel	We show that if the zeta function of a regular language L is rational, then there exist cyclic languages L 1  and L 2  such that the generating function of L is the difference of the generating functions of L 1  and L 2 . We show also that it is decidable whether or not the zeta function of a given regular language is rational. If it is rational, it can be computed effectively	rationality;regular language	Juha Honkala	1989	Theor. Comput. Sci.	10.1016/0304-3975(89)90159-X	formal language;regular language;computer science;philosophy of language;pure mathematics;mathematics;algorithm;riemann zeta function	ECom	-0.05164354377533555	17.530460758706827	24784
7f5f5a53df9446586e910d517bd1440f319a097b	communication complexity of stochastic games	protocols;communication networks;complexity theory;nash equilibrium;bimatrix games communication complexity stochastic games strategy nash equilibria separable reward state independent transition game;probability density function;qa mathematics;communication complexity;data mining;strategy nash equilibria;computer networks;upper bound;counting circuits;stochastic processes;complexity theory stochastic processes upper bound nash equilibrium communication system control computer networks communication networks algorithm design and analysis counting circuits protocols;games;separable reward state independent transition game;upper and lower bounds;stochastic processes communication complexity stochastic games;communication system control;algorithm design and analysis;lower bound;stochastic games;bimatrix games;bimatrix game;pure strategy nash equilibria	We derive upper and lower bounds on the communication complexity of determining the existence of pure strategy Nash equilibria for some classes of stochastic games. We prove that pure equilibria of single controller stochastic games and those of SER-SIT (Separable Reward - State Independent Transition) games correspond to those of bimatrix games that are constructed from these stochastic games. Hence we extend communication complexity upper bounds of bimatrix games to these stochastic games. For SER-SIT games, we prove an upper bound of O(n2) which is tight and which coincides with that for bimatrix games. Here n is the number of actions of each player in each state. Note that this bound is independent of the size of the actual payoffs. For single-controller games, we obtain an upper bound of min (O(n2|S|), O(|S| n2 log M)) where S is the set of states and M is the largest entry across all payoff matrices. Further, we reduce bimatrix games to stochastic games and hence, the lower bound extends from bimatrix games to stochastic games as well. We also establish the following results while proving upper bounds for SER-SIT games. To prove that pure equilibria of SER-SIT games correspond to those of auxiliary bimatrix games, we show that every SER-SIT game that has a pure equilibrium has a state-independent pure equilibrium too. We also show that we cannot relax the constraints of separable rewards or state independent transitions. We provide counter examples when the game is SER (but not SIT) and SIT (but not SER).	communication complexity;maxima and minima;nash equilibrium	Nagarajan Krishnamurthy;T. Parthasarathy;G. Ravindran	2009	2009 International Conference on Game Theory for Networks	10.1109/GAMENETS.2009.5137427	combinatorial game theory;mathematical optimization;combinatorics;mathematics;mathematical economics	ECom	9.013858614799824	24.091151953089234	24821
dd973bf70df819fe36fa8b89a66b8e507b096a96	pseudorandom graphs in data structures		We prove that the hash functions required for several data structure applications could be instantiated using the hash functions of Celis et al. (SIAM J. Comput., 2013). These functions simultaneously enjoy short description length as well as fast evaluation time. The applications we consider are: (1) Cuckoo Hashing, (2) Cuckoo Hashing with Stash and (3) the Power of Two Choices paradigm for load balancing. Our analysis relies on a notion of sparse pseudorandom graphs that are similar to random graphs in having no large connected component and no dense subgraph. Such graphs may be of independent interest. Relating pseudorandom graphs to the two-choice paradigm relies on a very simple new proof we give (at the price of somewhat worse parameters).	connected component (graph theory);cuckoo hashing;data structure;dense subgraph;hash function;load balancing (computing);power of two;programming paradigm;pseudorandom number generator;pseudorandomness;random graph;sparse matrix	Omer Reingold;Ron Rothblum;Udi Wieder	2014		10.1007/978-3-662-43948-7_78	pseudorandom generators for polynomials;theoretical computer science;pseudorandom function family;pseudorandom generator;pseudorandom noise;pseudorandom generator theorem	Theory	18.347701195805232	19.43535875351751	24841
e19febd0dd6c42528b57cc4b025447022342a413	data movement in odd-even merging	gamma function;analysis of algorithms;sorting networks;merging networks;odd even merge;merge exchange sort;zeta function	"""A complete analysis is given of the number of exchanges used by the well-known Batcher’s odd-even merging (and sorting) networks. Batcher’s method involves a fixed sequence of """"compareexchange"""" operations, so the number of comparisons required is easy to compute, but the problem of determining how many comparisons result in exchanges has not been successfully attacked before. New results are derived in this paper giving accurate formulas for the worst-case and average values of this quantity. The worst-case analysis leads to the unexpected result that, asymptotically, the ratio of exchanges to comparisons approaches 1, although convergence to this asymptotic maximum is very slow. The average-case analysis shows that, asymptotically, only 41of the comparators are involved in exchanges. The method used to derive this result can, in principle be used to get any asymptotic accuracy. The derivation involves principles of the theory of complex functions; in particular, properties of the F-function and the generalized Riemann ’-function are integral to the solution. Intermediate results in the analysis may be applicable to the average-case analysis of other merging methods, and the final portion of the derivation illustrates the utility of the """"gamma function"""" method of asymptotic analysis."""	best, worst and average case;comparator;probabilistic analysis of algorithms;sorting;whole earth 'lectronic link	Robert Sedgewick	1978	SIAM J. Comput.	10.1137/0207022	mathematical optimization;combinatorics;discrete mathematics;sorting network;analysis of algorithms;mathematics;algorithm;gamma function;riemann zeta function	Theory	11.80194420358362	24.468858331123716	24862
b3a0b8c75ae31f4acdf93d982c820b97b6421867	heuristics for an assembly flow-shop with non-identical assembly machines and sequence dependent setup times to minimize sum of holding and delay costs	holding and delay costs;non identical assembly machines;imperialist competitive algorithm;simulated annealing;sequence dependent setup time;assembly flow shop	This paper addresses the two-stage assembly flow-shop scheduling problem with non-identical assembly machines at the second stage to minimize a sum of holding and delay costs. Although there are more than one assembly machine in many manufacturing systems, to the best of our knowledge, the two-stage assembly flow-shop scheduling problem (TSAFSP) has never been addressed with more than one assembly machine at stage two. Moreover, setup time is an inevitable factor in many cases and so in this paper, for more reality, sequence dependent setup times are considered for both stages. After extending mathematical modeling, to solve the addressed problem, four hybrid meta-heuristics are developed. A simulated annealing algorithm (SA) and an imperialist competitive algorithm (ICA) in order to find a sequence of jobs at the first stage and a heuristic (HEU) and again SA for assigning addressed jobs to assembly machines in stage two; therefore, these hybrid meta-heuristics are SAþHEU, ICAþHEU, SAþSA and ICAþSA. Computational results reveal that ICAþHEU outperforms all other algorithms; however, the run time of SAþHEU is the smallest among the algorithms. & 2013 Elsevier Ltd. All rights reserved.	computation;flip-flop (electronics);flow shop scheduling;heuristic (computer science);imperialist competitive algorithm;independent computing architecture;job stream;mathematical model;run time (program lifecycle phase);scheduling (computing);simulated annealing	Javad Navaei;Seyyed M. T. Fatemi Ghomi;Fariborz Jolai;Ashkan Mozdgir	2014	Computers & OR	10.1016/j.cor.2013.10.008	mathematical optimization;real-time computing;simulated annealing;computer science;mathematics;imperialist competitive algorithm	AI	14.987513037905893	6.7252050637496055	24885
37892bed8faf8e6ffbdddc056d716c02cfded438	on eliminating the lambda-rules from simple matrix grammars				Gheorghe Paun	1981	Fundam. Inform.		discrete mathematics;combinatorics;mathematics;matrix (mathematics);lambda;rule-based machine translation	Vision	-2.039332897532793	18.73853566527986	24946
5ed1214b36a0517078c32a90c77961f0f4baec14	time-dependent performance analysis of a discrete-time priority queue	performance measure;time dependent;discrete time priority queue;discrete time;transient analysis;technology and engineering;priority queue;performance analysis;generating function	We present the transient analysis of the system content in a two-class discrete-time M/D/1 priority queue. In particular, we derive an expression for the generating function of the transient system contents of both classes at the beginning of slots. Performance measures are calculated from this generating function. To illustrate our approach we conclude with some examples.	nsa product types;priority queue;profiling (computer programming);queueing theory;transient state	Joris Walraevens;Dieter Fiems;Herwig Bruneel	2008	Perform. Eval.	10.1016/j.peva.2008.02.002	discrete time and continuous time;generating function;real-time computing;earliest deadline first scheduling;multilevel queue;bulk queue;double-ended priority queue;computer science;mathematics;distributed computing;queue management system;priority queue	Metrics	7.82313262998649	11.474818768274194	24951
c8074e34d7995287f6235e38b2d2fa67d92d4667	weighted tardiness for the single machine scheduling problem: an examination of precedence theorem productivity	selected works;scheduling;bepress;weighted tardiness	Earlier research by Kanet [11] has provided a number of new theorems for deciding precedence between pairs of jobs for 1jjSwjTj. The theorems supplant those of Rinnooy Kan, Lageweg, and Lenstra [16]. Presented here are the results of an analysis of the marginal benefit these new theorems provide over the earlier versions of Rinnooy Kan et al. Results show that the new theorems can provide noteworthy improvements in the ability to discover precedence relations between job pairs. For a large set of problem instances the new theorems uncovered up to 8% more precedence relations than the original theorems of Rinnooy Kan et al. The improvement in the productivity in discovering precedence relations shows to be dependent on the coefficient of variation of the distribution of job weights. Logical application of the theorems is to include them in search procedures and/or heuristic approaches to 199SwjTj. One such heuristic based on the theorems is provided here in which the solutions to a large set of sample problems are within 8–12% of the optimum. & 2012 Elsevier Ltd. All rights reserved. 1. Single machine weighted tardiness The problem of scheduling a single machine to minimize weighted tardiness is of great practical importance. Every manufacturing firm that organizes the flow of materials through work centers has the problem to decide the sequence in which orders are to be processed at each work center. The choice of sequence is heavily influenced by the desire to meet customer due dates making minimization of tardiness an important goal. Often the manufacturer places different priorities on orders based on specific customers. Thus, minimizing weighted tardiness is the more precise goal. Unfortunately the problem is well known to be NP-hard [12] so that finding good solutions is difficult. Because of its inherent practical importance, combined with its difficulty, the problem has attracted the attention of operations researchers for decades. In the last five years alone one can find dozens of papers in the scientific literature that address this important problem. Many of the papers attack various variations of the problem and develop sophisticated search algorithms and/or heuristic procedures. A few recent examples include the works of Valente and Alves [21], Tseng, Liao, and Huang [20], Tasgetiren, Pan, and Liang [19], Wang and Tang [23], Altunc and Keha [3], and Akturk and Ilhan [2]. Wang and Tang studied the use of a population-based variable neighborhood search (a combination of variable depth and tabu search) to solve instances of 199SwjTj. Altunc and Keha ll rights reserved. also studied 199SwjTj applying a time-indexed mixed integer programming (MIP) formulation. Valente and Alves examined the use of beam search in solving instances of 199SwjTj with sequence dependent setup times. Tasgetiren, Pan, and Liang studied the same problem employing a special evolution algorithm and the apparent tardiness cost (ATC) heuristic of Vepsalainen and Morton [22]. Tseng, Liao, and Huang formulated the problem of single machine weighted tardiness with controllable processing times as an MIP and investigated neighborhood search methods to develop computationally tractable solutions. Akturk and Ilhan addressed the same problem via formulation as a nonlinear MIP. 2. Precedence theorems for 199RwjTj Perhaps because of the inherent complexity of the problem, very few analytical results are available. Among the most powerful analytic results for 199SwjTj is the ability to discover pair-wise precedence between pairs of jobs. First introduced by Emmons [10] theorems for the discovery of such precedencies examine a priori information regarding the required processing times and due dates for pairs of jobs. For two jobs j, and k, such (existential) theorems take the form ‘‘If condition then there exists an optimum schedule in which j precedes k’’. Rinnooy Kan et al. provided three theorems which extend the theorems of Emmons from the case of 199STj to the case of 199SwjTj. Kanet [11] provided six new theorems for 199SwjTj which supplant those of Rinnooy Kan et al. J.J. Kanet, C. Birkemeier / Computers & Operations Research 40 (2013) 91–97 92 Use of precedence relations as described here has played an important role in the development of branch-and-bound procedures for 199SwjTj. See, for example, the well-know report of Potts and Van Wassenhove [15], as well as the more recent developments by Pan and Shi [13] and Bigras, Gamache, and Savard [4]. Each of these authors’ algorithms constructs an initial precedence graph by repeatedly testing the theorems of Rinnooy Kan et al. until no further precedence relations can be generated. The algorithms construct partial sequences in which a node at level l in the search tree corresponds to scheduling the last l positions in the final sequence. Branching to a new partial schedule is done by prefixing a new job to the current partial schedule (i.e., in position n l 1). A new branch is discarded unless all successors of that job in the precedence graph already appear in the partial sequence of l jobs. The purpose here is to investigate the relative improvement in productivity of the theorems of Kanet [11] in terms of their ability to discover precedence relations. Although the intended use of such theorems would logically be to include them in a search procedure, developing such a procedure is unnecessary for the goal of this study. We want to simply determine the marginal improvement in the number of precedence discoveries of the newer Kanet theorems over the earlier theorems of Rinnooy Kan et al. 3. The problem and notation The well researched problem 1jjSwjTj involves a set N of n jobs all available for processing (without interruption) at a single machine. Each job j has a predetermined processing time pj, a due date dj, and a weight wj. The objective is to find a set of job completion times {Cj}8jAN that minimizes SiAN wj max{0, Cj dj}, where the function max{0, Ci di} is the tardiness for job j, Tj. Using the notations of Rinnooy Kan et al., define P(Q)1⁄4SiAQ pi for any set of jobs Q. Define Q0 for QDN as Q0 1⁄4N Q. Define the sets Bi and Ai, as the sets of jobs known to precede i and follow i, respectively, in some optimum sequence. Let the notation ‘‘j! k’’ mean ‘‘there exists an optimum sequence in which job j precedes job k.’’ 4. The power of precedence theorems The ability of pair-wise precedence relations to reduce the search space can be significant. To illustrate, consider an instance of 1jjSwjTj with n jobs. As noted in Kanet [11], whenever we find n 1 precedence relations involving some job j we have 9Bj9þ9Aj91⁄4n 1, allowing the original problem of size n to be subdivided into two independent sub-problems of size 9Bj9 and 9Aj9. For example when n1⁄47, if we discover 6 precedence relations so that 9Bj91⁄46, this partitions the original problem into two problems of size 6 and 0, respectively. We know that all other jobs will precede j, so the solution space reduces from 7!1⁄45040 to 6!1⁄4720 possible sequences. If we found 6 precedence relations involving j so that 9Bj91⁄43 and 9Aj91⁄43, then we have two independent problems of size 3 and the complexity is reduced to 3!þ3!1⁄412. Moreover because of the transitivity of the relation ‘‘!’’ once we discover j! k, then j and all its predecessors inherit k and all followers of k as their followers; and k and all its successors inherit j and all its predecessors as predecessors in some optimum solution; i.e., Ai’Ai [ k [ Ak8iA j [ Bj, and Bi’Bi [ j [ Bk8iAk [ Ak: As these sets grow it may then become easier for another precedence to be discovered, thus the discovery of just a few precedence relations can have a drastic effect in reducing the original problem’s complexity. 5. The relevant theorems The theorems of Rinnooy Kan et al. [16] and Kanet [11] are provided here as reference. RK 1: Given 199 P wjTj and pjrpk and Bj, Bk, Aj, Ak and wjZwk if djrmax{dk, P(Bk)þpk} then j ! k. RK 2: Given 199 P wjTj and Bj, Bk, Aj, Ak and wjZwk if dkZmax{dj, P(Aj)-pk} then j ! k. RK 3: Given 199 P wjTj and Bj, Bk, Aj, Ak and wj, wk if dkZP(Aj) then j ! k. Notice that the above theorems extend those original theorems of Emmons [10] with the added condition (for RK 1 and RK 2) that wjZwk. The theorems of Kanet [11] generalize those of Rinnooy Kan in that the job weights play a role in the theorems’ hypotheses and are relevant for all wj, wk40. The theorems of Kanet are provided below. K 1a: Given 199 P wjTj and pjrpk and Bj, Bk, Aj, Ak and wjZwk If djrmax{dk, (wj-wk)(P(Bj[Bk)þpjþpk)/wjþwkdk/wj} or djr(wj-wk)(P(Bj[Bk)þpjþpk)/wjþwk(P(Bk)þpk)/wj then j ! k. K 1b: Given 199 P wjTj and pjrpk and Bj, Bk, Aj, Ak and wjowk, If dkZ(wk-wj)P(Aj)/wkþwjdj/wk and dkZ(wk-wj)P(Aj)/wkþwj(P(Aj[Ak)-pk)/wk then j ! k. K 1c: Given 199 P wjTj and pjrpk and Bj, Bk, Aj, Ak and wjowk If djr(wj-wk)P(Aj)/wjþwk(P(Bk)þpk)/wj and pjr(wj-wk)(P(Aj)-P(Bk))/wjþwkpk/wj then j ! k. K 2a: Given 199 P wjTj and Bj, Bk, Aj, Ak and wjZwk If dkZmin{dj, (wk-wj)(P(Bj[Bk)þpjþpk)/wkþwjdj/wk} and dkZP(Aj)-wjpk/wk then j ! k. K 2b: Given 199 P wjTj and Bj, Bk, Aj, Ak and wjZwk If djr(wj-wk)(P(Bj[Bk)þpjþpk)/wjþwk(P(Bk)þpk)/wj and pkZwk(P(Aj)-P(Bk)-pk)/wj then j ! k. K 2c: Given 199 P wjTj and Bj, Bk, Aj, Ak and wjowk If dkZ(wk-wj)P(Aj)/wkþwjdj/wk and dkZP(Aj)-wjpk/wk then j ! k. K 3 (RK 3): Given 199 P wjTj and Bj, Bk, Aj, Ak and wj, wk If dkZP(Aj) then j ! k. As noted above, the Kanet theorems generalize those of Rinnooy Kan et al.; the theorem RK 1 reduces to K 1a; RK 2 reduces to K 2a; RK 3 K 3. Theorems K 1b, K 1c, K 2b, and K 2c cover cases not addressed by the RK theorems. RK 1–3 use information only in Bk and Aj; K 1–3 use additional information in Bj[Bk and Aj[Ak. K 1–3 allow for all combinations of pj, pk, wj, and wk (e.g., j! k can be recommended even when wjowk). 6. Assessing the marginal benefit of the new theorems To assess the marginal benefit of the new theorems a computational study wa	arjen lenstra;beam search;branch and bound;cobham's thesis;coefficient;complexity;feasible region;gene kan;heuristic;integer programming;interrupt;job stream;linear programming;linux/rk;marginal model;np-hardness;nonlinear system;operations research;operator-precedence grammar;potts model;precedence graph;regular expression;scheduling (computing);scientific literature;search algorithm;search tree;single-machine scheduling;tabu search;variable neighborhood search;vertex-transitive graph;whole earth 'lectronic link	John J. Kanet;C. Birkemeier	2013	Computers & OR	10.1016/j.cor.2012.05.013	mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;scheduling	AI	24.01105773373962	10.049477260106926	24960
7d2a5d0a0744ddb255488680453913fdeb782521	asynchronous graph-rewriting automata and simulation of synchronous execution	call graph;structural change;graph rewriting;cellular automata	In this paper, we consider asynchronous update scheme for a variant of graph rewriting systems called graph-rewriting automata, and show that synchronous update can be simulated by asynchronous update using a constructed rule set from the one for synchronous update. It is well known that such rule construction is possible on cellular automata or other automata networks whose structures are fixed, but graph rewriting automata induce structural changes and additional mechanism of communication and local synchronization is required. Some simple examples are given by simulation.	automaton;graph rewriting;simulation	Kohji Tomita;Satoshi Murata;Haruhisa Kurokawa	2007		10.1007/978-3-540-74913-4_87	cellular automaton;call graph;continuous spatial automaton;quantum finite automata;computer science;theoretical computer science;asynchronous cellular automaton;structural change;automata theory;distributed computing;graph algebra;mobile automaton;algorithm;graph rewriting	Logic	-0.5058505973121379	24.327628059458597	25034
7e713b3d1bd39cf36a09457a903a35fb750f1b1f	coalgebras, chu spaces, and representations of physical systems		We investigate the use of coalgebra to represent quantum systems, thus providing a basis for the use of coalgebraic methods in quantum information and computation. Coalgebras allow the dynamics of repeated measurement to be captured, and provide mathematical tools such as final coalgebras, bisimulation and coalgebraic logic. However, this application raises new challenges for coalgebra: how to accommodate the contravariance which arises naturally as we represent both the states and the properties of physical systems; and how to represent the symmetries of these systems, which account e.g. for their unitary dynamics. This motivates us to introduce a novel fibrational structure for coalgebra, and also to make new connections betwen coalgebras and Chu spaces.	bisimulation;information and computation;quantum information;quantum system;spaces	Samson Abramsky	2010	2010 25th Annual IEEE Symposium on Logic in Computer Science	10.1007/s10992-013-9276-4	discrete mathematics;pure mathematics;mathematics	Logic	-2.9771321600256617	12.722891208244784	25045
18741f104665343fdd694f6d1df60f657aa4f85b	a hybrid dynamic system model for multimodal transportation electrification	power system dynamics vehicles modeling vehicle dynamics knowledge based systems public transportation;public transportation;power system dynamics;transportation electrification axiomatic design heterofunctional networks hybrid dynamic system multimodal transportation petri nets power systems;vehicles;modeling;vehicle dynamics;knowledge based systems	In recent years, transportation electrification has emerged as a trend to support energy efficiency and CO2 emissions reduction targets. The true success, however, of this trend depends on the successful integration of electric transportation modes into the infrastructure systems that support them. Left unmanaged, plug-in electric vehicles may suffer from delays due to charging or cause destabilizing charging loads on the electrical grid. Online electric vehicles have emerged to remediate the need for stationary charging and its effects. While many works have sought to mitigate these effects with advanced control functionality, such as coordinated charging, vehicle-to-grid stabilization, and charging queue management, few works have assessed these impacts as a holistic transportation-electricity nexus. This paper develops a hybrid dynamic system model for transportation electrification. It also includes next generation traffic simulation concepts of multimodality and multiagency. Such a model can be used by electrified transportation fleet operators to not just assess but also improve their operations and control. The hybrid dynamic system model is composed of a marked Petri-net model superimposed on the continuous time kinematic and electrical state evolution. The model is demonstrated on an illustrative example of moderate size and functional heterogeneity.	advanced process control;agent-based model;algorithm;axiomatic design;connected car;dynamic dispatch;dynamical system;extended validation certificate;holism;ibm power systems;load profile;multi-agent system;multimodal interaction;network congestion;online and offline;petri net;plug-in (computing);quality of service;radial (radio);robustness (computer science);routing;simulation;stationary process;test case	Amro M. Farid	2017	IEEE Transactions on Control Systems Technology	10.1109/TCST.2016.2579602	vehicle dynamics;simulation;systems modeling;engineering;knowledge-based systems;transport engineering;advanced traffic management system	Robotics	4.291866769457232	8.949800827163779	25050
f2f5e48f7c746e0d41fbd211e4c6d892bf412a66	homeostasis in synchronous distributed computation, a formal view	dynamique repartie;distributed computing;computer system;homeostasis;systeme informatique;homeostasie;formalisme;calcul reparti	Abstract   Our objective is to introduce and illustrate a few basic notions upon which a mathematics of distributed computation can begin to develop. The central issue, as we see it, concerns the existence of a distributed, locally determined, global dynamics which responds homeostatically to a changing environment. This paper contains two elementary examples of such systems expressed in terms of our basic notions. A simple theorem characterizing the existence of such systems in a special case is proved. The theorem, the examples, and the associated discussion demonstrate the utility of our formalism.	computation;distributed computing;homeostasis	W. Richard Stark	1983	Inf. Sci.	10.1016/0020-0255(83)90004-X	homeostasis;computer science;artificial intelligence;theoretical computer science;mathematics;algorithm	DB	-2.4993351887137227	26.151977537382113	25118
6cc53f65c367e67f1306877c013ce48b3e3c9c1e	designing cellular networks using a parallel hybrid metaheuristic on the computational grid	radio networks;optimisation sous contrainte;parallel computing;estensibilidad;modelizacion;parallelisme;constrained optimization;distributed system;algoritmo paralelo;multiobjective programming;optimum pareto;programmation multiobjectif;haute performance;metaheuristics;systeme reparti;mise a jour;computational grid;informatique mobile;parallel algorithm;hybrid metaheuristics;systeme modulaire;cellular radio;optimal method;heuristic method;modelo hibrido;combinatorial optimization problem;distributed computing;metodo heuristico;optimization method;sistema modular;analyse multiresolution;algoritmo genetico;modele hybride;metodo optimizacion;genetics;hybrid model;algorithme parallele;computer network;optimisation combinatoire;actualizacion;optimizacion con restriccion;grid;modelisation;combinatorial problem;large scale;probleme combinatoire;parallelism;problema combinatorio;sistema repartido;paralelismo;distributed environment;reseau radio;mathematical programming;red celular;rejilla;mobile telecommunication;cell network;reseau cellulaire;robustesse;modular system;cellular network;methode optimisation;parallel computer;algorithme genetique;alto rendimiento;grille;radio communication;calculo repartido;genetic algorithm;robustness;radiocommunication;extensibilite;scalability;methode heuristique;diversification;radiotelephonie cellulaire;combinatorial optimization;mobile computing;diversificacion;pareto optimum;multiresolution analysis;modeling;grid computing;programmation mathematique;high performance;optimo pareto;calcul reparti;programacion matematica;updating;analisis multiresolucion;radiocomunicacion;distributed architecture;optimizacion combinatoria;robustez;programacion multiobjetivo;cellular network design	6 7 Abstract 8 Cellular network design is a major issue in mobile telecommunication systems. In this paper, a model of the problem in its full prac-9 tical complexity, based on multiobjective constrained combinatorial optimization, has been investigated. We adopted the Pareto 10 approach at resolution in order to compute a set of diversified non-dominated networks, thus removing the need for the designer to rank 11 or weight objectives a priori. We designed and implemented a ''ready-to-use'' platform for radio network optimization that is flexible 12 regarding both the modeling of the problem (adding, removing, updating new antagonist objectives and constraints) and the solution 13 methods. It extends the ''white-box'' ParadisEO framework for metaheuristics applied to the resolution of mono/multi-objective Com-14 binatorial Optimization Problems requiring both the use of advanced optimization methods and the exploitation of large-scale parallel 15 and distributed environments. Specific coding scheme and genetic and neighborhood operators have been designed and embedded. On 16 the other side, we make use of many generic features related to advanced intensification and diversification search techniques, hybrid-17 ization of metaheuristics and grid computing for the distribution of the computations. They aim at improving the quality of networks 18 and robustness, to speed-up the search and obtain results in a tractable time, hence efficiently solving large instances of the problem. 19 Using three realistic benchmarks, the computed networks and speed-ups on different parallel and/or distributed architectures show 20 the efficiency and the scalability of hierarchical models of hybridization and parallelization used in conjunction. 21 Ó 2006 Published by Elsevier B.V. 22 23 1. Introduction 24 The design of large cellular networks is a complex task 25 with a great impact on the quality of service and the cost 26 of the network. Engineering of mobile telecommunication 27 networks involves two major problems: the design of the 28 network and the frequency planning. The design consists 29 in positioning base stations (BS) on potential sites, in order 30 to fulfill some objectives and constraints [20]. The frequen-31 cy planning sets up frequencies used by BS with criteria of 32 reusing. In this paper, we address the first problem. Net-33 work design is an NP-hard combinatorial optimization 34 problem [21]. The BS positioning problem deals with find-35 ing a set of sites for antennas from a set of pre-defined can-36 didate sites, determining the type and the number of 37 antennas, and setting up …	algorithm;bayesian network;cobham's thesis;combinatorial optimization;computation;cylinder-head-sector;diversification (finance);embedded system;grid computing;interference (communication);job design;mathematical optimization;metaheuristic;mobile phone;np-hardness;network planning and design;paradiseo;parallel computing;pareto efficiency;program optimization;quality of service;scalability;software propagation	El-Ghazali Talbi;Sébastien Cahon;Nouredine Melab	2007	Computer Communications	10.1016/j.comcom.2006.08.017	multiresolution analysis;diversification;cellular network;mathematical optimization;constrained optimization;scalability;systems modeling;genetic algorithm;combinatorial optimization;computer science;artificial intelligence;parallel algorithm;grid;mobile computing;algorithm;grid computing;robustness;distributed computing environment	AI	20.812709021917627	7.220285798029889	25208
fdd5a4a6c04957bf86d4cf5892803c14fd7998ee	new model of maximal covering location problem with fuzzy conditions	particle swarm optimization pso;maximal covering location problem mclp;fuzzy conditions	The objective of Maximal Covering Location Problem is locating facilities such that they cover the maximal number of locations in a given radius or travel time. MCLP is applied in many different real-world problems with several modifications. In this paper a new model of MCLP with fuzzy conditions is presented. It uses two types of fuzzy numbers for describing two main parameters of MCLP - coverage radius and distances between locations. First, the model is defined, then Particle Swarm Optimization method for solving the problem is described and tested.	maximal set	Darko Drakulic;Aleksandar Takaci;Miroslav Maric	2016	Computing and Informatics		mathematical optimization;combinatorics;machine learning;mathematics	DB	23.681657838981145	8.35024637184337	25286
1e06430f092cfc8542156376af0e54e843c7d273	simple programming languages and restricted classes of turing machines	programming language;turing machine	Abstract   In this paper we investigate the computational power of simple programming languages and provide characterizations (or partial characterizations) of the functions computable by such programs in terms of some space and/or time complexity classes of Turing machines. Call a function  f ( x  1 ,…, x  1 ) over the nonnegative integers linearly bounded if  f ( x  1 ,…, x  1 ) O ( x  1 +…+ x  1 ). We show that any linearly bounded function  f ( x  1 ,…, x  1 ) computable by a Turing machine in  O ( n ) space and  O (2  λn  ) time, where  λ   n=¦x     1   +…+x     1   ¦   is the length of the binary representation of  x  1 +…+ x  1 , can be computed by a program without nested loops using only the instruction set   R  =x←x−1,   if   x=0   then   y←y+1,   do   x…lcubendrcub  . Thus, functions like   ¦x  y  ¦, ged{x,y},   x  k  , [log x]  , etc. can be computed by  R -programs. Any function computable by an   R  -program can be computed by a Turing machine in  O ( n ) space and  O (2  n  ) time. It is open whether or not the time can be reduced to  O (2  λ  ) for some  λ  f ( x  1 ,…, x  1  over the nonnegative integers is computable by a linear space bounded Turing machine if and only if it is computable by a program using only the constructs   x←1, x←x+y, x←x−y,   do   x…  end   such that (i) there are no nested loops, and (ii) the occurence of a construct  x ← x + y  in a loop precludes the occurrence of a construct  y ← x + z  within the same loop. Extensions are also made for some time complexity classes of Turing machines.	turing machine	Oscar H. Ibarra;Louis E. Rosier	1983	Theor. Comput. Sci.	10.1016/0304-3975(83)90085-3	linear speedup theorem;combinatorics;discrete mathematics;computer science;turing machine;mathematics;programming language;computable number;algorithm;algebra	Theory	4.001660446399924	23.33693737626776	25329
1cbd73068205b0ed04ebadbe1cc43eac9d8b310f	technical report: performance of the expected force on as-level inernet topologies		The Expected Force (ExF) is a metric which quantifies the spreading power of all network nodes. It is derived from a continuous-time epidemiological perspective, and uses the combinatorics inherent in local topology to compute the influence of each node. This is in direct contrast to the usual approach to measuring centrality, which is counting some type of walk on a network [1, 2]. The ExF has been previously shown to strongly and significantly outperform other existing centrality measures in predicting the outcome of spreading processes on many complex networks [3]. Infrastructure networks, however, are different from other networks in that they are strongly constrained by specific engineering and economic constraints. A study of Internet connectivity on the router-level found that the high performance topologies which result from a design process are extremely rare to occur by chance, whereas more likely random networks have poor performance [4]. Likewise, airline traffic networks maximize dynamic traffic flows, whereas social networks often experience bottlenecks to dynamic transfer of information [5]. This raises the question of how the ExF will perform on highly engineered network topologies. This technical report presents an evaluation of the ExF on real world snapshots of the Internet’s autonomous system (AS) level connectivity. As in [3], comparison is made to the eigenvalue centrality and the k-shell. The ExF is shown to be strongly predictive of node influence, significantly outperforming the other measures.	autonomous system (internet);centrality;complex network;flow network;internet;network topology;randomness;router (computing);social network	Glenn Lawyer	2014	CoRR		simulation;artificial intelligence;mathematics;distributed computing	Metrics	-3.7194818661125715	5.820781952172451	25352
38eb836c870775d5c4db9c0a8bf85abdd1dac503	ac-3d an efficient arc-consistency algorithm with a low space-complexity	search problem;complejidad espacio;algoritmo busqueda;algorithm complexity;search space;algorithme recherche;complejidad algoritmo;heuristic method;search algorithm;arc consistency;metodo heuristico;problema investigacion;constraint satisfaction;satisfaction contrainte;complexite algorithme;estructura datos;space complexity;structure donnee;methode heuristique;satisfaccion restriccion;complexite espace;probleme recherche;data structure;constraint sat isfaction problem	Arc-consistency algorithms are widely used to prune the sea rch-space of Constraint Satisfaction Problems ( CSPs). They usesupport-checksto find out about the properties of CSPs. They usearc-heuristicsto select the constraint and domain-heuristicsto select the values for their next support-check. We will demonstrate that domain-heuri stics can significantly enhance the average time-complexity of existing arc-consistency algo rithms. We will combine Alan Mackworth’s AC-3 and John Gaschnig’s DEE and equip the resulting hybrid with a double-support domain-heuristic thereby creating an arc-consistency alg orithm calledAC-3d, which has an average time-complexity which can compete with AC-7 and which improves onAC-7’s space-complexity. AC-3d is easy to implement and requires the same data structures as AC-3. We will present experimental results to justify our average time-c omplexity claim.	algorithm;constraint satisfaction;dspace;data structure;experiment;heuristic;lexicography;local consistency;recommender system;time complexity	Marc R. C. van Dongen	2002		10.1007/3-540-46135-3_58	mathematical optimization;data structure;constraint satisfaction;search problem;computer science;calculus;mathematics;dspace;constraint satisfaction problem;algorithm;local consistency;search algorithm	AI	11.232562002156767	16.950123327815916	25385
a5d6bc6e031e62fe0858a4b92472edf677ebe0f9	simple linear time recognition of unit interval graphs	design of algorithms;graphe intervalle;interval graph;unit interval graphs;grafo intervalo;temps lineaire;proper interval graphs;reconocimiento;linear time algorithm;tiempo lineal;algorithme;algorithm;recognition;interval graphs;linear time;graph algorithm;breadth first search;reconnaissance;graph algorithms;algoritmo	We present a linear time algorithm for unit interval graph recognition. The algorithm is simple and based on Breadth-First Search. It is also direct | it does not rst recognize the graph as an interval graph. Given a graph G, the algorithm produces an ordering of the vertices of the graph whenever G is a unit interval graph. This order corresponds to the order of the intervals of some unit interval model for G when arranged according to the increasing order of their left end coordinates. Breadth-First Search can also be used to construct a unit interval model for a unit interval graph on n vertices; in this model each endpoint is rational, with denominator n.	algorithm;breadth-first search;communication endpoint;time complexity;vertex (geometry)	Derek G. Corneil;Hiryoung Kim;Sridhar Natarajan;Stephan Olariu;Alan P. Sprague	1995	Inf. Process. Lett.	10.1016/0020-0190(95)00046-F	time complexity;graph power;unit disk graph;factor-critical graph;combinatorics;geometric graph theory;discrete mathematics;interval graph;graph bandwidth;breadth-first search;null graph;degree;computer science;distance-regular graph;simplex graph;comparability graph;cycle graph;mathematics;voltage graph;butterfly graph;quartic graph;complement graph;indifference graph;line graph;algorithm;string graph;strength of a graph	Graphics	24.534238425503016	28.609597018264328	25394
295efa3e6bfebe2481e806536adb1891ccb5f550	simple and space-efficient minimal perfect hash functions	linear time;hash function;information theoretic	A perfect hash function (PHF) h : U → [0, m − 1] for a key set S is a function that maps the keys of S to unique values. The minimum amount of space to represent a PHF for a given set S is known to be approximately 1.44n/m bits, where n = |S|. In this paper we present new algorithms for construction and evaluation of PHFs of a given set (for m = n and m = 1.23n), with the following properties: 1. Evaluation of a PHF requires constant time. 2. The algorithms are simple to describe and implement, and run in linear time. 3. The amount of space needed to represent the PHFs is around a factor 2 from the information theoretical minimum. No previously known algorithm has these properties. To our knowledge, any algorithm in the literature with the third property either: – Requires exponential time for construction and evaluation, or – Uses near-optimal space only asymptotically, for extremely large n. Thus, our main contribution is a scheme that gives low space usage for realistic values of n. The main technical ingredient is a new way of basing PHFs on random hypergraphs. Previously, this approach has been used to design simple PHFs with superlinear space usage. ⋆ This work was supported in part by GERINDO Project–grant MCT/CNPq/CTINFO 552.087/02-5, and CNPq Grants 30.5237/02-0 (Nivio Ziviani) and 142786/2006-3 (Fabiano C. Botelho) 3 This version of the paper is identical to the one published in the WADS 2007 proceedings. Unfortunately, it does not give reference and credit to the paper The Bloomier Filter: An Efficient Data Structure for Static Support Lookup Tables, by Chazelle et al., Proceedings of SODA 2004. They present a way of constructing PHFs that is equivalent to ours. It is explained as a modification of the “Bloomier Filter” data structure at the end of Section 3.3, but they do not make explicit that a PHF is constructed. Thus, the simple construction of a PHF described must be attributed to Chazelle et al. The new contribution of this paper is to analyze and optimize the constant of the space usage considering implementation aspects as well as a way of constructing MPHFs from that PHFs.	algorithm;bloom filter;cryptographic hash function;data structure;information theory;lookup table;map;mobile data terminal;perfect hash function;space–time tradeoff;time complexity	Fabiano C. Botelho;Rasmus Pagh;Nivio Ziviani	2007		10.1007/978-3-540-73951-7_13	time complexity;combinatorics;discrete mathematics;hash function;perfect hash function;computer science;mathematics;rolling hash;algorithm;hash filter	Theory	11.169025227923369	25.19505809715112	25500
0599ff80eaf3065311dc63a69074c3fe27a80641	guessing more secrets via list decoding	list decoding;reed solomon code	We consider the following game introduced by Chung, Graham, and Leighton in [Chung et al. 01]. One player, A, picks k > 1 secrets from a universe of N possible secrets, and another player, B, tries to gain as much information about this set as possible by asking binary questions f : [N ] −→ {0, 1}. Upon receiving a question f , A adversarially chooses one of her k secrets, and answers f according to it. In this paper we present an explicit set of 2(log N) questions, along with a	graham scan;list decoding	Alexander A. Razborov	2005	Internet Mathematics	10.1080/15427951.2005.10129099	arithmetic;list decoding;artificial intelligence;mathematics;reed–solomon error correction;algorithm;statistics	Theory	9.877394728072955	24.782714665978567	25503
90679cf47f60cac8b1b5e967e1d6b4c5e1640d93	lower bounds on the complexity of recognizing sat by turing machines	machine turing;complexite calcul;turing machine;satisfiability;sat;complejidad computacion;computational complexity;borne inferieure;time space tradeoffs;satisfaisabilite;satifiability;maquina turing;lower bound;cota inferior	 this paper are strengthenings of the results in [4] and[9] for Turing machines. The results in [4] and [9] hold for SAT but ourresults hold for 2-SAT also, since the formulae we reduce the language L tobelong to 2-SAT. Therefore our techniques are less promising if the ultimategoal is to prove that SAT does not belong to P, since it is known that 2-SATbelongs to P. Moreover we obtain the same lower bounds for NTMs as forDTMs, which indicates that our techniques may not be useful in... 	boolean satisfiability problem;turing machine	Rahul Santhanam	2001	Inf. Process. Lett.	10.1016/S0020-0190(00)00227-1	linear speedup theorem;np;turing reduction;time hierarchy theorem;pspace;alternating turing machine;nspace;computer science;turing machine;artificial intelligence;machine learning;universal turing machine;2-exptime;mathematics;probabilistic turing machine;dspace;upper and lower bounds;computational complexity theory;non-deterministic turing machine;algorithm;dtime;satisfiability;super-recursive algorithm	DB	6.537053749479402	21.69935888808675	25531
4131edfed7a6a63367a2474e03414a59f57906d2	restricted ambiguity of erasing morphisms	pattern languages;conference contribution;decision problem;erasing morphisms;pattern language;ambiguity;article	A morphism h is called ambiguous for a string s if there is another morphism that maps s to the same image as h; otherwise, it is called unambiguous. In this paper, we examine some fundamental problems on the ambiguity of erasing morphisms. We provide a detailed analysis of so-called ambiguity partitions, and our main result uses this concept to characterise those strings that have a morphism of strongly restricted ambiguity. Furthermore, we demonstrate that there are strings for which the set of unambiguous morphisms, depending on the size of the target alphabet of these morphisms, is empty, finite or infinite. Finally, we show that the problem of the existence of unambiguous erasing morphisms is equivalent to some basic decision problems for nonerasing multi-pattern languages.		Daniel Reidenbach;Johannes C. Schneider	2011	Theor. Comput. Sci.	10.1016/j.tcs.2011.02.041	combinatorics;discrete mathematics;computer science;decision problem;pattern language;mathematics;algorithm	ECom	-3.9561267605570474	17.483820780074577	25582
2a556fda0c5656db2e868cd6aeb6796eee73f9be	division algorithm for cellular automata rules		Given two cellu lar automata rules represented as operato rs Q and X, together with certain nat ural restrictions on their neighborhood st ruct ures , an algor ithm is provided which yields two other rules, A and R, such that Q = AX +R. A generalized arithmetic of residues follows from this.	automata theory;cellular automaton;division algorithm;microsoft dynamics ax;network address translation;ural (computer)	Burton Voorhees	1990	Complex Systems		mathematics;division algorithm;stochastic cellular automaton;discrete mathematics;cellular automaton;mobile automaton;nat;growcut algorithm	Logic	-0.4300605871058272	23.283028846907275	25592
61f500a78839f55ae6691d89e7b2313eafe73287	clique-based facets for the precedence constrained knapsack problem	network design;nova;research repository;university of newcastle;knapsack problem;integer programming;clique inequalities;precedence constraint;institutional repository;research online	We consider a knapsack problem with precedence constraints imposed on pairs of items, known as the precedence constrained knapsack problem (PCKP). This problem has applications in manufacturing and mining, and also appears as a subproblem in decomposition techniques for network design and related problems. We present a new approach for determining facets of the PCKP polyhedron based on clique inequalities. A comparison with existing techniques, that lift knapsack cover inequalities for the PCKP, is also presented. It is shown that the clique-based approach generates facets that cannot be found through the existing cover-based approaches, and that the addition of clique-based inequalities for the PCKP can be computationally beneficial, for both PCKP instances arising in real applications, and applications in which PCKP appears as an embedded structure. N. Boland (B) School of Mathematical and Physical Sciences, University of Newcastle, Callaghan, NSW 2308, Australia e-mail: natashia.boland@newcastle.edu.au A. Bley Technical University Berlin, Straße des 17. Juni 136, 10623 Berlin, Germany e-mail: bley@math.tu-berlin.de C. Fricke TSG Consulting, Level 11, 350 Collins Street, Melbourne, VIC 3000, Australia G. Froyland School of Mathematics and Statistics, University of New South Wales, Sydney, NSW 2052, Australia e-mail: g.froyland@unsw.edu.au R. Sotirov Universiteit van Tilburg Warandelaan 2, P.O. Box 90153, 5000 LE Tilburg, The Netherlands e-mail: r.sotirov@uvt.nl	basis (linear algebra);branch and bound;clique (graph theory);convex hull;directed graph;email;embedded system;knapsack problem;lagrangian relaxation;linear programming relaxation;mos technology vic-ii;network planning and design;polyhedron;serializability;set packing;successive over-relaxation;tree (data structure);vertex cover	Natashia Boland;Andreas Bley;Christopher Fricke;Gary Froyland;Renata Sotirov	2012	Math. Program.	10.1007/s10107-010-0438-7	continuous knapsack problem;mathematical optimization;network planning and design;combinatorics;integer programming;cutting stock problem;change-making problem;mathematics;nova;knapsack problem;algorithm	Theory	22.910906434380117	9.731353180395143	25593
2eab3b645ae24219ed1604bc52e629da766b0a66	a solution to the ghi problem for best-first search	graph-history interaction ghi problem;best-rst search;base-twin algorithm bta.	In a search graph the node's value is dependent on the path leading to it. Diierent paths may lead to diierent values. Hence, it is diicult to determine the value of any node unambiguously. The problem is known as the graph-history-interaction (GHI) problem. This report provides a solution for best-rst search. First, we give a precise formulation of the problem. Then we review all important earlier proposals to overcome it, also for other searches than best rst. Next, our solution is given in outline. The solution is implemented in a best-rst search algorithm. Experimental results in the eld of computer chess connrm the claim that the GHI problem has been solved for best-rst search. Search algorithms are used in many domains, ranging from theorem proving to computer games. The algorithms are searching in a search space containing problem states (positions), often represented as nodes. A move which transforms a position into a new position is represented as an edge connecting the two nodes. In a search tree, it may happen that identical nodes are encountered at diierent places. If these so-called transpositions are not recognized, the search algorithm unnecessarily expands identical subtrees. Therefore, it is prootable to recognize transpositions and to ensure that for each set of identical nodes, only one subtree is expanded. In computer-chess programs using a depth-rst search algorithm, this idea is realized by storing the result of a node's investigation in a transposition table (e.g., Hyatt et al. (1984); Marsland (1986)). If an identical node is encountered in the search process, the result is retrieved from the transposition table and used without further investigation. If a (selective) best-rst search algorithm (which stores the whole search tree in memory) is used, the search tree is converted into a search graph, by joining identical nodes into one node, thereby merging the subtrees. These common ways of dealing with transpositions contain an important aw: determining whether nodes are identical is not the same as determining whether the search states represented by the nodes are identical. For two reasons, the path leading to a node cannot be ignored. First, the history of a node may partly determine the legitimacy of a move. For instance, in chess, castling rights are not only determined by the position of the pieces on the board, but also by the knowledge that in the position under investigation the King and Rook have not moved previously.	automated theorem proving;best-first search;chess engine;computer chess;definite clause grammar;pc game;search algorithm;search tree;test set;transposition table;tree (data structure)	Dennis M. Breuker;H. Jaap van den Herik;Jos W. H. M. Uiterwijk;L. Victor Allis	1998		10.1007/3-540-48957-6_3	interpolation search;beam search;mathematical optimization;bidirectional search;counting problem;artificial intelligence;jump search;mathematics;incremental heuristic search;iterative deepening depth-first search;best-first search;combinatorial search;algorithm;fringe search;search algorithm	AI	9.856153965016807	15.867276848323028	25621
19f250bfa62f44573683b6519c8de1b600ef220a	how many queries are needed to learn?	exact identification;polynomial time hierarchy;equivalence queries;temps polynomial;learning;time complexity;query formulation;polynomial query learning;formulacion pregunta;calculo automatico;equivalence;formulation question;computing;proper learning;algorithme;aprendizaje;calcul automatique;algorithm;apprentissage;induccion;certificates;query complexity;induction;calcul numerique;numerical computation;calculo numerico;polynomial time;membership queries;polynomial time learning;equivalencia;lower bound;algoritmo;tiempo polinomial	We investigate the query complexity of exact learning in the membership and (proper) equivalence query model. We give a complete characterization of concept classes that are learnable with a polynomial number of polynomial sized queries in this model. We give applications of this characterization, including results on learning a natural subclass of DNF formulas, and on learning with membership queries alone. Query complexity has previously been used to prove lower bounds on the time complexity of exact learning. We show a new relationship between query complexity and time complexity in exact learning: If any “honest” class is exactly and properly learnable with polynomial query complexity, but not learnable in polynomial time, then P = NP. In particular, we show that an honest class is exactly polynomial-query learnable if and only if it is learnable using an oracle for Γ p  4 .		Lisa Hellerstein;Krishnan Pillaipakkamnatt;Vijay Raghavan;Dawn Wilkins	1996	J. ACM	10.1145/234752.234755	time complexity;mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;algorithm	Theory	4.519773326830304	17.852195571525932	25673
10aa2d57d4449bc833f6633b06c0d25a91724d25	learning complexity vs. communication complexity	communication complexity	This paper has two main focal points. We first consider an important class of machine learning algorithms - large margin classifiers, such as support vector machines. The notion of margin complexity quantifies the extent to which a given class of functions can be learned by large margin classifiers. We prove that up to a small multiplicative constant, margin complexity is equal to the inverse of discrepancy. This establishes a strong tie between seemingly very different notions from two distinct areas. In the same way that matrix rigidity is related to rank, we introduce the notion of rigidity of margin complexity. We prove that sign matrices with small margin complexity rigidity are very rare. This leads to the question of proving lower bounds on the rigidity of margin complexity. Quite surprisingly, this question turns out to be closely related to basic open problems in communication complexity, e.g., whether PSPACE can be separated from the polynomial hierarchy in communication complexity. There are numerous known relations between the field of learning theory and that of communication complexity, as one might expect since communication is an inherent aspect of learning. The results of this paper constitute another link in this rich web of relations. This link has already proved significant as it was used in the solution of a few open problems in communication complexity.	algorithm;communication complexity;discrepancy function;focal (programming language);machine learning;margin classifier;pspace;polynomial hierarchy;support vector machine	Nathan Linial;Adi Shraibman	2008	2008 23rd Annual IEEE Conference on Computational Complexity	10.1017/S0963548308009656	complete;time complexity;complexity class;combinatorics;margin;discrete mathematics;complexity;average-case complexity;decision tree model;structural complexity theory;sparse language;worst-case complexity;communication complexity;complexity index;mathematics;up;low;game complexity;descriptive complexity theory	Theory	8.890902926965495	19.83953035961686	25676
c2b85569e83700a489f24f7e193bc68a0d02fe94	some fixed-point results for the dynamic assignment problem	optimal solution;assignment problem;dynamic assignment problem;fixed point	In previous work the authors consider the dynamic assignment problem, which involves solving sequences of assignment problems over time in the presence of uncertain information about the future. The algorithm proposed by the authors provides generally high-quality but non-optimal solutions. In this work, though, the authors prove that if the optimal solution to a dynamic assignment problem in one of two problem classes is unique, then the optimal solution is a fixed point under the algorithm.	algorithm;assignment problem;fixed point (mathematics)	Michael Z. Spivey;Warren B. Powell	2003	Annals OR	10.1023/B:ANOR.0000004760.20323.fc	augmented assignment;mathematical optimization;combinatorics;discrete mathematics;linear bottleneck assignment problem;generalized assignment problem;mathematics;fixed point;assignment problem;weapon target assignment problem;quadratic assignment problem	Theory	23.256722786836658	11.680960371090345	25705
08b4fbac9d54287620054e74f1c45cb90d23ea49	buyback problem with discrete concave valuation functions		We discuss an online discrete optimization problem called the buyback problem. In the literature of the buyback problem, the valuation function representing the value of a set of selected elements is given by a linear function. In this paper, we consider a generalization of the buyback problem using a nonlinear valuation function. We propose an online algorithm for the problem with a discrete concave valuation function, and show that it achieves the same competitive ratio as the best possible ratio for a linear valuation function.	concave function;value (ethics)	Shun Fukuda;Akiyoshi Shioura;Takeshi Tokuyama	2017	Discrete Optimization	10.1016/j.disopt.2017.07.002	discrete valuation	Logic	17.702937075118264	13.979720216080011	25714
b21d500f41c5209303e4b9670cca4a180663b3f3	coin tossing algorithms for integral equations and tractability	integral equation	Integral equations with Lipschitz kernels and right-hand sides are intractable for deterministic methods, the complexity increases exponentially in the dimension d. This is true even if we only want to compute a single function value of the solution. For this latter problem we study coin tossing algorithms (or restricted Monte Carlo methods), where only random bits are allowed. We construct a restricted Monte Carlo method with error e that uses roughly e−2 function values and only d log2 e random bits. The number of arithmetic operations is of the order e−2 + d log2 e. Hence, the cost of our algorithm increases only mildly with the dimension d, we obtain the upper bound C · (e−2 + d log2 e) for the complexity. In particular, the problem is tractable for coin tossing algorithms.	algorithm	Erich Novak;Harald Pfeiffer	2004	Monte Carlo Meth. and Appl.	10.1515/mcma.2004.10.3-4.491	mathematical optimization;combinatorics;discrete mathematics;mathematics;integral equation	EDA	10.984226949436586	20.75198088046907	25721
e82208c393a0be7164fdc535165865364e1d7f51	dynamic pricing and balancing mechanism for a microgrid electricity market		The trading is a well known, easy and efficient method of distributing goods. Energy cannot be stored efficiently, which implies that supply and demand of power has to be balanced at all times; this adds complexity to the trading of electric power. Introduction of microgrids, with internal balancing of power and trading with external power grid, brings many questions about power distribution, sharing of costs and revenues. Using market mechanism for such purpose seems appropriate. In this article we present an example of balancing a microgrid with its own energy production sources and connected to a higher voltage distribution grid, by introduction of the continuous double auction market with agents following the Adaptive-Aggressive Strategy.	microgrid	Jaroslaw Stanczak;Weronika Radziszewska;Zbigniew Nahorski	2014		10.1007/978-3-319-11310-4_69	financial economics;microeconomics;business;market economy	ECom	1.9363726951951288	5.501484541589931	25783
1f97cae9cfad03d8ef33b451dee00b7e444b368f	fast and flexible packed string matching	text algorithms;online searching;information retrieval;experimental algorithms;exact string matching	Searching for all occurrences of a pattern in a text is a fundamental problem in computer science with applications in many other fields, like natural language processing, information retrieval and computational biology. In the last two decades a general trend has appeared trying to exploit the power of the word RAM model to speed-up the performances of classical string matching algorithms. In this model an algorithm operates on words of length w, grouping blocks of characters, and arithmetic and logic operations on the words take one unit of time.In this paper we use specialized word-size packed string matching instructions, based on the Intel streaming SIMD extensions (SSE) technology, to design a very fast string matching algorithm. We evaluate our solution in terms of efficiency, stability and flexibility, where we propose to use the deviation in running time of an algorithm on distinct equal length patterns as a measure of stability.From our experimental results it turns out that, despite their quadratic worst case time complexity, the new presented algorithm becomes the clear winner on the average in many cases, when compared against the most recent and effective algorithms known in literature. A very fast algorithm based on specialized word-size packed string matching instructions.The algorithm works using the Intel streaming SIMD extensions (SSE) technology.We prove the effectiveness of our solution in terms of running times, stability and flexibility.Our solution turns out to be the fastest algorithm for short patterns in the average case.We conduct and discuss a wide series of experimental tests.	heuristic (computer science);performance;streaming simd extensions;string searching algorithm;time complexity	Simone Faro;M. Oguzhan Külekci	2014	J. Discrete Algorithms	10.1016/j.jda.2014.07.003	mathematical optimization;combinatorics;commentz-walter algorithm;computer science;theoretical computer science;machine learning;boyer–moore string search algorithm;mathematics;programming language;string metric;algorithm;rabin–karp algorithm;string searching algorithm	Theory	12.436652963243516	27.699086511453025	25804
0262fafbe25842f857de2a5cc22e3d891285f7a4	analysis of boolean functions		Boolean functions are perhaps the most basic objects of study in theoretical computer science. They also arise in other areas of mathematics, including combinatorics, statistical physics, and mathematical social choice. The field of analysis of Boolean functions seeks to understand them via their Fourier transform and other analytic methods. This text gives a thorough overview of the field, beginning with the most basic definitions and proceeding to advanced topics such as hypercontractivity and isoperimetry. Each chapter includes a highlight application such as Arrowu0027s theorem from economics, the Goldreich-Levin algorithm from cryptography/learning theory, Hstadu0027s NP-hardness of approximation results, and sharp threshold theorems for random graph properties. The book includes roughly 450 exercises and can be used as the basis of a one-semester graduate course. It should appeal to advanced undergraduates, graduate students, and researchers in computer science theory and related mathematical fields.	computational complexity theory	Li-Yang Tan	2012	CoRR		mathematics education;computer science;artificial intelligence;algorithm	Logic	6.450380439240852	16.278153831652894	25809
5062ddbf53555b18c589d34160149eea0080fc70	bi-polynomial rank and determinantal complexity		The permanent vs. determinant problem is one of the most important problems in theoretical computer science, and is the main target of geometric complexity theory proposed by Mulmuley and Sohoni. The current best lower bound for the determinantal complexity of the d by d permanent polynomial is d/2, due to Mignon and Ressayre in 2004. Inspired by their proof method, we introduce a natural rank concept of polynomials, called the bi-polynomial rank. The bi-polynomial rank is related to width of an arithmetic branching program. We prove that the bi-polynomial rank gives a lower bound of the determinantal complexity. As a consequence, the above Mignon and Ressayre bound is improved to (d− 1)+1 over the field of reals. We show that the computation of the bi-polynomial rank is formulated as a rank minimization problem. We propose a computational approach for giving a lower bound of this rank minimization, via techniques of the concave minimization. This also yields a new strategy to attack the permanent vs. determinant problem.	binary decision diagram;computation;computational complexity theory;concave function;geometric complexity theory;ketan mulmuley;low-rank approximation;polynomial;theoretical computer science	Akihiro Yabe	2015	CoRR		combinatorics;discrete mathematics;mathematics;rank;algebra	Theory	24.604109291319574	14.77807177282628	25812
0bd51f149a2c196613723309f554507571df1420	on approximating minimum infrequent and maximum frequent sets	greedy algorithm	The maximum cardinality of a frequent set as well as the minimum cardinality of an infrequent set are important characteristic numbers in frequent (item) set mining. Gunopulos et al. [10] have shown that finding a maximum frequent set is NP-hard. In this paper I show that the minimization problem is also NP-hard. As a next step I investigate whether these problems can be approximated. While a simple greedy algorithm turns out to approximate a minimum infrequent set within a logarithmic factor one can show that there is no such algorithm for the maximization problem.	approximation algorithm;expectation–maximization algorithm;greedy algorithm;np-hardness	Mario Boley	2007		10.1007/978-3-540-75488-6_8	mathematical optimization;combinatorics;greedy algorithm;discrete mathematics;computer science;mathematics	ML	24.30180610282595	19.538193622089903	25842
26af3f245cd76702edbf2879a5257d261cf0755f	compact milp models for optimal and pareto-optimal lad patterns	lad;milp;maximum prime pattern;strong prime pattern;maximum spanned pattern;strong spanned pattern	This paper develops MILP models for various optimal and Pareto-optimal LAD patterns that involve at most 2n 0-1 decision variables, where n is the number of support features for the data under analysis, which usually is small. Noting that the previous MILP pattern generation models are defined in 2n+m 0-1 variables, where m is the number of observations in the dataset with m@?n in general, the new models are expected to generate useful LAD patterns more efficiently. With experiments on six well-studied machine learning datasets, we first demonstrate the efficiency of the new MILP models and next use them to show different utilities of strong prime patterns and strong spanned patterns in enhancing the overall classification accuracy of a LAD decision theory.	least absolute deviations;pareto efficiency	Cui Guo;Hong Seo Ryoo	2012	Discrete Applied Mathematics	10.1016/j.dam.2012.05.006	mathematical optimization;combinatorics;discrete mathematics;mathematics	ML	23.706881317059775	15.879674124534091	25876
315f1a2f0287a349a642840262ee67109e6ce81d	the reconstruction and optimization of trie hashing functions	mathematical analysis;hash function;data structure;structural properties	We propose an adaptation to the trie hashing algorithm published by W. Litwin in 1980. This adaptation extends the algorithm so that it will save necessary information on secondary storage to reconstruct the hashing function after loss of information (E.G., system crash or termination of a find/insert program). An algorithm is given to reconstruct the trie from the information saved, and another for optimizing the reconstructed trie. A mathematical analysis of the trie data structure is given, making visible the essential structural properties of these tries; based on this analysis correctness of the algorithms presented can be established.	algorithm;auxiliary memory;computer data storage;correctness (computer science);cryptographic hash function;data structure;rendezvous hashing;trie	Leen Torenvliet;Peter van Emde Boas	1983			feature hashing;hopscotch hashing;hash table;double hashing;hash function;perfect hash function;extendible hashing;dynamic perfect hashing;data structure;computer science;theoretical computer science;universal hashing;database;k-independent hashing;rolling hash;locality preserving hashing;hash array mapped trie;locality-sensitive hashing;hash tree	Theory	9.959903382574126	29.292747861602138	25938
775d8484981fe8e65953e4905c4371b8d5fecf06	anytime graph matching		In this paper, we propose and explain the use of anytime algorithms in graph matching (GM). GM methods have been involved in many pattern recognition problems. In such a context, GM methods are part of a more complex retrieval system that imposes time and memory constraints on such methods. Anytime algorithms are well suited for use in such an uncertain environment. An anytime algorithm quickly provides the first solution to the problem, finds a list of improved solutions and eventually converges to the optimal solution instead of providing one and only one solution (i.e., the optimal solution). We describe how to convert a recent depth-first GM method into an anytime one. By constraining the solver, the algorithm creates an anytime heuristic search algorithm that allows a flexible trade-off between the search time and the solution quality. We analyze the properties of the resulting anytime algorithm and consider its performance in terms of the deviation of the provided solution from the optimal or the best one found by a state-of-the-art method. Experiments were carried out on seven different types of graph datasets. Moreover, the adopted algorithm was compared to four approximate error-tolerant GM methods. Results showed that the anytime GM can outperform suboptimal methods by only waiting for a small amount of supplementary time. This conclusion brings into question the usual evidence that claims that it is impossible to use optimal GM methods in real-world applications. c © 2016 Elsevier Ltd. All rights reserved.	anytime algorithm;approximation algorithm;depth-first search;error-tolerant design;heuristic;matching (graph theory);optimization problem;pattern recognition;search algorithm;solver	Zeina Abu-Aisheh;Romain Raveaux;Jean-Yves Ramel	2016	Pattern Recognition Letters	10.1016/j.patrec.2016.10.004	mathematical optimization;computer science;machine learning;mathematics;algorithm	AI	23.613292677762118	4.404456371573889	25986
76d270cbac3821d2c8e0a983f4f5213f50ba38ea	approximation schemes for minimizing total (weighted) completion time with release dates on a batch machine	esquema;longest processing time;temps polynomial;approximation numerique;traitement par lot;polynomial;procesamiento por lote;aproximacion numerica;processing time;schema;41a10;aproximacion polinomial;informatique theorique;scheduling;polinomio;complecion;approximation polynomiale;batch process;polynomial time;approximation scheme;temps traitement;fully polynomial time approximation scheme;numerical approximation;batch processing;polynome;completion;scheme;tiempo proceso;journal magazine article;polynomial time approximation scheme;ordonnancement;reglamento;polynomial approximation;computer theory;68m20;tiempo polinomial;informatica teorica	A batch machine is a machine that can process a number of jobs simultaneously as a batch, and the processing time of a batch is equal to the longest processing time of the jobs assigned to it. In this paper we present a polynomial time approximation scheme (PTAS) for scheduling a batch machine to minimize the total completion time with job release dates. Also, we present a fully polynomial time approximation scheme (FPTAS) for scheduling an unbounded batch machine, which can process an arbitrary number of jobs simultaneously, to minimize the total weighted completion time with job release dates.	batch processing;ptas reduction;polynomial;polynomial-time approximation scheme;scheduling (computing);time complexity	Zhaohui Liu;T. C. Edwin Cheng	2005	Theor. Comput. Sci.	10.1016/j.tcs.2005.07.028	mathematical optimization;combinatorics;polynomial-time approximation scheme;computer science;mathematics;algorithm;batch processing	Theory	16.93156409042884	10.863230957114938	25996
ff2458db46b40107ca2c02c5ef58dae6b8653f69	nondeterministic state complexity for suffix-free regular languages	regular language;finite state automaton;automata theory;upper and lower bounds;formal language	We investigate the nondeterministic state complexity of ba sic operations for suffix-free regular languages. The nondeterministic state complexity of an operat ion is the number of states that are necessary and sufficient in the worst-case for a minimal nondete rministic finite-state automaton that accepts the language obtained from the operation. We consid er basic operations (catenation, union, intersection, Kleene star, reversal and complementation) and establish matching upper and lower bounds for each operation. In the case of complementation th e upper and lower bounds differ by an additive constant of two.	automaton;best, worst and average case;finite-state machine;kleene star;nondeterministic algorithm;regular language;utility functions on indivisible goods	Yo-Sub Han;Kai Salomaa	2010		10.4204/EPTCS.31.21	nondeterministic finite automaton with ε-moves;combinatorics;formal language;discrete mathematics;nondeterministic finite automaton;state diagram;regular language;computer science;deterministic finite automaton;deterministic automaton;automata theory;mathematics;finite-state machine;upper and lower bounds;generalized nondeterministic finite automaton;nondeterministic algorithm;algorithm;context-sensitive language	Logic	-1.4610167127119515	21.042942123380655	26044
7b88b5fb37a02b810901b27fb0a0adabceb86e6c	a simple variance reduction method with applications to finance and queueing theory	queueing theory;variance reduction		queueing theory;variance reduction	C. Costantini	2001	Monte Carlo Meth. and Appl.	10.1515/mcma.2001.7.1-2.131	g-network;mean value analysis;econometrics;mathematical optimization;mathematics;queueing theory;statistics;variance reduction	ML	8.57651140555736	12.1116143125106	26095
df29e47c32fae26cd7a546e9af7b58e05606a240	setting gates for activities in the stochastic project scheduling problem through the cross entropy methodology	cross entropy;heuristic method;precedence constraint;project scheduling;cross entropy method	This paper addresses the problem of scheduling activities in projects with stochastic activity durations. The aim is to determine for each activity a gate—a time before it the activity cannot begin. Setting these gates is analogous to setting inventory levels in the news vendor problem. The resources required for each activity are scheduled to arrive according to its gate. Since activities’ durations are stochastic, the start and finish time of each activity is uncertain. This fact may lead to one of two outcomes: (1) an activity is ready to start its processing as all its predecessors have finished, but it cannot start because the resources required for it were scheduled to arrive at a later time. (2) The resources required for the activity have arrived and are ready to be used but the activity is not ready to start because of precedence constraints. In the first case we will incur a “holding” cost while in the second case, we will incur a “shortage” cost. Our objective is to set gates so as to minimize the sum of the expected holding and shortage costs. We employ the Cross-Entropy method to solve the problem. The paper describes the implementation of the method, compares its results to various heuristic methods and provides some insights towards actual applications.	cross entropy;cross-entropy method;heuristic;inventory;scheduling (computing);stochastic process	Illana Bendavid;Boaz Golany	2009	Annals OR	10.1007/s10479-009-0579-3	mathematical optimization;real-time computing;simulation;cross-entropy method;operations management;mathematics;cross entropy;schedule;statistics	AI	13.810447548439685	7.925923374826368	26106
8921fb088c3f119b889f578db36f5f09207d7309	locality of reference and the use of sojourn time variance for measuring queue unfairness	file attente;tiempo parada;occupation time;sojourn time;localite;execution time;file attente temporelle;time queue;queue;metric;locality;temps arret;equite;fila espera temporal;equidad;equity;temps occupation;smoothing;busy period;tiempo ocupacion;alisamiento;temps execution;metrico;job fairness;stopping time;raqfm;periode occupation;tiempo ejecucion;fila espera;lissage;metrique;periodo ocupacion	The variance of job sojourn time (or waiting time) is used, either explicitly or implicitly, as an indication of unfairness perhaps for as long as queueing theory exists. In this work we demonstrate that this quantity has a disadvantage as an unfairness metric, since it is not local to the busy period in which it is measured. It therefore may account for job discrepancies which are not relevant to unfairness of scheduling. We show that RAQFM, a recently proposed job fairness metric, does possess such a locality property. We further show that within a large class of unfairness metrics RAQFM is unique in possessing this property. Acknowledgements: This work was supported in part by grant 380-801 from the Israeli Ministry of Science and Technology	ergodic theory;fairness measure;locality of reference;queueing theory;scheduling (computing);software metric;time deviation	Hanoch Levy;David Raz;Benjamin Avi-Itzhak	2007	Oper. Res. Lett.	10.1016/j.orl.2006.06.003	real-time computing;simulation;multilevel queue;metric;stopping time;mathematics;queue;equity;statistics;smoothing	Theory	6.884931313864937	11.60761039785091	26128
4db762762614f65b3d7418fa6cc379d6be880fd6	the coin problem and pseudorandomness for branching programs	pseudorandomness;and or tree;generators;probability function;game theory;magnetic heads;m sided dice problem;lower bounds;computability;random sequences;random variables;lower bounds pseudorandomness branching programs;branching program pseudorandomness;upper bound;automata;computational modeling;computational complexity;generators magnetic heads computational modeling random variables approximation methods upper bound automata;branching program;nisan generator coin problem branching program pseudorandomness computational model probability function read once width w branching program and or tree m sided dice problem independent toss;approximation methods;coin problem;nisan generator;tree searching;independent toss;tree searching computability computational complexity game theory random sequences;computational model;branching programs;read once width w branching program;lower bound	The \emph{Coin Problem} is the following problem: a coin is given, which lands on head with probability either $1/2 + \beta$ or $1/2 - \beta$. We are given the outcome of $n$ independent tosses of this coin, and the goal is to guess which way the coin is biased, and to answer correctly with probability $\ge 2/3$. When our computational model is unrestricted, the majority function is optimal, and succeeds when $\beta \ge c /\sqrt{n}$ for a large enough constant $c$. The coin problem is open and interesting in models that cannot compute the majority function. In this paper we study the coin problem in the model of \emph{read-once width-$w$ branching programs}. We prove that in order to succeed in this model, $\beta$ must be at least $1/ (\log n)^{\Theta(w)}$. For constant $w$ this is tight by considering the recursive tribes function, and for other values of $w$ this is nearly tight by considering other read-once AND-OR trees. We generalize this to a \emph{Dice Problem}, where instead of independent tosses of a coin we are given independent tosses of one of two $m$-sided dice. We prove that if the distributions are too close and the mass of each side of the dice is not too small, then the dice cannot be distinguished by small-width read-once branching programs. We suggest one application for this kind of theorems: we prove that Nisan's Generator fools width-$w$ read-once \emph{regular} branching programs, using seed length $O(w^4 \log n \log \log n + \log n \log (1/\eps))$. For $w=\eps=\Theta(1)$, this seed length is $O(\log n \log \log n)$. The coin theorem and its relatives might have other connections to PRGs. This application is related to the independent, but chronologically-earlier, work of Braver man, Rao, Raz and Yehudayoff~\cite{BRRY}.	acc0;binary decision diagram;computational model;majority function;nc (complexity);polynomial;programming research group;pseudorandomness;randomness;recursion;supratik chakraborty	Joshua Brody;Elad Verbin	2010	2010 IEEE 51st Annual Symposium on Foundations of Computer Science	10.1109/FOCS.2010.10	game theory;combinatorics;discrete mathematics;computer science;mathematics;upper and lower bounds;computational model;algorithm;algebra	Theory	9.288285640932711	22.435175424583598	26189
95083c70e3bcf095564a0460cb396399357e8004	a generic scheme for the design of efficient on-line algorithms for lattices	circuit declenchement;metodo caso peor;complexite;circuito desenganche;algorithmique;image processing;generic algorithm;batch production;maintenance;implementation;speech processing;complejidad;tratamiento palabra;procesamiento imagen;procede discontinu;transformacion;traitement parole;tabla dato;complexity;traitement image;enrejado;produccion por lote;table donnee;algorithmics;treillis;algoritmica;motivacion;production par lot;batch process;borne inferieure;methode cas pire;pattern recognition;mantenimiento;motivation;trigger;procedimiento discontinuo;reconnaissance forme;transformation;data table;reconocimiento patron;implementacion;worst case method;on line algorithm;lower bound;cota inferior;lattice	A major issue with large dynamic datasets is the processing of small changes in the input through correspondingly small rearrangements of the output. This was the motivation behind the design of incremental or on-line algorithms for lattice maintenance, whose work amounts to a gradual construction of the final lattice by repeatedly adding rows/columns to the data table. As an attempt to put the incremental trend on strong theoretical grounds, we present a generic algorithmic scheme that is based on a detailed analysis of the lattice transformation triggered by a row/column addition and of the underlying sub-structure. For each task from the scheme we suggest an efficient implementation strategy and put a lower bound on its worst-case complexity. Moreover, an instanciation of the incremental scheme is presented which is as complex as the best batch algorithm.	best, worst and average case;column (database);computation;online algorithm;online and offline;performance;substitution (logic);table (information);worst-case complexity	Petko Valtchev;Mohamed Rouane Hacene;Rokia Missaoui	2003		10.1007/978-3-540-45091-7_20	transformation;complexity;simulation;motivation;genetic algorithm;image processing;computer science;artificial intelligence;table;lattice;speech processing;mathematics;upper and lower bounds;implementation;algorithmics;algorithm;batch processing	Theory	14.93559754492591	26.8698620010072	26228
9bd225df2ee332cd0169452262d43ff76730d11f	relatively regular languages and thin codes	regular language;close relationships	A language is called a relatively regular language if its syntactic monoid has finite ideals. In this paper, we show that there are close relationships between the relatively regular languages and some other classes of languages such as (generalized) disjunctive languages, fd-domains and 2-codes. In particular, we prove that every relatively regular 2-code is thin. Thus, the well known result of Bestel and Perrin in 1985 becomes an easy corollary of our result. c © 2006 Elsevier Ltd. All rights reserved.	code;disjunctive normal form;perrin number;regular language;syntactic monoid;whole earth 'lectronic link	Yun Liu;Kar-Ping Shum;Yuqi Guo	2008	Eur. J. Comb.	10.1016/j.ejc.2006.09.002	arithmetic;discrete mathematics;pumping lemma for regular languages;regular language;regular grammar;mathematics;cone;abstract family of languages;generalized star height problem;algorithm	Theory	-3.70683778372162	18.866245158781336	26241
9719b6139e4bbeb09a0f3e816ee923047d53232b	single-edge monotonic sequences of graphs and linear-time algorithms for minimal completions and deletions	delecion;graphe lineaire;graphe minimal;graphe biparti;seuil;grafo bipartido;vertex;chain graph;temps lineaire;linear time algorithm;threshold;algorithme temps lineaire;calculo automatico;tiempo lineal;grafo lineal;68wxx;computing;grafo minimo;calcul automatique;algorithme lineaire;graph classes;chaine graphe;informatique theorique;graph chain;linear time;complecion;68r10;minimal deletions of graphs;characterization;minimal completions of graphs;linear time algorithms;vertice;cadena grafo;umbral;caracterisation;threshold graph;classe np;bipartite graph;completion;caracterizacion;structural properties;minimal graph;linear graph;computer theory;deletion;informatica teorica	We study graph properties that admit an increasing, or equivalently decreasing, sequence of graphs on the same vertex set such that for any two consecutive graphs in the sequence their difference is a single edge. This is useful for characterizing and computing minimal completions and deletions of arbitrary graphs into having these properties. We prove that threshold graphs and chain graphs admit such sequences. Based on this characterization and other structural properties, we present linear-time algorithms both for computing minimal completions and deletions into threshold, chain, and bipartite graphs, and for extracting a minimal completion or deletion from a given completion or deletion. Minimum completions and deletions into these classes are NP-hard to compute.	algorithm;time complexity	Pinar Heggernes;Charis Papadopoulos	2009	Theor. Comput. Sci.	10.1016/j.tcs.2008.07.020	1-planar graph;pathwidth;vertex;combinatorics;computing;discrete mathematics;completion;bipartite graph;mathematics;maximal independent set;chordal graph;indifference graph;algorithm;algebra	Theory	22.820482674746636	27.596823780611707	26243
14d15a1cd21f9689aeaf396436b4de17d4d4aa43	aspects of power system protection in the post-restructuring era	vertical integration;power generation control;protection philosophies power system protection post restructuring era protection practices electric utility industry engineering principles component protection vertically integrated electric utility systems system protection wide area disturbances transmission system owner iso generator control protection systems power apparatus transmission system;power system;power system protection power industry iso acoustical engineering maintenance engineering design engineering power engineering and energy control systems power generation power system control;electric utilities;power system protection;electricity supply industry;power generation control power system protection electricity supply industry	Protection practices in electric utility industry as existed prior to re-structuring were designed to m certain goals of sound engineering principles as th were applied, primarily to component protection vertically integrated electric utility systems. There h been a significant shift in emphasis from uncomplica component protection to system protection to avoid mitigate wide-area disturbances. It is not clear how responsibilities for designing and maintaining t protection systems will be divided between transmission system owner and the ISO. Protection control of generators will also impact the performance the power system. The settings used in many prote systems that are designed to protect power appar will affect the ability of the transmission system transfer power between two points on the network. owners of the transmission system as well as the should have an interest in knowing the limitatio imposed by both the apparatus and the sys protection, and the ability to change those settings if t do not meet their respective objectives. It is possible the objectives of the two entities will be in conflict. T paper will examine the existing protection philosophi and their impact on these issues.	audio engineer;computer;dependability;entity	S. H. Horowitz;Arun G. Phadke;James S. Thorp	1999		10.1109/HICSS.1999.772860	vertical integration;telecommunications;electrical engineering;electric power system;power-system protection	OS	-0.01479601157394893	7.322153128018787	26254
8dda76790871286f03ca78bfabc291fc3c371880	an improved hash code for scatter storage	searching;hash table;hash code;scatter storage	Although scatter storage tables are used widely in system programming, they are subject to various drawbacks. One of these is that the size of the table cannot be arbitrary, but is restricted to powers of 2 by the hash coding method. In this note we present a new hash coding method that, besides being very simple and as fast as the best known methods, allows the table size to be almost any prime number. The scatter storage techniques currently used in assemblers, compilers, and elsewhere, are excellently summarized in [1]. Items are entered into a table using an index which is computed from the item by means of some hash coding method. As tong as no two inserted items have the same hash code, searching and insertion are each performed in a single step, regardless of the size of the table. When two items have the same hash code, a collision is said to exist. In this ease the second item must be put out of place in the table. This takes extra time; but if the hash codes are randomly distributed, the average number of steps is less than 2 even for a table which is 75 percent full. The usual hash coding methods involve the calculation of a k-bit field which is assumed to be a random integer between 0 and 2 ~ -1. Thus the table size is restricted to	assembly language;bit field;code;compiler;cryptographic hash function;hash table;power of two;randomness;system programming	Ward Douglas Maurer	1968	Commun. ACM	10.1145/362851.362880	hash table;double hashing;parallel computing;hash function;perfect hash function;dynamic perfect hashing;merkle tree;quadratic probing;sha-2;computer science;theoretical computer science;hash chain;hash buster;database;hash list;rolling hash;programming language;cryptographic hash function;fowler–noll–vo hash function;mdc-2;hash tree;hash filter	Theory	10.346886319135322	28.593593023235638	26281
216f64d9f36846f9983d4c696237f4466e9ee633	low-complexity cryptographic hash functions		Cryptographic hash functions are efficiently computable functions that shrink a long input into a shorter output while achieving some of the useful security properties of a random function. The most common type of such hash functions is collision resistant hash functions (CRH), which prevent an efficient attacker from finding a pair of inputs on which the function has the same output. Despite the ubiquitous role of hash functions in cryptography, several of the most basic questions regarding their computational and algebraic complexity remained open. In this work we settle most of these questions under new, but arguably quite conservative, cryptographic assumptions, whose study may be of independent interest. Concretely, we obtain the following results: Low-complexity CRH. Assuming the intractability of finding short codewords in natural families of linear error-correcting codes, there are CRH that shrink the input by a constant factor and have a constant algebraic degree over Z2 (as low as 3), or even constant output locality and input locality. Alternatively, CRH with an arbitrary polynomial shrinkage can be computed by linear-size circuits. Win-win results. If low-degree CRH with good shrinkage do not exist, this has useful consequences for learning algorithms and data structures. ∗ This work was done in part while the authors were visiting the Simons Institute for the Theory of Computing, supported by the Simons Foundation and by the DIMACS/Simons Collaboration in Cryptography through NSF grant CNS-1523467. † The first author was partially supported by the European Union’s Horizon 2020 Programme (ERCStG-2014-2020) under grant agreement no. 639813 ERC-CLC, by an ICRC grant and by the Check Point Institute for Information Security. The second author was partially supported by a Melvin R. Berlin Fellowship in the Cyber Security Research Program. The second and third authors were partially supported by ERC starting grant 259426. The second, third and fourth authors were partially supported by ISF grant 1709/14, BSF grant 2012378, and NSF-BSF grant 2015782. The third author was additionally supported by a DARPA/ARL SAFEWARE award, NSF Frontier Award 1413955, NSF grants 1228984, 1136174, 1118096, and 1065276, and DARPA through the ARL under Contract W911NF-15-C-0205. The fifth author was partially supported by NSF Grants CNS-1350619 and CNS1414119, Alfred P. Sloan Research Fellowship, Microsoft Faculty Fellowship, the NEC Corporation, a Steven and Renee Finn Career Development Chair from MIT, and DARPA and U.S. Army Research Office under contracts W911NF-15-C-0226. The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense, the National Science Foundation, or the U.S. Government. © Benny Applebaum, Naama Haramaty-Krasne, Yuval Ishai, Eyal Kushilevitz, and Vinod Vaikuntanathan; licensed under Creative Commons License CC-BY 8th Innovations in Theoretical Computer Science Conference (ITCS 2017). Editor: Christos H. Papadimitrou; Article No. 7; pp. 7:1–7:31 Leibniz International Proceedings in Informatics Schloss Dagstuhl – Leibniz-Zentrum für Informatik, Dagstuhl Publishing, Germany 7:2 Low-Complexity Cryptographic Hash Functions Degree-2 hash functions. Assuming the conjectured intractability of solving a random system of quadratic equations over Z2, a uniformly random degree-2 mapping is a universal one-way hash function (UOWHF). UOWHF relaxes CRH by forcing the attacker to find a collision with a random input picked by a challenger. On the other hand, a uniformly random degree-2 mapping is not a CRH. We leave the existence of degree-2 CRH open, and relate it to open questions on the existence of degree-2 randomized encodings of functions. 1998 ACM Subject Classification F.0 Theory of Computation – General	bean scripting framework;chinese library classification;code word;collision resistance;computable function;cryptographic hash function;cryptography;data structure;error detection and correction;forward error correction;ibm notes;informatics;information security;keneth alden simons;linear algebra;locality of reference;machine learning;one-way function;polynomial;quadratic equation;randomized algorithm;stochastic process;theoretical computer science;theory of computing;theory of computation;universal one-way hash function	Benny Applebaum;Naama Haramaty;Yuval Ishai;Eyal Kushilevitz;Vinod Vaikuntanathan	2017	Electronic Colloquium on Computational Complexity (ECCC)	10.4230/LIPIcs.ITCS.2017.7	discrete mathematics;random function;collision;cryptographic hash function;computable function;hash function;mathematics	Crypto	11.959979995858667	21.751772484824283	26296
0793dceb6a25fbed5fb8960786748fabb1203cf7	a generalization of burnside's combinatorial lemma		Burnside’s lemma is one of the tools most basic to the theory of enumeration. P6lya, in his celebrated work [lo], applied it to solve combinatorial problems in chemistry. A profound generalization of P6lya’s result was discovered by de Bruijn [2, 91. Slepian [12] utilized Burnside’s and P6lya’s results in attacking problems involving switching circuits. Applications of P6lya’s theorem, and hence Burnside’s lemma, include enumeration of graphs, trees, and Boolean functions. Given a group G which acts on a set S, this lemma (Burnside’s) provides a means of counting the total number of G-orbits of S (equivalence classes of S induced by G) in terms of Fc , the number of s E S left fixed by u for permutations CJ E G. Specifically,	de bruijn graph;graph (discrete mathematics);graph enumeration;tree (data structure);turing completeness	Michael J. Klass	1976	J. Comb. Theory, Ser. A	10.1016/0097-3165(76)90021-2	combinatorics;discrete mathematics;mathematics;algebra	Theory	21.420450769973844	24.640240376748405	26341
0b6c119d21b143bcd87e064f5745f5d655466d54	optimizing cloud use under interval uncertainty	interval uncertainty;cloud computing	One of the main advantages of cloud computing is that it helps the users to save money: instead of buying a lot of computers to cover all their computations, the user can rent the computation time on the cloud to cover the rare peak spikes of computer need. From this viewpoint, it is important to find the optimal division between in-house and in-the-cloud computations. In this paper, we solve this optimization problem, both in the idealized case when we know the complete information about the costs and the user’s need, and in a more realistic situation, when we only know interval bounds on the corresponding quantities. 1 Formulation of the Problem What is cloud computing. The main idea behind cloud computing (see, e.g., [8, 17, 22, 27]) is that instead of performing all the computations on his/her own computer, a user can sometimes rent computing time from a computer-timerental company. This, in effect, is what is known as cloud computing. Computations that use rented computer time are called computing in the cloud. Renting is usually more expensive than buying and maintaining one’s own computer, so if the user needs the same amount of computations day after day, cloud computing is not a good financial option. However, if a peak need for computing occurs rarely, it is often cheaper to rent the corresponding computation time than to buy a lot of computing power and idle it most of the time. How much computation time should we rent? Once the user knows his/her computational requirements, the proper question is: should we use the cloud at all? if yes, how much computing power should we buy for in-house computations and how much computation time should we rent from the cloud company? how much will it cost? Finally, if a cloud company offers a multi-year deal with fixed rates, should we take it or should we buy computation time on a year-by-year basis? Why this is important. Surprisingly, while the main purpose of cloud computing is to save user’s money, most cloud users are computer folks with little knowledge of economics. As a result, often, they make wrong financial decisions about the cloud use; see, e.g., [28]. It is important to come up with proper recommendations for using cloud computing. What we do in this paper. In this paper, we provide the desired financial recommendations, first under the idealized assumption that we have a complete information, and then, in a more realistic situation of interval uncertainty. 2 How Much Computations to Perform In-House and How Much in Cloud: Case of Complete Information Case of complete information: description. Let us first consider the idealized case when we have complete information about our needs and about all the costs. This means, first, that we know the cost of keeping a certain level of computational ability in-house. Let us pick some time quantum (e.g., day or hour). Then, the overall cost of buying and maintaining the corresponding computers is proportional to these computer’s computational ability – i.e., the number of computing operations (e.g., Teraflops) that these computers can perform in this time unit. Let c0 denote the cost per unit of computations. Then, if we buy computers with computational ability x0, we pay c0 · x0 for these computers. This also means that we know the cost of computing in the cloud. Let us denote this cost by c1. So, if one day, we need to perform x computations in the cloud, we have to pay the amount c1 · x. As we have mentioned, computing in the cloud is usually more expensive than computing in-house. Part of this extra cost is the cost of moving data, another part is the overhead to support the computing staff, marketing staff, etc. As a result, c1 > c0. Complete knowledge also means that we know the user’s needs. This means that for each possible computation need x, we know the probability that one of the days, we will need to perform exactly x computations. These probabilities can be estimated by analyzing the previous needs: if we needed x computations in 10% of the days, this means that the probability of needing x computations is exactly 10%. The probability distribution is usually described either by a cumulative distribution function (cdf) F (x) = Prob(X ≤ x), or by the probability density function (pdf) ρ(x) for which the probability to be within an interval [x, x] is equal to the integral ∫ x x ρ(x) dx, and the overall probability is 1: ∫ ρ(x) dx = 1. The relationship between pdf and cdf is straightforward: • F (x) is the integral of pdf: F (x) = ∫ x 0 ρ(t) dt; • vice versa, the pdf is the derivative of the cdf: ρ(x) = dF dx . What is the cost of buying x0 computational abilities and doing all other computations in the cloud? We want to select the amount x0 of computing power to buys, so that everything in excess of x0 will be sent to the cloud. We want to select this amount so that the expected overall cost of computations is the smallest possible. So, to find the corresponding value x0, let us compute how much it will cost the user to buy x0 equipment and to rent all other computation time. We already know that the cost of buying and maintaining an equipment with capacity x0 is equal to c0 · x0. The expected cost of using the cloud can be obtained by adding the costs multiplied by the corresponding probabilities. We need computations in the cloud when x > x0, For each such value x, we need to rent the amount x − x0 in the cloud. The cost of such renting is c1 ·(x−x0). The probability of needing exactly x computations is proportional to ρ(x). To be more precise, the probability that we need between x and x+∆x computations is equal to c1 ·(x−x0)·ρ(x)·∆x. The expected cost of using the cloud is therefore equal to the sum of such products, i.e., to the value ∑ c1 · (x− x0) · ρ(x) ·∆x. In the limit, when ∆x → 0, this sum tends to the integral ∫ x0 c1 · (x− x0) · ρ(x) dx. Thus, the overall cost is equal to the sum of the in-house and in-the-cloud costs: C(x0) = c0 · x0 + c1 · ∫ x0 (x− x0) · ρ(x) dx. (1) Let us use this cost expression to find the optimal value x0. We want to find the value x0 for which the cost expression (1) attains its smallest possible value. To find this minimizing value, we need to differentiate the expression (1) with respect to x0 and equate the corresponding derivative to 0. To make this differentiation easier, let us transform the expression (1) by using integration by parts ∫ u dv = u · v − ∫ v du. Here, ρ(x) = d(F (x)− 1) dx , so we can take u = x−x0 and v = F (x)−1. The product uv = (x−x0) · (F (x)−1) is equal to 0 on both endpoints x = x0 and x = ∞, so we get C(x0) = c0 · x0 − c1 · ∫	access network;care-of address;cloud computing;computation;emoticon;flops;interval arithmetic;mainframe computer;mathematical optimization;offset binary;optimization problem;optimizing compiler;overhead (computing);portable document format;reconfigurable computing;requirement;time complexity	Vladik Kreinovich;Esthela Gallardo	2015		10.1007/978-3-319-32152-3_40	cloud computing;computer science;operating system	HPC	2.938574772697939	13.513318254870871	26345
15f8374fb9e755dc9d116ed5b5298b24a0c283c2	fast theta-subsumption with constraint satisfaction algorithms	meta learning;k locality;inductive logic programming;constraint satisfaction;phase transition;order parameter;stochastic complexity;constraint satisfaction problem;data structure;relational learning	Relational learning and Inductive Logic Programming (ILP) commonly use as covering test the θ-subsumption test defined by Plotkin. Based on a reformulation of θ-subsumption as a binary constraint satisfaction problem, this paper describes a novel θ-subsumption algorithm named Django,1 which combines well-known CSP procedures and θ-subsumption-specific data structures. Django is validated using the stochastic complexity framework developed in CSPs, and imported in ILP by Giordana et Saitta. Principled and extensive experiments within this framework show that Django improves on earlier θ-subsumption algorithms by several orders of magnitude, and that different procedures are better at different regions of the stochastic complexity landscape. These experiments allow for building a control layer over Django, termed Meta-Django, which determines the best procedures to use depending on the order parameters of the θ-subsumption problem instance. The performance gains and good scalability of Django and Meta-Django are finally demonstrated on a real-world ILP task (emulating the search for frequent clauses in the mutagenesis domain) though the smaller size of the problems results in smaller gain factors (ranging from 2.5 to 30).	algorithm;binary constraint;constraint satisfaction problem;cryptographic service provider;data structure;django;emulator;experiment;inductive logic programming;inductive reasoning;kolmogorov complexity;plotkin bound;scalability;subsumption architecture	Jérôme Maloberti;Michèle Sebag	2004	Machine Learning	10.1023/B:MACH.0000023150.80092.40	phase transition;data structure;constraint satisfaction;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;constraint satisfaction problem;algorithm	AI	11.826361347172691	16.669305128266366	26353
65e73a155372195f03346f09e852e23644d1e77c	non-abusiveness helps: an o(1)-competitive algorithm for minimizing the maximum flow time in the online traveling salesman problem	main result;competitive algorithm;maximum flow time;online algorithm;alternative analysis method;non-abusive adversary;nonabusive adversary;competitive analysis;salesman problem oltsp request;salesman problem;constant competitive ratio;maximum flow;competitive ratio;traveling salesman problem	In the online traveling salesman problem OlTsp requests for visits to cities arrive online while the salesman is traveling. We study the Fmax-OlTsp where the objective is to minimize the maximum flow time. This objective is particularly interesting for applications. Unfortunately, there can be no competitive algorithm, neither deterministic nor randomized. Hence, competitive analysis fails to distinguish online algorithms. Not even resource augmentation which is helpful in scheduling works as a remedy. This unsatisfactory situation motivates the search for alternative analysis methods. We introduce a natural restriction on the adversary for the Fmax-OlTsp on the real line. A non-abusive adversary may only move in a direction if there are yet unserved requests on this side. Our main result is an algorithm which achieves a constant competitive ratio against the nonabusive adversary. Research supported by the German Science Foundation (DFG, grant GR 883/10) Supported by the TMR Network DONET of the European Community ERB TMRXCT98-0202 Partially supported by Algorithmic Methods for Optimizing the Railways in Europe (AMORE) grant HPRN-CT-1999-00104 † Partially supported by Algorithmic Methods for Optimizing the Railways in Europe (AMORE) grant HPRN-CT-1999-00104 ‡ Supported by the TMR Network DONET of the European Community ERB TMRXCT98-0202 K. Jansen et al. (Eds.): APPROX 2002, LNCS 2462, pp. 200–214, 2002. c © Springer-Verlag Berlin Heidelberg 2002 An O(1)-Competitive Algorithm 201	adversary (cryptography);competitive analysis (online algorithm);display resolution;lecture notes in computer science;maximum flow problem;online algorithm;optimizing compiler;randomized algorithm;scheduling (computing);springer (tank);travelling salesman problem;triple modular redundancy	Sven Oliver Krumke;Luigi Laura;Maarten Lipmann;Alberto Marchetti-Spaccamela;Willem de Paepe;Diana Poensgen;Leen Stougie	2002		10.1007/3-540-45753-4_18	mathematical optimization;machine learning;mathematics;algorithm	Theory	15.924654201604987	5.318675358328241	26356
647857e9addc2e4cdc131d6662bdb1006d0fd857	atomic characterizations of uniform multi-pass attribute grammars	attribute grammar			Éva Gombás;Miklós Bartha	1985	Acta Cybern.		natural language processing;tree-adjoining grammar;l-attributed grammar;computer science;s-attributed grammar;pattern recognition;context-free grammar;programming language;attribute grammar	DB	-2.8532782194183595	20.553174524015507	26365
7f9d7dada2da4d9dcec79eee8ca977050c05acc9	optimized throughput improvement of assembly flow line with digital twin online analytics		This work studies a digital twin online analytics for throughput improvement of assembly flow line. As the representation of the physical assembly flow line, the proposed method includes two digital twin models to analyze the online data collected from the physical line and to calculate and apply optimal throughput improvement scheme to the physical line. With the proposed method, the online data could be fully utilized to serve the physical line, and the dependency on the experience of onsite engineers is greatly reduced. Two practical assembly lines are equipped with the proposed digital twin online analytics to demonstrate its effectiveness and efficiency.	online analytical processing;throughput	Heqing Sun;Cheng Li;Xinyu Fang;Hao Gu	2017	2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2017.8324685	control engineering;throughput;real-time computing;workstation;data modeling;engineering;flow line;analytics	Robotics	9.023748911113898	4.206656406968273	26398
de2408e8a9cb2c4efc42ba0507f7a9a80723d62a	a simple parallel tree contraction algorithm	arbre graphe;algoritmo paralelo;parallel algorithm;algorithm complexity;tree graph;complejidad algoritmo;reduction;algorithme parallele;complexite algorithme;arbol binario;arbre binaire;reduccion;arbol grafo;algoritmo optimo;algorithme optimal;optimal algorithm;binary tree	Abstract   A simple reduction from the tree contraction problem to the list ranking problem is presented. The reduction takes  O (log  n ) time for a tree with  n  nodes, using   O(  n  log   n  )   EREW processors. Thus tree contraction can be done as efficiently as list ranking. A broad class of parallel tree computations to which the tree contraction techniques apply is described. This subsumes earlier characterizations. Applications to the computation of certain properties of cographs are presented in some detail.	algorithm;parallel tree contraction	Karl R. Abrahamson;Norm Dadoun;David G. Kirkpatrick;Teresa M. Przytycka	1989	J. Algorithms	10.1016/0196-6774(89)90017-5	segment tree;red–black tree;combinatorics;discrete mathematics;tree rotation;vantage-point tree;exponential tree;reduction;binary tree;computer science;trie;order statistic tree;range tree;fusion tree;gomory–hu tree;k-ary tree;interval tree;mathematics;parallel algorithm;fractal tree index;search tree;tree;tree traversal;tree;algorithm;avl tree	Theory	17.979371568643465	28.154028737527483	26401
e5c58eca33fe8fa14cb2b08271326958b38b9c6f	scaling relations of data gathering times in an epidemically data sharing system with opportunistically communicating mobile sensors		We investigated data gathering time in an epidemically data sharing system with opportunistically communicating mobile sensors. We proposed a stochastic process of the system where N sensors moved randomly and independently on the d–dimensional square grid with size L and when meeting opportunistically at the same position on the grid, the sensors shared and stored all possessing data epidemically. We focused on three data gathering times, that is, latency times that (1) at least one sensor collects all (2) every sensor collects at least one common data (3) every sensor collects all. As a result, we found that in general the complementary cumulative distribution functions of these times decay exponentially in their asymptotic regions.We also examined a decay speed, which is also called relaxation time, of the exponential decay numerically with varying d, L, and N. Finally we showed scaling relations of the relaxation times. We think that these relations are useful for estimating the minimum required number of sensors to collect data within a certain short period of time when the sensors are densely covered on the system.	scalability;sensor	Akihiro Fujihara;Hiroyoshi Miwa	2010		10.1007/978-3-642-16793-5_9	real-time computing;computer science;data mining;distributed computing	DB	6.815055731582649	31.11724417726551	26453
b2b7afcb28b9661cf373090805cf30bfaec6768a	an intrinsically non minimal-time minsky-like 6-states solution to the firing squad synchronization problem	prueba;aplicacion;firing squad;68q80;anneau;65y05;synchronisation;preuve;68w10 firing squad;synchronization;informatique theorique;68q25;sincronizacion;ring;application;proof;anillo;computer theory;informatica teorica	Here is presented a 6-states non minimal-time solution which is intrinsically Minsky-like and solves the three following problems: unrestricted version on a line, with one initiator at each end of a line and the problem on a ring. We also give a complete proof of correctness of our solution, which was never done in a publication for Minsky’s solutions. 1991 Mathematics Subject Classification. 65Y05,68Q25,68Q80,68W10.	correctness (computer science);firing squad synchronization problem;mathematics subject classification;scsi initiator and target	Jean-Baptiste Yunès	2008	ITA	10.1051/ita:2007051	synchronization;telecommunications;computer science;artificial intelligence;mathematics;algorithm	Theory	4.735541885674171	25.681497728830376	26490
ad1f44314422fa0f34a513fcf62c535cb5ac8754	building-in-briefcase (bib)		A building’s environment has profound influence on occupant comfort and health. Continuous monitoring of building occupancy and environment is essential to fault detection, intelligent control, and building commissioning. Though many solutions for environmental measuring based on wireless sensor networks exist, they are not easily accessible to households and building owners who may lack time or technical expertise needed to set up a system and get quick and detailed overview of environmental conditions. Building-in-Briefcase (BiB) is a portable sensor network platform that is trivially easy to deploy in any building environment. Once the sensors are distributed, the environmental data is collected and communicated to the BiB router via TCP/IP protocol and WiFi technology which then forwards the data to the central database securely over the internet through a 3G radio. The user, with minimal effort, can access the aggregated data and visualize the trends in real time on the BiB web portal. Paramount to the adoption and continued operation of an indoor sensing platform is battery lifetime. This design has achieved a multi-year lifespan by careful selection of components, an efficient binary communications protocol and data compression. Our BiB sensor is capable of collecting a rich set of environmental parameters, and is expandable to measure others, such as CO2. This paper describes the power characteristics of BiB sensors and their occupancy estimation and activity recognition functionality. Our vision is large-scale deployment of BiB in thousands of buildings, which would provide ample research opportunities and opportunities to identify ways to improve the building environment and energy efficiency.	activity recognition;communications protocol;data compression;fault detection and isolation;intelligent control;internet protocol suite;router (computing);sensor;software deployment	Kevin Weekly;Ming Jin;Han Zou;Christopher Hsu;Alexandre M. Bayen;Costas J. Spanos	2014	CoRR		simulation;telecommunications;operating system;world wide web;computer security	Mobile	2.0337410850349795	32.157433579017756	26496
5a962dee4f196669a415a557b8de4ac763fbed80	strong formulations and cutting planes for designing digital data service networks	optimal solution;cutting plane;valid inequalities;linear programming relaxation;integer program;lower bound	This paper deals with the problem of designing a least-cost digital data service (DDS) network that connects a given set of locations through digital switching offices with bridging capabilities. We present several alternative mixed 0---1 integer programming formulations and evaluate analytically their relative strengths by comparing their respective linear programming relaxations. By exploiting the structures inherent in a particularly strong formulation, we develop several classes of valid inequalities and cutting planes in order to tighten the initial formulation. For several problems of real-world data, computational results show that the strong formulation with valid inequalities and cutting planes generates a very tight lower bound (over 98% of the optimality) and so finds an optimal solution well within an acceptable time bound.	digital data	Youngho Lee;Lu Lu;Yuping Qiu;Fred Glover	1993	Telecommunication Systems	10.1007/BF02109861	mathematical optimization;combinatorics;linear programming relaxation;mathematics;upper and lower bounds;branch and cut;cutting-plane method	HPC	21.89786269644228	14.57469372251709	26550
8a391622e58819b5156f4b31f94c75d5e6887234	an experiment study on text transformation for compression using stoplists and frequent words	compression algorithm;frequent word;text preprocessing;mathematics;dictionaries encoding compression algorithms natural languages information technology software systems systems engineering and theory laboratories mathematics computer science;data compression;compression algorithms;information technology;sclpt;software systems;text analysis;text compression;natural languages;text compression algorithm;systems engineering and theory;stoplist word;star encoding;text analysis data compression;dictionaries;lpt;dictionary text transformation algorithm text compression algorithm frequent word stoplist word predefined codes;lipt text transformation text preprocessing star encoding lpt rlpt sclpt;rlpt;dictionary;text transformation algorithm;predefined codes;computer science;lipt;encoding;text transformation	The paper presents a new text transform algorithm suitable for embedding in compression algorithms. The strategy the new algorithm employed to increase performance of text compression is to replace words with predefined codes. Instead of using a huge dictionary containing exhaustive words as in previous works, the new algorithm uses a list of stoplists and/or frequent words. The research devised different encoding schemes for such a list. It then made experiments of using these schemes with different compression algorithms on standard texts. The result shows that each scheme gives increasing compression when using with specific compression algorithms.	algorithm;code;data compression;dictionary;experiment	Jirapond Tadrat;Veera Boonjing	2008	Fifth International Conference on Information Technology: New Generations (itng 2008)	10.1109/ITNG.2008.178	data compression;natural language processing;speech recognition;computer science;theoretical computer science;semantic compression;move-to-front transform;lossless compression;incremental encoding;information technology;statistics	Robotics	11.594870457649831	28.161117033844473	26584
1c5428606fc2b908e27d9ae9cfa57bcbede006e4	a tabu search algorithm for finding good forest harvest schedules satisfying green-up constraints	multicriteria optimization;algoritmo busqueda;modele mathematique;bassin versant;north america;america del norte;amerique du nord;amerique;algorithme recherche;estudio comparativo;search algorithm;gestion forestiere;recherche aleatoire;modelo matematico;impact environnement;operations research;satisfiability;explotacion forestal;etude comparative;forest logging;environmental concern;canada;british columbia;colombie britannique;recherche operationnelle;tabu search algorithm;cuenca;colombia britanica;comparative study;forest harvesting;mathematical model;investigacion aleatoria;linear program;tabu search;administracion forestal;exploitation forestiere;america;watershed;random search;impacto medio ambiente;investigacion operacional;busqueda tabu;recherche tabou;forest management;environment impact	Due to environmental concerns, forest harvesting in many regions must now satisfy adjacency. or green-up constraints. As a result, the forest harvesting problem, which originally could be formulated as a linear programming problem, becomes combinatorial in nature. Moreover, current harvest scheduling codes, like FORPLAN, Timber RAM and others. are unable to generate harvest schedules satisfying the adjacency constraints. In this paper we formulate forest harvesting problems with adjacency constraints arising in the Tangier watershed as multicriteria optimization problems. We use tabu search to investigate the trade-offs among the different criteria which were chosen as the total volume of lumber cut, the period to period deviation from even-flow of lumber during a harvest rotation and adjacency violations. Apparently, the tabu search methodology can be easily applied to solve harvesting problems with adjacency constraints. For harvesting problems in the Tangier watershed, the tabu search is shown to produce better schedules than the O’Hara et al. method (1989) which is considered to be one of the most effective approaches for forest harvesting problems. We also confirm the expected outcome that requiring adherence to green-up constrains. or to certain limitations on flow deviations, will reduce the total volume of lumber that can be cut. However. our approach is sufficiently effective to reveal that for the forest harvesting problems in the Tangier watershed which we studied, this volume reduction does not exceed 8% and sometimes even does not exceed 2% of the total volume that could be possibly cut.	code;columbia (supercomputer);common criteria;cut (graph theory);emoticon;linear programming;mathematical optimization;optimization problem;random forest;random-access memory;scheduling (computing);search algorithm;tabu search;the forest;watershed (image processing)	Shelby Brumelle;Daniel Granot;Merja Halme;Ilan Vertinsky	1998	European Journal of Operational Research	10.1016/S0377-2217(97)00282-8	mathematical optimization;random search;forest management;watershed;tabu search;computer science;linear programming;operations management;comparative research;mathematical model;mathematics;satisfiability;search algorithm	AI	19.415082307471693	10.125508601268926	26617
f602afc74527572451c2c0d2c9e35d1134175417	placement of tasks under uncertainty on massively multicore architectures. (placement de tâches sous incertitudes sur des architectures massivement multicoeurs)		This PhD thesis is devoted to the study of combinatorial optimization problems related to massively parallel embedded architectures when taking into account uncertain data (e.g. execution time). Our focus is on chance constrained programs with the objective of nding the best solution which is feasible with a preset probability guarantee. A qualitative analysis of the uncertain data we have to treat (dependent random variables, multimodal, multidimensional, di cult to characterize through classical distributions) has lead us to design a non parametric method, the so-called robust binomial approach , valid whatever the joint distribution and which is based on robust optimization and statistical hypothesis testing. We also propose a methodology for adapting approximate algorithms for solving stochastic problems by integrating the robust binomial approach when verifying for solution feasibility. The practical relevance of our approach is validated through two problems arising in the compilation of data ow application for manycore platforms. The rst problem treats the stochastic partitioning of networks of processes on a xed set of nodes, by taking into account the load of each node and the uncertainty a ecting the weight of the processes. For nding stochastic solutions, a semi-greedy iterative algorithm has been proposed which allowed measuring the robustness and cost of the solutions with regard to those for the deterministic version of the problem. The second problem consists in studying the global placement and routing of data ow applications on a clusterized architecture. The purpose being to place the processes on clusters such that it exists a feasible routing, a GRASP heuristic has been conceived rst for the deterministic case and afterwards extended for the chance constrained variant of the problem.	approximation algorithm;combinatorial optimization;compiler;embedded system;grasp;greedy algorithm;heuristic;iterative method;manycore processor;mathematical optimization;multi-core processor;multimodal interaction;place and route;regular expression;relevance;robust optimization;routing;run time (program lifecycle phase);semiconductor industry;uncertain data;verification and validation	Oana Stan	2013				ML	20.799696000528275	5.698442722085929	26618
0f2bc4c6d00e8e105ffffcfda4627c126c503c95	analysis of an m/g/1 queue with customer impatience and adaptive arrival process	eigenvalues and eigenfunctions;internet m g 1 queue customer impatience adaptive arrival process workload based model laplace stieltjes transform queue management;queueing theory consumer behaviour customer satisfaction internet laplace transforms;queuing theory;queueing theory;joints;customer satisfaction;joints queueing analysis eigenvalues and eigenfunctions admission control mathematical model equations steady state;internet;laplace transforms;m g 1 queue;mathematical model;consumer behaviour;queueing analysis;admission control;steady state	We study an M/G/1 queue with impatience and an adaptive arrival process. The rate of the arrival process changes according to whether an incoming customer is accepted or rejected. We analyse two different models for impatience: (i) based on workload, and (ii) based on queue-length. For the workload-based model, we obtain the Laplace-Stieltjes Transform of the joint stationary workload and arrival rate process, and that of the waiting time. For the queue-length based model we obtain the analogous z-transform. These queueing models might also be useful for capturing the interaction between congestion control algorithms and queue management schemes in the Internet.	algorithm;internet;network congestion;queueing theory;stationary process	Onno J. Boxma;Balakrishna J. Prabhu	2009	International Conference on NETwork Games, Control and Optimization (NetGCooP 2011)		m/m/1 queue;m/d/c queue;real-time computing;simulation;m/m/c queue;m/m/∞ queue;bulk queue;computer science;m/d/1 queue;operations management;m/g/k queue;m/g/1 queue;fork–join queue;queueing theory	Metrics	7.868014116032967	11.49207967783725	26749
613e54746aa0f9f9001818d0545befc918565569	improving exhaustive search implies superpolynomial lower bounds	lower bounds;exact algorithm;time space tradeoffs;exact algorithms;lower bound;exhaustive search;improved exponential algorithms	The P vs NP problem arose from the question of whether exhaustive search is necessary for problems with short verifiable solutions. We still do not know if even a slight algorithmic improvement over exhaustive search is universally possible for all NP problems, and to date no major consequences have been derived from the assumption that an improvement exists.  We show that there are natural NP and BPP problems for which minor algorithmic improvements over the trivial deterministic simulation already entail lower bounds such as NEXP is not in P/poly and LOGSPACE is not equal to NP. These results are especially interesting given that similar improvements have been found for many other hard problems. Optimistically, one might hope our results suggest a new path to lower bounds; pessimistically, they show that carrying out the seemingly modest program of finding slightly better algorithms for all search problems may be extremely difficult (if not impossible).  We also prove unconditional superpolynomial time-space lower bounds for improving on exhaustive search.	algorithm;bpp (complexity);brute-force search;formal verification;karp's 21 np-complete problems;l (complexity);nexptime;np (complexity);p versus np problem;p/poly;simulation;time complexity	Ryan Williams	2010		10.1145/1806689.1806723	mathematical optimization;combinatorics;brute-force search;mathematics;upper and lower bounds;algorithm	Theory	10.335830647290196	19.026408407238677	26820
fabb49cdc21ef8b80d106173d3280a458ee14429	autonomous community architecture and construction technology for city petrol supply management system	electronic mail;petroleum communities vehicles cities and towns computer architecture electronic mail;timeliness performance;flexible;city petrol supply management system;share information;timeliness city petrol supply management system autonomous community architecture flexible;petrol station;timeliness;centralized management model;computer architecture;petroleum;petrol filling service;petroleum enterprise;autonomous community architecture;air pollution;petroleum industry;petrol filling service autonomous community architecture construction technology city petrol supply management system cpsms pollution gas reduction combustion air pollution service quality petroleum enterprise centralized management model timeliness performance petrol station share information;pollution gas reduction;construction technology;cities and towns;vehicles;communities;supply chain management air pollution combustion petroleum industry quality of service;quality of service;cpsms;service quality;supply chain management;combustion	City Petrol Supply Management System(CPSMS) is very important in current society. Effective CPSMS could reduce the waiting time of user, reduce pollution gas by incomplete combustion from engine idling, decrease the air pollution and promote the service quality of petroleum enterprise. But via centralized management model of traditional CPSMS, system is not flexible to get good timeliness performance. In this paper, we propose an Autonomous Community Architecture and construction technology to solve this problem. In this architecture, each petrol station could real-timely share information with each other. It could also share information with users. So that each petrol station could make decision to cooperate with each other to construct community. Each user could select most adequate petrol station for filling service. Waiting time for petrol filling service could be decreased.	centralized computing;management system;network congestion;tail call	Fan Wei;Liumei Zhang;Tianshi Liu;X J David Lu;Kinji Mori	2015	2015 IEEE Twelfth International Symposium on Autonomous Decentralized Systems	10.1109/ISADS.2015.31	supply chain management;quality of service;computer science;petroleum industry;petroleum;service quality;combustion;air pollution	Embedded	-0.03658372884041276	5.201287173438638	26887
5a451e84a65cfa14820616e8faddb31d0d8356b9	fast parallel algorithms for the maximum sum problem	calcul matriciel;algorithme rapide;algoritmo paralelo;parallel algorithm;complexite calcul;maximization;maximum sum;vecteur;algorithme parallele;complejidad computacion;computational complexity;fast algorithm;time use;pattern recognition;matrix;vector;matrix calculus;reconnaissance forme;reconocimiento patron;maximizacion;algoritmo rapido;calculo de matrices;maximisation;parallel algorithms	Abstract   A problem in pattern recognition is to find the maximum sum over all rectangular subregions of a given ( n  ×  n ) matrix of real numbers. The problem has one-dimensional (1D) and two-dimensional (2D) versions. For the 1D version, it is to find the maximum sum over all contiguous subvectors of a given vector of  n  real numbers. We give an algorithm for the 1D version running in  O (log  n ) time using   O(  (n)  (  log   n)  )   processors on the EREW PRAM, and an algorithm for the 2D version which takes  O (log  n ) time using   O(  (n     3   )  (  log   n)  )   processors on the EREW PRAM.	parallel algorithm	Zhaofang Wen	1995	Parallel Computing	10.1016/0167-8191(94)00063-G	combinatorics;parallel computing;computer science;calculus;mathematics;parallel algorithm;algorithm	HPC	14.185011223967864	30.95679346473918	26889
f35d7ced58a7bd61bdf343bb90abfb553672a25a	fleets management of cooperative connected automated vehicles in manufacturing processes		Industry 4.0 is a promising solution for the management of manufacturing processes, due to its potential to increase both energy saving and optimized production. Within this context, in this paper we propose the use of automated connected vehicles fleets for the autonomous handling of products among workstations in manufacturing processes. Numerical results confirm its effectiveness w.r.t a typical production process. Keywords—Industry 4.0, automated guided vehicle, vehicles fleet, industrial wireless networks.	autonomous robot;consensus dynamics;industry 4.0;workstation	Marco Di Vaio;Guido Guizzi;Alberto Petrillo;Stefania Santini	2017			computer science	Robotics	10.182391038342033	4.379613603697806	27006
91e7fdd38581a1631ab6412ceda104f49122dbe4	demand side management in smart buildings using knx/eib		This paper aims to present the development, design and analysis of a control scheme named Thermal Model Predictive Control for Demand Side Management Cooling Strategies. The control is implemented on a building in Athens whose thermal model is derived using the Finite Difference Calculation Method. The development and testing of the thermal model is implemented on-line while the predictive controller for cooling strategies is analysed through simulation results. The advantages of the scheme are described, including the ability of the predictive controller to consult the users for energy and cost savings during the peak demand, in an acceptable way by them regarding the thermal comfort issue. Smart Grids and Smart Microgrids can communicate with this controller for increasing their efficiency.	computer cooling;exbibyte;finite difference;floppy-disk controller;knx (standard);microgrid;online and offline;simulation;smart tv	P. Romanos;Nikos D. Hatziargyriou;Jurgen Schmid	2010		10.1007/978-3-642-19322-4_14	control engineering;simulation;engineering;operations management	Robotics	4.961742616300686	5.931277396648917	27026
d04fbe6d6e6ebdb6290c7782c491f743d430635a	representations and characterizations of languages in chomsky hierarchy by means of insertion-deletion systems	context free languages;insertion deletion systems;recursively enumerable languages;regular languages	Insertion-deletion operations are much investigated in linguistics and in DNA computing and several characterizations of Turing computability were obtained in this framework. In this note we contribute to this research direction with a new characterization of this type, as well as with representations of regular and context-free languages, mainly starting from context-free insertion systems of as small as possible complexity. For instance, each recursively enumerable language L can be represented in a way similar to the celebrated Chomsky-Schützenberger representation of context-free languages, i.e., in the form L = h(L(γ)∩D), where γ is an insertion system of weight (3, 0) (at most three symbols are inserted in a context of length zero), h is a projection, and D is a Dyck language. A similar representation can be obtained for regular languages, involving insertion systems of weight (2,0) and star languages, as well as for context-free languages – this time using insertion systems of weight (3, 0) and star languages.	chomsky hierarchy;computability;computable function;context-free language;dna computing;dyck language;insertion sort;recursion;recursively enumerable language;recursively enumerable set;regular language;turing	Gheorghe Paun;Mario J. Pérez-Jiménez;Takashi Yokomori	2007	Int. J. Found. Comput. Sci.	10.1142/S0129054108006005	formal language;discrete mathematics;pumping lemma for regular languages;regular language;pumping lemma for context-free languages;computer science;chomsky hierarchy;third-generation programming language;syntax;mathematics;context-free language;cone;abstract family of languages;computability;programming language;recursively enumerable language;algorithm	Theory	-1.8696960933534281	19.447865281637736	27057
02540eee361382a34434f942065b210f598e883b	polynomial time approximation algorithms for multi-constrained qos routing	polynomials;approximation algorithms;routing;computer science;quality of service;costs;delay;time factors;constraint optimization;algorithm design and analysis	We study the multi-constrained quality-of-service (QoS) routing problem where one seeks to find a path from a source to a destination in the presence of K ges 2 additive end-to-end QoS constraints. This problem is NP-hard and is commonly modeled using a graph with n vertices and m edges with K additive QoS parameters associated with each edge. For the case of K = 2, the problem has been well studied, with several provably good polynomial time-approximation algorithms reported in the literature, which enforce one constraint while approximating the other. We first focus on an optimization version of the problem where we enforce the first constraint and approximate the other K - 1 constraints. We present an O(mn log log log n + mn/epsi) time (1 + epsi)(K - 1)-approximation algorithm and an O(mn log log log n + m(n/epsi)K-1) time (1 + epsi)-approximation algorithm, for any epsi > 0. When K is reduced to 2, both algorithms produce an (1 + epsi)-approximation with a time complexity better than that of the best-known algorithm designed for this special case. We then study the decision version of the problem and present an O(m(n/epsi)K-1) time algorithm which either finds a feasible solution or confirms that there does not exist a source-destination path whose first weight is bounded by the first constraint and whose every other weight is bounded by (1 - epsi) times the corresponding constraint. If there exists an H-hop source-destination path whose first weight is bounded by the first constraint and whose every other weight is bounded by (1 - epsi) times the corresponding constraint, our algorithm finds a feasible path in O(m(H/epsi)K-1) time. This algorithm improves previous best-known algorithms with O((m + n log n)n/epsi) time for K = 2 and 0(mn(n/epsi)K-1) time for if ges 2.	approximation algorithm;decision problem;end-to-end principle;mathematical optimization;optimization problem;polynomial;quality of service;routing;time complexity;utility functions on indivisible goods	Guoliang Xue;Weiyi Zhang;Jian Tang;Krishnaiyan Thulasiraman	2008	IEEE/ACM Transactions on Networking	10.1145/1399562.1399575	algorithm design;mathematical optimization;combinatorics;computer science;graph theory;theoretical computer science;mathematics	Theory	22.193686045648	18.302765268481288	27115
3d6fa5d42f5853be04584bdea87badc32a485e00	a surrogate constraint tabu thresholding implementation for the frequency assignmentproblem	satisfiability;radio frequency;frequency assignment problem;weighted sums;combinatorial optimisation	This paper presents a surrogate constraint tabu thresholding (SCTT) implementationfor solving the frequency assignment problem. The frequency assignment problem is animportant combinatorial optimisation problem that arises in telecommunications. The mainobjective is to assign radio frequencies to a number of communication links such that interferenceis minimised. Interference is minimised by satisfying a number of problem specificconstraints. The surrogate constraint is created by taking a weighted sum of the constraintsnot satisfied. SCTT is compared with a tabu thresholding method from the literature on a setof simulated but realistic test problems with respect to quality of the solution in a given timeperiod. Computational results show that SCTT is more efficient and effective for all the testproblems. Copyright Kluwer Academic Publishers 1999	tabu search;thresholding (image processing)	D. Castelino;N. M. Stephens	1999	Annals OR	10.1023/A:1018958819459	mathematical optimization;combinatorics;mathematics;radio frequency;algorithm;satisfiability	Robotics	24.15005380682326	4.732809719451812	27211
5cabd4a704459be7509d556866fd4e2139104172	advanced power-source integration in hybrid electric vehicles: multicriteria optimization approach	torque;hydrogen;multicriteria;multi criteria optimization hybrid vehicle component sizing;convex optimization;power transmission mechanical convex programming fuel cell vehicles fuel economy hybrid electric vehicles hydrogen economy load flow control pareto optimisation;fuel cells;hybrid vehicle;battery;lifetime;fuel cell hybrid;fuel cell;particle swarm optimization;system;integrated circuit modeling;component sizing;model;design;optimization;machines;vehicles;optimization fuel cells hydrogen vehicles torque integrated circuit modeling energy management;pareto optimality advanced power source integration hybrid electric vehicle convex multicriteria optimization approach power flow control on board power source hev fuel minimization hybrid powertrain fuel cell hybrid bus hydrogen economy;energy management	System integration and power-flow control of on-board power sources are critical to the performance and cost competitiveness of hybrid electric vehicles (HEVs). The existing methods mostly focus on fuel minimization in hybrid powertrains, while disregarding many other concerns. This article presents an innovative multicriteria optimization approach and showcases its validity and usefulness in a case study of a fuel-cell hybrid bus. Three key technical contributions are made. First, a convex multicriteria optimization framework is devised for quickly and efficiently evaluating the optimal tradeoffs between the fuel-cell durability and hydrogen economy in the bus, as well as the corresponding fuel-cell dimension. Second, the impact of driving pattern on both the optimal fuel-cell size and Pareto optimality is investigated by considering discrepant driving schedules. Finally, a preliminary but useful economic assessment in both current and future scenarios is performed to explore the most cost-effective tradeoff.	algorithmic efficiency;cost efficiency;data degradation;durability (database systems);elegant degradation;hybrid kernel;hydrogen;mbc-55x;mathematical optimization;multi-objective optimization;on-board data handling;pareto efficiency;plug-in (computing);power management;program optimization;schedule (computer science);significant figures;system integration;test bench	Xiaosong Hu;Jiuchun Jiang;Bo Egardt;Dongpu Cao	2015	IEEE Transactions on Industrial Electronics	10.1109/TIE.2015.2463770	control engineering;design;hydrogen;convex optimization;hybrid vehicle;engineering;automotive engineering;system;torque;particle swarm optimization;battery;energy management	Robotics	4.947548704872098	5.80155464219136	27225
ac746e56b89c035fc0c86d53c2df8fc8ece391a2	local property reconstruction and monotonicity	generic model;property testing;locally decodable code;monotone function;hamming distance;relational model;value function	We propose a general model of local property reconstruction. Suppose we have a function f on domain Γ, which is supposed to have a particular property P, but may not have the property. We would like a procedure which produces a function g that has property P and is close to f (according to some suitable metric). The reconstruction procedure, called a filter, has the following form. The procedure takes as input an element x of Γ and outputs g(x). The procedure has oracle access to the function f and uses a single short random string ρ, but is otherwise deterministic. This model was inspired by a related model of online property reconstruction that was introduced by by Ailon, Chazelle, Comandur and Liu (2004). It is related to the property testing model, and extends the framework that is used in the model of locally decodable codes. A similar model, in the context of hypergraph properties, was independently proposed and studied by Austin and Tao (2008). We specifically consider the property of monotonicity and develop an efficient local filter for thie property. The input f is a real valued function defined on the domain {1, . . . , n} (where n is viewed as large and d as a constant). The function is monotone if the following property holds: for two domain elements x and y, if x ≤ y (in the product order) then f(x) ≤ f(y). Given x, our filter outputs the value g(x) in (log n) time and uses a random seed ρ of the same size. With high probability, the ratio of the (Hamming) distance between g and f to the minimum possible Hamming distance between a monotone function and f is bounded above by a function of d (independent of n). ∗This is an extended abstract of work that will appear as “Local Monotonicity Reconstruction” in SIAM Journal of Computing. A preliminary version of this work appeared as “Parallel Monotonicity Reconstruction” [29]. †This work was supported in part by NSF under grants CCF-0515201 and CCF-0832787. ‡This paper is partly based on material that appeared in this author’s Ph.D. dissertation for the Department of Computer Science, Princeton University.	computer science;hamming distance;ibm notes;locally decodable code;property testing;random seed;monotone	Michael E. Saks;Seshadhri Comandur	2010		10.1007/978-3-642-16367-8_29	combinatorics;discrete mathematics;mathematics;algorithm	Theory	13.595354527230349	21.452631125768555	27272
08addbc01d79d517d44a43bc6cd955d8ef64559e	on the greedy algorithm for satisfiability	algoritmo busqueda;algorithm analysis;algorithme glouton;probleme np complet;algorithme recherche;sistema informatico;heuristic method;search algorithm;satisfaccion;aproximacion probabilista;metodo heuristico;computer system;verite;probabilistic approach;satisfiability;satisfaction;analysis of algorithms;probabilistic analysis;approche probabiliste;greedy algorithm;problema np completo;analyse algorithme;systeme informatique;methode heuristique;analisis algoritmo;np complete problem	"""We show that for the vast majority of satissable 3CNF formulae, the local search heuristic that starts at a random truth assignment, and repeatedly ips the variable that improves the number of satissed clauses the most, almost always succeeds in discovering a satisfying truth assignment. Consider the following simple heuristic for SATISFIABILITY: start with a random truth assignment, call it T; while there is a truth assignment T 0 which diiers from T in one variable, and T 0 satisses more clauses than T do choose the T 0 that satisses the most clauses, and set T := T 0 ; return T. Naturally, when the formula is unsatissable, this heuristic will not return a satisfying truth assignment, and so it will be in some sense \correct."""" We therefore ask the question: If the formula is satissable, how often will this heuristic return a satisfying truth assignment? We show that the answer is almost always! Naturally, there is nothing surprising or original about an NP-complete problem with a good average{case algorithm under the most natural probabilistic distribution. What is perhaps a little surprising is that the problem is so fundamental, the algorithm so simple, and the proof so easy. Let F be a Boolean formula of n variables in conjunctive normal form with three literals per clause (the familiar NP-complete 3SAT problem, Garey and Johnson 1979). Suppose that F is satissable, say by a truth assignment ^ T. We shall show that, for almost all such F, the greedy algorithm will in fact discover ^ T with very high probability. The reason is, of course, that most satissable formulae have just one satisfying truth assignment. Intuitively then, the greedy algorithm always discovers the satisfying assignment, since the clauses always \point the way."""" The probabilistic calculation that follows makes this intuition precise. If the greedy heuristic starts at a truth assignment that agrees with ^ T in very few variables, then it is likely that a local optimum that is not a global optimum will be found. However, it is straightforward to show that such starting points are very rare. Let us call a truth assignment bad if it agrees with ^ T in fewer than (1 2 ?)n variables, for some > 0; all other assignments are good. Lemma 1. The probability that the initial truth assignment, chosen at random, is bad is at most e ?2 2 n ."""	complete (complexity);conjunctive normal form;global optimization;greedy algorithm;heuristic;interpretation (logic);local optimum;local search (optimization);michael garey;np-completeness	Elias Koutsoupias;Christos H. Papadimitriou	1992	Inf. Process. Lett.	10.1016/0020-0190(92)90029-U	combinatorics;greedy algorithm;probabilistic analysis of algorithms;np-complete;computer science;analysis of algorithms;mathematics;algorithm;satisfiability;search algorithm	AI	11.10089789495934	17.34056990675037	27301
87f111a216efca354d390d375544e1391ba9dd2d	models for video-on-demand scheduling with costs	scheduling;clairvoyant;non clairvoyant;video on demand;online algorithms	Video-on-demand, which provides digital content as needed, supplies flexibility for the users but presents reactive challenges for the provider, as the peaks and troughs in demand lead to an inconsistent requirement of resources. The cost of keeping servers primed for demand that may not appear must be balanced against the cost of frustrating users who must wait for service. This VoD problem is a bi-objective optimization problem, minimizing cost to the provider and delay for the user. Mindful of real-world applications, we introduce a model that handles tasks of differing size (bandwidth) or value by assigning weights to these tasks, and combining the weight with the duration. In this way, we can account for differentiated tasks, in particular, premium users and variable sized tasks. We also extend our approach to account for multiple tasks on each machine.	algorithm;bandwidth (signal processing);best, worst and average case;bin packing problem;digital recording;mathematical optimization;optimization problem;scheduling (computing);set packing	Jean-Charles Grégoire;Angèle M. Hamel	2016	EURO J. Computational Optimization	10.1007/s13675-015-0059-2	real-time computing;computer science;operations management;distributed computing	DB	12.480466258229598	10.658523496198116	27313
4aeda60c33750f2b38d69e8a16bac3d5020b2c35	improving the decoding efficiency of private search		We show two ways of recovering all matching documents, in the Ostrovsky et al. Private Search [3], while requiring considerably shorter buffers. Both schemes rely on the fact that documents colliding in a buffer position provide the sum of their plaintexts. Efficient decoding algorithms can make use of this property to recover documents never present alone in a buffer position.	algorithm;plaintext	George Danezis;Claudia Díaz	2005	IACR Cryptology ePrint Archive		information retrieval;decoding methods;computer science	Crypto	10.481480277319863	29.14877722181891	27336
2d9e290c1ae0cd750fd23c60be37563440fa45ac	approximability of the capacitated b-edge dominating set problem	maastricht university;graphe biparti;vertex cover;approximate algorithm;grafo bipartido;vertex;edge dominating set;approximation algorithm;aproximacion;valid inequalities;digital archive;68wxx;relajacion;approximation;dominating set;integrality gap;programacion lineal;informatique theorique;open access;ensemble contour;68r10;algoritmo aproximacion;linear programming relaxation;edge set;linear programming;programmation lineaire;relaxation;conjunto dominando;vertice;publication;scientific;algorithme approximation;bipartite graph;68w25;institutional repository;ensemble dominant;computer theory;informatica teorica	In this paper, we discuss the approximability of the capacitated b-edge dominating set problem, which generalizes the edge dominating set problem by introducing capacities and demands on the edges. We present an approximation algorithm for this problem and show that it achieves a factor of 8/3 for general graphs and a factor of 2 for bipartite graphs. Moreover, we discuss the relationships of the edge dominating set problem and the vertex cover problem. The results show that improving the approximation factor beyond 8/3 using our approach of adding valid inequalities to a natural linear programming relaxation is as hard as improving the approximation factor for vertex cover beyond 2. c © 2007 Elsevier B.V. All rights reserved.	approximation algorithm;edge dominating set;linear programming relaxation;vertex cover	André Berger;Takuro Fukunaga;Hiroshi Nagamochi;Ojas Parekh	2007	Theor. Comput. Sci.	10.1016/j.tcs.2007.06.009	vertex;mathematical optimization;combinatorics;discrete mathematics;bidimensionality;bipartite graph;dominating set;vertex cover;linear programming;linear programming relaxation;edge cover;approximation;publication;relaxation;mathematics;maximal independent set;approximation algorithm;algorithm	Theory	21.329145242668464	26.59360606461269	27377
2d4a1a8fdca61ee79d77bc01682c64428900d0f8	efficient algorithms for solving the shortest covering path problem	camino mas corto;shortest path;nodes;transportes;nodes networks;routing;efficient algorithm;calculation;result;costo;calculo;methode calcul;algorithme;metodo calculo;resolucion problema;transports;algorithm;heuristic methods;mathematical programming;terminus;transportation;chemin plus court;resultado;algorithms;encaminamiento;calcul;resultat;programmation mathematique;walkways;programacion matematica;computing method;problem solving;resolution probleme;acheminement;cout;algoritmo	The Shortest Covering Path Problem (SCPP) is one of identifying the least cost path from a pre-specified starting node to a pre-specified terminus node. The path is constrained by the condition that it must cover every node in the network. A node is considered to be covered if it is within some pre-specified covering distance of a node on the path. This SCPP has many potential applications, especially in hierarchical network design, and bi-modal routing problems. In this paper we introduce two efficient algorithms for solving the SCPP. The first is a heuristic based upon a Lagrangian relaxation of the problem. The second is an exact algorithm based upon a branch and bound procedure which utilizes the bounds generated by the Lagrangian relaxation scheme. Computational tests indicate that both procedures are very efficient. The heuristic identified and verified the optimal solution for 135 of the 160 test problems solved. The optimal solution to the remaining 25 problems was readily identified by the exact ...	algorithm	John R. Current;Hasan Pirkul;Erik Rolland	1994	Transportation Science	10.1287/trsc.28.4.317	transport;mathematical optimization;routing;combinatorics;calculation;input/output;computer science;mathematics;node;shortest path problem;k shortest path routing;algorithm	Theory	21.021646038126576	8.033261238848393	27424
2b13cf163e7ab02906760587233ab9c0512f3216	turing degrees of multidimensional sfts	turing degree;π 0 1 classes;2 dimensional;tilings;computational complexity;subshift of finite type;undecidability	In this paper we are interested in computability aspects of subshifts and in particular Turing degrees of 2-dimensional SFTs (i.e. tilings). To be more precise, we prove that given any Π1 class P of {0, 1} there is a SFT X such that P ×Z is recursively homeomorphic to X \U where U is a computable set of points. As a consequence, if P contains a computable member, P and X have the exact same set of Turing degrees. On the other hand, we prove that if X contains only non-computable members, some of its members always have different but comparable degrees. This gives a fairly complete study of Turing degrees of SFTs. Wang tiles have been introduced by Wang [Wang(1961)] to study fragments of first order logic. Independently, subshifts of finite type (SFTs) were introduced to study dynamical systems. From a computational and dynamical perspective, SFTs and Wang tiles are equivalent, and most recursive-flavoured results about SFTs were proved in a Wang tile setting. Knowing whether a tileset can tile the plane with a given tile at the origin (also known as the origin constrained domino problem) was proved undecidable by Wang [Wang(1963)]. Knowing whether a tileset can tile the plane in the general case was proved undecidable by Berger [Berger(1964), Berger(1966)]. Understanding how complex, in the sense of recursion theory, the points of an SFT can be is a question that was first studied by Myers [Myers(1974)] in 1974. Building on the work of Hanf [Hanf(1974)], he gave a tileset with no computable tilings. Durand/Levin/Shen [Durand et al.(2008)Durand, Levin, and Shen] showed, 40 years later, how to build a tileset for which all tilings have high Kolmogorov complexity. A Π1 class (of sets) is an effectively closed subset of {0, 1} , or equivalently the set of oracles on which a given Turing machine does not halt. Π1 classes occur naturally in various areas in computer science and recursive mathematics, see e.g. [Cenzer and Remmel(1998), Simpson(2011a)] and the upcoming book [Cenzer and Remmel(2011)]. It is easy to see that any SFT is a Π1 class (up to a computable coding of ΣZ 2 into {0, 1}). This has various consequences. As an example, every non-empty SFT contains a point which is not Turing-hard (see ∗mail: Emmanuel.Jeandel@lif.univ-mrs.fr †mail: Pascal.Vanier@lif.univ-mrs.fr 1 ha l-0 06 13 16 5, v er si on 3 1 Ju n 20 12 Durand/Levin/Shen [Durand et al.(2008)Durand, Levin, and Shen] for a selfcontained proof). The main question is how different SFTs are from Π1 classes. In the one-dimensional case, some answers to these questions were given by Cenzer/Dashti/King/Tosca/Wyman [Dashti(2008), Cenzer et al.(2008)Cenzer, Dashti, and King, Cenzer et al.(2012)Cenzer, Dashti, Toska, and Wyman]. The main result in this direction was obtained by Simpson [Simpson(2011b)], building on the work of Hanf and Myers: for every Π1 class S, there exists a SFT with the same Medvedev degree as S. The Medvedev degree roughly relates to the “easiest” Turing degree of S. What we are interested in is a stronger result: can we find for every Π1 class S a SFT which has the same Turing degrees? We prove in this article that this is true if S contains a computable point but not always when this is not the case. More exactly we build (Theorem 4.1) for every Π1 class S a SFT for which the set of Turing degrees is exactly the same as for S with the additional Turing degree of computable points. We also show that SFTs that do not contain any computable point always have points with different but comparable degrees (Corollary 5.11), a property that is not true for all Π1 classes. In particular there exist Π1 classes that do not have any points with comparable degrees. As a consequence, as every countable Π1 class contains a computable point, the question is solved for countable sets: the sets of Turing degrees of countable Π1 classes are the same as the sets of Turing degrees of countable sets of tilings. In particular, there exist countable sets of tilings with some non-computable points. This can be thought as a two-dimensional version of Corollary 4.7 in [Cenzer et al.(2012)Cenzer, Dashti, Toska, and Wyman]. This paper is organized as follows. After some preliminary definitions, we start with a quick proof of a generalization of Hanf, already implicit in Simpson [Simpson(2011b)]. We then build a very specific tileset, which forms a grid-like structure while having only countably many tilings, all of them computable. This tileset will then serve as the main ingredient to prove the result on the case of classes with a computable point in section 4. In section 5 we finally show the result on classes without computable points.	computability theory;computable function;computer science;dynamical system;existential quantification;first-order logic;halting problem;kolmogorov complexity;oracle machine;recursion;recursive set;simpson's rule;subshift of finite type;system fault tolerance;tile-based video game;turing degree;turing machine;undecidable problem;universal quantification;wang tile	Emmanuel Jeandel;Pascal Vanier	2013	Theor. Comput. Sci.	10.1016/j.tcs.2012.08.027	turing degree;hyperarithmetical theory;combinatorics;two-dimensional space;discrete mathematics;computability theory;turing reduction;time hierarchy theorem;alternating turing machine;computer science;turing completeness;2-exptime;description number;post's theorem;mathematics;computational complexity theory;pa degree;algorithm;subshift of finite type;algebra	Theory	-2.9786778338379176	15.777280205449133	27446
7720999c73edb326ee604b1e9b4bcce7b92880fd	combinational complexity of some monotone functions	mathematics;boolean functions;switching circuits;sorting;paper technology;monotone function;boolean function;wires;logic circuits;monos devices;computational complexity;lower bound;boolean functions computational complexity monos devices sorting switching circuits logic circuits wires mathematics paper technology	Edmund A. Lamagna and John E. Savaget Brown University Providence. RI 02912 An important open question in the field of computational complexity in the development of non­ trivial lower bounds on the number of logical opera­ tions required to compute switching functions. Although counting arguments can be used to show that most Boolean functions of n inputs and O(n) or fewer outputs have complexity growing exponentially in n, no one has yet exhibited a particular such function whose unlimited fan-out combinational complexity is known to grow faster than linearly in n when a func­ tionally complete set of primitive operations is allowed.	combinational logic;computational complexity theory;fan-out;monotone	Edmund A. Lamagna;John E. Savage	1974		10.1109/SWAT.1974.9	circuit complexity;boolean algebra;boolean circuit;combinatorics;discrete mathematics;boolean network;majority function;decision tree model;boolean expression;product term;computer science;theoretical computer science;karp–lipton theorem;complexity index;mathematics;combinational logic;boolean function;algorithm;parity function	Theory	8.551265488607228	21.994033755627992	27472
064f4a76f98d35f700938902453b900c59a4c938	a dynamic adaptive local search algorithm for the circular packing problem	bin packing problem;cercle;algoritmo busqueda;local search algorithm;algoritmo adaptativo;algorithme recherche;heuristic method;search algorithm;packing;problema relleno;metodo heuristico;cutting stock problem;systeme ouvert;optimisation combinatoire;busca local;adaptive algorithm;algorithme adaptatif;probleme decoupe;circulo;probleme remplissage;cutting and packing;problema troquelado;heuristics;dynamic search;methode heuristique;combinatorial optimization;open systems;dynamic adaptation;circle;sistema abierto;local search;recherche locale;garnissage;optimizacion combinatoria;relleno	This paper studies the circular packing problem (CPP) which consists of packing n non-identical circles Ci of known radius ri, i ∈ N = {1, … , n}, into the smallest containing circle C. The objective is to determine the coordinates (xi, yi) of the center of Ci, i ∈ N, as well as the radius r and center (x, y) of C. This problem, which is a variant of the two-dimensional open dimension problem, is solved using a two-step, dynamic, adaptive, local search algorithm. At each iteration, the algorithm identifies the set of potential “best local positions” of a circle Ci, i ∈ N, given the positions of the previously packed circles, and determines for each of these positions the coordinates and radius of the smallest containing circle. The “best local position” minimizes the radius of the current containing circle. That is, every time an additional circle is packed, both the center and the radius of the containing circle are dynamically updated, and the smallest containing circle is known. The experimental results reflect the good performance of the algorithm.	local search (optimization);search algorithm;set packing	Mhand Hifi;Rym M'Hallah	2007	European Journal of Operational Research	10.1016/j.ejor.2005.11.069	inverse curve;smallest-circle problem;radius;mathematical optimization;unit circle;circle packing;combinatorial optimization;computer science;local search;calculus;midpoint circle algorithm;mathematics;geometry;circumscribed circle;circular segment;generalised circle;sphere	Robotics	20.48844378392137	6.983314112840221	27497
34fabf8b3622c9a1283e72593c30d4cd337ae9c6	effective job shop scheduling through active chain manipulation	job shop scheduling;production system;temps total achevement;systeme production;amelioration iterative;sistema produccion;algorithme;algorithm;makespan;scheduling;job shop;ordonamiento;tabu search;chaine active;job shop scheduling problem;ordonnancement;heuristic algorithm;recherche tabou;algoritmo	A practical yet effective heuristic algorithm is developed in this paper for solving the make-span reduction job shop scheduling problem. The algorithm iteratively improves an existing job shop schedule through exploring the schedule's neighborhood, using a simple active chain manipulation scheme. A Tabu search technique is employed, as part of the active chain manipulation procedure developed in this paper, to prevent the trap of local optimality. Test results show that the algorithm is capable of efficiently generating very good schedules.	job shop scheduling;scheduling (computing)	Dake Sun;Rajan Batta;Li Lin	1995	Computers & OR	10.1016/0305-0548(94)E0018-3	heuristic;job shop scheduling;mathematical optimization;flow shop scheduling;tabu search;computer science;production system;scheduling;algorithm	Robotics	19.347737277843567	6.533968074269485	27501
f594fdbc5b9bcb302d4822ce302c15f9612d3ade	approximating the traffic grooming problem	optical network;wavelength assignment;approximate algorithm;optical switch;traffic grooming;wavelength division multiplexing wdm;exact solution;wdm optical network;optical networks;network topology;add drop multiplexer;add drop multiplexer adm;wavelength division multiplex	The problem of grooming is central in studies of optical networks. In graph-theoretic terms, this can be viewed as assigning colors to the lightpaths so that at most g of them (g being the grooming factor) can share one edge. The cost of a coloring is the number of optical switches (ADMs); each lightpath uses two ADMs, one at each endpoint, and in case g lightpaths of the same wavelength enter through the same edge to one node, they can all use the same ADM (thus saving g-1 ADMs). The goal is to minimize the total number of ADMs. This problem was shown to be NP-complete for g=1 and for a general g. Exact solutions are known for some specific cases, and approximation algorithms for certain topologies exist for g=1. We present an approximation algorithm for this problem. For every value of g the running time of the algorithm is polynomial in the input size, and its approximation ratio for a wide variety of network topologies-including the ring topology-is shown to be 2lng+o(lng). This is the first approximation algorithm for the grooming problem with a general grooming factor g.		Michele Flammini;Luca Moscardelli;Mordechai Shalom;Shmuel Zaks	2008	J. Discrete Algorithms	10.1016/j.jda.2007.09.001	traffic grooming;telecommunications;computer science;mathematics;distributed computing;optical switch;network topology;computer network	Theory	22.715357479436506	18.467401269206352	27523
4c044dff088dbe903649397b34b156717895d16e	structural aspects of local adjunct languages		Several open problems concerning local adjunct languages are considered and solved. One of the most interesting (from a linguistic point of view) and difficult (mathematically) open problems was whether or not null symbols can be dispensed without sacrificing the weak generative capacity. This problem is solved and the answer is negative.  Also considered are some problems concerning one-sided grammars, homomorphisms of languages (it is shown that local adjunct languages are not closed under homomorphism),  β -linear languages and mixed adjunct grammars.		Leon S. Levy	1973	Information and Control	10.1016/S0019-9958(73)90732-8	discrete mathematics;mathematics;cone;abstract family of languages;algorithm;algebra	Theory	-3.021542673142364	15.338982117903784	27549
2138f5cc2a64251fd3351ef629c6c02d254333d8	the probabilistic analysis of a greedy satisfiability algorithm	approximation asymptotique;satisfactoriabilidad;algorithm analysis;algorithme glouton;satisfiability;greedy algorithm;algoritmo gloton;analyse algorithme;satisfaisabilite;asymptotic approximation;analisis algoritmo;aproximacion asintotica	Consider the following simple, greedy Davis-Putnam algorithm applied to a random 3-CNF formula of constant density c: Arbitrarily set to TRUE a literal that appears in as many clauses as possible, irrespective of their size (and irrespective of the number of occurrences of the negation of the literal). Reduce the formula. If any unit clauses appear, then satisfy their literals arbitrarily, reducing the formula accordingly, until no unit clause remains. Repeat. We prove that for c < 3.42 a slight modification of this algorithm computes a satisfying truth assignment with probability asymptotically bounded away from zero. Previously, algorithms of increasing sophistication were shown to succeed for c < 3.26. Preliminary experiments we performed suggest that c ≃ 3.6 is feasible running algorithms like the above, which take into account not only the number of occurrences of a literal but also the number of occurrences of its negation, irrespectively of clause-size information.	boolean satisfiability problem;greedy algorithm;probabilistic analysis of algorithms	Alexis C. Kaporis;Lefteris M. Kirousis;Efthimios G. Lalas	2006	Random Struct. Algorithms	10.1002/rsa.20104	combinatorics;greedy algorithm;discrete mathematics;computer science;mathematics;algorithm;satisfiability	Theory	10.1196264756038	18.719752245784736	27576
5cfb53a95980f5742d1246bcda191fa55c461748	efficient generic multi-stage self-stabilizing algorithms for trees.				Jean R. S. Blair;Fredrik Manne	2004			weight-balanced tree	Crypto	16.79781072355565	29.318712461821335	27600
22f2b89195aeb6efaf3505e09286ae365e558775	lower bounds for kernelizations	polynomial hierarchy;lower bound	We first present a method to rule out the existence of strong p lynomial kernelizations of parameterized problems under the hypothesis P6= NP. For example, this method is applicable to the problem S AT parameterized by the number of variables of the input formula. Then we obtain furt he improvements of corresponding results in [5, 7] by refining the central lem ma of their proof method, a lemma due to Fortnow and Santhanam. In particular, assuming that the polynomial hierarchy does not collapse to its third leve l, w show that every parameterized problem with a “linear OR” and with NP-hard un erlying classical problem does not have polynomial reductions to itself that assign to every instancex with parameterk an instancey with |y| = kO(1) · |x|1−ε (hereε is any given real number greater than zero).	np-hardness;parameterized complexity;polynomial hierarchy;polynomial-time reduction	Yijia Chen;Jörg Flum;Moritz Müller	2007	Electronic Colloquium on Computational Complexity (ECCC)		mathematical optimization;combinatorics;discrete mathematics;mathematics;upper and lower bounds	Theory	16.090972678496115	19.240432878268617	27662
593d459f6a163f99e227bbd207cb8e253be0c9c3	an effective decision procedure for linear arithmetic with integer and real variables	additional key words and phrases: decision procedure;integer and real arithmetic;weak !−automata.;finite-state representations;finite automata	This paper considers nite-automata based algorithms for handling linear arithmetic with both real and integer variables. Previous work has shown that this theory can be dealt with by using nite automata on innnite words, but this involves some diicult and delicate to implement algorithms. The contribution of this paper is to show, using topological arguments, that only a restricted class of automata on innnite words are necessary for handling real and integer linear arithmetic. This allows the use of substantially simpler algorithms, which have been successfully implemented.	a-normal form;algorithm;automata theory;automaton;breakpoint;convex set;correctness (computer science);decision problem;hybrid system;ll parser;powerset construction;temporal database	Bernard Boigelot;Sébastien Jodogne;Pierre Wolper	2003	CoRR		combinatorics;discrete mathematics;computer science;artificial intelligence;mathematics;finite-state machine;algorithm	Logic	-4.0651608602464036	18.675266715397196	27686
412afacfc29a18c0ad83402b5d33f40de0a12aea	a unified analysis of distributed counting with queueing theory	queueing theory		queueing theory	Roger Wattenhofer;Peter Widmayer	1998			discrete mathematics;g-network;m/d/c queue;mean value analysis;layered queueing network;theoretical computer science;bulk queue;bcmp network;queueing theory;mathematics;traffic equations	Theory	8.49433561142804	12.18457995921345	27711
e8a0424cc9f7174e461bad57ecab373d77fa4ba0	how much is that dawg in the window? a moving window algorithm for the directed acyclic word graph	data compression;language theory;graphe acyclique;teoria lenguaje;acyclic graph;algorithme;algorithm;algorritmo;informatique theorique;directed graph;grafico orientado;graphe oriente;directed acyclic word graph;palabra;grafico aciclico;word;compresion dato;theorie langage;compression donnee;mot;computer theory;informatica teorica	There is a class of data compression techniques that involve replacing repeating strings by pointers to previous occurrences of those strings. In order to implement these techniques, it would be useful to have an index which can quickly locate repeats within a fixed window of the text seen so far. One such index is the directed acyclic word graph (DAWG). An algorithm is presented which constructs the DAWG for a fixed window of k letters moving from left to right along the input text. It is shown that this algorithm has worst case behavior proportional to nk, where n is the length of the input text and k is the sixe of the window. This bound is the best possible for a window moving through the DAWG and also for a window moving through the suffix tree, a functionally related structure. The average case for the algorithm is analyxed under the assumption that input strings are random texts constructed from a fixed alphabet where each letter has equal probability. The resulting upper bound is 0( n log k). Q 1987 Academic Press, Inc.	algorithm;best, worst and average case;data compression;deterministic acyclic finite state automaton;directed acyclic graph;suffix automaton;suffix tree	Janet A. Blumer	1987	J. Algorithms	10.1016/0196-6774(87)90045-9	data compression;combinatorics;directed graph;computer science;philosophy of language;theoretical computer science;word;mathematics;directed acyclic word graph;directed acyclic graph;algorithm	Theory	14.18914041692465	27.347525811557077	27751
a2eecf340fafffcfd99d594920932fc57324e8c9	nc algorithms for weighted planar perfect matching and related problems		Consider a planar graph G = (V,E) with polynomially bounded edge weight function w : E → [0, poly(n)]. The main results of this paper are NC algorithms for finding minimum weight perfect matching in G. In order to solve this problems we develop a new relatively simple but versatile framework that is combinatorial in spirit. It handles the combinatorial structure of matchings directly and needs to only know weights of appropriately defined matchings from algebraic subroutines. Moreover, using novel planarity preserving reductions, we show how to find: maximum weight matching in G when G is bipartite; maximum multiple-source multiple-sink flow in G where c : E → [1, poly(n)] is a polynomially bounded edge capacity function; minimum weight f -factor in G where f : V → [1, poly(n)]; min-cost flow in G where c : E → [1, poly(n)] is a polynomially bounded edge capacity function and b : V → [1, poly(n)] is a polynomially bounded vertex demand function. There have been no known NC algorithms for these problems previously. 2012 ACM Subject Classification Theory of computation → Network flows, Theory of computation → Shared memory algorithms, Theory of computation → Pseudorandomness and derandomization	blossom algorithm;linear algebra;matching (graph theory);maxima and minima;minimum weight;minimum-cost flow problem;nc (complexity);norm (social);planar graph;pseudorandomness;randomized algorithm;shared memory;subroutine;theory of computation;weight function	Piotr Sankowski	2018		10.4230/LIPIcs.ICALP.2018.97	discrete mathematics;combinatorics;matching (graph theory);planarity testing;vertex (geometry);minimum weight;bipartite graph;mathematics;weight function;algorithm;planar graph;bounded function	Theory	24.079432028326938	24.18477695504198	27793
6a74b45d54b43916217cec3b49452f4d443e214d	the capacitated lot-sizing problem with linked lot sizes	grupo de excelencia;valid inequalities;mixed integer program;administracion de empresas;clspl;lot sizing;economia y empresa;mip;grupo a	In this paper a new mixed integer programming (MIP) model formulation and its incorporation into a time-oriented decomposition heuristic for the capacitated lot-sizing problem with linked lot sizes (CLSPL) is proposed. The solution approach is based on an extended model formulation and valid inequalities to yield a tight formulation. Extensive computational tests prove the capability of this approach and show a superior solution quality with respect to other solution algorithms published so far.		Christopher Suerie;Hartmut Stadtler	2003	Management Science	10.1287/mnsc.49.8.1039.16406	mathematical optimization;operations management;mathematical economics	Theory	17.136240652046485	4.230645957042955	27807
0ddae0a1b2ade9f8f35895e98c6ec15e882282bb	maximizing non-monotone submodular functions	submodular function;maximizing non-monotone submodular functions;value oracle model;random set;algorithms work;constant-factor approximation algorithm;certain constraint satisfaction problem;symmetric submodular function;approximation algorithm;symmetric case;nonnegative submodular function;approximation algorithms;combinatorial optimization	Submodular maximization generalizes many important problems including Max Cut in directed/undirected graphs and hypergraphs, certain constraint satisfaction problems and maximum facility location problems. Unlike the problem of minimizing submodular functions, the problem of maximizing submodular functions is NP-hard.	constraint satisfaction problem;expectation–maximization algorithm;graph (discrete mathematics);maximum cut;np-hardness;submodular set function;monotone	Uriel Feige;Vahab S. Mirrokni;Jan Vondrák	2007	48th Annual IEEE Symposium on Foundations of Computer Science (FOCS'07)	10.1109/FOCS.2007.29	mathematical optimization;combinatorics;discrete mathematics;directed graph;maximum coverage problem;function approximation;computer science;local search;submodular set function;facility location problem;np-hard;mathematics;computational complexity theory;constraint satisfaction problem;algorithm	Theory	21.92242608640119	15.943753259318026	27822
05efeac1ce39c7285c3fddb35a6d04df1bf8e187	reliability investigation of a hybrid fuel cell electric vehicle powered by downsized fuel cells	system configuration;fuel cell vehicle;fuel cell;load sharing;electric vehicle;state of charge	Fuel cell electric vehicles are mostly relying on operation of their fuel cell and battery system. Single power source systems use battery units as backup; however, in heavy loads or instances with low State Of Charge (SOC) levels, there is a need for other mechanisms to provide reliable energy for the system. This paper investigates the natural enhanced reliability of operation in an advanced system configuration with two downsized fuel cells. The two fuel cell configuration brings high fuel efficiency by economic load sharing between two fuel cells. The reliability of this system configuration is investigated and compared with conventional designs of hybrid fuel cell vehicles.	backup;cell (microprocessor);state of charge;system configuration	Pardis Khayyer;Afshin Izadian;Parviz Famouri	2008		10.1007/978-90-481-3656-8_89	aircraft fuel system;brake specific fuel consumption	Mobile	4.313324671649928	6.879613925167592	27892
26893bd20c298c2b87dca9859ab5c78985ff1a4f	disk performance enhancement through markov-based cylinder remapping	simulated annealing algorithm;statistical test;dg ux 8482;simulated annealing;cylinder mapping;markov model;first order;maximum likelihood estimate;dg ux;disk subsystem;markov models;unix 8482;unix;markov chain	A scheme for disk subsystem performance enhancement that is based on (virtual) cylinder remapping is proposed. A natural workload on a real system is measured, and statistical tests are used to determine that disk accesses are appropriately modeled by a first order Markov chain. Maximum likelihood estimators of the Markov model parameters are used in a simulated annealing algorithm to find a permutation of the (virtual) cylinders that substantially reduces expected seek distance. This permutation is then installed in a real system and tested under a workload that is stochastically generated from the Markov model. The proposed scheme is seen to offer a 25.6% reduction in mean service time when compared to the original (unmapped) cylinder arrangement.	algorithm;cylinder seal;cylinder-head-sector;markov chain;markov model;norm (social);simulated annealing	Robert Geist;Darrell Suggs;Robert G. Reynolds;Shardul Divatia;Fred Harris;Evan Foster;Priyadarshan Kolte	1992		10.1145/503720.503735	maximum-entropy markov model;real-time computing;simulation;computer science;continuous-time markov chain;theoretical computer science;markov model;hidden markov model	Metrics	10.813119323654222	11.719688503769804	27934
d99b14984e9f047b75d73b71b5028c971e579a75	performance comparison of queues with batch renewal arrivals in continuous and discrete times	maximum entropy methods;queueing theory;correlation time domain analysis servers mathematical model queueing analysis dispersion equations;time domain analysis;servers;maximum entropy batch renewal arrival process traffic process traffic correlation discrete time domain continuous time domain batch renewal traffic gi g m x 1 n queue queue length distribution blocking probability waiting time distribution adverse effect buffer performance queueing model batch poisson arrival;mathematical model;queueing theory maximum entropy methods poisson distribution;correlation;dispersion;queueing analysis;poisson distribution	It has been proven that the batch renewal process is the least biased choice of traffic process given the infinite sets of measures of the traffic correlation, (i.e. indices of dispersion, covariances or correlation functions) in the discrete time domain. The same conclusion is expected to hold in the continuous time domain. That motivates the study and comparison of similar queues, fed by batch renewal traffic, in both domains. In this paper, performance distributions are obtained for the GIG/M[X]/1/N queue in continuous time and compared with the corresponding results for the GIG/Geo[X]/1/N queue in discrete time. The expressions for queue length distribution, blocking probability and waiting time distributions are derived. They can be used to assess the adverse effect on buffer performance that is induced by traffic correlation. The queueing model with batch Poisson arrival, as special case, is also presented. The queue length distribution is interpreted by maximum entropy.	blocking (computing);embedded system;erlang (unit);global information grid;information theory;markov chain;principle of maximum entropy;queueing theory;time complexity	Wei Li;Demetres D. Kouvatsos;Rod J. Fretwell	2012	2012 IEEE 14th International Conference on High Performance Computing and Communication & 2012 IEEE 9th International Conference on Embedded Software and Systems	10.1109/HPCC.2012.109	mean value analysis;m/m/1 queue;m/d/c queue;pollaczek–khinchine formula;dispersion;real-time computing;heavy traffic approximation;m/m/c queue;m/m/∞ queue;bulk queue;m/d/1 queue;mathematical model;layered queueing network;m/g/k queue;m/g/1 queue;fork–join queue;poisson distribution;d/m/1 queue;fluid queue;queueing theory;kendall's notation;correlation;burke's theorem;g/g/1 queue;server;statistics	Metrics	7.898951769319421	11.602519963733526	27985
1862a86a73f32538942acae8e77a4977502dbdd4	hybrid ac and dc smart home resilient architecture transforming prosumers in unircons		Todays technological developments are drivers for new solutions towards massive renewables deployments resulting in increased network challenges. The paper presents a new approach for prosumers having such a local PV production and storage devices which allows, with adequate design, the user to change from classic prosumer to consumer-only from grid perspective, with enhanced efficiency and resilience based on a hybrid (AC and DC) architecture. Three use-cases are presented: PV behind the meter, PV and storage behind the meter and a newly proposed UniRCon (Unidirectional Resilient Consumer) architecture. This use-cases analysis considers four timeline horizons (2018, 2020, 2022, and 2025). It is shown for the selected profiles of consumption and production that PV plus storage behind the meter bring savings, as recognized and expected by today trend of business-cases, and that the complete UniRCon architecture steps in even with more savings together with higher resilience against the grid outages. The UniRCon solution gives also better ramp behaviour during the evening period, compared with the duck curve expected to challenge power systems with high PV penetration.	device driver;home automation;ibm power systems;ramp simulation software for modelling reliability, availability and maintainability;timeline	Mihai Sanduleac;Mihaela Albu;Lucian Toma;João Martins;Anabela Gonçalves Pronto;Vasco Delgado-Gomes	2017	2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)	10.1109/ICE.2017.8280070	electric power system;renewable energy;grid;architecture;metre;timeline;home automation;prosumer;electrical engineering;computer science	HPC	2.2864287723237244	7.682423690592052	27990
61653ce3ec67cf9be4454a23bae4d2a231244708	several properties of array languages	array language	The languages generated by connected and disconnected array grammars are studied. We define substitutions of array languages, and we study closure properties of classes of array languages under substitutions. A characterization by means of substitutions for connected context-free array languages and a Kleene-like theorem for regular array languages are given.		Dorel Lucanu	1987	Inf. Sci.	10.1016/0020-0255(87)90038-7	array data type;combinatorics;discrete mathematics;mathematics;cone;algorithm	DB	-2.9509353644096996	17.740921088109552	27998
1d4b3752b4b3ef0b18ee6394e06f40491467e191	focused stochastic local search and the lovász local lemma		We develop tools for analyzing focused stochastic local sea rch lgorithms. These are algorithms which search a state space probabilistically by repeatedly selecting a constraint that is violated in the current state and moving to a random nearby state which, hope fully, addresses the violation without introducing many new ones. A large class of such algorithms a rise from the algorithmization of the Lovász Local Lemma, a non-constructive tool for proving th e existence of satisfying states. Here we give tools that provide a unified analysis of such algorithms and of many more, expressing them as instances of a general framework. Research supported by NSF grant CCF-1514128. Research supported by NSF grant CCF-1514434.	algorithm;ibm notes;local search (constraint satisfaction);local search (optimization);state space	Dimitris Achlioptas;Fotis Iliopoulos	2016			mathematical optimization;combinatorics;discrete mathematics;lovász local lemma;algorithmic lovász local lemma;graph coloring;mathematics;algorithm;satisfiability	Theory	16.006703335817924	18.692799704506005	28010
e8679b7b0bca160adf260abc3677587b7b9ec744	a stability criterion via fluid limits and its application to a polling system	sistema fila espera;systeme attente;fluid limit;proceso markov;invitation a emettre;modelo fluido;fluid model;positive recurrence;stability;recurrence;recurrencia;processus markov;queueing system;markov process;polling;modele fluide;stabilite;polling system;estabilidad;exhaustive service policy;invitacion a transmitir	We introduce a generalized criterion for the stability of Markovian queueing systems in terms of stochastic fluid limits. We consider an example in which this criterion may be applied: a polling system with two stations and two heterogeneous servers.	polling (computer science);routh–hurwitz stability criterion	Serguei Foss;Artyom P. Kovalevskii	1999	Queueing Syst.	10.1023/A:1019187004209	polling;polling system;stability;control theory;mathematics;markov process;mathematical economics;statistics	Metrics	9.070496562783537	11.980884160531605	28024
112b3c44617075b6f38cc063e330e7118f43529b	some results on more flexible versions of graph motif	article accepte pour publication ou publie;graph motif problem;computational complexity;biological networks;computational biology	The problems studied in this paper originate from Graph Motif, a problem introduced in 2006 in the context of biological networks. Informally speaking, it consists in deciding if a multiset of colors occurs in a connected subgraph of a vertex-colored graph. Due to the high rate of noise in the biological data, more flexible definitions of the problem have been outlined. We present in this paper two inapproximability results for two different optimization variants of Graph Motif: one where the size of the solution is maximized, the other when the number of substitutions of colors to obtain the motif from the solution is minimized. We also study a decision version of Graph Motif where the connectivity constraint is replaced by the well known notion of graph modularity. While the problem remains N P-complete, it allows algorithms in F P T for biologically relevant parameterizations.	algorithm;biological network;color;decision problem;graph coloring;hardness of approximation;mathematical optimization;motif;p-complete;whole earth 'lectronic link	Romeo Rizzi;Florian Sikora	2014	Theory of Computing Systems	10.1007/s00224-014-9564-6	graph power;factor-critical graph;biological network;combinatorics;directed graph;graph bandwidth;null graph;graph property;computer science;simplex graph;forbidden graph characterization;machine learning;aperiodic graph;cubic graph;graph factorization;mathematics;voltage graph;distance-hereditary graph;graph;windmill graph;computational complexity theory;butterfly graph;quartic graph;complement graph;line graph;algorithm;strength of a graph	Theory	23.98646480106337	23.02785047824362	28058
5483f15611d69c83c3a1177d8e201ce7efc811f2	an improved satisfiable sat generator based on random subgraph isomorphism	sat encoded sr-sgi;improved satisfiable;satisfiable sat instance;subgraph isomorphism generator;sat encoded srhd-sgi instance;sr-sgi counterpart;satisfiable random subgraph isomorphism;empirical hardness;random subgraph isomorphism;srhd-sgi instance;sat generator;satisfiable random high degree;empirical evidence	We introduce Satisfiable Random High Degree Subgraph Isomorphism Generator(SRHD-SGI), a variation of the Satisfiable Random Subgraph Isomorphism Generator (SR-SGI). We use the direct encoding to translate the SRHD-SGI instances into Satisfiable SAT instances. We present empirical evidence that the new model preserves the main characteristics of SAT encoded SR-SGI: easy-hard-easy pattern of evolution and exponential growth of empirical hardness. Our experiments indicate that SAT encoded SRHD-SGI instances are empirically harder than their SR-SGI counterparts. Therefore we conclude that SRHD-SGI is an improved generator of satisfiable SAT instances.	boolean satisfiability problem;experiment;patterns of evolution;subgraph isomorphism problem;time complexity	Calin Anton	2011		10.1007/978-3-642-21043-3_5	algorithm	AI	11.635135116795412	17.9158848398021	28118
487253be0fa519fbb11c1863b70befb56ed92f57	finite automata and rational languages. an introduction	finite automata	Without Abstract	automata theory;finite-state machine	Jean Berstel	1988		10.1007/BFb0013107	discrete mathematics;deterministic automaton;finite-state machine;regular expression;mathematics	Logic	-2.5372007271502888	22.15303535915351	28136
ffa0cff61b555405c261f100b594055bbf5e6add	a continuous optimization model for a joint problem of pricing and resource allocation	loi discrete;etude marche;modelizacion;discrete distribution;ley discreta;largeur bande;continuous function;90c90;funcion discreta;non linear programming;strategie stackelberg;revenue management;funcion utilidad;resource allocation;stackelberg strategy;pricing;fonction utilite;programacion no lineal;condition necessaire suffisante;real time;porcentaje ganancia;taux profit;exigence usager;exigencia usuario;convexite;utility function;market structure;fonction continue;programmation non lineaire;segmentation;fijacion precios;convexidad;optimisation combinatoire;modelisation;discrete function;fonction discrete;tariffication;telecomunicacion;funcion continua;tarification;continuous optimization;user requirement;necessary and sufficient condition;market survey;temps reel;estrategia stackelberg;telecommunication;anchura banda;preferencia;estudio mercado;tiempo real;bandwidth;programacion binivel;optimization;preference;asignacion recurso;estructura mercado;convexity;allocation ressource;bilevel programming;combinatorial optimization;structure marche;programmation biniveau;modeling;return rate;fixation prix;segmentacion;condicion necesaria suficiente;telecommunications;tarificacion;optimizacion combinatoria	This paper investigates the problem of maximizing the revenue of a telecommunications operator by simultaneously pricing point-to-point services and allocating bandwidth in its network, while facing competition. Customers are distributed into market segments, i.e., groups of customers with a similar preference for the services. This preference is expressed using utility functions, and customers choose between the offers of the operator and of the competition according to their utility. We model the problem as a leader-follower game between the operator and the customers. This kind of problem has classically been modeled as a bilevel program. A market segmentation is usually defined by a discrete distribution function of the total demand for a service; in this case, the problem can be modeled as a combinatorial optimization problem. In this paper, however, we motivate the use of a continuous distribution function and investigate the nonlinear continuous optimization problem obtained in this case. We analyze the mathematical properties of the problem, and in particular we give a necessary and sufficient condition for its convexity. We introduce methods to solve the problem and we provide encouraging numerical results on realistic telecommunications instances of the problem, showing that it can be solved efficiently.	approximation algorithm;bilevel optimization;branch and bound;combinatorial optimization;concave function;continuous optimization;convex function;interior point method;iteration;linear programming;mathematical optimization;michel hénon;nonlinear system;numerical analysis;optimization problem;point-to-point (telecommunications);purchasing;solver;telecommunications network	Mustapha Bouhtou;Guillaume Erbs	2009	RAIRO - Operations Research	10.1051/ro/2009008	computational problem;pricing;probability distribution;rate of return;continuous function;optimization problem;mathematical optimization;systems modeling;convexity;combinatorial optimization;resource allocation;generalized assignment problem;user requirements document;cutting stock problem;mathematics;market structure;continuous optimization;mathematical economics;segmentation;bandwidth	ECom	12.433609716239133	8.947661397693182	28148
b8f3c8db9581ef7d548c3a83743c8b468ad91ea9	response time preservation: a general technique for developing approximate algorithms for queueing networks	distributed system;queueing network;approximate algorithm;general techniques;mean value analysis;multiclass queueing networks;priority scheduling;error analysis;queueing system;approximate solutions;product from solutions	Response Time Preservation (RTP) is introduced as a general technique for developing approximate analysis procedures for queueing networks. The underlying idea is to replace a subsystem by an equivalent server whose response time in isolation equals that of the entire subsystem in isolation. The RTP based approximations, which belong to the class of decomposition approximations, can be viewed as a dual of the Norton's Theorem approach for solving queueing networks since it matches response times rather than throughputs. The generality of the RTP technique is illustrated by developing solution procedures for several important queueing systems which violate product form assumptions. Examples include FCFS servers with general service times, FCFS servers with different service times for multiple classes, priority scheduling, and distributed systems.	approximation algorithm;distributed computing;norton's theorem;response time (technology);responsiveness;scheduling (computing);server (computing)	Subhash C. Agrawal;Jeffrey P. Buzen;Annie W. Shum	1984		10.1145/800264.809314	g-network;mean value analysis;real-time computing;computer science;theoretical computer science;layered queueing network;distributed computing;statistics	Metrics	7.019646768615858	12.200920956253407	28200
8e930b24381bfdc75fc7530dceba1698eae26679	a recursive greedy algorithm for walks in directed graphs	graph theory;approximate algorithm;graph theory travelling salesman problems greedy algorithms computational complexity;best approximation;triangle inequality;time window;greedy algorithms;satisfiability;optimization problem;polynomial time algorithm;computational complexity;directed graph;travelling salesman problems;greedy algorithm;profitability;greedy algorithms optimized production technology approximation algorithms vehicles traveling salesman problems routing steiner trees tree graphs floors delay;quasipolynomial time algorithm greedy algorithm directed graphs walk orienteering problem time window problem k traveling salesman problem quasi poly time steiner problem;steiner tree	Given an arc-weighted directed graph G = (V, A, /spl lscr/) and a pair of nodes s, t, we seek to find an s-t walk of length at most B that maximizes some given function f of the set of nodes visited by the walk. The simplest case is when we seek to maximize the number of nodes visited: this is called the orienteering problem. Our main result is a quasi-polynomial time algorithm that yields an O(log OPT) approximation for this problem when f is a given submodular set function. We then extend it to the case when a node v is counted as visited only if the walk reaches v in its time window [R(v), D(v)]. We apply the algorithm to obtain several new results. First, we obtain an O(log OPT) approximation for a generalization of the orienteering problem in which the profit for visiting each node may vary arbitrarily with time. This captures the time window problem considered earlier for which, even in undirected graphs, the best approximation ratio known [Bansal, N et al. (2004)] is O(log/sup 2/ OPT). The second application is an O(log/sup 2/ k) approximation for the k-TSP problem in directed graphs (satisfying asymmetric triangle inequality). This is the first non-trivial approximation algorithm for this problem. The third application is an O(log/sup 2/ k) approximation (in quasi-poly time) for the group Steiner problem in undirected graphs where k is the number of groups. This improves earlier ratios (Garg, N et al.) by a logarithmic factor and almost matches the inapproximability threshold on trees (Halperin and Krauthgamer, 2003). This connection to group Steiner trees also enables us to prove that the problem we consider is hard to approximate to a ratio better than /spl Omega/(log/sup 1-/spl epsi// OPT), even in undirected graphs. Even though our algorithm runs in quasi-poly time, we believe that the implications for the approximability of several basic optimization problems are interesting.	approximation algorithm;directed graph;graph (discrete mathematics);greedy algorithm;hardness of approximation;mahdiyar;mathematical optimization;microsoft windows;np-hardness;p (complexity);polynomial;quasi-polynomial;recursion;reinforcement learning;rounding;semantic-oriented programming;social inequality;steiner tree problem;submodular set function;time complexity;travelling salesman problem	Chandra Chekuri;Martin Pál	2005	46th Annual IEEE Symposium on Foundations of Computer Science (FOCS'05)	10.1109/SFCS.2005.9	mathematical optimization;combinatorics;greedy algorithm;discrete mathematics;graph theory;mathematics;algorithm	Theory	22.84002256168883	18.755056252104843	28237
39caa46c19df1ec714e3e25182f458a740e87851	non-clairvoyant scheduling with precedence constraints	equi partition;fairness;online scheduling;non clairvoyant algorithm;precedence constraint;upper and lower bounds;precedences	We consider Edmonds's model (1999) extended by precedence constraints. In our setting, a scheduler has to schedule non-clairvoyantly jobs consisting in DAGs of tasks arriving over time, each task going through phases of different degrees of parallelism, unknown to the scheduler. As in the original model without precedence constraints, the scheduler is only informed of the arrival and the completion of each task, at the time of these events, and nothing more. Furthermore, it is not aware of the DAG structure of each job beforehand neither of the precise characteristics of the phases of the tasks that compose each job.  We consider the preemptive strategy Equi○Equi, that divides the processors evenly among the alive jobs and then divides the processing power alloted to each job evenly among its alive tasks. We show that whatever how complex the precedences are, Equi○Equi is (2 + ε)-speed 0(κ/ε)-competitive for the flowtime metric, where κ is the maximum number of independent tasks in each job. That is to say, the flowtime of the schedule computed by EquioEqui is at a constant ratio of the optimal flowtime as soon as Equi is given slightly more than twice the resources as the optimum it is compared to. Interestingly, the extra speed needed to obtain a competitive algorithm, namely (2+ε), is the same in presence of precedence constraints, as in the original setting without precedences studied by Edmonds in 1999. This means that the maximum load that the system can handle without diverging, is the same with or without precedence constraints.  Furthermore, we propose a simple scheme to analyze a special class of schedulers, namely Equi-schedulers, which allows to obtain upper and lower bounds on particular precedences structures, such as independent chains, IN-trees, OUT-trees and Serial-parallel DAGs.	central processing unit;directed acyclic graph;edmonds' algorithm;jack edmonds;job stream;parallel computing;scheduling (computing)	Julien Robert;Nicolas Schabanel	2008			mathematical optimization;combinatorics;real-time computing;mathematics;distributed computing;upper and lower bounds	Theory	15.540038207237371	11.682681879737565	28247
de41745a321c5103db5b88c6a246690265aeda54	classification of ca rules targeting synthesis of reversible cellular automata	synthese par regle;temps lineaire;1 dimensional;tiempo lineal;classification;sintesis por regla;automate cellulaire;linear time;rule synthesis;cellular automata;cellular automaton;clasificacion;automata celular	This paper reports classification of CA (cellular automata) rules targeting efficient synthesis of reversible cellular automata. An analytical framework is developed to explore the properties of CA rules for 3-neighborhood 1-dimensional CA. It is found that in two-state 3neighborhood CA, the CA rules fall into 6 groups depending on their potential to form reversible CA. The proposed classification of CA rules enables synthesis of reversible CA in linear time.	automata theory;reversible cellular automaton;time complexity	Sukanta Das;Biplab K. Sikdar	2006		10.1007/11861201_11	cellular automaton;time complexity;biological classification;computer science;artificial intelligence;one-dimensional space;mathematics;algorithm	ML	-3.849555764300249	23.4990447754076	28272
6d078197a61b867e495a4b4f6ecd32bad2e64860	an almost optimal pac algorithm		The best currently known general lower and upper bounds on the number of labeled examples needed for learning a concept class in the PAC framework (the realizable case) do not perfectly match: they leave a gap of order log(1/ ) (resp. a gap which is logarithmic in another one of the relevant parameters). It is an unresolved question whether there exists an “optimal PAC algorithm” which establishes a general upper bound with precisely the same order of magnitude as the general lower bound. According to a result of Auer and Ortner (2007), there is no way for showing that arbitrary consistent algorithms are optimal because they can provably differ from optimality by factor log(1/ ). In contrast to this result, we show that every consistent algorithm L (even a provably suboptimal one) induces a family (LK)K≥1 of PAC algorithms (with 2K − 1 calls of L as a subroutine) which come very close to optimality: the number of labeled examples needed by LK exceeds the general lower bound only by factor `K(1/ ) where `K denotes (a truncated version of) the K-times iterated logarithm. Moreover, LK is applicable to any concept class C of finite VC-dimension and it can be implemented efficiently whenever the consistency problem for C is feasible. We show furthermore that, for every consistent algorithm L, L2 is an optimal PAC algorithm for precisely the same concept classes which were used by Auer and Ortner (2007) for showing the existence of suboptimal consistent algorithms. This can be seen as an indication that LK may have an even better performance than it is suggested by our worstcase analysis.	algorithm;concept class;consistency model;iteration;mathematical optimization;probably approximately correct learning;requirements analysis;subroutine;vc dimension	Hans Ulrich Simon	2015			combinatorics;discrete mathematics;mathematics;algorithm	Theory	14.57239898158372	19.936619967272293	28344
08335fa95b69bf8dbb1868f25de2e276e62b7dd6	scheduling two-machine flow shops with exact delays	total completion time;approximation algorithm;exact delay;makespan;np hard;flow shop	We consider two-machine flow shop problems with exact delays. In this model, there are two machines, the upstream machine and the downstream machine. Each job j has two operations: the first operation has to be processed on the upstream machine and the second operation has to be processed on the downstream machine, subject to the constraint that the time interval between the completion time of the first operation and the start time of the second operation is exactly lj. We concentrate on the objectives of makespan and total completion time. For the makespan objective, we first show that the problem is strongly NP-hard even if there are only two possible delay values. We then show that some special cases of the problem are solvable in polynomial time. Finally, we design efficient approximation algorithms for the general case and some special cases. For the total completion time objective, we give optimal polynomial-time algorithm for a special case and an efficient approximation algorithm for another one.	approximation algorithm;decision problem;downstream (software development);makespan;np-hardness;polynomial;scheduling (computing);strong np-completeness;time complexity	Joseph Y.-T. Leung;Haibing Li;Hairong Zhao	2007	Int. J. Found. Comput. Sci.	10.1142/S0129054107004711	mathematical optimization;real-time computing;flow shop scheduling;computer science;np-hard;mathematics;approximation algorithm	Theory	15.665900626805872	9.39841446786328	28347
2e06a5050fc6ed338bf0eaa1d92e928fbcbbf31c	handling load with less stress	performance measure;sojourn time;heavy tailed distributions;queue length;shortest job first;buffer overflow;m g 1 queue;queueing system;heavy traffic;large deviations;average solourn time;heavy tailed distribution;m g 1 queues;large deviation	We study how the average performance of a system degrades as the load nears its peak capacity. We restrict our attention to the performance measures of average sojourn time and the large deviation rates of buffer overflow probabilities. We first show that for certain queueing systems, the average sojourn time of requests depends much more weakly on the load ρ than the commonly observed 1/(1 − ρ) dependence for most queueing policies. For example, we show that for an M/G/1 system under the preemptive Shortest Job First (pSJF) policy, the average sojourn time varies as log(1/(1 − ρ)) with load for a certain class of distributions. We observe that such results hold even for more restricted policies. We give some examples of non-preemptive policies and policies that do not use the knowledge of job sizes while scheduling, where the dependence of average sojourn time on load is significantly better than 1/(1 − ρ). Similar results hold even for very simple non-preemptive threshold based policies that partition all the jobs into two job classes based on a fixed threshold and do FIFO within each class. Finally we study the large deviations rate of the queue length under a simple dedicated partition-based policy.	best, worst and average case;buffer overflow;ergodic theory;fifo (computing and electronics);job stream;scheduling (computing);shortest job next	Nikhil Bansal;David Gamarnik	2006	Queueing Syst.	10.1007/s11134-006-8218-z	large deviations theory;real-time computing;shortest job next;buffer overflow;heavy-tailed distribution;mathematics;distributed computing;m/g/1 queue;statistics	Metrics	7.270412325040865	11.32567797603245	28406
3b97f79f4297f5b4bfa328ab7b8933bce1f41ca0	expected length of the longest common subsequence for large alphabets	longest common subsequence;informatique theorique;palabra;word;mot;computer theory;informatica teorica	We consider the lengthL of the longest common subsequence of two randomly uniformly and independently chosen character words over ak-ary alphabet. Subadditivity arguments yield thatE [L] /n converges to a constant k . We prove a conjecture of Sankoff and Mainville from the early 1980s claiming that k √ k→ 2 as k→∞.	longest common subsequence problem;randomness	Marcos A. Kiwi;Martin Loebl;Jirí Matousek	2004		10.1007/978-3-540-24698-5_34	arithmetic;combinatorics;longest increasing subsequence;computer science;longest common subsequence problem;word;mathematics;programming language;longest alternating subsequence;algorithm	Theory	10.794708071390568	25.68947380916273	28518
43f47c919cc7b89b159c068db26a3f09e9679537	a polynomial algorithm for recognizing the am-order class	algorithme reconnaissance;directed acyclic graph;grafo aciclico;complexite;am orders;multiprocessor scheduling;recognition algorithm;preemptive scheduling;computational grid;nombre entier;digraph;aplicacion;temps polynomial;multiprocessor;complejidad;arbre ordonne;digrafo;problema np duro;graphe acyclique;polynomial complexity;05c20;complexity;maillage;polynomial;acyclic graph;grid;integer;np hard problem;celdarada;probleme np difficile;rejilla;scheduling;polynomial algorithm;directed graph;polinomio;entero;ordre n;68r10;graphe oriente;polynomial time;algorithme polynomial;grille;orden n;grid pattern;grafo orientado;procesador;task graphs;processeur;multiprocesador;n order;application;polynome;processor;ordonnancement;reglamento;68m20;a m;interval order;tiempo polinomial;multiprocesseur;digraphe	"""Recently new classes of directed, acyclic graphs with n vertices, namely A""""m-orders where m is a larger than 1 integer, have been presented. These classes contain the interval orders, but are incomparable to trees. Here it is shown that the complexity of recognizing the A""""m-order class is O(n^9), hence independent of m. However, recognizing if a graph is in A""""m-orders for all m might be done in O(n^3) time. These classes have an application in the preemptive multiprocessor scheduling problem. This problem is NP-hard if the number of processors is arbitrary but open for a fixed number of processors m. When the task graph is an A""""m-order, the problem is polynomial on m processors. Hence it is interesting to recognize such task graphs in a polynomial, independent of m time, especially when the number of processors is large, for instance on a computation grid."""	algorithm;polynomial	Aziz Moukrim;Eric Sanlaville	2009	Discrete Mathematics	10.1016/j.disc.2008.10.032	combinatorics;discrete mathematics;directed graph;mathematics;multiprocessor scheduling;directed acyclic graph;algorithm	Theory	18.982544222278616	28.160207249701404	28558
6d1e94540c2aa9c7ac5e1798152a53ecea07dad5	toward net-zero carbon manufacturing operations: an onsite renewables solution	demand response;net metering;green energy coefficient;distributed generation;sustainable operations	A growing number of manufacturing firms are striving to achieve eco-friendly operations through onsite wind or solar generation. This paper proposes a zero-carbon power supply model to guide the integration of onsite renewable energy into manufacturing facilities. We intend to address two fundamental questions: (1) Is it costeffective to deploy onsite wind turbines and solar photovoltaics (PVs) systems to achieve net-zero carbon environmental performance? (2) Is the renewable generation system able to meet the electricity demand despite the power intermittency? To answer these questions, we formulate a stochastic optimization model to minimize the levelized cost of onsite renewable energy. The goal is achieved by optimizing the sizing of wind and solar generating units. The proposed energy solution is tested in ten cities around the world under diverse climatic conditions. While PV is still expensive, we conclude that manufacturers could realize zero-carbon emissions at affordable cost provided the local wind speed is above 5 m/s. Journal of the Operational Research Society (2016). doi:10.1057/s41274-016-0014-5	mathematical optimization;power supply;stochastic optimization	Binbin Li;Yu Tian;Fred Chen;Tongdan Jin	2017	JORS	10.1057/s41274-016-0014-5	wind power;operations management;distributed generation	AI	3.7522093640455028	7.328928198746893	28566
06a5c77e56e785542dd8caca807365878ee804ba	impact of climate change on overhead lines operated using dynamic rating in a smart gird	overhead line thermal model climate change overhead line capacity overhead line dynamic ratings smart gird uk power system;smart power grids;probabilistic analysis climate change dynamic rating overhead line;biological system modeling atmospheric modeling power system dynamics data models conductors wind;power overhead lines;climate mitigation;smart power grids climate mitigation power overhead lines	Smart grid technologies which include meteorological sensors provide the possibility to maximize overhead line capacity with the use of dynamic ratings. The benefit of dynamic ratings is significant yet dependent on weather conditions. Given that it is increasingly certain that we are locked into a future where climate change will become significant, it is possible that the advantage of dynamic ratings will be compromised in the future. This paper investigates the impact of climate change on overhead lines operated using dynamic ratings in the UK power system. In the proposed approach, the future weather information of UK is generated from a range of climate models on the basis of a range of emission scenarios. It is then used as the input to an overhead line thermal model to predict overhead line dynamic ratings. The study examines an overhead line located in Slough and a reduction in average ratings of less than 5.52% at different probability levels is shown. This indicates that the dynamic rating will mitigate the impact of climate change in the future when compared against a static rating reduction of 14%.	climate model;overhead (computing);sensor	Xiaolong Hu;Ian Cotton	2013	IEEE PES ISGT Europe 2013	10.1109/ISGTEurope.2013.6695373	simulation;engineering;electrical engineering;operations management	SE	3.7276046251785138	6.500978573752485	28586
e5078733568d09f559dd259b8fe5d415f1440418	tight bounds for the maximum acyclic subgraph problem	maximum degree;subgrafo;grado grafo;temps polynomial;complexite calcul;algorithme;sous graphe;computational complexity;directed graph;cycle graphe;graphe oriente;polynomial time;algorithms;grafo orientado;degre graphe;cycle graph;subgraph;graph degree;regular graph;tiempo polinomial;ciclo diagrama	Ž . Given a directed graph G s V, A , the maximum acyclic subgraph problem is to Ž . find a maximum cardinality subset A9 of the arcs such that G9 s V, A9 is acyclic. In this paper, we present polynomial-time and RNC algorithms which, when given Ž any graph G without two-cycles, find an acyclic subgraph of size at least 1r2 q Ž .. < < Ž . ' V 1r D G A , where D G is the maximum degree of G. This bound is Ž . existentially tight, since there exists a class of graphs without two-cycles for which Ž Ž .. < < ' the largest acyclic subgraph has size at most 1r2 q O 1r D G A . For the Ž . common case of low-degree graphs, our algorithms provide an even better im1 < < provement over the known algorithms that find an acyclic subgraph of size A . 2 For example, for graphs without two-cycles, our algorithms find an acyclic subgraph 2 19 < < Ž . < < Ž . of size at least A when D G s 2 or 3, and A when D G s 4 or 5. For 3 30 Ž . D G s 2, this bound is optimal in the worst case. For 3-regular graphs, we can 13 2 < < < < achieve A , which is slightly better than A . As a consequence of this work, we 18 3 find that all graphs without two-cycles contain large acyclic subgraphs, a fact which was not previously known. The results can also be extended to find large acyclic subgraphs of graphs with two-cycles. Q 1997 Academic Press	algorithm;best, worst and average case;directed acyclic graph;directed graph;feedback arc set;maximum cut;polynomial;time complexity	Bonnie Berger;Peter W. Shor	1997	J. Algorithms	10.1006/jagm.1997.0864	time complexity;combinatorics;discrete mathematics;directed graph;regular graph;cycle graph;subgraph isomorphism problem;mathematics;induced subgraph isomorphism problem;computational complexity theory;algorithm	Theory	22.12598961271704	25.127082612048216	28623
e2c1900eee2fc377c6caf282bc4ed8d34fcfaed6	spanning trees with bounded total excess			file spanning;minimum spanning tree;offset binary	Hikoe Enomoto;Yukichika Ohnishi;Katsuhiro Ota	2011	Ars Comb.		combinatorics;discrete mathematics;mathematics;bounded function;spanning tree	Theory	24.480277096533356	25.964689262531387	28631
f4235744367ba2b5791fcb11fd52db1d7e93febc	computing pathwidth faster than 2n	approximate algorithm;dynamic program;tree decomposition	Computing the Pathwidth of a graph is the problem of finding a tree decomposition of minimum width, where the decomposition tree is a path. It can be easily computed in O∗(2n) time by using dynamic programming over all vertex subsets. For some time now there has been an open problem if there exists an algorithm computing Pathwidth with running time O∗(cn) for c < 2†. In this paper we show that such an algorithm with c = 1.9657 exists, and that there also exists an approximation algorithm and a constant τ such that an opt+ τ approximation can be obtained in O∗(1.89n) time.	additive model;approximation algorithm;dynamic programming;feedback arc set;pspace;pathwidth;polynomial;time complexity;tree decomposition;treewidth	Karol Suchan;Yngve Villanger	2009		10.1007/978-3-642-11269-0_27	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	22.20977400139426	21.55592840592132	28690
9c5d9308f672c341785cfb6d50e94cee594ef8d3	capacity planning of telemedicine network through molecular assembly	molecular assembly;hierarchy;capacity planning;telemedicine;enterprise networks;simulation;real time processing;laboratory tests;traffic flow;optimization problem;general solution;design;optimization;design methodology	In this paper, we have proposed a design methodology based on molecular assembly (MA) to provide capacity planning for the implementation of telemedicine applications within a hospital enterprise network (HEN). We view the HEN as a set of nodes in clinical and non-clinical departments, to be integrated and automated their tasks flow including patient registration, disease diagnosis, laboratory testing, pharmacy, radiology and billing information. We have formulated the capacity planning problem as an optimization problem with an objective to maximize the traffic within the generated clusters, subject to the real-time processing constraint. The clusters are produced by MA for a specific application, whereby MA integrates the nodes in various departments into clusters with traffic as the force of attraction. MA iterates and utilizes the knowledge of previously generated solutions in improvising the traffic flow within the generated clusters. We have carried out experiments on a typical hospital enterprise network comprising of 50 nodes, distributed in various clinical and non-clinical departments. The simulation results for an application-specific scenario demonstrate the feasibility of MA in reducing the traffic at the backbone by synthesizing the single cluster of 50 nodes into 4 clusters by traffic volume and reducing the traffic at the backbone by 45%.	computer cluster;electronic billing;experiment;internet backbone;mathematical optimization;node (computer science);optimization problem;radiology;real-time clock;simulation	Sami J. Habib;Paulvanna Nayaki Marimuthu	2012		10.1145/2345396.2345555	optimization problem;design;real-time computing;simulation;computer science;engineering;traffic flow;mathematics;hierarchy	HPC	8.045467176358041	5.7899126349553365	28692
b69039f7f1d504980ef3238808f8b48f6df89afe	molecular solutions for minimum and exact cover problems in the tile assembly model	parallel computing;exact set cover problem the tile assem;xxxxx;exact set cover problem;the tile assembly model;期刊论文;np complete problem minimum set cover;minimum set cover problem;np complete problem	The tile assembly model is a novel biological computing model where information is encoded in DNA tiles. It is an efficient way to solve NP-complete problems due to its scalability and parallelism. In this paper, we apply the tile assembly model to solve the minimum and exact set cover problems, which are well-known NP-complete problems. To solve the minimum set cover problem, we design a MinSetCover system composed of three parts, i.e., the seed configuration subsystem, the nondeterministic choice subsystem, and the detection subsystem. Moreover, we improve the MinSetCover system and propose a MinExactSetCover system for solving the problem of exact cover by 3-sets. Finally we analyze the computation complexity and perform a simulation experiment to verify the effectiveness and correctness of the proposed systems.	assembly language;boolean satisfiability problem;computation;correctness (computer science);dna computing;dspace;exact cover;experiment;karp's 21 np-complete problems;parallel computing;scalability;set cover problem;simulation;tile-based video game;whole earth 'lectronic link	Xu Zhou;Yantao Zhou;Keqin Li;Ahmed Sallam;Keqin Li	2014	The Journal of Supercomputing	10.1007/s11227-014-1222-x	mathematical optimization;parallel computing;set packing;np-complete;vertex cover;computer science;edge cover	HPC	15.93770511761919	22.125677086308446	28726
04b466c0ee0fb62945103e2454ada087b73a7d36	parallel game tree search on simd machines	program transformation;search trees;load balance;game tree search	We describe an approach to the parallelization of game tree search on SIMD machines. It turns out that the single-instruction restriction of SIMD-machines is not a big obstacle for achieving eeciency. We achieve speedups up to 5850 on a 16K processor MasPar MP-1 if the search trees are suuciently large and if there are no strong move ordering heuristics. To our best knowledge, the largest speedups previously reported (usually on MIMD machines) are more than an order of magnitude smaller.	heuristic (computer science);mimd;maspar;parallel computing;simd;tree traversal	Holger Hopp;Peter Sanders	1995		10.1007/3-540-60321-2_28	optimal binary search tree;red–black tree;parallel computing;game tree;computer science;theoretical computer science;order statistic tree;k-d tree;distributed computing;iterative deepening depth-first search;search tree;monte carlo tree search;ternary search tree;k-d-b-tree;tree traversal;sss*;depth-first search;dichotomic search;search algorithm	NLP	9.33728578463129	31.916838003748026	28797
c552f3eb11a49012712a29ed6c6b42cc06dddde7	water eminence scrutinizing scheme based on zigbee and wireless antenna expertise - a study		Wireless Sensor Network (WSN) is the essential structure of a water eminence monitoring by means of wireless sensor network (WSN) technology. To scrutinize water quality greater than different sites as a synchronized application, an estimable system structural design constituted by spread sensor nodes and a base station is suggested. The nodes and base stations are linked using WSN technology like Zigbee. Base stations are related via Ethernet. Design and execution of a prototype using WSN technology are the exigent work. Data’s are identified by means of dissimilar sensors at the node plane to compute the parameters like pH, turbidity and oxygen quantity is transmitted via WSN to the support station. Information unruffled from the distant location is capable of displayed in diagram set-up as well as it is able to be calculated using dissimilar replication tools at the supporting station. The recent methods have benefits such as null amount carbon emission, low power utilization, more stretchy to put together at distant locations. Keywords—Wireless sensor network, water quality monitoring, Zigbee technology	diagram;isoelastic utility;ph (complexity);piezoelectricity;prototype;sensor	V. Karthikeyan;S. Geethanjali;M. Mekala;T. Deepika	2014	CoRR		embedded system;real-time computing;telecommunications;computer network	Mobile	2.0958567372853536	30.908642805534047	28841
27eb643a1a0408451cb1673f93c97d9339ec101d	optimal collapsing protocol for multiparty pointer jumping	collapsing protocol;number on the forehead model;multiparty communication complexity;total influence;pointer jumping	In this paper, we study the pointer jumping problem under the one-way number-on-the-forehead (NOF) multiparty communication model. This problem is widely considered to be a candidate for proving strong lower bounds under the NOF model, and has applications to proving lower bounds for many other problems. We investigate the maximum communication complexity of collapsing protocols for pointer jumping, where each player sees all layers behind her and only the composition of layers ahead of her. We present a collapsing protocol in which every player communicates at most $n-\frac{1}{2}\log_{2} n+1$ bits, which tightly matches the lower bound of $n-\frac{1}{2}\log_{2} n-2$ given by Brody and Chakrabarti (in Proc. 25th Annual Symposium on Theoretical Aspects of Computer Science (STACS), pp. 145–156, 2008). Actually, in our protocol only three players need to communicate information: the first player sends log2(n+1) bits, the second to last player sends $n-\frac{1}{2}\log_{2} n+1$ bits, and the last player just outputs the answer. A natural question is whether the log2(n+1) bits communicated by the first player is necessary for achieving a low maximum communication complexity. We make progress towards this question by proving that in any collapsing protocol for the 3-player pointer jumping problem, if the first player only sends one bit, then the second player must communicate at least n−2 bits.	communication complexity;computer science;model of computation;one-way function;pointer (computer programming);pointer jumping;randomized algorithm;randomness;stacs;utility functions on indivisible goods	Hongyu Liang	2013	Theory of Computing Systems	10.1007/s00224-013-9476-x	computer science;theoretical computer science;distributed computing;algorithm	Theory	8.836860027594103	24.60894124381656	28855
2609f23364b0611e75d69ac5d311ebe6fcd75f44	empirical hardness models: methodology and a case study on combinatorial auctions	modelizacion;runtime prediction;learning algorithm;modele empirique;algorithmique;methode empirique;empirical analysis;measurement;algorithm analysis;execution time;supervised learning;economic sciences;probleme np complet;metodo empirico;performance;empirical method;venta conjunta;vente groupee ou liee;intelligence artificielle;bundling;algorithme apprentissage;hardness;supervised machine learning;optimisation combinatoire;algorithm portfolios;modelisation;combinatorial problem;ciencias economicas;dureza;probleme combinatoire;problema combinatorio;estudio caso;model building;algorithmics;algoritmica;subasta;bidding;etude cas;empirical model;artificial intelligence;temps execution;design;modelo empirico;problema np completo;analyse algorithme;durete;sciences economiques;enchere;inteligencia artificial;economics;apprentissage supervise;winner determination problem;modeling methodology;learning artificial intelligence;tiempo ejecucion;combinatorial auctions;combinatorial optimization;building model;experimentation;empirical analysis of algorithms;aprendizaje supervisado;algoritmo aprendizaje;modeling;analisis algoritmo;np complete problem;optimizacion combinatoria;apprentissage intelligence artificielle;combinatorial auction	Is it possible to predict how long an algorithm will take to solve a previously-unseen instance of an NP-complete problem? If so, what uses can be found for models that make such predictions? This article provides answers to these questions and evaluates the answers experimentally.  We propose the use of supervised machine learning to build models that predict an algorithm's runtime given a problem instance. We discuss the construction of these models and describe techniques for interpreting them to gain understanding of the characteristics that cause instances to be hard or easy. We also present two applications of our models: building algorithm portfolios that outperform their constituent algorithms, and generating test distributions that emphasize hard problems.  We demonstrate the effectiveness of our techniques in a case study of the combinatorial auction winner determination problem. Our experimental results show that we can build very accurate models of an algorithm's running time, interpret our models, build an algorithm portfolio that strongly outperforms the best single algorithm, and tune a standard benchmark suite to generate much harder problem instances.	algorithm;benchmark (computing);experiment;machine learning;np-completeness;supervised learning;time complexity	Kevin Leyton-Brown;Eugene Nudelman;Yoav Shoham	2009	J. ACM	10.1145/1538902.1538906	mathematical optimization;combinatorial auction;combinatorial optimization;computer science;artificial intelligence;machine learning;mathematics;supervised learning;algorithmics;algorithm	AI	21.825105298010833	6.321099493694189	28864
89e97ae80911d6815c66873e7dc588f345eb5831	three ∑ p 2 -complete problems in computational learning theory	satisfiability;machine learning;pattern language;computational learning theory	The consistency problem associated with a concept classC is to determine, given two setsA andB of examples, whether there exists a conceptc inC such that eachx inA is a positive example ofc and eachy inB is a negative example ofc. We explore in this paper the following intuition: for a concept classC, if the membership problem of determining whether a given example is positive for a concept isNP-complete, then the corresponding consistency problem is likely to be ∑ P 2 -complete. To support this intuition, we prove that the following three consistency problems for concept classes of patterns, graphs and generalized Boolean formulas, whose membership problems are known to beNP-complete, are ∑ P 2 -complete: (a) given two setsA andB of strings, determine whether there exists a patternp such that every string inA is in the languageL(p) and every string inB is not in the languageL(p); (b) given two setsA andB of graphs, determine whether there exists a graphG such that every graph inA is isomorphic to a subgraph ofG and every graph inB is not isomorphic to any subgraph ofG; and (c) given two setsA andB of Boolean formulas, determine whether there exists a 3-CNF Boolean formula θ such that for every ϕ ∈A, θ ∧ ϕ is satisfiable and for every Ψ ∈B, θ ∧ Ψ is not satisfiable. These results suggest that consistendy problems in machine learning are natural candidates for ∑ P 2 -complete problems if the corresponding membership problems are known to beNP-complete. In addition, we prove that the corresponding prediction problems for concept classes of polynomial-time nondeterministic Turing machines, nondeterministic Boolean circuits, generalized Boolean formulas, patterns and graphs are prediction-complete for the classR NP of all concept classes whose membership problems are inNP.	boolean circuit;computational learning theory;conjunctive normal form;emoticon;machine learning;non-deterministic turing machine;polynomial;time complexity	Ker-I Ko;Wen-Guey Tzeng	1991	computational complexity	10.1007/BF01200064	combinatorics;discrete mathematics;computer science;pattern language;mathematics;computational learning theory;algorithm;satisfiability	Theory	7.866133776301675	19.260443534225466	28865
1e55132c0696c119737887969b50db3835a85d64	the complexity of counting locally maximal satisfying assignments of boolean csps	journal article;computational complexity of counting problems;constraint satisfaction problem;approximate computation	We investigate the computational complexity of the problem of counting the locally maximal satisfying assignments of a Constraint Satisfaction Problem (CSP) over the Boolean domain {0, 1}. A satisfying assignment is locally maximal if any new assignment which is obtained from it by changing a 0 to a 1 is unsatisfying. For each constraint language Γ, #LocalMaxCSP(Γ) denotes the problem of counting the locally maximal satisfying assignments, given an input CSP with constraints in Γ. We give a complexity dichotomy for the problem of exactly counting the locally maximal satisfying assignments and a complexity trichotomy for the problem of approximately counting them. Relative to the problem #CSP(Γ), which is the problem of counting all satisfying assignments, the locally maximal version can sometimes be easier but never harder. This finding contrasts with the recent discovery that approximately counting locally maximal independent sets in a bipartite graph is harder (under the usual complexity-theoretic assumptions) than counting all independent sets.	computational complexity theory;constraint satisfaction problem;cryptographic service provider;maximal set	Leslie Ann Goldberg;Mark Jerrum	2016	Theor. Comput. Sci.	10.1016/j.tcs.2016.04.008	mathematical optimization;combinatorics;discrete mathematics;counting problem;#sat;computer science;mathematics;constraint satisfaction problem	Theory	17.755514480040876	18.757102988666635	28870
886629957f2b70ae9a7be2d979553af5a7b96e05	on homomorphic simulation of automata by α0-products			automata theory;automaton;simulation	Pál Dömösi;Zoltán Ésik	1988	Acta Cybern.			Logic	-2.8600238829573597	22.64336084818955	28911
2eca8711cdf12c1c53f1daf8e319c1d13edb93d9	the g/m/1 queue revisited	queuing theory;queueing theory;busy period	The G/M/1 queue is one of the classical models of queueing theory. The goal of this paper is two-fold: (i) To introduce new derivations of some well-known results, and (ii) to present some new results for the G/M/1 queue and its variants. In particular, we pay attention to the G/M/1 queue with a set-up time at the start of each busy period, and the G/M/1 queue with exceptional first service. For Arie Hordijk on his 65-th birthday, in friendship and admiration	nico habermann;queueing theory;uptime	Ivo J. B. F. Adan;Onno J. Boxma;David Perry	2005	Math. Meth. of OR	10.1007/s00186-005-0032-6	m/m/1 queue;m/d/c queue;pollaczek–khinchine formula;real-time computing;simulation;m/m/c queue;m/m/∞ queue;bulk queue;computer science;m/d/1 queue;mathematics;m/g/k queue;kingman's formula;m/g/1 queue;fork–join queue;d/m/1 queue;queueing theory;kendall's notation;burke's theorem;g/g/1 queue;statistics	Metrics	8.668284816388086	11.577534478052591	28914
fb3fd9ebb1daf602fc3bbae9acf124ebae1a6263	investigations of fault-tolerant networks of computers (preliminary version)	fault tolerant	St(p,t+l) = Tranr(.9(V,(P),f), ’ . . Sf(v,(p:,t)) where Tram : Qd +Q is the transition function. Such objects are called celhhr spaces, tessalations, iterative arrays of finite automata, systolic arrays, or networks of computers. They have been extensively studied [vN] [HI IK] [‘E!) as they are a natural model of parallel universal computers, and of many physical and biologicxl phenomena. We will examine the cluestion of how to make such networks resistant to errors. ’ Supported in part by National Science Foundation ~;rants DCR 8407256. CCR 87-10078. CCR 8746518, and by AFOSR c’ontract 8704co	algorithm;automata theory;cellular automaton;central processing unit;clock synchronization;computation;conway's game of life;display resolution;elegant degradation;ergodicity;finite-state machine;forward kinematics;graceful exit;iterative method;john reif;journal of computer and system sciences;jumper (computing);multidimensional system;podc;real-time transcription;shannon (unit);simulation;sparse matrix;symposium on theory of computing;systolic array;the circle (file system);toom's rule;very-large-scale integration	Piotr Berman;Janos Simon	1988		10.1145/62212.62219	fault tolerance;computer science;mathematics	Theory	3.7891944331055423	26.49085372354566	28980
dbab48583b60972122135e533be0198a85923d63	a new cloud computing method for establishing asymmetric cycle time intervals in a wafer fabrication factory	wafer fabrication;forecasting;cycle time;bound;asymmetric;back propagation network bpn;cloud computing	Estimating the cycle time of each job in a wafer fabrication factory is critical. An equally critical problem is to estimate the range of a cycle time. This topic has rarely been discussed because most existing methods for range calculation establish only a symmetric range. However, a symmetric range does not meet the requirements of managerial applications based on the lower and upper bounds of a cycle time. Recently, a few researchers have attempted to establish the asymmetric bounds of a cycle time. However, these methods either have overly complex computations or do not consistently perform well. This study proposes a new approach for effective cycle-time bounding. First, construction of a back propagation network predicts the cycle time of a job. Second, two linear functions of the output are formed, and the threshold on the output node is fuzzified to derive the lower and upper bounds of the cycle time. In theory, such a treatment tightens the lower and upper bounds and improves the forecasting precision. Third, theorems for the feasibility of the two linear functions are proved. Fourth, a cloud computing scheme is proposed to improve the bounds in an effective manner. Finally, a real case illustrates the applicability of the proposed methodology. Experimental results show that this methodology narrows the range of cycle times for untrained data by 31%, while maintaining a considerably high hit rate of 92.5%.	backpropagation;business process network;cloud computing;computation;efx factory;entity–relationship model;linear function;magnetic-core memory;nonlinear system;parallel computing;requirement;scheduling (computing);software factory;software propagation;wafer fabrication	Toly Chen;Hsin-Chieh Wu	2017	J. Intelligent Manufacturing	10.1007/s10845-015-1052-6	wafer fabrication;mathematical optimization;real-time computing;simulation;cloud computing;forecasting;cycle time variation;computer science;engineering;artificial intelligence;machine learning;mathematics;asymmetric warfare;statistics	HPC	12.737665442668233	7.498298599465235	29012
9d50d086bc61c6b316b1fc888143fe835cb6819e	the phase transition behaviour of non-binary forward checking algorithms		In this paper the phase transition, that is to say the transition from a region in which almost all problems have many solutions to a region in which almost all problems have no solution as the constraints become tighter, is investigated by examining n-ary Constraint Satisfaction Problems (CSPs). The paper reports a series of experiments with samples of randomly-generated problems, using a family of non-binary Forward Checking algorithms. We observe the behaviour of these algorithms with respect to the phase transition properties of n-ary Constraint Satisfaction Problems (CSPs). An n-ary random problem has an arity for the constraints, a number of variables, a uniform domain size, connectivity, and tightness of constraints. It was observed that for a problem with a given arity, number of variables, domain size, and connectivity there is a critical level of constraint tightness at which a phase transition occurs, such that the problems change from being soluble to insoluble. At the phase transition the search effort becomes orders of magnitude harder than elsewhere. It is shown that the location of the really hard problems can be predicted with a reasonable degree of accuracy. The accuracy of prediction based on the expected number of solutions is discussed. MOTS-CLÉS : Transition de phase, satisfaction de contraintes	algorithm;constraint satisfaction;experiment;look-ahead (backtracking);randomness	Mihaela Butaru;Zineb Habbas	2008	Stud. Inform. Univ.		phase transition;artificial intelligence;pattern recognition;look-ahead;computer science;theoretical computer science;binary number	AI	11.651066544908959	18.077936476194374	29023
2367cf1811b70a21eeacd111384c6c1218012493	comparing universal covers in polynomial time	distributed computing;universal cover;connected graph;polynomial time algorithm;degree matrix;graph homomorphism;computational complexity;polynomial time;linear program	The universal cover T G of a connected graph G is the unique (possibly infinite) tree covering G, i.e., that allows a locally bijective homomorphism from T G to G. It is well-known that if a graph G covers a graph H, then their universal covers are isomorphic, and that the latter can be tested in polynomial time by checking if G and H share the same degree refinement matrix. We extend this result to locally injective and locally surjective homomorphisms by following a very different approach. Using linear programming techniques we design two polynomial time algorithms that check if there exists a locally injective or a locally surjective homomorphism, respectively, from a universal cover T G to a universal cover T H (both given by their degree matrices). This way we obtain two heuristics for testing the corresponding locally constrained graph homomorphisms. Our algorithm can also be used for testing (subgraph) isomorphism between universal covers, and for checking if there exists a locally injective or locally surjective homomorphism (role assignment) from a given tree to an arbitrary graph H.	algorithm;assignment problem;connectivity (graph theory);covering space;cycle (graph theory);decision problem;degree matrix;existential quantification;graph (discrete mathematics);heuristic (computer science);linear programming;polynomial;refinement (computing);subgraph isomorphism problem;time complexity;tree (data structure)	Jirí Fiala;Daniël Paulusma	2009	Theory of Computing Systems	10.1007/s00224-009-9200-z	time complexity;graph power;integral graph;combinatorics;discrete mathematics;universal graph;topology;degree matrix;covering space;computer science;linear programming;connectivity;edge cover;mathematics;voltage graph;tutte polynomial;graph algebra;graph homomorphism;computational complexity theory;complement graph;algorithm;string graph	Theory	23.777763753103496	24.671192147129936	29047
707411dac82fcb89e129653ebb8ecaf739e245fe	the equivalence of solving queries and production tree projections.	polynomial time algorithm	Suppose a database schema D is extended to ]5 by adding new relation schemes, and states for D are extended to states for B by applying joins and projections to existing relations. It is shown that certain desirable properties that D has with respect to D are equivalent to the existence of a tree projection of 6 with respect to D. These properties amount to the ability to efficiently compute the join of all the relations in a state for D from an extension of this state over D’. The equivalence is proved for unrestricted (i.e., both finite and infinite) databases. If 6 is obtained from D by adding a set of new relation schemas that form a tree schema, then the equivalence also holds for finite databases. In this case there is also a polynomial time algorithm for testing the existence of a tree projection of a with respect to D. ‘On leave of absence from Hebrew University, Jerusalem, Israel. Work partially supported by NSF grant IST-84-12791, a grant of AT&T Foundation, and ‘a grant of IBM Corp. Permission to capy without fee 811 or prrt of this material is gantcd pm&Jcd that the copies are not made or distributed for direct commwckl rdvan@@A lk ACM copyrifil notice and the titk of the publication 8d its d8te rppmr, 8nd notice is given th8l copying is by prmksion of Ihe Association for Computing Machinery. To copy olhwisc, or to republish, N+m 8 fee 8nd/or SpCCific pcmkion.	algorithm;database schema;ibm notes;p (complexity);turing completeness	Yehoshua Sagiv;Oded Shmueli	1985		10.1145/6012.15413	mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics	DB	13.665683984121394	21.35273744260444	29103
234544bad3d310f0b98024c7ec2b54bf04c70af9	smart microgrids: overview and outlook		The idea of changing our energy system from a hierarchical design into a set of nearly independent microgrids becomes feasible with the availability of small renewable energy generators. The smart microgrid concept comes with several challenges in research and engineering targeting load balancing, pricing, consumer integration and home automation. In this paper we first provide an overview on these challenges and present approaches that target the problems identified. While there exist promising algorithms for the particular field, we see a missing integration which specifically targets smart microgrids. Therefore, we propose an architecture that integrates the presented approaches and defines interfaces between the identified components such as generators, storage, smart and “dumb” devices.	algorithm;energy systems language;existential quantification;home automation;load balancing (computing);microgrid;microsoft outlook for mac;smart tv	Anita Sobe;Wilfried Elmenreich	2013	CoRR		simulation;engineering;computer security	EDA	1.1319727735536609	7.242251211820525	29133
c0410c97644f304e143bd108e581c7898d1bfec8	improving data-center efficiency for a smarter planet	data center;information technology data systems data warehouses modular constructoin strategic planning	"""In 2009, IBM launched its Smarter Planet™ initiative, which is based on the paradigm that virtually any physical object, process, or system can be instrumented, interconnected, and infused with intelligence. Because of the increased demand for information technology (IT) to facilitate Smarter Planet solutions, physical data centers have become interconnected, instrumented, and intelligent (i.e., adaptable, scalable, energy efficient, and cost effective). """"Green data centers,"""" which are discussed in this paper, are those that make use of facilities and IT integration, resulting in lower energy costs, reduced carbon footprint, and reduced demand for power, space, and cooling resources. This paper reviews energy-efficiency strategies that are being incorporated in eight million square feet of data-center space that IBM operates in support of its customers. These strategies include both a dynamic infrastructure IT initiative and an energy-efficiencies pillar of the IBM New Enterprise Data Center initiative. For example, compared to nonmodular designs, implementation of a modular design to optimize expandable data centers will better match the IT demand with the data-center energy supply. This high-level overview describes the integration of these strategies to create a class of leading-edge IBM data centers and a plan for the optimization of existing data centers."""	data center;smarter planet	Chris Molloy;Mickey Iqbal	2010	IBM Journal of Research and Development	10.1147/JRD.2010.2050539	data center;simulation;computer science;systems engineering;engineering;electrical engineering;operating system	OS	2.260086630393424	9.22281796254101	29135
0ef45ac9cafdb1c8115fbabdf9311b0c5c313c05	optimal time-space trade-offs for sorting	sorting;upper bounds;sorting upper bound chromium computer science time measurement extraterrestrial measurements postal services;comparison based;time space;upper bound;comparison based models optimal time space trade offs sorting sequential model lower bound logarithmic factor upper bound time space product;sorting computational complexity;computational complexity;uct;power generation;model of computation;sorting algorithm;trade off;lower bound	We study the fundamental problem of sorting in a sequential model of computation and in particular consider the time-space trade-off (product of time and space) for this problem. Beame has shown a lower bound of Ω(n2) for this product leaving a gap of a logarithmic factor up to the previously best known upper bound of O(n2 log n) due to Frederickson. Since then, no progress has been made towards tightening this gap. The main contribution of this paper is a comparison based sorting algorithm which closes this gap by meeting the lower bound of Beame. The time-space product O(n2) upper bound holds for the full range of space bounds between log n and n/ log n. Hence in this range our algorithm is optimal for comparison based models as well as for the very powerful general models considered by Beame. ∗Supported by the ESPRIT Long Term Research Programme of the EU under project number 20244 (ALCOM-IT). E-mail: {pagter,theis}@brics.dk. †Part of this work was done while the author was visiting the Fields Institute, Toronto, Canada. ‡Basic Research in Computer Science, Centre of the Danish National Research Foundation.	computer science;model of computation;sorting algorithm	Jakob Illeborg Pagter;Theis Rauhe	1998		10.1109/SFCS.1998.743455	mathematical optimization;combinatorics;computer science;mathematics;upper and lower bounds;algorithm	Theory	12.546140019624195	21.91994602140913	29149
cc60466c18832c0e162c6c80703a720e54a96caa	applications of smart grid technologies on power distribution systems	power distribution system;distributed energy resources;distributed system;environmental factors;optimisation;new technology;distribution systems;distribution automation;distribution automation smart grid distribution systems distributed energy resources plug in electric vehicles;information technology;power distribution control;distribution system optimization power distribution systems smart grid technologies economic factors political factors environmental factors social factors technical factors power delivery infrastructures empowering customers distributed energy resources plug in electric vehicles distribution automation;smart grid;power distribution;indexes;smart grids;smart power grids;smart grids energy resources electric vehicles power distribution automation information technology indexes;energy resources;indexation;plug in electric vehicles;electric vehicles;power distribution economics;distributed energy resource;electric vehicle;new products;smart power grids electric vehicles environmental factors optimisation power distribution control power distribution economics;automation	Economic, political, environmental, social and technical factors have prompted the emergence of the smart grid concept. Distribution systems are arguably the element of power delivery infrastructures where smart grid technologies are likely to have the most significant impacts. The smart grid concept has driven the coordinated and integrated application of existing power, communications, control, and information technologies at distribution system level. Furthermore, it has impelled the development and implementation of new technologies, tools and approaches for optimizing the operation of distribution systems, empowering customers, and creating new products and services. Expectedly, all these factors have also contributed to the emergence of new issues and challenges. The objective of this panel is to discuss and present novel applications of smart grid technologies on power distribution systems including integration of distributed energy resources, plug-in electric vehicles, distribution automation, and distribution system optimization.	emergence;mathematical optimization;plug-in (computing);program optimization	Julio Romero Aguero	2012	2012 IEEE PES Innovative Smart Grid Technologies (ISGT)	10.1109/ISGT.2012.6175536	embedded system;electronic engineering;engineering;operations management;smart grid;internet of things	HPC	1.4156599473087121	7.289885753676905	29171
eb1d17499d09a26bceeb2f4c208c0f5c8c878615	design and optimization of a grid connected residential pv-system with battery energy storage system		This paper studies a single-phase bidirectional grid tied inverter connected to a common DC-bus, together with a photovoltaic installation and a battery energy storage system. The design of this system and its control mechanisms are discussed. Appropriate components are determined and the system is implemented in the SIMULINK environment. The DC-link voltage is controlled by the battery which leaves the reference current provided to the inverter undetermined. This free parameter leaves room for optimization purposes. In this work an optimization for the electricity price is studied as nowadays variable price contracts and even spot price tied contracts are available on the energy market. Consumers could benefit of these types of contract when making use of a battery energy storage system. The results of this optimization and a full economic analysis of the system conclude this work. The full analysis furthermore discusses an optimal sized battery and inverter for given input parameters of the system. Finally a sensitivity analysis is carried out to study the effects of these parameters.		Tom Crauwels;Mauricio Dalla Vecchia;Simon Ravyts;Johan Driesen	2018	IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2018.8592722		EDA	3.682598065336689	6.186460026705353	29204
9a0d14f06d93448862b63ffcbffb947b12e5e729	reducing the computational complexity of scheduling problems in petri nets by means of transformation rules	optimal solution;concurrent computing;job shop scheduling;computational complexity processor scheduling petri nets optimal scheduling job shop scheduling sections dynamic scheduling concurrent computing resource management control system synthesis;processor scheduling;discrete event dynamic system;resource management;sections;discrete events dynamic systems;time petri net;computational complexity;optimal scheduling;control system synthesis;scheduling;np hard problems;scheduling problem;transformation rules;petri nets;petri net;scheduling problems;np hard problems scheduling problems petri nets transformation rules discrete events dynamic systems;scheduling computational complexity petri nets;dynamic scheduling	Scheduling problems are very important in order to optimise the behaviour of discrete events dynamic systems. Nevertheless, the computation of scheduling policies turns out to be NP-hard in most interesting cases in practice. The purpose of the paper is to apply transformation/reduction rules to the solution of the scheduling problem. These kind of rules have already been applied to the analysis of autonomous Petri nets or to program coding optimisation by means of time Petri nets. Here, reduction is intended to preserve the existence of at least one optimal solution for the scheduling problem. In many practical cases, transformation/reduction allows us to alleviate the computational problem of synthesising an optimal schedule. We show its usefulness by means of an illustrative example.	computational complexity theory;petri net;scheduling (computing)	J. C. Mugarza;Hervé Camus;Jean-Claude Gentina;Enrique Teruel;Manuel Silva Suárez	1998		10.1109/ICSMC.1998.725377	job shop scheduling;real-time computing;dynamic priority scheduling;computer science;theoretical computer science;two-level scheduling;distributed computing;petri net	AI	11.138835012365162	6.939184467283369	29209
340774d21fb565da4a9081ac0d23909655f412d9	nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems	graph sparsification;linear time algorithm;linear system;preconditioners;numerical analysis;graph partitioning;condition number;data structure	We present algorithms for solving symmetric, diagonally-dominant linear systems to accuracy ε in time linear in their number of non-zeros and log (κf (A) ε), where κf (A) is the condition number of the matrix defining the linear system. Our algorithm applies the preconditioned Chebyshev iteration with preconditioners designed using nearly-linear time algorithms for graph sparsification and graph partitioning.	algorithm;chebyshev iteration;condition number;diagonally dominant matrix;graph partition;linear system;preconditioner;the matrix;time complexity	Daniel A. Spielman;Shang-Hua Teng	2004		10.1145/1007352.1007372	spqr tree;graph power;mathematical optimization;factor-critical graph;combinatorics;discrete mathematics;graph bandwidth;data structure;null graph;numerical analysis;computer science;regular graph;graph partition;clique-width;distance-regular graph;simplex graph;condition number;mathematics;voltage graph;linear system;programming language;butterfly graph;quartic graph;line graph;algorithm;strength of a graph;adjacency matrix	Theory	20.12992029084021	30.47052606175505	29219
5faac14089fdf7bf065078427a9a2e3a64dafdd3	maximum multicommodity flows over time without intermediate storage	multicommodity flow;fptas;network flow;flow over time	Flows over time generalize classical “static” network flows by introducing a temporal dimension. They can thus be used to model non-instantaneous travel times for flow and variation of flow values over time, both of which are crucial characteristics in many real-world routing problems. There exist two different models of flows over time with respect to flow conservation: one where flow might be stored temporarily at intermediate nodes and a stricter model where flow entering an intermediate node must instantaneously progress to the next arc. While the first model is in general easier to handle, the second model is often more realistic since in applications like, e. g., road traffic, storage of flow at intermediate nodes is undesired or even prohibited. The main contribution of this paper is a fully polynomial time approximation scheme (FPTAS) for (min-cost) multi-commodity flows over time without intermediate storage. This improves upon the best previously known (2+ε)-approximation algorithm presented 10 years ago by Fleischer and Skutella (IPCO 2002).		Martin Groß;Martin Skutella	2012		10.1007/978-3-642-33090-2_47	mathematical optimization;flow network;simulation;multi-commodity flow problem;computer science;mathematics;algorithm	Theory	11.095011817964924	8.527409446426178	29243
7384294d285b681fd7b5c4bcbde9b849bab08bd6	relative to a random oracle, p/poly is not measurable in exp	pseudo random generator;algorithm complexity;complejidad algoritmo;computability;randomised algorithms;algorithme randomise;complexite algorithme;complexity class;computational complexity;calculabilite;random oracle;calculabilidad	Abstract It is shown that, with respect to a random oracle, EXP ∩ P/poly and EXP — P/poly do not have resource-bounded measure zero in EXP.	exptime;p/poly;random oracle;resource bounded measure	Marius Zimand	1999	Inf. Process. Lett.	10.1016/S0020-0190(98)00197-5	random oracle;complexity class;combinatorics;discrete mathematics;computer science;mathematics;pseudorandom generator;computability;computational complexity theory;algorithm	Crypto	6.831075443427773	22.32533247724938	29246
38205b3a35b92431bafe7280175ff5e52d03eb1a	one-dimensional bounded cellular acceptor with rotated inputs. a relationship between ∧ and ∨ types	theorie automate;automata aceptor;acceptor automaton;informatique theorique;automate cellulaire;automata theory;teoria automata;automate accepteur;cellular automaton;computer theory;automata celular;informatica teorica	Abstract#R##N##R##N#The authors previously introduced the following two-dimensional automaton, and made several discussions on its accepting power. The input two-dimensional tape is rotated by 90, 180 or 270 deg in clockwise direction. The rotated results are scanned by one-dimensional bounded cellular acceptors. The results of scanning are combined by product (∧) or sum (∨), to make the decision regarding the final acceptance. The purpose of this paper is to discuss further details of the accepting power of such an automaton. In the first-half of this paper, the situation is assumed where the rotated inputs are scanned by the deterministic one-dimensional bounded cellular acceptors. A discussion is made on the relation between the accepting powers when the results of the scanning are combined only by product or only by sum. It is shown that the families of sets accepted by the product or the sum type are always incomparable. In the second half of the paper, the relation between the accepting powers of the following two automata are described. One is the automaton obtained by combining the one-dimensional bounded cellular acceptors by sum (or product); the other is the automaton obtained by combining one-way parallel sequential array acceptors by sum (or product).	acceptor (semiconductors)	Hiroshi Taniguchi;Katsushi Inoue;Itsuo Takanami	1989	Systems and Computers in Japan	10.1002/scj.4690200301	cellular automaton;reversible cellular automaton;block cellular automaton;nested stack automaton;büchi automaton;elementary cellular automaton;computer science;electrical engineering;artificial intelligence;theoretical computer science;two-way deterministic finite automaton;continuous automaton;deterministic automaton;automata theory;ω-automaton;mathematics;geometry;linear bounded automaton;mobile automaton;timed automaton;pushdown automaton;algorithm	Robotics	-0.2621560555659778	22.121851287192232	29265
cbec62937cff66f139575959edc1fc10f01250e0	from determinism, non-determinism and alternation to recursion schemes for p, np and pspace (invited talk)	004;computational complexity recursion schemes p np pspace	Our goal is to approach the classes of computational complexity P, NP, and Pspace in a recursiontheoretic manner. Here we emphasize the connection between the structure of the recursion schemes and the underlying models of computation. 1998 ACM Subject Classification F.4.1 Mathematical Logic, F.1.1 Models of Computation, F.1.2 Modes of Computation, F.1.3 Complexity Measures and Classes	computational complexity theory;model of computation;np (complexity);nondeterministic algorithm;p (complexity);pspace;recursion	Isabel Oitavem	2013		10.4230/LIPIcs.CSL.2013.24	combinatorics;discrete mathematics;computer science;mathematics;algorithm	Theory	-4.324930615117202	24.04792729597087	29270
fc192a15d0997dcff6264751d43b0128cd969b0d	orientable edge colorings of graphs	algorithme reconnaissance;edge coloring;optimisation;coloracion grafo;forbidden substructure;recognition algorithm;closure;combinatorics;digraph;optimizacion;combinatoria;color;ramsey theory;canonical theory;reconocimiento;combinatoire;digrafo;algorithme temps lineaire;05c20;subestructura;orientation;recognition;coloration graphe;informatique theorique;directed graph;linear time;68r10;graphe oriente;sous structure;edge graph;substructure;arete graphe;couleur;grafo orientado;optimization;theorie ramsey;cerradura;58a25;teoria canonica;reconnaissance;theorie canonique;arista grafico;fermeture;orientation acyclique;graph colouring;computer theory;graphe colore;informatica teorica;digraphe;05c15	An edge coloring of a graph is orientable if and only if it is possible to orient the edges of the graph so that the color of each edge is determined by the head of its corresponding oriented arc. The goals of this paper include finding a forbidden substructure characterization of orientable colorings and giving a linear time recognition algorithm for orientable colorings. An edge coloring is lexical if and only if it is possible to number the vertices of the graph so that the color of each edge is determined by its lower endpoint. Lexical colorings are, of course, the orientable colorings in which the underlying orientation is acyclic. Lexical colorings play an important role in Canonical Ramsey theory, and it is this standpoint that motivates the current study.		Robert E. Jamison	2011	Discrete Applied Mathematics	10.1016/j.dam.2010.05.010	gallai–hasse–roy–vitaver theorem;combinatorics;discrete mathematics;directed graph;topology;mathematics;greedy coloring;algorithm	Theory	22.617836721113346	28.524670786382217	29301
3f302dc8088b6162afe544074071cfcae4def04b	a hybrid lagrangean heuristic with grasp and path-relinking for set k-covering	hybrid heuristics;metaheuristics;set k covering;lagrangean relaxation;path relinking;set multicovering;grasp;set covering;local search;lagrangean heuristics	The set k-covering problem is an extension of the set covering problem, in which each object has to be covered at least k times. We describe a GRASP with path-relinking heuristic for its solution, as well as the template of a family of Lagrangean heuristics. The hybrid GRASP Lagrangean heuristic employs the GRASP with path-relinking heuristic using modified costs to obtain solutions for the Lagrangean relaxation problem. Numerical experiments have shown that the Lagrangean heuristics performed consistently better than GRASP. The GRASP Lagrangean heuristic makes better use of the dual information provided by subgradient optimization and is able to discover better solutions even after the stabilization of the lower bounds.	covering problems;experiment;grasp;heuristic (computer science);linear programming relaxation;mathematical optimization;set cover problem;subderivative;subgradient method	Luciana S. Pessoa;Mauricio G. C. Resende;Celso C. Ribeiro	2013	Computers & OR	10.1016/j.cor.2011.11.018	mathematical optimization;combinatorics;computer science;local search;grasp;mathematics;algorithm;metaheuristic	Robotics	23.96501932575803	5.752648371951044	29302
b2e1cb0fc10af6fdefb8efdb9412a5a2533564c8	using exit time predictions to optimize self automated parking lots	software;vehicles layout predictive models cities and towns protocols estimation;cooperation;government funding;dissertacao;smart parking;blocked cars exit time predictions self automated parking lot prediction private car commuting available free parking public funding policy meter charged parking areas car transportation sustainability collaborative mobility parked cars;parking facilities;sustainable development road traffic control;ciencias da engenharia e tecnologias;parking meters	Private car commuting is heavily dependent on the subsidisation that exists in the form of available free parking. However, the public funding policy of such free parking has been changing over the last years, with a substantial increase of meter-charged parking areas in many cities. To help to increase the sustainability of car transportation, a novel concept of a self-automated parking lot has been recently proposed, which leverages on a collaborative mobility of parked cars to achieve the goal of parking twice as many cars in the same area, as compared to a conventional parking lot. This concept, known as self-automated parking lots, can be improved if a reasonable prediction of the exit time of each car that enters the parking lot is used to try to optimize its initial placement, in order to reduce the mobility necessary to extract blocked cars. In this paper we show that the exit time prediction can be done with a relatively small error, and that this prediction can be used to reduce the collaborative mobility in a self-automated parking lot.	multi-storey car park	Rafael Nunes;Luís Moreira-Matias;Michel Ferreira	2014	17th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2014.6957708	simulation;engineering;operations management;parking guidance and information;transport engineering	Robotics	5.335721060829575	7.805053106678542	29367
f0c739c4b31a013e8a103d746413f2fa48dfbf21	conceptual framework for a multi-building peak load management system	load management;optimization;lighting;load modeling;user interfaces;buildings	A building energy management (BEM) system serves as the key element of a smart building. It facilitates grid interaction and participation of a building in a demand response (DR) program. Typically, a BEM has been designed to manage loads in a single building. However, in reality, a number of adjacently located buildings can be owned by a single entity, like a campus. In this case, during DR events, instead of optimized control of loads in a single building, the coordinated control of loads in multiple buildings should be conducted to ensure the best operation condition for the entire facility. This paper proposes a conceptual framework to coordinate the operation of loads in multiple buildings, thereby reducing the peak demand of the entire facility during a DR event while minimizing occupant discomfort. Simulation results indicate that the proposed framework for coordinated control of multiple buildings results in less occupant discomfort than controlling loads in each building individually.	boundary element method;load management;load profile;simulation	Xiangyu Zhang;Manisa Pipattanasomporn;Murat Kuzlu;Saifur Rahman Bradley	2016	2016 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)	10.1109/ISGTEurope.2016.7856238	structural engineering;simulation;engineering;operations management	Visualization	3.257062721735575	5.841290673284285	29375
4d421a7d30221f1f2debf8be707551785de492af	#bis-hardness for 2-spin systems on bipartite bounded degree graphs in the tree non-uniqueness region	complexity;journal article;phase transition;bis hardness;spin systems;approximate counting	Counting independent sets on bipartite graphs (#BIS) is considered a canonical counting problem of intermediate approximation complexity. It is conjectured that #BIS neither has an FPRAS nor is as hard as #Sat to approximate. We study #BIS in the general framework of two-state spin systems on bipartite graphs. We define two notions, nearly-independent phase-correlated spins and unary symmetry breaking. We prove that it is #BIS-hard to approximate the partition function of any 2-spin system on bipartite graphs supporting these two notions. As a consequence, we classify the complexity of approximating the partition function of antiferromagnetic 2-spin systems on bounded-degree bipartite graphs.	antiferromagnetism;approximation algorithm;counting problem (complexity);partition function (mathematics);polynomial-time approximation scheme;symmetry breaking;unary operation	Jin-Yi Cai;Andreas Galanis;Leslie Ann Goldberg;Heng Guo;Mark Jerrum;Daniel Stefankovic;Eric Vigoda	2016	J. Comput. Syst. Sci.	10.1016/j.jcss.2015.11.009	phase transition;complete bipartite graph;combinatorics;discrete mathematics;complexity;#p-complete;#sat;computer science;mathematics;algorithm	Theory	21.1893074551409	22.892313618212953	29400
931795dfcabcfe615e918fb618c9bea7dba24685	a hybrid approach based on genetic algorithms and (max, +) algebra for network applications	system modeling;max algebra;artificial intelligence;genetic algorithms;flow networks	The following work addresses the problem of scheduling operations on a flow network, as well as alignment (path) allocation. This is a multi-objective problem, and this paper proposes a solution method through a hybrid approach based on a genetic algorithm in conjunction with (max, +) algebra. A concise system abstraction is proposed through a non-linear (max, +) model. This model describes the main optimization constraints which dictate the behavior of the mutation and crossover operations in the genetic algorithm. Additionally, each individual in the population represents the value assignment of the decision variables, which linearizes the (max, +) model. A hierarchic genetic structure is proposed for individuals such that variable dependence is modeled. For each individual, the (max, +)-linear model is solved through a matrix product which determines the daters for alignment enabling for transfer operations. The study is extendable to complex net-structured systems of different nature.	genetic algorithm	Karla Quintero;José Aguilar;Éric Niel	2017	Appl. Soft Comput.	10.1016/j.asoc.2017.01.006	mathematical optimization;systems modeling;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;algorithm	Embedded	19.84939885471072	8.085565855229833	29406
d7b0e37a17bdbf1fab9776b6497065cea088e2cc	approximating capacitated tree-routings in networks	approximate algorithm;approximation algorithm;tree cover;satisfiability;connected graph;routing problems;network optimization;graph algorithm;steiner tree problem	Let G=(V,E) be a connected graph such that each edge e in E is weighted by a nonnegative real w(e). Let s be a vertex designated as a sink, M subset of V be a set of terminals with a demand function q:MR +, k>0 be a routing capacity, and λ≥1 be an integer edge capacity. The capacitated tree-routing problem (CTR) asks to find a partition M={Z 1,Z 2,...,Z l } of M and a set T={T1,T2,...,Tl} of trees of G such that each T i contains Z i and s and satisfies    Zi v ) ( k v q . A single copy of an edge e∈E can be shared by at most λ trees in T; any integer number of copies of e are allowed to be installed, where the cost of installing a copy of e is w(e). The objective is to find a solution (M,T) that minimizes the total installing cost. In this paper, we propose a (2+p )-approximation algorithm to CTR, where p is any approximation ratio achievable for the Steiner tree problem. Published Research Articles in International Journals 2009-2010 On the approximation of the generalized capacitated tree-routing Problem EhabMorsy and Hiroshi Nagamochi	approximation algorithm;binary prefix;connectivity (graph theory);routing;steiner tree problem	Ehab Morsy;Hiroshi Nagamochi	2011	J. Comb. Optim.	10.1007/s10878-009-9238-5	mathematical optimization;combinatorics;discrete mathematics;steiner tree problem;connectivity;mathematics;approximation algorithm;algorithm;satisfiability	Theory	23.13527939786848	18.876668416408663	29440
aa7cc72996638285ed1780e8a86566f7d8fae33b	alignment-free phylogenetic reconstruction: sample complexity via a branching process analysis	sequence comparison;phylogenetic reconstruction;branching process;ciencias basicas y experimentales;matematicas;multiple sequence alignment;grupo a;sample complexity;data structure;article;alignment;branching processes	We present an efficient phylogenetic reconstruction algorithm allowing insertions and deletions which provably achieves a sequence-length requirement (or sample complexity) growing polynomially in the number of taxa. Our algorithm is distance-based, that is, it relies on pairwise sequence comparisons. More importantly, our approach largely bypasses the difficult problem of multiple sequence alignment. ∗The results described here were first announced without proof in the special case of ultrametric trees under the CFN model with inverse logarithmic indel rates [DR10]. Here we give full proofs of stronger results, including extensions to bounded-rate trees under GTR models. †CSAIL, MIT. ‡Department of Mathematics and Bioinformatics Program, UCLA. Work supported by NSF grant DMS-1007144. ar X iv :1 10 9. 50 02 v1 [ m at h. PR ] 2 3 Se p 20 11	algorithm;bioinformatics;canadian football network;ibm notes;multiple sequence alignment;phylogenesis;phylogenetics;sample complexity	Constantinos Daskalakis;Sébastien Roch	2011	CoRR	10.1214/12-AAP852	branching process;combinatorics;data structure;multiple sequence alignment;mathematics;algorithm;alignment-free sequence analysis;statistics	ML	14.30482341098616	21.929474505671635	29492
f74505a5a4928af2e09c194ed7045d4dab314b38	recherche de chemins contraints dans les réseaux biochimiques	institutional repositories;fedora;path finding;vital;network analysis;constraint programming;biochemical network;vtls;ils	The analysis of biochemical networks is mainly done using relational or procedural languages. Combining or designing new analyses requires lot of programming effort that cannot be reused for other analyses. To overcome these limitations, we introduce CP(BioNet) a new constraint programming domain for the analysis of biochemical networks. Analyses are formulated using constraints over graph domain variables. The constraints are then solved by a constraint solver designed for biochemical networks. This provides a flexible and powerful approach as simple analyses can then easily be combined to form complex ones. We focus here on Constrained path finding, finding a path from node A to node B in a graph with additional constraints, such as requiring this path to include a predefined set of mandatory intermediate nodes. Constraints for path finding are introduced and their implementation (propagators) is described. A prototype is presented and constrained path finding experiments are performed and analyzed to illustrate the benefits of this new approach.		Grégoire Dooms;Yves Deville;Pierre Dupont	2004			mathematical optimization;combinatorics;mathematics;algorithm	Crypto	20.089152703140304	8.235169654445606	29648
388000c21c84761982bd648576892472f5f8b76d	on the complexity of preflow-push algorithms for maximum-flow problems	graph theory;maximum flow;operations research;technical report;network flow;industrial engineering	We study the maximum-flow algorithm of Goldberg and Tarjan and show that the largest-label implementation runs inO(n 2 √m) time. We give a new proof of this fact. We compare our proof with the earlier work by Cheriyan and Maheswari who showed that the largest-label implementation of the preflow-push algorithm of Goldberg and Tarjan runs inO(n 2 √m) time when implemented with current edges. Our proof that the number of nonsaturating pushes isO(n 2 √m), does not rely on implementing pushes with current edges, therefore it is true for a much larger family of largest-label implementation of the preflow-push algorithms.	maximum flow problem;push–relabel maximum flow algorithm	Levent Tunçel	1994	Algorithmica	10.1007/BF01187018	maximum flow problem;mathematical optimization;combinatorics;tarjan's strongly connected components algorithm;flow network;computer science;technical report;graph theory;mathematics;geometry;operations research;algorithm	Theory	21.521440860157103	21.30232875359988	29683
37688b718f2618f6ef5f5eb7bef15f10a2b1be88	a 3-party simultaneous protocol for sum-index	sum index function;protocole transmission;communication complexity;complexite communication;simultaneous model;protocolo transmision;modele simultane;indexation;circuit borne inferieure;circuit lower bound;communication protocol;sun index function;lower bound;transmission protocol	We show that the SUM-INDEX function can be computed by a 3-party simultaneous protocol in which one player sends only O(nɛ) bits and the other sends O(n1-C(ɛ)) bits (0<C(ɛ)<1 ). This implies that, in the Valiant—Nisan—Wigderson approach for proving circuit lower bounds, the SUM-INDEX function is not suitable as a target function.	array data structure;circuit complexity	Xiaoming Sun	2002	Algorithmica	10.1007/s00453-002-1007-0	communications protocol;telecommunications;computer science;communication complexity;mathematics;upper and lower bounds;algorithm	Crypto	17.625830475605067	32.10161851304936	29755
62284a9311386e69d230e79d7e0acdcb534042b5	optimal control of queueing systems with heterogeneous servers	queue length;optimal policy;optimal control;monotonicity of optimal policies;numerical analysis;queueing system;controllable queueing systems	An optimal policy to minimize the queue length in a multi-server controllable queueing system with heterogeneous servers has a threshold property, and it uses the fastest server if necessary (see [8] and [17]). This study gives a numerical description of optimal policies that minimize the operational cost for such a system.	fastest;iteration;lookup table;numerical analysis;optimal control;queueing theory;server (computing)	Vladimir Rykov;Dmitry Efrosinin	2004	Queueing Syst.	10.1023/B:QUES.0000027992.91461.1e	mathematical optimization;real-time computing;optimal control;bulk queue;numerical analysis;computer science;layered queueing network;mathematics;distributed computing	Metrics	9.881169986513658	10.404471119059618	29827
cdf8abadf8baeaa7b5aaa61551bb96b4b1662c61	parallelizability of some p-complete geometric problems in the erew-pram	algoritmo paralelo;pram;parallel algorithm;algorithm complexity;temps polynomial;time complexity;complejidad algoritmo;computer model;valeur consigne;algorithme parallele;complexite temps;complexite algorithme;cost optimization;valor consigna;set point;polynomial time;ensemble convexe;time use;convex set;complejidad tiempo;algoritmo optimo;algorithme optimal;optimal algorithm;conjunto convexo;tiempo polinomial	P-complete problems seem to have no parallel algorithm which runs in polylogarithmic time using a polynomial number of processors. A P-complete problem is in class EP (Efficient and Polynomially fast) if and only if there exists a cost optimal algorithm to solve it in T(n) = O(t(n))Ɛ) (Ɛ>1) using P(n) processors such that T(n) × P(n) = O(t(n)), where t(n) is the time complexity of the fastest sequential algorithm which solves the problem. The goal of our research is to find EPparallel algorithms for P-complete problems. In this paper we consider two P-complete geometric problems in the plane. First we consider the convex layers problem of a set S of n points. Let k be the number of the convex layers of S. When 1 ≤ k ≤ nƐ/2 (0 < Ɛ < 1) we can find the convex layers of S in O( nlogn/p) time using p processors, where 1 ≤ p ≤ n1-Ɛ/2. Next, we consider the envelope layers problem of a set S of n line segments. Let k be the number of the envelope layers of S. When 1 ≤ k ≤ nƐ/2 (0 < Ɛ < 1), we propose an algorithm for computing the envelope layers of S in O( nα(n) log3 n/p) time using pprocessors, where 1 ≤p ≤ n1-Ɛ/2, and α(n) is the functional inverse of Ackermann's function which grows extremely slowly. The computational model we use in this paper is the EREW-PRAM. Our first algorithm, for the convex layers problem, belongs to EP, and the second one, for the envelope layers problem, belongs to the class EP if a small factor of log n is ignored.	p-complete;parallel random-access machine	Carla Denise Castanho;Wei Chen;Koichi Wada;Akihiro Fujiwara	2001		10.1007/3-540-44679-6_7	computer simulation;time complexity;mathematical optimization;combinatorics;computer science;mathematics;algorithm	Theory	19.72440519233455	26.823239437174742	29843
90d731b03e3bcd28c5ee892412a204a743a9f0ed	on chen and chen's new tree inclusion algorithm	lettre alphabet;pire cas;procesamiento informacion;algorithm complexity;analyse complexite;algorithm analysis;time complexity;05c05;efficient algorithm;complejidad algoritmo;arbre ordonne;analyse temporelle;depth;space time;polynomial;contre exemple;analisis temporal;espacio tiempo;68wxx;time analysis;contraejemplo;tree inclusion;trees;complexite temps;complexite algorithme;informatique theorique;polinomio;information processing;profundidad;algorithme polynomial;inclusion;algorithms;letra alfabeto;analyse algorithme;profondeur;complejidad tiempo;letter;traitement information;polynome;probleme inclusion;analisis algoritmo;espace temps;counterexample;computer theory;informatica teorica	Very recently, Chen and Chen [Y. Chen, Y. Chen, A new tree inclusion algorithm, Information Processing Letters 98 (2006) 253– 262] gave a new algorithm for the tree inclusion problem, which requires O(|T | × min{depth(P ), |leaves(P )|}) time and no extra space. In this Note, we show that there are flaws in their time-complexity analysis by presenting two counterexamples. We also give an example to show that the worst-case time complexity of their algorithm is non-polynomial. Consequently, the asymptotically most efficient algorithm for the tree inclusion problem is the former algorithm in [W. Chen, More efficient algorithm for ordered tree inclusion, Journal of Algorithms 26 (1998) 370–385]. © 2007 Elsevier B.V. All rights reserved.	algorithm;analysis of algorithms;best, worst and average case;entity–relationship model;information processing letters;polynomial;time complexity;tree (data structure)	Hai-Lung Cheng;Biing-Feng Wang	2007	Inf. Process. Lett.	10.1016/j.ipl.2007.02.006	time complexity;letter;information processing;counterexample;calculus;space time;mathematics;algorithm;inclusion;polynomial	Theory	18.62697310863747	26.170733084203118	29901
1f3c44d174e2f8c0dbb9f25e40628396d5e933f9	an analysis of the intertial response of small isolated power systems in presence of generation from renewable energy sources		Renewable Energy Sources are posing critical issues related to the mining of power systems stability, essentially due to a decrement of the inertial response during system's contingencies. As a consequence, to preserve the security and the reliability of the system, it is necessary to adopt new frequency adjustments mechanisms. This issue becomes particularly critical in isolated power systems, like those of small islands not supplied by the main grid, in the case of high shares of production from unpredictable renewabies such as photovoitaic and wind sources. In this framework, the present work deals with the analysis of the variation of the inertia time constant of a small island in various scenarios characterized by a different share of renewable energy. The study represents the first step of a more extended feasibility study for the conversion of a traditional power system based on fossil fuel towards a renewable energy-based power system.		Salvatore Favuzza;Mariano Giuseppe Ippolito;Rossano Musca;M. Navarro Navia;Eleonora Riva Sanseverino;Gaetano Zizzo;Massimo Bongiorno	2018	2018 IEEE 4th International Forum on Research and Technology for Society and Industry (RTSI)	10.1109/RTSI.2018.8548401		Embedded	1.838273033060774	7.195985026223884	29950
ab8783b45df414ed7bd300e6c374d32cab9eea28	an efficient implementation of sugiyama's algorithm for layered graph drawing	graph drawing;time complexity;m 500 layered;efficient implementation;p 480 layered	Sugiyama's algorithmic framework for layered graph drawing is commonly used in practical software. The extensive use of dummy vertices to break long edges between non-adjacent layers often leads to unsatisfactorial performance. The worst-case running-time of Sugiyama's approach is O(|V||E|log|E|) requiring O(|V||E|) memory, which makes it unusable for the visualization of large graphs. By a conceptually simple new technique we are able to keep the number of dummy vertices and edges linear in the size of the graph and hence reduce the worst-case time complexity of Sugiyama's approach by an order of magnitude to O((|V|+|E|)log|E|) requiring O(|V|+|E|) space.	algorithm;layered graph drawing	Markus Eiglsperger;Martin Siebenhaller;Michael Kaufmann	2004		10.1007/978-3-540-31843-9_17	time complexity;combinatorics;multiple edges;computer science;theoretical computer science;mathematics;distributed computing;graph drawing;algorithm	HCI	20.630763674055817	22.136831021341358	29998
122f4739d25c4240f3cc7a1d73da8abbbf7d3832	agile factorial production for a single manufacturing line with multiple products	lot sizing;genetic algorithm;production schedule;elsp	Industrial practices and experiences highlight that demand is dynamic and non-stationary. Research however has historically taken the perspective that stochastic demand is stationary therefore limiting its impact for practitioners. Manufacturers require schedules for multiple products that decide the quantity to be produced over a required time span. This work investigated the challenges for production in the framework of a single manufacturing line with multiple products and varying demand. The nature of varying demand of numerous products lends itself naturally to an agile manufacturing approach. We propose a new algorithm that iteratively refines production windows and adds products. This algorithm controls parallel genetic algorithms (pGA) that find production schedules while minimizing costs. The configuration of such a pGA was essential in influencing the quality of results. In particular providing initial solutions was an important factor. Two novel methods are proposed that generate initial solutions by transforming a production schedule into one with refined production windows. The first method is called factorial generation and the second one fractional generation method. A case study compares the two methods and shows that the factorial method outperforms the fractional one in terms of costs.	agile software development	Wolfgang Garn;James Aitken	2015	European Journal of Operational Research	10.1016/j.ejor.2015.03.042	mathematical optimization;simulation;genetic algorithm;computer science;operations management	Robotics	14.195625925819915	4.931653123537677	30008
54ead1c593f4e08fa08613e7bf7cbca7a917450d	syntactic complexity of bifix-free languages		We study the properties of syntactic monoids of bifix-free regular languages. In particular, we solve an open problem concerning syntactic complexity: We prove that the car-dinality of the syntactic semigroup of a bifix-free language with state complexity n is at most (n−1) n−3 +(n−2) n−3 +(n−3)2 n−3 for n 6. The main proof uses a large construction with the method of injective function. Since this bound is known to be reachable, and the values for n 5 are known, this completely settles the problem. We also prove that (n − 2) n−3 + (n − 3)2 n−3 − 1 is the minimal size of the alphabet required to meet the bound for n 6. Finally, we show that the largest transition semigroups of minimal DFAs which recognize bifix-free languages are unique up to renaming the states.	dfa minimization;regular language;syntactic monoid	Marek Szykula;John Wittnebel	2017		10.1007/978-3-319-60134-2_17	discrete mathematics;cardinality;combinatorics;syntactic predicate;second-generation programming language;comparison of multi-paradigm programming languages;mathematics;semigroup;monoid;abstract family of languages;sparse language	Logic	-1.683461162643756	20.310950272693923	30043
13b31ca093fa62c4d132d21c28fa80f4fb48b39c	path decomposition under a new cost measure with applications to optical network design	optimal solution;optical network;network design;approximate algorithm;path decomposition;approximation algorithms;efficient algorithm;network topology;dense wavelength division multiplexed;optical network design;optical electrical optical	We introduce a problem directly inspired by its application to DWDM (dense wavelength division multiplexing) network design. We are given a set of demands to be carried over a network. Our goal is to choose a route for each demand and to decompose the network into a collection of edge-disjoint simple paths. These paths are called optical line systems. The cost of routing one unit of demand is the number of line systems with which the demand route overlaps; our design objective is to minimize the total cost over all demands. This cost metric is motivated by the need to minimize O-E-O (optical-electrical-optical) conversions in optical transmission.  For given line systems, it is easy to find the optimal demand routes. On the other hand, for given demand routes designing the optimal line systems can be NP-hard. We first present a 2-approximation for general network topologies. As optical networks often have low node degrees, we offer an algorithm that finds the optimal solution for the special case in which the node degree is at most 3. Our solution is based on a local greedy approach.  If neither demand routes nor line systems are fixed, the situation becomes much harder. Even for a restricted scenario on a 3-regular Hamiltonian network, no efficient algorithm can guarantee a constant approximation better than 2. For general topologies, we offer a simple algorithm with an O(log K)- and an O(log n)-approximation, where K is the number of demands and n the number of nodes. This approximation ratio is almost tight. For rings, a common special topology, we offer a more complex 3/2-approximation algorithm.	approximation algorithm;default route;greedy algorithm;hamiltonian (quantum mechanics);np-hardness;network planning and design;network topology;pathwidth;routing;wavelength-division multiplexing	Elliot Anshelevich;Lisa Zhang	2008	ACM Trans. Algorithms	10.1145/1328911.1328926	mathematical optimization;network planning and design;combinatorics;computer science;mathematics;distributed computing;approximation algorithm;network topology	Theory	22.89761735697839	18.400431951260032	30055
aa74d508e2d966f701ba3c41c5b3f5a8e7098cfa	one for the price of two: a unified approach for approximating covering problems	problema arbol steiner;optimisation;vertex cover;foret graphe;approximate algorithm;optimizacion;feedback vertex set;algorithme glouton;teoria unificada;aproximacion;primal dual method;probleme arbre steiner;methode primale duale;approximation;aleatorizacion;feedback;probleme recouvrement;metodo primal dual;problema recubrimiento;vertex graph;unified theory;randomized algorithm;randomisation;greedy algorithm;bosque grafo;algoritmo gloton;optimization;steiner tree problem;covering problem;boucle reaction;performance ratio;randomization;retroalimentacion;forest graph;theorie unifiee;set cover;vertice grafo;sommet graphe	We present a simple and unified approach for developing and analyzing approximation algorithms for covering problems. We illustrate this on approximation algorithms for the following problems: Vertex Cover, Set Cover, Feedback Vertex Set, Generalized Steiner Forest, and related problems. The main idea can be phrased as follows: iteratively, pay two dollars (at most) to reduce the total optimum by one dollar (at least), so the rate of payment is no more than twice the rate of the optimum reduction. This implies a total payment (i.e., approximation cost) ≤ twice the optimum cost. Our main contribution is based on a formal definition for covering problems, which includes all the above fundamental problems and others. We further extend the Bafna et al. extension of the Local-Ratio theorem. Our extension eventually yields a short generic r -approximation algorithm which can generate most known approximation algorithms for most covering problems. Another extension of the Local-Ratio theorem to randomized algorithms gives a simple proof of Pitt's randomized approximation for Vertex Cover. Using this approach, we develop a modified greedy algorithm, which for Vertex Cover gives an expected performance ratio ≤ 2 .	approximation algorithm;covering problems;feedback vertex set;greedy algorithm;randomized algorithm;set cover problem;steiner tree problem;vertex cover	Reuven Bar-Yehuda	2000	Algorithmica	10.1007/s004530010009	randomization;mathematical optimization;combinatorics;greedy algorithm;discrete mathematics;feedback vertex set;vertex cover;covering problems;steiner tree problem;edge cover;approximation;vertex;feedback;mathematics;geometry;set cover problem;randomized algorithm;unified field theory;approximation algorithm;algorithm	Theory	21.39672240407347	14.419999209922818	30094
087ac0583fb66aa5caae1e14a4e8b0e87721ef78	new strong direct product results in communication complexity	strong direct product;communication complexity;information theory	We show two new direct product results in two different models of communication complexity. Our first result is in the one-way public-coin model. Let f ⊆ X × Y × Z be a relation and ε > 0 be a constant. Let R1,pubε(f) represent the communication complexity of f, with worst-case error ε in this model. We show that if for computing fk (k independent copies of f) in this model, o(k ċ R1, pub1/3(f)) communication is used, then the success is exponentially small in k. We show a new tight characterization of communication complexity in this model which strengthens the tight characterization shown in Jain et al. [2008]. We use this new characterization to show our direct product result and this characterization may also be of independent interest.  Our second direct product result is in the model of two-way public-coin communication complexity. We show a direct product result for all relations in this model in terms of a new complexity measure that we define. Our new measure is a generalization to nonproduct distributions, of the two-way product subdistribution bound of Jain et al. [2008]. Our direct product result therefore generalizes to nonproduct distributions, their direct product result in terms of the two-way product subdistribution bound. As an application of our new direct product result, we reproduce (via completely different arguments) strong direct product result for the set-disjointness problem which was previously shown by Klauck [2010]. We show this by proving that our new complexity measure gives a tight lower bound of Ω(n) for the set-disjointness problem on n-bit inputs (this strengthens the linear lower bound on the rectangle/corruption bound for set-disjointness shown by Razborov [1992]). In addition, we show that many previously known direct product results in this model are uniformly implied and often strengthened by our result.	best, worst and average case;blum axioms;communication complexity;computational complexity theory;one-way function	Rahul Jain	2011	J. ACM	10.1145/2699432	combinatorics;discrete mathematics;information theory;computer science;communication complexity;mathematics;statistics	Theory	9.04930848573135	24.40293449944918	30125
e688e8305986e312c1e9bdc3da507f1412f2bdd2	definability of cai-fürer-immerman problems in choiceless polynomial time	004;websearch;finite model theory descriptive complexity logic for textsc ptime choiceless polynomial time cai furer immerman;rwth publications;ikz117220	"""Choiceless Polynomial Time (CPT) is one of the most promising candidates in the search for a logic capturing Ptime. The question whether there is a logic that expresses exactly the polynomial-time computable properties of finite structures, which has been open for more than 30 years, is one of the most important and challenging problems in finite model theory. The strength of Choiceless Polynomial Time is its ability to perform isomorphism-invariant computations over structures, using hereditarily finite sets as data structures. But, as it preserves symmetries, it is choiceless in the sense that it cannot select an arbitrary element of a set—an operation which is crucial for many classical algorithms. CPT can define many interesting Ptime queries, including (the original version of) the Cai-Fürer-Immerman (CFI) query. The CFI query is particularly interesting because it separates fixed-point logic with counting from Ptime, and has since remained the main benchmark for the expressibility of logics within Ptime. The CFI construction associates with each connected graph a set of CFI-graphs that can be partitioned into exactly two isomorphism classes called odd and even CFI-graphs. The problem is to decide, given a CFI-graph, whether it is odd or even. In the original version, the underlying graphs are linearly ordered, and for this case, Dawar, Richerby and Rossman proved that the CFI query is CPT-definable. However, the CFI query over general graphs remains one of the few known examples for which CPT-definability is open. Our first contribution generalises the result by Dawar, Richerby and Rossman to the variant of the CFI query where the underlying graphs have colour classes of logarithmic size, instead of colour class size one. Secondly, we consider the CFI query over graph classes where the maximal degree is linear in the size of the graphs. For these classes, we establish CPT-definability using only sets of small, constant rank, which is known to be impossible for the general case. In our CFI-recognising procedures we strongly make use of the ability of CPT to create sets, rather than tuples only, and we further prove that, if CPT worked over tuples instead, no such procedure would be definable. We introduce a notion of """"sequence-like objects"""" based on the structure of the graphs’ symmetry groups, and we show that no CPT-program which only uses sequence-like objects can decide the CFI query over complete graphs, which have linear maximal degree. From a broader perspective, this generalises a result by Blass, Gurevich, and van den Bussche about the power of isomorphism-invariant machine models (for polynomial time) to a setting with counting. 1998 ACM Subject Classification F.4.1 Mathematical Logic"""	algorithm;benchmark (computing);cpt (file format);complexity class;computable function;computation;connectivity (graph theory);data structure;decision problem;degree (graph theory);directed graph;graph theory;immerman–szelepcsényi theorem;least fixed point;linear algebra;linear equation;maximal set;p (complexity);polynomial;time complexity;yuri gurevich	Wied Pakusa;Svenja Schalthöfer;Erkal Selman	2016		10.4230/LIPIcs.CSL.2016.19	combinatorics;discrete mathematics;computer science;mathematics;algorithm	Theory	7.045440200546676	19.20224359709934	30144
304dcce8b49b81e093f195420afa7480d59973a4	tree-based coarsening and partitioning of complex networks	complex networks;spanning trees;conductance;fundamental cuts;multilevel graph partitioning;graph coarsening	A hierarchy of increasingly coarse versions of a network allows one to represent the network on multiple scales at the same time. Often, the elementary operation for generating a hierarchy on a network is merging adjacent vertices, an operation that can be realized through contracting the edge between the two vertices. Such a hierarchy is defined by the selection of the edges to be contracted between a level and the next coarser level. The selection may involve (i) rating the edges, (ii) constraining the selection (e.g., that the selected edges form a matching), as well as (iii) maximizing the total rate of the selected edges under the constraints. Hierarchies of this kind are, among others, involved in multilevel methods for partitioning networks—a prerequisite for processing in parallel with distributed memory.  In this article, we propose a new edge rating by (i) defining weights for the edges of a network that express the edges’ importance for connectivity via shortest paths, (ii) computing a minimum weight spanning tree with respect to these weights, and (iii) rating the network edges based on the conductance values of the tree’s fundamental cuts.  To make the computation of our new edge rating efficient, we develop the first optimal linear-time algorithm to compute the conductance values of all fundamental cuts of a given spanning tree. We integrate the new edge rating into a leading multilevel graph partitioner and equip the latter also with a new greedy postprocessing for optimizing the Maximum Communication Volume (MCV) of a partition.  Our experiments, in which we bipartition frequently used benchmark networks, show that the postprocessing reduces MCV by 11.3%. Our new edge rating, here used for matching-based coarsening, further reduces MCV by 10.3% compared to the previously best rating with MCV postprocessing in place for both ratings. In total, with a modest increase in running time, our new approach reduces the MCV of complex network partitions by 20.4%.	benchmark (computing);complex network;computation;conductance (graph);distributed memory;experiment;file spanning;greedy algorithm;mac os x 10.3 panther;matching (graph theory);minimum spanning tree;minimum weight;mobile television;neighbourhood (graph theory);shortest path problem;time complexity	Roland Glantz;Henning Meyerhenke;Christian Schulz	2016	ACM Journal of Experimental Algorithmics	10.1145/2851496	conductance;mathematical optimization;combinatorics;discrete mathematics;multiple edges;minimum degree spanning tree;spanning tree;machine learning;mathematics;complex network;algorithm	Web+IR	23.501764272508783	28.499685565239183	30147
f53d8037dc4fd4dafdb11ef52c17232fbd2c5521	several results in program size complexity	finite element methods;computer languages;complexity theory;time measurement;clocks;oscillators;computer languages size measurement binary sequences encoding laboratories time measurement;size measurement;length measurement;additives;indexes;computational modeling;shape;binary sequences;writing;particle separators;electrical engineering;encoding	Intuitively, the program size complexity of a binary string measures the amount of information in the string. Researchers have formalized this notion in a number of different ways. Here, we demonstrate similarities between some of these formulations. We also investigate in some detail the properties of Kolmogorov's complexity measure.		Howard P. Katseff;Michael Sipser	1977	18th Annual Symposium on Foundations of Computer Science (sfcs 1977)	10.1109/SFCS.1977.28	database index;shape;length measurement;food additive;computer science;theoretical computer science;finite element method;mathematics;oscillation;computational model;writing;algorithm;encoding;time	Theory	3.7187188678646	23.148226842654772	30170
aaf98c5b476d31b350dc0b790eb3a9750baba2e0	a simulation optimisation approach for real-time scheduling in an open shop environment using a composite dispatching rule	simulation applications;neural network applications;data envelopment analysis;open shop scheduling;dispatching rule	In the last decades, many researchers have studied open shop scheduling (OSS) problem by considering deterministic parameters using mathematical modelling, heuristics and meta-heuristics. However, it is important to study the problem as close as possible to real world conditions which consists of uncertainty and stochastic parameters. In this study, dispatching rules, as accepted tools for real-time scheduling, are applied for optimising the OSS problem. Since none of conventional dispatching rules performs well for all performance measures, a simulation-based real-time scheduling composite dispatching rule is developed. For this purpose, a multi response optimisation approach based on computer simulation for scheduling a non-preemptive open shop with stochastic ready times is presented in order to minimise the mean waiting time of jobs. The presented approach composed of design of experiments, discrete event simulation, multi-layer perceptron artificial neural network, radial basis function and data enve...	mathematical optimization;real-time clock;scheduling (computing);simulation	Mohammad Mahdi Nasiri;Reza Yazdanparast;Fariborz Jolai	2017	Int. J. Computer Integrated Manufacturing	10.1080/0951192X.2017.1307452	discrete event simulation;open shop;scheduling (computing);fair-share scheduling;dynamic priority scheduling;real-time computing;heuristics;computer science;open-shop scheduling;flow shop scheduling	Robotics	11.611208190813514	6.131770688550795	30248
393f94e6870e292c97ca2f8a417b8bcb8ae29bbc	scheduling with regular performance measures and optional job rejection on a single machine		We address single machine problems with optional job–rejection, studied lately in Zhang et al. (2010) and Cao et al. (2006). In these papers, the authors focus on minimizing regular performance measures, i.e., functions that are non-decreasing in the jobs completion time, subject to the constraint that the total rejection cost cannot exceed a predefined upper bound. The authors prove that the considered problems are ordinary NP-hard and provide pseudo-polynomial-time Dynamic Programming (DP) solutions. In this paper, we focus on three of these problems: makespan with release-dates; total completion times; and total weighted completion, and present enhanced DPs for these problems. The resulting computational complexity achieved is O(nU), where n is the number of jobs and U is the upper bound on the total rejection cost. Moreover, the extensive numerical study we executed proves that all updated DP algorithms are extremely efficient, even for large-size problem instances.	algorithm;computational complexity theory;dynamic programming;job stream;makespan;np-hardness;numerical analysis;polynomial;polynomial-time approximation scheme;pseudo-polynomial time;real life;rejection sampling;schedule (project management);scheduling (computing);time complexity	Baruch Mor;Dana Shapira	2017	CoRR		mathematics;job shop scheduling;scheduling (computing);real-time computing;pseudo-polynomial time;dynamic programming;computational complexity theory;upper and lower bounds	AI	15.648862244595083	9.919002063348756	30261
20f013b0f534b742fc333bb94c245d06ac3e5031	pseudorandom generators for read-once acc^0	random restrictions;random number generation computational complexity logic circuits logic gates;random number generation;derandomization;logic circuits;polylogarithmic seed length pseudorandom generators read once acc 0 explicit construction read once constant depth circuits unbounded fan in and gate unbounded fan in or gate unbounded fan in not gate unbounded fan in generalized modulo m gate;logic gates generators integrated circuit modeling random variables computational modeling polynomials context;pseudorandom generators;logic gates;computational complexity;random restrictions pseudorandom generators derandomization	We consider the problem of constructing pseudorandom generators for read-once circuits. We give an explicit construction of a pseudorandom generator for the class of read-once constant depth circuits with unbounded fan-in AND, OR, NOT and generalized modulo m gates, where m is an arbitrary fixed constant. The seed length of our generator is poly-logarithmic in the number of variables and the error.	fan-in;modulo operation;pseudorandom generator;pseudorandomness	Dmitry Gavinsky;Shachar Lovett;Srikanth Srinivasan	2012	2012 IEEE 27th Conference on Computational Complexity	10.1109/CCC.2012.37	pseudorandom generators for polynomials;discrete mathematics;logic gate;computer science;engineering;theoretical computer science;pseudorandom function family;mathematics;lavarand;pseudorandom generator;random seed;pseudorandom number generator;pseudorandomness;pseudorandom generator theorem;algorithm	Theory	9.438330308776512	22.4173734835279	30263
692b728359bbc3a8808e5a443c7bf4d1e48f0b83	automatic presentations for cancellative semigroups	abelian group;regular language;finite automata	This paper studies FA-presentable structures and gives a complete classification of the finitely generated FA-presentable cancellative semigroups. We show that a finitely generated cancellative semigroup is FA-presentable if and only if it is a subsemigroup of a virtually abelian group.	automatic semigroup	Alan J. Cain;Graham P. Oliver;Nikola Ruskuc;Richard M. Thomas	2008		10.1007/978-3-540-88282-4_15	combinatorics;discrete mathematics;regular language;cancellative semigroup;computer science;elementary abelian group;mathematics;abelian group;finite-state machine;programming language;algorithm;algebra	Logic	-2.7278421422249104	19.707214648672142	30361
d0c0fd097747088d041f4a73a72b789750eafd2f	on some interval methods for algebraic, exponential and trigonometric polynomials	iterative method;convergence analysis;polynome exponentiel;relacion convergencia;methode simultanee;polynome generalise;polynome algebrique;taux convergence;convergence rate;polynome trigonometrique;metodo iterativo;trigonometric polynomials;methode iterative;polinomio trigonometrico;aritmetica intervalo;interval arithmetic;arithmetique intervalle;trigonometric polynomial;interval method	New inclusion methods for the simultaneous determination of the zeros of algebraic, exponential and trigonometric polynomials are presented. These methods are realized in real interval arithmetic and do not use any derivatives. Using Weierstrass' correction some modified methods with the increased convergence rate are constructed. Convergence analysis and numerical example are included. Die Arbeit behandelt neue Einschliessungsmethoden zur simultanen Berechnung aller Nullstellen von algebraischen, exponentiellen und trigonometrischen Polynomen. Die Verfahren sind für reelle Intervallarithmetik formuliert und benötigen keine Auswertungen von Ableitungen des gegebenen verallgemeinerten Polynomes. Unter Verwendung der sog. Weierstrass-Korrektoren werden verbesserte modifizierte Verfahren konstruiert. Hierzu enthält die Arbeit Konvergenzuntersuchungen und numerische Beispiele.	algebraic equation;die (integrated circuit);interval arithmetic;numerical analysis;rate of convergence;time complexity;trigonometric polynomial	Carsten Carstensen;Miodrag S. Petkovic	1993	Computing	10.1007/BF02238538	mathematical optimization;mathematical analysis;calculus;mathematics;iterative method;interval arithmetic;rate of convergence;algorithm;trigonometric polynomial;algebra;proofs of trigonometric identities	Theory	4.032308801949731	28.420466956131207	30363
e68e9bd467fc021ced0b6db366f4bb2fb5ea7f4d	the hitting and cover times of random walks on finite graphs using local degree information	protocolo red;network protocol;optimum;aplicacion;grado grafo;camino grafo;loi probabilite;ley probabilidad;graph path;transition probability;vertex;transition;graphe fini;cover time;finite graph;reseau;red;grafo finito;transicion;random walk;informatique theorique;probability distribution;optimo;ordre n;hitting time;68r10;probabilidad transicion;chemin graphe;orden n;vertice;degre graphe;transition probability matrix;68m12;marcha aleatoria;protocole reseau;n order;application;probabilite transition;marche aleatoire;graph degree;network;computer theory;informatica teorica	Standard random walks on finite graphs select the vertex visited next to the adjacent vertices at random with the same probability. Despite not using any global topological information, they guarantee O(n3) hitting and cover times for any graph, where n is the order of the graph. Motivated by network protocol applications, this paper investigates the impact of local topological information on designing ‘‘better’’ randomwalks. We first show that (a) for any transition probability matrix, the hitting (and hence the cover) time of a path graph isΩ(n2). We next investigate for any graph G = (V , E) a transition probability matrix P = (p(u, v))u,v∈V defined by p(u, v) =  deg−1/2(v) ∑ w∈N(u) deg−1/2(w) if v ∈ N(u), 0 otherwise, where N(u) and deg(u) are respectively the set of adjacent vertices of u and the u’s degree. Random walks obeying this transition probability matrix are shown to guarantee the following: For any graph, (b) the hitting time is O(n2), and (c) the cover time is O(n2 log n). Facts (a) and (b) show that the degree information on the adjacent vertices is powerful enough for random walks to achieve the optimum hitting time. © 2008 Elsevier B.V. All rights reserved.	communications protocol;emoticon;markov chain;neighbourhood (graph theory);obedience (human behavior);stochastic matrix	Satoshi Ikeda;Izumi Kubo;Masafumi Yamashita	2009	Theor. Comput. Sci.	10.1016/j.tcs.2008.10.020	probability distribution;random regular graph;random graph;communications protocol;vertex;markov chain;combinatorics;transition;mathematics;hitting time;bound graph;random walk;algorithm;statistics	Theory	23.57689064272394	31.668535320498815	30445
80c527959bbceeafde39c12af57416e2e261e9d7	tree powers	tree power	We present the first polynomial algorithm for recognizing tree powers. A graph G is a tree power if there is a tree T and a positive integer k such that T k ( G, k Ž . where x and y are adjacent in T if and only if d x, y F k. We also show that a T natural extension of tree power recognition is NP-complete, namely, given a graph G and a positive integer r, determine if there is a tree power within r edges of G. Q 1998 Academic Press	dijkstra's algorithm;karp's 21 np-complete problems;polynomial	Paul E. Kearney;Derek G. Corneil	1998	J. Algorithms	10.1006/jagm.1998.9999	combinatorics;discrete mathematics;tree rotation;vantage-point tree;exponential tree;spanning tree;stern–brocot tree;range tree;calkin–wilf tree;gomory–hu tree;k-ary tree;k-minimum spanning tree;mathematics;algorithm;avl tree	Theory	24.516865707756388	27.392170340596934	30471
fa14b52e40f6a798e324083360521c720a016612	fleet sizing for electric car sharing system via closed queueing networks	transportation approximation theory automobiles discrete time systems electric vehicles financial management optimisation queueing theory;real world systems fleet sizing electric car sharing system closed queueing network framework optimal fleet size determining problem discrete event system asymptotic vehicles behavior electric vehicle utilization optimization problem system revenue maximization;optimization approximation methods servers routing electric vehicles time factors;optimization car sharing queuing networks	This paper addresses the problem of determining the optimal fleet size of electric car sharing systems. We model the system as a Discrete Event System in a closed queueing network framework considering the specific requirements of the electric vehicle utilization. Hence, we describe the asymptotic behavior of the vehicles and develop an optimization problem for maximizing the system revenue by determining the optimal fleet size. The large-scale of real-world systems results in computational difficulties in obtaining the exact solution, and so an approximate formulation is provided. Some numerical results illustrate and validate the solution method.	ana (programming language);approximation algorithm;asymptote;computation;correctness (computer science);mathematical optimization;numerical analysis;optimization problem;queueing theory;requirement;steady state;world-system	Maria Pia Fanti;Agostino Marcello Mangini;Giovanni Pedroncelli;Walter Ukovich	2014	2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2014.6974098	simulation	Robotics	6.928034488772034	4.310759161176069	30472
0fd65bb9d6e9b0884c77e2605b6af79cf9bc4464	randomized online algorithms with high probability guarantees	004;online algorithms randomization high probability	We study the relationship between the competitive ratio and the tail distribution of randomized online problems. To this end, we define a broad class of online problems that includes some of the well-studied problems like paging, k-server and metrical task systems on finite metrics, and show that for these problems it is possible to obtain, given an algorithm with constant expected competitive ratio, another algorithm that achieves the same solution quality up to an arbitrarily small constant error with high probability; the “high probability” statement is in terms of the optimal cost. Furthermore, we show that our assumptions are tight in the sense that removing any of them allows for a counterexample to the theorem. 1998 ACM Subject Classification F.1.2 Modes of Computation, F.2.2 Nonnumerical Algorithms and Problems	competitive analysis (online algorithm);computation;metrical task system;online algorithm;paging;randomized algorithm;server (computing);whole earth 'lectronic link;with high probability	Dennis Komm;Rastislav Kralovic;Richard Královic;Tobias Mömke	2014		10.4230/LIPIcs.STACS.2014.470	competitive analysis;mathematical optimization;combinatorics;computer science;theoretical computer science;mathematics	Theory	16.635053692177877	16.184247686292395	30482
65b9a1af66f2bbee254787503bf8ea42956b4d4b	heavy-traffic asymptotics of a priority polling system with threshold service policy	stochastic simulation;tail queue length distribution;singular perturbation;heavy traffic;polling system	In this paper, by the singular-perturbation technique, we investigate the heavy-traffic behavior of a priority polling system with three queues under threshold policy. It turns out that the scaled queue-length of the critically loaded queue is exponentially distributed, independent of that of the stable queues, which possess the same distributions as a two-class priority queue with N-policy vacation. Further, we provide an approximation of the tail queue-length distribution of the stable queues, which shows that it has the same prefactors and decay rates as the classical two-class preemptive priority queue. Stochastic simulations are taken to support the results. HighlightsThe heavy-traffic behavior of a polling system with threshold policy is discussed.The scaled queue-length of the critically loaded queue is exponentially distributed.Approximations of queue lengths of the stable queues are provided.The decay rates of the stable queues are the same decay rate as the classical preemptive priority queues.		Zaiming Liu;Yuqing Chu;Jinbiao Wu	2016	Computers & OR	10.1016/j.cor.2015.06.013	singular perturbation;polling system;real-time computing;multilevel queue;stochastic simulation;mathematics;distributed computing;queue management system;fork–join queue;priority queue;statistics	OS	7.8137238012654775	11.350684634401203	30518
ce3fdcc89d2ede45ee8712b404727240224652d8	algorithm and complexity for a network assortativity measure		We show that finding a graph realization with the minimum Randić index for a given degree sequence is solvable in polynomial time by formulating the problem as a minimum weight perfect b-matching problem. However, the realization found via this reduction is not guaranteed to be connected. Approximating the minimum weight b-matching problem subject to a connectivity constraint is shown to be NP-Hard. For instances in which the optimal solution to the minimum Randić index problem is not connected, we describe a heuristic to connect the graph using pairwise edge exchanges that preserves the degree sequence. In our computational experiments, the heuristic performs well and the Randić index of the realization after our heuristic is within 3% of the unconstrained optimal value on average. Although we focus on minimizing the Randić index, our results extend to maximizing the Randić index as well. Applications of the Randić index to synchronization of neuronal networks controlling respiration in mammals and to normalizing cortical thickness networks in diagnosing individuals with dementia are provided.	algorithm;assortativity;ct scan;computation;decision problem;degree (graph theory);experiment;finite thickness;graph (discrete mathematics);heuristic;minimum weight;np-hardness;optimization problem;polynomial;procedural generation;randić's molecular connectivity index;thickness (graph theory);time complexity	Sarah J. Kunkler;Michael Drew Lamar;Rex K. Kincaid;David Phillips	2013	CoRR		mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	24.21396001488229	21.009222414211525	30559
0324b6d30c92b7f61527c6b323b7e6d44d991439	walks on spr neighborhoods	bryant second combinatorial challenge;nearest neighbor searches;biology computing;algorithms computational biology evolution molecular models genetic phylogeny;sequences;analysis of algorithms and problem complexity;unrooted binary tree;bryant second combinatorial challenge nearest neighbor interchange walk unrooted phylogenetic trees sequence consecutive trees pair subtree prune and regraft neighborhood unrooted binary tree;evolution biological;nearest neighbor searches decision trees;trees mathematics;genetics;trees;trees mathematics biology computing evolution biological genetics sequences;phylogenetic tree;biology and genetics;nearest neighbor;graphs and networks;consecutive trees pair;decision trees;subtree prune and regraft neighborhood;graphs and networks analysis of algorithms and problem complexity biology and genetics trees;unrooted phylogenetic trees sequence;binary tree;nearest neighbor interchange walk	A nearest-neighbor-interchange (NNI)-walk is a sequence of unrooted phylogenetic trees, $(T_1, T_2, \ldots, T_k)$ where each consecutive pair of trees differs by a single NNI move. We give tight bounds on the length of the shortest NNI-walks that visit all trees in a subtree-prune-and-regraft (SPR) neighborhood of a given tree. For any unrooted, binary tree, $(T)$, on $(n)$ leaves, the shortest walk takes $(\Theta (n^2))$ additional steps more than the number of trees in the SPR neighborhood. This answers Bryant's Second Combinatorial Challenge from the Phylogenetics Challenges List, the Isaac Newton Institute, 2011, and the Penny Ante Problem List, 2009.	binary tree;newton;phylogenetic tree;phylogenetics;prune belly syndrome;short;tree (data structure);trees (plant)	Alan Joseph J. Caceres;Juan Castillo;Jinnie Lee;Katherine St. John	2013	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2012.136	combinatorics;phylogenetic tree;binary tree;computer science;bioinformatics;machine learning;decision tree;sequence;mathematics;k-nearest neighbors algorithm;genetics	Theory	16.690433552991426	22.498511183271205	30560
fa352af119a75cae606633eb124e52245b59b52e	stable matchings in three-sided systems with cyclic preferences	graph theory;05c70;teoria grafo;theoreme gale shapley;game theory;mathematiques discretes;matematicas discretas;stable matching;stable marriage;90d06;discrete mathematics;cyclic preferences;teoria juego;theorie jeu;theorie graphe;appariement stable;cyclic preference;preference cyclique;stable marriage problem;mariage stable;gale shapley theorem	We consider generalizations of the Gale-Shapley (1962) Stable Marriage Problem to threesided families. Alkan (1988) gave an example which shows that in the case of general preferences stable matchings do not always exist. Here we suggest a more compact example. Danilov (2001) proved that stable matchings exist for some acyclic preferences and he raised the problem for the lexicographical-cyclic preferences. Here we show that the answer is negative. We construct a three-sided system with lexicographical-cyclic preferences for which no stable matching exists.	directed acyclic graph;lexicography;matching (graph theory);stable marriage problem;stable model semantics	Endre Boros;Vladimir Gurvich;Steven Jaslar;Daniel Krasner	2004	Discrete Mathematics	10.1016/j.disc.2004.08.012	game theory;combinatorics;stable marriage problem;graph theory;calculus;mathematics;mathematical economics;algebra	ECom	22.06216281078116	31.16774437590259	30581
0f7d41122ec22a4786111135a1618fd2a56567b3	a (biased) proof complexity survey for sat practitioners	datavetenskap datalogi;computer science	This talk is intended as a selective survey of proof complexity, focusing on some comparatively weak proof systems that are of particular interest in connection with SAT solving. We will review resolution, polynomial calculus, and cutting planes (related to conflict-driven clause learning, Gröbner basis computations, and pseudo-Boolean solvers, respectively) and some proof complexity measures that have been studied for these proof systems. We will also briefly discuss if and how these proof complexity measures could provide insights into SAT solver performance. Proof complexity studies how hard it is to find succinct certificates for the unsatisfiability of formulas in conjunctive normal form (CNF), i.e., proofs that formulas always evaluate to false under any truth value assignment, where these proofs should be efficiently verifiable. It is generally believed that there cannot exist a proof system where such proofs can always be chosen of size at most polynomial in the formula size. If this belief could be proven correct, it would follow that NP 6= coNP, and hence P 6= NP, and this was the original reason research in proof complexity was initiated by Cook and Reckhow [18]. However, the goal of separating P and NP in this way remains very distant. Another, perhaps more recent, motivation for proof complexity is the connection to applied SAT solving. Any algorithm for deciding SAT defines a proof system in the sense that the execution trace on an unsatisfiable instance is itself a polynomial-time verifiable witness (often referred to as a refutation rather than a proof ). In the other direction, most SAT solvers in effect search for proofs in systems studied in proof complexity, and upper and lower bounds for these proof systems hence give information about the potential and limitations of such SAT solvers. In addition to running time, an important concern in SAT solving is memory consumption. In proof complexity, time and memory are modelled by proof size and proof space. It therefore seems interesting to understand these two complexity measures and how they are related to each other, and such a study reveals intriguing connections that are also of intrinsic interest to proof complexity. In this context, it is natural to concentrate on comparatively weak proof systems that are, or could plausibly be, used as a basis for SAT solvers. This talk will focus on such proof systems, and the purpose of these notes is to summarize the main points. Readers interested in more details can refer to, e.g, the survey [31].	algorithm;boolean satisfiability problem;co-np;computation;conflict-driven clause learning;conjunctive normal form;constraint learning;formal verification;gröbner basis;np (complexity);p versus np problem;polynomial;proof calculus;proof complexity;solver;time complexity	Jakob Nordström	2014		10.1007/978-3-319-09284-3_1	discrete mathematics;computer-assisted proof;probabilistically checkable proof;computer science;mathematics;proof complexity;algorithm	Logic	9.09325861164706	19.497232929995334	30597
1ba826b760f4fbd0b6d0302202f492897799b53d	on decidability and closure properties of language classes with respect to bio-operations	closure properties;pushdown automaton;reversal bounded;un decidable;counters;bio operations	We present general results that are useful in showing closure and decidable properties of large classes of languages with respect to biologically-inspired operations. We use these results to prove new decidability results and closure properties of some classes of languages under bio-operations such hairpin-inversion, the recently studied operation of pseudo-inversion, and other bio-operations. We also provide techniques for proving undecidability results. In particular, we give a new approach for proving the undecidability of problems for which the usual method of reduction to the undecidability of the Post Correspondence Problem seems hard to apply. Our closure and decidability results strengthen or generalize previous results.	british informatics olympiad;decision problem;np-completeness;post correspondence problem;unary operation;undecidable problem	Oscar H. Ibarra	2015	Natural Computing	10.1007/s11047-015-9500-y	combinatorics;discrete mathematics;computer science;mathematics;pushdown automaton;algorithm	Theory	-0.17935024161846966	21.944353250519526	30667
b29929c1f017f963eea30fa81c7d9a63b19467f3	routing trains through railway stations: model formulation and algorithms	railway transportation;safety requirement;maastricht university;europa;empirical study;rail transportation;modele mathematique;pays bas;netherlands;routing;nederlandse spoorwegen;railway network;formulacion;train operation;modelo matematico;operations research;digital archive;automatic generation;timetables;reseau ferroviaire;algorithme;scenario;algorithm;transporte ferroviaro;estacion ferroviaria;argumento;scheduling;open access;holanda;script;railroad station;mathematical model;scheduling problem;ordonamiento;exigence securite;encaminamiento;railroad stations;production scheduling;europe;publication;scientific;branch and cut;red ferroviaria;transport ferroviaire;gare ferroviaire;formulation;exigencia seguridad;institutional repository;ordonnancement;acheminement;algoritmo	In this paper we consider the problem of routing trains through railway stations. This problem occurs as a subproblem in a project which the authors are carrying out in cooperation with the Dutch railways. The project involves the analysis of future infrastructural capacity requirements in the Dutch railway network. Part of this project is the automatic generation and evaluation of timetables. To generate a timetable a hierarchical approach is followed: at the upper level in the hierarchy a tentative timetable is generated, taking into account the specific scheduling problems of the trains at the railway stations at an aggregate level. At the lower level in the hierarchy it is checked whether the tentative timetable is feasible with respect to the safety rules and the connection requirements at the stations. To carry out this consistency check, detailed schedules for the trains at the railway yards have to be generated. In this paper we present a mathematical model formulation for this detailed scheduling problem, based on the Node Packing Problem (NPP). Furthermore, we describe a solution procedure for the problem, based on a branch-and-cut approach. The approach is tested in an empirical study with data from the station ofZwolle in The Netherlands.	aggregate data;algorithm;branch and cut;mathematical model;requirement;routing;schedule (computer science);scheduling (computing);set packing	Peter J. Zwaneveld;Leo G. Kroon;H. Edwin Romeijn;Marc Salomon;Stéphane Dauzère-Pérès;Stan P. M. van Hoesel;Harrie W. Ambergen	1996	Transportation Science	10.1287/trsc.30.3.181	job shop scheduling;mathematical optimization;routing;computer science;engineering;scenario;operations management;publication;mathematical model;formulation;mathematics;scheduling;transport engineering;empirical research;operations research;scheduling;algorithm;branch and cut	Embedded	17.68457041316906	5.506410437847299	30682
63ff00c3f77817d823279091fa61853146b54dc6	the push tree problem	dynamic data replication;worst case analysis;dynamic data;network optimisation;steiner tree;shortest path problem	In this paper, we introduce the Push Tree problem which contains elements from both the Steiner Tree and the Shortest Path problem. The Push Tree problem deals with the trade-offs between the push and pull mechanisms used in information distribution and retrieval. We present some initial complexity results and analyse several heuristics. Moreover, we discuss what lessons can be learned from the static and deterministic Push Tree problem for more realistic scenarios characterised by high uncertainty and changing information request and update patterns.	heuristic (computer science);shortest path problem;steiner tree problem	Frédéric Havet;Marc Wennink	2001		10.1145/378580.378733	mathematical optimization;combinatorics;dynamic data;steiner tree problem;computer science;incremental decision tree;mathematics;distributed computing;shortest path problem;tree traversal;algorithm	AI	15.72399141843226	15.812923697063932	30742
37c799aba771409684d55f75b94adc622ab6ad32	chemical graph matching using transputer networks	graph matching	Abstract   This paper discusses the use of networks of transputers for the matching of the labelled graphs which are used to represent chemical structures in computer-based chemical information systems; in particular, the implementation of a relaxation algorithm for chemical substructure searching is described. Tests with a doubly-linked chain of transputers suggest that near-linear speedups can be obtained by a partitioning of the database which is to be searched; lesser speedups are obtained with other network configurations. Current work is described involving the exploitation of an alternative level of parallelism in the relaxation algorithm and the parallel implementation of an algorithm for the identification of the maximal substructures common to a pair of chemical compounds.	molecular graph;transputer	Andrew T. Brint;Valerie J. Gillet;Michael F. Lynch;Peter Willett;Gordon A. Manson;George A. Wilson	1988	Parallel Computing	10.1016/0167-8191(88)90133-0	parallel computing;computer science;theoretical computer science;machine learning;distributed computing;algorithm;matching	HPC	19.123333739630507	30.118543878397908	30761
02bfdb98439eb78e6ccb7e817dd44f66f04befa8	synchronization and maximality for very pure subsemigroups of a free semigroup		A very pure subsemigroup P o f a f ree semigroup A + is a subsemigroup of A + sa t is fy ing the condi t ion : fo r al l u v E A + • u v , vu ~ P =u003e u , v e e. The notion of v e r y pu re subsemigroup of a f ree semigroup plaies an important ro le in some problems o f a lgebra , in format ion theory and language theory . In pa r t i cu la r the bases o f v e r y pu re subsemig roups ,ca l led very pure codes,have been cons idered by M.P. Schutzenberger in the factor izat ions of f ree monoids and in the const ruc t ion of the bases of f ree Lie a lgebras [ 17-18 ] . Fu r the r v e r y pu re subsemigroups and codes have r e m a r k able synch ron i z i ng p roper t i es which are of re levan t in terest in the theory o f in format ion t ransmiss ion [ 2, 10, 12, 13 ] . Recent ly J. Pin [ 11 ] has shown that a charac ter iza t ion of the va r i e t y of locally testable languages [ 6 ] can be obta ined in terms of the not ion of v e r y pu re subsemigroups . The aim of this paper is to present some new resu l ts which are main ly concerned wi th the p rope r t i es o f synchron iza t ion and maximal i ty o f v e r y pu re subsemigroups and codes. In sect ion 2 a b r i e f account of the synch ron i z i ng p roper t i es o f v e r y pu re subsemig r o u p s , g e n e r a l i z i n g some p r e v i o u s l y pub l i shed resu l ts , is g iven. In sect ion 3 two d i f f e ren t not ions of max imal i ty for a v e r y pu re code are in t roduced: one wi th respect to code cond i t ion and the o ther wi th respect to the p r o p e r t y of be ing  v e r y pu re  .The main resu l t o f th is sect ion states that the two not ions are indeed equ iva len t under the hypothes is that the code is nondense .Several co ro l la r ies are d e r i v e d . O n e in p a r t i c u l a r , s h o w s that a maximal v e r y pu re code has to be in f in i te . F ina l l y in sect ion 4 some resu l ts concern ing the smal lest v e r y pu re subsemigroup conta in ing a g iven set X c A + _ are p roven .	free monoid	Aldo de Luca;Antonio Restivo	1979		10.1007/3-540-09526-8_34	discrete mathematics;topology;mathematics;algebra	Robotics	-4.0753598678329155	18.26645878507824	30763
9bed8fdc1036526831b1524713a405661f78d9c3	routing and transmitting problems in de bruijn networks	camino mas corto;multiprocessor interconnection networks;shortest path;shortest paths;codigo prefijo;time complexity;routing;plus court chemin;routing intelligent networks multiprocessor interconnection networks tree graphs hypercubes network topology multiprocessing systems upper bound shortest path problem broadcasting;prefix code;lower bound de bruijn networks interconnection networks radix d shortest path routing problem linear time complexity;transmitting;interconnection network;shortest path routing;multiprocessor interconnection networks computational complexity;complexite temps;computational complexity;linear time;borne inferieure;interconnection networks;prefix trees;encaminamiento;de bruijn graph;string matching;complejidad tiempo;de bruijn networks;lower bound;acheminement;cota inferior;code prefixe;reseau interconnexion	De Bruijn graphs, both directed and undirected, have received considerable attention as architecture for interconnection networks. In this paper, we focus on undirected de Bruijn networks of radix d and dimension n, denoted by U B(d; n). We rst discuss the shortest-path routing problem. We present properties of the shortest paths between any two vertices of U B(d; n) and propose two shortest-path routing algorithms, one of which has linear time complexity. Secondly, we study the transmitting problem. We establish a lower bound for the optimal transmitting time which implies in particular that the optimal transmitting problem is trivial for U B(d; n) when d 5. We present a transmitting scheme on undirected binary de Bruijn networks U B(2; n) with transmitting time n ? 1 for n 5, and conjecture that the optimal transmitting time is n ? 1 for U B(2; n), and n for U B(3; n) and U B(4; n).	algorithm;apollonian network;de bruijn graph;graph (discrete mathematics);interconnection;naruto shippuden: clash of ninja revolution 3;routing;shortest path problem;time complexity;transmitter;tree network	Zhen Liu;Ting-Yi Sung	1996	IEEE Trans. Computers	10.1109/12.537129	time complexity;combinatorics;computer science;theoretical computer science;mathematics;distributed computing;algorithm;computer network	Theory	18.45725689493525	31.52915429272041	30789
94a2b752343b0e06379ecbd6ff4ee3805ec0c033	a formalisation of the normal forms of context-free grammars in hol4	greibach normal forms;blow up;theorem provers;context free grammars;information presentation;conference paper;informal presentation;theorem prover;keywords blow up;context free grammar;technical presentations;normal form;computer science;formalisation	We describe the formalisation of the Chomsky and Greibach no rmal forms for context-free grammars (CFGs) using the HOL4 theor em prover. We discuss the varying degrees to which proofs that are straigh forward on pen and paper, turn out to be much harder to mechanise. While both pro ofs are of similar length in their informal presentations, the mechanised pro ofs for Greibach normal form blow-up considerably.	context-free grammar;context-free language;greibach normal form;hol (proof assistant)	Aditi Barthwal;Michael Norrish	2010		10.1007/978-3-642-15205-4_11	discrete mathematics;computer science;mathematics;context-free grammar;programming language;algorithm	NLP	-2.613746730006963	17.411683229601078	30900
6c57d4ea757f997505e45ffdef6793ef3bf28f83	a fixed-parameter tractable algorithm for matrix domination	arbre recherche;parameterized complexity;procesamiento informacion;algorithm analysis;probleme np complet;fixed parameter tractable;analysis of algorithm;algorithme;analysis of algorithms;algorithm;search trees;arbol investigacion;computational complexity;informatique theorique;information processing;graph algorithm;problema np completo;analyse algorithme;traitement information;search tree;cero;graph algorithms;analisis algoritmo;np complete problem;computer theory;algoritmo;informatica teorica;zero	MATRIX DOMINATION is the NP-complete problem of determining whether a given {0,1} matrix contains a set of k non-zero entries that are in the same row or same column as all other non-zero entries. Using a kernelization and search tree approach, we show the problem to be fixed-parameter tractable with running time O(n3 + 1.959kk5/2).  2004 Elsevier B.V. All rights reserved.	algorithm;cobham's thesis;dominating set;kernelization;np-completeness;parameterized complexity;search tree;time complexity	Mark Weston	2004	Inf. Process. Lett.	10.1016/j.ipl.2002.12.001	parameterized complexity;combinatorics;np-complete;domination analysis;information processing;computer science;analysis of algorithms;mathematics;search tree;computational complexity theory;algorithm	AI	18.514173142999613	25.86533877078978	30916
ae26ef499fecdf26520b484a23773ad2cc0f89b0	on sufficient conditions to identify in the limit classes of grammars from polynomial time and data	inference grammaticale;learning algorithm;temps polynomial;linear grammars;polynomial identification in the limit;algorithme apprentissage;grammaire lineaire;linear grammar;inferencia gramatical;gramatica lineal;polynomial time;identification in the limit;grammatical inference;learning artificial intelligence;algoritmo aprendizaje;tiempo polinomial;apprentissage intelligence artificielle	Linearity and determinism seem to be two essential conditions for polynomial learning of grammars to be possible. We propose a general condition valid for certain subclasses of the linear grammars given which these classes can be polynomially identified in the limit from given data. This enables us to give new proofs of the identification of well known classes of grammars, and to propose a new (and larger) class of linear grammars for which polynomial identification is thus possible.	algorithm;context-free grammar;context-free language;generic programming;grammar induction;language identification in the limit;linear algebra;linear grammar;p (complexity);parsing;polynomial;time complexity	Colin de la Higuera;José Oncina	2002		10.1007/3-540-45790-9_11	context-sensitive grammar;time complexity;combinatorics;discrete mathematics;computer science;artificial intelligence;machine learning;mathematics;algorithm	Theory	3.5405654858044744	17.68298589294912	30945
bf80910ec376e2b1946c75efe44ce9e7bb387829	systolic-based parallel architecture for the longest common subsequences problem	tolerancia falta;dynamic programming;longest common subsequences;red sistolica;programacion dinamica;architecture systeme;systolic algorithms;fault tolerant;multiprocessor;sous sequence commune la plus longue;linear time algorithm;dynamic program;natural extension;parallel computation;input output;algorithme;algorithm;temps calcul;longest common subsequence;fault tolerant system;automatic recognition;calculo paralelo;systolic network;fault tolerance;chaine;programmation dynamique;sistema tolerando faltas;reseau systolique;arquitectura sistema;systeme tolerant les pannes;modularity;parallel architecture;tiempo computacion;computation time;multiprocesador;system architecture;sequence;calcul parallele;tolerance faute;secuencia;reconocimiento automatico;reconnaissance automatique;algoritmo;multiprocesseur	In this paper we design a new and efficient systolic architecture for the longest common subsequences problem which is, given two finite strings on any alphabet, to recover a subsequence of maximal length of both strings. A natural extension to this problem is to determine the set of all longest common subsequences of the two given strings. First, we present a modular linear time algorithm on an input/output bounded and fault-tolerant semi-mesh systolic structure for the longest common subsequence problem. Then, we extend this algorithm to the set of all longest common subsequences problem. ( 1998 Elsevier Science B.V. All rights reserved.	algorithm;fault tolerance;input/output;longest common subsequence problem;longest increasing subsequence;maximal set;parallel computing;semiconductor industry;time complexity	Guillaume Luce;Jean Frédéric Myoupo	1998	Integration	10.1016/S0167-9260(98)00003-0	fault tolerance;parallel computing;longest increasing subsequence;computer science;theoretical computer science;longest common subsequence problem;mathematics;longest alternating subsequence;algorithm;systems architecture	Theory	17.524472486456947	29.50925394303904	30991
087f5edff3b14798fc2b932144cd72b077c03516	simpler and more general minimization for weighted finite-state automata	general minimization;theoretical limit;weighted finite-state automaton;methods work;minimum number;weight semirings;previous work;particular type;general np-complete;minimization algorithm;unique minimal automaton;efficient new minimization algorithm;finite state automata	Previous work on minimizing weighted finite-state automata (including transducers) is limited to particular types of weights. We present efficient new minimization algorithms that apply much more generally, while being simpler and about as fast. We also point out theoretical limits on minimization algorithms. We characterize the kind of “well-behaved” weight semirings where our methods work. Outside these semirings, minimization is not well-defined (in the sense of producing a unique minimal automaton), and even finding the minimum number of states is in general NP-complete and inapproximable.	algorithm;automata theory;automaton;dfa minimization;finite-state machine;np-completeness;transducer	Jason Eisner	2003			computer science;dfa minimization;algorithm	NLP	0.46531437670491943	21.10458687629477	31050
bcdf6b57f04da6de37230e61f1ef5774b8dabe45	disjunctive and conjunctive normal forms of pseudo-boolean functions	fonction booleenne;maximo;disjunctive normal form;boolean function;maximum;pseudoboolean function;monotonie;algorithme;minimo;algorithm;minimum;funcion booliana;monotonicity;fomrme normale conjonctive;fonction pseudo booleenne;value function;monotonia;conjunctive normal form;pseudo boolean;fomrme normale disjonctive;representation polynomiale;polynomial representation;algoritmo	After showing that every pseudo-Boolean function (i.e. real-valued function with binary variables) can be represented by a disjunctive normal form (essentially the maximum of several weighted monomials), the concepts of implicants and of prime implicants are analyzed in the pseudo-Boolean context, and a consensus-type method is presented for nding all the prime implicants of a pseudo-Boolean function. In a similar way the concepts of conjunctive normal form, implicates and prime implicates, as well as the resolution method are examined in the case of pseudo-Boolean functions. ? 2000 Elsevier Science B.V. All rights reserved.	conjunctive normal form;database normalization;disjunctive normal form;monomial;pseudo-boolean function	Stephan Foldes;Peter L. Hammer	2000	Discrete Applied Mathematics	10.1016/S0166-218X(00)00276-6	conjunctive normal form;combinatorics;discrete mathematics;monotonic function;maxima and minima;mathematics;negation normal form;bellman equation;boolean function;canonical normal form;disjunctive normal form;algorithm	AI	4.8941456505665135	20.720092383944895	31090
a9a63025db310312d8802c80d7621a6d74ff0f6a	some thoughts on reconciling various character set proposals	expanded character set;various character set proposal;universal language;tape code representation;subscripting technique;following respect;expanded set;minimal standard character subsets;communication purpose;standard expanded character set	Recently there have appeared several proposals for expanded character sets. In general, these differ in the following respects:<list><item>the number of characters in the expanded set, </item><item>the characters selected, </item><item>card and/or tape code representation, and </item><item>superscripting and subscripting techniques. </item></list> Currently, it seems to be popular to talk in terms of establishing a “standard expanded character set.” In the opinion of the author, this will prove to be extremely difficult in practice and undesirable in theory. This does not mean, however, that there should be no attempt to achieve “minimal standard character subsets” for communication purposes and “universal languages.”	character encoding	Edward A. Voorhees	1960	Commun. ACM	10.1145/367349.367353	arithmetic;mathematics;algorithm	Graphics	-3.7401693569030443	14.102540332040071	31151
7d9729002fd9d960fc0465b68ef99a10ad79a85d	kolmogorov equations based approximate analysis and sizing of constant work in process unreliable manufacturing system loops	manufacturing systems;service level;availability;constant work in process;demand rate;kolmogorov equations;computer architecture;equations manufacturing systems buffer storage optimization methods production control computer architecture control systems production systems state estimation productivity;work in process;process control;mathematical model;production;service level requirement kolmogorov equations constant work in process unreliable manufacturing system loops demand rate;approximation methods;kolmogorov equation;work in progress;manufacturing system;service level requirement;unreliable manufacturing system loops;work in progress manufacturing systems	CONWIP or constant work in process is an important manufacturing systems production discipline whereby within a CONWIP loop, there is a cap on the maximum amount of work in process that is permitted at any time. This allows for some mobile storage within the loop, albeit a bounded amount. Enforcement of the discipline is carried out at the entrance of the loop. The presence of a loop wide constraint creates indirectly a significant degree of solidarity among the machines within the loop. This property is exploited to develop a model of storage dynamics involving a number of (virtual) macro machines having some common states and interacting through some unknown parameters which are then estimated. Numerical results are presented and an application in minimal CONWIP loop storage sizing for a given demand rate and service level requirement is reported.	aggregate data;approximation algorithm;computation;concatenation;interaction;kanban (development);kolmogorov equations;mathematical model;mathematical optimization;modulo operation;numerical method;requirement	Fatima Zahra Mhada;Roland P. Malhamé	2008	2008 47th IEEE Conference on Decision and Control	10.1109/CDC.2008.4739279	control engineering;real-time computing;loop fission;engineering;work in process;process control;control theory;mathematics;statistics	HPC	7.671576214033651	8.366350155517036	31177
219fb11fa6e4867022a50dcabcdf8e596b19fcdf	the cycle time distribution of exponential cyclic queues	cycle time;population size	The cycle time distribution of a cyclic queue with two exponential servers is derived. Results show that when the population size N is large enough, the cycle time distribution is not sensitive to the ratio of service rates and asymptotically approaches an Erlangian distribution. If service rates are identical, however, the cycle time has an exact Erlangian distribution for any N.	circular buffer;time complexity	We-Min Chow	1980	J. ACM	10.1145/322186.322193	combinatorics;real-time computing;population size;cycle time variation;computer science;mathematics	Metrics	8.734008975687738	10.716624210265875	31192
3248643b70f3d822dd8d3ed702014802bca585d8	design and evaluation of an architecture for future smart grid service provisioning	energy efficiency;distributed power generation;renewable energy;service oriented architecture smart grid management energy efficiency;energy efficient;real time;energy management systems;field trial;service architecture;smart grid management;smart grids;ibcn;internet;technology and engineering;energy measurement;smart power grids;solar cell;energy consumption;clouds;electricity generation;grid service;power grid;internet services;power distribution economics;market players smart grid service provisioning distributed renewable electricity generators solar cells wind turbines common service architecture smart energy devices distributed energy management system public power grid energy consumption power network operators supply and demand;electricity;smart grids energy consumption electricity energy management energy measurement internet;wind turbine;supply and demand distributed power generation energy management systems power distribution economics smart power grids;service oriented architecture;energy management system;sple;energy management;supply and demand;design methodology;saas	The increase of distributed renewable electricity generators, such as solar cells and wind turbines, requires new energy management systems where real-time measurements and communication between end users, suppliers and utilities are vital. To address this need, we propose a common service architecture that allows houses with renewable energy generation and smart energy devices to plug into a distributed energy management system, integrated with the public power grid. The presented architecture facilitates end-users to optimize their energy consumption, enables power network operators to better balance supply and demand, and creates a platform where new market players (e.g. ESCOs) can easily provide new services. This service architecture has been implemented and is currently evaluated in a field trial with 21 users, of which we present the initial results.	control system;news aggregator;provisioning;real-time clock;smart device;software deployment;solar cell	Matthias Strobbe;Tom Verschueren;Kevin Mets;Stijn Melis;Chris Develder;Filip De Turck;Thierry Pollet;Stijn Van de Veire	2012	2012 IEEE Network Operations and Management Symposium	10.1109/NOMS.2012.6212052	embedded system;simulation;computer science;service-oriented architecture;smart grid;efficient energy use;law	Embedded	1.1712911023169925	5.962090890843958	31227
9c5186a0cdab06692d72df05e8a7edf296318caf	an efficient algorithm finds noticeable trends and examples concerning the cerny conjecture	longueur mot;automata estado finito;automate deterministe;efficient algorithm;deterministic finite automaton;palabra finita;discrete mathematics;inicializacion;mot fini;complexity;recurrence;upper bound;synchronisation;algorithm;deterministic automaton;word length;synchronization;informatique theorique;recurrencia;automata determinista;longitud palabra;finite automaton;sincronizacion;automate fini;synchronizing word;borne superieure;cerny conjecture;initialization;initialisation;finite word;cota superior;computer theory;informatica teorica	A word w is called synchronizing (recurrent, reset, directed) word of a deterministic finite automaton (DFA) if w sends all states of the automaton on a unique state. Jan Cerny had found in 1964 a sequence of n-state complete DFA with shortest synchronizing word of length (n–1)2. He had conjectured that it is an upper bound for the length of the shortest synchronizing word for any n-state complete DFA.#R##N##R##N#The examples of DFA with shortest synchronizing word of length (n–1)2 are relatively rare. To the Cerny sequence were added in all examples of Cerny, Piricka and Rosenauerova (1971), of Kari (2001) and of Roman (2004).#R##N##R##N#By help of a program based on some effective algorithms, a wide class of automata of size less than 11 was checked. The order of the algorithm finding synchronizing word is quadratic for overwhelming majority of known to date automata. Some new examples of n-state DFA with minimal synchronizing word of length (n–1)2 were discovered. The program recognized some remarkable trends concerning the length of the minimal synchronizing word.	algorithm;synchronizing word	Avraham Trakhtman	2006		10.1007/11821069_68	synchronization;combinatorics;discrete mathematics;computer science;mathematics;finite-state machine;algorithm	Theory	12.663999666019894	29.23658050234473	31307
0b0768807284e4237b739bf120f7fd58c98934f7	faster algorithms for incremental topological ordering	graph search;directed acyclic graph;online algorithm;random sampling;search method;priority queue	We present two online algorithms for maintaining a topological order of a directed acyclic graph as arcs are added, and detecting a cycle when one is created. Our first algorithm takes O(m) amortized time per arc and our second algorithm takes O(n/m) amortized time per arc, where n is the number of vertices and m is the total number of arcs. For sparse graphs, our O(m) bound improves the best previous bound by a factor of log n and is tight to within a constant factor for a natural class of algorithms that includes all the existing ones. Our main insight is that the two-way search method of previous algorithms does not require an ordered search, but can be more general, allowing us to avoid the use of heaps (priority queues). Instead, the deterministic version of our algorithm uses (approximate) median-finding; the randomized version of our algorithm uses uniform random sampling. For dense graphs, our O(n/m) bound improves the best previously published bound by a factor of n and a recent bound obtained independently of our work by a factor of log n. Our main insight is that graph search is wasteful when the graph is dense and can be avoided by searching the topological order space instead. Our algorithms extend to the maintenance of strong components, in the same asymptotic time bounds.	amortized analysis;approximation algorithm;directed acyclic graph;graph traversal;monte carlo method;online algorithm;priority queue;randomized algorithm;sampling (signal processing);sensor;sparse matrix;topological sorting	Bernhard Haeupler;Telikepalli Kavitha;Rogers Mathew;Siddhartha Sen;Robert E. Tarjan	2008		10.1007/978-3-540-70575-8_35	sampling;online algorithm;mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;voltage graph;moral graph;best-first search;programming language;topological sorting;complement graph;priority queue;directed acyclic graph;algorithm	Theory	20.141171373789774	23.561591610197244	31323
54d3d8d01cd5536b6f17a0d598f839213121e834	approximating sparse covering integer programs online	covering integer programs;linear programming;online algorithms	A covering integer program (CIP) is a mathematical program of the form: min{cx | Ax ≥ 1, 0 ≤ x ≤ u, x ∈ Z}, where A ∈ R ≥0 , c, u ∈ R n ≥0. In the online setting, the constraints (i.e., the rows of the constraint matrix A) arrive over time, and the algorithm can only increase the coordinates of x to maintain feasibility. As an intermediate step, we consider solving the covering linear program (CLP) online, where the requirement x ∈ Z is replaced by x ∈ R. Our main results are (a) an O(log k)-competitive online algorithm for solving the CLP, and (b) an O(log k · log l)-competitive randomized online algorithm for solving the CIP. Here k ≤ n and l ≤ m respectively denote the maximum number of non-zero entries in any row and column of the constraint matrix A. By a result of Feige and Korman, this is the best possible for polynomial-time online algorithms, even in the special case of set cover (where A ∈ {0, 1} and c, u ∈ {0, 1}). The novel ingredient of our approach is to allow the dual variables to increase and decrease throughout the course of the algorithm. We show that the previous approaches, which either only raise dual variables, or lower duals only within a guess-and-double framework, cannot give a performance better than O(log n), even when each constraint only has a single variable (i.e., k = 1).	duality (optimization);emoticon;integer programming;linear programming;online algorithm;randomized algorithm;set cover problem;sparse;time complexity	Anupam Gupta;Viswanath Nagarajan	2012	Math. Oper. Res.	10.1007/978-3-642-31594-7_37	online algorithm;mathematical optimization;combinatorics;discrete mathematics;computer science;linear programming;mathematics	Theory	23.83135464688151	13.71471125937199	31366
3cb93efec028278b437a4e42997f7ba6670626b7	an attempt to dynamically break symmetries in the social golfers problem	search space;combinatorial problems;satisfiability;constraint programming	A number of different satisfaction and optimisation combinatorial problems have recently been approached with constraint programming over the domain of finite sets, for increased declarativity and efficiency. Such problems where one tries to find sets of values that satisfy some conditions often present much symmetry on variables and values. In particular, the social golfers problem encompasses many possible symmetries. Allowing symmetric solutions increases search space unnecessarily, thus multiplying solution time. Therefore, ordering constraints have been proposed and incorporated in set solvers. However, such constraints are imposed statically in the global problem model and are unable to detect symmetries that still occur in sub-problems after a partial labelling. In this paper we discuss how to overcome this and present an approach that sequentially labels variables with an Intelligent Backtracking scheme that avoids such symmetries by dynamically disallowing the assignment of indistinguishable values in the golfers problem. Experimental results show that this approach outperforms previous ones, recently achieved by the constraint programming community, namely over sets. Unfortunately, the current method is incomplete and may loose solutions. Nevertheless, results are correct and show that similar techniques can be used efficiently to obtain faster solutions.	backtracking;c++;constraint programming;emoticon;entity;mathematical optimization;natural language;out-of-order execution;propagator;software propagation;symmetry breaking;verification and validation	Francisco Azevedo	2006		10.1007/978-3-540-73817-6_2	mathematical optimization;combinatorics;discrete mathematics;mathematics	AI	22.416331054224116	4.938737572210593	31412
1ecc0d6edeedddeab6e3e7981a620d1910a04881	a randomized parallel 3d convex hull algorithm for coarse grained multicomputers	parallel algorithm;local computation;convex hull;coarse grained multicomputer	We present a randomized parallel algorithm for constructing the 3D convex hull on a generic p-processor coarse grained multicomputer with arbitrary interconnection network and n/p local memory per processor, where ~ z p’+’ (for some arbitrarily small c > O). For any given set of n points in 3-space, the algorithm computes the 3D convex hull, with high probability, in 0(w) local computation time and 0(1 ) communication phases with at most 0(~) data sent/received by each processor. That is, with high probability, the algorithm computes the 3D convex hull of an arbitrary point set in time 0(* + I’~,P), where I’~,P denotes the time complexity of one communication phase. In the terminology of the BSP model, our algorithm requires, with high probability, O(1) supersteps and a synchronization period @(%). In the LogP model, the execution time of our algorithm is asymptotically optimaJ for several archit ect ures. ● This work was partially supported by the Natural Sciences and Engineering Research Council of Canada and the ESPRIT Basic Research Actions Nr. 7141 (ALCOM II). tschool of Computer Science, Carleton Univer.9ity, Ottawa, Canada KIS 5B6. Email: dehne@scs. carlet on. ca ~J@t. of Computer Science, York University, NOrth York, Canada M3J 1P3. Email: {deng, dyrnond}@cs .yorku. ca 5 Dept. of Computer Science, Utrecht University, 3508 TB Utrecht, The Netherlands. Email: andreas@cs .ruu. nl II School Of EE and Dept. of Computer Sci., Purdue University, West Lafayette, IN 47907, USA. Email: ashf aq~cs .purdue. edu Permission to make. digitirl/llarci copies of :111or p:~rt of [his nl:llcri:ll wiLhout fee is granted provided lhat the ct]pics ;Ire II(J1 m:ldc {Jr dis~l-il,~itcd for profit or commercial advantage, the ACM copyrighl/sccvcr notice, the title of the publication and its date appear, and notice is given that copyright is by permission of the Association for Computin: Machinery, Inc. (ACM). To copy otherwise, to repuhlish,[o post on servers or LO redistribute to lists, requires specific permission and/cor ftx, SPAA’95 Santa Bmlxm CA USA(”) 1995 ACM O-89791 -717-0/9.5/07.S3.50	computation;computer science;convex hull;email;institute of radio engineers;interconnection;kaspersky internet security;limbo;logp machine;parallel algorithm;parallel computing;randomized algorithm;run time (program lifecycle phase);small-c;terabyte;time complexity;with high probability	Frank Dehne;Xiaotie Deng;Patrick W. Dymond;Andreas Fabri;Ashfaq A. Khokhar	1995		10.1145/215399.215410	mathematical optimization;combinatorics;parallel computing;computer science;theoretical computer science;convex hull;parallel algorithm	Theory	12.927574947923713	31.586633826707356	31428
bbcc07e22ffa752887a5ca363ade76a1ebfebf04	assembly line balancing in a mixed-model sequencing environment with synchronous transfers	cycle time;mixed model assembly lines;assembly line balancing;mixed model;approximate solution;cyclic scheduling;mathematical model;multiple model;lower bound	We consider the assembly line balancing problem in a mixed-model line which is operated under a cyclic sequencing approach. We specifically study the problem in an assembly line environment with synchronous transfer of parts between the stations. We formulate the assembly line balancing problem with the objective of minimizing total cycle time by incorporating the cyclic sequencing information. We show that the solution of a mathematical model that combines multiple models into a single one by adding up operation times constitutes a lower bound for this formulation. As an approximate solution to the original problem, we propose an alternative formulation that suggests to minimize the maximum subcycle time. We also develop a simple heuristic approach for this alternative problem. We provide computational results that compare the various approaches we discuss. 2002 Elsevier Science B.V. All rights reserved.	algorithmic efficiency;approximation algorithm;computation;heuristic;iteration;mathematical model;mixed model;production leveling;resultant	Selçuk Karabati;Serpil Sayin	2003	European Journal of Operational Research	10.1016/S0377-2217(02)00764-6	mixed model;mathematical optimization;simulation;cycle time variation;operations management;mathematical model;mathematics;upper and lower bounds;statistics	Robotics	14.009750531669695	5.244059165859918	31441
c71e083a6343be6f3b08b8e1a5ae08f71e6db840	estimation of retrial rate in a retrial queue	sistema fila espera;operador integral;file attente;systeme attente;approximation asymptotique;taux appel;systeme markov;commande;secuencia repetida;sequence repetee;formulacion;queue;etude methode;estudio metodo;estimator;estimador;decision estadistica;operateur integral;markovian system;file avec rappel;scheduling;queueing system;integral operator;retrial queue;statistical inference;ordonamiento;control;method study;asymptotic approximation;statistical decision;file m m 1;repeated sequence;fila espera;sistema markov;formulation;decision statistique;ordonnancement;aproximacion asintotica;variance;variancia;estimateur	We consider estimation of the rate of retrials for anM/M/1 repeated orders queueing system with the help of integral estimators. The main problem is connected with the statistical accuracy of the estimator, i.e. with its variance. We derive a simple asymptotic formula for this variance when the interval of observation is long. In connection with this problem we introduce a new Markovian description of retrial queues.		Gennadi Falin	1995	Queueing Syst.	10.1007/BF01150411	mathematical optimization;statistical inference;estimator;repeated sequence;calculus;formulation;mathematics;variance;scheduling;queue;scientific control;statistics	Metrics	9.333492329974966	12.009482427341728	31451
649870ea48b5ca108237a708d7c05faf6f9d1f14	opportunistic data structures with applications	database indexing;compression algorithm;data set;theoretical framework;data compression;succinct data structure;glimpse tool;sublinear query time complexity;auxiliary information;opportunistic data structures;search;data structures indexing entropy costs tree data structures plugs computer science fault tolerance postal services data engineering;performance improvement;succinct suffix array;computational complexity;database theory data structures data compression database indexing computational complexity;data structures;inf 01 informatica;storage capacity;indexation;sublinear space complexity;entropy;suffix array data structures;data structure;data indexing;database theory;query performance;sublinear space complexity opportunistic data structures data compression data indexing entropy data set query performance search succinct suffix array suffix tree data structures suffix array data structures glimpse tool sublinear query time complexity;structural properties;suffix tree data structures	In this paper we address the issue of compressing and indexing data. We devise a data structure whose space occupancy is a function of the entropy of the underlying data set. We call the data structure opportunisticsince its space occupancy is decreased when the input is compressible and this space reduction is achieved at no significant slowdown in the query performance. More precisely, its space occupancy is optimal in an information-content sense because a textT [1; u℄ is stored usingO(Hk(T )) + o(1) bits per input symbol in the worst case, where Hk(T ) is thekth order empirical entropy of T (the bound holds for any fixed k). Given an arbitrary stringP [1; p℄, the opportunistic data structure allows to search for the o occurrences of P in T in O(p + o log u) time (for any fixed > 0). If data are uncompressible we achieve the best space bound currently known [12]; on compressible data our solution improves the succinct suffix array of [12] and the classical suffix tree and suffix array data structures either in space or in query	alphabet (formal languages);best, worst and average case;data structure;entropy (information theory);suffix array;suffix tree	Paolo Ferragina;Giovanni Manzini	2000		10.1109/SFCS.2000.892127	data compression;data structure;computer science;theoretical computer science;data mining;database;programming language;algorithm	Theory	11.926295874656146	26.844534379362642	31470
28a2cc24cf7094edd51e62720d7b1e376db72450	solutions of twisted word equations, edt0l languages, and context-free groups		We prove that the full solution set of a twisted word equation with regular constraints is an EDT0L language. It follows that the set of solutions to equations with rational constraints in a contextfree group (= finitely generated virtually free group) in reduced normal forms is EDT0L. We can also decide whether or not the solution set is finite, which was an open problem. Moreover, this can all be done in PSPACE. Our results generalize the work by Lohrey and Sénizergues (ICALP 2006) and Dahmani and Guirardel (J. of Topology 2010) with respect to complexity and with respect to expressive power. Both papers show that satisfiability is decidable, but neither gave any concrete complexity bound. Our results concern all solutions, and give, in some sense, the “optimal” formal language characterization. 1998 ACM Subject Classification F.2.2 Nonnumerical Algorithms and Problems, F.4.2 Grammars and Other Rewriting Systems, F.4.3 Formal Languages	database normalization;formal language;icalp;linear temporal logic to büchi automaton;pspace;rewriting;twisted	Volker Diekert;Murray Elder	2017		10.4230/LIPIcs.ICALP.2017.96	natural language processing;linguistics;programming language	PL	-3.3419280403521014	18.26061209721015	31472
179dee6f63ee6654288728d896713d7e2a18a6b4	tape- and time-bounded turing acceptors and afls: extended abstract	complexity class;formal language	Complexity classes of formal languages defined by time- and tape-bounded Turing acceptors are studied with the aim of showing sufficient conditions for these classes to be AFLs and to be principal AFLs.	formal language;turing	Ronald V. Book;Sheila A. Greibach;Ben Wegbreit	1970		10.1145/800161.805154	complexity class;formal language;discrete mathematics;computer science;theoretical computer science;mathematics;algorithm	Theory	-1.6517661654461628	22.194183524578772	31485
24a7982fa58c66c6ad64783d6b1b9cede0af3ab0	multiple-lot lot streaming in a two-stage assembly system		In this chapter, we address a lot streaming problem for a two-stage assembly system involving multiple lots with the objective of minimizing the makespan. Each lot consists of items of a unique product type. We designate this problem as a multiple-lot, two-stage assembly, lot streaming problem (ML-TSALSP) which combines two key decisions: lot splitting and lot sequencing. While the problem of scheduling in such a machine environment has been addressed in the literature, our problem is different because of the presence of the streaming of a lot over the stages. We derive some structural properties for this problem, and develop a branch-and-bound-based solution procedure that relies on effective lower bounds and dominance properties. Our computational investigation reveals the efficacy of the proposed branch-and-bound-based methodology for this problem.		Liming Yao;Subhash C. Sarin	2014		10.1007/978-1-4614-9056-2_15	job shop scheduling;product type;scheduling (computing);distributed computing;branch and bound;computer science	Robotics	15.668053995082225	7.799769921637442	31575
78a855e055e5accf71fc70c1e81ebfb61ee520f5	solving nonlinear single-facility network location problems	location problem;probleme localisation;reseau;481 location on networks;red;185;problema localizacion;network	"""We present a general approach to solving nonlinear single-facility network location problems. We assume that cost is any convex function of distances, and solve this class of problem by solving convex subproblems on """"treelike segments"""" into which the network is decomposed. We show that only a fraction of treelike segments generally need be examined, and that our method results in a reasonably efficient general-purpose algorithm. The algorithm is particularly effective on real-world as opposed to random networks, and when the cost function is nondecreasing and """"semiseparable,"""" as are many popular cost functions. Finally, we describe theoretical complexity bounds and computational experience."""	nonlinear programming	John Hooker	1986	Operations Research	10.1287/opre.34.5.732	mathematical optimization;computer science;calculus;mathematics;mathematical economics	Theory	22.324316335297844	11.42630855735684	31586
1da594fee5f5dd719d80f67d053dac09d9def904	on codification in finite abstract random automata			automaton	Silviu Guiasu	1968	Information and Control	10.1016/S0019-9958(68)90346-X	quantum finite automata;automata theory;ω-automaton	Theory	-2.4539816339662384	22.288762592880325	31636
9e82adfdf33248c22d3ca2d123688e543b74acc6	dynamic usage of capacity for arrivals and departures in queue minimization	optimal solution;minimization;piecewise linear;capacity allocation;complexity theory;lotsenassistenz;airports;resource manager;resource management;fixed time;traffic flow;linear programming methods queue minimization air traffic airport traffic flow control flow management capacity allocation integer solution integer problems;integer programming;linear programming;airports resource management minimization optimization complexity theory aircraft throughput;linear program;optimization;linear programming airports integer programming;aircraft;throughput	To analyse and solve air traffic problems of an airport in the time scope of, for instance, 24 hours we have to control traffic flows of aggregated flights rather than individual flights. Hence, queue arising from flow management is the unique physical value characterising it. Key performance indicators such as throughput, delay, etc. in some way or another depend on occurrence and behavior of arrival and departure queues. Therefore, we study and investigate properties of weighted queues sum as a function of capacity allocation. It results in straightforward and effective O(N2) algorithms giving integer solution for the problems of weighted queues sum minimization at the end of a time period and total weighted queues sum minimization over a time period with arbitrary number of considered time intervals. These integer problems have been solved earlier with linear programming methods which have the best complexity of O(N3.5L). Here two initial solutions depending on the weight of corresponding queues are given. It is also shown which intervals are the key intervals for reallocation of capacity in order to reach desired flow variation. Moreover, the minimal finite solution set, which contains an optimal flow for each weight value in the mentioned problems, can be easily constructed. The developed algorithms find optimal solutions in “interval-to-interval” techniques. The obtained solution method gives us the tool for controlling and managing of flow construction and queue outcome depending on strategies we follow. It gives in maximal 0.1 seconds an optimal solution of considered problems for the whole day with interval length from 5 to 15 minutes.	airport security;algorithm;capacity optimization;linear programming;mathematical optimization;maximal set;memory management;pareto efficiency;piecewise linear continuation;throughput	Olga Gluchshenko	2011	2011 IEEE International Conference on Control Applications (CCA)	10.1109/CCA.2011.6044451	mathematical optimization;real-time computing;operations management;mathematics;fork–join queue	Theory	14.14976686925846	8.520741749859747	31679
201c9cb46ca233556fc20a6431fab946a334d0d9	on the relationship between ll(1) and lr(1) grammars	lri grammars;lalri grammars;additional key words and phrases: lli grammars	It is shown that every p-reduced LL(I) grammar is LALR(I) and, as a corollary, that every A-free LL(I) grammar is SLR(I) A partial converse to this result is also demonstrated: If there is at most one marked rule m the basis of every state set in the canonical collection of sets of LR(k) items for a grammar G in which S i ~ S-/ts impossible, then G ~s LL(k).	canonical lr parser;ll parser	John C. Beatty	1982	J. ACM	10.1145/322344.322350	arithmetic;algorithm	Theory	-1.8142205814394827	18.05180549109125	31725
c2a1f8b4f98befd2749acd1260313a7317c987b1	data analysis and optimization for (citi)bike sharing	computational sustainability;optimization;bike sharing	Bike-sharing systems are becoming increasingly prevalent in urban environments. They provide a low-cost, environmentally-friendly transportation alternative for cities. The management of these systems gives rise to many optimization problems. Chief among these problems is the issue of bicycle rebalancing. Users imbalance the system by creating demand in an asymmetric pattern. This necessitates action to put the system back in balance with the requisite levels of bicycles at each station to facilitate future use. In this paper, we tackle the problem of maintaing system balance during peak rush-hour usage as well as rebalancing overnight to prepare the system for rush-hour usage. We provide novel problem formulations that have been motivated by both a close collaboration with the New York City bike share (Citibike) and a careful analysis of system usage data. We analyze system data to discover the best placement of bikes to facilitate usage. We solve routing problems for overnight shifts as well as clustering problems for handling mid rush-hour usage. The tools developed from this research are currently in daily use at NYC Bike Share LLC, operators of Citibike.	cluster analysis;computation;display resolution;feedback;lunar lander challenge;mathematical optimization;optimization problem;provable security;routing;usage data	Eoin O'Mahony;David B. Shmoys	2015			simulation;computer science;artificial intelligence	AI	4.506979706955516	9.305579958984671	31853
d7e14873f6653287d8fc5fed7c65625fc73493d6	improved algorithms for the approximate k-list problem in euclidean norm		We present an algorithm for the approximate k-List problem for the Euclidean distance that improves upon the Bai-Laarhoven-Stehlé (BLS) algorithm from ANTS’16. The improvement stems from the observation that almost all the solutions to the approximate k-List problem form a particular configuration in n-dimensional space. Due to special properties of configurations, it is much easier to verify whether a k-tuple forms a configuration rather than checking whether it gives a solution to the k-List problem. Thus, phrasing the k-List problem as a problem of finding such configurations immediately gives a better algorithm. Furthermore, the search for configurations can be sped up using techniques from Locality-Sensitive Hashing (LSH). Stated in terms of configurationsearch, our LSH-like algorithm offers a broader picture on previous LSH algorithms. For the Shortest Vector Problem, our configuration-search algorithm results in an exponential improvement for memory-efficient sieving algorithms. For k = 3, it allows us to bring down the complexity of the BLS sieve algorithm on an n-dimensional lattice from 2 to 2 with the same space-requirement 2. Note that our algorithm beats the Gauss Sieve algorithm with time resp. space requirements of 2 resp. 2, while being easy to implement. Using LSH techniques, we can further reduce the time complexity down to 2 while retaining a memory complexity of 2.	algorithmic efficiency;approximation algorithm;euclidean distance;general number field sieve;lattice problem;locality of reference;locality-sensitive hashing;requirement;search algorithm;time complexity;lsh	Gottfried Herold;Elena Kirshanova	2017		10.1007/978-3-662-54365-8_2	euclidean domain;euclidean shortest path;euclidean distance;magnitude;euclidean distance matrix	Theory	12.761586510226058	26.415704586714668	31886
6e36fa502e17507d1226455d7b262e2396fcc3fc	multiagent systems for the hoist scheduling problem	hoists;multiagent system;materials handling scheduling multi agent systems hoists;multi agent systems;multiagent systems optimal scheduling processor scheduling rails job production systems contracts computer science chemical products routing electric breakdown;transfer operator;scheduling;materials handling;scheduling problem;self assigned priorities multiagent systems hoist scheduling problem transfer operations auction mechanisms	In this article a new approach for solving the Hoist Scheduling Problem is proposed. It is based on two distinct, though coupled, multiagent systems. The fist system is responsible for making a decision about the input date for the next job, while the second system is concerned with the assignment of transfer operations of jobs between tanks to the hoists. These multiagent systems use two different types of auction mechanisms to attain cooperation. Remaining conflicts are solved through self-assigned priorities. Partial results are proposed and issues related to further work on the topic are raised.	agent-based model;javascript syntax;job stream;multi-agent system;scheduling (computing)	Kwang Hyung Lee;David Jégou;Pierre Baptiste	2001		10.1109/FUZZ.2001.1009021	fair-share scheduling;hoist;fixed-priority pre-emptive scheduling;job shop scheduling;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;artificial intelligence;two-level scheduling;multi-agent system;distributed computing;round-robin scheduling;scheduling	AI	11.95995937984154	6.828263498017011	31887
b80e8d708c4fb7ed7496eb2ac4d68db2e76e0823	approximating the traveling tournament problem with maximum tour length 2	approximate algorithm;benchmark problem;traveling tournament problem;lower bound	  We consider the traveling tournament problem, which is a well-known benchmark problem in tournament timetabling. The most  important variant of the problem imposes restrictions on the number of consecutive home games or away games a team may have.  We consider the case where at most two consecutive home games or away games are allowed. We show that the well-known independent  lower bound for this case cannot be reached and present an approximation algorithm that has an approximation ratio of       3/2+\frac6n-</font >43/2+\frac{6}{n-4}, where n is the number of teams in the tournament. In the case that n is divisible by 4, this approximation ratio improves to       3/2+\frac5n-</font >13/2+\frac{5}{n-1}.    	maximum length sequence;traveling tournament problem	Clemens Thielen;Stephan Westphal	2010		10.1007/978-3-642-17514-5_26	simulation;mathematics;upper and lower bounds	NLP	19.839422557324752	16.650472017715696	31898
cc77aa456800b57e78165f6caf624db8ce152dfc	pair algebra and its application to automata theory	automata theory		automata theory;automaton	Juris Hartmanis;Richard Edwin Stearns	1964	Information and Control	10.1016/S0019-9958(64)90181-0	combinatorics;discrete mathematics;theory of computation;quantum finite automata;computer science;nested word;automata theory;ω-automaton;mathematics;graph algebra;dfa minimization;mobile automaton;timed automaton;algorithm;algebra	Logic	-2.2691939754458152	21.891295204648042	31920
042da39e531f55f810e0a2ba49b46ab4d2631144	decentralized data fusion and active sensing with mobile sensors for modeling and predicting spatiotemporal traffic phenomena	my publications;article	The problem of modeling and predicting spatiotemporal traffic phenomena over an urban road network is important to many traffic applications such as detecting and forecasting congestion hotspots. This paper presents a decentralized data fusion and active sensing (DFAS) algorithm for mobile sensors to actively explore the road network to gather and assimilate the most informative data for predicting the traffic phenomenon. We analyze the time and communication complexity of DFAS and demonstrate that it can scale well with a large number of observations and sensors. We provide a theoretical guarantee on its predictive performance to be equivalent to that of a sophisticated centralized sparse approximation for the Gaussian process (GP) model: The computation of such a sparse approximate GP model can thus be parallelized and distributed among the mobile sensors (in a Google-like MapReduce paradigm), thereby achieving efficient and scalable prediction. We also theoretically guarantee its active sensing performance that improves under various practical environmental conditions. Empirical evaluation on real-world urban road network data shows that our DFAS algorithm is significantly more time-efficient and scalable than state-ofthe-art centralized algorithms while achieving comparable predictive performance.	approximation algorithm;broadcasting (networking);centralized computing;communication complexity;computation;gaussian process;hotspot (wi-fi);information;mapreduce;network congestion;parallel computing;programming paradigm;scalability;sensor;software deployment;sparse approximation;sparse matrix	Jie Chen;Kian Hsiang Low;Colin Keng-Yan Tan;Ali Oran;Patrick Jaillet;John M. Dolan;Gaurav S. Sukhatme	2012			simulation;computer science;data science;data mining	Mobile	6.142016387968471	31.458352876632812	31945
59ca3ee9ae090e2fd697fec4d54f37595792bfa3	intelligent wireless ev fast charging with smfir. technology	smfir;wireless fast charging;electric vehicle;olev	While introducing electric vehicles EVs into the massive market volume is important for the global environmental protection and reduced dependence on the petroleum depletion, the customers' acceptance on electric vehicles is one of critical elements toward future eco-friendly transportation. Transportation sectors are responsible for approximately 25% of global CO2 emissions. One of the major issues in market penetration of electric vehicles is establishing enough numbers of charging stations in view of customers' convenience. Wireless and fast charging system can contribute significantly to establishing charging stations for EV with improved safety and convenience. Applying the shaped magnetic field in resonance SMFIR® technology enables the EV battery charging wirelessly without having any plug or wire. The power capacity can be high enough to reduce the charging time to less than half an hour depending on the energy storage capacity of battery. In this paper, the main features of intelligent wireless EV fast charging system operating at stationary are described with the technical aspect of system architecture including the development of billing and center operational management system.	extended validation certificate	In-Soo Suh	2011	Transactions of the SDPS		trickle charging;embedded system;simulation;engineering;electrical engineering	Visualization	2.7656930805343873	8.164327886559251	31958
4e181e3252d4eece69bc71ae297963e64cabf489	nonlocal description of the time characteristic for input flows by means of observations		In this paper, we propose a nonlocal method for describing and studying temporal characteristics of input flows moving in space. Here, the intervals between the first arrivals of neighboring groups rather than between each neighboring—customers are used for description. Various heuristic algorithms are proposed that determine successive moments when the first customers from various groups actually arrive to the system and allow one to find their distribution. Such an approach to the description of input flows is shown to be effective for determining the distribution of real flows of various physical natures (for example, traffic flow).	aharonov–bohm effect;algorithm;heuristic;nonlocal lagrangian;random number generation	Mikhail A. Fedotkin;A. M. Fedotkin;E. V. Kudryavtsev	2015	Automatic Control and Computer Sciences	10.3103/S0146411615010034	mathematical optimization;discrete mathematics;calculus;mathematics	Metrics	10.032388690058902	11.363108885047243	31975
b47c80d90d6b194b3599819e285a19c72439580c	cglive - a real time power monitoring solution for enterprises	databases;intelligent green it management;software;green products;temperature sensors;energy audit;workstations green products monitoring power demand temperature sensors databases software;enterprise network environment cglive realtime power monitoring solution energy monitoring software tool energy consumption pc;power aware computing;monitoring;sensor networks;business data processing;workstations;remote monitoring green it intelligent green it management energy audit m2m technology sensor networks performance optimization;remote monitoring;green it;computerised monitoring;power demand;performance optimization;power aware computing business data processing computerised monitoring;m2m technology	CGLive is a real time energy monitoring software tool that could be used to monitor and reduce energy consumption of PC's in a enterprise network environment. Working of CGLive has been tested in a lab environment and was found to be successful. Dashboard of CGLive can show current status of a work station, energy consumed by it and also the Process which consume higher percentage of CPU. CGLive can issue commands towards ensuring shutdown, logon, logoff and hibernate a particular machine.	central processing unit;dashboard;login;programming tool;shutdown (computing)	G. Subrahmanya V. R. K. Rao;S. Ramesh;V. Arun Muthuraj;Karthik Sundararaman;Jinka Parthasarathi	2011	2011 IEEE/ACM International Conference on Green Computing and Communications	10.1109/GreenCom.2011.43	embedded system;real-time computing;engineering;operating system	EDA	1.0670255800729687	31.23076495585522	32008
62f6630dd1971a0b23ff885083593d2863d069b9	a general treatment of rearrangement problems in a linear storage	reference string;head;record;activity model;rearrangement;file;order statistic;movement;cost function;optimal strategies;allocation	I)lffercnt cost models of allocation and rearrangen,cnt of a ~¢1 {!' I, t:~ . . . . . /';,} of files are investigated in the paper It is as,,t,n:ed that the distribution p,~ t ) of the reference string .$( t ) dcpend~ on the users' activity. F, r large values of n a limitin.g pr,,cess is used and a contintmus rearrangement model ;s imroduced, ,n which the integral formulas can be handled ~,impler than those suvamation formulas in the discrete case. S~me open problems could be solved by the help of this treatment. The connection with order statistical treatement is f,,und and used for a simple u:er activity model. 1he formulas ¢,tn be u.~;ed to approximate the average head movement, in case of different distribution,, in optimal deterministic file ~til ~caLit~ii problems. ' )etermiHstic and stochastic strategies of allc,cation , nd rearrangerqent are studied and compared.	approximation algorithm;classical nucleation theory;function model	Mátyás Arató;András A. Benczúr	1982	Perform. Eval.	10.1016/0166-5316(82)90003-7	order statistic;discrete mathematics;limiting;mathematics	Theory	9.421957436502478	10.867798797908902	32026
fc79fca901a8421611262818149f1ea6619de5b2	the concave least-weight subsequence problem revisited	numero entero;optimisation;nombre entier;algorithmique;optimizacion;time complexity;formatage;integer number;formataje;formatting;complexite temps;optimizacion concava;optimisation concave;algorithmics;algoritmica;concave optimization;optimization;complejidad tiempo	Abstract   We are given an integer  n  and a real-valued function  w ( i ,  j ) defined for integers 0 ≤  i   j  ≤  n  and with the property that  w ( i  0 ,  j  0 ) +  w ( i  1 ,  j  1 ) ≤  w ( i  0 ,  j  1 ) +  w ( i  1 ,  j  0 ) for 0 ≤  i  0   i  1   j  0   j  1  ≤  n . The  concave least-weight subsequence problem  is to find an integer  k  ≥ 1 and a sequence of integers 0 =  l  0   l  1   l   k −1   l   k   =  n  such that   ∑  i=0  k−  w(l     i   , l     i+1   )   is minimized. One application of this problem is determining optimal line breaks in a text formatting system. D. S. Hirschberg and L. L. Larmore ( SIAM J. Comput.  16  (1987), 628–638) showed that the concave least-weight subsequence problem can be solved in  O ( n  log  n ) time and that if a certain extra condition is imposed it can be solved in  O ( n ) time. Here we show that the concave least weight subsequence problem can always be solved in  O ( n ) time, without any extra conditions.	concave function	Robert E. Wilber	1988	J. Algorithms	10.1016/0196-6774(88)90032-6	arithmetic;integer;time complexity;mathematical optimization;combinatorics;disk formatting;computer science;mathematics;algorithmics;algorithm	Theory	23.51982129650744	13.795044573597668	32034
e2a724e06a2e003a4e7f73e352259dacbd583b1b	priority systems with orientation. analytical and numerical results		A class of priority queueing systems with non-zero switchover times is considered. Some performance characteristics such as distributions of busy periods, conditions of stationarity, traffic coefficients, distribution of queue length, probabilities of the system’s state, etc. are presented. Numerical algorithms for their modelling are developed.	numerical method	Gheorghe Mishkoy	2017		10.1007/978-3-319-71504-9_11	mathematical optimization;queueing theory;queue;switchover;mathematics	EDA	8.557459574786154	11.58462523888806	32063
c45ae977406d4f3f9ef6c302350846337c574abd	netcap: a capacity planning tool for practical content distribution network designs	content distribution network;network synthesis;capacity planning;evolutionary approach;system integration;optimization;data management system	This paper describes a capacity planning tool NETCAP, which is a prototype software program for automatically planning and integrating application-specific content-distribution networks (CDNs). The CDN integration problem consists of two problems: data management system design problem and network topology design problem. The data management system design problem comprises of the server placement and file allocation problems, where the network topology design problem involves determining the network topology with network technology considerations. The CDN integration problem has been formulated as an optimization problem; where the objective function is to optimize a network topology that satisfies both the servers’ access requirements and clients’ communications. An evolutionary technique is used in NETCAP to search the design space. The experimental results for a CDN integration problem described here demonstrate the effectiveness of NETCAP in finding good CDN designs from a large design space in a few minutes. Copyright # 2006 John Wiley & Sons, Ltd.	computer program;content delivery network;data hub;genetic algorithm;john d. wiley;mathematical optimization;network topology;optimization problem;programming tool;prototype;regular expression;requirement;server (computing);systems design	Sami J. Habib	2007	Int. J. Communication Systems	10.1002/dac.813	network synthesis filters;simulation;network management station;telecommunications;computer science;network simulation;computer network;system integration	AI	8.041720627908484	5.795728396628871	32070
c97e6d18b712e9a29e0280679f4c0a4f34790ac6	a decomposition of the max-min fair curriculum-based course timetabling problem		We propose a decomposition of the max-min fair curriculum-based course timetabling (MMF-CB-CTT) problem. The decomposition models the room assignment subproblem as a generalized lexicographic bottleneck optimization problem (GLBOP). We show that the GLBOP can be solved in polynomial time if the corresponding sum optimization problem can be solved in polynomial time as well. Thus, the room assignment subproblem of the MMF-CB-CTT problem can be solved efficiently. We apply this result to a previously proposed heuristic algorithm for the MMF-CB-CTT problem, in which solving the room assignment subproblem is a key ingredient. Our experimental results indicate that using the proposed decomposition improves the performance of the algorithm on most of the 21 ITC2007 test instances with respect to the quality of the best solution found and the average solution quality. Furthermore, we introduce a measure for the quality of a solution to a (generalized) lexicographic bottleneck optimization problem. This measure helps to overcome some limitations imposed by the qualitative nature of max-min fairness and aids the statistical evaluation of the performance of randomized algorithms for such problems.	fairness measure;heuristic (computer science);incremental funding methodology;lexicographical order;mathematical optimization;max-min fairness;maxima and minima;multistage interconnection networks;optimization problem;polynomial;randomized algorithm;time complexity	Moritz Mühlenthaler;Rolf Wanka	2013	CoRR		mathematical optimization;generalized assignment problem;mathematics;algorithm	EDA	20.222013179673457	9.831340096405404	32078
54e1368ca6e1058af9afab23e34d59a397ea4c46	computing the maximum agreement of phylogenetic networks	arbre phylogenetique;subgrafo;temps polynomial;complexite calcul;branching;problema np duro;calculo automatico;phylogenetic network;arbol filogenetico;computing;calcul automatique;algorithm;np hard problem;complejidad computacion;structure reseau;phylogenetic tree;probleme np difficile;sous graphe;computational complexity;informatique theorique;ramificacion;polynomial time;maximum agreement subnetwork;algorithme polynomial;ramification;network structure;subgraph;phylogenetic network comparison;composante biconnexe;computer theory;tiempo polinomial;informatica teorica	We introduce the maximum agreement phylogenetic subnetwork problem (MASN) of finding a branching structure shared by a set of phylogenetic networks. We prove that the problem is NP-hard even if restricted to three phylogenetic networks and give an O(n)-time algorithm for the special case of two level-1 phylogenetic networks, where n is the number of leaves in the input networks and where N is called a level-f phylogenetic network if every biconnected component in the underlying undirected graph contains at most f nodes having indegree 2 in N . Our algorithm can be extended to yield a polynomial-time algorithm for two level-f phylogenetic networks N1, N2 for any f which is upper-bounded by a constant; more precisely, its running time is O(|V (N1)| · |V (N2)| ·4 f ), where V (Ni) denotes the set of nodes of Ni.	algorithm;biconnected component;directed graph;graph (discrete mathematics);np-hardness;phylogenetic network;phylogenetics;polynomial;subnetwork;time complexity	Charles Choy;Jesper Jansson;Kunihiko Sadakane;Wing-Kin Sung	2005	Theor. Comput. Sci.	10.1016/j.tcs.2004.12.012	combinatorics;computing;discrete mathematics;phylogenetic tree;branching;computer science;mathematics;ramification;phylogenetic network;algorithm	Theory	21.51428696471577	27.05070908190434	32106
957f1f1b0d43d9819e9e8f21ac264e1e13600bb1	exact (exponential) algorithms for the dominating set problem	minimum dominating set;graphe non oriente;algorithme rapide;graph theory;maximum degree;graphe biparti;teoria grafo;non directed graph;grado grafo;time complexity;grafo bipartido;problema np duro;theorie graphe;dominating set;np hard problem;complexite temps;probleme np difficile;grafo no orientado;fast algorithm;exact algorithm;conjunto dominando;degre graphe;complejidad tiempo;bipartite graph;algoritmo rapido;graph degree;ensemble dominant	We design fast exact algorithms for the problem of computing a minimum dominating set in undirected graphs. Since this problem is NP-hard, it comes with no big surprise that all our time complexities are exponential in the number n of vertices. The contribution of this paper are ‘nice’ exponential time complexities that are bounded by functions of the form c with reasonably small constants c < 2: For arbitrary graphs we get a time complexity of 1.93782. And for the special cases of split graphs, bipartite graphs, and graphs of maximum degree three, we reach time complexities of 1.41422, 1.73206, and 1.64515, respectively.	algorithm;dominating set;graph (discrete mathematics);np-hardness;time complexity	Fedor V. Fomin;Dieter Kratsch;Gerhard J. Woeginger	2004		10.1007/978-3-540-30559-0_21	time complexity;combinatorics;discrete mathematics;bipartite graph;dominating set;longest path problem;clique problem;graph theory;metric dimension;np-hard;mathematics;maximal independent set;chordal graph;indifference graph;algorithm	Theory	21.34671610161719	26.529317678716737	32111
6c7ec73aacd813ef00f82b21be4a7fe172ab6b3a	on queueing systems with a fractional number of devices		Queueing systems with several servers and a special discipline whereby demands are successively received by servers until the servicing is completed are considered. Among these systems, there are such systems whose characteristics constantly depend on a certain positive parameter. Given integer values of the latter, the waiting probability and average sojourn time coincide with those calculated using the Erlang C formula. Therefore, these systems can be considered as generalizations of the classical M/M/s system to a fractional number of servers.	ergodic theory;erlang (unit);server (computing)	Valeriy Naumov;Olli Martikainen	2013	Automatic Control and Computer Sciences	10.3103/S0146411613040056	combinatorics;discrete mathematics;m/m/c queue;mathematics;kendall's notation	Metrics	8.532915626037264	10.811237382878677	32144
dc310f0e626d11ddf6fc747515c19478158b56d7	regular and context-free pattern languages over small alphabets	pattern languages;context free languages;conference contribution;regular languages;article	Pattern languages are generalisations of the copy language, which is a standard textbook example of a context-sensitive and noncontext-free language. In this work, we investigate a counter-intuitive phenomenon: with respect to alphabets of size 2 and 3, pattern languages can be regular or context-free in an unexpected way. For this regularity and context-freeness of pattern languages, we give several sufficient and necessary conditions and improve known results.		Daniel Reidenbach;Markus L. Schmid	2014	Theor. Comput. Sci.	10.1016/j.tcs.2013.07.035	arithmetic;natural language processing;interlinguistics;formal language;pumping lemma for regular languages;regular language;computer science;third-generation programming language;agglutinative language;context-free language;cone;ontology language;abstract family of languages;programming language;second-generation programming language;comparison of multi-paradigm programming languages;algorithm	Theory	-2.799511842025179	17.73276799449218	32241
c0d4c5713dba6472edb651334d25c3a5aa78d6f3	the input/output complexity of sorting and related problems	complexite;gestion memoire;combinatorics;algorithmique;sorting;combinatoria;storage management;complejidad;combinatoire;complexity;tria;directional derivative;transformacion fourier rapida;permutation;fast fourier transform;input output;gestion memoria;analisis input output;algorithmics;algoritmica;triage;permutacion;input output analysis;upper and lower bounds;sorting algorithm;optimal algorithm;transformation fourier rapide;analyse input output;lower bound;fast fourier transformation	We provide tight upper and lower bounds, up to a constant factor, for the number of inputs and outputs (I/OS) between internal memory and secondary storage required for five sorting-related problems: sorting, the fast Fourier transform (FFT), permutation networks, permuting, and matrix transposition. The bounds hold both in the worst case and in the average case, and in several situations the constant factors match. Secondary storage is modeled as a magnetic disk capable of transferring P blocks each containing B records in a single time unit; the records in each block must be input from or output to B contiguous locations on the disk. We give two optimal algorithms for the problems, which are variants of merge sorting and distribution sorting. In particular we show for P = 1 that the standard merge sorting algorithm is an optimal external sorting method, up to a constant factor in the number of I/Os. Our sorting algorithms use the same number of I/Os as does the permutation phase of key sorting, except when the internal memory size is extremely small, thus affirming the popular adage that key sorting is not faster. We also give a simpler and more direct derivation of Hong and Kung's lower bound for the FFT for the special case B = P = O(1).	auxiliary memory;best, worst and average case;computer data storage;external sorting;fast fourier transform;input/output;merge sort;operating system;sorting algorithm	Alok Aggarwal;Jeffrey Scott Vitter	1988	Commun. ACM	10.1145/48529.48535	arithmetic;fast fourier transform;bogosort;combinatorics;sorting network;computer science;external sorting;mathematics;merge algorithm;upper and lower bounds;algorithmics;algorithm;statistics	Theory	13.278765229167119	30.44536940084885	32264
c8781a6329bb350394e58ba9babe6f5e09a799be	green wireless communications: from concept to reality [industry perspectives]	energy efficiency;environmental factors;renewable energy resources;wireless networks;pollution control;green products;green design wireless networks renewable energy resources green products electromagnetics recycling environmental factors energy efficiency pollution control;electromagnetics;green design;recycling	Green wireless communications has recently attracted a lot of attention. Most recent work on green wireless communications focuses on energy efficiencies and sustainable/renewable energies. In a broader sense, however, green wireless communications could also include wireless communications using environmentally sustainable materials, occupying less land space, accompanying less electromagnetic pollution, together with waste recycling and reducing wastes, and cost reductions.		Jinsong Wu	2012	IEEE Wireless Communications	10.1109/MWC.2012.6272415	renewable energy;electromagnetism;computer science;wireless network;efficient energy use;sustainable design;recycling	Mobile	5.225481314485392	31.848605747271687	32277
1a64bbaca3839fd7bee5b7bc37d801e0258e5eb7	on generating the irredundant conjunctive and disjunctive normal forms of monotone boolean functions	game theory;incremental polynomial time;convex programming;disjunctive normal form;dualization;np hardness;polynomial time;normal form;relay contact circuit;monotone boolean formula;conjunctive normal form;prime implicate;quasi polynomial time;posistional game;prime implicant;monotone boolean function	Abstract   Let  f :{0,1}  n  →{0,1} be a monotone Boolean function whose value at any point  x ∈{0,1}  n   can be determined in time  t . Denote by   c=  ⋀  I∈C    ⋁  i∈I    x     i    the irredundant CNF of  f , where  C  is the set of the prime implicates of  f . Similarly, let   d=  ⋁  J∈D    ⋀  j∈J    x     j    be the irredundant DNF of the same function, where  D  is the set of the prime implicants of  f . We show that given subsets  C ′⊆ C  and  D ′⊆ D  such that ( C ′, D ′)≠( C , D ), a new term in ( C ⧹ C ′)∪( D ⧹ D ′) can be found in time   O  (n(t+n))+m      o  (  log    m)    , where  m =| C ′|+| D ′|. In particular, if  f ( x ) can be evaluated for every  x ∈{0,1}  n   in polynomial time, then the forms  c  and  d  can be jointly generated in incremental quasi-polynomial time. On the other hand, even for the class of ∧,∨-formulae  f  of depth 2, i.e., for CNFs or DNFs, it is unlikely that uniform sampling from within the set of the prime implicates and implicants of  f  can be carried out in time bounded by a quasi-polynomial 2 polylog(·)  in the input size of  f . We also show that for some classes of polynomial-time computable monotone Boolean functions it is NP-hard to test either of the conditions  D ′= D  or  C ′= C . This provides evidence that for each of these classes neither conjunctive nor disjunctive irredundant normal forms can be generated in total (or incremental) quasi-polynomial time. Such classes of monotone Boolean functions naturally arise in game theory, networks and relay contact circuits, convex programming, and include a subset of ∧,∨-formulae of depth 3.	boolean algebra;disjunctive normal form;monotone	Vladimir Gurvich;Leonid Khachiyan	1999	Discrete Applied Mathematics	10.1016/S0166-218X(99)00099-2	time complexity;implicant;game theory;conjunctive normal form;combinatorics;discrete mathematics;mathematics;disjunctive normal form;algorithm	AI	7.656316734881353	18.50181578910733	32293
50f5af51eb8f66f1ddccd4682c5b56aa8504d67c	almost 2-sat is fixed-parameter tractable (extended abstract)	parameterized complexity;computer science and information systems;fixed parameter tractable;satisfiability	We consider the following problem. Given a 2-cnf formula, is it possible to remove at most k clauses so that the resulting 2-cnf formula is satisfiable? This problem is known to different research communities in theoretical computer science under the names Almost 2-SAT, All-but-k 2-SAT, 2-cnf deletion, and 2-SAT deletion. The status of the fixed-parameter tractability of this problem is a long-standing open question in the area of parameterized complexity. We resolve this open question by proposing an algorithm that solves this problem in O(15 ∗k∗m) time showing that this problem is fixed-parameter tractable.	2-satisfiability;algorithm;cobham's thesis;parameterized complexity;theoretical computer science	Igor Razgon;Barry O'Sullivan	2008		10.1007/978-3-540-70575-8_45	computational problem;parameterized complexity;mathematical optimization;combinatorics;discrete mathematics;vertex cover;computer science;mathematics;algorithm;satisfiability	Theory	9.056620812374527	19.555097849484273	32341
edc2dc35e2e06cfc411de22f0764e01f4cca8561	sorting sequential files with limited auxiliary storage	normal form grammar;bounded context acceptor;pushdown automaton;parsing;context free grammar;extended bounded context acceptor;bounded right context	This paper considers the problem of sorting files whose size exceeds main memory and for which only limited auxiliary memory resources are available.	auxiliary memory;computer data storage;sorting	David S. Burris;Kurt A. Schember	1980		10.1145/503838.503855	computer science;theoretical computer science;programming language;algorithm	DB	-1.2852138828993394	23.166716305339232	32362
0576ced0c3114769b0d2031dd29c68082e653bc0	on multiprocessor temperature-aware scheduling problems	approximation algorithms;temperature aware scheduling;identical processors;inapproximability	We study temperature-aware scheduling problems under the model introduced by Chrobak et al. in [6]. We consider a set of parallel identical processors and three optimization criteria: makespan, maximum temperature and (weighted) average temperature. On the positive side, we present polynomial time approximation algorithms for the minimization of the makespan and the maximum temperature, as well as, optimal polynomial time algorithms for minimizing the average temperature and the weighted average temperature. On the negative side, we prove that there is no ( 4 3 − ε)-approximation algorithm for the problem of minimizing the makespan for any ε > 0, unless P = NP.	approximation algorithm;central processing unit;flip-flop (electronics);job scheduler;job stream;makespan;mathematical optimization;multiprocessing;p versus np problem;polynomial;scheduling (computing);thermal management (electronics);time complexity;uptime	Evripidis Bampis;Dimitrios Letsios;Giorgio Lucarelli;Evangelos Markakis;Ioannis Milis	2013	J. Scheduling	10.1007/s10951-013-0319-z	mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;approximation algorithm	Theory	15.598922002640343	11.054833134910638	32387
1a188c969ed16dcdb7f1623761df64b1e07cac1e	faster subsequence recognition in compressed strings	longest common subsequence	Processing compressed strings without decompression is often essential when dealing with massive data sets. We consider local subsequence recognition problems on strings compressed by straight-line programs (SLP), which is closely related to Lempel–Ziv compression. For an SLP-compressed text of length m, and an uncompressed pattern of length n, Cégielski et al. [4] gave an algorithm for local subsequence recognition running in time O(mn log n). We improve the running time to O(mn). Our algorithm can also be used to compute the longest common subsequence between a compressed text and an uncompressed pattern in time O(mn); the same problem with a compressed pattern is known to be NP-hard.	acm computing surveys;algorithm;approximate string matching;approximation algorithm;comparison of programming languages (string functions);computation;computational geometry;computer programming;context-free language;counting problem (complexity);data compression;edit distance;ieee transactions on information theory;information processing letters;journal of computer and system sciences;lz77 and lz78;lecture notes in computer science;lempel–ziv–stac;lempel–ziv–welch;longest common subsequence problem;microsoft windows;np-hardness;preparata code;semiconductor industry;springer (tank);string searching algorithm;substring;successive linear programming;superword level parallelism;taxonomy (general);theoretical computer science;time complexity;watson (computer);welch's method	Alexander Tiskin	2007	CoRR		combinatorics;longest increasing subsequence;data structure;theoretical computer science;longest common subsequence problem;mathematics;computational complexity theory;algorithm	Theory	13.916652416681982	27.195086728097536	32398
6eae9b07f79a968e124ded0d7c5187834dc26d75	maximizing circle of trust in online social networks	approximate algorithm;best approximation;approximation algorithms;polynomial time algorithm;trusted computing;np hard problem;computational complexity;online social networks;polynomial time;fully polynomial time approximation scheme;online social network;error bound;circle of trust;information leakage;polynomial time approximation scheme	As an imperative channel for fast information propagation, Online Social Networks(OSNs) also have their defects. One of them is the information leakage, i.e., information could be spread via OSNs to the users whom we are not willing to share with. Thus the problem of constructing a circle of trust to share information with as many friends as possible without further spreading it to unwanted targets has become a challenging research topic but still remained open.  Our work is the first attempt to study the Maximum Circle of Trust problem seeking to share the information with the maximum expected number of poster's friends such that the information spread to the unwanted targets is brought to its knees. First, we consider a special and more practical case with the two-hop information propagation and a single unwanted target. In this case, we show that this problem is NP-hard, which denies the existence of an exact polynomial-time algorithm. We thus propose a Fully Polynomial-Time Approximation Scheme (FPTAS), which can not only adjust any allowable performance error bound but also run in polynomial time with both the input size and allowed error. FPTAS is the best approximation solution one can ever wish for an NP-hard problem. We next consider the number of unwanted targets is bounded and prove that there does not exist an FPTAS in this case. Instead, we design a Polynomial-Time Approximation Scheme (PTAS) in which the allowable error can also be controlled. Finally, we consider a general case with many hops information propagation and further show its #P-hardness and propose an effective Iterative Circle of Trust Detection (ICTD) algorithm based on a novel greedy function. An extensive experiment on various real-word OSNs has validated the effectiveness of our proposed approximation and ICTD algorithms.	approximation algorithm;experiment;greedy algorithm;imperative programming;information leakage;interval propagation;iterative method;mathematical optimization;np-hardness;optimization problem;ptas reduction;polynomial;polynomial-time approximation scheme;social network;software propagation;spectral leakage;time complexity	Yilin Shen;Yu-Song Syu;Dung T. Nguyen;My T. Thai	2012		10.1145/2309996.2310023	mathematical optimization;polynomial-time approximation scheme;computer science;theoretical computer science;approximation algorithm	AI	20.1192228031578	18.211282541303344	32408
bc65734f95de8b041dd7a078af85bfc7edce06d7	a general backtrack algorithm for the isomorphism problem of combinatorial objects	isomorphism problem	Our aim is to present a practical algorithm for the isomorphism problem that can be easily adapted to any class of combinatorial objects. We investigate the underlying principles of backtrack algorithms that determine a canonical representative of a combinatorial object. We identify the parts of the algorithm that are dependent on the class of combinatorial objects and those parts that are independent of the class. An interface between the two parts is developed to provide a general backtrack algorithm for the isomorphism problem of combinatorial objects that incorporates the technique of branch-and-bound, and that also uses the automorphisms of the combinatorial object to prune the search tree. Our general algorithm incorporates from computational group theory an algorithm known as the base change algorithm. The base change algorithm allows one to recover as much information as possible about the automorphism group when a new branch of the search tree is processed. Thus, it can lead to greater pruning of the search tree. This work is intended to lead to a better understanding of the practical isomorphism algorithms. It is not intended as a contribution to the theoretical study of the complexity of the isomorphism problem.	algorithm;backtrack	Gregory Butler;Clement W. H. Lam	1985	J. Symb. Comput.	10.1016/S0747-7171(85)80021-3	combinatorics;discrete mathematics;mathematics;algorithm;search algorithm	Theory	18.346857125560387	23.610044421535157	32460
643e9c185f6cab12db1ef1c26f51de54fedcf619	optimal lower bounds for some distributed algorithms for a complete network of processors	algorithmique;reseau transmission donnee;algorithm complexity;multiprocessor;limite inferior;complejidad algoritmo;transmission message;message transmission;data transmission network;complexite algorithme;algorithmics;algoritmica;algorithme reparti;red transmision datos;multiprocesador;distributed algorithm;limite inferieure;lower bound;transmision mensaje;multiprocesseur	Abstract   Lower bounds for distributed algorithms for complete networks of processors (i.e., networks where each pair of processors is connected by a communication line) are discussed. We first show an Ω( n  log  n ) lower bound for the number of messages required by any algorithm in a given class of distributed algorithms for such networks. This class includes algorithms for problems like finding a leader or constructing a spanning tree. We then show an   Ω(n     2   )   lower bound for other problems, like constructing a maximal matching or a Hamiltonian circuit. In proving the lower bounds we are counting the edges which carry messages during the executions of the algorithms (ignoring the actual number of messages carried by each edge). Interestingly, this number is shown to be of the same order of magnitude as the total number of messages needed by these algorithms. The proofs of the lower bounds apply for synchronous networks and for arbitrarily long messages.	distributed algorithm	Ephraim Korach;Shlomo Moran;Shmuel Zaks	1989	Theor. Comput. Sci.	10.1016/0304-3975(89)90103-5	distributed algorithm;combinatorics;multiprocessing;computer science;theoretical computer science;mathematics;distributed computing;upper and lower bounds;algorithmics;algorithm	Theory	18.390786479951736	31.600620420614067	32498
6696a167dfcd82a1ecc74f7fcd8601ab2cf5febd	reversal complexity classes for alternating turing machines	complexite;reconocimiento lenguaje;machine turing;reconnaissance langage;complexite calcul;complejidad calculo;language theory;clase complejidad;complejidad;regular language;reversal complexity;computing complexity;turing machine;complexity;teoria lenguaje;68q05;language recognition;lenguaje racional;classe complexite;complexity class;computational complexity;alternation;informatique theorique;regular languages;langage rationnel;68q15;theorie langage;maquina turing;computer theory;informatica teorica	Alternating Turing machines (ATMs) with bounded number of reversals are considered. It is proved that the machines making fewer than log* n reversals can recognize only regular languages. On the other hand, the class of languages that can be recognized by ATMs using log* n reversals is very wide. The authors prove that above this limit even a slight increase ofthe number ofreversals leads to a considerably larger class of languages. It is also proved that every T(n)-.time bounded ATM may be replaced by an equivalent machine working in the same time and making no more than log* (T(n)) reversals. Key words, alternation, reversal complexity, regular languages, computational complexity AMS(MOS) subject classifications. 68Q05, 68Q15	atm turbo;alternating turing machine;alternation (formal language theory);complexity class;computational complexity theory;computational linguistics;regular language	Miroslaw Kutylowski;Maciej Liskiewicz;Krzysztof Lorys	1990	SIAM J. Comput.	10.1137/0219014	regular language;computer science;artificial intelligence;mathematics;algorithm	Theory	-0.08590715673908068	19.723427714501675	32512
1226707b1d5cbd01270546a739bbca4ed9fa15f5	node-weighted steiner tree and group steiner tree in planar graphs	network design;approximation algorithms;node weights;planarity	We improve the approximation ratios for two optimization problems in planar graphs. For node-weighted Steiner tree, a classical network-optimization problem, the best achievable approximation ratio in general graphs is Θ (log n), and nothing better was previously known for planar graphs. We give a constant-factor approximation for planar graphs. Our algorithm generalizes to allow as input any nontrivial minor-closed graph family, and also generalizes to address other optimization problems such as Steiner forest, prize-collecting Steiner tree, and network-formation games.  The second problem we address is group Steiner tree: given a graph with edge weights and a collection of groups (subsets of nodes), find a minimum-weight connected subgraph that includes at least one node from each group. The best approximation ratio known in general graphs is O(log3 n), or O(log2 n) when the host graph is a tree. We obtain an O(log n polyloglog n) approximation algorithm for the special case where the graph is planar embedded and each group is the set of nodes on a face. We obtain the same approximation ratio for the minimum-weight tour that must visit each group.	approximation algorithm;embedded system;graph minor;mathematical optimization;optimization problem;planar graph;steiner tree problem	Erik D. Demaine;Mohammad Taghi Hajiaghayi;Philip N. Klein	2009	ACM Trans. Algorithms	10.1145/2601070	1-planar graph;outerplanar graph;block graph;pathwidth;mathematical optimization;network planning and design;combinatorics;discrete mathematics;planarity testing;steiner tree problem;computer science;clique problem;gomory–hu tree;graph coloring;clique-sum;k-ary tree;k-minimum spanning tree;mathematics;tree-depth;cycle basis;chordal graph;indifference graph;approximation algorithm;book embedding;algorithm;planar graph	Theory	24.151706803773514	21.182900701297655	32537
1caa2c8360d7285057cb0a8c5e79c48ebe209062	geomi: geometry for maximum insight	navegacion;graph theory;vision ordenador;teoria grafo;protocole transmission;graph drawing;graph method;complex network;interactive method;metodo grafo;theorie graphe;network analysis;methode graphe;computer vision;navigation;protocolo transmision;representacion de grafos;visual analysis;aparato visual;appareil visuel;vision ordinateur;analyse circuit;visual system;analisis circuito;trace de graphes;transmission protocol	This paper describes the GEOMI system, a visual analysis tool for the visualisation and analysis of large and complex networks. GEOMI provides a collection of network analysis methods, graph layout algorithms and several graph navigation and interaction methods. GEOMI is a new generation of visual analysis tools combining graph visualisation techniques with network analysis methods. GEOMI is available from http://www.cs.usyd.edu.au/∼visual/valacon/geomi/.	algorithm;biological network;complex network;graph drawing;graph theory;interaction;planar graph;social network analysis;structure mining	Adel Ahmed;Tim Dwyer;Michael Forster;Xiaoyan Fu;Joshua Wing Kei Ho;Seok-Hee Hong;Dirk Koschützki;Colin Murray;Nikola S. Nikolov;Ronnie Taib;Alexandre Tarassov;Kai Xu	2005		10.1007/11618058_42	navigation;combinatorics;visual system;network analysis;computer science;artificial intelligence;graph theory;mathematics;graph drawing;complex network;algorithm	HCI	21.863506492710055	30.301287825779117	32552
6e6fa26457a7632103e0165c680195dfe329f532	a statistical test for the time constancy of scaling exponents	transformation ondelette;wavelet analysis;test hypothese;teletrafic;selfsimilarity;analytical models;time constancy;estimation theory;long range dependence;wavelet based estimates;test statistique;scaling phenomena;analisis datos;self similar process;phenomene echelle;test hipotesis;signal analysis;pollution measurement;test estadistico;automatic testing;statistical test;independent gaussian variables;telecommunication network;traffic control;analisis de senal;telecommunication computing;prior knowledge;invariant test;indexing terms;power function;processus stationnaire;uniformly most powerful invariant test statistical test time constancy scaling exponents long range dependence exactly self similar processes wavelet based estimates idealized inference problem independent gaussian variables invariant test umpi test power functions wavelet detail coefficients robustness bellcore ethernet data sets;statistical properties;wavelet transforms;exactly self similar processes;data analysis;telecommunication traffic;teletrafico;power functions;computational modeling;statistical analysis;bellcore ethernet data sets;red telecomunicacion;idealized inference problem;signal processing;autosimilitud;wavelet detail coefficients;wavelet analysis pollution measurement computational modeling analytical models robustness telecommunication computing ethernet networks automatic testing telecommunication traffic traffic control;reseau telecommunication;long range dependent;teletraffic;uniformly most powerful invariant;scaling exponent;umpi test;signal processing statistical analysis wavelet transforms estimation theory local area networks telecommunication traffic;analyse donnee;autosimilitude;uniformly most powerful invariant test;robustness;transformacion ondita;proceso estacionario;ethernet networks;stationary process;analyse signal;local area networks;wavelet transformation;telecommunication networks;scaling exponents;hypothesis test	A statistical test is described for determining if scaling exponents vary over time. It is applicable to diverse scaling phenomena including long range dependence and exactly self-similar processes in a uniform framework, without the need for prior knowledge of the type in question. It is based on the special properties of wavelet-based estimates of the scaling exponent, strongly motivating an idealised inference problem: the equality or otherwise of means of independent Gaussian variables with known variances. A uniformly most powerful invariant test exists for this problem and is described. A separate UMPI test is also given for when the scaling exponent undergoes a level change. The power functions of both tests are given explicitly and compared. Using simulation the effect in practice of deviations from the idealisations made of the statistical properties of the wavelet detail coefficients are analysed and found to be small. The tests inherit the significant robustness and computational advantages of the underlying wavelet-based estimator. A detailed methodology is given describing its use in practical situations. The use and benefits of the test are illustrated on the Bellcore Ethernet data sets. Keywords— Self-similarity, long-range dependence, scaling exponent, wavelets, hypothesis testing, stationarity, telecommunications networks.	byte;coefficient;image scaling;selective repeat arq;self-similarity;simulation;stationary process;telecommunications network;time series;wavelet	Darryl Veitch;Patrice Abry	2001	IEEE Trans. Signal Processing	10.1109/78.950788	econometrics;statistical hypothesis testing;power function;theoretical computer science;signal processing;mathematics;statistics	ML	11.037880789637684	14.046147919361534	32577
4c3299a69d46baededdc282aa393948230f94857	two-way join optimization in partitioned database systems	database system;generic algorithm;computer experiment;community networks;polynomial algorithm;nonlinear optimization	The optimization of two-way joins is studied in order to minimize the response time in a partitioned database. We assume that the background communication network is capable of parallel transmission, which differentiates the response time measure from the total cost measure. However, we do not make the standard simplifying assumption that communications between different sites is uniform, which results in a nonlinear optimization formulation of the problem. Subsequently, we derive a fast polynomial algorithm to solve the problem. Two less general algorithms are also proposed to explore the effect of local semijoins and remote semijoins as reducers. Finally, computational experiments are carried out to investigate the trade-off between the computation time and the quality of solutions as well as to analyze the sensitivity of the solutions to various parameters of our model.		Fang Li;Lawrence V. Saxton	1988		10.1007/3-540-50171-1_12	mathematical optimization;genetic algorithm;computer experiment;nonlinear programming;computer science;theoretical computer science;database;distributed computing;algorithm	DB	15.696930807436559	6.308038847849349	32602
46fd506a486a367ca7b9eebd6f96946f0e889ca8	hybrid approaches for the two-scenario max-min knapsack problem	mixed integer programming hybrid method;knapsack problem;max min optimization;relaxation	In this paper, we deal with the two-scenario max–min knapsack (MNK) problem. First, we consider several formulations of MNK as a mixed integer programming problem. Then, we propose a hybrid method as an alternative to solve the MNK exactly. The approach combines relaxation technique and the temporary setting of variables to improve iteratively two sequences of upper and lower bounds. More precisely, pseudocuts are added to the problem to strengthen the bounds and reduce the gap between the best lower bound and the best upper bound. The algorithm stops when the proof of the optimality of the best solution is found. We also use a reduction technique to set some variables definitively at their optimal values. Numerical experiments demonstrate the robustness of the approach. In particular, our algorithm is efficient to solve large and correlated instances of MNK.	action biker;algorithm;best, worst and average case;black box;emoticon;experiment;heuristic (computer science);integer programming;international federation of operational research societies;knapsack problem;linear programming relaxation;mathematical optimization;maxima and minima;maximal set;numerical method;pixel;preprocessor;quadratic function;reduction (complexity);solver;strongly correlated material;time complexity	Saïd Hanafi;Raïd Mansi;Christophe Wilbaut;Arnaud Fréville	2012	ITOR	10.1111/j.1475-3995.2011.00836.x	continuous knapsack problem;mathematical optimization;combinatorics;computer science;cutting stock problem;change-making problem;relaxation;mathematics;knapsack problem;algorithm	AI	20.187337981965598	9.790887875912604	32619
65c8ce0ee55e2a301f4133dc87a76eaa1861d36b	approximation algorithms for feasible cut and multicut problems	approximate algorithm;optimization problem	"""Let G = (V; E) be an undirected graph with a capacity function u : E!< + and let S 1 ; S 2 ; : : : ; S k be k commodities, where each S i consists of a pair of nodes. A set X of nodes is called feasible if it contains no S i , and a cut (X; X) is called feasible if X is feasible. Several optimization problems on feasible cuts are shown to be NP-hard. A 2-approximation algorithm for the minimum-capacity feasible v-cut problem is presented. The multicut problem is to nd a set of edges F E of minimum capacity such that no connected component of G nF contains a commodity S i. It is shown that an ?approximation algorithm for the minimum-ratio feasible cut problem gives a 2(1 + ln T)-approximation algorithm for the multicut problem, where T denotes the cardinality of S i S i. A new approximation guarantee of O(t log T) for the minimum capacity-to-demand ratio Steiner cut problem is presented; here each commodity S i is a set of two or more nodes and t denotes the maximum cardinality of a commodity S i. N2L 3G1. Supported in part by NSERC grant no. OGP0138432 (NSERC code OGPIN 007). y A preliminary version of this paper has appeared in: \Approximation algorithms for feasible cut and multicut problems"""", Proc."""	approximation algorithm;connected component (graph theory);cut (graph theory);graph (discrete mathematics);graph coloring;mathematical optimization;maximum cut;np-hardness;steiner tree problem	Bo Yu;Joseph Cheriyan	1995		10.1007/3-540-60313-1_158	optimization problem;mathematical optimization;maximum cut;combinatorics;computer science;mathematics;approximation algorithm	Theory	23.014729980679352	19.09819763307745	32652
c028bcc490d0708b4eaa78b1a1ed0834fdf34ba8	core decomposition of uncertain graphs	core decomposition;uncertain graphs;dense subgraph	Core decomposition has proven to be a useful primitive for a wide range of graph analyses. One of its most appealing features is that, unlike other notions of dense subgraphs, it can be computed linearly in the size of the input graph. In this paper we provide an analogous tool for uncertain graphs, i.e., graphs whose edges are assigned a probability of existence. The fact that core decomposition can be computed efficiently in deterministic graphs does not guarantee efficiency in uncertain graphs, where even the simplest graph operations may become computationally intensive. Here we show that core decomposition of uncertain graphs can be carried out efficiently as well.  We extensively evaluate our definitions and methods on a number of real-world datasets and applications, such as influence maximization and task-driven team formation.	expectation–maximization algorithm;graph operations;preprocessor	Francesco Bonchi;Francesco Gullo;Andreas Kaltenbrunner;Yana Volkovich	2014		10.1145/2623330.2623655	1-planar graph;block graph;pathwidth;mathematical optimization;split graph;combinatorics;discrete mathematics;cograph;universal graph;graph product;longest path problem;dense graph;forbidden graph characterization;permutation graph;mathematics;tree-depth;maximal independent set;modular decomposition;treewidth;partial k-tree;graph operations;chordal graph;indifference graph	Theory	19.546299167205667	22.1437340297062	32674
d9eb9f8d3a61476ff220c4daa6bcef7a33be205d	a note on the pareto optimality of solutions to the linear bilevel programming problem	multiobjective programming;optimum pareto;programmation multiobjectif;systeme bilineaire;programacion lineal;linear programming;bilinear system;programmation lineaire;bilevel programming;pareto optimum;optimo pareto;pareto optimality;sistema bilineal;programacion multiobjetivo	Abstract   In this note it is shown that no general hypothesis on the cost functions can guarantee that a Pareto optimal solution to a linear bilevel programming problem exists. Indeed, whatever the leader's and follower's objectives, it is always possible to design constraints such that the resulting linear bilevel problem's solution is not Pareto optimal.	pareto efficiency	Patrice Marcotte;Gilles Savard	1991	Computers & OR	10.1016/0305-0548(91)90096-A	mathematical optimization;combinatorics;linear programming;mathematics;mathematical economics	AI	23.347795387327515	11.253858144446449	32697
bef4738f10704017c27b3fc384e7a51f2a0f029d	perfect circular arc coloring	complexite;acoplamiento grafo;coloracion grafo;circular arc graph;combinatorial algorithm;complejidad;graph coloring;perfect graph;complexity;graph matching;optimisation combinatoire;np hard problem;couplage graphe;coloration graphe;matching;combinatorial optimization;article;graphe arc circulaire;graph colouring;optimizacion combinatoria	The circular arc coloring problem is to find a minimum coloring of a set of arcs of a circle so that no two overlapping arcs share a color. This N P-hard problem arises in a rich variety of applications and has been studied extensively. In this paper we present an O(n2m) combinatorial algorithm for optimally coloring any set of arcs that corresponds to a perfect graph, and propose a new approach to the general circular arc coloring problem.	algorithm;combinatorial optimization;graph coloring;p (complexity)	Xujin Chen;Zhiquan Hu;Wenan Zang	2005	J. Comb. Optim.	10.1007/s10878-005-1411-x	matching;mathematical optimization;combinatorics;discrete mathematics;complexity;fractional coloring;perfect graph;combinatorial optimization;complete coloring;edge coloring;np-hard;graph coloring;mathematics;list coloring;greedy coloring;matching	Theory	22.70185334262233	26.663756031135094	32720
cf111ab889611f1b08f885ab783bde7157807641	an effective heuristic algorithm for the traveling-salesman problem	traveling salesman problem;heuristic algorithm	An Eflective Heuristic Algorithm for the Traveling. THE SYMMETRIC traveling-salesman problem is: Given an n by n symmetric matrix of.symmetric traveling salesman problem. However, the design and implementation of an algorithm based on this heuristic is not trivial. There are many.This article is about the heuristic for the travelling salesman problem. An Effective Heuristic Algorithm for the Traveling-Salesman Problem.Furthermore, the algorithm has improved the best known solutions for a series of large-scale problems with. 141, An Effective Heuristic Algorithm for the Traveling-Salesman Problem Lin, BW 1973 Show Context.In the TSP, the processing of a single k-exchange takes constant time for any. 1973, An effective heuristic algorithm for the traveling salesman problem.is a generalization of the well-known traveling salesman problem TSP, where. The elaborated heuristic algorithm is demonstrated by examples considering different. Effective for the given task and it becomes more easily interpretable.of heuristics for the TSP is mainly speed and closeness to optimal solutions. Ing the performance of an approximation algorithm for the TSP. Helsgaun, An Effective Implementation of the. Lin-Kernighan.	approximation algorithm;centrality;heuristic (computer science);kernighan–lin algorithm;time complexity;travelling salesman problem;whole earth 'lectronic link	Sen Lin;Brian W. Kernighan	1973	Operations Research	10.1287/opre.21.2.498	heuristic;optimization problem;mathematical optimization;combinatorics;greedy algorithm;mathematics;travelling salesman problem;algorithm	Theory	24.023218441382873	4.504764109823089	32722
9c3dd6134b8c77bd56e52b3d84531db18207f4da	lower bounds on the dnf exception problem for short exception lists and related problems		In this paper we prowide lower bounds on the complexity of the DNF exception problem for short exception lists and hypercube covering problem. The method proposed is based on the relaxation of the initial problem to a certain linear programming problem. Some explicit bounds are provided for the case when exception list size is bounded above by a logarithm of dimension. The bound provided in this case is significantly stronger than the bounds known before.	covering problems;linear programming relaxation	Yura Maximov	2015	CoRR		combinatorics;discrete mathematics;mathematics;algorithm	Theory	15.208465450266148	20.115313771358615	32775
49bd4342511e813a9abf709bc7cf514e8445a4c9	cyber defense analysis of smart grid including renewable energy resources based on coalitional game theory			game theory	Noorollah Fardad;Soodabeh Soleymani;Faramarz Faghihi	2018	Journal of Intelligent and Fuzzy Systems	10.3233/JIFS-171980	machine learning;smart grid;simulation;game theory;renewable energy;artificial intelligence;mathematics	AI	-1.8259009752002249	5.592586579962064	32880
24927a463e19c4348802f7f286acda31a035715b	a data structure for dynamic trees	maximum flow;simplex algorithm;fast algorithm;minimum spanning tree;network flow;data structure	We propose a data structure to maintain a collection of vertex-disjoint trees under a sequence of two kinds of operations: a link operation that combines two trees into one by adding an edge, and a cut operation that divides one tree into two by deleting an edge. Our data structure requires O(log n) time per operation when the time is amortized over a sequence of operations. Using our data structure, we obtain new fast algorithms for the following problems:  (1) Computing deepest common ancestors.  (2) Solving various network flow problems including finding maximum flows, blocking flows, and acyclic flows.  (3) Computing certain kinds of constrained minimum spanning trees.  (4) Implementing the network simplex algorithm for the transshipment problem.  Our most significant application is (2); we obtain an O(mn log n)-time algorithm to find a maximum flow in a network of n vertices and m edges, beating by a factor of log n the fastest algorithm previously known for sparse graphs.	amortized analysis;blocking (computing);data structure;directed acyclic graph;fastest;file spanning;flow network;link/cut tree;maximum flow problem;minimum spanning tree;network simplex algorithm;sparse matrix;time complexity	Daniel Dominic Sleator;Robert E. Tarjan	1981		10.1145/800076.802464	maximum flow problem;mathematical optimization;combinatorics;flow network;data structure;minimum-cost flow problem;push–relabel maximum flow algorithm;link/cut tree;computer science;minimum spanning tree;mathematics;simplex algorithm;algorithm	Theory	20.905866088432308	24.607611475501386	32936
8e3a20df70cbfc8964505855542b703ce3defa04	restricted power domination and fault-tolerant power domination on grids	prueba;power domination;68r99;phase measurement;optimisation;68rxx;nombre domination;approximate algorithm;combinatorics;measurement;fault tolerant;optimizacion;05bxx;combinatoria;vertex;approximation algorithm;combinatoire;maillage;potencia;68wxx;unit;numero dominacion;electric power system;preuve;celdarada;medida;informatique theorique;68r10;algoritmo aproximacion;fault tolerant power domination;restricted power domination;puissance;grid pattern;optimization;vertice;mesure;cardinalite;domination number;algorithme approximation;grids;proof;68w25;power;68r01;unite;unidad;computer theory;informatica teorica	The power domination problem is to find a minimum placement of phase measurement units (PMUs) for observing the whole electric power system, which is closely related to the classical domination problem in graphs. For a graph G = (V , E), the power domination number of G is the minimum cardinality of a set S ⊆ V such that PMUs placed on every vertex of S results in all of V being observed. A vertex with a PMU observes itself and all its neighbors, and if an observed vertex with degree d > 1 has only one unobserved neighbor, then the unobserved neighbor becomes observed. Although the power domination problem has been proved to be NP-complete even when restricted to some special classes of graphs, Dorfling and Henning in [M. Dorfling, M.A. Henning, A note onpower domination in grid graphs, Discrete AppliedMathematics 154 (2006) 1023–1027] showed that it is easy to determine the power domination number of an n×m grid. Their proof provides an algorithm for giving a minimum placement of PMUs. In this paper, we consider the situation in which PMUs may only be placed within a restricted subset of V . Then, we present algorithms to solve this restricted type of power domination on grids under the conditions that consecutive rows or columns form a forbidden zone. Moreover, we also deal with the fault-tolerant measurement placement in the designed scheme and provide approximation algorithms when the number of faulty PMUs does not exceed 3. © 2010 Elsevier B.V. All rights reserved.	approximation algorithm;column (database);degree (graph theory);dominating set;fault tolerance;np-completeness;power management unit;vertex (graph theory)	Kung-Jui Pai;Jou-Ming Chang;Yue-Li Wang	2010	Discrete Applied Mathematics	10.1016/j.dam.2010.03.001	vertex;mathematical optimization;fault tolerance;combinatorics;discrete mathematics;unit;domination analysis;power;proof;mathematics;electric power system;approximation algorithm;measurement	Theory	22.177806651188412	29.531498690011396	32984
02d83a098b9e704db80d2131c8e8eb88137127c0	dynamic charging scheduling for ev parking lots with photovoltaic power system		This paper studies the optimal charging scheduling for electric vehicles (EVs) in a workplace parking lot, powered by both the photovoltaic power system and the power grid. Due to the uncertainty and fluctuation of solar energy and the time-varying EV charging requirements, it is challenging to guarantee the economic operation of the parking lot charging station. To address this issue, we formulate the EV charging scheduling in the parking lot as a benefit maximization problem. First, by analyzing the relationship among the EV charging requirements, the charging load, and the harvested solar energy, we derive several necessary conditions for obtaining an optimal decision, such that the primal optimization problem can be simplified. Then, we design a dynamic charging scheduling scheme (DCSS) to manage the EV charging processes, in which the model predictive control method is employed to deal with the real-time information of EV charging requirements and the solar energy. Simulation results demonstrate the effectiveness and efficiency of the designed DCSS.	dungeon crawl stone soup;entropy maximization;extended validation certificate;load profile;mathematical optimization;optimization problem;quantum fluctuation;real-time data;requirement;scheduling (computing);simulation	Yongmin Zhang;Lin X. Cai	2018	IEEE Access	10.1109/ACCESS.2018.2873286	renewable energy;charging station;real-time computing;computer network;parking lot;computer science;dynamic priority scheduling;scheduling (computing);electric power system;model predictive control;photovoltaic system	Embedded	3.7858105141419616	4.5028544187519906	33043
e00ee6d3f0a4d4af1ba1156b1ea78a94a379542d	fast algorithms for towers of finite fields and isogenies. (algorithmes rapides pour les tours de corps finis et les isogénies)		In this thesis we apply techniques from computer algebra and language theory to speed up the elementary operations in some specific towers of finite fields. We apply our construction to the problem of computing isogenies between elliptic curves and obtain faster (both asymptotically and in practice) variants of Couveignes’ algorithm. The document is divided in four parts. In Part I we recall some basic notions from algebra and complexity theory. Part II deals with the transposition principle: in it we generalize ideas of Bostan, Schost and Lecerf, and show that it is possible to automatically transpose computer programs without losses in time complexity and with a small loss in space complexity. Part III combines the results on the transposition principle with classical techniques from elimination theory; we apply these ideas to obtain asymptotically optimal algorithms for the arithmetic of Artin-Schreier towers of finite fields. We also describe an implementations of these algorithms. Finally, in Part IV we use the previous results to speed up Couveignes’ algorithm and compare the result with the other state of the art algorithms for isogeny computation. We also present a new generalization of Couveignes’ algorithm that computes isogenies of unknown degree.	artin billiard;asymptotically optimal algorithm;computational complexity theory;computer program;dspace;elimination theory;symbolic computation;time complexity	Luca De Feo	2010			calculus;mathematics	Theory	6.081718132390479	26.734846004766826	33064
84bbc1f352456ebae4eaa45c7207a3131534995e	an approximation algorithm for the general routing problem	optimisation;approximate algorithm;algorithm analysis;optimizacion;routing;travelling salesman problem;sistema informatico;approche heuristique;combinatorial problems;probleme np dur;problema np duro;computer system;connected graph;problema viajante comercio;analysis of algorithms;resolucion problema;np hard problem;minimizacion costo;probleme combinatoire;problema combinatorio;minimisation cout;cost minimization;probleme commis voyageur;scheduling;enfoque heuristico;ordonamiento;optimization;analyse algorithme;systeme informatique;encaminamiento;combinatory problem;heuristic approach;graphe connexe;analisis algoritmo;ordonnancement;grafo connexo;problem solving;resolution probleme;acheminement	Abstract   In this paper a generalization of the TSP which is given by Orloff and called the general routing problem (GRP) is considered. The goal of the GRP is to find a minimum cost cycle in a graph  G  = ( V , E ) which visits vertices in a required subset  V ′ ⊂ V  exactly once and covers edges in a required subset  E ′ ⊂ E  at least once. We generalize the known heuristic of Christofides for the TSP with triangle inequality and approximate ratio 3/2 to the GRP.	approximation algorithm;routing	Klaus Jansen	1992	Inf. Process. Lett.	10.1016/0020-0190(92)90161-N	mathematical optimization;routing;combinatorics;computer science;connectivity;analysis of algorithms;np-hard;mathematics;travelling salesman problem;scheduling;algorithm	DB	21.127784275768207	12.778467661485578	33071
e21651172cdb2435cdfab0afbbaab2f5c2e073db	the number of runs in a string: improved analysis of the linear upper bound	repetition;chaine caractere;periodicite;upper bound;periodicity;periodicidad;informatique theorique;cadena caracter;repeticion;borne superieure;cota superior;character string;computer theory;informatica teorica	A run (or a maximal repetition) in a string is an inclusionmaximal periodic segment in a string. Let ρ(n) be the maximal number of runs in a string of length n. It has been shown in [8] that ρ(n) = O(n), the proof was very complicated and the constant coefficient in O(n) has not been given explicitly. We propose a new approach to the analysis of runs based on the properties of subperiods: the periods of periodic parts of the runs. We show that ρ(n) ≤ 5 n. Our proof is inspired by the results of [4], where the role of new periodicity lemmas has been emphasized.	coefficient;maximal set;quasiperiodicity	Wojciech Rytter	2006		10.1007/11672142_14	string;computer science;calculus;mathematics;upper and lower bounds;programming language;algorithm	Theory	12.796643180201833	29.23513797115554	33146
e1ac01b188184cdb6e7c6feb930c032ea3304fdb	complete convergence of message passing algorithms for some satisfiability problems	satisfiability problem;assignment distribution;rigorous analysis;survey propagation;previous rigorous analysis;complete convergence;low density parity check;random satisfiable;ldpc setting;certain message;popular message;warning propagation;ldpc code;variable ratio;message passing;satisfiability	"""Experimental results show that certain message passing algorithms, namely, survey propa- gation, are very efiective in flnding satisfying assignments in random satisflable 3CNF formulas. In this paper we make a modest step towards providing rigorous analysis that proves the ef- fectiveness of message passing algorithms for random 3SAT. We analyze the performance of Warning Propagation, a popular message passing algorithm that is simpler than survey propa- gation. We show that for 3CNF formulas generated under the planted assignment distribution, running warning propagation in the standard way (run message passing until convergence, sim- plify the formula according to the resulting assignment, and satisfy the remaining subformula, if necessary, using a simple \ofi the shelf"""" heuristic) works when the clause-to-variable ratio is a su-ciently large constant. We are not aware of previous rigorous analysis of message passing algorithms for satisflability instances, though such analysis was performed for decoding of Low Density Parity Check (LDPC) Codes. We discuss some of the difierences between results for the LDPC setting and our results."""	message passing	Uriel Feige;Elchanan Mossel;Dan Vilenchik	2013	Theory of Computing	10.4086/toc.2013.v009a019	low-density parity-check code;combinatorial optimization;computer science;theoretical computer science;mathematics;distributed computing;approximation algorithm;algorithm;statistics	Theory	10.650957716683589	18.38089735313244	33169
8d48f7c06eae915ccbff28bdb73107f302309fa7	efficient simulation of circuits by erew prams	parallel calculus;complexite calcul;complejidad calculo;computing complexity;modelo;calculo paralelo;informatique theorique;calculabilite;modele;calcul parallele;models;calculability;calculabilidad;computer theory;informatica teorica	Unbounded fan-in circuits over the basis of conjunctions, disjunctions and negation can be simulated efficiently only by CRCW PRAMs. It is shown that bounded fan-in circuits can be simulated efficiently even by EREW PRAMs.	electronic circuit simulation	Ingo Wegener	1990	Inf. Process. Lett.	10.1016/0020-0190(90)90113-C	artificial intelligence;mathematics;algorithm	DB	5.673748091422884	23.55921884363081	33174
ef534dfee684c0ff0a1395c7b223e1c16dc13502	two-source extractors for quasi-logarithmic min-entropy and improved privacy amplification protocols		This paper offers the following contributions: • We construct a two-source extractor for quasi-logarithmic min-entropy. That is, an extractor for two independent n-bit sources with min-entropy Õ(log n). Our construction is optimal up to poly(log log n) factors and improves upon a recent result by Ben-Aroya, Doron, and Ta-Shma (ECCC’16) that can handle min-entropy log n · 2 √ log . • A central problem in combinatorics is that of constructing k-Ramsey graphs on n vertices with k = O(log n). Prior to this work, the best construction, which readily follows by the work of Ben-Aroya et al. , is for k = (log n) O( √ log log log n) . We improve that to k = (log n) log logn) O(1) . • We obtain a privacy amplification protocol against active adversaries with security parameter λ = k/(log k), where k is the min-entropy of the source shared by the parties. Prior to this work, the security parameter of the best protocols by Chattopadhyay and Li (FOCS’16), and Cohen (FOCS’16), was k/2 √ log log . We obtain our results by constructing an improved non-malleable extractor. For n-bit sources, when set with error guarantee ε, our non-malleable extractor has seed length d = O(log n) + Õ(log(1/ε)) and can support any min-entropy Ω(d). The main technical novelty of this work lies in an improved construction of an independencepreserving merger (IPM) – a variant of the well-studied notion of a merger, that was recently introduced by Cohen and Schulman (FOCS’16). Our construction is based on a new connection to correlation breakers with advice. In fact, our IPM satisfies a stronger and more natural property than that required by the original definition, and we believe it may find further applications. ∗Computing and Mathematical Sciences Department, Caltech. Supported by a Walter S. Baer and Jeri Weiss CMI Postdoctoral Fellowship. Email: coheng@caltech.edu. ISSN 1433-8092 Electronic Colloquium on Computational Complexity, Report No. 114 (2016)	advice (programming);computer memories inc.;electronic colloquium on computational complexity;email;international standard serial number;leftover hash lemma;li-chen wang;maxima and minima;randomness extractor;security parameter;thomas m. baer;whole earth 'lectronic link	Gil Cohen	2016	Electronic Colloquium on Computational Complexity (ECCC)		discrete mathematics;min entropy;mathematics;logarithm	Theory	11.770411553339857	21.908230676121217	33175
22b0f84d47d9726b33c509711c2578626910936e	experimentation with optimization problems in algorithm courses	dynamic programming;course design;experimental method;optimisation;approximate algorithm;approximation algorithms;active learning;greedy algorithms;dynamic program;analysis of algorithm;greedy algorithm algorithm courses optimization problems computer science curricula active learning experimental method approximation algorithm;optimization problems;algorithm design techniques;optimization problem;approximation theory;computer science education;design technique;algorithm design and analysis greedy algorithms heuristic algorithms approximation algorithms optimization dynamic programming computer science;function approximation;heuristic algorithms;educational courses;greedy algorithm;algorithms;optimisation approximation theory computer science education educational courses greedy algorithms;optimization;computer science;experimentation;algorithm design;algorithm design and analysis;heuristic algorithm;experimentation computer science education optimization problems algorithms algorithm design techniques	Algorithms are one of the core elements in computer science curricula. They involve design and analysis activities, mainly analysis of correctness and efficiency. A property which has received less attention is optimality. In order to gain insight and skills on optimization, and to promote active learning, we proposed an experimental method assisted by interactive assistants. In this paper we give a detailed account of how to use the experimental method in an algorithm course. Firstly, we show how to use it with greedy algorithms, with equivalent selection functions as the most interesting issue. Secondly, we use the method to demonstrate the need of other algorithm design techniques (e.g. dynamic programming) to solve other problems. Thirdly, nearly-optimal selection functions can be used as an introduction to approximation algorithms (i.e. heuristics).	active learning (machine learning);algorithm design;approximation algorithm;backtracking;computer science;correctness (computer science);dynamic programming;emoticon;experiment;greedy algorithm;heuristic (computer science);mathematical optimization	J. Ángel Velázquez-Iturbide;Ouafae Debdi	2011	2011 IEEE EUROCON - International Conference on Computer as a Tool	10.1109/EUROCON.2011.5929294	optimization problem;algorithm design;mathematical optimization;greedy algorithm;computer science;theoretical computer science;machine learning;approximation algorithm	Vision	9.018982569814078	15.520490547443234	33207
b6b4c0b3c785c843ae4550d306c237099c8113af	on the maximum acyclic subgraph problem under disjunctive constraints	approximation algorithms;maximum acyclic subgraph problem;computational complexity;disjunctive constraints	Disjunctively constrained versions of classic problems in graph theory such as shortest paths, minimum spanning trees and maximum matchings were recently studied. In this article we introduce disjunctive constrained versions of the Maximum Acyclic Subgraph problem. Negative disjunctive constraints state that a certain pair of edges cannot be contained simultaneously in a feasible solution. Positive disjunctive constraints enforces that at least one arc for the underlying pair is in a feasible solution. It is convenient to represent these disjunctive constraints in terms of an undirected graph, called constraint graph, whose vertices correspond to the arcs of the original graph, and whose edges encode the disjunctive constraints. For the Maximum Acyclic Subgraph problem under Negative Disjunctive Constraints we develop 1/2-approximative algorithms that are polynomial for certain classes of constraint graphs. We also show that determining if a feasible solution exists for an instance of the Maximum Acyclic Subgraph problem under Positive Disjunctive Constraints is an NP-Complete problem. A new version of a classic problem in graph theory was introduced.We studied Maximum Acyclic Subgraph under Negative Disjunctive Constrains (MASNDC).We studied Maximum Acyclic Subgraph under Positive Disjunctive Constrains (MASPDC).Six 1/2-approximative algorithms for the MASNDC were developed.We showed that determining the feasibility of MASPDC is NP-Complete.	directed acyclic graph;disjunctive normal form;feedback arc set	Sílvia Maria Santana Mapa;Sebastián Urrutia	2015	Inf. Process. Lett.	10.1016/j.ipl.2014.07.013	mathematical optimization;combinatorics;discrete mathematics;computer science;subgraph isomorphism problem;mathematics;induced subgraph isomorphism problem;maximum common subgraph isomorphism problem;computational complexity theory;approximation algorithm;algorithm	DB	23.90820528982278	22.860137072726975	33225
fa2808288eb88b7e690a619497bd99e80bde80eb	conflict-based repair techniques for solving dynamic scheduling problems	dynamic programming;programacion dinamica;constraint satisfaction;resolucion problema;satisfaction contrainte;scheduling;programmation dynamique;scheduling problem;ordonamiento;satisfaccion restriccion;ordonnancement;problem solving;resolution probleme;dynamic scheduling	Scheduling problems have been studied a lot over the last decade. Due to the complexity and the variety of such problems, most work consider static problems in which activities are known in advance and constraints are fixed. However, every schedule is subject to unexpected events (consider for example a new activity to schedule or a machine breakdown). In these cases, a new solution taking these events into account is needed in a preferably short time and as close as possible to the current solution.	scheduling (computing)	Abdallah Elkhyari;Christelle Guéret;Narendra Jussien	2002		10.1007/3-540-46135-3_49	job shop scheduling;mathematical optimization;parallel computing;real-time computing;constraint satisfaction;dynamic priority scheduling;computer science;dynamic programming;distributed computing;scheduling	AI	16.395108951773594	9.69916110692528	33258
8d17fafd79415512879ec38ab124265aeec1f662	global optimization - stochastic or deterministic?	metodo directo;algoritmo aleatorizado;algorithmique;stochastic method;routing;routage;search method;optimum global;programmation stochastique;optimization method;aeronef;algorithme randomise;probabilistic approach;global optimum;metodo optimizacion;approche deterministe;aeronave;deterministic approach;algorithmics;algoritmica;enfoque probabilista;approche probabiliste;enfoque determinista;methode optimisation;randomized algorithm;methode stochastique;global optimization;direct search;stochastic programming;methode directe;optimo global;programacion estocastica;direct method;aircraft;enrutamiento;metodo estocastico	Using an aircraft routing problem as a case-study, this paper reports on some practical experience with stochastic and deterministic methods for global optimization. Results show that the deterministic method DIRECT [12] is found to be more reliable than the competing techniques THJ [1] or ECTS [2].		Mike C. Bartholomew-Biggs;Steven C. Parkhurst;Simon P. Wilson	2003		10.1007/978-3-540-39816-5_12	direct method;stochastic programming;mathematical optimization;routing;computer science;stochastic optimization;calculus;mathematics;global optimum;randomized algorithm;deterministic system;algorithmics;algorithm;global optimization	Robotics	20.875289401216552	6.709883016715153	33261
3a6cbf5140b686b11c5fcff761bebd794b32c2f1	low-cost bluetooth communication for the autonomous mobile minirobot khepera	robot sensing systems;minirobot;wireless communication;monitoring;mobile communication;communication bluetooth khepera minirobot;personal area networks;circuits;bluetooth;frequency;master slave;khepera;communication;hardware;bluetooth mobile communication hardware frequency monitoring wireless communication robot sensing systems personal area networks master slave circuits	This paper presents a low-cost Bluetooth communication for autonomous mobile minirobots. The interfacing of the Bluetooth hardware is done by a simple UART connection, which makes the approach easily portable. Using ASCII commands and events, which are exchanged over this serial link, the Bluetooth operations can be controlled and monitored. Since internal Bluetooth stack operations are concealed, no deeper knowledge of the Bluetooth technology is necessary to utilize this wireless communication. These features make the presented approach perfectly suited for the integration into minirobots like the Khepera, where computational power and spatial resources are strictly limited.	bluetooth;khepera mobile robot;serial communication	Michael Grosseschallau;Ulf Witkowski;Ulrich Rückert	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570764	embedded system;electronic circuit;master/slave;mobile telephony;telecommunications;computer science;frequency;bluetooth;ant;wireless;computer network	Robotics	-1.2513360356969219	31.210433805296233	33289
f44049c891828044c20be3a6f063d69eb559ed7a	using battery energy storage to reduce renewable resource curtailment		This paper presents the results of a study done to determine the potential for energy storage systems to increase the output of renewable power generation and improve the performance of the power grid in northern Vermont. At present, a large amount of renewable energy generation, both wind and solar, is connected to the power transmission system in northern Vermont. At times and under certain conditions, limitations of capacity or operation of the transmission system in New England force curtailment in the operation of that renewable generation, so it produces less power than it could. Electrical energy storage can potentially improve this situation by allowing the renewable energy to be stored rather than curtailed, and then used at later times, when needed and when transmission constraints do not limit its use. The study looked at whether, and how, energy storage units of the appropriate type and size, installed at the right locations in the northern Vermont power grid, could both improve the situation and payback their cost.	operation payback	Chris Root;Hantz Presume;Douglas Proudfoot;Lee Willis;Ralph Masiello	2017	2017 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT)	10.1109/ISGT.2017.8085955	wind power;grid energy storage;renewable energy credit;operations management;distributed generation;pumped-storage hydroelectricity;wind hybrid power systems;intermittent energy source;energy development;engineering	HPC	3.1006149218846417	7.317925088089241	33305
7352e47e8fc4fac14e8b0ff2fa29844aa18aa4c4	a continuous time queueing problem with special type of parallel channels	continuous time;queue length;laplace transform;probability generating function;queueing system;steady state	Zusammenfassung: In dieser Arbeit wird das Verhalten eines Zwei-Kanal-Warteschlangensystems untersucht, in dem die Anktinfte an zwei aufeinanderfolgenden Ubergangsstellen (l) unkorreliert und (2) korreliert sind; die/]lbergangszeit ist exponentialverteilt. Es werden Laplaee-Transformationen der Wahrscheinlichkeitsfunktionen ffir die L/inge der Warteschlange ermittelt und daraus die entsprechenden Ergebnisse ffir den Gleichgewichtszustand abgeleitet.	eine and zwei	Shamik D. Sharma	1975	Zeitschr. für OR	10.1007/BF01957173	mean value analysis;m/m/1 queue;mathematical optimization;m/d/c queue;generating function;pollaczek–khinchine formula;combinatorics;discrete mathematics;heavy traffic approximation;m/m/c queue;m/m/∞ queue;bulk queue;m/d/1 queue;layered queueing network;mathematics;m/g/k queue;m/g/1 queue;fork–join queue;d/m/1 queue;queueing theory;kendall's notation;steady state;g/g/1 queue;laplace transform	AI	8.717513244256702	12.292006944973942	33307
19b32b1b0c235d9ce87e3b6a24294a511c646f40	approximation algorithms for the weight-reducible knapsack problem		We consider the weight-reducible knapsack problem ,w here we are given a limited budget that can be used to decrease item weights, and we would like to optimize the knapsack objective value using such weight improvements. We develop a pseudo-polynomial algorithm for the problem, as well as a polynomial-time 3-approximation algorithm based on solving the LP-relaxation. Furthermore, we consider the special case of one degree of im- provement with equal improvement costs for each item, and present a linear-time 3-approximation algorithm based on solving a cardinality- constrained and a classic knapsack problem, and show that the analysis of the polynomial-time 3-approximation algorithm can be improved to yield a 2-approximation.	approximation algorithm;knapsack problem	Marc Goerigk;Yogish Sabharwal;Anita Schöbel;Sandeep Sen	2014		10.1007/978-3-319-06089-7_14	continuous knapsack problem;mathematical optimization;combinatorics;polynomial-time approximation scheme;generalized assignment problem;cutting stock problem;change-making problem;mathematics;knapsack problem;algorithm	Theory	20.421011014427375	14.253812118069549	33356
d5d40fe48d5ffa935ed8c1ccf89080400ffa8930	learning random monotone dnf under the uniform distribution	uniform distribution;polynomial time;turing machine	We show that randomly generated monotone c log(n)-DNF formula can be learned exactly in probabilistic polynomial time. Our notion of randomly generated is with respect to a uniform distribution. To prove this we identify the class of well behaved monotone c log(n)-DNF formulae, and show that almost every monotone DNF formula is well-behaved, and that there exists a probabilistic Turing machine that exactly learns all well behaved monotone c log(n)-DNF formula.	atomic formula;pp (complexity);probabilistic turing machine;procedural generation;time complexity;monotone	Linda Sellie	2008			mathematical optimization;linearity;electrode;wafer;photodetector;etching;detector;mathematics;uniform distribution (continuous);resistive touchscreen	Theory	8.947579252013437	21.4224996893039	33364
58f00946978cb30a958373caa46f35fdf91d0d98	competitive analysis of most-request-first for scheduling broadcasts with start-up delay	configuracion;preemptive scheduling;system configuration;05bxx;competitividad;lower bounds;upper bounds;performance;on demand data broadcasts;analisis matematico;mathematical analysis;68wxx;algorithme;upper bound;algorithm;ordonnancement non preemptif;non preemptive scheduling;informatique theorique;retard;borne inferieure;competitiveness;competitive analysis;upper and lower bounds;data broadcast;rendimiento;borne superieure;configuration;retraso;competitivite;analyse mathematique;article;lower bound;analyse competitive;cota superior;competitive ratio;cota inferior;computer theory;68m20;algoritmo;informatica teorica	In this paper, we give a tight and complete mathematical analysis of the Most-Request-First algorithm for scheduling ondemand broadcasts with start-up delay. The algorithm is natural and simple, yet its practical performance is surprisingly good. We derive tight upper and lower bounds on its competitive ratio under different system configurations. Our results reveal an interesting relationship between the start-up delay and the competitiveness of the algorithm. c © 2008 Elsevier B.V. All rights reserved.	algorithm;atomic electron transition;best, worst and average case;competitive analysis (online algorithm);mac os x 10.5 leopard;markov random field;scheduling (computing)	Regant Y. S. Hung;Hing-Fung Ting	2008	Theor. Comput. Sci.	10.1016/j.tcs.2008.01.036	simulation;computer science;mathematics;upper and lower bounds;algorithm	Theory	16.628140014399833	11.954004099684218	33378
5082b9f757c56ac1605c3b5fd2f8f97cca473156	quantum adversary (upper) bound	upper bound;query complexity;quantum physics	We describe a method to upper bound the quantum query complexity of Boolean formula evaluation problems, using fundamental theorems about the general adversary bound. This nonconstructive method can give an upper bound on query complexity without producing an algorithm. For example, we describe an oracle problem which we prove (nonconstructively) can be solved in O(1) queries, where the previous best quantum algorithm uses a polylogarithmic number of queries. We then give an explicit O(1)-query algorithm for this problem based on span programs.	adversary (cryptography);decision tree model;polylogarithmic function;quantum algorithm	Shelby Kimmel	2012		10.1007/978-3-642-31594-7_47	query optimization;combinatorics;discrete mathematics;mathematics;upper and lower bounds;quantum algorithm;physics;algorithm;quantum mechanics	Theory	9.84720572641506	23.006974052897537	33391
5851207b16c906cbb31301cfb031ba19adaaa37e	optimization of large transport networks using the ant colony heuristic	modelizacion;repartition trafic;transportation network;europa;transportation networks;optimisation;network design;ant colony optimisation;red transporte;transportes;ant colony optimization;optimizacion;road traffic;estudio comparativo;transport multimodal;ant colony;suiza;approche heuristique;network analysis planning;suisse;conception;optimisation par colonie de fourmis;long terme;transporte multimodal;long term;multimodal transportation;resolucion problema;objective function;modelisation;etude comparative;transports;modal split;planificacion;trafic routier;largo plazo;optimizacion por colonia de hormigas;heuristic methods;transportation;transportation planning;comparative study;diseno;enfoque heuristico;design;benefit cost analysis;planning;trafico carretera;optimization;long range planning;switzerland;heuristic approach;planification;europe;modeling;cost benefit analysis;infraestructura;reparticion trafico;problem solving;resolution probleme;infrastructure;reseau transport	Long-term transportation planning in larger regions encompasses more than the evaluation of individual infrastructure projects; it must also assess synergies and interference among sets of projects. The objective is the maximizing of the overall benefit within specific budget restrictions by finding the most favourable bundle of projects, i.e. solving the network design problem. For large numbers of projects, complete enumeration of all combinations, requiring time consuming equilibrium calculations is not feasible for detailed networks. The ant colony heuristic is suitable for this kind of problem. According to our knowledge, this paper presents the above-mentioned heuristic’s first application to a realistically sized network: a substantial Swiss city and surrounding region. A detailed multimodal network assignment provides the basis for calculations. First, each infrastructure project is assessed using comprehensive cost-benefit analysis. The ant colony heuristic is then successfully executed and evaluated. The paper focuses on problematic calibration details and objective function, and provides new insights into applications of the heuristic to large networks. Suggestions are made for general applications and further research in the conclusions.	ant colony;heuristic (computer science);interference (communication);loss function;multimodal interaction;network planning and design;optimization problem;switzerland;synergy	Basil J. Vitins;Kay W. Axhausen	2009	Comp.-Aided Civil and Infrastruct. Engineering	10.1111/j.1467-8667.2008.00569.x	mathematical optimization;computer science;engineering;cost–benefit analysis;operations research;transportation planning	Web+IR	18.155503647791285	5.132752139049858	33403
3427e4b8d12a964af50b69e321ad666d3079562d	cut sharing for multistage stochastic linear programs with interstage dependency	multistage stochastic programming;multistage;decomposition;monte carlo sampling;echantillonnage;methode monte carlo;programmation stochastique;multietage;satisfiability;sampling;algorithme;random parameters;mathematical programming;decomposition algorithm;poliescalonado;linear programming;programmation lineaire;linear program;algorithms;stochastic programming;programmation mathematique;programacion estocastica;monte carlo methods	Multistage stochastic programs with interstage independent random parameters have recourse functions that do not depend on the state of the system. Decomposition-based algorithms can exploit this structure by sharing cuts (outer-linearizations of time recourse function) among different scenario subproblems at the same stage. The ability to share cuts is necessary in practical implementations of algorithms that incorporate Monte Carlo sampling within the decomposition scheme. In this paper, we provide methodology for sharing cuts in decomposition algorithms for stochastic programs that satisfy certain interstage dependency models. These techniques enable sampling-based algorithms to handle a richer class of multistage problems, and may also be used to accelerate the convergence of exact decomposition algorithms.	algorithm;independent set (graph theory);iteration;linear programming;monte carlo method;multistage amplifier;sampling (signal processing);stochastic modelling (insurance)	Gerd Infanger;David P. Morton	1996	Math. Program.	10.1007/BF02592154	mathematical optimization;computer science;linear programming;theoretical computer science;mathematics;algorithm;monte carlo method	AI	23.935903040871736	10.809429769067977	33437
2e13d612585193e432e3de552a875ce1a0600548	optimal query complexity bounds for finding graphs	pseudo boolean function;coin weighing;combinatorial group testing;combinatorial search;artificial intelligent;adaptive algorithm;query complexity;littlewood offord theorem;fourier coefficient;weighted graph;search model;pseudo boolean;group testing;graph finding	We consider the problem of finding an unknown graph by using queries with an additive property. This problem was partially motivated by DNA shotgun sequencing and linkage discovery problems of artificial intelligence. Given a graph, an additive query asks the number of edges in a set of vertices while a cross-additive query asks the number of edges crossing between two disjoint sets of vertices. The queries ask the sum of weights for weighted graphs. For a graph G with n vertices and at most m edges, we prove that there exists an algorithm to find the edges of G using O(mlogn^2mlog(m+1)) queries of both types for all m. The bound is best possible up to a constant factor. For a weighted graph with a mild condition on weights, it is shown that O(mlognlogm) queries are enough provided m>=(logn)^@a for a sufficiently large constant @a, which is best possible up to a constant factor if m=0. This settles, in particular, a conjecture of Grebinski [V. Grebinski, On the power of additive combinatorial search model, in: Proceedings of the 4th Annual International Conference on Computing and Combinatorics (COCOON 1998), Taipei, Taiwan, 1998, pp. 194-203] for finding an unweighted graph using additive queries. We also consider the problem of finding the Fourier coefficients of a certain class of pseudo-Boolean functions as well as a similar coin weighing problem.	decision tree model	Sung-Soon Choi;Jeong Han Kim	2010	Artif. Intell.	10.1016/j.artint.2010.02.003	graph power;combinatorics;discrete mathematics;group testing;topological graph;independent set;directed graph;multiple edges;graph bandwidth;level structure;null graph;graph labeling;computer science;artificial intelligence;mixed graph;hypercube graph;cycle graph;path graph;graph factorization;mathematics;path;combinatorial search;complement graph;line graph;strength of a graph;closure problem;fourier series;matching	ML	19.349120967886158	21.331540076674163	33445
0eefdc01766ca85c224e628887e8cba0fbbcf5b3	a sortation system model	automotive engineering;manufacturing systems;paints;assembly systems job shop scheduling automotive engineering paints manufacturing systems machinery production industries manufacturing industries production systems broadcasting storage automation;system modeling;job shop scheduling;machinery production industries;look ahead;manufacturing industries;production systems;assembly systems;technical report;broadcasting;storage automation;manufacturing system	Automotive manufacturing is a complex task involving several steps of machining and assembly. Typically, larger components of an automobile such as the body, engine etc. are assembled over multiple systems. These large assemblies are transferred from one assembly system to another using conveyors. The conveyor/transfer system serves as a buffer and also serves to sort and re-sequence the components in a form that is required by the downstream operation. This requires the transfer system to be able to ‘look ahead’ at the requirements for the downstream operation and resequence the assemblies, if necessary. The sortation and re-sequencing part of the conveyor system is called a selectivity bank. The capacity requirement calculation and configuration design of these selectivity banks is difficult due to the randomness in the operation of, and the differences in schedules between the two systems it is connecting. Simulation is a valuable tool that is increasingly being used in the design, testing and upgrading of these systems. This paper presents the typical design issues of such selectivity banks, that are addressed using simulation. A case study is presented to elucidate the concepts and applications. The paper concentrates on automotive manufacturing systems but the concepts presented here are applicable to sortation systems used in several industries.	algorithm;assembly language;data buffer;downstream (software development);filter bank;randomness;relevance;requirement;selectivity (electronic);simulation	Arun Jayaraman;Ramu Narayanaswamy;Ali K. Gunal	1997		10.1145/268437.268667	job shop scheduling;simulation;systems modeling;computer science;engineering;technical report;automotive engineering;production system;manufacturing;broadcasting;manufacturing engineering	Robotics	9.291106924455551	4.614744917285676	33461
b0ff516cdd607a58e20213098554d5ee334a77b8	linear-consistency testing	abelian group	We extend the notion of linearity testing to the task of checking linear consistency of multiple functions. Informally, functions are “linear” if their graphs form straight lines on the plane. Two such functions are “consistent” if the lines have the same slope. We propose a variant of a test of M. Blum et al. (J. Comput. System Sci.47 (1993), 549?595) to check the linear consistency of three functions f1, f2, f3 mapping a finite Abelian group G to an Abelian group H:Pick x, y?G uniformly and independently at random and check if f1(x)+f2(y)=f3(x+y). We analyze this test for two cases: (1) G and H are arbitrary Abelian groups and (2) G=Fn2 and H=F2. Questions bearing close relationship to linear-consistency testing seem to have been implicitly considered in recent work on the construction of PCPs and in particular in the work of J. Hastad 9 (in “Proceedings of the Twenty-Ninth Annual ACM Symposium on Theory of Computing, El Paso, Texas, 4?6 May 1997,” pp. 1?10). It is abstracted explicitly for the first time here. As an application of our results we give yet another new and tight characterization of NP, namely ??>0, NP=MIP1??, 1/2O(logn), 3, 1. That is, every language in NP has 3-prover 1-round proof systems in which the verifier tosses O(logn) coins and asks each of the three provers one question each. The provers respond with one bit each such that the verifier accepts instance of the language with probability 1?? and rejects noninstances with probability at least 12. Such a result is of some interest in the study of probabilistically checkable proofs.		Yonatan Aumann;Johan Håstad;Michael O. Rabin;Madhu Sudan	2001	J. Comput. Syst. Sci.	10.1006/jcss.2001.1747	combinatorics;discrete mathematics;computer science;mathematics;abelian group;programming language;algorithm	Theory	9.796113484348611	21.32022435099841	33466
d237e59bf9081979f0abb1680c6f588a3cd01451	méthodes multi-objectifs pour l'ordonnancement de lignes réentrantes	minimisation;file attente;modelizacion;cycle time;multiobjective programming;minimization;programmation multiobjectif;optimisation multi objectif;swarm intelligence;completion time;ants colony system;systeme evenement discret;experiment plan;intelligence en essaim;optimizacion pso;queuing system;maintenance;systeme aide decision;dicrete event simulation system;sorting;gollete estrangulamiento;heuristic method;machine parallele;competitive algorithms;multi objective optimization;queue;temps achevement;metodo heuristico;minimizacion;maquina paralelas;sistema ayuda decision;tria;buffer system;algoritmo genetico;sistema reactivo;sistema amortiguador;sistema acontecimiento discreto;busca local;modelisation;algorithme competitif;goulot etranglement;discrete event system;decision support system;simulation a evenements discrets;metamodel;metaheuristique;metamodele;ant colony system;metamodelo;ant colony algorithm;non dominated sorting genetic algorithm;scheduling;particle swarm optimization;triage;reactive system;algorithme genetique;mantenimiento;systeme reactif;optimisation pso;algorithme de colonies de fourmi;genetic algorithm;parallel machines;cenetic algorithm;methode heuristique;systeme tampon;tiempo acabado;modeling;inteligencia de enjambre;bottleneck;local search;fila espera;plan d experiences;ordonnancement;recherche locale;reglamento;discrete event simulation;programacion multiobjetivo	This article presents the scheduling of a reentrant maintenance line with parallel machine stages. In this study the system is composed of machines with their upstream buffer and are modeled by queuing system. The criteria are the maximization of the utilization rate of the bottleneck and the minimization of the mean cycle time of the products. We present the results obtained by a multi-objective ant colony algorithm with local search (MOACS-LS), which are compared with the results obtained by one of the most competitive genetic algorithm called Non-dominated Sorting Genetic Algorithm version 2 (NSGA2). This two metaheuristics are coupled with a discrete event simulation module. Our results are compared with an industrial solution.		Frédéric Dugardin;Lionel Amodeo;Farouk Yalaoui	2009	Journal of Decision Systems	10.3166/jds.18.231-255	metamodeling;minimisation;ant colony optimization algorithms;simulation;systems modeling;genetic algorithm;decision support system;reactive system;cycle time variation;swarm intelligence;computer science;sorting;bicarbonate buffering system;artificial intelligence;local search;discrete event simulation;multi-objective optimization;queue management system;particle swarm optimization;scheduling;queue;algorithm	Logic	19.107453752360552	6.298479600985338	33572
e9b1c93223ea7f7c8a835bd588a39d4aae45a5fe	an efficient context-free parsing algorithm	context free	A parsing algorithm which seems to be the most efficient general context-free algorithm known is described. It is similar to both Knuth's LR(<italic>k</italic>) algorithm and the familiar top-down algorithm. It has a time bound proportional to <italic>n</italic><supscrpt>3</supscrpt> (where <italic>n</italic> is the length of the string being parsed) in general; it has an <italic>n</italic><supscrpt>2</supscrpt> bound for unambiguous grammars; and it runs in linear time on a large class of grammars, which seems to include most practical context-free programming language grammars. In an empirical comparison it appears to be superior to the top-down and bottom-up algorithms studied by Griffiths and Petrick.	addressing mode;algorithm;attribute grammar;bottom-up parsing;bottom-up proteomics;communications of the acm;context-free language;parsing;processor register;programming language;random access;random-access machine;tadao kasami;time complexity;top-down and bottom-up design	Jay Earley	1970	Commun. ACM	10.1145/362007.362035	parser combinator;memoization;bottom-up parsing;mathematics;top-down parsing;physics	PL	-0.28564718388100635	25.56019796335019	33624
201e8d28b211a3822327831c40d1afab2fdba117	ride sharing with a vehicle of unlimited capacity	vehicle routing ride sharing pick up and delivery problem;004	A ride sharing problem is considered where we are given a grap h, whose edges are equipped with a travel cost, plus a set of objects, each associated with a tra nsportation request given by a pair of origin and destination nodes. A vehicle travels through the graph, carrying each object from its origin to its destination without any bound on the number of objects that c an be simultaneously transported. The vehicle starts and terminates its ride at given nodes, and th e goal is to compute a minimum-cost ride satisfying all requests. This ride sharing problem is shown to be tractable on paths by designing a O(h log h+ n) algorithm, withh being the number of distinct requests and with n being the number of nodes in the path. The algorithm is then used as a subroutine t o efficiently solve instances defined over cycles, hence covering all graphs with maximum degree 2. This traces the frontier of tractability, since NP-hard instances are exhibited over trees whose maximum degr ee is3.	algorithm;cobham's thesis;fairness measure;graph (discrete mathematics);h+: the digital series;mathematical optimization;network topology;newman's lemma;requirement;routing;shortest path problem;sol-gel;subroutine;tracing (software);treewidth	Angelo Fanelli;Gianluigi Greco	2016		10.4230/LIPIcs.MFCS.2016.36	simulation;computer science;mathematics;distributed computing	Theory	23.08344657314684	17.903560313796408	33633
3a00ab94895d81917f6a204e5eaea1609fa055e3	randomized online algorithms for minimum metric bipartite matching	careful use;simple randomized greedy algorithm;randomized embedding;hierarchically separated tree;potential function;general metrics;poly-logarithmic result;randomized online algorithm;recent result;poly-logarithmic competitive online algorithm;minimum metric bipartite matching;online algorithm;graph;facet;polyhedron;greedy algorithm;face;vertex;cycle;bipartite matching;linear inequalities;polytope	We present the first poly-logarithmic competitive online algorithm for minimum metric bipartite matching. Via induction and a careful use of potential functions, we show that a simple randomized greedy algorithm is competitive on a hierarchically separated tree. Application of recent results on randomized embedding of metrics into trees yield the poly-logarithmic result for general metrics.	greedy algorithm;matching (graph theory);mathematical induction;online algorithm;randomized algorithm	Adam Meyerson;Akash Nanavati;Laura J. Poplawski	2006			face;polytope;vertex;online algorithm;mathematical optimization;combinatorics;greedy algorithm;discrete mathematics;facet;bipartite graph;linear inequality;3-dimensional matching;mathematics;geometry;graph;polyhedron	Theory	23.538050968643113	20.718507619423658	33652
e4d432722fc0219c66de88b1613df23cf23036b7	an iterative algorithm for spline interpolation	iterative method;spline;interpolation spline;interpolation;multistep method;methode newton;esplin;interpolacion;methode multipas;iterative algorithm;metodo iterativo;metodo multipaso;theoreme schoenberg whitney;methode iterative;spline function;metodo newton;newton method;linear equations;spline interpolation	One of the fundamental results in spline interpolation theory is the famous Schoenberg-Whitney Theorem, which completely characterizes those distributions of interpolation points which admit unique interpolation by splines. However, until now there exists no iterative algorithm for the explicit computation of the interpolating spline function, and the only practicable method to obtain this function is to solve explicitly the corresponding system of linear equations. In this paper we suggest a method which computes iteratively the coefficients of the interpolating function in its B-spline basis representation; the starting values of our one-step iteration scheme are quotients of two low order determinants in general, and sometimes even just of two real numbers. Furthermore, we present a generalization of Newton's interpolation formula for polynomials to the case of spline interpolation, which corresponds to a result of G. Mühlbach for Haar spaces. Eines der fundamentalen Resultate in der Spline-Interpolations-Theorie ist der berühmte Satz von Schoenberg-Whitney, der eine vollständige Charakterisierung derjenigen Verteilungen von Punkten angibt, welche eindeutige Interpolation durch Splines zulassen. Allerdings gibt es bisher keinen iterativen Algorithmus zur expliziten Berechnung der interpolierenden Splinefunktion, und die einzig praktikable Methode zur Gewinnung dieser Funktion ist die explizite Lösung des zugehörigen linearen Gleichungssystems. In dieser Arbeit schlagen wir eine Methode vor, die auf iterative Weise die Koeffizienten des interpolierenden Splines in seiner B-Spline-Basis Darstellung berechnet. Die Startwerte unseres Einschritt-Iterationsverfahrens sind Quotienten zweier Determinanten von, im allgemeinen Fall, kleiner Reihenzahl, und in manchen Fällen sogar nur von zwei reellen Zahlen. Weiterhin geben wir eine Verallgemeinerung von Newton's Interpolationsformel für Polynome auf den Fall der Spline-Interpolation an, die einem Resultat von G. Mühlbach für den Haarschen Fall entspricht.	algorithm;b-spline;coefficient;computation;eine and zwei;haar wavelet;iteration;linear equation;newton;newton's method;polynomial;spline (mathematics);spline interpolation;system of linear equations;vhf omnidirectional range;zur farbenlehre	Guido Walz	1993	Computing	10.1007/BF02243874	spline interpolation;spline;interpolation;mathematical optimization;mathematical analysis;bilinear interpolation;trigonometric interpolation;perfect spline;birkhoff interpolation;smoothing spline;monotone cubic interpolation;interpolation;polynomial interpolation;stairstep interpolation;cubic hermite spline;calculus;inverse quadratic interpolation;bicubic interpolation;mathematics;iterative method;thin plate spline;polyharmonic spline;linear interpolation;nearest-neighbor interpolation;multivariate interpolation;trilinear interpolation;algebra	Theory	4.044878338009275	28.413145267773253	33706
e574370814195c3e2ea0869dbad62e2beb8fea18	random walks on truncated cubes and sampling 0-1 knapsack solutions	comptage;hypercube;probleme sac a dos;chaine markov;cadena markov;melangeage;random sampling;balanced permutations;problema mochila;balanced permutations 68q25;contaje;random walks;41a10;knapsack problem;permutation aleatoire;aproximacion polinomial;random walk;muestreo aleatorio;37a25;mixing time;approximation polynomiale;counting;approximation scheme;hypercubes;analyse combinatoire;68q25;random permutation;60j10;marcha aleatoria;mixing;68r05;echantillonnage aleatoire;68w25;mezclado;marche aleatoire;analisis combinatorio;random permutations;polynomial approximation;combinatorial analysis;markov chains;markov chain;hipercubo	We solve an open problem concerning the mixing time of symmetric random walk on the n-dimensional cube truncated by a hyperplane, showing that it is polynomial in n. As a consequence, we obtain a fully polynomial randomized approximation scheme for counting the feasible solutions of a 0-1 knapsack problem. The results extend to the case of any fixed number of hyperplanes. The key ingredient in our analysis is a combinatorial construction we call a “balanced almost uniform permutation,” which is of independent interest.	cubes;knapsack problem;polynomial;polynomial-time approximation scheme;randomized algorithm	Ben Morris;Alistair Sinclair	2004	SIAM J. Comput.	10.1137/S0097539702411915	continuous knapsack problem;markov chain;mathematical optimization;combinatorics;discrete mathematics;mathematics;knapsack problem;random walk;hypercube;statistics	Theory	17.355381743049257	25.209124056813927	33727
3e1905ad7e8ab2aa969c4e60302ea3ff48cf438e	linearization of ancestral multichromosomal genomes	evolution molecular;genomics;computational biology bioinformatics;genome;chromosomes;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Recovering the structure of ancestral genomes can be formalized in terms of properties of binary matrices such as the Consecutive-Ones Property (C1P). The Linearization Problem asks to extract, from a given binary matrix, a maximum weight subset of rows that satisfies such a property. This problem is in general intractable, and in particular if the ancestral genome is expected to contain only linear chromosomes or a unique circular chromosome. In the present work, we consider a relaxation of this problem, which allows ancestral genomes that can contain several chromosomes, each either linear or circular. We show that, when restricted to binary matrices of degree two, which correspond to adjacencies, the genomic characters used in most ancestral genome reconstruction methods, this relaxed version of the Linearization Problem is polynomially solvable using a reduction to a matching problem. This result holds in the more general case where columns have bounded multiplicity, which models possibly duplicated ancestral genes. We also prove that for matrices with rows of degrees 2 and 3, without multiplicity and without weights on the rows, the problem is NP-complete, thus tracing sharp tractability boundaries. As it happened for the breakpoint median problem, also used in ancestral genome reconstruction, relaxing the definition of a genome turns an intractable problem into a tractable one. The relaxation is adapted to some biological contexts, such as bacterial genomes with several replicons, possibly partially assembled. Algorithms can also be used as heuristics for hard variants. More generally, this work opens a way to better understand linearization results for ancestral genome structure inference.	breakpoint;chromosomes;cobham's thesis;column (database);computational complexity theory;decision problem;genome;genome, bacterial;heuristics;inference;linear programming relaxation;matching (graph theory);np-completeness;occur (action);personality character;reduction (complexity);replicon;subgroup;algorithm;multiplicity	Ján Manuch;Murray Patterson;Roland Wittler;Cédric Chauve;Eric Tannier	2012		10.1186/1471-2105-13-S19-S11	biology;genomics;dna microarray;bioinformatics;chromosome;genetics;genome	ML	17.83792038376937	21.96998361931243	33728
4b2da81ab490a36ec752c03cd7ce0be3a0dd6cb4	an infinite server system with general packing constraints	virtual machine;fluid limit;infinite server system;queueing networks;grupo de excelencia;ciencias basicas y experimentales;matematicas;vector packing;grupo a;stochastic bin packing;cloud computing	We consider a service system model primarily motivated by the problem of efficient assignment of virtual machines to physical host machines in a network cloud, so that the number of occupied hosts is minimized. There are multiple input flows of different type customers, with a customer mean service time depending on its type. There is an infinite number of servers. A server-packing configuration is the vector k = {ki}, where ki is the number of type i customers the server “contains.” Packing constraints must be observed; namely, there is a fixed finite set of configurations k that are allowed. Service times of different customers are independent; after a service completion, each customer leaves its server and the system. Each new arriving customer is placed for service immediately; it can be placed into a server already serving other customers (as long as packing constraints are not violated), or into an idle server. We consider a simple parsimonious real-time algorithm, called Greedy, that attempts to mi...	set packing	Alexander L. Stolyar	2013	Operations Research	10.1287/opre.2013.1184	mathematical optimization;real-time computing;cloud computing;computer science;virtual machine;operations management;distributed computing	DB	9.256290510159712	9.862947929662248	33744
347f74b70ac719eb38f7c5c848b3e83299ae6056	probabilistic roadmaps of trees for parallel computation of multiple query roadmaps	high dimensionality;exhaustible resource;spectrum;single machine;rapidly exploring random tree;motion planning;parallel computer;data structure;probabilistic roadmap method	We propose the combination of techniques that solve multipl e queries for motion planning problems with single query planners in a motion pla nning framework that can be efficiently parallelized. In multiple query motion plannin g, a data structure is built during a preprocessing phase in order to quickly respond to on-line q ueries. Alternatively, in single query planning, there is no preprocessing phase and all comp utations occur during query resolution. This paper shows how to effectively combine a po werful sample-based method primarily designed for multiple query planning (the Probab ilistic Roadmap Method PRM) with sample-based tree methods that were primarily designe d for single query planning (such as Expansive Space Trees, Rapidly Exploring Random Trees, a nd others). Our planner, which we call the Probabilistic Roadmap of Trees ( PRT), uses a tree algorithm as a subroutine for PRM. The nodes of thePRM roadmap are now trees. We take advantage of the very powerful sampling schemes of recent tree planners to populate our roa dmaps. The combined sampling scheme is in the spirit of the non-uniform sampling and refine ment techniques employed in earlier work onPRM. PRT not only achieves a smooth spectrum between multiple query a nd single query planning but it combines advantages of both. We present experiments which show thatPRT is capable of solving problems that cannot be addressed effic iently with PRM or single-query planners. A key advantage of PRT is that it is significantly more decoupled thanPRM and sample-based tree planners. Using this property, we des igned and implemented a parallel version ofPRT. Our experiments show that PRT distributes well and can easily solve high dimensional problems that exhaust resources ava ilable to single machines.	algorithm;computation;data structure;experiment;list of algorithms;motion planning;nonuniform sampling;online and offline;parallel computing;population;precomputed radiance transfer;preprocessor;probabilistic roadmap;sampling (signal processing);statistical relational learning;subroutine	Mert Akinc;Kostas E. Bekris;Brian Y. Chen;Andrew M. Ladd;Erion Plaku;Lydia E. Kavraki	2003		10.1007/11008941_9	mathematical optimization;computer science;theoretical computer science;machine learning	Robotics	6.040629720990101	30.173962228347083	33769
2ad81d891e43b38b36845db79a9db1fa01e5707e	bringing order to special cases of klee's measure problem		Klee’s Measure Problem (KMP) asks for the volume of the union of n axis-aligned boxes in R. Omitting logarithmic factors, the best algorithm has runtime O∗(nd/2) [Overmars,Yap’91]. There are faster algorithms known for several special cases: Cube-KMP (where all boxes are cubes), Unitcube-KMP (where all boxes are cubes of equal side length), Hypervolume (where all boxes share a vertex), and kGrounded (where the projection onto the first k dimensions is a Hypervolume instance). In this paper we bring some order to these special cases by providing reductions among them. In addition to the trivial inclusions, we establish Hypervolume as the easiest of these special cases, and show that the runtimes of Unitcube-KMP and Cube-KMP are polynomially related. More importantly, we show that any algorithm for one of the special cases with runtime T (n, d) implies an algorithm for the general case with runtime T (n, 2d), yielding the first non-trivial relation between KMP and its special cases. This allows to transfer W[1]-hardness of KMP to all special cases, proving that no n algorithm exists for any of the special cases assuming the Exponential Time Hypothesis. Furthermore, assuming that there is no improved algorithm for the general case of KMP (no algorithm with runtime O(nd/2−ε)) this reduction shows that there is no algorithm with runtime O(nbd/2c/2−ε) for any of the special cases. Under the same assumption we show a tight lower bound for a recent algorithm for 2-Grounded [Yıldız,Suri’12].	algorithm;apache axis;exptime;exponential time hypothesis;internet security association and key management protocol;klee's measure problem;olap cube	Karl Bringmann	2013		10.1007/978-3-642-40313-2_20	combinatorics;discrete mathematics;mathematics;geometry;algorithm	Theory	20.528710971691016	22.32642318859774	33790
55ae91ad99cf1bbb281b169ff36080fe8b1ce35c	the plurality problem with three colors and more	game theory;algorithm analysis;asymptotic optimality;color;combinatorial search;search algorithm;teoria juego;theorie jeu;probleme majorite;majority problem;informatique theorique;game;couleur;analyse algorithme;analisis algoritmo;recherche combinatoire;computer theory;informatica teorica	The plurality problem is a game between two participants: Paul and Carole. We are given n balls, each of them is colored with one out of c colors. At any step of the game, Paul chooses two balls and asks whether they are of the same color, whereupon Carole answers yes or no. The game ends when Paul either produces a ball a of the plurality color (meaning that the number of balls colored like a exceeds those of the other colors), or when Paul states that there is no plurality. How many questions Lc(n) does Paul have to ask in the worst case?For c = 2, the problem is equivalent to the well-known majority problem which has already been solved (Combinatorica 11 (1991) 383-387). In this paper we show that 3 ⌊n/2⌋-2 ≤ L3(n) ≤ ⌊5n/3⌋ - 2. Moreover, for any c ≤ n, we show that surprisingly the naive algorithm for the plurality problem is asymptotically optimal.	color	Martin Aigner;Gianluca De Marco;Manuela Montangero	2005	Theor. Comput. Sci.	10.1016/j.tcs.2004.12.035	games;game theory;combinatorics;computer science;artificial intelligence;mathematics;combinatorial search;algorithm;search algorithm	ECom	13.592818517357797	18.69238436534922	33806
03b29f035cd9c903f3be9d213933a7453aeab8d0	distributed state space generation of discrete-state stochastic models	distributed memory;discrete distribution;vector spaces;queueing network;reliability;networks;communication system;stochastic process;probability;neural nets;system modeling;formalism;stochastic petri net;queueing theory;distributed processing;computations;computer communications;parameterization;software engineering;graphs;continuous time markov chain;probability distribution functions;model complexity;computer networks;expressive power;computer programming;discrete time markov chain;state vectors;mathematical models;heuristic methods;probability distribution;state space;network of workstation;parameters;input output processing;system analysis;complex systems;stochastic control;algorithms;reliability analysis;heuristics;markov processes;stochastic model;petri nets;petri net;distributed data processing;computer systems performance;distributed algorithm;work stations;memory computers;numerical methods and procedures;discrete event simulation	High-level formalisms such as stochastic Petri nets can be used to model complex systems. Analysis of logical and numerical properties of these models often requires the generation and storage of the entire underlying state space. This imposes practical limitations on the types of systems which can be modeled. Because of the vast amount of memory consumed, we investigate distributed algorithms for the generation of state space graphs. The distributed construction allows us to take advantage of the combined memory readily available on a network of workstations. The key technical problem is to nd e ective methods for on-they partitioning, so that the state space is evenly distributed among processors. In this paper we report on the implementation of a distributed state-space generator that may be linked to a number of existing system modeling tools. We discuss partitioning strategies in the context of Petri net models, and report on performance observed on a network of workstations, as well as on a distributed memory multi-computer. This research was supported in part by the National Aeronautics and Space Administration under NASA Contract No. NAS1-19480 while the rst and third authors were in residence at the Institute for Computer Applications in Science and Engineering (ICASE), NASA Langley Research Center, Hampton, VA 236810001. They were also supported in part by NASA Grant NAG-1-1132. Professor Nicol's work is supported in part by NSF grant CCR-9201195. i https://ntrs.nasa.gov/search.jsp?R=19960008693 2018-12-16T13:40:39+00:00Z	central processing unit;chart;complex systems;computer cluster;distributed algorithm;distributed memory;hoc (programming language);markov chain;numerical analysis;numerical partial differential equations;simulation;state diagram;state space;stochastic petri net;stochastic process;systems modeling;time complexity;workstation	Gianfranco Ciardo;Joshua Gluckman;David M. Nicol	1998	INFORMS Journal on Computing	10.1287/ijoc.10.1.82	probability distribution;stochastic process;distributed algorithm;mathematical optimization;complex systems;distributed memory;computer science;theoretical computer science;machine learning;mathematics;distributed computing;petri net;algorithm;statistics	Logic	7.311150707487515	14.1744349616259	33851
0a5388cba8e67c3df7ad52c5001d04038ba5b9c3	a multiagents approach for the job shop scheduling problem with earliness and tardiness	multi agent systems job shop scheduling just in time;job shop scheduling;multi agent systems;common due date;just in time;jit multiagents job shop scheduling earliness tardiness just in time manufacturing;job shop scheduling problem;job shop scheduling research and development management systems engineering and theory artificial intelligence manufacturing costs erbium single machine scheduling frequency selective surfaces processor scheduling	The problem addressed in this paper is the Job Shop Scheduling problem when the objective is to minimize the total earliness and tardiness from a common due date for a set of jobs. This objective became very significant after the introduction of the Just-in-time manufacturing approach. A multiagents approach is used to solve this difficult problem. The paper presents preliminary work on modeling the problem using agents theory.		Leonardo B. Valencia;Ghaith Rabadi	2003		10.1109/ICSMC.2003.1244577	fair-share scheduling;fixed-priority pre-emptive scheduling;job shop scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;artificial intelligence;two-level scheduling;scheduling;least slack time scheduling;lottery scheduling;multiprocessor scheduling	AI	12.594157934607887	6.453246106853489	33889
c7fd19c0016678a4cb0121c8767ac18d7caef388	hybrid one-dimensional reversible cellular automata are regular	generation;hybrid cellular automaton;ley uniforme;optimisation;condiciones limites;combinatorics;temps polynomial;optimizacion;condition aux limites;generacion;combinatoria;random generation;68q80;combinatoire;regular language;automate etat fini;periodic boundary condition;lenguaje racional;terme;37b15;boundary condition;informatique theorique;automate cellulaire;algorithme aleatoire;polynomial time;langage rationnel;finite state automaton;distribution uniforme;optimization;reversible cellular automaton;cellular automata;loi uniforme;cellular automaton;uniform distribution;computer theory;langage regulier;automata celular;tiempo polinomial;informatica teorica	It is shown that the set of hybrid one-dimensional reversible cellular automata (CA) with the periodic boundary condition is a regular set. This has several important consequences. For example, it allows checking whether a given CA is reversible and the random generation of a reversible CA from the uniform distribution, both using time polynomial in the size of the CA. Unfortunately, the constant term in the resulting random generation algorithm is much too large to be of practical use. We show that for the less general case of null boundary (NB) CA, this constant can be reduced drastically, hence facilitating a practical algorithm for uniform random generation. Our techniques are further applied asymptotically to count the number of reversible NBCA. © 2007 Elsevier B.V. All rights reserved.	algorithm;automata theory;concatenation;constant term;naive bayes classifier;periodic boundary conditions;polynomial;procedural generation;reversible cellular automaton;reversible computing;solid modeling;utility functions on indivisible goods	Jesse D. Bingham;Brad D. Bingham	2007	Discrete Applied Mathematics	10.1016/j.dam.2007.07.003	cellular automaton;time complexity;reversible cellular automaton;combinatorics;discrete mathematics;generation;regular language;boundary value problem;mathematics;periodic boundary conditions;uniform distribution;algorithm	Theory	10.02911665388792	25.08619287995132	33894
686b2a4c097f8787a71f085fd186275ee7f205c9	atm vp-based network design	network design;bin packing;cutting plane;routing;point to point;valid inequalities;bandwidth packing;satisfiability;integer programming;linear programming relaxation;integer program;branch and bound;article;column generation;telecommunications	We consider the problem of designing an ATM VP-based leased line backbone network. Given point-to-point communication demands having predefined sizes in a network, the problem is to find configurations of demand routes and link facilities installed on each edge satisfying all demands at minimum cost under some constraints. One of the most important constraints is that a single demand cannot be split over multiple link facilities. This is a sort of bin packing constraint. We propose an integer programming formulation of the problem and an algorithm to solve it. An efficient column generation technique to solve the linear programming relaxation is proposed, and a valid inequality is used to strengthen the integer programming formulation. The algorithm incorporates the column generation technique and the cutting plane approach into a branch-and-bound scheme.#R##N##R##N#We test the proposed algorithm on some real problems. The results show that the algorithm can be used to solve the problems within reasonably small computing times.	atm turbo;network planning and design	Jangha Kang;Kyungchul Park;Sungsoo Park	2004	European Journal of Operational Research	10.1016/S0377-2217(03)00372-2	column generation;mathematical optimization;routing;network planning and design;combinatorics;discrete mathematics;bin packing problem;integer programming;point-to-point;computer science;linear programming relaxation;branch and price;cutting stock problem;mathematics;branch and bound;branch and cut;cutting-plane method;satisfiability	Theory	21.467960129819485	11.777243686691834	33927
748b7d197671ccf28e86bee4d8ecab735659311d	hard problems in similarity searching	complexite parametrisee;parameterized complexity;complexite calcul;problema np duro;biology;biologia;np hard problem;complejidad computacion;hamming distance;probleme np difficile;computational complexity;informatique theorique;recherche similitude;distance hamming;parametrized complexity;computational biology;similarity searching;distancia hamming;similarity search;biologie;np complexity;computer theory;informatica teorica	The Closest Substring Problem is one of the most important pr oblems in the field of computational biology. It is stated as follows: give n a set oft sequences s1; s2; : : : st over an alphabet , and two integersk; d with d k, can one find a strings of lengthk and, for alli = 1; 2; : : : ; t, substringsoi of si, all of lengthk, such thatd(s; oi) d (for all i = 1; 2; : : : ; t)? (here,d(:; :) represents the Hamming distance). Closest Substring was shown to be NP-hard [9 ] andW [1℄-hard with respect to the number t of input sequences [7]; recently, an important number of results concerning the parameterized computational complexity of Closest Substring has been added in [6]. In this paper we introduce and analyze two variants of the Clo sest Substring Problem, obtained by imposing restrictions on the pairwise di tances between the substringsoi: the bounded Hamming distance constraint asks that d(oi; oj) p, for all i; j 2 f1; 2; : : : ; tg (wherep < 2d is a given constant) and yields the problem called BCCS; thesum-of-pairsconstraint asks that P1 i<j t d(oi; oj) P (whereP < dt(t 1) is a given constant) and yields the problem called SCCS. We motivate the introduction of these problems, and we show t at while SCCS is very close to Closest Substring, BCCS is a non-trivial res triction of Closest Substring more suitable to use in certain practical applicatio ns. We then concentrate on BCCS and show that all the hardness results available for Clo sest Substring remain valid for BCCS even when the parameter p is restricted to a certain range.	approximation algorithm;computation;computational biology;computational complexity theory;hamming distance;motif;regular expression;source code control system;substring;time complexity	Christophe Moan;Irena Rusu	2004	Discrete Applied Mathematics	10.1016/j.dam.2004.06.003	parameterized complexity;mathematical optimization;combinatorics;hamming distance;np;computer science;np-hard;mathematics;computational complexity theory;algorithm	Theory	15.894795679987462	23.951889401912737	33954
688f1058bfaa63f03e0ed700b1abef0d6ae26b0c	model predictive control-based optimal coordination of distributed energy resources	distributed power generation;power generation control;predictive control;optimisation;generators;wind power plants;optimal control;wind forecasting;power generation reliability;system on chip;diesel electric generators;energy storage;optimization;wind power plants diesel electric generators distributed power generation energy storage optimal control optimisation power generation control power generation dispatch power generation economics power generation reliability predictive control;wind power generation;power generation dispatch;model predictive control based optimal coordination closed loop mpc look ahead dispatch optimization problem generator life fuel cost minimization system economics diesel generators optimal control strategy isolated systems system operation reliability wind penetration conventional generators demand response energy storage renewable energy resources distributed energy resources;power generation economics;generators wind forecasting wind power generation energy storage system on chip optimization	Distributed energy resources, such as renewable energy resources (wind, solar), energy storage and demand response, can be used to complement conventional generators. The uncertainty and variability due to high penetration of wind makes reliable system operations and controls challenging, especially in isolated systems. In this paper, an optimal control strategy is proposed to coordinate energy storage and diesel generators to maximize wind penetration while maintaining system economics and normal operation performance. The goals of the optimization problem are to minimize fuel costs and maximize the utilization of wind while considering equipment life of generators and energy storage. Model predictive control (MPC) is used to solve a look-ahead dispatch optimization problem and the performance is compared to an open loop look-ahead dispatch problem. Simulation studies are performed to demonstrate the efficacy of the closed loop MPC in compensating for uncertainties and variability caused in the system.	closed-loop transfer function;control theory;diesel;dynamic dispatch;heart rate variability;mathematical optimization;optimal control;optimization problem;simulation;spatial variability	Ebony Mayhorn;Karanjit Kalsi;Jianming Lian;Marcelo Elizondo	2013	2013 46th Hawaii International Conference on System Sciences	10.1109/HICSS.2013.410	system on a chip;optimal control;computer science;operations management;energy storage;model predictive control	Robotics	3.8292447222961097	5.3763796197776434	33990
7995e115ba7ebbeb7a8be51bffb9f32051e25c39	structure and recognition of graphs with no 6-wheel subdivision	subgraph homeomorphism problem;topology;subgrafo;temps polynomial;topological containment;efficient algorithm;topologie;homeomorphisme;topologia;homeomorfismo;sous graphe;subdivisions;polynomial time;homeomorphism;graph algorithm;subdivision;subgraph;graph algorithms;tiempo polinomial	The subgraph homeomorphism problem has been shown by Robertson and Seymour to be polynomial-time solvable for any fixed pattern graph H. The result, however, is not practical, involving constants that are worse than exponential in |H|. Practical algorithms have only been developed for a few specific pattern graphs, the most recent of these being the wheels with four and five spokes. This paper looks at the subgraph homeomorphism problem where the pattern graph is a wheel with six spokes. The main result is a theorem characterizing graphs that do not contain subdivisions of W 6. We give an efficient algorithm for solving the subgraph homeomorphism problem for W 6. We also give a strengthening of the previous W 5 result.	algorithm;decision problem;graph (discrete mathematics);polynomial;time complexity;wheels	Rebecca Robinson;Graham Farr	2007	Algorithmica	10.1007/s00453-007-9162-y	strong perfect graph theorem;mathematical optimization;combinatorics;discrete mathematics;universal graph;topology;forbidden graph characterization;subdivision;subgraph isomorphism problem;mathematics;geometry;induced subgraph isomorphism problem;homeomorphism	Theory	22.85203601075605	27.208847748421697	34052
ab09f73eec611106dd2ebc08ab76b6909118a3f6	parameterized complexity of discrete morse theory	parameterized complexity;collapsibility;fixed parameter tractability;w p completeness;treewidth;discrete morse theory;computational topology;erasability;alternating cycle free matching	Optimal Morse matchings reveal essential structures of cell complexes which lead to powerful tools to study discrete geometrical objects, in particular discrete 3-manifolds. However, such matchings are known to be NP-hard to compute on 3-manifolds, through a reduction to the erasability problem. Here, we refine the study of the complexity of problems related to discrete Morse theory in terms of parameterized complexity. On the one hand we prove that the erasability problem is W[P]-complete on the natural parameter. On the other hand we propose an algorithm for computing optimal Morse matchings on triangulations of 3-manifolds which is fixed-parameter tractable in the treewidth of the bipartite graph representing the adjacency of the 1- and 2-simplexes. This algorithm also shows fixed parameter tractability for problems such as erasability and maximum alternating cycle-free matching.  We further show that these results are also true when the treewidth of the dual graph of the triangulated 3-manifold is bounded. Finally, we investigate the respective treewidths of simplicial and generalized triangulations of 3-manifolds.	algorithm;cobham's thesis;discrete morse theory;dual graph;matching (graph theory);np-hardness;parameterized complexity;thue–morse sequence;treewidth	Benjamin A. Burton;Thomas Lewiner;João Paixão;Jonathan Spreer	2013		10.1145/2462356.2462391	parameterized complexity;combinatorics;discrete mathematics;computational topology;topology;discrete morse theory;mathematics;geometry;treewidth	Theory	22.722577230165115	23.238190286856554	34374
4748d1b268f1370643af6cc91ab0e884c496cb74	a case study of coordinated electric vehicle charging for peak shaving on a low voltage grid	power distribution planning;power demand power transformer insulation production power cables vehicles load modeling prediction algorithms;smart grid coordinated electric vehicle charging peak shaving objective online coordination algorithm low voltage grid constraint uncoordinated charging peak power demand unbalanced load flow analysis nodal voltage impact;coordinated charging;smart power grids;smart grids coordinated charging electric vehicles;load flow;electric vehicles;battery powered vehicles;smart power grids battery powered vehicles load flow power distribution planning	This paper discusses the impact of coordinated charging of electric vehicles for a peak shaving objective, through an online coordination algorithm, on low voltage grid constraints. The results for uncoordinated and coordinated charging are compared to assess the effect on the peak power demand. Furthermore, an unbalanced load flow analysis is performed on a real low voltage grid to assess the impact on the nodal voltages. The simulation results show a positive impact of coordinated charging for both the peak shaving objective and for voltage deviations. The results show that the coordination algorithm obtains effective results, while only needing a limited amount of communication, measurements and predictive knowledge.	algorithm;data-flow analysis;load management;simulation;unbalanced circuit	Niels Leemput;Frederik Geth;Bert Claessens;Juan Van Roy;Raf Ponnette;Johan Driesen	2012	2012 3rd IEEE PES Innovative Smart Grid Technologies Europe (ISGT Europe)	10.1109/ISGTEurope.2012.6465656	embedded system;electronic engineering;load balancing;engineering;electrical engineering;smart grid	EDA	3.912921675177022	5.688536368618707	34380
4bf13b8d5e7d8480e7b6bc8d0f455106f79ceeb1	computing translocation distance by a genetic algorithm	bioinformatics unsigned genomes genetic algorithm translocation distance approximation algorithms;genomics biological cells yttrium genetic algorithms approximation algorithms approximation methods;approximation algorithms;1 5 e approximation algorithm translocation distance computing permutation combinatorics sequence analysis translocation operation genome representation chromosomes translocation distance gene orientation polynomial decidability innovative genetic algorithm unsigned translocation distance problem randomly generated signed versions randomly generated strings ga approach;unsigned genomes;translocation distance;genetic algorithm;genomics approximation theory combinatorial mathematics decidability genetic algorithms;bioinformatics	Translocation is a useful operation on strings with challenging questions in combinatorics of permutations and interesting applications in analysis of sequences. A translocation operation essentially is the interchange of prefixes and suffixes among two substrings of a string. For the case of genomes represented as strings, symbols that represent genes and chromosomes are modeled as substrings of the genomes; thus, translocation is an operation that models the interaction between chromosomes inside a genome. The translocation distance between two genomes is defined as the minimum number of translocations to convert one genome into another and has been proved to be a meaningful manner of modeling the evolutive distance between organisms. The particular case of unsigned genomes, those in which the orientation of the genes are not considered, is particularly difficult, while the signed case, in which the orientation of genes is considered, has been proved to be polynomially decidable. This paper presents an innovative Genetic Algorithm (GA) approach to solve the unsigned translocation distance problem. A distinguishing feature of the proposed GA is that it uses as fitness function the translocation distance for randomly generated signed versions of the input (that is an unsigned genome). Experiments over randomly generated strings (synthetic genomes) showed that the proposed GA approach computes answers that are better than those computed by an L5+ε-approximation algorithm, the latter also implemented as part of this work.	artificial gene synthesis;computable function;experiment;fitness function;genetic algorithm;heuristic (computer science);memetics;procedural generation;sequence database;substring;synthetic intelligence;time complexity	Lucas A. da Silveira;José Luis Soncco-Álvarez;Thaynara A. de Lima;Mauricio Ayala-Rincón	2015	2015 Latin American Computing Conference (CLEI)	10.1109/CLEI.2015.7359994	combinatorics;discrete mathematics;mathematics;algorithm	Comp.	15.892765146244308	22.425315760561798	34412
9648592781440d48ba44a56fe199ec639e7add8e	approximate solution of np optimization problems	classe ptas;approximate algorithm;algorithmique;aproximacion;clase complejidad;satisfiabilite;probleme np dur;problema np duro;definability;reducibility;satisfiability;reductibilidad;approximation;optimisation combinatoire;optimization problem;np hard problem;classe complexite;complexity class;algorithmics;algoritmica;approximate solution;classe apx;probleme optimisation np;completitud;completeness;combinatorial optimization;completude;classe fptas;definissabilite;optimizacion combinatoria;reductibilite	This paper presents the main results obtained in the field of approximation algorithms in a unified framework. Most of these results have been revisited in order to emphasize two basic tools useful for characterizing approximation classes, that is, combinatorial properties of problems and approximation preserving reducibilities. In particular, after reviewing the most important combinatorial characterizations of the classes PTAS and FPTAS, we concentrate on the class APX and, as a concluding result, we show that this class coincides with the class of optimization problems which are reducible to the maximum satisfiability problem with respect to a polynomialtime approximation preserving reducibility.	apx;approximation algorithm;boolean satisfiability problem;central processing unit;clique problem;communication endpoint;decision problem;emoticon;enrico clementi;greedy algorithm;local search (optimization);miriam registry;mathematical optimization;max;maximum satisfiability problem;np (complexity);np-hardness;optimization problem;p versus np problem;ptas reduction;planar graph;polynomial;polynomial-time approximation scheme;probabilistically checkable proof;snp (complexity);spanning tree;steiner tree problem;substring;time complexity;tree (data structure);turing completeness;unified framework	Giorgio Ausiello;Pierluigi Crescenzi;Marco Protasi	1995	Theor. Comput. Sci.	10.1016/0304-3975(94)00291-P	complexity class;optimization problem;mathematical optimization;combinatorics;discrete mathematics;polynomial-time approximation scheme;apx;combinatorial optimization;completeness;computer science;approximation;np-hard;mathematics;algorithmics;approximation algorithm;algorithm;satisfiability	Theory	16.18972403634817	19.669964989469452	34424
33f54474e94e5ed6be271a2d7c4aadab94d34818	multi-directional width-bounded geometric separator and protein folding	modelizacion;subgrafo;proteine;folding;separador;pliage;upper bound;grid;modelisation;sous graphe;rejilla;exact algorithm;doblado;borne inferieure;grille;protein folding;proteina;separator;subgraph;borne superieure;protein;modeling;separateur;lower bound;cota superior;cota inferior	We introduce the concept of multi-directional width-bounded geometric separator and get improved separator for the grid graph, which improves exact algorithm for the protein folding problem in the HPmodel. For a grid graph G with n grid points P , there exists a separator A ⊆ P such that A has less than or equal to 1.02074√n points, and G − A has two disconnected subgraphs with less than or equal to 2 3 n nodes on each of them. We also derive 0.7555 √ n lower bound for such a separator on grid graph. The previous upper bound record for the grid graph 2 3 -separator is 1.129 √ n [6].	exact algorithm;geometric separator;lattice graph;protein structure prediction	Bin Fu;Sorinel Adrian Oprisan;Lizhe Xu	2005		10.1007/11602613_99	vertex separator;combinatorics;mathematics;geometry;upper and lower bounds;algorithm	Theory	23.541776201393848	29.692588814999358	34477
87b35d99e93f7c7cb0849a86f429ccba5ca0d870	random nondeterministic real functions and arthur merlin games		We construct a nondeterministic version of APP, denoted NAPP, which is the set of all real valued functions f : f0;1g ! 0; 1], that are approximable within 1/k, by a probabilistic nondeterministic transducer, in time poly(1 k ; n). We show that the subset of all Boolean functions in NAPP is exactly AM. We exhibit a natural complete problem for NAPP, namely computing the acceptance probability of a nondeterministic Boolean circuit. Then we prove that similarly to AM, the error probability for NAPP functions can be reduced exponentially. We also give a co-nondeterministic version, denoted coNAPP, and prove that all results for NAPP also hold for coNAPP. Then we construct two mappings between NAPP and promise-AM, which preserve completeness. Finally we show that in the world of deterministic computation, oracle access to AM is the same as oracle access to NAPP, i.e. P NAPP = P prAM .	boolean circuit;computation;deterministic automaton;nondeterministic algorithm;probabilistic automaton;transducer	Philippe Moser	2002	Electronic Colloquium on Computational Complexity (ECCC)		simulation;computer science;artificial intelligence	Theory	0.6664330633942106	21.675277449387117	34507
62424b58403d2e0c9f0fd23f5bbcfc37dde15e6e	on combinatorial generation of prefix normal words		A prefix normal word is a binary word with the property that no substring has more 1s than the prefix of the same length. This class of words is important in the context of binary jumbled string matching. In this paper we present an efficient algorithm for exhaustively listing the prefix normal words with a fixed length. The algorithm is based on the fact that the language of prefix normal words is a bubble language, a class of binary languages with the property that, for any word w in the language, exchanging the first occurrence of 01 by 10 in w results in another word in the language. We prove that each prefix normal word is produced in O(n) amortized time, and conjecture, based on experimental evidence, that the true amortized running time is O(polylog(n)).	amortized analysis;formal language;microsoft word for mac;string searching algorithm;substring;time complexity	Peter Burcsi;Gabriele Fici;Zsuzsanna Lipták;Frank Ruskey;Joe Sawada	2014		10.1007/978-3-319-07566-2_7	arithmetic;prefix;prefix code;kibibyte;prefix grammar;speech recognition;kraft's inequality;mathematics;yottabyte;algorithm	Logic	12.987203296725445	26.44246831790121	34509
bdb6f1767787d6323f854598b0f7d4f33b93ccb7	operational research and critical systems thinking - an integrated perspectivepart 2: or as argumentative practice	forecasting;combining ability;argumentacion;systems;reliability;argumentation;project management;information systems;professional practice;history;sistema critica;professional competence;ingenieria de sistemas;maintenance;pratique professionnelle;systeme critique;soft or;information technology;heuristic method;systems engineering;packing;metodo heuristico;systeme integre;sistema integrado;or education;operations research;location;practice of or;investment;journal;professional;journal of the operational research society;sistema reactivo;inventory;purchasing;philosophy of or;critical systems thinking;history of or;critical system;logistics;professional services;mathematical programming;marketing;scheduling;systems thinking;competence professionnelle;ingenierie systeme;reactive system;systeme reactif;production;communications technology;historia;methode heuristique;computer science;operational research;methodology;perfil profesional;arquetipo;integrated system;experience base;programmation mathematique;programacion matematica;practica profesional;histoire;applications of operational research;or society;jors;management science;infrastructure;archetype	On the basis of a review of the role of systems thinking in the history of OR, Part 1 of this essay proposed a systematic understanding of OR as applied systems thinking. Further, it identified the contribution of ‘critical’ systems thinking (CST) in a combined ability of its two strands, critical systems heuristics (CSH) and total systems intervention (TSI), to enhance the conceptual sophistication of OR. Part 2 aims to translate this understanding into a framework for good professional practice. How exactly can CST strengthen the competence profile of OR professionals? Drawing on three experience-based archetypes of professional service and some basic argumentation-theoretical considerations, a new understanding of OR and applied systems thinking as argumentative practice emerges. In this new understanding CST finds a systematic place and some exemplary uses of CSH and TSI can be located—an integrated perspective. Journal of the Operational Research Society (2012) 63, 1307–1322. doi:10.1057/jors.2011.145 Published online 14 December 2011	c shell;computer science tripos;critical systems thinking;heuristic (computer science);operations research;time-slot interchange	Werner Ulrich	2012	JORS	10.1057/jors.2011.145	project management;logistics;inventory;economics;forecasting;reactive system;investment;computer science;marketing;operations management;methodology;reliability;archetype;critical systems thinking;location;management;operations research;information technology;scheduling;systems thinking	AI	17.295699011177838	7.025273196464784	34521
31a98317204b05aa18937a79f24a58acc947deab	quantum turing automata		A denotational semantics of quantum Turing machines having a quantum control is defined in the dagger compact closed category of finite dimensional Hilber t spaces. Using the Moore-Penrose generalized inverse, a new additive trace is introduced on t he restriction of this category to isometries, which trace is carried over to directed quantum Turing machi nes as monoidal automata. The JoyalStreet-VerityInt construction is then used to extend this structure to a rever sibl bidirectional one.	automata theory;automaton;coherent control;denotational semantics;graph (discrete mathematics);hilbert space;moore–penrose pseudoinverse;quantum;science, industry and business library;turing machine;utility functions on indivisible goods	Miklós Bartha	2012		10.4204/EPTCS.143.2	hyperarithmetical theory;discrete mathematics;turing reduction;time hierarchy theorem;pspace;quantum finite automata;nspace;turing machine;universal turing machine;turing completeness;pure mathematics;description number;mathematics;probabilistic turing machine;computational complexity theory;categorical quantum mechanics;algorithm;quantum turing machine;register machine;super-recursive algorithm	Theory	1.2572985030506136	21.855092999297483	34663
70a65227f74fe3b2d5af40b22948bcd490edecbb	multi-agent scheduling on a single machine to minimize total weighted number of tardy jobs	temps polynomial;machine unique;probleme np complet;aproximacion;fonction objectif;approximation;feasibility;objective function;single machine;maquina unica;multi agent deterministic sequencing;informatique theorique;scheduling;polynomial time;funcion objetivo;fully polynomial time approximation scheme;problema np completo;practicabilidad;journal magazine article;faisabilite;ordonnancement;reglamento;np complete problem;computer theory;tiempo polinomial;informatica teorica	We consider the feasibility model of multi-agent scheduling on a single machine, where each agent’s objective function is to minimize the total weighted number of tardy jobs. We show that the problem is strongly NP-complete in general. When the number of agents is fixed, we first show that the problem can be solved in pseudo-polynomial time for integral weights, and can be solved in polynomial time for unit weights; then we present a fully polynomial-time approximation scheme for the problem.	approximation algorithm;loss function;multi-agent system;optimization problem;p (complexity);polynomial;polynomial-time approximation scheme;pseudo-polynomial time;scheduling (computing);strong np-completeness;time complexity	T. C. Edwin Cheng;Cai Tong Ng;J. J. Yuan	2006	Theor. Comput. Sci.	10.1016/j.tcs.2006.07.011	time complexity;feasibility study;mathematical optimization;combinatorics;polynomial-time approximation scheme;np-complete;computer science;approximation;mathematics;scheduling;algorithm	AI	17.168793493082234	10.394043595365698	34665
ee49849cfd59d1cdfeef03309621f18c1a5b6dc6	a randomized satisfiability procedure for arithmetic and uninterpreted function symbols	assignment;algoritmo aleatorizado;symbolic computation;asignacion;satisfactoriabilidad;automatic proving;algorithm performance;loi probabilite;ley probabilidad;variable aleatoire;linear arithmetic;competitive algorithms;satisfiabilite;assignation;variable aleatoria;plan randomise;algorithme deterministe;demostracion automatica;algorithme randomise;probabilistic approach;satisfiability;uninterpreted function symbols;calculo simbolico;demonstration automatique;algorithme competitif;aleatorizacion;deterministic algorithms;plan aleatorizado;satisfiability procedure;arithmetique lineaire;resultado algoritmo;randomized design;informatique theorique;enfoque probabilista;approche probabiliste;probability distribution;defaillance;random variable;performance algorithme;randomized algorithm;randomisation;ensemble aleatoire;satisfaisabilite;failures;randomization;calcul symbolique;fallo;random set;satisfactibilidad;computer theory;conjunto aleatorio;informatica teorica	We present a new randomized algorithm for checking the satisfiability of a conjunction of literals in the combined theory of linear equalities and uninterpreted functions. The key idea of the algorithm is to process the literals incrementally and to maintain at all times a set of random variable assignments that satisfy the literals seen so far. We prove that this algorithm is complete (i.e., it identifies all unsatisfiable conjunctions) and is probabilistically sound (i.e., the probability that it fails to identify satisfiable conjunctions is very small). The algorithm has the ability to retract assumptions incrementally with almost no additional space overhead. The algorithm can also be easily adapted to produce proofs for its output. The key advantage of the algorithm is its simplicity. We also show experimentally that the randomized algorithm has performance competitive with the existing deterministic symbolic algorithms.	randomized algorithm;uninterpreted function	Sumit Gulwani;George C. Necula	2005	Inf. Comput.	10.1016/j.ic.2004.10.006	randomization;probability distribution;random variable;discrete mathematics;symbolic computation;assignment;mathematics;randomized algorithm;completely randomized design;algorithm;difference-map algorithm;statistics;satisfiability	Logic	10.617553405301955	18.2795729378974	34670
61271c1c24bf585e624e20809280864d5b51c7a3	structure theory and fpt algorithmics for graphs, digraphs and hypergraphs, 08.07. - 13.07.2007	structuration theory		algorithmics;directed graph;parameterized complexity		2007			combinatorics;discrete mathematics;mathematics	Theory	23.51445274460546	25.74384619722778	34710
139b119c63aaf77e73989e2d85d51dfadc0ee7b5	automata on directed graphs: edge versus vertex marking	modelizacion;transformacion grafo;digraph;automata estado finito;maquina estado finito;digrafo;logica monadica;mu calculo;graph transformation;expressive power;modelisation;transformation graphe;finite state automata;directed graph;vertex graph;graphe oriente;logique monadique;edge graph;arete graphe;monadic logic;grafo orientado;finite automaton;automate fini;machine etat fini;modeling;finite state machine;vertice grafo;mu calculus;arista grafico;sommet graphe;mu calcul;regularity condition;digraphe	We investigate two models of finite-state automata that operate on rooted directed graphs by marking either vertices (V-automata) or edges (E-automata). Runs correspond to locally consistent markings and acceptance is defined by means of regular conditions on the paths emanating from the root. Comparing the expressive power of these two notions of graph acceptors, we show that E-automata are more expressive than V-automata. Moreover, we prove that E-automata are at least as expressive as the μ-calculus. Our main result implies that every MSOdefinable tree language can be recognised by E-automata with uniform runs, that is, runs that do not distinguish between isomorphic subtrees.	automata theory;directed graph;expressive power (computer science);finite-state machine;item unique identification;tree (data structure);tree automaton	Dietmar Berwanger;David Janin	2006		10.1007/11841883_5	combinatorics;discrete mathematics;directed graph;computer science;mathematics;finite-state machine;programming language;algorithm	Theory	-4.33465225765342	21.311672916237136	34721
11fb037bb9bbb9a3843fd8eb120e80343b30653a	independence and coloring problems on intersection graphs of disks	conjunto independiente;graph theory;coloracion grafo;teoria grafo;independent set;competitividad;on line;en linea;approximation algorithm;theorie graphe;optimisation combinatoire;upper bound;ensemble independant;coloration graphe;algoritmo aproximacion;borne inferieure;competitiveness;en ligne;algorithme approximation;borne superieure;combinatorial optimization;competitivite;lower bound;cota superior;graph colouring;cota inferior;optimizacion combinatoria	This chapter surveys on-line and approximation algorithms for the maximum independent set and coloring problems on intersection graphs of disks. It includes a more detailed treatment of recent upper and lower bounds on the competitive ratio of on-line algorithms for coloring such graphs.	floppy disk	Thomas Erlebach;Jirí Fiala	2006		10.1007/11671541_5	1-planar graph;mathematical optimization;brooks' theorem;combinatorics;topology;fractional coloring;combinatorial optimization;graph theory;complete coloring;edge coloring;graph coloring;mathematics;geometry;maximal independent set;upper and lower bounds;chordal graph;greedy coloring;indifference graph;approximation algorithm;algorithm	Theory	18.766270535775558	26.308371290989395	34784
c93b16b2c85489ffdc1eabf760bfb97e7a5bad19	profile-based control for central domestic hot water distribution	district heating;buildings reliability dh hemts water heating boilers;district heating building management systems building simulation;building management systems;building simulation;profile based control strategy water heating systems energy losses water losses building simulation optimized water energy management user behavioral pattern context aware enhancements cdhw systems central domestic hot water distribution;habit based control building simulation dhw control energy profiling	A main goal of hot water distribution research is to improve the system's efficiency, i.e., to fulfill hot water requirements while minimizing energy and water losses. Central domestic hot water (CDHW) systems represent an important part of current installations worldwide, e.g., hotels, hospitals, sports centers, social facilities, and multifamily residential or apartment buildings. The optimization of such systems claims for forecasting capabilities and context-aware enhancements are based on patterns of use. Thus, the level of uncertainty is reduced, and systems are not forced to operate using blind/oversized/generic assumptions. This paper presents a novel control strategy based on habit profiles for the management of a CDHW system. A simulated environment is utilized to compare the introduced strategy with habitual performances. Simulations are supported by real databases concerning users' behavioral patterns. Results are promising and point to place profile-based strategies as a suitable approach for an optimized water and energy management in future buildings.	algorithm;bsd;behavioral pattern;coefficient;computer simulation;control system;control theory;database;fuzzy concept;home automation;mathematical optimization;performance;requirement;setpoint (control system);soft computing;virtual reality	Félix Iglesias;Peter Palensky	2014	IEEE Transactions on Industrial Informatics	10.1109/TII.2013.2275032	building management system;simulation;environmental engineering;computer science;engineering;computer network	Robotics	5.264921592404973	6.271971761847615	34797
2b07752fd2de86e8a27c082c7896787f63853cda	compressing multisets using tries	decoding channel coding conferences complexity theory entropy manganese;data compression;set theory;trie data structure multiset compression multiset lossless representation multiset encoding multiset encoder multiset decoder o m n log m operation o mn operation multiset cardinality constant factor;computational complexity;data structures;set theory computational complexity data compression data structures	We consider the problem of efficient and lossless representation of a multiset of m words drawn with repetition from a set of size 2n. One expects that encoding the (unordered) multiset should lead to significant savings in rate as compared to encoding an (ordered) sequence with the same words, since information about the order of words in the sequence corresponds to a permutation. We propose and analyze a practical multiset encoder/decoder based on the trie data structure. The act of encoding requires O(m(n + log m)) operations, and decoding requires O(mn) operations. Of particular interest is the case where cardinality of the multiset scales as m = 1/c2n for some c >; 1, as n → ∞. Under this scaling, and when the words in the multiset are drawn independently and uniformly, we show that the proposed encoding leads to an arbitrary improvement in rate over encoding an ordered sequence with the same words. Moreover, the expected length of the proposed codes in this setting is asymptotically within a constant factor of 5/3 of the lower bound.	algorithm;bernoulli polynomials;code;computational complexity theory;data structure;encoder;image scaling;lookup table;lossless compression;lossy compression;lucas sequence;scalability;trie;unordered associative containers (c++)	Vincent Gripon;Michael G. Rabbat;Vitaly Skachek;Warren J. Gross	2012	2012 IEEE Information Theory Workshop	10.1109/ITW.2012.6404756	combinatorics;discrete mathematics;mathematics;algorithm	Theory	11.735647801104946	26.70533353167206	34801
080c95e509c41316133291b6857a3fabe1067a37	integrality gaps for strengthened linear relaxations of capacitated facility location	90b80;operations research;mathematical programming;discrete location and assignment	Metric uncapacitated facility location is a well-studied problem for which linear programming methods have been used with great success in deriving approximation algorithms. Capacitated facility location (Cfl) is a generalization for which there are local-search-based constant-factor approximations, while there is no known compact relaxation with constant integrality gap. This paper produces, through a host of impossibility results, the first comprehensive investigation of the effectiveness of mathematical programming for metric capacitated facility location, with emphasis on lift-and-project methods. We show that the relaxations obtained from the natural LP at Ω(n) levels of the semidefinite Lovász-Schrijver hierarchy for mixed programs, and at Ω(n) levels of the Sherali-Adams hierarchy, have an integrality gap of Ω(n), where n is the number of facilities, partially answering an open question of [41, 5]. For the families of instances we consider, both hierarchies yield at the nth level an exact formulation for Cfl. Thus our bounds are asymptotically tight. Building on our methodology for the Sherali-Adams result, we prove that the standard Cfl relaxation enriched with the submodular inequalities of [1], a generalization of the flow-cover valid inequalities, has also an Ω(n) gap and thus not bounded by any constant. This disproves a long-standing conjecture of [39]. We finally introduce the family of proper relaxations which generalizes to its logical extreme the classic star relaxation and captures general configuration-style LPs. We characterize the behavior of proper relaxations for Cfl through a sharp threshold phenomenon. Mathematics Subject Classification (2010) 90B80 Operations Research, Mathematical Programming; discrete location and assignment	alexander schrijver;approximation algorithm;facility location problem;least squares;linear multistep method;linear programming relaxation;mathematical optimization;mathematics subject classification;operations research;polynomial;star height;submodular set function;time complexity	Stavros G. Kolliopoulos;Yannis Moysoglou	2016	Math. Program.	10.1007/s10107-015-0916-z	mathematical optimization;combinatorics;mathematics;algorithm	Theory	22.83838474002271	15.787562796448983	34828
c797d4bb9b88d96b40aef130f3f157f69355d39e	speeding up dynamic programming without omitting any optimal solution and some applications in molecular biology (revised form of the reports no. 8586-cs, 8587-cs, and 8588-cs)	dynamic programming;optimal solution;solution optimale;programacion dinamica;cost function;graphe programmation dynamique;efficient algorithm;biologia molecular;dynamic program;genetics;algorithme;acceleration convergence;algorithm;compact representation;molecular biology;solucion optima;dynamic program graph;algorithme galil giancarlo;galil giancarlo algorithm;programmation dynamique;aceleracion convergencia;local alignment;algoritmo;convergence acceleration;biologie moleculaire	We extend the algorithm of Galil and Giancarlo, which speeds up dynamic programming in the case of concave cost functions, such that a compact representation of all optimal solutions is computed. Compared to the Galil-Giancarlo algorithm our time bound grows only by a small constant factor. With a compact representation, we develop eecient algorithms for the solution of problems in molecular biology concerning the computation of all optimal local alignments and all optimal subalignments in genetic sequences.	algorithm;blum axioms;computation;computer scientist;concave function;dynamic programming;local optimum;loss function;sequence alignment	Norbert Blum	1994	J. Algorithms	10.1006/jagm.2000.1078	mathematical optimization;computer science;theoretical computer science;dynamic programming;smith–waterman algorithm;mathematics;algorithm	Theory	16.532556773114013	23.545336229307797	34834
bbe2b730c2505529d49e1b106690e86919fc38a9	implementation and computational comparisons of primal, dual and primal-dual computer codes for minimum cost network flow problems	computations;simplex method;computer programming;mathematical models;network flows;transportation;linear programming;algorithms;fortran;network flow	Abstract : The paper presents extensive computational experience with a special purpose primal simplex algorithm. The performance is compared to that of several 'state of the art' out-of-kilter computer codes. The computational characteristics of several different primal feasible start procedures and pivot selection strategies are also examined. The study discloses the advantages, in both computation time and memory requirements, of the primal approach over the out-of-kilter method. The test environment has the following distinguishing properties: (1) all of the codes are tested on the same machine and the same problems, (2) the test set includes capacitated and uncapacitated transhipment networks, transportation problems, and assignment problems, and (3) problem sizes ranging from 100 to 8,000 nodes with up to 35,000 arcs are examined. (Author)	code;flow network	Fred Glover;David Karney;Darwin Klingman	1974	Networks	10.1002/net.3230040302	mathematical optimization;combinatorics;flow network;computer science;linear programming;theoretical computer science;mathematics;algorithm	Theory	24.280569250252857	10.24810050828897	34840
daf9e61b5410e2f9c145386467f4aca0fba1cc2d	intelligent parking systems	systeme stationnement intelligent;programacion entera;revenue management;uncertainty modeling;fuzzy programming;parking;stationnement;logique floue;estacionamiento;logica difusa;logical programming;modelisation incertitude;intelligent control;programmation en nombres entiers;fuzzy logic;integer programming;programmation logique;traffic;control;programmation floue;integer program;programacion logica;inventory control;programacion difusa;controle intelligent	The basic concepts of the parking reservation system and parking revenue management system are discussed in this paper. The proposed “intelligent” parking space inventory control system that is based on a combination of fuzzy logic and integer programming techniques makes “on line” decisions whether to accept or reject a new driver’s request for parking. In the first step of the proposed model, the best parking strategies are developed for many different patterns of vehicle arrivals. These parking strategies are developed using integer programming approach. In the second step, learning from the best strategies, specific rules are defined. The uniqueness of the proposed approach is that the rules are derived from the set of chosen examples assuming that the future traffic arrival patterns are known. The results were found to be close to the best solution assuming that the future arrival pattern is known.		Dusan Teodorovic;Panta Lucic	2006	European Journal of Operational Research	10.1016/j.ejor.2005.02.033	fuzzy logic;inventory control;simulation;integer programming;computer science;artificial intelligence;operations management;parking guidance and information;scientific control;intelligent control	Robotics	10.28175062998384	7.009318306304112	34909
c2087756d925a4f32ed9db6eca423ed98152b6a6	improved extractors for recognizable and algebraic sources		We study the task of seedless randomness extraction from recognizable sources, which are uniform distributions over sets of the form {x : f(x) = v} for functions f in some specified class C. We give two simple methods for constructing seedless extractors for C-recognizable sources. Our first method shows that if C admits XOR amplification, then we can construct a seedless extractor for C-recognizable sources by using a mildly hard function for C as a black box. By exploiting this reduction, we give polynomial-time, seedless randomness extractors for algebraic sources over any prime field, where algebraic sources are uniform distributions over the set of solutions of a system of low degree polynomials. In particular, the new extractor has linear output length and exponentially small error for min-entropy k ≥ (1− α)n, where α > 0 is a small enough constant. Our second method shows that a seed-extending pseudorandom generator with exponentially small error for C yields an extractor with exponentially small error for C-recognizable sources, improving a reduction by Kinne, Melkebeek, and Shaltiel [KvMS12]. Using the hardness of the parity function against AC0 [H̊as87], we significantly improve Shaltiel’s extractor [Sha11] for AC0-recognizable sources. Finally, assuming sufficiently strong one-way permutations, we construct seedless extractors for sources recognizable by BPP algorithms, and these extractors run in quasi-polynomial time. ∗Supported by NSF Grant CCF-1526952, NSF Grant CCF-1705028, and a Simons Investigator Award (#409864, David Zuckerman). ISSN 1433-8092 Electronic Colloquium on Computational Complexity, Report No. 110 (2018)	ac0;algebraic equation;algorithm;bpp (complexity);black box;electronic colloquium on computational complexity;exclusive or;ibm notes;international standard serial number;keneth alden simons;maxima and minima;one-way function;parity function;polynomial;pseudorandom generator;pseudorandomness;quasi-polynomial;randomness extractor;time complexity	Fu Li;David Zuckerman	2018	Electronic Colloquium on Computational Complexity (ECCC)		algebraic number;combinatorics;discrete mathematics;mathematics	Theory	11.553715258340798	21.805894556823464	34945
06b7e0cd3c8111f383bbe93cb720b86ab65e31d1	"""erratum to """"a new branch and bound method with pretreatment for the binary quadratic programming"""" [appl. math. comput. 192(2007) 252-259]"""	quadratic program;branch and bound method	We present in this note, an Erratum in “A new branch and bound method with pretreatment for the binary quadratic programming” by Xuewen Mu et al.	branch and bound;quadratic programming	Morteza Pakdaman	2011	Applied Mathematics and Computation	10.1016/j.amc.2011.01.017	mathematical optimization;combinatorics;mathematics;algorithm	Theory	23.71220748188736	9.397761336349381	35010
419f9a4b03a45ca4a31d724863a936cd038f2f45	the open vehicle routing problem with time windows	distribution;intervalo tiempo;flotte;insertion;modelizacion;forecasting;reliability;project management;information systems;formacion;maintenance;routing;vehicle routing problem;soft or;information technology;heuristic method;packing;time window;routage;vehicle routing;metodo heuristico;probleme tournee vehicule;problema ruta vehiculo;operations research;location;time interval;investment;journal;journal of the operational research society;formation;inventory;service utilisateur;purchasing;modelisation;history of or;logistics;insercion;marketing;vehicle routing problem with time windows;scheduling;fleet;production;communications technology;fenetre temporelle;heuristics;methode heuristique;computer science;servicio usuario;operational research;ventana temporal;user service;modeling;applications of operational research;or society;jors;management science;infrastructure;intervalle temps;enrutamiento	In this paper, we consider the open vehicle routing problem with time windows (OVRPTW). The OVRPTW seeks to find a set of non-depot returning vehicle routes, for a fleet of capacitated vehicles, to satisfy customers’ requirements, within fixed time intervals that represent the earliest and latest times during the day that customers’ service can take place. We formulate a comprehensive mathematical model to capture all aspects of the problem, and incorporate in the model all critical practical concerns. The model is solved using a greedy look-ahead route construction heuristic algorithm, which utilizes time windows related information via composite customer selection and route-insertion criteria. These criteria exploit the interrelationships between customers, introduced by time windows, that dictate the sequence in which vehicles must visit customers. Computational results on a set of benchmark problems from the literature provide very good results and indicate the applicability of the methodology in real-life routing applications.	microsoft windows;vehicle routing problem	Panagiotis P. Repoussis;Christos D. Tarantilis;George Ioannou	2007	JORS	10.1057/palgrave.jors.2602143	distribution;insertion;logistics;routing;simulation;inventory;economics;forecasting;investment;computer science;marketing;operations management;operating system;heuristics;vehicle routing problem;reliability;mathematics;location;management;operations research;scheduling	Theory	17.65596947293967	5.348011310743651	35079
ebc468ce063c5c1a95c93a11e4a02d6a866d26d5	a spanning tree method for bounding hitting times of random walks on graphs	arbre graphe;random graph;spanning trees;random walks on graphs;mathematiques discretes;tree graph;matematicas discretas;grafo aleatorio;arbre maximal;discrete mathematics;graphe aleatoire;calculo automatico;methode calcul;computing;calcul automatique;upper bound;metodo calculo;arbol maximo;random walk;hitting time;vertex graph;05c85;05c80;60j10;spanning tree;marcha aleatoria;arbol grafo;borne superieure;marche aleatoire;vertice grafo;computing method;sommet graphe;hitting times;cota superior	In this paper we consider the problem of computing the expected hitting time to a vertex for random walks on graphs. We give a method for computing an upper bound on the expected hitting time from an arbitrary spanning tree of the graph. We illustrate this method with two examples. In these examples, we show that the bounds obtained from the spanning method are sharper than bounds obtained from other commonly used techniques.	directed graph;file spanning;spanning tree	Randy Cogill;Cheng Peng	2010	SIAM J. Discrete Math.	10.1137/090758982	random graph;combinatorics;discrete mathematics;topology;minimum degree spanning tree;spanning tree;minimum spanning tree;loop-erased random walk;mathematics;hitting time	Theory	23.718155950860336	31.61544387482407	35105
31b1e592435d4ef8429e0c98966aebd580104ec6	solving capacitated facility location problems by fenchel cutting planes	location problem;probleme localisation;probleme sac a dos;localisation installation;cutting planes;programacion entera;cutting plane;profundidad penetracion;heuristic method;capacitated facility location problem;metodo heuristico;problema mochila;location;programmation en nombres entiers;optimisation combinatoire;knapsack problem;branch and bound method;penetration depth;integer programming;metodo branch and bound;metodo plano secante;fabrica;industrial plant;heuristics;problema localizacion;methode heuristique;methode separation et evaluation;methode plan secant;profondeur penetration;combinatorial optimization;cutting plane method;usine;facility location;optimizacion combinatoria	In this paper, we apply the Fenchel cutting planes methodology to Capacitated Facility Location problems. We select a suitable knapsack structure from which depth cuts can be obtained. Moreover, we simultaneously obtain a primal heuristic solution. The lower and upper bounds achieved by our procedure are compared with those provided by Lagrangean relaxation of the demand constraints. As the computational results show the Fenchel cutting planes methodology outperforms the Lagrangean one, both in the obtaining of the bounds and in the effectiveness of the branch and bound algorithm using each relaxation as the initial formulation.	facility location problem	M. T. Ramos;J. Sáez	2005	JORS	10.1057/palgrave.jors.2601810	mathematical optimization;combinatorics;integer programming;combinatorial optimization;mathematics;cutting-plane method	Theory	22.040899276491213	11.693725246383247	35114
16ab2676b08ff1d4eee1b888e57607d2a9374414	submodular functions are noise stable	learning algorithm;game theory;product distribution;science learning;computational complexity;polynomial time;submodular functions	We show that all non-negative submodular functions have high noise-stability. As a consequence, we obtain a polynomial-time learning algorithm for this class with respect to any product distribution on {−1, 1} (for any constant accuracy parameter ). Our algorithm also succeeds in the agnostic setting. Previous work on learning submodular functions required either query access or strong assumptions about the types of submodular functions to be learned (and did not hold in the agnostic setting). Additionally we give simple algorithms that efficiently release differentially private answers to all Boolean conjunctions and to all halfspaces with constant average error, subsuming and improving the recent work due to Gupta, Hardt, Roth and Ullman (STOC 2011).	polynomial;realms of the haunting;sethi–ullman algorithm;submodular set function;symposium on theory of computing;time complexity	Mahdi Cheraghchi;Adam R. Klivans;Pravesh Kothari;Homin K. Lee	2011	Electronic Colloquium on Computational Complexity (ECCC)		time complexity;game theory;mathematical optimization;combinatorics;product distribution;computer science;submodular set function;machine learning;mathematics;computational complexity theory;algorithm	Theory	9.702152786711311	19.5544547629883	35123
c9b838436599732cb06128bd9f5e187975739ed7	non-stationary random process for large-scale failure and recovery of power distributions	power distribution;real data;resilience;non stationary random process;transient little s law;dynamic queue	A key objective of the smart grid is to improve reliability of utility services to end users. This requires strengthening resilience of distribution networks that lie at the edge of the grid. However, distribution networks are exposed to external disturbances such as hurricanes and snow storms where electricity service to customers is disrupted repeatedly. External disturbances cause large-scale power failures that are neither well-understood, nor formulated rigorously, nor studied systematically. This work studies resilience of power distribution networks to large-scale disturbances in three aspects. First, a nonstationary random process is derived to characterize an entire life cycle of large-scale failure and recovery. Second, resilience is defined based on the non-stationary random process. Close form analytical expressions are derived under specific largescale failure scenarios. Third, the non-stationary model and the resilience metric are applied to a real life example of largescale disruptions due to Hurricane Ike. Real data on large-scale failures from an operational network is used to learn time-varying model parameters and resilience metrics.	internet key exchange;real life;stationary process;stochastic process	Yun Wei;Chuanyi Ji;Floyd Galvan;Stephen Couvillon;George Orellana;James Momoh	2012	CoRR	10.4236/am.2016.73022	psychological resilience	HPC	-2.769300687736315	7.257531527028059	35160
0e2a1e5c5e69113850885613fba674f7b7bc8091	resolution for max-sat	probleme satisfiabilite;weighted max sat;max sat;resolution;saturacion;formule cnf;maximum satisfiability;intelligence artificielle;program verification;satisfiability;satisfiabilite maximum;upper bound;verificacion programa;calcul raffinement;formula cnf;exact algorithm;problema satisfactibilidad;refinement calculus;borne inferieure;artificial intelligence;inteligencia artificial;conjunctive normal form;completeness;satisfiabilidad maxima;borne superieure;verification programme;satisfiability problem;saturation;lower bound;cota superior;cota inferior	Max-SAT is the problem of finding an assignment minimizing the number of unsatisfied clauses in a CNF formula. We propose a resolution-like calculus for Max-SAT and prove its soundness and completeness. We also prove the completeness of some refinements of this calculus. From the completeness proof we derive an exact algorithm for Max-SAT and a time upper bound. We also define a weighted Max-SAT resolution-like rule, and show how to adapt the soundness and completeness proofs of the Max-SAT rule to the weighted Max-SAT rule. Finally, we give several particular Max-SAT problems that require an exponential number of steps of our Max-SAT rule to obtain the minimal number of unsatisfied clauses of the combinatorial principle. These results are based on the corresponding resolution lower bounds for those particular problems. © 2007 Elsevier B.V. All rights reserved.	boolean satisfiability problem;conjunctive normal form;constraint satisfaction problem;cryptographic service provider;dpll algorithm;davis–putnam algorithm;emoticon;exact algorithm;logical framework;maximum satisfiability problem;polynomial;putnam model;refinement (computing);resolution (logic);solver;time complexity	Maria Luisa Bonet;Jordi Levy;Felip Manyà	2007	Artif. Intell.	10.1016/j.artint.2007.03.001	discrete mathematics;computer science;artificial intelligence;mathematics;upper and lower bounds;algorithm	AI	5.545539823982699	21.12853139738176	35191
ea8728c21c160668b6c00b98bbd4b3046602bcaf	linearity and unprovability of set union problem strategies. i. linearity of strong postorder	graph theory;complexite calcul;theorie graphe;computational complexity	Abstract   In this paper we prove that strong postorder path compression systems have linear growth.	tree traversal	Martin Loebl;Jaroslav Nesetril	1997	J. Algorithms	10.1006/jagm.1996.0815	combinatorics;graph theory;mathematics;computational complexity theory;algorithm	Theory	19.487631755110794	24.66925044601204	35205
bcecdcf59e3a639efe3d074ee46a5420a163449e	complexity measures for assembly sequences	optimisation;np complete problem complexity measures assembly sequences optimization manufacturing process geometric model;cost function;optimisation production control assembling computational complexity computational geometry;manufacturing process;computational geometry;polynomials;assembly;manufacturing processes;production control;cost optimization;computational complexity;approximate solution;assembly solid modeling manufacturing processes whales cost function computer science automation humans system testing polynomials;assembling;solid modeling;assembly sequences;complexity measures;system testing;optimization;geometric model;humans;whales;computer science;np complete problem;automation	Our work examines various complexity measures for two-handed assembly sequences. For many products there exists an exponentially large set of valid sequences, and a natural goal is to use automated systems to select wisely from the choices. Since assembly sequencing is a preprocessing phase for a long and expensive manufacturing process, any work towards nding a better assembly sequence is of great value when it comes time to assemble the physical product in mass quantities. Although there has been a great deal of algorithmic success for nding feasible assembly sequences, there has been very little success towards optimizing the costs of sequences. We attempt to explain this lack of progress, by proving the inherent di culty in nding optimal, or even near-optimal, assembly sequences. We begin by introducing a formal framework for studying the optimization of several complexity measures. We consider a variety of di erent settings and natural cost measures for assembly sequences. Following which, we de ne a graph-theoretic problem which is a generalization of assembly sequencing, focusing on the combinatorial aspect of the family of feasible assembly sequences, while temporarily separating out the speci c geometric assumptions inherent, to assembly sequencing. For our virtual assembly sequencing problem we are able to use techniques common to the theory of approximability to prove the hardness of nding even near{optimal sequences for most cost measures in our generalized framework. As a special case, we prove strong inapproximability results for the problem of scheduling with and/or precedence constraints. Of course, hardness results in our generalized framework do not immediately carry over to the original geometric problems. We continue by realizing several of these hardness results in rather simple geometric settings, proving the di culty of some of the original problems. We are able to show strong inapproximability results in a far simpler setting than the domain of most assembly sequencers, for example using an assembly consisting solely of unit disks in the plane. These inapproximability results, to the best of our knowledge, are the strongest hardness results known for a purely combinatorial problem in a geometric setting. Supported by a grant from the Stanford Integrated Manufacturing Association (SIMA), by NSF/ARPA Grant IRI9306544, by NSF Grant CCR-9215219, by ARO MURI Grant DAAH04-96-1-0007 and by NSF Award CCR-9357849, with matching funds from IBM, Mitsubishi, Schlumberger Foundation, Shell Foundation, and Xerox Corporation. Supported by an Alfred P. Sloan Research Fellowship, an IBM Faculty Partnership Award, an ARO MURI Grant DAAH04-96-1-0007, and NSF Young Investigator Award CCR-9357849, with matching funds from IBM, Mitsubishi, Schlumberger Foundation, Shell Foundation, and Xerox Corporation.	approximation algorithm;assembly language;complexity;graph theory;hardness of approximation;ibm notes;mathematical optimization;preprocessor;scheduling (computing)	Michael H. Goldwasser;Jean-Claude Latombe;Rajeev Motwani	1996		10.1109/ROBOT.1996.506981	mathematical optimization;np-complete;computational geometry;computer science;geometric modeling;automation;mathematics;assembly;solid modeling;computational complexity theory;system testing;algorithm;polynomial	Theory	19.646777395515	14.144155515090986	35266
27dcfcc86a0003b73982f81dd91ff1eb3a8f7127	graph properties checkable in linear time in the number of vertices	second order;existential second order logic;time complexity;combinatorial problems;nondeterminism;complexity lower bounds;complexity class;linear time;transitive closure;finite model theory;lower bound	This paper originates from the observation that many classical NP graph problems, including some NPcomplete problems, are actually of very low nondeterministic time complexity. In order to formalize this observation, we define the complexity class vertexNLIN, which collects the graph problems computable on a nondeterministic RAM in time OðnÞ; where n is the number of vertices of the input graph G 1⁄4 ðV ;EÞ; rather than its usual size jV j þ jEj: It appears that this class is robust (it is defined by a natural restrictive computational device; it is logically characterized by several simple fragments of existential second-order logic; it is closed under various combinatorial operators, including some restrictions of transitive closure) and meaningful (it contains many natural NP problems: connectivity, hamiltonicity, non-planarity, etc.). Furthermore, the very restrictive definition of vertexNLIN seems to have beneficial effects on our ability to answer difficult questions about complexity lower bounds or separation between determinism and nondeterminism. For instance, we prove that vertexNLIN strictly contains its deterministic counterpart, vertexDLIN, and even that it does not coincide with its complementary class, co-vertexNLIN. Also, we prove that several famous graph problems (e.g. planarity, 2-colourability) do not belong to vertexNLIN, although they are computable in deterministic time OðjV j þ jEjÞ: r 2003 Elsevier Inc. All rights reserved.	adjacency matrix;complexity class;computable function;computation;computational complexity theory;cubic function;dtime;decision problem;descriptive complexity theory;directed acyclic graph;directed graph;euler;first-order predicate;first-order reduction;general-purpose modeling;graph coloring;graph property;hamiltonian path;higher-order function;information;karp's 21 np-complete problems;michael garey;model of computation;np (complexity);ntime;p (complexity);planar (computer graphics);planar graph;polynomial;programming paradigm;random-access memory;time complexity;time hierarchy theorem;transitive closure;unary operation;unbounded nondeterminism;vertex (geometry);vertex (graph theory)	Etienne Grandjean;Frédéric Olive	2004	J. Comput. Syst. Sci.	10.1016/j.jcss.2003.09.002	time complexity;combinatorics;discrete mathematics;feedback vertex set;computer science;cycle graph;mathematics;algorithm	Theory	21.77053577529979	23.814768159964423	35298
c97495477b11c2d2dd69e5a1335a5175e8a11285	optimization with more than one budget	shortest path;random polynomials;independent set;topological properties;optimization problem;polynomial time;approximation scheme;spanning tree;data structure;budget constraint;perfect match	A natural way to deal with multiple, partially conflicting objectives is turning all the objectives but one into budget constraints. Some classical polynomial-time optimization problems, such as spanning tree and forest, shortest path, (perfect) matching, independent set (basis) in a matroid or in the intersection of two matroids, become NP-hard even with one budget constraint. Still, for most of these problems deterministic and randomized polynomial-time approximation schemes are known. In the case of two or more budgets, typically only multi-criteria approximation schemes are available, which return slightly infeasible solutions. Not much is known however for the case of strict budget constraints: filling this gap is the main goal of this paper. We show that shortest path, perfect matching, and spanning tree (and hence matroid basis and matroid intersection basis) are inapproximable already with two budget constraints. For the remaining problems, whose set of solutions forms an independence system, we present deterministic and randomized polynomial-time approximation schemes for a constant number k of budget constraints. Our results are based on a variety of techniques: 1. We present a simple and powerful mechanism to transform multi-criteria approximation schemes into pure approximation schemes. This gives, for example, deterministic approximation schemes for k-budgeted forest and bipartite matching, and randomized approximation schemes for k-budgeted matching, independent set in matroids, and independent set in the intersection of two representable matroids. 2. We show that points in low dimensional faces of any matroid polytope are almost integral, an interesting result on its own. This gives a deterministic approximation scheme for k-budgeted matroid independent set. 3. We present a deterministic approximation scheme for 2-budgeted matching. The backbone of this result is a purely topological property of curves in R.	basis (linear algebra);deterministic algorithm;file spanning;friedrich kittler;independent set (graph theory);internet backbone;matching (graph theory);mathematical optimization;matroid intersection;matroid polytope;ptas reduction;polynomial;polynomial-time approximation scheme;rp (complexity);randomized algorithm;shortest path problem;spanning tree;time complexity;whole earth 'lectronic link	Fabrizio Grandoni;Rico Zenklusen	2010	CoRR		matroid;time complexity;optimization problem;mathematical optimization;budget constraint;combinatorics;discrete mathematics;independent set;data structure;spanning tree;computer science;mathematics;matroid partitioning;shortest path problem;algorithm	Theory	23.722670768196007	20.039481252490354	35330
5525b59ad1f1f19059f35c975aee58d0b83e3e14	pseudorandom generators and learning algorithms for ac	learning algorithm	For anyAC0 functionf ofn bits, there is a polynomialp such that anyp(logn)-wise decomposable distribution “fools”f. In other words,f cannot distinguish between the pseudorandom strings in the distribution and truly random strings. The polynomialp depends only on the size and depth of the circuit computingf.	algorithm;machine learning;pseudorandom number generator	Meera Sitharam	1994		10.1145/195058.195236	pseudorandom generators for polynomials;combinatorics;discrete mathematics;theoretical computer science;pseudorandom function family;mathematics;pseudorandom generator;pseudorandomness;pseudorandom generator theorem	Theory	10.355856411561355	22.304027367653898	35341
0e708457695840554b003a2fbe26557355b6760c	in search of the tractability boundary of planning problems	polynomial factorization	Recently, considerable focus has been given to the problem of determining the boundary between tractable and intractable planning problems. To this end, we present complexity results for two classes of planning problems from the literature. First, we show that approximating a solution to a planning problem in the class 3S to within polynomial factors is NPhard. We also show that plan existence is NP-hard for planning problems with chain causal graphs and variables with domain size at most 7. In addition to the immediate implications, our results provide some insight into what makes some planning problems intractable.	approximation algorithm;automated planning and scheduling;carrier-to-noise ratio;causal filter;causal graph;cobham's thesis;internationalized domain name;np-hardness;polynomial;serial digital video out;shortest path problem;time complexity	Omer Giménez;Anders Jonsson	2008			mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;factorization of polynomials	AI	14.701468629750359	17.22712146320767	35342
5c24cb05fa8d56712c884d57b217cdc091fd9b67	07281 open problems -- structure theory and fpt algorithmcs for graphs, digraphs and hypergraphs	004;structuration theory	The following is a list of the problems presented on Monday, July 9, 2007 at the open-problem session of the Seminar on Structure Theory and FPT Algorithmics for Graphs, Digraphs and Hypergraphs, held at Schloss Dagstuhl in Wadern, Germany.	directed graph;parameterized complexity	Erik D. Demaine;Gregory Gutin;Dániel Marx;Ulrike Stege	2007			combinatorics;discrete mathematics;mathematics	Theory	20.166285617147558	20.31446351934627	35376
1803fdd8eb25604ec03b3b1a592690fbad5cb18b	prophet inequalities with limited information	algorithms;design;theory;sequencing and scheduling;stochastic programming	In the classical prophet inequality, a gambler observes a sequence of stochastic rewards V1, ..., Vn and must decide, for each reward Vi, whether to keep it and stop the game or to forfeit the reward forever and reveal the next value Vi. The gambler’s goal is to obtain a constant fraction of the expected reward that the optimal offline algorithm would get. Recently, prophet inequalities have been generalized to settings where the gambler can choose k items, and, more generally, where he can choose any independent set in a matroid. However, all the existing algorithms require the gambler to know the distribution from which the rewards V1, ..., Vn are drawn. The assumption that the gambler knows the distribution from which V1, ..., Vn are drawn is very strong. Instead, we work with the much simpler assumption that the gambler only knows a few samples from this distribution. We construct the first single-sample prophet inequalities for many settings of interest, whose guarantees all match the best possible asymptotically, even with full knowledge of the distribution. Specifically, we provide a novel single-sample algorithm when the gambler can choose any k elements whose analysis is based on random walks with limited correlation. In addition, we provide a black-box method for converting specific types of solutions to the related secretary problem to single-sample prophet inequalities, and apply it to several existing algorithms. Finally, we provide a constant-sample prophet inequality for constant-degree bipartite matchings. In addition, we apply these results to design the first posted-price and multi-dimensional auction mechanisms with limited information in settings with asymmetric bidders. Connections between prophet inequalities and posted-price mechanisms are already known, but applying the existing framework requires knowledge of the underlying distributions, as well as the so-called “virtual values” even when the underlying prophet inequalities do not. We therefore provide an extension of this framework that bypasses virtual values altogether, allowing our mechanisms to take full advantage of the limited information required by our new prophet inequalities. 1 ar X iv :1 30 7. 37 36 v1 [ cs .D S] 1 4 Ju l 2 01 3	black box;independent set (graph theory);matching (graph theory);matroid;online algorithm;online and offline;secretary problem;social inequality	Pablo Azar;Robert D. Kleinberg;S. Matthew Weinberg	2014		10.1137/1.9781611973402.100	mathematical optimization;combinatorics;mathematics;mathematical economics;algorithm;statistics	Theory	17.996197134701056	15.604986813215152	35413
edff6155775f244782cee772cb14e22a0554a928	improved lower bounds for sum coloring via clique decomposition		Given an undirected graph G = (V,E) with a set V of vertices and a set E of edges, the minimum sum coloring problem (MSCP) is to find a legal vertex coloring of G, using colors represented by natural numbers 1, 2, ... such that the total sum of the colors assigned to the vertices is minimized. This paper describes an approach based on the decomposition of the original graph into disjoint cliques for computing lower bounds for the MSCP. Basically, the proposed approach identifies and removes at each extraction iteration a maximum number of cliques of the same size (the largest possible) from the graph. Computational experiments show that this approach is able to improve on the current best lower bounds for 14 benchmark instances, and to prove optimality for the first time for 4 instances. We also report lower bounds for 24 more instances for which no such bounds are available in the literature. These new lower bounds are useful to estimate the quality of the upper bounds obtained with various heuristic approaches. keywords: sum coloring; graph coloring; clique decomposition; bounds; heuristics	algorithm;benchmark (computing);clique (graph theory);color;complement graph;computation;experiment;graph (discrete mathematics);graph coloring;heuristic (computer science);iteration;vertex (geometry)	Qinghua Wu;Jin-Kao Hao	2013	CoRR		mathematical optimization;combinatorics;discrete mathematics;fractional coloring;complete coloring;mathematics	Theory	24.44618707846624	21.934068499282102	35467
8ea468f1d29033e75c998367563da7b0fd7d9cb1	the primal-dual method for approximation algorithms	location problem;network design;probleme localisation;localisation installation;approximate algorithm;feedback vertex set;approximation algorithm;primal dual method;problema np duro;methode primale duale;optimisation combinatoire;np hard problem;metodo primal dual;probleme np difficile;mathematical programming;approximate solution;algoritmo aproximacion;facility location problem;fabrica;industrial plant;problema localizacion;algorithme approximation;combinatorial optimization;programmation mathematique;programacion matematica;usine;facility location;optimizacion combinatoria	In this survey, we give an overview of a technique used to design and analyze algorithms that provide approximate solutions to NP-hard problems in combinatorial optimization. Because of parallels with the primal-dual method commonly used in combinatorial optimization, we call it the primal-dual method for approximation algorithms. We show how this technique can be used to derive approximation algorithms for a number of different problems, including network design problems, feedback vertex set problems, and facility location problems.	approximation algorithm;blossom algorithm;combinatorial optimization;diffusing update algorithm;eric blossom;expectation–maximization algorithm;feedback vertex set;integer programming;linear programming relaxation;matching (graph theory);mathematical optimization;network planning and design;norsk data;parallels desktop for mac;scheduling (computing);steiner tree problem;supermodular function;times ascent	David P. Williamson	2002	Math. Program.	10.1007/s101070100262	optimization problem;mathematical optimization;randomized rounding;combinatorics;apx;covering problems;combinatorial optimization;facility location problem;mathematics;hardness of approximation;l-reduction;approximation algorithm;algorithm	Theory	21.917272118632017	13.074611991131421	35510
a993de8495a99b370f2de9f4f44cf93d2cd53542	decipherment complexity in 1: 1 substitution ciphers		In this paper we show that even for the case of 1:1 substitution ciphers—which encipher plaintext symbols by exchanging them with a unique substitute—finding the optimal decipherment with respect to a bigram language model is NP-hard. We show that in this case the decipherment problem is equivalent to the quadratic assignment problem (QAP). To the best of our knowledge, this connection between the QAP and the decipherment problem has not been known in the literature before.	1:1 pixel mapping;algorithm;bigram;cipher;decipherment;decision problem;language model;n-gram;np-hardness;plaintext;quadratic assignment problem;time complexity	Malte Nuhn;Hermann Ney	2013				NLP	11.593121617480731	23.846545542863925	35546
ca5a7a891a5e70fa11977d26f37d6465bd34a977	tree-decompositions of small pathwidth	tree decomposition	Motivated by the desire to speed up dynamic programming algorithms for graphs of bounded treewidth, we initiate a study of the tradeoff between width and pathwidth of tree-decompositions. We therefore investigate the catwidth parameter cat w (G) which is the minimum width of any tree-decomposition (T, X) of a graph G when the pathwidth pw(T) of the tree T is 1. The catwidth parameter lies between the treewidth and the pathwidth of the graph, tw(G) ≤ catw(G) ≤ pw(G), and just as treewidth relates to chordal graphs and pathwidth relates to interval graphs, catwidth relates to what we call catval graphs. We introduce the notion of an extended asteroidal triple (XAT) and characterize catval graphs as the XAT-free chordal graphs. We provide alternative characterizations of these graphs, show that there are graph classes for which the various parameters differ by an arbitrary amount, and consider algorithms for computing catwidth.	pathwidth	Jan Arne Telle	2001	Electronic Notes in Discrete Mathematics	10.1016/S1571-0653(04)00410-X	combinatorics;mathematics;tree decomposition	Theory	22.343810153376417	23.998863087037343	35565
9a5c8c9bab416bb7b1d6b992f3e3389ded380630	secure transmission of morphed stego keys over internet using ip steganography	morphed stego keys;internet protocol steganography;image security;internet security	Image data security over the internet is very important today. Steganography is a method of embedding data into the images. Image morphing is a process of generating intermediate images from one image to another. The concept of image morphing is used for image steganography to achieve the high embedding capacity and image security. Stego keys were generated during morphing process. These stego keys are destination cover image, number of bits used for steganography, a number of intermediate images and sequence number of intermediate images. These stage keys are needed to transfer the image data securely over the internet. Internet protocol header identification field is used for carrying these stego keys securely without changing the actual purpose of identification field. This paper presents the mechanism to transfer the morphed stego keys securely over the internet using IP steganography.	secure transmission;steganography	Anant M. Bagade;Sanjay N. Talbar	2014	IJICS	10.1504/IJICS.2014.065164	steganography tools;computer science;internet security;internet privacy;world wide web;computer security	Networks	4.885816525213592	14.99502245674677	35656
06187008f190011593554b74c3008e8632543121	schedule revision in a distributed job shop with the makespan objective	minimisation;manufacturing systems;electrical capacitance tomography;flexible manufacturing systems;job shop scheduling;distributed job shop;processor scheduling;schedule revision;distributed computing;makespan objective;computational modeling;production control;precedence constraints;job shop scheduling processor scheduling manufacturing systems electrical capacitance tomography distributed computing laboratories computational modeling computer integrated manufacturing problem solving flexible manufacturing systems;precedence constraint;job shop;minimisation production control;local schedule disruption;computer integrated manufacturing;local schedule disruption schedule revision distributed job shop makespan objective global makespan minimization precedence constraints;problem solving;global makespan minimization	This paper examines the problem of schedule revision in a distributed job shop where the object is to minimize the global makespan. Schedules of work cells may interact through precedence constraints, and a work cell’s response to a local schedule disruption may affect schedules of other cells. Complete knowledge about how local schedule changes affect the global schedule may require global knowledge about the schedule. Here, we show that knowledge of only local constraints may be almost as useful as global knowledge for the revision of one cell’s schedule. We present simulation results from a general distributed job shop model.	denial-of-service attack;makespan;schedule (computer science);simulation	Thomas Kaeppel Tsukada;Kang G. Shin	1997		10.1109/ROBOT.1997.614258	job shop scheduling;minimisation;mathematical optimization;real-time computing;computer science;computer-integrated manufacturing;computational model;statistics	AI	11.66450175294232	6.511331196326058	35672
75dfdf9705cadd3a23af559f0482537618c54e1c	distributed optimisation of a logistic system and its suppliers using ant colonies	intercambio informacion;swarm intelligence;multiagent system;ant colony optimisation;logistique;chaine approvisionnement;coordination mechanisms;ant colony;supply chain system;distributed scheduling;supply chain performance;distributed optimisation;metaheuristique;logistics;optimizacion enjambre particula;scheduling;echange information;optimisation repartie;information exchange;optimisation essaim particule;supply chain;sistema multiagente;ant colonies;ordonnancement;reglamento;systeme multiagent;logistica	This paper introduces a new multi-agent approach for collaborative management of logistic and supply systems based on the ant colony optimisation (ACO) meta-heuristic. The logistic system and its suppliers can be modelled as partners of a supply chain. The management methodology is defined as a set of distributed scheduling problems that exchange information during the optimisation process. Each problem is solved by an ant colony agent that uses the pheromone matrix as the communication platform. A simulation example shows that the proposed coordination mechanism improves the supply-chain performance compared to a traditional management approach, where both problems are considered separately.	ant colony;mathematical optimization	Carlos A. Silva;João Miguel da Costa Sousa;Thomas A. Runkler;José M. G. Sá da Costa	2006	Int. J. Systems Science	10.1080/00207720600784452	swarm intelligence;computer science;engineering;artificial intelligence;ant colony;supply chain;operations research	Robotics	19.493979092523684	5.562374681713488	35678
c1bcaf57f9daa624738cc4e31db1291e2e74c150	algorithmic number theory		We survey some recent developments in the study of the complexity of certain lattice problems. We focus on the recent progress on complexity results of intractability. We will discuss Ajtai’s worstcase/average-case connections for the shortest vector problem, similar results for the closest vector problem and short basis problem, NP-hardness and non-NP-hardness, transference theorems between primal and dual lattices, and application to secure cryptography.	best, worst and average case;computational number theory;cryptography;lattice problem;np-hardness	Jan van Leeuwen;Wieb Bosma	2000		10.1007/10722028	algorithmic mechanism design;algorithmic learning theory;algorithmic probability;algorithmic information theory;computational number theory	Theory	10.71924465199619	19.939753701763173	35686
2e62af0ebe61034fa85633370ad2ab2aecd14f9b	approximate string matching for self-indexes	data compression;approximation algorithms;information technology;indexes;data structures;heuristic algorithms;partitioning algorithms	Self-index is a compressed data structure that stores index of T (of length n) very efficiently and allows exact string matching (to locate all occurrences of P of length m) in m steps. Moreover it allows to obtain any substring of T so it may replace the original text. The approximate string matching task is to locate all substrings w of T that are withing a given edit distance k (e.g., Levenshtein or Hamming d.) from P.The used filtering algorithm splits P into subpatterns which are searched by selfindex. Their occurrences are seeds of potential approximate occurrences and they are verified by algorithm based on dynamic programming. The filters are divided [1] into 3 categories: (A) Partitioning into Exact Search divides P into so many substrings so that at least one must occur exactly. Each perspective occurrence has to be verified. (B) Neighborhood Generation generates the set (called neighborhood) of all strings within a given edit distance. Each string is then searched exactly without verification. (C) Intermediate Partitioning is combination of A and B.	approximate string matching;approximation algorithm;compressed data structure;data compression;dynamic programming;edit distance;string searching algorithm;substring;window function	Lukas Hrbek;Jan Holub	2016	2016 Data Compression Conference (DCC)	10.1109/DCC.2016.25	data compression;database index;approximate string matching;data structure;computer science;theoretical computer science;machine learning;pattern recognition;mathematics;string metric;information technology;bitap algorithm;statistics	Theory	12.895010953084576	27.65665451139557	35704
c4c4223aa2ee94e3df14a784e3d3b77a58e50b1b	mixed integer rounding cuts and master group polyhedra		We survey recent research on mixed-integer rounding (MIR) inequalities and a generalization, namely the two-step MIR inequalities defined by Dash and Günlük (2006). We discuss the master cyclic group polyhedron of Gomory (1969) and discuss how other subadditive inequalities, similar to MIR inequalities, can be derived from this polyhedron. Recent numerical experiments have shed much light on the strength of MIR inequalities and the closely related Gomory mixedinteger cuts, especially for the MIP instances in the MIPLIB 3.0 library, and we discuss these experiments and their outcomes. Balas and Saxena (2007), and independently, Dash, Günlük and Lodi (2007), study the strength of the MIR closure of MIPLIB instances, and we explain their approach and results here. We also give a short proof of the well-known fact that the MIR closure of a polyhedral set is a polyhedron. Finally, we conclude with a survey of the complexity of cutting-plane proofs which use MIR inequalities. This survey is based on a series of 5 lectures presented at the Seminaire de mathematiques superieures, of the NATO Advanced Studies Institute, held in the University of Montreal, from June 19-30, 2006.	cutting-plane method;experiment;mir:ror;numerical analysis;polyhedron;rounding;whole earth 'lectronic link	Sanjeeb Dash	2011		10.3233/978-1-60750-718-5-1	discrete mathematics;subadditivity;combinatorics;inequality;polyhedron;dash;mathematical proof;cyclic group;integer;rounding;mathematics	Theory	23.71502829333303	11.43850024161482	35705
eb03becd1afe0974766849ed91ac47a8e8a419a2	on stateless multihead automata: hierarchies and the emptiness problem	finite automata	We look at stateless multihead finite automata in their two-way and one-way, deterministic and nondeterministic variations. The transition of a k-head automaton depends solely on the symbols currently scanned by its k heads, and every such transition moves each head one cell left or right, or instructs it to stay. We show that stateless (k +4)-head two-way automata are more powerful than stateless k-head two-way automata. In the one-way case, we prove a tighter result: stateless (k + 1)-head one-way automata are more powerful than stateless k-head one-way automata. Finally, we show that the emptiness problem for stateless 2-head two-way automata is undecidable.	automaton;stateless protocol	Oscar H. Ibarra;Juhani Karhumäki;Alexander Okhotin	2008		10.1007/978-3-540-78773-0_9	combinatorics;discrete mathematics;quantum finite automata;computer science;ω-automaton;mathematics;finite-state machine;mobile automaton;algorithm	Theory	-0.7290438220310347	22.68693797470196	35711
8d00326a0746d007f1a439d8667e3098e8a35d3e	genral linear relations among different types of predictive complexity	theorie statistique;learning algorithm;algorithm complexity;complexite kolmogorov;complejidad algoritmo;relacion lineal;linear relation;algorithme apprentissage;relation lineaire;complexite algorithme;teoria estadistica;algoritmo aprendizaje;statistical theory	In this paper we introduce a general method that allows to prove tight linear inequalities between different types of predictive complexity and thus we generalise our previous results. The method relies upon probabilistic considerations and allows to describe (using geometrical terms) the sets of coefficients which correspond to true inequalities. We also apply this method to the square-loss and logarithmic complexity and describe their relations which were not covered by our previous research.		Yuri Kalnishkan	1999		10.1007/3-540-46769-6_27	statistical theory;calculus;mathematics;algorithm;statistics	ML	4.627040975224756	17.902006967088017	35723
ad1a1a21c9d02f811788c7f6d655dfd650ccdadb	a loopless gray-code algorithm for listing k-ary trees	arbre graphe;secuencia binaria;camino;gray code;binary sequence;preorder transversl;tree graph;representation of k ary tree;loopless algorithm;k ary tree;homogeneidad;algorithme;algorithm;transposition;codificacion;traverse geodesy;arbol binario;cheminement preodre;arbre binaire;coding;code gray;repreesentation arbre k naire;arbre k naire;homogeneite;arbol grafo;sequence binaire;cheminement;codigo gray;codage;homogeneity;algorithme sans boucle;transposicion;algoritmo;binary tree	The bit sequence representation for k-ary trees is a sequence b1,b2,?,bnk+1 of bits that is formed by doing a preorder traversal of the k-ary tree and writing a 1 when the visited subtree is not empty and a zero when the visited subtree is empty. The representation is well known and in the case of binary trees, the bit sequence representation also represents well-formed parenthesis strings. This paper presents the first loopless algorithm for listing the bit sequence representations of k-ary trees in a Gray-code order. The algorithm is simpler than existing loop free algorithms for both binary and k-ary trees. The algorithm is also the only known algorithm that generates the bit sequences by homogeneous transpositions.	k-ary tree;loopless algorithm	Dominique Roelants van Baronaigien	2000	J. Algorithms	10.1006/jagm.1999.1073	gray code;combinatorics;discrete mathematics;homogeneity;transposition;binary tree;pseudorandom binary sequence;k-ary tree;mathematics;coding;weight-balanced tree;tree;algorithm	Theory	15.855194005780227	28.77810771351285	35738
60b56d2135491c3fb60a7b90076bc0aba882aed8	mutual exclusion scheduling with interval graphs or related classes: complexity and algorithms	interval graph;graph coloring;mutual exclusion;scheduling problem;color appearance	This note summarizes the main results presented in the author’s Ph.D. thesis, supervised by Professor Michel Van Caneghem and defended on 14th June 2005 at University of Aix-Marseille II, France. The thesis, written in French, is available at http://www.lif-sud.univ-mrs.fr/ Rapports/25-2005.html. The mutual exclusion scheduling problem has an elegant graph-theoretic formulation: given an undirected graph G and an integer k, find a minimum coloring of G such that each color appears at most k times. When G is an interval graph, this problem has some applications in workforce planning. Then, the object of the thesis is to study the complexity of mutual exclusion scheduling problem for interval graphs and related classes.	algorithm;graph (discrete mathematics);graph coloring;graph theory;mutual exclusion;scheduling (computing)	Frédéric Gardi	2006	4OR	10.1007/s10288-005-0079-5	graph power;pathwidth;job shop scheduling;mathematical optimization;combinatorics;interval graph;mutual exclusion;computer science;complete coloring;edge coloring;comparability graph;graph coloring;mathematics;voltage graph;distributed computing;graph;indifference graph;line graph;algorithm	Theory	20.348772831422156	19.868675058377924	35747
fdc4b9281c1a50ddddf8bd2b036d720b1dbbe8ac	parallel dedicated machine scheduling problem with sequence-dependent setups and a single server	single server;setup time;scheduling;polynomial time;parallel dedicated machines;scheduling problem;machine scheduling;integer program;lower bound;sequence dependent setups;hybrid genetic algorithm	This paper addresses a scheduling problem on parallel dedicated machines in which the setup times are sequence-dependent and the setup operations are performed by a single server. The objective of the problem is to minimize the makespan of the system. The problem is formulated as an integer program and the lower bounds are constructed. A special case of the problem is presented and solved in polynomial time. For the general cases, a hybrid genetic algorithm is developed to solve the problem. The algorithm is tested by both randomly generated data sets and real-world data sets from a printing industry. The computational results show that the algorithm is efficient and effective for both types of data sets. 2009 Elsevier Ltd. All rights reserved.	computation;decision problem;experiment;genetic algorithm;integer programming;job stream;makespan;memetic algorithm;polynomial;printing;procedural generation;scheduling (computing);server (computing);time complexity	Simin Huang;Linning Cai;Xiaoyue Zhang	2010	Computers & Industrial Engineering	10.1016/j.cie.2009.10.003	fair-share scheduling;nurse scheduling problem;time complexity;job shop scheduling;open-shop scheduling;mathematical optimization;function problem;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;distributed computing;upper and lower bounds;scheduling	AI	15.777274246934047	9.071761708956913	35832
0aa91d2e7a35d2a1380e8afb3b3116769066b799	a four-sweep lbfs recognition algorithm for interval graphs	recognition algorithm;info info dm computer science cs discrete mathematics cs dm	In their 2009 paper, Corneil et al. design a linear time interval graph recognition algorithm based on six sweeps of Lexicographic Breadth-First Search (LBFS) and prove its correctness. They believe that their corresponding 5-sweep LBFS interval graph recognition algorithm is also correct. Thanks to the LBFS structure theory established mainly by Corneil et al., we are able to present a 4-sweep LBFS algorithm which determines whether or not the input graph is a unit interval graph or an interval graph. Like the algorithm of Corneil et al., our algorithm does not involve any complicated data structure and can be executed in linear time.	algorithm;correctness (computer science);data structure;lexicographic breadth-first search;time complexity	Peng Li;Yaokun Wu	2014	Discrete Mathematics & Theoretical Computer Science		combinatorics;interval graph;theoretical computer science;mathematics;algorithm	AI	19.50486193783672	28.305320582996476	35895
e13b4f4bc7c9f4159bc9a1410337dcc4c47708f0	technical note - some very easy knapsack/partition problems	702 some very easy knapsack partition problems	Consider the problem of partitioning a group of b indistinguishable objects into subgroups, each of size at least l and at most u. The objective is to minimize the additive separable cost of the partition, where the cost associated with a subgroup of size j is cj. In the case that ci¾· is convex, we show how to solve the problem in Olog u-l + 1 steps. In the case that ci¾· is concave, we solve the problem in Ominl, b/u, b/l-b/u, u-l steps. This problem generalizes a lot-sizing result of Chand and has potential applications in clustering.	karp's 21 np-complete problems	James B. Orlin	1985	Operations Research	10.1287/opre.33.5.1154	continuous knapsack problem;mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	20.280142220349855	13.712160370123113	35936
023f7d1632e3df4e79df820e2e47bf8e1dcd6ac7	the complexity of planning revisited - a parameterized analysis	computer science	To identify tractable sub problems for BOUNDED SASPLANNING several syntactical restrictions have been introduced by Backstrom and Klein (CI 1991). A BOUNDED SASPLANNING instance is: (P) POST-UNIQUE if no two actions change the same variable to the same value; (U) UNARY if each action changes exactly one variable; (B) BINARY if every variable has exactly 2 values; (S) SINGLE-VALUED if every two actions that depend on the same variable (but do not change that variable) require the same value from that variable.	cobham's thesis;unary operation	Christer Bäckström;Yue Chen;Peter Jonsson;Sebastian Ordyniak;Stefan Szeider	2012	CoRR			AI	6.256485481021053	18.092500842985213	35948
14ecf6bf7879ad1f4fdef7ca15074e5b706f5cdb	arms: a fine-grained 3d aqi realtime monitoring system by uav		Recently, mobile devices have been used to carry sensors to monitor air quality index (AQI), and help construct an AQI map in 2-dimensional (2D) areas. In this paper, we design a novel 3-dimensional (3D) AQI monitoring system, called Arms (AQI realtime monitoring system), to efficiently build realtime fine-grained 3D AQI maps, with the help of unmanned-aerial- vehicles (UAVs). Based on the data monitored by Arms, a novel dispersion model, namely Adaptive Gaussian Plume Model (AGPM) is proposed to predict the distribution of AQI. Moreover, the adaptive monitoring techniques, i.e., complete and optimized monitoring, are designed to effectively produce and maintain realtime AQI maps, while greatly reducing the measurement efforts. Experimental results verify that Arms can provide higher predicting accuracy of AQI with the proposed AGPM than other existing models. In addition, the whole system's battery consumption can be greatly reduced.	coat of arms;map;mobile device;plume (fluid dynamics);sensor;unmanned aerial vehicle	Yuzhe Yang;Zijie Zheng;Kaigui Bian;Ying Jiang;Lingyang Song;Zhu Han	2017	GLOBECOM 2017 - 2017 IEEE Global Communications Conference	10.1109/GLOCOM.2017.8253968	real-time computing;air quality index;mobile device;data modeling;computer science	Embedded	2.6751661551041344	29.658924602381205	35981
052f9bbf1244f32f0f40e54d4b95737cf02c8d3c	computing pure nash and strong equilibria in bottleneck congestion games	nash equilibrium;nash equilibria;network routing;computational complexity;polynomial time;congestion game;lower bound	Bottleneck congestion games properly model the properties of many realworld network routing applications. They are known to possess strong equilibria—a strengthening of Nash equilibrium to resilience against coalitional deviations. In this paper, we study the computational complexity of pure Nash and strong equilibria in these games. We provide a generic centralized algorithm to compute strong equilibria, which has polynomial running time for many interesting classes of games such as, e.g., matroid or single-commodity bottleneck congestion games. In addition, we examine the more demanding goal to reach equilibria in polynomial time using natural improvement dynamics. Using unilateral improvement dynamics in matroid games pure Nash equilibria can be reached efficiently. In contrast, computing even a single coalitional improvement move in matroid and single-commodity games is strongly NP-hard. In addition, we establish a variety of hardness results and lower bounds regarding the An extended abstract of this paper appeared in the Proceedings of the 18th Annual European Symposium on Algorithms (ESA). T. Harks (B) School of Business and Economics, Maastricht University, Maastricht, The Netherlands e-mail: t.harks@maastrichtuniversity.nl M. Hoefer Department of Computer Science, RWTH Aachen University, Aachen, Germany e-mail: mhoefer@cs.rwth-aachen.de M. Klimm Department of Mathematics, TU Berlin, Berlin, Germany e-mail: klimm@math.tu-berlin.de A. Skopalik TU Dortmund, Dortmund, Germany e-mail: alexander.skopalik@tu-dortmund.de	algorithm;centralized computing;computational complexity theory;computer science;esa;email;matroid;np-hardness;nash equilibrium;network congestion;polynomial;routing;strong np-completeness;time complexity	Tobias Harks;Martin Hoefer;Max Klimm;Alexander Skopalik	2013	Math. Program.	10.1007/s10107-012-0521-3	epsilon-equilibrium;mathematical optimization;simulation;best response;coordination game;computer science;mathematics;correlated equilibrium;risk dominance;mathematical economics;algorithm;nash equilibrium	Theory	19.667115848820156	18.62249870558608	35984
baf373699c99f06adbe049fe06db9da125a5ceec	a market-based multi-agent-system for decentralized power and grid control	energy conversion;power system simulation;logic gates matlab wind power generation frequency measurement cogeneration load modeling;multi agent system;renewable energy sources;agent based;power system simulation market based multi agent system decentralized market based power control system demapos grid control renewable energy sources distributed energy conversion plants web services;web services multi agent systems power grids power markets power system simulation;web service;multi agent systems;power markets;electricity generation;web services;decentralized control;power grids;control strategy;power control	Due to an increasingly decentralized fashion of electricity generation from fluctuating, renewable energy sources, new control concepts have to be found to manage a multitude of distributed energy conversion plants and to minimize the amount of power reserve needed. The basic implementation of the ‘DEcentralized MArket Based POwer Control System’ (DEMAPOS) presented in this article applies a market-based, decentralized control of generators and consumers of electrical energy. The control as well as a power system simulation needed for system testing were designed, implemented and validated. The developed, agent-based control communicates via web services with the power system simulation which relies on real-world data. Results from various test runs demonstrate the huge potential of this control strategy.	agent-based model;algorithm;control theory;distributed control system;linear function;load shedding;map;multi-agent system;simulation;system monitoring;system testing;testbed;uninterruptible power supply;web service	Tobias Linnenberg;Ireneus Wior;Sebastian Schreiber;Alexander Fay	2011	ETFA2011	10.1109/ETFA.2011.6059126	control engineering;web service;simulation;computer science;engineering;artificial intelligence;multi-agent system	Robotics	1.1851455020285167	6.096742818642349	36033
8b22b7fec807bbb442a6d1805ae3f2a43ffe2a7d	floats, integers, and single source shortest paths	arithmetique ordinateur;espace lineaire;temps lineaire;linear time algorithm;usssp;tiempo lineal;algorithme;algorithm;computer arithmetic;linear time;undierected single source shortest path problem;single source shortest path;aritmetica ordenador;floating point;coma flotante;linear space;virgule flottante;algoritmo	Floats are ugly, but to everyone but theoretical computer scientists, they are the real thing. A linear time algorithm is presented for the undirected single source shortest paths problem with positive oating point weights.	algorithm;computer scientist;graph (discrete mathematics);shortest path problem;time complexity	Mikkel Thorup	2000	J. Algorithms	10.1006/jagm.2000.1080	time complexity;combinatorics;floyd–warshall algorithm;computer science;floating point;theoretical computer science;mathematics;algorithm;linear space	Theory	19.802591979447246	27.814508705518737	36133
2702a2eb791a6952dfdad89bf4ffe9e6fa556d88	dispatch: an optimal algorithm for online perfect bipartite matching with i.i.d. arrivals		This work presents the first algorithm for the problem of weighted online perfect bipartite matching with i.i.d. arrivals. Previous work only considered adversarial arrival sequences. In this problem, we are given a known set of workers, a distribution over job types, and non-negative utility weights for each worker, job type pair. At each time step, a job is drawn i.i.d. from the distribution over job types. Upon arrival, the job must be irrevocably assigned to a worker. The goal is to maximize the expected sum of utilities after all jobs are assigned. Our work is motivated by the application of ride-hailing, where jobs represent passengers and workers represent drivers. We introduce Dispatch, a 0.5-competitive, randomized algorithm and prove that 0.5-competitive is the best possible. Dispatch first selects a “preferred worker” and assign the job to this worker if it is available. The preferred worker is determined based on an optimal solution to a fractional transportation problem. If the preferred worker is not available, Dispatch randomly selects a worker from the available workers. We show that Dispatch maintains a uniform distribution over the workers even when the distribution over the job types is non-uniform. 2012 ACM Subject Classification Theory of computation → Online algorithms	competitive analysis (online algorithm);device driver;job stream;k-server problem;matching (graph theory);nonuniform sampling;online algorithm;randomized algorithm;randomness;sampling (signal processing);server (computing);theory of computation;transportation theory (mathematics)	Minjun Chang;Dorit S. Hochbaum;Quico Spaen;Mark Velednitsky	2018	CoRR		transportation theory;algorithm;independent and identically distributed random variables;randomized algorithm;bipartite graph;uniform distribution (continuous);computer science	Theory	14.67139552130409	10.829381734256135	36141
07c4083cacb18d786d451db18207c2fd83ad1bfc	improved upper and lower bound heuristics for degree anonymization in social networks		Motivated by a strongly growing interest in anonymizing social network data, we investigate the NP-hard Degree Anonymization problem: given an undirected graph, the task is to add a minimum number of edges such that the graph becomes k-anonymous. That is, for each vertex there have to be at least k−1 other vertices of exactly the same degree. The model of degree anonymization has been introduced by Liu and Terzi [ACM SIGMOD’08], who also proposed and evaluated a two-phase heuristic. We present an enhancement of this heuristic, including new algorithms for each phase which significantly improve on the previously known theoretical and practical running times. Moreover, our algorithms are optimized for largescale social networks and provide upper and lower bounds for the optimal solution. Notably, on about 26% of the real-world data we provide (provably) optimal solutions; whereas in the other cases our upper bounds significantly improve on known heuristic solutions.	algorithm;data anonymization;graph (discrete mathematics);heuristic (computer science);np-hardness;social network;two-phase locking	Sepp Hartung;Clemens Hoffmann;André Nichterlein	2014		10.1007/978-3-319-07959-2_32	mathematical optimization;combinatorics;discrete mathematics;machine learning;mathematics	AI	21.767347944575974	20.340665801892694	36149
ab5d415ee2aea90d3484c800b1fb3c74914d192e	a general graph model for representing exact communication volume in parallel sparse matrix-vector multiplication	calcul matriciel;modelizacion;graph theory;hipergrafico;coloracion grafo;teoria grafo;sparse graph;heuristic method;grafo disperso;metodo heuristico;theorie graphe;modelisation;descomposicion matricial;matrice creuse;coloration graphe;decomposition matricielle;matrix decomposition;edge graph;arete graphe;load balance;methode heuristique;hypergraph;matrix calculus;hypergraph partitioning;graph model;sparse matrix;modeling;graphe epars;calculo de matrices;arista grafico;matriz dispersa;graph colouring;hypergraphe	In this paper, we present a new graph model of sparse matrix decomposition for parallel sparse matrix–vector multiplication. Our model differs from previous graph-based approaches in two main respects. Firstly, our model is based on edge colouring rather than vertex partitioning. Secondly, our model is able to correctly quantify and minimise the total communication volume of the parallel sparse matrix– vector multiplication while maintaining the computational load balance across the processors. We show that our graph edge colouring model is equivalent to the fine-grained hypergraph partitioning-based sparse matrix decomposition model. We conjecture that the existence of such a graph model should lead to faster serial and parallel sparse matrix decomposition heuristics and associated tools.	benchmark (computing);central processing unit;cork encoding;distributed computing;edge coloring;graph coloring;graph partition;heuristic (computer science);lecture notes in computer science;parallel algorithm;parallel processing (dsp implementation);siam journal on scientific computing;sparse matrix;springer (tank)	Aleksandar Trifunovic;William J. Knottenbelt	2006		10.1007/11902140_85	graph power;combinatorics;discrete mathematics;systems modeling;graph bandwidth;sparse matrix;dense graph;matrix calculus;graph theory;load balancing;sparse approximation;mathematics;matrix decomposition;complement graph;algorithm;adjacency matrix	HPC	18.63300635833125	28.78584341993673	36151
3ce7a74bad33aaeb1545425e74db5f0ffbf653c4	strong algorithms for the ordinal matroid secretary problem		In contrast with the standard and widely studied utility variant, in the ordinal Matroid Secretary Problem (MSP) candidates do not reveal numerical weights but the decision maker can still discern if a candidate is better than another. We consider three competitiveness measures for the ordinal MSP. An algorithm is α ordinal-competitive if for every weight function compatible with the ordinal information, the expected output weight is at least 1/α times that of the optimum; it is α intersection-competitive if its expected output includes at least 1/α fraction of the elements of the optimum, and it is α probability-competitive if every element from the optimum appears with probability 1/α in the output. This is the strongest notion as any α probability-competitive algorithm is also α intersection, ordinal and utility (standard) competitive. Our main result is the introduction of a technique based on forbidden sets to design algorithms with strong probability-competitive ratios on many matroid classes. In fact, we improve upon the guarantees for almost every matroid class considered in the MSP literature: we achieve probability-competitive ratios of e for transversal matroids (matching Kesselheim et al. [29], but under a stronger notion); of 4 for graphic matroids (improving on 2e by Korula and Pál [33]); of 3 √ 3 ≈ 5.19 for laminar matroids (improving on 9.6 by Ma et al. [39]); and of k for a superclass of k column sparse matroids, improving on the ke result by Soto [44]. We also get constant ratios for hypergraphic matroids, for certain gammoids and for graph packing matroids that generalize matching matroids. The forbidden sets technique is inspired by the backward analysis of the classical secretary problem algorithm and by the analysis of the e-competitive algorithm for online weighted bipartite matching by Kesselheim et al. [29]. Additionally, we modify Kleinberg’s 1+O( √ 1/ρ) utility-competitive algorithm for uniform matroids of rank ρ in order to obtain a 1 + O( √ log ρ/ρ) probability-competitive algorithm. Our second contribution are algorithms for the ordinal MSP on arbitrary matroids. We devise an O(1) intersection-competitive algorithm, an O(log ρ) probability-competitive algorithm and an O(log log ρ) ordinal-competitive algorithm for matroids of rank ρ. The last two results are based on the O(log log ρ) utility-competitive algorithm by Feldman et al. [19].	algorithm;graphic matroid;matching (graph theory);matroid rank;max;numerical analysis;ordinal data;secretary problem;set packing;sparse matrix;weight function	José A. Soto;Abner Turkieltaub;Victor Verdugo	2018		10.1137/1.9781611975031.47	weighted matroid;ordinal number;mathematics;combinatorics;generating function;discrete mathematics;secretary problem;algorithm;independent set;log-log plot;matroid;graph	Theory	17.858479200143993	15.576407352063928	36164
e7b7440487b382522795e49c9abc8176f8b14142	a polynomial time match test for large classes of extended regular expressions	conference contribution;pattern language;polynomial time;regular expression;large classes;np complete problem	In the present paper, we study the match test for extended regular expressions. We approach this NP-complete problem by introducing a novel variant of two-way multihead automata, which reveals that the complexity of the match test is determined by a hidden combinatorial property of extended regular expressions, and it shows that a restriction of the corresponding parameter leads to rich classes with a polynomial time match test. For presentational reasons, we use the concept of pattern languages in order to specify extended regular expressions. While this decision, formally, slightly narrows the scope of our results, an extension of our concepts and results to more general notions of extended regular expressions is straightforward.	automata theory;automaton;brute-force search;janus;matching (graph theory);np-completeness;pattern language;polynomial;primality test;regular expression;time complexity	Daniel Reidenbach;Markus L. Schmid	2010		10.1007/978-3-642-18098-9_26	combinatorics;discrete mathematics;mathematics;generalized star height problem;algorithm	Theory	-3.755733628627865	17.544596714756672	36307
46754934f89c1685f5d6d76f13fcd161c59d2524	bounded edge-connectivity and edge-persistence of cartesian product of graphs	delecion;cartesian product of graphs;hypercube;optimisation;combinatorics;subgrafo;optimizacion;persistence;persistencia;combinatoria;combinatoire;edge persistence;diameter;persistance;connected graph;ciclo;cartesian product;graph connectivity;producto grafo;sous graphe;cycles;informatique theorique;68r10;conectividad grafo;hypercubes;optimization;paths;bounded edge connectivity;subgraph;graphe produit;cycle;connectivite graphe;graph product;graphe connexe;produit graphe;computer theory;deletion;grafo conexo;informatica teorica;hipercubo	"""The bounded edge-connectivity @l""""k(G) of a connected graph G with respect to k(>=d(G)) is the minimum number of edges in G whose deletion from G results in a subgraph with diameter larger than k and the edge-persistence D^+(G) is defined as @l""""d""""(""""G"""")(G), where d(G) is the diameter of G. This paper considers the Cartesian product G""""1xG""""2, shows @l""""k""""""""""""1""""+""""k""""""""""""2(G""""1xG""""2)>=@l""""k""""""""""""1(G""""1)+@l""""k""""""""""""2(G""""2) for k""""1>=2 and k""""2>=2, and determines the exact values of D^+(G) for G=C""""nxP""""m, C""""nxC""""m, Q""""nxP""""m and Q""""nxC""""m."""	cartesian closed category;k-edge-connected graph;persistence (computer science)	You Lu;Jun-Ming Xu;Xinmin Hou	2009	Discrete Applied Mathematics	10.1016/j.dam.2009.07.003	combinatorics;discrete mathematics;topology;connectivity;mathematics;hypercube	Theory	24.12178835164238	30.836475794101208	36381
dd135bcde557e03bd8e78f745c38ae5618a3f940	imperfectness of data for sts-based physical mapping	combinatorial problems;polynomial time algorithm;consecutive ones property;dna hybridization;computational biology;dna sequence;physical map	In the STS-based mapping, we are requested to obtain the correct orde r of probes in a DNA sequence from a given set of fragments or equivalently a hyb ridization matrix A. It is well-known that the problem is formulated as the combinatorial problem of obtaining a permutation of A’s columns so that the resulting matrix has the consecutive-one property. If the data (the hybridization matrix) is error free and includes enough information, then the above column order dete rmines the correct order of the probes uniquely. Unfortunately this is no longer tru if the data include errors, which has been one of the popular research tar gets in computational biology. Even if there is no error, ambiguities in the probe or d r may still remain. This in fact happens by the lack of some information of the data, but almost no further investigation was made previously. In this pap er, we define a measure of such imperfectness of the data as a minimum amount of additional fragments which are needed to fix the probe order uniquely. S veral polynomial-time algorithms to compute such additional fragments of minimum cost are presented.	algorithm;column (database);computational biology;time complexity	Hiro Ito;Kazuo Iwama;Takeyuki Tamura	2004		10.1007/1-4020-8141-3_23	combinatorics;bioinformatics;mathematics;algorithm	Theory	17.210686016929696	22.137351731078063	36449
8956efc606ae928035a1f95d44e423474a952f58	branch and cut and price for the pickup and delivery problem with time windows	camino mas corto;shortest path;pickup and delivery;transportes;modele mathematique;set partitions;desigualdad;inequality;gestion trafic;time window;inegalite;vehicle routing;ramassage et livraison;formulacion;plus court chemin;pickup and delivery problem with time windows;valid inequalities;modelo matematico;traffic management;satisfiability;algorithme;resolucion problema;transports;algorithm;pickup and delivery problem;branch and cut and price algorithms;computer experiment;transportation;linear programming relaxation;precedence constraint;mathematical model;gestion trafico;recogida y entrega;design;routes and routing;branch and cut;experimentation;formulation;lower bound;column generation;problem solving;resolution probleme;shortest path problem;experimentacion;time windows;branch and price;algoritmo	In the pickup and delivery problem with time windows (PDPTW), vehicle routes must be designed to satisfy a set of transportation requests, each involving a pickup and a delivery location, under capacity, time window, and precedence constraints. This paper introduces a new branch-and-cut-and-price algorithm in which lower bounds are computed by solving through column generation the linear programming relaxation of a set partitioning formulation. Two pricing subproblems are considered in the column generation algorithm: an elementary and a non-elementary shortest path problem. Valid inequalities are added dynamically to strengthen the relaxations. Some of the previously proposed inequalities for the PDPTW are also shown to be implied by the set partitioning formulation. Computational experiments indicate that the proposed algorithm outperforms a recent branch-and-cut algorithm.	algorithm;branch and cut;column generation;computation;computational complexity theory;experiment;linear programming relaxation;microsoft windows;shortest path problem	Stefan Ropke;Jean-François Cordeau	2009	Transportation Science	10.1287/trsc.1090.0272	mathematical optimization;operations management;vehicle routing problem;mathematics;shortest path problem;algorithm	Robotics	18.62778696210192	6.614763285363787	36485
e87153626c8b32b39a5d419c1775b1871887390e	optimal algorithms for the coin weighing problem with a spring scale.	optimal algorithm	Suppose we are given coins out of a collection of coins of two distinct weightsw0 andw1, true and counterfeit coins, respectively, where d of them are counterfeit coins. Assume we are allowed to weigh subsets of coins in a spring scale. Determine the counterfeit coins in a minimal number of weighing. This problem is equivalent to the following learning problem: Given a linear function f = xi1 + xi2 + · · ·+ xid , where1 ≤ i1 < i2 < · · · < id ≤ n and a substitution oracle of values in the domain{0, 1}n to f . Find f with minimal number of substitution queries. In this paper we give the first optimal 1. (in the number of weighing or substitutions) polynomial timeadaptive algorithm that determines the counterfeit coins. We then extend our algorithm to the following more general coin weighing problems with a spring scale: Suppose we are given n coins out of a collection of coins of unknown integer weights. Determine the weight of each coin in a minimal number of weighing. We give an optimal adaptive polynomial time algorithm for this problem. This algorithm is based on a new optimal adaptive algorithm for reconstructing bounded weight vectors in polynomial time. This solves the general problem of learninganylinear function with bounded integer coefficient in polynomial time with optimal number of substitution queries. To the best of our knowledge all the algorithms in this paper are the first optimal polynomial time adaptive algorithms for the problem of coin weighing in a spring scale.	adaptive algorithm;coefficient;linear function;p (complexity);polynomial;time complexity	Nader H. Bshouty	2009			mathematical optimization;combinatorics;computer science;mathematics;algorithm	Theory	19.07729966221946	21.1624141062819	36575
85f600934743ee6735156a03ba59850686afc34c	an approximate model of processor communication rings under heavy load	complexite calcul;communicating process;proceso comunicante;computational complexity;processus communicant;procesador;processeur;random numbers;processor	Abstract   A communication ring of  N  cells rotates unidirectionally in discrete steps, carrying messages (packets) among  N  processors at fixed locations around the ring. Each cell holds only one packet. A packet's destination is chosen so that packets are delivered after being on the ring for i.i.d. random numbers of steps. When a cell makes a delivery, the receiving processor uses the same cell to send a new packet. Thus, at every step every cell is moving a packet.  The packet delivery process in this model gives a useful approximation to the corresponding process in rings where stable, but typically very long queues of waiting packets form at the processors. The distribution of times between successive deliveries is derived for a general distribution of packet transit times on the ring. A limit law shows that, for large  N , the former distribution is approximately exponential when packet destinations are chosen uniformly at random from among the processors.	approximation algorithm	Edward G. Coffman;Leopold Flatto;Edgar N. Gilbert;Albert G. Greenberg	1997	Inf. Process. Lett.	10.1016/S0020-0190(97)00159-2	combinatorics;real-time computing;computer science;theoretical computer science;mathematics;distributed computing;transmission delay;packet switch;computational complexity theory;algorithm	DB	10.289886802792875	11.432319714532795	36581
4692d2eabb792e96175c37de93f027aaf764afda	priority queues on parallel machines	constant time operations;binomial trees;binomial tree;priority queue;parallel priority queues;parallel machines;pipelined operations;data structure	We present time and work optimal priority queues for the CREW PRAM, supporting FindMin in constant time with one proces-and DecreaseKey in constant time with O(log n) processors. A priority queue can be build in time O(log n) with O(n= log n) processors and k elements can be inserted into a priority queue in time O(log k) with O((log n + k)= log k) processors. With a slowdown of O(log log n) in time the priority queues adopt to the EREW PRAM by only increasing the required work by a constant factor. A pipelined version of the priority queues adopt to a processor array of size O(log n), supporting the oper	central processing unit;parallel random-access machine;priority queue;processor array;time complexity	Gerth Stølting Brodal	1999	Parallel Computing	10.1016/S0167-8191(99)00032-0	priority inheritance;parallel computing;real-time computing;data structure;computer science;distributed computing;programming language;binomial options pricing model;priority queue;priority ceiling protocol	Theory	12.215578214541269	32.173678486036756	36720
6f36ea1787f207a48888e1a6ac195e8522449915	compression-based analysis of cyclic tag system emulated by rule 110			rule 110;tag system	Shigeru Ninagawa;Genaro Juárez Martínez	2014	J. Cellular Automata		tag system;discrete mathematics;algorithm;rule 110;theoretical computer science;compression (physics);computer science	NLP	1.7027299207869078	18.619260084731334	36800
4799c88ba0bd0626f9e4916ef3f530e2c8e677bf	factor oracle: a new structure for pattern matching	grafo aciclico;algoritmo busqueda;algorithm analysis;automata estado finito;algorithme recherche;search algorithm;graphe acyclique;acyclic graph;indexing;informatique theorique;pattern matching;analyse algorithme;finite automaton;concordance forme;automate fini;string matching;algorithm design;analisis algoritmo;computer theory;informatica teorica	HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Factor oracle : a new structure for pattern matching Cyril Allauzen, Maxime Crochemore, Mathieu Raffinot	archive;comefrom;factor oracle;hal;linear algebra;pattern matching	Cyril Allauzen;Maxime Crochemore;Mathieu Raffinot	1999		10.1007/3-540-47849-3_18	algorithm design;search engine indexing;combinatorics;discrete mathematics;computer science;pattern matching;mathematics;finite-state machine;directed acyclic graph;algorithm;string searching algorithm;search algorithm	ML	16.263346958294076	27.04373577878033	36801
bcf468a832d61b81df8259409746853e89845e35	a new bottom-left-fill heuristic algorithm for the two-dimensional irregular packing problem	bin packing problem;optimisation;approximations heuristic;algoritmo busqueda;optimizacion;computers computer science;cutting stock trim;penurie;algorithme recherche;benchmark problem;heuristic method;search algorithm;packing;problema relleno;metodo heuristico;intelligence artificielle;cutting stock problem;comportement grimpeur;search production scheduling;production scheduling approximations heuristic;search production scheduling cutting stock trim;artificial intelligent;busca local;probleme decoupe;penuria;scheduling;computers computer science artificial intelligence optimization;probleme remplissage;artificial intelligence;tabu search;optimization;problema troquelado;hill climbing;methode heuristique;inteligencia artificial;production scheduling;climbing behavior;comportamiento trepador;shortage;local search;ordonnancement;recherche locale;busqueda tabu;heuristic algorithm;garnissage;reglamento;recherche tabou;relleno	This paper presents a new heuristic algorithm for the two-dimensional irregular stock-cutting problem, which generates significantly better results than the previous state of the art on a wide range of established benchmark problems. The developed algorithm is able to pack shapes with a traditional line representation, and it can also pack shapes that incorporate circular arcs and holes. This in itself represents a significant improvement upon the state of the art. By utilising hill climbing and tabu local search methods, the proposed technique produces 25 new best solutions for 26 previously reported benchmark problems drawn from over 20 years of cutting and packing research. These solutions are obtained using reasonable time frames, the majority of problems being solved within five minutes. In addition to this, we also present 10 new benchmark problems, which involve both circular arcs and holes. These are provided because of a shortage of realistic industrial style benchmark problems within the literature and to encourage further research and greater comparison between this and future methods.	algorithm;benchmark (computing);heuristic (computer science);hill climbing;iteration;local search (optimization);nesting algorithm;set packing;tabu search	Edmund K. Burke;Robert S. R. Hellier;Graham Kendall;Glenn Whitwell	2006	Operations Research	10.1287/opre.1060.0293	heuristic;mathematical optimization;bin packing problem;simulation;tabu search;economic shortage;computer science;artificial intelligence;local search;operations management;hill climbing;cutting stock problem;mathematics;scheduling;scheduling;algorithm;search algorithm	AI	19.769728322696864	6.409435188961916	36845
13b2c0d7e7ba8fb993ac0e3a861ac80300615f2b	sublinear-time algorithms for monomer-dimer systems on bounded degree graphs	matchings;approximation algorithms;random sampling;correlation decay;graph algorithms	For a graph G, let Z(G, λ) be the partition function of the monomer-dimer system defined by ∑ k mk(G)λ , where mk(G) is the number of matchings of size k in G. We consider graphs of bounded degree and develop a sublinear-time algorithm for estimating logZ(G, λ) at an arbitrary value λ > 0 within additive error ǫn with high probability. The query complexity of our algorithm does not depend on the size of G and is polynomial in 1/ǫ, and we also provide a lower bound quadratic in 1/ǫ for this problem. This is the first analysis of a sublinear-time approximation algorithm for a #P -complete problem. Our approach is based on the correlation decay of the Gibbs distribution associated with Z(G, λ). We show that our algorithm approximates the probability for a vertex to be covered by a matching, sampled according to this Gibbs distribution, in a near-optimal sublinear time. We extend our results to approximate the average size and the entropy of such a matching within an additive error with high probability, where again the query complexity is polynomial in 1/ǫ and the lower bound is quadratic in 1/ǫ. Our algorithms are simple to implement and of practical use when dealing with massive datasets. Our results extend to other systems where the correlation decay is known to hold as for the independent set problem up to the critical activity.	approximation algorithm;decision tree model;degree (graph theory);domino tiling;independent set (graph theory);matching (graph theory);partition function (mathematics);polynomial;time complexity;utility functions on indivisible goods;with high probability	Marc Lelarge;Hang Zhou	2014	Theor. Comput. Sci.	10.1016/j.tcs.2014.06.040	sampling;mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;approximation algorithm	Theory	20.476208556583035	21.591966983761	36886
9ba7194bb8f607b967879be93a79c167bf63b654	finite automata with restricted two-way motion	finite automata	We consider finite two-way automata and measure the use of twoway motion by counting the number of left moves in accepting computations. Restriction of the automata according to this measure allows us to study in detail the use of two-way motion for the acceptance of regular languages in terms of state complexity. The two-way spectrum of a given regular language is introduced. This quantity reflects the change of size of minimal accepting devices if the use of two-way motion is increased incrementally. We give examples for spectra, prove uniform upper and lower bounds and study their sharpness. We also have state complexity results for two-way automata with uniformly bounded use of two-way motion.	automata theory;automaton;computation;finite-state machine;regular language	David Damanik	2014	CoRR		combinatorics;discrete mathematics;nondeterministic finite automaton;continuous spatial automaton;quantum finite automata;computer science;nested word;deterministic finite automaton;ω-automaton;mathematics;finite-state machine;algorithm	Logic	-0.16286923856937247	21.29440461683845	36893
2037d34e0fec613227fa9d0ba5e5f1c0d6a94ad3	reformulation and decomposition of integer programs	institutional repositories;cutting plane;fedora;vital;mixed integer program;lagrangean relaxation;extended formulation;linear programming relaxation;vtls;integer program;benders algorithm;branch and bound;column generation;ils;branch and price	In this survey we examine ways to reformulate integer and mixed integer programs. Typically, but not exclusively, one reformulates so as to obtain stronger linear programming relaxations, and hence better bounds for use in a branch-and-bound based algorithm. First we cover in detail reformulations based on decomposition, such as Lagrangean relaxation, Dantzig-Wolfe column generation and the resulting branch-and-price algorithms. This is followed by an examination of Benders’ type algorithms based on pro jection. Finally we discuss in detail extended formulations involving additional variables that are based on problem structure. These can often be used to provide strengthened a priori formulations. Reformulations obtained by adding cutting planes in the original variables are not treated here.	algorithm;branch and bound;branch and price;column generation;lagrangian relaxation;linear programming relaxation	François Vanderbeck;Laurence A. Wolsey	2010		10.1007/978-3-540-68279-0_13	mathematical optimization;combinatorics;discrete mathematics;integer programming;linear programming relaxation;branch and price;mathematics;branch and cut	AI	24.246801303357355	11.063753695095597	36902
011008efecd336ea1488aaf3b28fc84ca1164941	verifying and decoding in constant depth	list decoding;constant depth circuits;interactive proof systems;error correcting codes;error correction code;interactive proofs	We develop a general approach for improving the efficiency of a computationally bounded receiver interacting with a powerful and possibly malicious sender. The key idea we use is that of delegating some of the receiver's computation to the (potentially malicious) sender. This idea was recently introduced by Goldwasser et al. [14] in the area of program checking. A classic example of such a sender-receiver setting is interactive proof systems. By taking the sender to be a (potentially malicious) prover and the receiver to be a verifier, we show that (p-prover) interactive proofs with k rounds of interaction are equivalent to (p-prover) interactive proofs with k+O(1) rounds, where the verifier is in NC0. That is, each round of the verifier's computation can be implemented in constant parallel time. As a corollary, we obtain interactive proof systems, with (optimally) constant soundness, for languages in AM and NEXP, where the verifier runs in constant parallel-time.  Another, less immediate sender-receiver setting arises in considering error correcting codes. By taking the sender to be a (potentially corrupted) codeword and the receiver to be a decoder, we obtain explicit families of codes that are locally (list-)decodable by constant-depth circuits of size polylogarithmic in the length of the codeword. Using the tight connection between locally list-decodable codes and average-case complexity, we obtain a new, more efficient, worst-case to average-case reduction for languages in EXP.	average-case complexity;best, worst and average case;code word;codec;computation;exptime;error detection and correction;formal verification;interaction;interactive proof system;nc (complexity);nexptime;polylogarithmic function	Shafi Goldwasser;Dan Gutfreund;Alexander Healy;Tali Kaufman;Guy N. Rothblum	2007		10.1145/1250790.1250855	list decoding;combinatorics;discrete mathematics;error detection and correction;interactive proof system;theoretical computer science;mathematics;algorithm;statistics	Theory	9.080960969632587	25.023742571498122	36903
ac1fb1753c6dd0035ef741cec9218ae8283c9265	mvgs: a new graph signature for self-reconfiguration planning of modular robots based on multiple views theory	multiple views theory;self reconfiguration planning srp;modular robots;graph signature	Self-reconfiguration planning (SRP) of modular robots has been a major research for the past decade and still is a key issue. In this paper, we present a novel new graph signature approach for SRP based on Multiple Views Theory, called MVGSMVGS (Multi-View Graph Signature). In the proposed method the time complexity of the graph signature generation reduced to O(logn)O(logn), in which nn is the number of modules, from the best solutions with O(n2)O(n2). Also, we propose a new similarity metric, between graph signatures to better guide the heuristic search toward the final configuration. The proposed approach has been implemented in a simulator and the results show significantly better performance than the other previously proposed methods.	robot	Khalil Taheri;Hadi Moradi;Masoud Asadpour;Parisa Parhami	2016	Robotics and Autonomous Systems	10.1016/j.robot.2016.01.012	computer science;theoretical computer science;machine learning;self-reconfiguring modular robot;graph;moral graph	Robotics	13.90429194737135	16.061770448717223	36954
ecaa67df934e25f99def40036cdbcfae721dfff1	construction of extractors using pseudo-random generators (extended abstract)	pseudo random generator;uniform distribution	We introduce a new approach to construct extractors. Extractors are algorithms that transform a “weakly random” distribution into au almost uniform distribution. Explicit constructions of extractors have a variety of important applications, and tend to be very difficult to achieve. We demonstrate an unsuspected connection between extractors and pseudorandom generators. In fact, we show that every pseudorandom generator of a certain kind is an extractor. A pseudprandom generator construction due to Impagliazzo and Wigderson, once reinterpreted via our connection, is already an extractor that beats most known constructions and solves an important open question. We also show that, using the simpler Nisan-Wigderson generator and standard error-correcting codes, one can build even better extractors with the additional advantage that both the construction and the analysis are extremely simple and admit a short self-contained treatment.	algorithm;code;forward error correction;pseudorandom generator;pseudorandomness;randomness extractor	Luca Trevisan	1999		10.1145/301250.301289	combinatorics;discrete mathematics;theoretical computer science;mathematics;pseudorandom generator;uniform distribution	Theory	10.045641235951194	25.221412371012956	36960
5ad47e61517d4e5507fd96ecd00e3a910b6fd545	efficient parallel algorithms for the r-dominating set and p-center problems on trees	parallel algorithm;set theory;dominating set;computational complexity;time use;testing feasibility crew pram parallel algorithms vertex set edge set;set theory parallel algorithms concurrency theory computational complexity;concurrency theory;parallel algorithms	Let T=(V, E) be a tree with vertex set V and edge set E. Let n=|V|. Each e/spl isin/E has a non-negative length. In this paper, we first present an algorithm on the CREW PRAM for solving the V/V/r-dominating set problem on T, where r/spl ges/0 is a real number. The algorithm requires O(log/sup 2/ n) time using O(n log n) work. Applying this algorithm as a procedure for testing feasibility, the V/V/p-center problem on the CREW PRAM is solved in O(log/sup 2/ n) time using O(n log/sup 2/ n) work, where p/spl ges/1 is an integer. Previously, He and Yesha had proposed algorithms on the CREW PRAM for special cases of the V/V/r-dominating set and the V/V/p-center problems, in which r is an integer and the lengths of all edges are 1. Their V/V/r-dominating set algorithm requires O(log n log log n) time using O(n log n log log n) work; and their V/V/p-center algorithm requires O(log/sup 2/ n log log n) time using O(n log/sup 2/ n log log n) work. As compared with He and Yesha's results, ours are more general and more efficient from the aspect of work.	dominating set;parallel algorithm	Tzu-Chin Lin;Biing-Feng Wang	2002		10.1109/ICPADS.2002.1183387	parallel computing;computer science;theoretical computer science;distributed computing;parallel algorithm;algorithm	Theory	15.563297399583108	32.10326606330017	37021
c813c428315c8583efd039384574ce94010b8901	the hypergraph assignment problem	assignment;directed hypergraphs;set partitioning;bipartite hypergraph;extended formulation;90c27;hyperassignment;doctoral thesis;hypergraph;bipartite	This thesis deals with the hypergraph assignment problem (HAP), a set partitioning problem in a special type of hypergraph. The HAP generalizes the assignment problem from bipartite graphs to what we call bipartite hypergraphs, and is motivated by applications in railway vehicle rotation planning. The main contributions of this thesis concern complexity, polyhedral results, analyses of random instances, and primal methods for the HAP. We prove that the HAP is NP -hard and APX -hard even for small hyperedge sizes and hypergraphs with a special partitioned structure. We also study the complexity of the set packing and covering relaxations of the HAP, and present for certain cases polynomial exact or approximation algorithms. A complete linear description is known for the assignment problem. We therefore also study the HAP polytope. There, we have a huge number of facet-defining inequalities already for a very small problem size. We describe a method for dividing the inequalities into equivalence classes without resorting to a normal form. Within each class, facets are related by certain symmetries and it is sufficient to list one representative of each class to give a complete picture of the structural properties of the polytope. We propose the algorithm “HUHFA” for the classification that is applicable not only to the HAP but combinatorial optimization problems involving symmetries in general. In the largest possible HAP instance for which we could calculate the complete linear description, we have 14049 facets, which can be divided into 30 symmetry classes. We can combinatorially interpret 16 of these classes. This is possible by employing cliques to generalize the odd set inequalities for the matching problem. The resulting inequalities are valid for the polytope associated with the set packing problem in arbitrary hypergraphs and have a clear combinatorial meaning. An analysis of random instances provides a better insight into the structure of hyperassignments. Previous work has extensively analyzed random instances for the assignment problem theoretically and practically. As a generalization of these results for the HAP, we prove bounds on the expected value of a minimum cost hyperassignment that uses half of the maximum possible number of hyperedges that are not edges. In a certain complete partitioned hypergraph G2,2n with i. i. d. exponential random variables with mean 1 as hyperedge costs it lies between 0.3718 and 1.8310 if the vertex number tends to infinity. Finally, we develop an exact combinatorial solution algorithm for the HAP that combines three methods: A very large-scale neighborhood search, the composite columns method for the set partitioning problem, and the network simplex algorithm.	apx;assignment problem;directed graph;integer programming;linear programming formulation;loss function	Ralf Borndörfer;Olga Heismann	2015	Discrete Optimization	10.1016/j.disopt.2014.11.002	mathematical optimization;combinatorics;discrete mathematics;bipartite graph;computer science;3-dimensional matching;assignment;mathematics	Theory	24.310959053142895	20.757338057283047	37048
79737a07dcfa7b10512a5f23e4c990cfa0799c4e	combinatorial properties of uniformly recurrent words and an application to semigroups		We prove some combinatorial properties of uniformly recurrent infinite words which can be expressed in terms of bi-ideal and n-divided sequences. A consequence of these results is an improvement of a theorem of Shirshov [13] and a new finiteness condition for finitely generated semigroups which generalizes both a theorem of Restivo and Reutenauer [12] and a theorem of de Luca and Restivo [4].	recurrent word	Aldo de Luca;Stefano Varricchio	1991	IJAC	10.1142/S0218196791000158	combinatorics;discrete mathematics;mathematics;algebra	Theory	-3.003487766658511	17.961936364754237	37094
d921b55db743d5cf9c652a3fcb2d7a5d4c628570	an ear decomposition approach to approximating the smallest 3-edge connected spanning subgraph of a multigraph	68w40;network design;mathematiques discretes;depth first search 05c40;approximation algorithms;matematicas discretas;metodo descomposicion;approximation algorithm;methode decomposition;discrete mathematics;05c40;68wxx;composante connexe;90b18;connected graph;multigraph;graphe simple;decomposition method;graph connectivity;ear decomposition;90c27;multigrafo;68r10;conectividad grafo;edge graph;05c85;algoritmo aproximacion;conception reseau;arete graphe;depth first search;multigraphe;algorithme approximation;connectivite graphe;68w25;graphe connexe;arista grafico;multigraphs;edge connectivity;grafo conexo	This paper gives a 3/2 approximation algorithm for the smallest 3-edge connected spanning subgraph of an undirected multigraph. The previous best algorithm of Khuller and Raghavachari [8] has approximation ratio 5/3. The algorithm of Cheriyan and Thurimella [3] achieves ratio 3/2 for simple graphs. Our approach is based on the relationship between an ear decomposition of a 2-edge connected graph and 3-edge connected components, enabling us to achieve running time O(mα(m,n)).	approximation algorithm;connected component (graph theory);connectivity (graph theory);ear decomposition;file spanning;graph (discrete mathematics);multigraph;time complexity	Harold N. Gabow	2002	SIAM J. Discrete Math.	10.1137/S0895480102405476	mathematical optimization;combinatorics;discrete mathematics;connectivity;connected dominating set;mathematics;approximation algorithm	Theory	21.605882183178107	27.764398299009102	37127
e059ec2dc85d23370fd46fd098d25fb911e9695b	an exact solution approach for the preferential bidding system problem in the airline industry	flight crews;branch and price algorithms;programacion entera;preferential bidding system;mathematical methods;exact solution;approche heuristique;air transportation;result;programmation en nombres entiers;methode calcul;experimental result;metodo calculo;resolucion problema;transport aerien;transporte aereo;crew scheduling;numerical analysis;integer programming;scheduling;personal de navegacion;personnel navigant;subasta;resultado experimental;bidding;enfoque heuristico;resultado;crew;airline industry;resultat;enchere;airlines;heuristic approach;resultat experimental;crew accommodation;computing method;ordonnancement;reglamento;problem solving;resolution probleme;work schedules personnel;branch and price;bids	This paper introduces the first exact approach for constructing aircrew member personalized monthly work schedules when a preferential bidding system (PBS) is used. With such a system, each employee bids for his/her preferred activities, yielding a bidding score for each feasible schedule. The PBS problem thus consists of assigning to each employee a schedule that maximizes his/her preferences, in order of seniority, while covering all crew pairings. The proposed exact solution approach relies on column generation, and when a tentative maximum score for a crew member is established, it explicitly enumerates for that employee all feasible schedules with that score. Tests on real-life cases show that this approach can substantially improve the quality of the solutions produced by the best known existing method in similar computational times.	real-time bidding	Heykel Achour;Michel Gamache;François Soumis;Guy Desaulniers	2007	Transportation Science	10.1287/trsc.1060.0172	mathematical optimization;simulation;integer programming;bidding;numerical analysis;computer science;engineering;branch and price;operations management;mathematics;operations research;scheduling;algorithm;aviation	AI	17.67726958432963	6.5329160619206155	37135
fec8c6eaa447d7667281a55e251a46abb010c985	studs, seeds and immigrants in evolutionary algorithms for unrestricted parallel machine scheduling	semilla;modelizacion;allocation rule;algoritmo paralelo;job management;tiempo total acabamiento;parallel algorithm;availability;disponibilidad;resource allocation;semence;machine parallele;temps total achevement;intelligence artificielle;probabilistic approach;algoritmo genetico;algorithme parallele;modelisation;parallel machine scheduling;makespan;bank system;scheduling;enfoque probabilista;approche probabiliste;algorithme genetique;artificial intelligence;algorithme evolutionniste;seed;genetic algorithm;parallel machines;gestion trabajos;algoritmo evolucionista;resource availability;asignacion recurso;inteligencia artificial;evolutionary algorithm;allocation ressource;gestion travaux;modeling;disponibilite;sistema bancario;systeme bancaire;ordonnancement;reglamento	Parallel machine scheduling, involves the allocation of jobs to the system resources (a bank of machines in parallel). A basic model consisting of m machines and n jobs is the foundation of more complex models. Here, jobs are allocated according to resource availability following some allocation rule. In the specialised literature, minimisation of the makespan has been extensively approached and benchmarks can be easily found. This is not the case for other important objectives such as the due date related objectives. To solve the unrestricted parallel machine scheduling problem, this paper proposes MCMP-SRI and MCMP-SRSI, which are two multirecombination schemes that combine studs, random and seed immigrants. Evidence of the improved behaviour of the EAs when inserting problem-specific knowledge with respect to SCPC (an EA without multirecombination) is provided. Experiments and results are discussed.	evolutionary algorithm;parallel computing;scheduling (computing);seeds (cellular automaton)	Edgardo Ferretti;Susana C. Esquivel;Raúl Héctor Gallard	2004		10.1007/978-3-540-30498-2_18	availability;systems modeling;genetic algorithm;resource allocation;computer science;artificial intelligence;evolutionary algorithm;parallel algorithm;operations research;scheduling;algorithm	HPC	19.76069121405241	6.078118975398368	37160
1402ba4f0dbc620a51f6cba287c863aae158c7ad	infinite hypergraphs i. basic properties	graph theory;hipergrafico;teoria grafo;esquema programa;schema programme;programmation;etude theorique;theorie graphe;programacion;informatique theorique;estudio teorico;program schemate;hypergraph;theoretical study;programming;hypergraphe;computer theory;informatica teorica	On etudie les proprietes fondamentales des hypergraphes infinis a hyperaretes etiquetees. Une structure algebrique est fournie qui permet de decrire de tels graphes a l'aide d'expressions infinies. On prouve que deux telles expressions definissent le meme graphe si et seulement si elles sont congruentes modulo un certain systeme de reecriture. Ces resultats seront utilises dans la seconde partie de cet article pour etudier certains systemes d'equations recursives sur les hypergraphes et pour caracteriser leurs solutions		Michel Bauderon	1991	Theor. Comput. Sci.	10.1016/0304-3975(91)90222-N	programming;combinatorics;graph theory;mathematics;algorithm	ECom	0.21263494434889865	17.31304231489351	37172
3d5eafdd06e65698e420d817df76a9285e8d8f44	scheduling of a smart antenna: capacitated coloring of unit circular-arc graphs	graph theory;distributed system;optimisation;coloracion grafo;teoria grafo;systeme reparti;approximate algorithm;optimizacion;resolucion conflicto;scheduling with conflicts;approximation algorithm;unit circular arc;antenne;simultaneidad informatica;grafo circular;theorie graphe;graphe circulaire;concurrency;sistema repartido;coloration graphe;circular graph;resolution conflit;scheduling;smart antenna;algoritmo aproximacion;scheduling problem;coaccion capacidad;antenna;optimization;unit circular arc graphs;contrainte capacite;capacitated coloring;antena;algorithme approximation;algoritmo optimo;capacity constraint;algorithme optimal;optimal algorithm;conflict resolution;simultaneite informatique;ordonnancement;reglamento;smart antennas;graph colouring	We consider scheduling problems that are motivated by an optimization of the transmission schedule of a smart antenna. In these problems we are given a set of messages and a conflict graph that specifies which messages cannot be transmitted concurrently. In our model the conflict graph is a unit circular-arc graph. Two variants of the problem are considered: c-mbl and nu-c-mbl. In c-mbl, the messages have unit demands, whereas in nu-c-mbl demands are arbitrary. We present an optimal algorithm for c-mbl and a 3-approximation algorithm for nu-c-mbl.	algorithm;concurrency (computer science);mathematical optimization;scheduling (computing);serializability;smart antenna	Guy Even;Shimon Shahar	2006		10.1007/11922377_6	mathematical optimization;combinatorics;independent set;computer science;graph theory;conflict resolution;antenna;smart antenna;mathematics;approximation algorithm;algorithm;statistics	Theory	20.87505268435777	28.668730299788137	37209
1bc0a3bc2c64fab8ece1a22f6f655c3c726ae0a9	topology matters: smoothed competitiveness of metrical task systems	camino mas corto;online algorithm;topology;shortest path;metrical task systems;maximum degree;desviacion tipica;algorithme en ligne;competitividad;standard deviation;topologie;competitive algorithms;plus court chemin;algorithme deterministe;average case analysis;algoritmo en linea;metrical task system;algorithm en ligne;asymptotic behavior;comportement asymptotique;topologia;smoothed analysis;upper bound;comportamiento asintotico;algorithme competitif;deterministic algorithms;smoothing methods;work function;informatique theorique;methode lissage;borne inferieure;ecart type;chemin plus court;competitiveness;competitive analysis;online algorithms;analyse cas moyen;borne superieure;competitivite;algorithme fonction travail;analyse douce;lower bound;analyse competitive;cota superior;competitive ratio;cota inferior;computer theory;work function algorithm;systeme tache metrique;binary tree;informatica teorica	Borodin, Linial and Saks [6] introduced a general framework to model online problems, calledmetrical task systems. We are given an undirected and connected graphG = (V, E), with node setV and edge set E, and a positive length function λ : E → IR on the edges of G. Let n be the number of nodes in G. We extendλ to a metricδ onG. Let δ : V × V → IR0 be a distance function such that δ(u, v) denotes the shortest path distance (with respect to λ) between any two nodes u andv in G. A task τ is ann-vector(r(v1), . . . , r(vn)) of request costs. The cost to process task τ in nodevi is r(vi) ∈ IR0 ∪{∞}. The online algorithm starts from a given initial position s0 ∈ V and has to service a sequence S = 〈τ1, . . . , τr〉 of tasks, arriving one at a time. If the online algorithm resides after task τt−1 in nodeu, the cost to service task τt in nodev is δ(u, v) + rt(v); δ(u, v) is thetransition cost andrt(v) is theprocessing cost. The objective is to minimize the total transition plus proce ssing cost. Many well-known online problems can be formulated as metric al task systems; for example, the paging problem, the static list accessing p roblem and thek-server problem. One might as well consider metrical task system as a general scheduling problem. Due to its generality, the competitive ratio of an a lgorithm for metrical task systems is usually weak compared to the one of an online algor ithm that is designed for a particular problem, such as the k-server problem. A widely accepted measure for the performance of an online al gorithm is itscompetitive ratio [11]. Let ALG[S] andOPT[S], respectively, be the cost of the online and the optimal offline algorithm on a sequence S. For a cost minimization problem, the competitive ratioc of online algorithmALG is defined as the supremum over all input sequences S of the ratioALG[S]/OPT[S]. Borodin, Linial and Saks [6] gave a deterministic online alg orithm that has a competitive ratio of2n − 1 for every metrical task system; this algorithm is known as the work function algorithm and we will subsequently use WFA to refer to it. The 2n − 1 competitive ratio of WFA is optimal. Borodin, Linial and Sak s [6] and Manasse, McGeoch and Sleator [10] proved that every deterministic online algorithm has competitive ratio at least 2n− 1 for any arbitrary metrical task system. We emphasize that this lower bound is proven independently of the underly ing metric, i.e., it holds for any arbitrary graphG and length functionλ.	catherine mcgeoch;competitive analysis (online algorithm);emoticon;graph (discrete mathematics);k-server problem;metrical task system;michael saks (mathematician);nati linial;online algorithm;online and offline;page replacement algorithm;paging;scheduling (computing);server (computing);shortest path problem;smoothed analysis;smoothing	Guido Schäfer;Naveen Sivadasan	2005	Theor. Comput. Sci.	10.1016/j.tcs.2005.04.006	competitive analysis;online algorithm;combinatorics;asymptotic analysis;computer science;calculus;mathematics;upper and lower bounds;algorithm;statistics;metrical task system	Theory	16.881363116058345	12.914377827840301	37210
bb30f9bcdba06bba4c16a67ab9ed09d3754226b3	tighter packed bit-parallel nfa for approximate string matching	approximate string matching;automaton;error threshold;automata;side effect;pattern matching;automate;appariement chaine;concordance forme;string matching	We propose a new variant of the bit-parallel NFA of Baeza-Yates and Navarro (BPD) for approximate string matching [1]. Given a length-m pattern and an error threshold k, the original BPD uses (m−k)(k +2) bits of space. We decrease this to (m− k)(k +1), and also give a slightly more efficient simulation algorithm for the NFA. In experiments our modified NFA is often noticeably more efficient than the original algorithm under moderate values of k and m.	approximate string matching;experiment;like button;nondeterministic finite automaton;simulation;string searching algorithm	Heikki Hyyrö	2006		10.1007/11812128_32	combinatorics;theoretical computer science;mathematics;algorithm	ECom	12.952554075702539	27.131730508961105	37325
b6de0eae6b41f6b465dc00ee145320e3e9f7d81b	a new algorithm for the assignment problem: an alternative to the hungarian method	assignment;optimal solution;assignment problem;asignacion;programacion entera;metodo simplejo;duality;assignation;simplex method;programmation en nombres entiers;algorithme;algorithm;combinatorial problem;dualite;probleme combinatoire;problema combinatorio;programacion lineal;integer programming;hungarian method;linear programming;programmation lineaire;dualidad;methode simplexe;algoritmo	Abst rac t -This paper presents a new algorithm for the well-studied assignment problem. Our assignment algorithm is based on a 2n × 2n matrix. The dual to the assignment problem is considered in this paper by relaxing the constraints of the original assignment problem. A 2.n x 2n matrix is formed for an initial feasible solution to the dual. Then operations are performed on the matrix until an optimal solution is found. © 1997 Elsevier Science Ltd	assignment problem;hungarian algorithm;oracle rac;the matrix;whole earth 'lectronic link	Ping Ji;W. B. Lee;Hongyu Li	1997	Computers & OR	10.1016/S0305-0548(97)00019-1	augmented assignment;mathematical optimization;combinatorics;linear bottleneck assignment problem;duality;integer programming;computer science;generalized assignment problem;linear programming;hungarian algorithm;assignment;mathematics;assignment problem;weapon target assignment problem;simplex algorithm;algorithm;quadratic assignment problem	EDA	23.06225944451301	12.173330625582038	37334
81bb0853bb0642e122e98fb9c387bd6d682cabbb	tripartite probability distributions and communication complexity	bob;communication complexity;quantum correlations;local community;quantum physics;computational complexity;probability distribution;bell inequality	We show that every tripartite quantum correlation generated with a Schmidt state (in particular every correlation generated with the GHZ state) can be simulated with the sending of two bits of classical communication from Alice to Bob and Charlie plus the sending of two bits of classical communication from Bob to Charlie. This extends recent results which showed that the maximal violation of Bell inequalities attainable by these correlations is uniformly bounded. For simplicity, we state and prove the result for three parties, but the generalization to the case of n parties follows easily. We also show that every n-partite probability distribution generated with local resources plus c-bits of local communication can violate a Bell inequality by at most a factor of 2 c .	alice and bob;bell state;bell's theorem;communication complexity;existential quantification;greenberger–horne–zeilinger state;maximal set;quantum correlation;schmidt decomposition;social inequality	Carlos Palazuelos;David Pérez-García;Ignacio Villanueva	2010	CoRR		probability distribution;bell state;quantum teleportation;pure mathematics;communication complexity;bell's theorem;mathematics;computational complexity theory;physics;quantum mechanics;bell test experiments	Theory	8.00909780688801	25.189412099955348	37342
20febc12bddf828cdd5b992ab48ae875bb672deb	constructing optimal search trees in optimal time	databases;arbre recherche;base donnee;b trees;database;2 3 trees;base dato;tree data structures;indexing terms;algorithme;algorithm;search trees;tree construction;arbol investigacion;indexing;data structures;indexation;estructura datos;indizacion;2 3 4 trees;algorithms;binary search trees tree data structures algorithm design and analysis senior members application software databases indexing computer science parallel algorithms phase change random access memory;a;structure donnee;tree searching;search tree;b trees optimal search trees optimal time 2 3 trees 2 3 4 trees;optimal algorithm;data structure;tree data structures tree searching;algoritmo	Ða; b-trees are an important class of search trees. They include 2-3 trees, 2-3-4 trees, and B-trees as subclasses. We show that a space-minimum a; b-tree is also height-minimum and present an optimal algorithm for constructing a; b-trees that are height-minimum and space-minimum. Given n keys, our algorithm constructs an a; b-tree with minimum height and fewest possible nodes. Our algorithm takes n time if the keys in S are sorted and n logn time if the keys are not sorted. We also discuss possible applications of	2–3–4 tree;algorithm;b+ tree;b-tree;search tree	Si-Qing Zheng;Molin Sun	1999	IEEE Trans. Computers	10.1109/12.780881	b-tree;search engine indexing;combinatorics;index term;data structure;computer science;theoretical computer science;mathematics;search tree;tree;programming language;algorithm	Theory	15.31057631056692	27.757056569422616	37356
d0d7ce7883de76f69048b5553484e3799b82e114	business modelling for smart continual commissioning in esco set-ups		The availability of sensors, smart meters, and so called ‘intelligent devices’ (IoT) enables owners and tenants to better understand and flexibly adjust the status of buildings and their systems according to their needs. However, it also requires a more intense and detailed knowledge about how to exploit, analyse and manage ‘big data’ compiled from these devices. Building operators, facility managers and energy suppliers are expected to collaborate and to share this data aiming to deliver more holistic, comprehensive services to clients (i.e. owners and tenants of buildings). This paper discusses how so called ESCO-business models (energy service companies) and CC-business models (continuous commissioning) can be integrated through sharing of big data and collaboration of major stakeholders involved in building operation, energy supply and engineering consultancy. It explains how building owners will benefit from the availability of such comprehensive, collaborative services.		Karsten Menzel;Andriy Hryshchenko	2017		10.1007/978-3-319-65151-4_29	systems engineering;energy supply;operator (computer programming);big data;computer science;project commissioning;facility management;internet of things;exploit	Robotics	1.4756381960908875	7.677512502197683	37457
565c447741cc0df7e5c019c4ff2b9649b87550f5	counting subwords and regular languages		Let x and y be words. We consider the languages whose words z are those for which the numbers of occurrences of x and y, as subwords of z, are the same (resp., the number of x’s is less than the number of y’s, resp., is less than or equal). We give a necessary and sufficient condition on x and y for these languages to be regular, and we show how to check this condition efficiently.	regular language	Charles J. Colbourn;Ryan E. Dougherty;Thomas Finn Lidbetter;Jeffrey Shallit	2018		10.1007/978-3-319-98654-8_19	combinatorics;discrete mathematics;regular language;mathematics	Theory	-0.5104511139809248	20.602859563454814	37524
e6caff814bba9949fce6a48c76e3b158a8ddafbb	extending search phases in the micali-vazirani algorithm		The Micali-Vazirani algorithm is an augmenting path algorithm that offers the best theoretical runtime of O(n0.5m) for solving the maximum cardinality matching problem for non-bipartite graphs. This paper builds upon the algorithm by focusing on the bottleneck caused by its search phase structure and proposes a new implementation that improves efficiency by extending the search phases in order to find more augmenting paths. Experiments on different types of randomly generated and real world graphs demonstrate this new implementation’s effectiveness and limitations. 1998 ACM Subject Classification G.2.2 Graph Theory, F.2.2 Nonnumerical Algorithms and Problems	algorithm;experiment;flow network;graph (discrete mathematics);graph theory;matching (graph theory);procedural generation	Michael Huang;Clifford Stein	2017		10.4230/LIPIcs.SEA.2017.10	computer science;algorithm	ML	20.308046090336784	20.682643207089708	37531
a5b61ad04ba98f0473d01390e352078d1c948a7a	optimality conditions for hunter's bound	arbre graphe;graph node;hunter s bound;probability;nudo grafo;tree graph;loi probabilite;ley probabilidad;05c05;arbre maximal;probability bounds;input;condicion optimalidad;condition optimalite;arbol maximo;bound states;probability distribution;probabilidad;probabilite;entree ordinateur;spanning tree;entrada ordenador;arbol grafo;optimality condition;noeud graphe;probability of the union	The bound known as Hunter’s bound states that P(A1∪· · ·∪ An) ≤ ∑n i=1 pi − ∑ {i, j}∈T pi, j , where T designates the heaviest spanning tree of the graph on n nodes with edge weights pi, j . We prove that Hunter’s bound is optimal if and only if the input probabilities are given on a tree. c © 2007 Elsevier B.V. All rights reserved.	bound state;file spanning;spanning tree	Pierangela Veneziani	2008	Discrete Mathematics	10.1016/j.disc.2007.11.019	probability distribution;mathematical optimization;combinatorics;discrete mathematics;bound state;spanning tree;probability;mathematics;tree	Theory	23.786926602525654	31.702082550752746	37593
41f80c443d61fd87f06088eed9769b685cd184d0	graph grammars and global program data flow analysis	computers;finite element methods;mirrors;iso;computer aided instruction;code standards;flow graphs;force;data analysis;control structure;graph grammar;aggregates;flow graphs data analysis algorithm design and analysis program processors computer aided instruction code standards information analysis artificial intelligence;data flow analysis;production;artificial intelligence;optimization;electrical engineering;programming;information analysis;program processors;construction;algorithm design and analysis;local area networks	"""Program structure is defined in terms of a simple graph grammar, the """"semi-structured flow graph grammar,"""" which admits many of the control structure extensions suggested for """"structured programming."""" The grammar defines a set of graph reductions which are shown to have the """"Finite Church-Rosser (FCR)"""" property; i.e., when applied in any order to a graph, the limit (when no further reductions are possible) is unique. In particular, if a given graph is generated by the grammar, repeated application of the reductions will result in a single node regardless of the order in which they are applied. This property gives rise to an algorithm that parses a given program flow graph in time linear in the size of the graph. The resulting parse is used in a global data flow analysis algorithm which requires a number of bit-vector steps which is also linear in the size of the given graph."""	aharonov–bohm effect;algorithm;attribute grammar;bit array;church–rosser theorem;common subexpression elimination;control flow graph;data-flow analysis;dataflow;edward wegman;gw-basic;goto;graham scan;graph (discrete mathematics);graph rewriting;loop-invariant code motion;mathematical optimization;maximum flow problem;parsing;reduction strategy (lambda calculus);semiconductor industry;structured programming;time complexity	Rodney Farrow;Ken Kennedy;Linda Zucconi	1976	17th Annual Symposium on Foundations of Computer Science (sfcs 1976)	10.1109/SFCS.1976.17	graph power;combinatorics;directed graph;graph bandwidth;null graph;graph property;computer science;regular graph;clique-width;theoretical computer science;simplex graph;cubic graph;mathematics;voltage graph;distance-hereditary graph;graph;data analysis;programming language;butterfly graph;climate graph;quartic graph;complement graph;line graph;algorithm;string graph;strength of a graph;coxeter graph;algebra	Theory	-1.5354172999493603	24.05619289968206	37626
744176c2f1f39571e3595d0a3a3bc5640cc39cd6	exact inference for relational graphical models with interpreted functions: lifted probabilistic inference modulo theories		Probabilistic Inference Modulo Theories (PIMT) is a recent framework that expands exact inference on graphical models to use richer languages that include arithmetic, equalities, and inequalities on both integers and real numbers. In this paper, we expand PIMT to a lifted version that also processes random functions and relations. This enhancement is achieved by adapting Inversion, a method from Lifted First-Order Probabilistic Inference literature, to also be modulo theories. This results in the first algorithm for exact probabilistic inference that efficiently and simultaneously exploits random relations and functions, arithmetic, equalities and inequalities.	algorithm;first-order predicate;graphical model;modulo operation	Rodrigo de Salvo Braz;Ciaran O'Reilly	2017	CoRR		discrete mathematics;inequality;combinatorics;probabilistic logic;real number;inference;modulo;variable elimination;graphical model;integer;mathematics	AI	-1.6553714963471187	14.894448946406964	37633
b95e1405b1b384475281eb47e0d25024d9a1f351	the vectorization of the partition problem	parallel calculus;vectorisation;probleme np complet;supercomputer;vectorization;resolucion problema;supercomputador;vectorisacion;probleme combinatoire;calculo paralelo;problema combinatorio;particion;partition;problema np completo;timing results;combinatory problem;calcul parallele;superordinateur;np complete problem;problem solving;resolution probleme;partition problem	Abstract   This paper describes a vectorized algorithm for the partition problem, a famous NP-complete problem. A set of partition problems that required 518 seconds to be solved on a VAX/8550 computer would require only 2 seconds on the Cyber 205 under the vector mode. A partition problem with  n  equal to 1000 was solved in only 6.34 seconds.	automatic vectorization;partition problem	Shyong Jian Shyu;Richard C. T. Lee	1990	Parallel Computing	10.1016/0167-8191(90)90071-G	partition;partition problem;combinatorics;supercomputer;np-complete;partition refinement;computer science;graph partition;calculus;vectorization;mathematics;algorithm;algebra	HPC	18.20006668519222	28.290359350251727	37705
a16ae7a7367391f7baeb5085655c329af12683ce	ordering heuristics for parallel graph coloring	cilk;graph coloring;ordering heuristics;parallel algorithms	This paper introduces the largest-log-degree-first (LLF) and smallest-log-degree-last (SLL) ordering heuristics for parallel greedy graph-coloring algorithms, which are inspired by the largest-degree-first (LF) and smallest-degree-last (SL) serial heuristics, respectively. We show that although LF and SL, in practice, generate colorings with relatively small numbers of colors, they are vulnerable to adversarial inputs for which any parallelization yields a poor parallel speedup. In contrast, LLF and SLL allow for provably good speedups on arbitrary inputs while, in practice, producing colorings of competitive quality to their serial analogs.  We applied LLF and SLL to the parallel greedy coloring algorithm introduced by Jones and Plassmann, referred to here as JP. Jones and Plassman analyze the variant of JP that processes the vertices of a graph in a random order, and show that on an O(1)-degree graph G=(V,E), this JP-R variant has an expected parallel running time of O(lgV/lglgV) in a PRAM model. We improve this bound to show, using work-span analysis, that JP-R, augmented to handle arbitrary-degree graphs, colors a graph G=(V,E) with degree Delta using Theta(V+E) work and O(lgV+ lg Delta . min sqrt-E, Delta +lg DeltaVlglgV) expected span. We prove that JP-LLF and JP-SLL --- JP using the LLF and SLL heuristics, respectively --- execute with the same asymptotic work as JP-R and only logarithmically more span while producing higher-quality colorings than JP-R in practice.  We engineered an efficient implementation of JP for modern shared-memory multicore computers and evaluated its performance on a machine with 12 Intel Core-i7 (Nehalem) processor cores. Our implementation of JP-LLF achieves a geometric-mean speedup of 7.83 on eight real-world graphs and a geometric-mean speedup of 8.08 on ten synthetic graphs, while our implementation using SLL achieves a geometric-mean speedup of 5.36 on these real-world graphs and a geometric-mean speedup of 7.02 on these synthetic graphs. Furthermore, on one processor, JP-LLF is slightly faster than a well-engineered serial greedy algorithm using LF, and likewise, JP-SLL is slightly faster than the greedy algorithm using SL.	adversary (cryptography);color;computer;graph coloring;greedy algorithm;greedy coloring;heuristic (computer science);jones calculus;maxima and minima;multi-core processor;nehalem (microarchitecture);parallel computing;sl (complexity);shared memory;speedup;synthetic intelligence;time complexity	William Hasenplaugh;Tim Kaler;Tao B. Schardl;Charles E. Leiserson	2014		10.1145/2612669.2612697	mathematical optimization;combinatorics;parallel computing;computer science;theoretical computer science;graph coloring;mathematics;distributed computing;parallel algorithm;greedy coloring;algorithm		20.599038993178343	21.899887031041782	37726
c83b071330a41caf5a0592f55cbcd7f7ed5b4b1a	a mixed integer sdp approach for the optimal placement of energy storage devices in power grids with renewable penetration	generators;renewable energy sources;artificial neural networks;energy storage;production;power generation;power grids power networks energy storage systems ess renewable sources optimal power flow opf mixed integer semidefinite program mi sdp energy production fixed storage devices locations renewable generation profiles;power demand;renewable energy sources energy storage integer programming load flow power grids;generators artificial neural networks energy storage production power generation power demand renewable energy sources	In power networks, Energy Storage Systems (ESS) can help to cope with intermittent availability of renewable sources. However, fixed, maintenance, and operating costs are a critical aspect that must be considered in the positioning and sizing of these devices. This paper addresses the problem of placing storage devices in order to achieve an Optimal Power Flow (OPF) in presence of renewable sources. The problem is addressed formulating a Mixed Integer Semidefinite Program (MI-SDP) that takes into account energy production and ESS costs. While this approach provides a solution that does not guarantee a physical meaning, this latter is recoverable from the dual solution of the MI-SDP with fixed storage devices locations. The approach is demonstrated on the IEEE 14 and 30 bus benchmark systems where power demand, renewable generation profiles and costs have been taken from real data.	benchmark (computing);schedule (computer science);semidefinite programming	Marcello Torchio;Lalo Magni;Davide Martino Raimondo	2015	2015 American Control Conference (ACC)	10.1109/ACC.2015.7171937	renewable energy;electricity generation;mathematical optimization;base load power plant;engineering;electrical engineering;distributed generation;energy storage;intermittent energy source;artificial neural network	Embedded	4.957482700958575	5.581934391912321	37845
7019fcd585eea4450d4ccd41707d583f3c097f9a	optimal wafer cutting in shuttle layout problems	camino mas corto;bin packing problem;experimental design;mascara;plan masse;shortest path;generation colonne;microelectronic fabrication;manufacturing cost;fabricacion microelectrica;semiconducteur;costo fabricacion;maximum clique problem;generacion columna;pricing;layout problem;plan experiencia;probleme agencement;probleme clique maximal;plus court chemin;problema relleno;fijacion precios;semiconductor material;problema clique maxima;layout plan;cout fabrication;branch and bound method;semiconductor materials;tariffication;wafer;plan experience;metodo branch and bound;tarification;retard;vertex weighted clique problem;cutting problem;problema disposicion;probleme remplissage;pastilla electronica;masque;methode separation et evaluation;pastille electronique;retraso;mask;semiconductor layout problem;fixation prix;plano masa;column generation;tarificacion;fabrication microelectronique	A major cost in semiconductor manufacturing is the generation of photo masks which are used to produce the dies. When producing smaller series of chips it can be advantageous to build a shuttle mask (or multi-project wafer) to share the startup costs by placing different dies on the same mask. The shuttle layout problem is frequently solved in two phases: first, a floorplan of the shuttle is generated. Then, a cutting plan is found which minimizes the overall number of wafers needed to satisfy the demand of each die type. Since some die types require special production technologies, only compatible dies can be cut from a given wafer, and each cutting plan must respect various constraints on where the cuts may be placed. We present an exact algorithm for solving the minimum cutting plan problem, given a floorplan of the dies. The algorithm is based on delayed column generation, where the pricing problem becomes a maximum vertex-weighted clique problem in which each clique consists of cutting compatible dies. The resulting branch-and-price algorithm is able to solve realistic cutting problems to optimality in a couple of seconds.	branch and price;clique problem;column generation;dantzig–wolfe decomposition;exact algorithm;floorplan (microelectronics);multi-project wafer service;semiconductor device fabrication;superword level parallelism;the matrix;wafer (electronics)	Lasse Nisted;David Pisinger;Avri Altman	2011	J. Comb. Optim.	10.1007/s10878-009-9284-z	column generation;pricing;mathematical optimization;combinatorics;bin packing problem;mathematics;mask;shortest path problem;design of experiments;algorithm;wafer	AI	18.725750996670193	7.231837993212706	37892
85f392247c3d9c4b8725a61c63cfe50b7ac3cf5e	the optimal number of used machines in a two-stage flexible flowshop scheduling problem	deterministic;flowshop;sequencing;makespan;scheduling;flowtime	We study practical scheduling problems with a major decision referring to the number of machines to be used. We focus on a two-stage flexible flowshop, where each job is processed on the first (critical) machine, and then continues to one of the second-stage parallel machines. Jobs are assumed to have identical processing times, and are processed in batches. A setup time is required when starting a new batch. We consider two objective functions: minimum makespan and minimum flowtime. In both cases, a closed form expression for the optimal number of machines to be used is introduced, and a unique and unusual sequence of decreasing batch sizes is shown to be optimal.	scheduling (computing)	Enrique Gerstl;Gur Mosheiov	2014	J. Scheduling	10.1007/s10951-013-0343-z	job shop scheduling;mathematical optimization;real-time computing;computer science;operating system;sequencing;scheduling;determinism	Theory	15.305783438688607	8.907773811728742	38080
49d1455344b214674e0c6933ca8559388a7645f2	on p systems operating in sequential mode	p system;standard definition;parallel applications	In the standard definition of a P system, a computation step co nsists of a parallel application of a “maximal” set of nondetermini stically chosen rules. Referring to this system as a parallel P system, we consider i n this paper a sequential P system, in which each step consists of an applicat ion of a single nondeterministically chosen rule. We show the following: 1. For 1-membrane catalytic systems (CS’s), the sequential version is strictly weaker than the parallel version in that the former defines (i . . generates) exactly the semilinear sets, whereas the latter is known to defi ne nonrecursive sets. 2. For 1-membrane communicating P systems (CPS’s), the sequ ential version can only define a proper subclass of the semilinear sets, wher eas the parallel version is known to define nonrecursive sets. 3. Adding a new type of rule of the form: ab ! axby omed ome to the CPS (a natural generalization of the rule ab! axby ome in the original model), wherex; y 2 fhere; outg, to the sequential 1-membrane CPS makes it equivalent to a vector addition system. 4. Sequential 1-membrane symport/antiport systems (SA’s) are equivalent to vector addition systems, contrasting the known result that t e parallel versions can define nonrecursive sets. 5. Sequential 1-membrane SA’s whose rules have radius 1, (1, 1) 2) (i.e., of the form (a; out); (a; in); (a; out; b; in); (a; out; b ; in)) generate exactly the semilinear sets. However, if the rules have radius 1, (1, ), (2,1) (i.e., of the form (ab; out; ; in)), the SA’s can only generate a proper subclass of the semilinear sets.	commutation theorem;computation;maximal set;p system;parallel computing;semilinear response;standard-definition television;vector addition system	Zhe Dang;Oscar H. Ibarra	2004			standard-definition television;computer architecture;real-time computing;computer science;distributed computing;algorithm;p system	Logic	1.633313759251827	24.757736132087356	38104
1c5e8e4e5f8c86ffb663811b2f33a18755e16a9f	discrete time queues for modelling an hdlc coupler	file attente;data transmission;evaluation performance;performance evaluation;evaluacion prestacion;queue;discrete time;modelisation;transmission donnee;hdlc procedure;fila de espera;modeling;procedure hdlc;transmision datos;modelaje	The classic queueing theory applied to continuous distribution functions, but very often we are interested in phenomena that have discrete distribution functions, in particular for digital transmissions. The queueing theory provides some theorems that allow users to solve systems analytically. However, we are limited by some constraints to an approximation of the model: constraint on arrival of service distributions. Generally, models must belong to Jackson or BCMP queueing networks. We can then use approximate methods: methods using decomposition, mean-value analysis, aggregation, or isolation 271, but these entail loss of information, which must be evaluated. In the extreme cases, we are obliged to consider simulation to obtain some results [6, 51. In a discreteevents simulator, the state space is finite and enumerable, and each transition occurs in a discrete manner. The time progression is provided in two ways according to whether it is directed by the events or by a clock. The simulator progresses in time only when a change of state occurs. This means that the time slot is not constant for each At, depending on the amount of time between two consecutive events. On the other hand, clockdirected simulation induces a fixed time slot. After each period of time (quantum) we examine the system in order to determine if a change of state occurs, which corresponds to an event during this quantum. The basic	acoustic coupler;approximation algorithm;color gradient;jackson;object composition;queueing theory;simulation;state space	J. P. Claude	1986	Journal of Systems and Software	10.1016/0164-1212(86)90023-3	discrete time and continuous time;real-time computing;simulation;systems modeling;telecommunications;computer science;programming language;queue;data transmission	Metrics	9.414529348118249	12.137512382958095	38108
fc599c6985705d7adbaf41dbc4ff1eb375b94165	bounds on the number of examples needed for learning functions	function learning;learning;pac learning;complexite calcul;fonction reguliere;learning model;piecewise smooth;68t05;aprendizaje;apprentissage;computational complexity;real function;fonction reelle;funcion regular;value function;computational learning theory;sample complexity;funcion real;lower bound;smooth function	We prove general lower bounds on the number of examples needed for learning function classes within different natural learning models which are related to pac-learning (and coincide with the pac-learning model of Valiant in the case of {0, 1}-valued functions). The lower bounds are obtained by showing that all nontrivial function classes contain a “hard binary-valued subproblem.” Although (at first glance) it seems to be likely that real-valued function classes are much harder to learn than their hardest binary-valued subproblem, we show that these general lower bounds cannot be improved by more than a logarithmic factor. This is done by discussing some natural function classes like nondecreasing functions or piecewise-smooth functions (the function classes that were discussed in [M. J. Kearns and R. E. Schapire, Proc. 31st Annual Symposium on the Foundations of Computer Science, IEEE Computer Society Press, Los Alamitos, CA, 1990, pp. 382–392, full version, J. Comput. System Sci., 48 (1994), pp. 464–497], [D. Kimber and P. M. Long, Proc. 5th Annual Workshop on Computational Learning Theory, ACM, New York, 1992, pp. 153–160]) with certain restrictions concerning their slope.	algorithm;binary data;computable function;computation;computational complexity theory;computational learning theory;computer science;concept learning;graph coloring;hp 48 series;hausdorff dimension;machine learning;modulo operation;polynomial;probably approximately correct learning;time complexity	Hans Ulrich Simon	1997	SIAM J. Comput.	10.1137/S0097539793259185	smoothness;mathematical optimization;combinatorics;computer science;artificial intelligence;mathematics;bellman equation;upper and lower bounds;computational complexity theory;computational learning theory;probably approximately correct learning;algorithm;algebra	Theory	8.79953666214774	19.620876081984314	38131
29c0e6168cf9319e9f27639c2615b81b285d4e00	production optimization for continuously operated processes with optimal operation and scheduling of multiple units	mixed integer linear program;computacion informatica;nonlinear programming;multi stage optimization;grupo de excelencia;optimal manufacturing;dynamic model based scheduling;product sequencing;optimization problem;ciencias basicas y experimentales;single unit;quimica;scheduling problem;parameter estimation;integer linear program;multiple unit production optimization;dynamic optimization	A production optimization problem for continuously operated processes is presented and a solution strategy is proposed. The strategy consists of decoupling the complete problem into a mixed-integer linear programming (MILP) scheduling problem, including sequencing and allocation, and a multi-stage dynamic optimization (DO) problem, including the determination of optimal trajectories and setpoints. The scheduling problem is treated as a master problem and the DO problem as a primal problem, and the complete problem is solved through iteration between the two. The approach is similar in nature to standard methods for solving mixed-integer nonlinear (MINLP) problems, such as Outer Approximation and Benders Decomposition, but more adapted to the specific problem, by permitting more freedom in choosing the binary representation. The decomposition strategy implies flexibility in choosing the optimization tools required, and enables the treatment of larger problems. The approach is a generalization of a previously reported one, where only the single-unit case was discussed. Splitting the primal problem into smaller DO subproblems, parameter estimation from the DO subproblems, termination criteria and other topics are discussed. The target process for demonstration of the method is an industrial polymerization process.	mathematical optimization;scheduling (computing)	Rasmus H. Nyström;Iiro Harjunkoski;Andreas Kroll	2006	Computers & Chemical Engineering	10.1016/j.compchemeng.2005.09.009	nurse scheduling problem;optimization problem;mathematical optimization;function problem;nonlinear programming;generalized assignment problem;cutting stock problem;mathematics;estimation theory;algorithm	DB	13.715612067062139	4.502817487857546	38138
62083653f0e3764dbc9e7ab4bee70efc9071a3ca	robust algorithms for constructing strongly convex hulls in parallel	use;problem;secuencial;erreur;plane;aplicacion;sequential;capsula convexa;geometrie algorithmique;computer model;computational geometry;polygone;plan;bridges;methode;time;result;calculo automatico;funda;probleme;utilizacion;computing;primitivo;pram computational model;enveloppe convexe;algorithme;calcul automatique;polygon;unit;algorithm;utilisation;bridge;modelo;sequentiel;temps;robust algorithms;robustesse;puente;plano;pont;robust method;time use;parallel computer;subroutine;poligono;resultado;primitif;robustness;geometria computacional;sous programme;modele;procesador;resultat;problema;error;processeur;primitive;generalized convexity;convex hull;application;metodo;method;models;processor;convex polygon;subprograma;unite;unidad;robustez;tiempo;algoritmo	Given a set S of n points in the plane, an -strongly convex -hull of S is de0ned as a convex polygon P with the vertices taken from S such that no point of S lies farther than outside P and such that even if the vertices of P are perturbed by as much as , P remains convex. This paper presents the 0rst parallel robust method for this generalized convex hull problem (note that the convex hull of S is the 0-strongly convex 0-hull of S). We show that an -strongly convex O( + )-hull of S can be constructed in O(logn) time using n processors with imprecise computations, where is the error unit of primitive operations. This result also implies an improved sequential algorithm. Our algorithm consists of two parts: (1) computing a convex O( + ) -hull of n points, in O(logn) time using n processors, and (2) constructing an -strongly convex O( + )-hull of a convex polygon with n vertices, in O(logn) time with n processors. We also 0nd an approximate bridge of two sets with n points each, in O(logn) time using n processors, which we use as a subroutine. All these algorithms are fundamental and have their own applications. The parallel computational model in this paper is the EREW PRAM. c © 2002 Elsevier Science B.V. All rights reserved.	approximation algorithm;central processing unit;computation;computational model;convex hull;parallel random-access machine;sequential algorithm;subroutine;vertex (geometry)	Wei Chen;Koichi Wada;Kimio Kawaguchi	2002	Theor. Comput. Sci.	10.1016/S0304-3975(01)00274-2	convex analysis;subderivative;support function;mathematical optimization;combinatorics;convex optimization;krein–milman theorem;convex polytope;convex combination;orthogonal convex hull;convex body;linear matrix inequality;convex conjugate;computational geometry;computer science;convex hull;absolutely convex set;polygon;gauss–lucas theorem;mathematics;geometry;convex set;convex curve;programming language;logarithmically convex function;algorithm;proper convex function;output-sensitive algorithm;choquet theory	Theory	17.900065021602963	28.90534433434612	38177
651a8c94a6474d9624e385d3debbd562b4e5a8c5	cryptographic limitations on learning boolean formulae and finite automata	complexite;fonction booleenne;fourier inversion;learning algorithm;connectionism;learning;limitation;conexionismo;complejidad;boolean function;graph coloring;automate etat fini;public key cryptosystem;complexity;group convolution;fast fourier transform;aprendizaje;number theory;connexionnisme;apprentissage;cryptage;limitacion;criptografia;funcion booliana;informatique theorique;cryptography;group representations;deterministic finite automata;learning from examples;finite groups;finite automata;polynomial time;rsa cryptosystem;learning problems;cryptographie;reseau neuronal;symmetric group;red neuronal;probably approximately correct;neural network;computer theory;informatica teorica	In this paper, we prove the intractability of learning several classes of Boolean functions in the distribution-free model (also called the Probably Approximately Correct or PAC model) of learning from examples. These results are representation independent, in that they hold regardless of the syntactic form in which the learner chooses to represent its hypotheses. Our methods reduce the problems of cracking a number of well-known public-key cryptosystems to the learning problems. We prove that a polynomial-time learning algorithm for Boolean formulae, deterministic finite automata or constant-depth threshold circuits would have dramatic consequences for cryptography and number theory. In particular, such an algorithm could be used to break the RSA cryptosystem, factor Blum integers (composite numbers equivalent to 3 modulo 4), and detect quadratic residues. The results hold even if the learning algorithm is only required to obtain a slight advantage in prediction over random guessing. The techniques used demonstrate an interesting duality between learning and cryptography. We also apply our results to obtain strong intractability results for approximating a generalization of graph coloring.	algorithm;automata theory;blum axioms;cryptosystem;deterministic finite automaton;finite-state machine;graph coloring;modulo operation;password cracking;polynomial;public-key cryptography;quadratic residue;rsa (cryptosystem);time complexity	Michael Kearns;Leslie G. Valiant	1994	J. ACM	10.1145/174644.174647	fast fourier transform;mathematical optimization;connectionism;combinatorics;number theory;discrete mathematics;complexity;computer science;cryptography;graph coloring;mathematics;boolean function;symmetric group;algorithm;statistics;algebra;generalization error	Theory	5.850645445690377	22.130367420257723	38209
c1d08395f7864d1396113dbc26cf087fe0f19648	(almost) tight bounds and existence theorems for confluent flows	internet routing;approximate algorithm;approximation algorithms;routing;existence theorem;satisfiability;connected graph;polynomial time algorithm;directed graph;upper and lower bounds;tight bounds;network flow;confluent flow	A flow is said to be confluent if at any node all the flow leaves along a single edge. Given a directed graph G with k sinks and non-negative demands on all the nodes of G, we consider the problem of determining a confluent flow that routes every node demand to some sink such that the maximum congestion at a sink is minimized. Confluent flows arise in a variety of application areas, most notably in networking; in fact, most flows in the Internet are confluent since Internet routing is destination based.We present near-tight approximation algorithms, hardness results, and existence theorems for confluent flows. The main result of this paper is a polynomial-time algorithm for determining a confluent flow with congestion at most 1 + ln(k) in G, if G admits a splittable flow with congestion at most 1. We complement this result in two directions. First, we present a graph G that admits a splittable flow with congestion at most 1, yet no confluent flow with congestion smaller than Hk, thus establishing tight upper and lower bounds to within an additive constant less than 1. Second, we show that it is NP-hard to approximate the congestion of an optimal confluent flow to within a factor of (lg k)/2, thus resolving the polynomial-time approximability to within a multiplicative constant. We also consider a demand maximization version of the problem. We show that if G admits a splittable flow of congestion at most 1, then a variant of the congestion minimization algorithm yields a confluent flow in G with congestion at most 1 that satisfies 1/3 fraction of total demand.We show that the gap between confluent flows and splittable flows is much smaller, if the underlying graph were k connected. In particular, we prove that k-connected graphs with k sinks admit confluent flows of congestion less than C + dmax, where C is the congestion of the best splittable flow, and dmax is the maximum demand of any node in G. The proof of this existence theorem is non-constructive and relies on topological techniques introduced in [16].	approximation algorithm;confluence (abstract rewriting);directed graph;entropy maximization;np-hardness;network congestion;polynomial;routing;tcp congestion control;time complexity;utility functions on indivisible goods	Jiangzhuo Chen;Robert D. Kleinberg;László Lovász;Rajmohan Rajaraman;Ravi Sundaram;Adrian Vetta	2004		10.1145/1007352.1007432	mathematical optimization;routing;combinatorics;discrete mathematics;flow network;directed graph;computer science;connectivity;mathematics;upper and lower bounds;approximation algorithm;satisfiability	Theory	22.696561692657163	18.174724777309955	38213
c8a3dfef4f0ab75e7f5caf47c5d75a358edb9960	sorting and selecting in rounds	selection problem;problema seleccion;general and miscellaneous mathematics computing and information science;mathematics;probability;combinatorics;algorithm complexity;sorting;computer graphics;combinatoria;complejidad algoritmo;combinatoire;processing 990220 computers computerized models computer programs 1987 1989;data processing;68p10;mathematical logic;median;parallel computation;upper bound;complexite algorithme;comparacion multiple;comparaison multiple;expander graph;parallel computer;algorithms;selecting;multiple comparison;lower bound;probleme selection	"""We present upper bounds for sorting and selecting the median in a fixed number of rounds. These bounds match the known lower bounds to within logarithmic factors. They also have the merit of being """"explicit modulo expansion""""; that is, probabilistic arguments are used only to obtain expanding graphs, and when explicit constructions for such graphs are found, explicit algorithms for sorting and selecting will follow. Using the best currently available explicit constructions for expanding graphs, we present the best currently known explicit algorithms for sorting and selecting in rounds. Key words, sorting, selecting, median, parallel computation AMS(MOS) subject classification. 68P10"""	algorithm;computation;modulo operation;parallel computing;sorting	Nicholas Pippenger	1987	SIAM J. Comput.	10.1137/0216066	mathematical optimization;combinatorics;discrete mathematics;data processing;computer science;mathematics;upper and lower bounds;algorithm;algebra	Theory	9.386095465626022	26.23015469911678	38233
e0ec87c9065973e0de2a25dd1865d969ceca752a	on the pipage rounding algorithm for submodular function maximization - a view from discrete convex analysis	matroid;discrete convexity;concave function;submodular function;convex analysis;submodular functions	We consider the problem of maximizing a nondecreasing submodular set function under a matroid constraint. Recently, Calinescu et al. (2007) proposed an elegant framework for the approximation of this problem, which is based on the pipage rounding technique by Ageev and Sviridenko (2004), and showed that this framework indeed yields a (1 − 1/e)-approximation algorithm for the class of submodular functions which are represented as the sum of weighted rank functions of matroids. This paper sheds a new light on this result from the viewpoint of discrete convex analysis by extending it to the class of submodular functions which are the sum of M\-concave functions. M\-concave functions are a class of discrete concave functions introduced by Murota and Shioura (1999), and contain the class of the sum of weighted rank functions as a proper subclass. Our result provides a better understanding for why the pipage rounding algorithm works for the sum of weighted rank functions. Based on the new observation, we further extend the approximation algorithm to the maximization of a nondecreasing submodular function over an integral polymatroid. This extension has an application in multi-unit combinatorial auctions.	approximation algorithm;concave function;convex analysis;expectation–maximization algorithm;matroid rank;polymatroid;rounding;submodular set function	Akiyoshi Shioura	2009	Discrete Math., Alg. and Appl.	10.1142/S1793830909000063	matroid;convex analysis;mathematical optimization;combinatorics;discrete mathematics;submodular set function;mathematics;concave function	Theory	22.3617101518972	15.514363099437372	38291
149ce5d9fc67c539aff47eab4a8a46ce8e50ade6	a one-way array algorithm for matroid scheduling	minimum spanning tree;greedy algorithm	The greedy algorithm is a standard paradigm for solving matroid optimization problems on sequential computers. This paper presents a greedy algorithm suitable for a fully-pipelined linear array of processors, a generalization of Huang's algorithm [Hua90] for minimum spanning trees. Application of the algorithm to uniprocessor scheduling with release times and deadlines is discussed in detail. A key feature of the algorithm is its use of matroid contraction.	central processing unit;computer;file spanning;greedy algorithm;huang's algorithm;mathematical optimization;matroid;minimum spanning tree;programming paradigm;scheduling (computing);uniprocessor system	Matthias F. Stallmann	1991		10.1145/113379.113411	edmonds' algorithm;euclidean minimum spanning tree;circuit rank;mathematical optimization;combinatorics;greedy algorithm;discrete mathematics;kruskal's algorithm;minimum degree spanning tree;spanning tree;prim's algorithm;computer science;expected linear time mst algorithm;minimum spanning tree;weighted matroid;matroid partitioning;reverse-delete algorithm;distributed minimum spanning tree;algorithm	Theory	16.717206397574166	13.533922213451605	38413
f5086731b1b6e189e6ab7b81ef9f1769365785bf	exact bounds on epsilon processes	03f05;03f35;epsilon substitution;termination proof	In this paper we show that the lengths of the approximating processes in epsilon substitution method are calculable by ordinal recursions in an optimal way.	(ε, δ)-definition of limit;computability;ordinal data;recursion;substitution method	Toshiyasu Arai	2011	Arch. Math. Log.	10.1007/s00153-010-0225-4	combinatorics;discrete mathematics;calculus;mathematics	Theory	2.3553211673564487	20.725375044369212	38504
de7e93a88ba250518249dc605fa96f4220f6d2d8	the complexity of approximating bounded-degree boolean #csp	maximum degree;counting constraint satisfaction problem;independent set;approximation algorithm;complexity;satisfiability;polynomial time;csp;constraint satisfaction problem;bipartite graph;epsrc	The degree of a CSP instance is the maximum number of times that a variable may appear in the scope of constraints. We consider the approximate counting problem for Boolean CSPs with bounded-degree instances, for constraint languages containing the two unary constant relations {0} and {1}. When the maximum degree is at least 25 we obtain a complete classification of the complexity of this problem. It is exactly solvable in polynomial-time if every relation in the constraint language is affine. It is equivalent to the problem of approximately counting independent sets in bipartite graphs if every relation can be expressed as conjunctions of {0}, {1} and binary implication. Otherwise, there is no FPRAS unless NP = RP. For lower degree bounds, additional cases arise in which the complexity is related to the complexity of approximately counting independent sets in hypergraphs.	approximation algorithm;counting problem (complexity);decision problem;np (complexity);polynomial-time approximation scheme;rp (complexity);time complexity;unary operation	Martin E. Dyer;Leslie Ann Goldberg;Markus Jalsenius;David Richerby	2012	Inf. Comput.	10.1016/j.ic.2011.12.007	time complexity;mathematical optimization;combinatorics;discrete mathematics;complexity;counting problem;independent set;bipartite graph;#sat;computer science;communicating sequential processes;constraint satisfaction dual problem;mathematics;constraint satisfaction problem;approximation algorithm;algorithm;2-satisfiability;satisfiability	Theory	22.606355294065057	23.939206287913162	38548
ba05f59e9c32d2b61f1482c87d7235f51334eccd	an optimization portfolio decision model of life cycle activity-based costing with carbon footprint constraints for hybrid green power strategies		Abstract A stable electricity supply is indispensable for both economic development and residential life. Social economic growth has caused a significant deficiency of conventional energy; hence, reducing the use of energy and developing new electricity sources are topics that have attracted wide attention from both academia and industries. In a green electric power system, reasonable costs and benefit controls, as well as carbon footprint computations, are considered to be the key barriers encountered. This study focuses on the total cost, feed-in tariff price, and carbon footprint of a power system, and proposes a 0–1 mixed integer linear programming (MILP) decision model for achieving an optimization portfolio of green electric power systems, using activity-based cost (ABC) and lifecycle assessment (LCA) approaches. The major contributions of this study are, as follows: (1) the integrated model can help green power suppliers to more accurately understand how to allocate resources and funding for energy-saving activities to each green electric power system through appropriate cost drivers; (2) the proposed model provides cost and benefit analysis information, which will assist management in planning clean energy production systems; and (3) the obtained portfolio shows that the maximum profits for green power planning contribute to the development of a national energy policy in Taiwan.	mathematical optimization	Chih-Hao Yang	2018	Computers & OR	10.1016/j.cor.2018.03.003	operations management;real-time computing;mathematics;energy policy;carbon footprint;cost–benefit analysis;total cost;activity-based costing;electric power system;cost driver;portfolio	HCI	3.9165296696781513	7.660711237309216	38676
0903a68d94a82e09b867fd3e249067c67ff4aac8	randomized selection with quintary partitions	computational complexity;smallest of;data structure	We show that several versions of Floyd and Rivest’s algorithm Select for finding the kth smallest of n elements require at most n + min{k, n− k}+ o(n) comparisons on average and with high probability. This rectifies the analysis of Floyd and Rivest, and extends it to the case of nondistinct elements. Our computational results confirm that Select may be the best algorithm in practice.	computation;randomized algorithm;with high probability	Krzysztof C. Kiwiel	2003	CoRR		combinatorics;discrete mathematics;data structure;computer science;mathematics;programming language;computational complexity theory;algorithm	Theory	13.159391414122199	22.88160608282069	38833
6393e181dcd42fd62c18c54b128db6a4ba3a9560	geometric tail of queue length of low-priority customers in a nonpreemptive priority map/ph/1 queue	decay rate;tail probability;90b22;markovian arrival process;priority queue;60k25;phase type distribution;68m20	We consider a MAP/PH/1 queue with two priority classes and nonpreemptive discipline, focusing on the asymptotic behavior of the tail probability of queue length of low-priority customers. A sufficient condition under which this tail probability decays asymptotically geometrically is derived. Numerical methods are presented to verify this sufficient condition and to compute the decay rate of the tail probability.	iterative method	Jungong Xue;Attahiru Sule Alfa	2011	Queueing Syst.	10.1007/s11134-011-9221-6	m/m/1 queue;mathematical optimization;m/d/c queue;pollaczek–khinchine formula;radioactive decay;real-time computing;m/m/c queue;bulk queue;m/d/1 queue;mathematics;phase-type distribution;m/g/k queue;m/g/1 queue;fork–join queue;d/m/1 queue;priority queue;burke's theorem;g/g/1 queue;markovian arrival process;statistics	Metrics	8.747718029529713	11.651114403550434	38869
280b697a7acd66f2835ef4220984fafd79b8e96e	tracking join and self-join sizes in limited storage	sample size;random sampling;query optimization;tug of war;signature scheme;exact computation;lower bound	Query optimizers rely on fast high quality estimates of re sult sizes in order to select between various join plans Self join sizes of relations provide bounds on the join size of any pairs of such relations It also indicates the degree of skew in the data and has been advocated for several estimation procedures Exact computation of the self join size requires storage proportional to the number of distinct attribute val ues which may be prohibitively large In this paper we study algorithms for tracking approximate self join sizes in limited storage in the presence of insertions and deletions to the relations Such algorithms detect changes in the de gree of skew without an expensive recomputation from the base data We show that an algorithm based on a tug of war approach provides a more accurate estimation than one based on a sample and count approach which is in turn more accurate than a sampling only approach Next we study algorithms for tracking approximate join sizes in limited storage the goal is to maintain a small signature of each relation such that join sizes can be accu rately estimated between any pairs of relations We show that taking random samples for join signatures can lead to inaccurate estimation unless the sample size is quite large moreover by a lower bound we show no other signature scheme can signi cantly improve upon sampling without further assumptions These negative results are shown to hold even in the presence of sanity bounds On the other hand we present a join signature scheme based on tug of war signatures that provides guarantees on join size estima tion as a function of the self join sizes of the joining rela tions this scheme can signi cantly improve upon the sam pling scheme	accu (organisation);antivirus software;approximation algorithm;computation;digital signature;display resolution;join (sql);sampling (signal processing);type signature;ues (cipher)	Noga Alon;Phillip B. Gibbons;Yossi Matias;Mario Szegedy	1999		10.1145/303976.303978	sample size determination;tug of war;sampling;query optimization;combinatorics;computer science;theoretical computer science;database;mathematics;distributed computing;upper and lower bounds	DB	14.22035647179765	22.68308455700107	38939
d0e46819196a79a132dd3e5e440875ba2bda0c57	optimal power management for electric tugboats with unknown load demand	hybrid electric vehicles power management optimization marine powertrain systems;integer programming boats energy management systems hybrid electric vehicles;industry consulted harbor tugboat model electric tugboats optimal power management scheme energy management land based hybrid electric vehicles hev power supply battery life cost function power load demand tracking engine fuel consumption battery state of charge mixed integer programming optimal power planning starting time stopping time prediction scheme optimization scheme;batteries engines fuels cost function switches power demand	This paper, inspired by the research on energy management for land-based hybrid electric vehicles (HEVs), presents an optimal power management scheme for electric tugboats that optimally splits the power supply from engines and batteries in response to the load demand, while minimizing the engine fuel consumption and maintaining the battery life. For this purpose, an optimization problem is formulated, in which the cost function consists of power load demand tracking, engine fuel consumption and change in battery state of charge. Utilizing the mixed-integer programming, the optimal power planning for the engines and batteries is determined. The proposed optimal algorithm can control the operation, i.e. starting time and stopping time, for several engines, which is a key difference from several other optimal algorithms developed for land-based HEVs. Since the load demand is unknown, a novel prediction scheme is introduced to anticipate the load demand, allowing the implementation of optimization scheme. Numerical illustration is presented on an industry-consulted harbor tugboat model to show the effectiveness of the proposed schemes.	algorithm;integer programming;linear programming;loss function;mathematical optimization;numerical method;optimization problem;power management;power supply;state of charge;tugboat	Thanh Long Vu;Jaspreet Singh Dhupia;Aaron Alexander Ayu;Louis Kennedy;Alf Kare Adnanes	2014	2014 American Control Conference	10.1109/ACC.2014.6859004	control engineering;engineering;automotive engineering;hybrid power	EDA	4.65704268764952	5.08367861707395	39054
9fea88b32495a7ea31ac08fe789b5192fb8c220f	relating monotone formula size and monotone depth of boolean functions	monotonicity formula;boolean function		monotone	Ingo Wegener	1983	Inf. Process. Lett.	10.1016/0020-0190(83)90011-X	bernstein's theorem on monotone functions;true quantified boolean formula;combinatorics;mathematical analysis;discrete mathematics;strongly monotone;computer science;maximum satisfiability problem;mathematics;boolean function;complete boolean algebra;boolean satisfiability problem;algorithm;two-element boolean algebra;parity function	DB	7.400831320363909	21.754689681155035	39091
7089d0d4656d3a3485ccb502d35f26f263863eb8	mixed real-integer linear quantifier elimination	quantifier elimination	Consider t,hc elementary t.heory T of the real numl~ers in the language L having 0,l as constants, addition and subtract,ion and integer part, as operations; and cqualit~-: order and congruences module natural number constants as relations. We show that. T admits au effective quamifier elimination procedure and is decidable. Moreover this procedure provides sample answers for existentially quantified variables. The procedure comprises as special cases linear climinat:ion for the reals and for Prcsburger arithmet~ic. ~VC provide closely matching upper aud lower bounds for the complesity of the quantifier elimination and decision problem for T. .~pplicat.ions include a cliaracterixation of T-definable subs& of the real line, and the modeling of parametric mixed int,eger linear optimization, of continuous phenomena with periodici+; and the simulatmn and analysis of hybrid control systems. IVe also consitlcr the elementary theory of reals in varations of this langtmge in view of quantifier elimination and decidability and provide positive and ncgat,ive results for various variaIlt lauguages.	control system;decision problem;existential quantification;floor and ceiling functions;linear programming;mathematical optimization;quantifier (logic)	Volker Weispfenning	1999		10.1145/309831.309888	quantifier elimination;mathematics;algebra	Logic	-2.345876323190283	13.525575961485806	39109
23fcca3706b18e7e5dc226a58581f1a4075650ab	online checkpointing with improved worst-case guarantees	bounded memory;breakpoints;empirical evaluation	In the online checkpointing problem, the task is to continuously maintain a set of k checkpoints that allow to rewind an ongoing computation faster than by a full restart. The only operation allowed is to replace an old checkpoint by the current state. Our aim are checkpoint placement strategies that minimize rewinding cost, i.e., such that at all times T when requested to rewind to some time t ≤ T the number of computation steps that need to be redone to get to t from a checkpoint before t is as small as possible. In particular, we want that the closest checkpoint earlier than t is not further away from t than qk times the ideal distance T/(k + 1), where qk is a small constant. Improving over earlier work showing 1 + 1/k ≤ qk ≤ 2, we show that qk can be chosen asymptotically less than 2. We present algorithms with asymptotic discrepancy qk ≤ 1.59 + o(1) valid for all k and qk ≤ ln(4) + o(1) ≤ 1.39 + o(1) valid for k being a power of two. Experiments indicate the uniform bound pk ≤ 1.7 for all k. For small k, we show how to use a linear programming approach to compute good checkpointing algorithms. This gives discrepancies of less than 1.55 for all k < 60. We prove the first lower bound that is asymptotically more than one, namely qk ≥ 1.30− o(1). We also show that optimal algorithms (yielding the infimum discrepancy) exist for all k.	algorithm;application checkpointing;computation;discrepancy function;experiment;linear programming;media controls;power of two;transaction processing system	Karl Bringmann;Benjamin Doerr;Adrian Neumann;Jakub Sliacan	2013	INFORMS Journal on Computing	10.1287/ijoc.2014.0639	mathematical optimization;real-time computing;computer science;theoretical computer science;mathematics;breakpoint;algorithm	Theory	16.101950167757092	15.768362853045014	39163
ff096452093554d45bc27f63a3b05fc5fef52a33	"""technical note - a """"hard"""" assignment problem"""	assignment problem	We construct numerical examples that force Hungarian-method algorithms for the assignment problem to their worst-case time bounds. These bounds are thereby clarified.	assignment problem	Robert E. Machol;Michael Wien	1976	Operations Research	10.1287/opre.24.1.190	mathematical optimization;combinatorics;linear bottleneck assignment problem;generalized assignment problem;mathematics;assignment problem;weapon target assignment problem;mathematical economics;quadratic assignment problem	Crypto	23.41373659489392	12.003935859302937	39165
2a997e1872486275d3a8761e1776f65f10570b35	a linear time string matching algorithm on average with efficient text storage			string searching algorithm;time complexity	Thomas Berry;Somasundaram Ravindran	2001			rabin–karp algorithm;time complexity;approximate string matching;discrete mathematics;string searching algorithm;commentz-walter algorithm;boyer–moore string search algorithm;theoretical computer science;computer science;string metric	Theory	13.458857528116855	27.356365193863216	39186
fae2213f573f05e9e73532d838b8427deb632aa6	analyse des suites aléatoires engendrées par des automates cellulaires et applications à la cryptographie		On s'intéresse aux interactions entre la cryptologie et les automates cellulaires. Il a ´ eté montré récemment qu'il n'existe pas de r` eglé elémentaire d'automate cellulaire non-linéaire robustè a la corrélation. Ce résultat limite fortement l'usage d'automates cellulaires pour la construction de suites pseudo-aléatoires servant de clés utilisables en cryptographiè a clé secrète. De plus, pour de tels mécanismes de génération de suites pseudo-aléatoires, Meier et Staffelbach ont proposé une technique de cryptanalyse efficace. Cependant, des pistes subsistent pour construire des automates cellulaires sus-ceptibles d'engendrer de bonnes suites pseudo-aléatoires, que nousévoqueronsà la fin de cet article. Abstract : This paper considers interactions between cellular automata and cryptology. It is known that non-linear elementary rule which is correlation-immune don't exist. This results limits the use of cellular automata as pseudo-random generators suitable for cryptographic applications. In addition, for this kind of pseudo-random generators, a successful cryptanalysis was proposed by Meier and Staffelbach. However , other ways to design cellular automata capable to generate good pseudo-random sequences remain and will be discussed in the end of this article. 1 Les automates cellulaires Les automates cellulaires (ou AC) ontété inventés par Ulam et von Neumann [11]. Il s'agità la fois d'un modèle de système dynamique discret et d'un modèle de calcul. Un automate cellulaire est composé d'un ensemble bi-infini de cellules identiques qui peuvent prendrè a un instant donné unétatà valeurs dans un ensemble fini. Le temps estégalement discret et l'´ etat d'une cellule au temps t est fonction de l'´ etat au temps t − 1 d'un nombre fini de cellules appelé son «voisinage». ` A chaque nouvelle unité de temps, les mêmes r` egles sont appliquéesà l'ensemble des cellules, produisant une nouvelle «configuration» de cellules dépendantentì erement de la configuration précédente. Nous nous restreindrons icì a des automates cellulaires sur un anneau de N cellules et dont l'ensemble desétats est binaire. Définition 1 Un automate cellulaire est un ensemble fini de cellules identiques indicées par Z N. Chaque cellule est une machine d'´ etats finis C = x t+1 i = f (x t i−1 , x t i , x t i+1) La fig. 1 illustre une transition d'un automate cellulaire sur un anneau de 8 cellules. Chacune des cellules pouvant prendre deuxétats, il existe 2 3 = 8 configurations possibles d'un tel voisinage. Pour que l'automate cellulaire fonctionne, il faut définir quel doitêtre l'´ etat, ` a l'instant suivant, …	automata theory;cellular automaton;cryptanalysis;cryptography;interaction;linear algebra;nonlinear system;nouvelle ai;pseudorandomness;quel;sensitivity index;xfig	Bruno Martin	2008	CoRR		theoretical computer science;computer science;pseudorandom generator;random sequence;cryptography;cellular automaton;cryptanalysis	Crypto	1.832355443368635	27.102360490919235	39193
551d82c769f1b97715904fc85424c820a5a88589	some undecidable problems on approximability of np optimization problems	approximate algorithm;optimization problem;computational complexity;polynomial time	In this paper some undecidable problems on approximability of NP optimization problems are investigated. In particular, the following problems are all undecidable: (1) Given an NP optimization problem, is it approximable in polynomial time? (2) For any polynomial-time computable functionr(n), given a polynomial time approximable NP optimization problem, has it a polynomial-time approximation algorithm with approximation performance ratior(n) (r(n)-approximable)? (3) For any polynomial-time computable functionsr(n), r'(n), wherer'(n) <r(n) a.e., given anr(n)-approximable NP optimization problem, is itr'(n)-approximable?	approximation algorithm;computable function;mathematical optimization;optimization problem;polynomial;time complexity;undecidable problem	Xiong Huang	1996	Journal of Computer Science and Technology	10.1007/BF02943528	time complexity;optimization problem;mathematical optimization;computer science;decision problem;computational complexity theory;l-reduction;algorithm	Theory	16.363972578429472	19.459194565133764	39216
d066035a658b3e65654e287b6136d7a107ddea8a	computation engineering - applied automata theory and logic	computation engineering;applied automata theory;automata theory	computation engineering;applied automata theory;automata theory	automata theory;computation	Ganesh Gopalakrishnan	2006		10.1007/0-387-32520-4		Logic	-3.0629079662414904	22.885983212728956	39219
08059824b84774273cabe41dc8f75232753cc292	theoretical analysis of workload imbalance minimization problem on identical parallel machines		This paper considers the problem of assigning N non-preemptive jobs to M identical parallel machines or processors as equally as possible. This problem is known as workload imbalance minimization problem. First, we establish that this problem can be formulated as the difference between the maximum and minimum workloads. In other words, it is defined as the minimization of the difference between the workload of the bottleneck machine and the workload of the fastest machine.		Yassine Ouazene;Farouk Yalaoui;Alice Yalaoui;Hicham Chehade	2016		10.1007/978-3-662-49390-8_29	computer science;theoretical computer science;machine learning;distributed computing	HPC	14.801440659238798	10.72260359575296	39246
c883946166149e60e393a325be343660c5a43d18	computational complexity of certain problems related to carefully synchronizing words for partial automata and directing words for nondeterministic automata	automata;computational complexity;synchronization;directing words	We show that the problem of checking careful synchronizability of partial finite automata is PSPACE-complete. Also the problems of checking D 1-, D 2-, and D 3-directability of nondeterministic finite automata are PSPACE-complete; moreover, the restrictions of all these problems to automata with two input letters remain PSPACE-complete.	analysis of algorithms;automata theory;computational complexity theory;finite-state machine;nondeterministic finite automaton;pspace;pspace-complete	Pavel Martyugin	2013	Theory of Computing Systems	10.1007/s00224-013-9516-6	synchronization;nondeterministic finite automaton with ε-moves;discrete mathematics;nondeterministic finite automaton;continuous spatial automaton;quantum finite automata;computer science;nested word;theoretical computer science;deterministic finite automaton;automata theory;ω-automaton;mathematics;automaton;computational complexity theory;mobile automaton;algorithm	Theory	-0.8372784263019449	22.344479343039087	39260
a75e50b42d3ae946620d4f9429d617458b9aceef	new bounds for parallel prefix circuits	parallel prefix circuit;structural information;small constant factor;minimum depth;new bound;lower bound;upper and lower bounds	In this paper, new upper and lower bounds are obtained for the number of gates in parallel prefix circuits with minimum depth when the number of inputs is a power of two. In addition, structural information concerning these circuits is described. Parallel prefix circuits with bounds imposed on the fan-out of the gates are also considered. In both cases, the upper and lower bounds obtained differ by small constant factors.	fan-out;power of two	Faith Ellen	1983		10.1145/800061.808738	combinatorics;discrete mathematics;theoretical computer science;mathematics	Theory	8.988700445602236	23.375570419911103	39281
1b4f1ce64f7040f53dacaa9a0fd2757a11af64ba	efficient construction of probabilistic tree embeddings		In this paper we describe an algorithm that embeds a graph metric (V, dG) on an undirected weighted graphG = (V,E) into a distribution of tree metrics (T,DT ) such that for every pair u, v ∈ V , dG(u, v) ≤ dT (u, v) and ET [dT (u, v)] ≤ O(log n)·dG(u, v). For a graph with n vertices andm edges, our algorithm runs in O(m log n) time with high probability. The key component to achieve it is a new approximate single-source shortest-path algorithm, which implements the priority queue with a new data structure named “leveled buckets”. The algorithm has three properties: it only requires linear time in terms of the number of edges in the input graph; the computed distances preserve triangle inequality; most importantly, when computing the shortest-paths to the k-nearest vertices from the source, it only requires to visit these vertices and their edge lists. These properties are essential to guarantee the correctness and the stated work bound. With this shortest-path algorithm, we discuss how to generate an intermediate structure, the approximate dominance sequences of the input graph, in O(m log n) time, and further proposed a simple yet efficient algorithm to converted this sequence to a tree embedding (FRT-embedding) in O(n log n) time, both with high probability. Combining the three subroutines gives the stated work bound of the algorithm. Then we show that this efficient construction can facilitate a number of applications. We proved that FRT trees (the generated tree embedding) are Ramsey partitions with asymptotically tight bound, so the construction of a series of distance oracles can be accelerated. We implemented a simple distance oracle based on FRT trees, and show that this simple approach provides good distance approximation on real-world graphs. ar X iv :1 60 5. 04 65 1v 3 [ cs .D S] 1 8 Fe b 20 17	approximation algorithm;correctness (computer science);data structure;distance (graph theory);distance oracle;emoticon;graph (discrete mathematics);priority queue;shortest path problem;social inequality;subroutine;time complexity;vertex (geometry);with high probability	Guy E. Blelloch;Yan Gu;Yihan Sun	2017		10.4230/LIPIcs.ICALP.2017.26	mathematical optimization;combinatorics;discrete mathematics;mathematics;bound graph;algorithm	Theory	20.684699440745554	23.22156356214596	39309
533308bfad78f481179da3a9e0965713d19878b8	combining dynamic programming with filtering to solve a four-stage two-dimensional guillotine-cut bounded knapsack problem	dynamic programming;lagrangian filtering;cutting and packing;reduced cost fixing	The two-dimensional knapsack problem consists in packing a set of small rectangular items into a given large rectangle while maximizing the total reward associated with selected items. We restrict our attention to packings that emanate from a k-stage guillotine-cut process. We introduce a generic model where a knapsack solution is represented by a flow in a directed acyclic hypergraph. This hypergraph model derives from a forward labeling dynamic programming recursion that enumerates all non-dominated feasible cutting patterns. To reduce the hypergraph size, we make use of further dominance rules and a filtering procedure based on Lagrangian reduced costs fixing of hyperarcs. Our hypergraph model is (incrementally) extended to account for explicit bounds on the number of copies of each item. Our exact forward labeling algorithm is numerically compared to solving the max-cost flow model in the base hyper-graph with side constraints to model production bounds. Benchmarks are reported on instances from the literature and on datasets derived from a real-world application.	dynamic programming;knapsack problem	François Clautiaux;Ruslan Sadykov;François Vanderbeck;Quentin Viaud	2018	Discrete Optimization	10.1016/j.disopt.2018.02.003	mathematical optimization;combinatorics;discrete mathematics;mathematics;knapsack problem	Theory	21.682085942788078	10.009026915220987	39354
390de98c76dd34783b588ccfb90affe20fba370d	regular expression searching in sublinear time			regular expression;time complexity	Steven M. Kearns	2013	CoRR		discrete mathematics;regular expression;sublinear function;mathematics	NLP	13.450058730900702	27.236771342470412	39360
b19b147249bf1663b8e62bdde76c319a9f7a04a5	modeling and solving several classes of arc routing problems as traveling salesman problems	traveling salesman problem;graph theory;teoria grafo;routing;travelling salesman problem;transformacion;probleme np dur;problema np duro;theorie graphe;problema viajante comercio;combinatorial problem;np hard problem;probleme combinatoire;problema combinatorio;probleme commis voyageur;scheduling;shipments;encaminamiento;low density;transformation;trucks;acheminement	Several important types of arc routing problems can be transformed into traveling salesman problems. Computational results indicate that the approach works well on low density graphs containing few edges. Instances involving up to 220 vertices, 660 arcs, and a few edges were solved to optimality. It constitutes the only known approach for solving Mixed Rural Postman Problems and Stacker Crane Problems to optimality.	arc routing	Gilbert Laporte	1997	Computers & OR	10.1016/S0305-0548(97)00013-0	2-opt;mathematical optimization;combinatorics;computer science;graph theory;mathematics;travelling salesman problem;algorithm	Theory	21.47429772823501	12.451141420397153	39467
97e5d9819c5e33bb78c162af53ea6c0bcbe446ed	proof of a phase transition in probabilistic cellular automata		Cellular automata are a model of parallel computing. It is well known that simple deterministic cellular automata may exhibit complex behaviors such as Turing universality [3,13] but only few results are known about complex behaviors of probabilistic cellular automata.	stochastic cellular automaton	Damien Regnault	2013		10.1007/978-3-642-38771-5_38	stochastic cellular automaton;continuous spatial automaton;quantum finite automata;quantum cellular automaton;mobile automaton	Logic	1.2070848364724507	23.94044743426601	39478
cf37d2c2d84e2735ba79c6c5a816a320bde511c1	correspondence of 2-d projections by bipartite matching	graph theory;vision ordenador;graphe biparti;teoria grafo;vision estereoscopica;bipartite matching;vision stereoscopique;theorie graphe;computer vision;algorithme;algorithm;programacion lineal;linear programming;tâche appariement;tarea apareamiento;programmation lineaire;grafico bipartido;vision ordinateur;stereopsis;bipartite graph;matching task;algoritmo	A method is presented to determine the correspondence between 2-D projections ofa 3-D scene. The problem is formulated as a maximum cardinality with minimum weight matching of a bipartite graph and is solved by a network flow algorithm.	algorithm;matching (graph theory);maximum flow problem;minimum weight;minimum-weight triangulation	Paul M. Griffin	1989	Pattern Recognition Letters	10.1016/0167-8655(89)90065-2	maximum flow problem;computer vision;complete bipartite graph;combinatorics;discrete mathematics;bipartite graph;computer science;linear programming;graph theory;3-dimensional matching;hopcroft–karp algorithm;mathematics;blossom algorithm;assignment problem;algorithm;matching	Vision	22.649092854573492	28.07010729652841	39496
5cc37788a7167c10529a8fce5c3d75192a35d71b	a parsing method for context-free languages using bottom-up lookahead computation	bottom up;context free language;context free grammars;gramatica cf;lenguaje cf;grammaire cf;parsing;context free grammar;analizador sintaxico;parser;analyseur syntaxique;langage cf	A new parsing algorithm of context-free languages using bottom-up computation of lookahead information is presented. Earley's algorithm uses a great number of items during enumeration to recognize a context-free language. If items with lookahead fields are used, the number of items can be reduced, but item spacing is considerably increased. The method presented here may reduce the number of items during enumeration without using lookahead fields of items. The computation of lookahead information takes place in a bottom-up manner. It is not necessary to compute lookahead information until it is required during enumeration.	algorithm;bottom-up parsing;computation;context-free language;earley parser;top-down and bottom-up design	Yoshimichi Watanabe;Takehiro Tokuda	1996	Systems and Computers in Japan	10.1002/scj.4690271002	natural language processing;parsing expression grammar;computer science;theoretical computer science;parsing;context-free grammar;programming language	NLP	-0.4081129769465065	25.67382725030775	39521
e15eecdeb34e6a4265a3b7588cdea6f1ad5426f5	processor-efficient exponentiation in finite fields	algoritmo paralelo;design of algorithms;parallel algorithm;funcion exponencial;multiprocessor;fonction exponentielle;sistema informatico;exponential function;computer system;algorithme parallele;finite field;criptografia;cryptography;finite field arithmetic;champ fini;cryptographie;systeme informatique;operating cost;cout exploitation;multiplicacion;multiprocesador;multiplication;costo explotacion;parallel algorithms;multiprocesseur	Abstract The processor-efficiency of parallel algorithms for exponentiation in a finite field extension is studied, assuming that a normal basis over the ground field is given.		Joachim von zur Gathen	1992	Inf. Process. Lett.	10.1016/0020-0190(92)90259-X	exponentiation by squaring;discrete mathematics;exponential field;computer science;mathematics;parallel algorithm;algorithm;modular exponentiation	DB	14.170695220939063	31.520578352550466	39537
647201168081a9dfe91b2db77d13c01c8adcd00f	improved inapproximability results for the shortest superstring and related problems	explicit lower bounds;bounded metrics;shortest superstring problem;asymmetric traveling salesperson problem;max atsp problem;inapproximability;maximum compression problem	We develop a new method for proving explicit approximation lower bounds for the Shortest Superstring problem, the Maximum Compression problem, the Maximum Asymmetric TSP problem, the (1,2)–ATSP problem and the (1,2)–TSP problem improving on the best known approximation lower bounds for those problems.	hardness of approximation;travelling salesman problem	Marek Karpinski;Richard Schmied	2013			mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	22.274873089103327	19.59024405541476	39720
a364a27e4cacfeda4fa0a89b6633da529f6a876a	time advancement in distributed event simulation	modelizacion;distributed system;complexite;systeme reparti;mise a jour;multiprocessor;sistema informatico;heuristic method;simulation;complejidad;simulacion;metodo heuristico;transmission message;computer system;complexity;message transmission;algorithme;modelisation;algorithm;sistema repartido;horloge;systeme informatique;puesta al dia;methode heuristique;multiprocesador;modeling;clock;reloj;updating;transmision mensaje;algoritmo;multiprocesseur	The problem of updating the simulation clock in distributed discrete event simulation is investigated. Three objectives for efficiently updating the simulation clock in processes modeled by the strongly connected components of a process graph are identified. An optimal solution is proposed for one of the objectives. The optimization problem for another objective is shown to be NP-complete. Consequently, a computationally efficient heuristic solution is proposed	simulation	Hon Fung Li;K. Venkatesh;Thiruvengadam Radhakrishnan	1990	J. Parallel Distrib. Comput.	10.1016/0743-7315(90)90108-2	clock;complexity;multiprocessing;simulation;systems modeling;computer science;artificial intelligence;algorithm	HPC	2.4425940317848376	28.134641075178404	39726
6ced359ad7d8867397e2f52c8ee25beb8119adab	approximating the k-traveling repairman problem with repairtimes	optimal solution;approximate algorithm;travel time;approximation algorithms;combinatorial optimization	Given an undirected graph G = (V,E) and a source vertex s ∈ V , the k-traveling repairman (KTR) problem, also known as the minimum latency problem, asks for k tours, each starting at s and together covering all the vertices (customers) such that the sum of the latencies experienced by the customers is minimum. Latency of a customer p is defined to be the distance traveled (time elapsed) before visiting p for the first time. Previous literature on the KTR problem has considered the version of the problem in which the repairtime of a customer is assumed to be zero for latency calculations. We consider a generalization of the problem in which each customer has an associated repairtime. For a fixed k, we present a (β + 2)-approximation algorithm for this problem, where β is the best achievable approximation ratio for the KTR problem with zero repairtimes (currently β = 6). For arbitrary k, we obtain a ( 2β + 2 )-approximation ratio. When the repairtimes of all the customers are the same, we present an approximation algorithm with better ratio.2 We also introduce the bounded-latency problem, a complementary version of the KTR problem, in which we are given a latency bound L and are asked to find the minimum number of repairmen required to service all the customers such that the latency of no customer is more than L. For this problem, we present a simple bicriteria approximation algorithm that finds a solution with at most 2/ρ times the number of repairmen required by an optimal solution, with the latency of no customer exceeding (1 + ρ)L, ρ > 0. © 2006 Published by Elsevier B.V.	approximation algorithm;black box;graph (discrete mathematics);interrupt latency;travelling salesman problem	Raja Jothi;Balaji Raghavachari	2007	J. Discrete Algorithms	10.1016/j.jda.2006.03.023	mathematical optimization;combinatorics;combinatorial optimization;computer science;mathematics;approximation algorithm;algorithm	Theory	21.30557482285984	15.517653565216742	39802
6abfa8af847fcae9c691b4c053364bbb395082ff	shiftable intervals	scheduling;optimization problems on graphs;interval graphs	Let a set of n fixed length intervals and a set of n (larger) windows, in one-to-one correspondence with the intervals, be given, and assume that each interval can be placed in any position within its window. If the position of each interval has been fixed, the intersection graph of such set of intervals is an interval graph. By varying the position of each interval in all possible ways, we get a family of interval graphs. In the paper we define some optimization problems related to the clique, stability, chromatic, clique cover numbers and cardinality of the minimum dominating set of the interval graphs in the family, mainly focussing on complexity aspects, bounds and solution algorithms. Some problems are proved to be NP-hard, others are solved in polynomial time on some particular classes of instances, which are characterized in the paper. Many practical applications can be reduced to these kind of problems, suggesting the use of Shiftable Intervals as a new interesting modeling framework.	algorithm;clique (graph theory);clique cover;computational complexity theory;dominating set;financial times;independent set (graph theory);interval arithmetic;job stream;mathematical optimization;microsoft windows;np-hardness;one-to-one (data model);optimization problem;scheduling (computing);software release life cycle;time complexity	Federico Malucelli;Sara Nicoloso	2000	Electronic Notes in Discrete Mathematics	10.1016/S1571-0653(05)80167-2		Theory	24.182167891534586	21.906081870219133	39830
164320e65f8f4f46d23b4fc977c0ac4985d0b123	on the equivalence problem for e-pattern languages	pattern generation;pattern language;normal form	On the one hand, the inclusion problem for nonerasing and erasing pattern languages is undecidable (see JSSY93]). On the other hand, the language equivalence problem for nonerasing pattern languages is trivially decidable (see Ang80a]) but the question of whether the same holds for erasing pattern languages is still open. It has been conjectured by Jiang et al. JSSY93] that the language equivalence problem for erasing pattern languages is also decidable. In this paper, we introduce a new normal form for patterns and show, using the normal form, that the language equivalence problem for erasing pattern languages is decidable in many special cases. We conjecture that our normal form procedure decides the problem in the general case, too. If the conjecture holds true, then the normal form is the shortest pattern generating a given erasing pattern language.	beta normal form;pattern language (formal languages);turing completeness;undecidable problem	Enno Ohlebusch;Esko Ukkonen	1997	Theor. Comput. Sci.	10.1016/S0304-3975(96)00289-7	combinatorics;discrete mathematics;computer science;pure mathematics;pattern language;mathematics;algorithm;algebra	Theory	-3.1569040581607375	17.41006608755003	39852
f1f676de016f2106835bbd46d9c1a19b8887ce4e	cascaded atn grammars	language understanding	A generalization of the notion of ATN grammar, called a cascaded ATN (CATN), is presented. CATN's permit a decomposition of complex language understanding behavior into a sequence of cooperating ATN's with separate domains of responsibility, where each stage (called an ATN transducer) takes its input from the output of the previous stage. The paper includes an extensive discussion of the principle of factoring conceptual factoring reduces the number of places that a given fact needs to be represented in a grammar, and hypothesis factoring reduces the number of distinct hypotheses that have to be considered during parsing.	cascaded integrator–comb filter;cylinder-head-sector;decision tree;fly-by-wire;integer factorization;natural language understanding;parsing;phrase structure rules;recursion;transducer;transition path sampling;whole earth 'lectronic link	William A. Woods	1980	American Journal of Computational Linguistics		natural language processing;augmented transition network;computer science;artificial intelligence;algorithm	NLP	-2.449840128799023	14.678378833038808	39887
fa33b1e7bfd29b2459836e2dcc5cdd3a6061d2b0	an application of discrete mathematics in the design of an open pit mine	dynamic programming;graph theory;programacion dinamica;teoria grafo;probleme extremum;arbre maximal;discrete mathematics;theorie graphe;arbol maximo;directed graph;grafico orientado;vertex graph;graphe oriente;extremum problem;programmation dynamique;spanning tree;cuspide grafico;problema extremo;sommet graphe	The determination of the “optimum pit limit” of a mine is considered to be a fundamental problem in mine planning as it provides information which is essential in the evaluation of the economic potential of a mineral deposit, and in the formulation of long-, intermediate-, and short-range mine plans. A number of mathematical techniques have been proposed to solve this problem, some of the more elaborate ones posing considerable computational problems. In this paper we discuss the development and implementation of a graph-theoretic technique originally proposed by Lerchs and Grossman. Our implementation strategy involves the use of a dynamic programming technique to “bound” the optimum.	computation;computational problem;dave grossman (game developer);discrete mathematics;dynamic programming;graph theory	Lou Caccetta;L. M. Giannini	1988	Discrete Applied Mathematics	10.1016/0166-218X(88)90030-3	mathematical optimization;combinatorics;directed graph;spanning tree;graph theory;dynamic programming;vertex;mathematics;algorithm	Robotics	20.358100855912944	28.65947313148299	39944
b6c63d86af95c1ac0aea2f4bd63bca80c71b13e9	scheduling mapreduce jobs under multi-round precedences		We consider non-preemptive scheduling of MapReduce jobs with multiple tasks in the practical scenario where each job requires several map-reduce rounds. We seek to minimize the average weighted completion time and consider scheduling on identical and unrelated parallel processors. For identical processors, we present LP-based O(1)approximation algorithms. For unrelated processors, the approximation ratio naturally depends on the maximum number of rounds of any job. Since the number of rounds per job in typical MapReduce algorithms is a small constant, our scheduling algorithms achieve a small approximation ratio in practice. For the single-round case, we substantially improve on previously best known approximation guarantees for both identical and unrelated processors. Moreover, we conduct an experimental analysis and compare the performance of our algorithms against a fast heuristic and a lower bound on the optimal solution, thus demonstrating their promising practical performance.	approximation algorithm;central processing unit;heuristic;job stream;mapreduce;parallel computing;scheduling (computing)	Dimitris Fotakis;Ioannis Milis;Orestis Papadigenopoulos;Vasilis Vassalos;Georgios Zois	2016		10.1007/978-3-319-43659-3_16	parallel computing;real-time computing;computer science;distributed computing	Theory	15.486410252037022	11.257578562284161	39982
ba1fff69432dba5a48c92ce426ded0b1d42cabf1	design issues in atm and optical networks	graph theory;optical network;reseau communication;teoria grafo;reseau optique;longitud onda;system with n degrees of freedom;concepcion optimal;layout problem;conception optimale;probleme agencement;duality;wavelength;packet switching;conmutacion por paquete;theorie graphe;transmision asincronica;dualite;telecomunicacion optica;telecommunication optique;systeme n degres liberte;optimal design;optical telecommunication;problema disposicion;asynchronous transmission;dualidad;transmission asynchrone;longueur onde;sistema n grados libertad;red de comunicacion;optical fiber communication;communication network;commutation paquet;communication fibre optique	In this paper, graph-theoretic models are described that are of use in studies of designs for ATM networks and for optical networks. Although these models share a basic framework, the problems studied, and the parameters under concern, are not identical. The differences stem from the constraints imposed by the two different technologies, and their perspective applications. For ATM networks, a short summary of the virtual path layout problem is given, and some results are discussed. A detailed description is given for the use of duality and high dimensional geometry in deriving and analyzing optimal designs for chain and ring networks. Regarding optical networks the wavelength assignment problem and the ring partition problem are described, together with few recent results.	atm turbo	Shmuel Zaks	2001	Computers and Artificial Intelligence		duality;telecommunications;computer science;graph theory;optimal design;asynchronous communication;wavelength;mathematics;algorithm;packet switching;telecommunications network	AI	21.136498660583676	29.34267412735169	40024
a15943d28ab13305a843e7f15f30bc2953595a52	on the cell probe complexity of membership and perfect hashing	lower bounds;upper bound;computational complexity;read once branching programs;integer multiplication;data structure;lower bound	We study two fundamental static data structure problems, membership and perfect hashing, in Yao's cell probe model. The first space and bit probe optimal worst case upper bound is given for the membership problem. We also give a new efficient membership scheme where the query algorithm makes just one adaptive choice, and probes a total of three words. A lower bound shows that two word probes generally do not suffice. For minimal perfect hashing we show a tight bit probe lower bound, and give a simple scheme achieving this performance, making just one adaptive choice. Linear range perfect hashing is shown to be implementable with the same number of bit probes, of which just  one is adaptive. In contrast, we establish that for sufficiently sparse sets, non-adaptive perfect hashing needs exponentially more bit probes. This is the first such separation of adaptivity and non-adaptivity.	algorithm;best, worst and average case;data structure;perfect hash function;sparse matrix;yao graph	Rasmus Pagh	2001		10.1145/380752.380836	mathematical optimization;hash table;combinatorics;discrete mathematics;dynamic perfect hashing;data structure;computer science;theoretical computer science;mathematics;upper and lower bounds;programming language;2-choice hashing;algorithm	Theory	11.9034123353434	25.009181351210746	40107
fcc464e10afa629391c29353184de2a7cac59552	on injective enumerability of recursively enumerable classes of cofinite sets		To date the problem of finding a general characterization of injective enumerability of recursively enumerable (r.e,) classes of r.e. sets has proved intractable. This paper investigates the problem for r.e. classes of cofinite sets. We state a suitable criterion for r.e. classes ~ such that there is a bound n C w with Iw A I _< n for all A c W. On the other hand an example is constructed which shows that Lachlan's condition (F) does not imply injective enumerability for r.e. classes of cofinite sets. We also look at a certain embeddability property and show that it is equivalent with injective enumerability for certain classes of cofinite sets. At the end we present a reformulation of property (F).	recursion;recursively enumerable set	Stephan Wehner	1995	Arch. Math. Log.	10.1007/BF01375520	maximal set;combinatorics;discrete mathematics;topology;mathematics	Theory	7.60500493921485	18.71986425531839	40120
e35707404d516a9def1942167708934bf8325628	a theoretical comparison of feasibility cuts for the integrated aircraft-routing and crew-pairing problem	gestion integrada;flight crews;gestion integree;extreme rays;modele mathematique;etude theorique;routing;feasibility analysis;estudio comparativo;integrated planning;routage;formulacion;integrated management;pairing;aircraft routing;aeronef;air transportation;modelo matematico;working conditions;satisfiability;aeronave;feasibility;feasibility cuts;etude comparative;benders decomposition;transport aerien;transporte aereo;planificacion;numerical analysis;theory;personal de navegacion;comparative study;personnel navigant;estudio teorico;mathematical model;pairings;crew pairing;crew;planning;airlines;emparejamiento;connections transportation;planification;theoretical study;appariement;experimentation;formulation;practicabilidad;faisabilite;aircraft;experimentacion;enrutamiento	The integrated aircraft routing and crew pairing problem consists in determining a minimum-cost set of aircraft routes and crew pairings such that each flight leg is covered by one aircraft and one crew, and some side constraints are satisfied. Linking constraints impose minimum connection times for crews that depend on aircraft connections. The main solution approach for this problem consists in solving a constrained crew pairing problem iteratively, adding feasibility cuts until a solution is found where the connection set used by the crew pairings is feasible for the aircraft routing problem. The feasibility cuts can be generated by a Benders decomposition approach in which aircraft routing is handled by the subproblem, or they can be selected from a predefined family. We perform a theoretical comparison of the different types of feasibility cuts. We also propose a simple procedure to strengthen these cuts. Computational experiments performed on test instances provided by two major airlines are presented to support the theoretical results.	benders decomposition;computation;experiment;routing	Anne Mercier	2008	Transportation Science	10.1287/trsc.1070.0197	planning;benders' decomposition;feasibility study;routing;simulation;numerical analysis;engineering;operations management;comparative research;pairing;mathematical model;formulation;mathematics;integrated business planning;operations research;theory;aviation;satisfiability	Robotics	18.021519132168013	5.796783638752171	40181
142152e86e096e648cb169e593c39ee40143bf34	parallel complexity of computing a maximal set of disjoint paths	arbre graphe;tratamiento paralelo;directed graphs;graphe non oriente;nc;non directed graph;algoritmo busqueda;shared memory;algorithm complexity;traitement parallele;tree graph;multiprocessor;algorithme recherche;memoria compartida;complejidad algoritmo;sistema informatico;prams;search algorithm;computer system;camino optimo;chemin optimal;maximal paths;optimal path;complexite algorithme;parallel complexity;computational complexity;grafo no orientado;directed graph;undirected graphs;graphe oriente;polylogarithmic time;grafo orientado;systeme informatique;depth first search;multiprocesador;arbol grafo;parallel processing;memoire partagee;disjoint paths;multiprocesseur	Given a graph, G = (V, E), and sets S ⊂ V and Q ⊂ V, the maximal paths problem requires the computation of a maximal set of vertex disjoint paths in G that begin at vertices of S and end at vertices of Q. It is well known that this problem can be solved sequentially in time that is proportional to the number of edges in G. However, its parallel complexity is not known. This note shows that this problem is NC-reducible to that of computing a depth-first search forest in a suitable n-vertex graph. This result can also be extended to directed graphs.	maximal set	Alok Aggarwal	1992	Inf. Process. Lett.	10.1016/0020-0190(92)90044-V	parallel processing;combinatorics;discrete mathematics;independent set;directed graph;graph center;computer science;cycle graph;vertex;mathematics;bound graph;neighbourhood;algorithm	DB	18.72288647843764	28.452690115485527	40188
11250918ff75ce37df023a468e99cc391c1796d8	the one-way communication complexity of group membership	communication complexity;upper bound;quantum physics;computational complexity	This paper studies the one-way communication complexity of the subgroup membership problem, a classical problem closely related to basic questions in quantum computing. Here Alice receives, as input, a subgroup H of a finite group G; Bob receives an element y ∈ G. Alice is permitted to send a single message to Bob, after which he must decide if his input y is an element of H. We establish the following bounds on the classical communication complexity of this problem in the bounded-error setting: 1. The problem can be solved with O(log |G|)-bit communication with the promise that H is normal. 2. The problem can be solved with O(dmax · log |G|)-bit communication, where dmax is the maximum degree of an irreducible complex representation of G. 3. For any prime p not dividing |G|, the problem can be solved with O(log |G|+ dmax · log p)-bit communication, where dmax is the maximum degree of an irreducible Fp-representation of G.	alice and bob;communication complexity;irreducibility;one-way function;quantum computing	Scott Aaronson;François Le Gall;Alexander Russell;Seiichiro Tani	2011	Chicago J. Theor. Comput. Sci.		combinatorics;computer science;communication complexity;mathematics;upper and lower bounds;computational complexity theory;algorithm;quantum mechanics	Theory	8.555046685221741	25.00876234908861	40201
ff46d974beff3fba835349a937bc3bc87e82386d	partitioning sat instances for distributed solving	computational grid;propositional satisfiability	In this paper we study the problem of solving hard propositional satisfiability problem (SAT) instances in a computing grid or cloud, where run times and communication between parallel running computations are limited. We study analytically an approach where the instance is partitioned iteratively into a tree of subproblems and each node in the tree is solved in parallel. We present new methods which combine clause learning and look-ahead to construct partitions, evaluate their efficiency experimentally, and finally demonstrate the power of the approach in a real grid environment by solving several instances that were not solved in a SAT solver competition.	boolean satisfiability problem;cloud computing;computation;constraint learning;experiment;grid computing;randomized algorithm;solver	Antti Eero Johannes Hyvärinen;Tommi A. Junttila;Ilkka Niemelä	2010		10.1007/978-3-642-16242-8_27	computer science;theoretical computer science;algorithm	AI	22.253497774370768	4.546707501573424	40208
9f1d774cd55c6cd50eb8149023e54473e1c4c03f	a note on the inapproximability of induced disjoint paths		We study the inapproximability of the induced disjoint paths problem on an arbitrary n-node m-edge undirected graph, which is to connect the maximum number of the k sourcesink pairs given in the graph via induced disjoint paths. It is known that the problem is NP-hard to approximate within m 1 2 −ε for a general k and any ε > 0. In this paper, we prove that the problem is NP-hard to approximate within n for a general k and any ε > 0 by giving a simple reduction from the independent set problem.	approximation algorithm;graph (discrete mathematics);hardness of approximation;independent set (graph theory);induced subgraph;np-hardness	Gaoxiu Dong;Weidong Chen	2017	CoRR		combinatorics;discrete mathematics;mathematics	Theory	23.759243189305376	22.757519706801563	40229
5e7df7e01a307a2936d658ab29add2bb87a3209a	single-machine makespan minimization scheduling with nonlinear shortening processing times	single machine;makespan;scheduling;nonlinear shortening processing times	In this paper, we consider the single-machine makespan minimization scheduling problem with nonlinear shortening processing times. By the nonlinear shortening processing times, we mean that the processing times of jobs are non-increasing nonlinear functions of their starting times. The computational complexity of the general problem remains an open problem, but we show that even with the introduction of nonlinear shortening processing times to job processing times, some special cases remain polynomially solvable. We also show that an optimal schedule of the general makespan minimization problem is V-shaped with respect to job normal processing times. A heuristic algorithm which utilize the V-shaped property is proposed, and computational experiments show that it is effective and efficient in obtaining near-optimal solutions. & 2011 Elsevier Ltd. All rights reserved.	algorithm;computation;computational complexity theory;convex optimization;decision problem;experiment;flow shop scheduling;heuristic (computer science);job stream;makespan;nonlinear system;scheduling (computing);single-machine scheduling	Ming-Zheng Wang;Ji-Bo Wang	2012	Computers & OR	10.1016/j.cor.2011.05.001	job shop scheduling;mathematical optimization;real-time computing;computer science;scheduling	AI	15.776724369895282	9.798775337252607	40232
4a40751b46cf8f166a7beaccc58d4bf91f82c71f	a hybrid evolution strategy for the open vehicle routing problem	flotte;elitism;duracion trayecto;elitisme;algoritmo busqueda;travel time;recombinaison;competitividad;routing;vehicle routing problem;algorithme recherche;heuristic method;modelo hibrido;search algorithm;routage;vehicle routing;metodo heuristico;probleme tournee vehicule;systeme ouvert;problema ruta vehiculo;modele hybride;hybrid model;optimisation combinatoire;busca local;flota;guided local search;metamodel;metamodele;metamodelo;fleet;evolution strategies;competitiveness;coaccion capacidad;evolution strategy;recombination;tabu search;recombinacion;contrainte capacite;methode heuristique;open vehicle routing;combinatorial optimization;capacity constraint;open systems;sistema abierto;competitivite;local search;recherche locale;busqueda tabu;recherche tabou;optimizacion combinatoria;duree trajet;enrutamiento	This paper presents a hybrid evolution strategy (ES) for solving the open vehicle routing problem (OVRP), which is a well-known combinatorial optimization problem that addresses the service of a set of customers using a homogeneous fleet of non-depot returning capacitated vehicles. The objective is to minimize the fleet size and the distance traveled. The proposed solution method manipulates a population of @m individuals using a (@m+@l)-ES; at each generation, a new intermediate population of @l offspring is produced via mutation, using arcs extracted from parent individuals. The selection and combination of arcs is dictated by a vector of strategy parameters. A multi-parent recombination operator enables the self-adaptation of the mutation rates based on the frequency of appearance of each arc and the diversity of the population. Finally, each new offspring is further improved via a memory-based trajectory local search algorithm, while an elitist scheme guides the selection of survivors. Experimental results on well-known benchmark data sets demonstrate the competitiveness of the proposed population-based hybrid metaheuristic algorithm.	benchmark (computing);bit array;combinatorial optimization;computation;evolution strategy;feasible region;generalized least squares;graph (discrete mathematics);local search (optimization);loss function;mathematical optimization;optimization problem;search algorithm;vehicle routing problem	Panagiotis P. Repoussis;Christos D. Tarantilis;Olli Bräysy;George Ioannou	2010	Computers & OR	10.1016/j.cor.2008.11.003	metamodeling;mathematical optimization;routing;simulation;tabu search;computer science;artificial intelligence;local search;vehicle routing problem;mathematics;evolution strategy;open system;recombination;guided local search;search algorithm	Robotics	20.571460501833855	5.577930021322619	40244
d0cdb3325f3fa51433cedf97f1f661e453579268	height-deterministic pushdown automata	regular language;pushdown automata visibly pushdown laguages height determinism;pushdown automata;pushdown automata visibly pushdown laguages heightdeterminism	We define the notion of height-deterministic pushdown automata, a model where for any given input string the stack heights during any (nondeterministic) computation on the input are a priori fixed. Different subclasses of height-deterministic pushdown automata, strictly containing the class of regular languages and still closed under boolean language operations, are considered. Several such language classes have been described in the literature. Here, we suggest a natural and intuitive model that subsumes all the formalisms proposed so far by employing height-deterministic pushdown automata. Decidability and complexity questions are also considered.	automata theory;computation;deterministic pushdown automaton;non-deterministic turing machine;regular language;stack (abstract data type)	Dirk Nowotka;Jirí Srba	2007		10.1007/978-3-540-74456-6_13	deterministic context-free language;deterministic pushdown automaton;combinatorics;discrete mathematics;deterministic context-free grammar;regular language;computer science;nested word;mathematics;context-free language;computability;programming language;pushdown automaton;embedded pushdown automaton;algorithm	Logic	-3.9628195598436156	21.20764912258145	40249
94b8542ddbe31a1c0045be4387778018f27b55c9	a tight lower bound for restricted pir protocols	lower bounds;private information retrieval;upper bound;privacy;lower bound	We show that any 1-round 2-server Private Information Retrieval Protocol where the answers are one bit long must ask questions that are at least n−2 bits long, which is nearly equal to the known n−1 upper bound. This improves upon the approximately 0.25n lower bound of Kerenidis and deWolf while avoiding their use of quantum techniques.	private information retrieval	Richard Beigel;Lance Fortnow;William I. Gasarch	2006	computational complexity	10.1007/s00037-006-0208-3	combinatorics;computer science;theoretical computer science;mathematics;upper and lower bounds;algorithm	Theory	10.621155803832286	24.883913038773798	40271
014c4fe56d20d5e43cd8594414c4d518fec53c8b	optimal two-dimensional compressed matching	periodicite;algorithme;periodicity;periodicidad;pattern matching;algorithms;concordance forme;algoritmo optimo;algorithme optimal;optimal algorithm	Recent proliferation of digitized data and the unprecedented growth in the volume of stored and transmitted data motivated the definition of the compressed matching paradigm. This is the problem of efficiently finding a patternPin a compressed textTwithout the need to decompress. We present the firstoptimaltwo-dimensional compressed matching algorithm. The compression under consideration is the two dimensional run-length compression, used by FAX transmission. We achieve optimal time by proving new properties of two-dimensional periodicity. This enables performing duels in which no witness is required. At the heart of the dueling idea lies the concept that two overlapping occurrences of a pattern in a text can use the content of apredetermined text positionorwitnessin the overlap to eliminate one of them. Finding witnesses is a costly operation in a compressed text, thus the importance of witness-free dueling.		Amihood Amir;Gary Benson;Martin Farach-Colton	1997	J. Algorithms	10.1006/jagm.1997.0860	mathematical optimization;computer science;theoretical computer science;pattern matching;mathematics;programming language;algorithm	Theory	14.819835266761125	26.5616145889335	40411
7ee19c3a50d1324249de95f6fdfdaeee1455abe3	fast power charging strategy for ev/phev in parking campus with deployment of renewable energy	generators;queueing theory plug in hybrid electric vehicles ev phev fast power charging station mechanism renewable energy deployment fuel engine vehicles power grid integral power demand power supply power charging stations;renewable energy sources;charging stations renewable energy sources energy storage generators power grids power demand;charging stations;secondary cells battery storage plants demand side management electricity supply industry hybrid electric vehicles power grids queueing theory renewable energy sources;energy storage;power grids;power demand	Electric Vehicles (EV) and Plug-in Hybrid Electric Vehicles (PHEV) are being considered as aspirant competitors of traditional fuel engine vehicles and more attractive goods to consumers in recent years. The current power grid is being challenged by the increasing power demand from ordinary power supply and extract demand of developing power charging stations for EV/PHEV. The architecture and efficient operation of fast power charging stations is becoming a popular research topic both in academia and industry. In this paper, we introduce a candidate EV/PHEV fast power charging station mechanism, based on the combined power resource of current electrical grid and local renewable energy. As the proposed relevant component, the local renewable energy can become the positive power supplement for reducing the integral demand of charging stations to power grid and slowing down the consumption of nonrenewable natural energy. A quantitative stochastic scheme is established for analyzing the performance of the outlined system via employing arguments from queueing theory and economics, after clean energy is deployed. The results figures show that the integral power demand can be reduced by arranging our mechanism and the win-win benefits can be shared by utilities and power consumers.	control system;electric sheep;energy systems language;extended validation certificate;grid network;hybrid kernel;load profile;power supply;queueing theory;software deployment;usb	Qi Wang;I. Safak Bayram;Fabrizio Granelli;Michael Devetsikiotis	2014	2014 IEEE 19th International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD)	10.1109/CAMAD.2014.7033268	wind power;renewable energy;electricity generation;simulation;electric power;base load power plant;peaking power plant;load balancing;grid parity;peak demand;dynamic demand;smart grid;distributed generation;pumped-storage hydroelectricity;energy storage;intermittent energy source;grid energy storage	Arch	3.8296177928059127	6.263164409000772	40444
5cae2daf13f19436aaaddbb2c38613159ad1de16	on the computation of fully proportional representation	dynamic programming;parameterized complexity;multi winner elections;np hardness;single peaked electorate	We investigate two systems of fully proportional representation suggested by Chamberlin & Courant and Monroe. Both systems assign a representative to each voter so that the “sum of misrepresentations” is minimized. The winner determination problem for both systems is known to be NP-hard, hence this work aims at investigating whether there are variants of the proposed rules and/or specific electorates for which these problems can be solved efficiently. As a variation of these rules, instead of minimizing the sum of misrepresentations, we considered minimizing the maximal misrepresentation introducing effectively two new rules. In the general case these “minimax” versions of classical rules appeared to be still NP-hard. We investigated the parameterized complexity of winner determination of the two classical and two new rules with respect to several parameters. Here we have a mixture of positive and negative results: e.g., we proved fixed-parameter tractability for the parameter the number of candidates but fixed-parameter intractability for the number of winners. For single-peaked electorates our results are overwhelmingly positive: we provide polynomial-time algorithms for most of the considered problems. The only rule that remains NP-hard for single-peaked electorates is the classical Monroe rule.	algorithm;computation;courant–friedrichs–lewy condition;maximal set;minimax;np-hardness;parameterized complexity;time complexity	Nadja Betzler;Arkadii M. Slinko;Johannes Uhlmann	2013	J. Artif. Intell. Res.	10.1613/jair.3896	parameterized complexity;mathematical optimization;computer science;artificial intelligence;machine learning;dynamic programming;mathematics;algorithm	AI	15.991685118481486	17.182848768769748	40447
b23eb7baa5f6fb4de2f4d814ca76ac18f044aa71	finding large clique minors is hard	discrete mathematics;complete graph	We prove that it is NP-complete, given a graph G and a parameter h, to determine whether G contains a complete graph Kh as a minor.	approximation algorithm;clique (graph theory);clique problem;hadwiger number;hardness of approximation;np-completeness;p versus np problem;polynomial;polynomial-time approximation scheme;time complexity	David Eppstein	2009	J. Graph Algorithms Appl.		block graph;graph power;edge-transitive graph;petersen graph;combinatorics;clique graph;discrete mathematics;topology;wagner graph;null graph;simplex graph;forbidden graph characterization;cubic graph;graph factorization;mathematics;voltage graph;windmill graph;butterfly graph;crossing number;graph minor;complete graph;complement graph;line graph;string graph	Theory	24.26362069301224	25.874467432875406	40450
06a53b5c2e2dd99f0bcea0a80e7848c40b74cf6c	even delta-matroids and the complexity of planar boolean csps		The main result of this article is a generalization of the classical blossom algorithm for finding perfect matchings. Our algorithm can efficiently solve Boolean CSPs where each variable appears in exactly two constraints (we call it edge CSP) and all constraints are even Δ-matroid relations (represented by lists of tuples). As a consequence of this, we settle the complexity classification of planar Boolean CSPs started by Dvořák and Kupec.  Using a reduction to even Δ-matroids, we then extend the tractability result to larger classes of Δ-matroids that we call efficiently coverable. It properly includes classes that were known to be tractable before, namely, co-independent, compact, local, linear, and binary, with the following caveat: We represent Δ-matroids by lists of tuples, while the last two use a representation by matrices. Since an n×n matrix can represent exponentially many tuples, our tractability result is not strictly stronger than the known algorithm for linear and binary Δ-matroids.	blossom algorithm;cobham's thesis;cryptographic service provider	Alexandr Kazda;Vladimir Kolmogorov;Michal Rolinek	2017		10.1145/3230649	mathematical optimization;combinatorics;discrete mathematics;computer science;machine learning;mathematics;approximation algorithm;algorithm;locality-sensitive hashing	Theory	7.23037556898717	18.797335009975026	40459
ea89c3c804e0e7866f385889c450f059e40d9c50	on the role of bottleneck monge matrices in combinatorial optimization	programacion discreta;optimisation;problema transporte;transportation problem;probleme transport;travelling salesman problem;mathematiques combinatoires;optimisation combinatoire;problema viajante comercio;programmation discrete;probleme commis voyageur;scheduling;matrice distribution;optimization;combinatorial optimization;combinatorial mathematics;ordonnancement;flow shop;discrete programming;matrice monge;optimizacion combinatoria	In this short summary of research we describe some significant aspects of exploiting the bottleneck Monge property in combinatorial optimization. A matrix (c~j) is said to fulfill the bottleneck Monge property or to be a max distribution matrix, if max(cit,,Ciq)<~ max(ciq, cip) for all I ~<i < j <~ rn, 1 <. p < q<~n. Several problems of discrete programming can immediately be solved, if the underlying data have this property, in particular flow shop problems with minimum makespan, time transportation problems and bottleneck travelling salesman problems.	combinatorial optimization;discrete optimization;makespan;mathematical optimization;travelling salesman problem	Rainer E. Burkard	1995	Oper. Res. Lett.	10.1016/0167-6377(95)00003-3	transportation theory;mathematical optimization;combinatorics;flow shop scheduling;combinatorial optimization;computer science;mathematics;travelling salesman problem;scheduling;algorithm	Theory	20.458251382250143	11.743555106902633	40462
c573ccd484561ccc7430ab54c6e295821b15a8b0	planar stage graphs: characterizations and applications	parallel algorithm;dependence graph;maximum matching;permutation graph;task scheduling;linear space	"""We consider combinatorial and algorithmic aspects of the well-known paradigm \killing two birds with one stone"""". We deene a stage graph as follows: vertices are the points from a planar point set, and fu; vg is an edge if and only if the (innnite, straight) line segment joining u to v intersects a given line segment, called a stage. We show that a graph is a stage graph if and only if it is a permutation graph. The characterization results in a compact linear space representation of stage graphs. This has been exploited for designing improved algorithms for matching in permutation graphs, two processor task scheduling for dependency graphs known to be permutation graphs, and dominance related problems for planar point sets."""	algorithm;execution unit;programming paradigm;scheduling (computing);whole earth 'lectronic link;windows nt processor scheduling	Frank Bauernöppel;Evangelos Kranakis;Danny Krizanc;Anil Maheshwari;Jörg-Rüdiger Sack;Jorge Urrutia	1997	Theor. Comput. Sci.	10.1016/S0304-3975(96)00201-0	1-planar graph;outerplanar graph;block graph;pathwidth;mathematical optimization;split graph;factor-critical graph;combinatorics;discrete mathematics;universal graph;independent set;bipartite graph;pancyclic graph;forbidden graph characterization;permutation graph;graph coloring;trapezoid graph;mathematics;parallel algorithm;modular decomposition;chordal graph;indifference graph;book embedding;line graph;linear space;planar graph;matching	Theory	24.335195362750312	27.0407198293213	40477
3b313c7e1dc828632f24b3b37898978abb08cc3e	a mazing 2+∊ approximation for unsplittable flow on a path	algorithms;design;graph algorithms;path and circuit problems;theory	We study the problem of unsplittable flow on a path (UFP), which arises naturally in many applications such as bandwidth allocation, job scheduling, and caching. Here we are given a path with nonnegative edge capacities and a set of tasks, which are characterized by a subpath, a demand, and a profit. The goal is to find the most profitable subset of tasks whose total demand does not violate the edge capacities. Not surprisingly, this problem has received a lot of attention in the research community. If the demand of each task is at most a small-enough fraction δ of the capacity along its subpath (δ -small tasks), then it has been known for a long time [Chekuri et al., ICALP 2003] how to compute a solution of value arbitrarily close to the optimum via LP rounding. However, much remains unknown for the complementary case, that is, when the demand of each task is at least some fraction δ > 0 of the smallest capacity of its subpath (δ -large tasks). For this setting a constant factor approximation is known, improving on an earlier logarithmic approximation [Bonsma et al., FOCS 2011]. In this paper we present a PTAS for δ -large tasks, for any constant δ > 0. Key to this result is a complex geometrically inspired dynamic program. Each task is represented as a segment underneath the capacity curve, and we identify a proper maze-like structure so that each corridor of the maze is crossed by only O (1) tasks in the optimal solution. The maze has a tree topology, which guides our dynamic program. Our result implies a 2 + ε approximation for UFP, for any constant ε > 0, improving on the previously best 7 + ε approximation by Bonsma et al. We remark that our improved approximation algorithm matches the best known approximation ratio for the considerably easier special case of uniform edge capacities.	approximation algorithm;icalp;job scheduler;ptas reduction;rounding;scheduling (computing);symposium on foundations of computer science;tree network;word lists by frequency	Aris Anagnostopoulos;Fabrizio Grandoni;Stefano Leonardi;Andreas Wiese	2014		10.1137/1.9781611973402.3	mathematical optimization;combinatorics;discrete mathematics;mathematics;algorithm	Theory	18.56120817819625	15.580038356452286	40524
50e7186b71d88e398d58df3a7bb392b818553917	another simplification of the recursion scheme		"""The present paper shows that all primitive recursive functions of one variable R~ can be obtained by starting with the function S(x) and repeatedly using the difference (h (x) -"""" g (x)) composition (h (g(x))) and pure iteration with no parameter. But the class of functions R', which is the closure under difference (x--"""" xk), substitution and pure iteration with no parameter of the set consisting the zero, successor and projection functions doesn't coincide with R. In view of the results of [1, 2] all we need to prove is if functions h(x), g(x) e R 1 then h (x) + g (x) e R 1 and there is a functionf(x 1 ..... x,) for whichf(xl ,..., xr)eR and f(x I ..... x, ) ~ R'."""	level of detail;recursion	Nadejda Georgieva	1977	Arch. Math. Log.	10.1007/BF02007251	left recursion;combinatorics;discrete mathematics;theoretical computer science;double recursion;mutual recursion;recursion	Theory	-0.5936008670226078	15.223891238923624	40527
b5b4cc57c4c570c3dc3748f492cb7b2d774f70ac	complexity of ideals in finite semigroups and finite-state machines	finite state machine	# G (S) denotes the complexity of a finite semigroup as introduced by Krohn and Rhodes. IfI is a maximal ideal or maximal left ideal of a semigroupS, then# G (I) ⩽ # G (S) ⩽ # G (I) + 1. Thus, ifV is an ideal ofS with# G (S) = n ⩾ k = # G (V), then there is a chain of ideals ofS $$V = V_k \subset V_{k + 1} \subset ... \subset V_n \subseteq S$$ with# G (V j ) =j, i.e., complexity is continuous with respect to ideals. Given a representation ofS as a subsemigroup ofF R (Q), all mappings on the setQ(e.g., as the semigroup of a finite state sequential machine with statesQ) a rank ideal consists of all elements ofS whose range contains no more thank elements for some fixed integerk. The above result also applies to rank ideals. Existing results on complexity are reviewed in the language of finite-state sequential machines.	finite-state machine;krohn–rhodes theory;maximal set	Kenneth Krohn;Richard Mateosian;John L. Rhodes	1967	Mathematical systems theory	10.1007/BF01692497	combinatorics;discrete mathematics;computer science;mathematics;finite-state machine;algorithm;algebra	Theory	-1.097153795426442	19.94029575609594	40537
c0025c8f4ff7372e6ea83f0d9ae94d21f439d625	minimal string difference encodings		Abstract   Given two strings s and t, a difference encoding is a third string that contains sufficient information to derivet  t  from  s . An algorithm is presented which derives a difference encoding that can be represented in the fewest number of bits relative to the  string edit  operators  insert, delete, replace , and  skip . This algorithm has practical significance for distributed text processing applications.	character encoding	Robert N. Goldberg	1982	J. Algorithms	10.1016/0196-6774(82)90014-1	string interpolation;discrete mathematics;commentz-walter algorithm;string;theoretical computer science;boyer–moore string search algorithm;mathematics;string metric;algorithm;string searching algorithm	Theory	11.382719041880623	27.746118703988333	40590
069610409a8ded82078968a1ef5314aeaa06935b	kernels for feedback arc set in tournaments	parameterized complexity kernels tournaments;004	A tournament $T = (V,A)$ is a directed graph in which there is exactly one arc between every pair of distinct vertices. Given a digraph on $n$ vertices and an integer parameter $k$, the {sc Feedback Arc Set} problem asks whether thegiven digraph has a set of $k$ arcs whose removal results in an acyclicdigraph. The {sc Feedback Arc Set} problem restricted to tournaments is knownas the {sc $k$-Feedback Arc Set in Tournaments ($k$-FAST)} problem. In thispaper we obtain a linear vertex kernel for FAST{}. That is, we give apolynomial time algorithm which given an input instance $T$ to FAST{} obtains an equivalent instance $Tu0027$ on $O(k)$ vertices. In fact, given any fixed $epsilon u003e 0$, the kernelized instance has at most $(2 + epsilon)k$ vertices.Our result improves the previous known bound of $O(k^2)$ on the kernel size forFAST{}. Our kernelization algorithm solves the problem on a subclass ofrntournaments in polynomial time and uses a known polynomial time approximationrnscheme for FAST.	apx;approximation algorithm;directed acyclic graph;feedback arc set;feedback vertex set;kernel (operating system);polynomial;time complexity	Stéphane Bessy;Fedor V. Fomin;Serge Gaspers;Christophe Paul;Anthony Perez;Saket Saurabh;Stéphan Thomassé	2009		10.4230/LIPIcs.FSTTCS.2009.2305	mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics	AI	23.15540240276058	22.77831166998612	40597
3abb6f4c7b463bb720849b4d8c3ee190a7a04a7f	linearity and unprovability of set union problem strategies	first occurrence;complexity analysis;set theory;data structure	We consider the set union problem (SUP) which consists in designing data for manipulation of a family of disjoint sets which partition a given universe of n elements. In response to a work of Tarjan we prove that the POSTORDER strategy for SUP has a linear length (thus solving a problem of Hart and Sharir). On the other side, we provide a data structure and axioms for an on line strategy-LOCAL POSTORDER-for SUP which fails to be linear but it has a very slow-indeed in the theory of finite sets unprovable-growth. This complements a result of Tarjan who showed an Ackermann type growth for a related problem. Our results may be summarized by saying that (in finite set theory) we may assume that our algorithms are linear (although we know that in fact they fail to be linear). Perhaps this is the first occurrence of unprovability in the complexity analysis of algorithms.	ackermann function;algorithm;analysis of algorithms;data structure;set theory;simple update protocol;software upgrade protocol	Martin Loebl;Jaroslav Nesetril	1988		10.1145/62212.62247	mathematical optimization;combinatorics;discrete mathematics;data structure;computer science;mathematics;algorithm;set theory	Theory	5.781389670504298	17.85009206979821	40632
3f58a5b5e98469a14dd259ed25bec51ac26f9b39	private approximation of search problems	search problem;optimal solution;solution optimale;vertex cover;aplicacion;49j30;05bxx;vertex;secure computation;aproximacion optima;approximation algorithm;coaccion;exact solution;contrainte;problema np duro;solucion exacta;calculo automatico;definicion;problema investigacion;94a60;68wxx;input;computing;probleme np;calcul automatique;np hard problem;conception algorithme;68q17;constraint;optimal approximation;approximation optimale;definition;probleme np difficile;solucion optima;algoritmo aproximacion;entree ordinateur;vertice;private approximation;solution exacte;entrada ordenador;algorithme approximation;49k30;algoritmo optimo;probleme recherche;algorithme optimal;application;optimal algorithm;68w25;solution list algorithms	Many approximation algorithms have been presented in the last decades for ${\cal NP}$-hard search problems. The focus of this paper is on cryptographic applications, where it is desirable to design algorithms which do not leak unnecessary information. Specifically, we are interested in private approximation algorithms—efficient approximation algorithms whose output does not leak information not implied by the optimal solutions to the search problems. Privacy requirements add constraints on the approximation algorithms; in particular, known approximation algorithms usually leak a lot of information. For functions, Feigenbaum et al. [ACM Trans. Algorithms, 2 (2006), pp. 435-472] presented a natural requirement that a private algorithm should not leak information not implied by the original function. Generalizing this requirement to relations is not straightforward as an input may have many different outputs. We present a new definition that captures a minimal privacy requirement from such algorithms; applied to an input instance, it should not leak any information that is not implied by its collection of exact solutions. We argue that our privacy requirement is natural and quite minimal. We show that, even under this minimal definition of privacy, for well-studied problems such as vertex cover and max exact 3SAT, private approximation algorithms are unlikely to exist even for poor approximation ratios. Similarly to Halevi et al. [in Proceedings of the 33rd ACM Symposium on Theory of Computing, ACM, New York, 2001, pp. 550-559], we define a relaxed notion of approximation algorithms that leak (a little) information, and demonstrate the applicability of this notion by showing near optimal approximation algorithms for max exact 3SAT that leak a little information.	approximation	Amos Beimel;Paz Carmi;Kobbi Nissim;Enav Weinreb	2008	SIAM J. Comput.	10.1137/060671899	vertex;mathematical optimization;combinatorics;computing;definition;vertex cover;search problem;computer science;calculus;mathematics;constraint;approximation algorithm;algorithm	Theory	20.72565822752741	14.23039653635827	40666
f509c9939601e50e812375b901a32949431171f3	a graph clustering approach to weak motif recognition	experimental tests;graph clustering;degeneration;polynomial time;weighted graph;dna sequence	The aim of the motif recognition problem is to detect a set of mutually similar subsequences in a collection of biological sequences. Weak motif recognition is where the sequences are highly degenerate. Our new approach to this problem uses a weighted graph model and a heuristic that determines high weight subgraphs in polynomial time. Our experimental tests show impressive accuracy and efficiency. We give results that demonstrate a theoretical dichotomy between cliques in our graph that represent actual motifs and those that do not.		Christina Boucher;Daniel G. Brown;Paul Church	2007		10.1007/978-3-540-74126-8_14	time complexity;graph power;biology;dna sequencing;factor-critical graph;combinatorics;discrete mathematics;directed graph;graph bandwidth;null graph;graph property;computer science;simplex graph;machine learning;clustering coefficient;mathematics;voltage graph;graph;tutte polynomial;windmill graph;butterfly graph;intersection number;quartic graph;complement graph;line graph;algorithm;strength of a graph	AI	21.83860027665229	24.62215953124542	40698
4c085e0d32c593d7eced7677cfdf36264972d7e6	an algorithm for the scheduling of setups and production to meet due dates	control systems;hierarchical setup structure;job shop scheduling;closed loop systems;real time control;floor management setup scheduling production scheduling problem driven algorithm closed loop production control algorithm medical device manufacturing facility due dates setup times random disruptions hierarchical setup structure real time control;problem driven algorithm;setup times;scheduling algorithm job shop scheduling production control production facilities manufacturing medical services control systems costs laboratories productivity;random disruptions;closed loop production control algorithm;medical device manufacturing facility;scheduling algorithm;setup time;production control;medical services;floor management;scheduling;production facilities;manufacturing;scheduling biomedical equipment closed loop systems production control;medical device;production scheduling;productivity;setup scheduling;biomedical equipment;due dates	A closed-loop production control algorithm for a medical device manufacturing facility of an international healthcare conglomerate with due dates, significant setup times, and random disruptions is proposed. The algorithm is problem driven, exploits a hierarchical setup structure, and uses real-time control. The algorithm has been reduced to a set of simplistic rules with which floor management feels comfortable. The purpose of this research is to provide the theoretical underpinnings of those simple rules. >	algorithm;scheduling (computing)	Mitchell H. Burman;Stanley B. Gershwin	1992		10.1109/ROBOT.1992.220193	job shop scheduling;real-time computing;simulation;computer science;engineering;control system;scheduling	Theory	10.50718533780259	5.243366735159341	40710
bce113facd079894eb7c26654ce2ce04aefdc209	two metaheuristics for solving the connected multidimensional maximum bisection problem		In this paper, a connected multidimensional maximum bisection problem is considered. This problem is a generalization of a standard NP-hard maximum bisection problem, where each graph edge has a vector of weights and induced subgraphs must be connected. We propose two metaheuristic approaches, a genetic algorithm (GA) and an electromagnetism-like metaheuristic (EM). The GA uses modified integer encoding of individuals, which enhances the search process and enables usage of standard genetic operators. The EM, besides standard attraction–repulsion mechanism, is extended with a scaling procedure, which additionally moves EM points closer to local optima. A specially constructed penalty function, used for both approaches, is performed as a practical technique for temporarily including infeasible solutions into the search process. Both GA and EM use the same local search procedure based on 1-swap improvements. Computational results were obtained on instances from literature with up to 500 vertices and 60,000 edges. EM reaches all known optimal solutions on small-size instances, while GA reaches all known optimal solutions except for one case. Both proposed methods give results on medium-size and large-scale instances, which are out of reach for exact methods.	metaheuristic	Zoran Maksimovic;Jozef Kratica;Aleksandar Savic	2017	Soft Comput.	10.1007/s00500-016-2203-1	metaheuristic;penalty method;machine learning;artificial intelligence;evolutionary computation;mathematical optimization;computer science;genetic algorithm;combinatorial optimization;vertex (geometry);algorithm;local search (optimization);local optimum	Logic	24.588370027250075	5.370188053331845	40806
57a3f77ff82128e9b67628fc073e3d8fc383b0cc	ai buzzwords explained: distributed constraint optimization problems		The power network is the largest operating machine on earth, generating more than US$400bn a year1 keeping the lights on for our homes, offices, and factories. A significant concern in power networks is for the energy providers to be able to generate enough power to supply the demands at any point in time. Short terms demand peaks are however hard to predict and, thus, in the modern smart electricity grid, the energy providers can exploit the demand-side flexibility of the consumers to reduce the peaks in load demand.	constrained optimization;distributed constraint optimization;mathematical optimization	Ferdinando Fioretto;William Yeoh	2018	AI Matters	10.1145/3175502.3175506	grid;short terms;electricity;exploit;distributed computing;computer science;distributed constraint optimization	AI	2.9052243520700953	6.0831654669360855	40863
551f6162d4802430765eb540f2ef97e71b97d40b	church-rosser languages and their application to parsing problems		Church-Rosser languages were defined by McNaughton, Narendran, and Otto in 1988. They are the deterministic variant of the growing context-sensitive languages. Their word problem is decidable in linear time and they are a propper superset of the deterministic context-free languages. Their definition is baes on confluent length-reducing string rewriting systems, enhanced by the possibility to mark word ends and to use variables (nonterminals). The thesis discusses the application of Church-Rosser languages to basic parsing problems, which, for example, appear in compiler construction. It is shown that it is possible to compute a description of each Church-Rosser language which has rewriting system fulfilling a special syntactical restriction. This restriction is similar to context-sensitive rules with swapped sides and ist called context-splittability. This result, which was not expected before, is a classification of the Church-Rosse languages which is also expandable to growing context-sensitive languages. For example, this normal form allows to compute syntax trees for accepted words of a Church-Rosser languages. Furthermore, it makes the proof easier that the Church-Rosser languages properly contain the deterministic context-free languages. Using this normal form a construction is introduced which can be used to describe certain the prefix languages of certain Church-Rosser languages again as Church-Rosser languages. Since in general this is not possible some decision problems arise. This are also discussed in the thesis, and at least paritally circumvented by test methods.	church–rosser theorem;parsing	Jens R. Woinowski	2001			natural language processing;formal language;pumping lemma for regular languages;pumping lemma for context-free languages;computer science;nested word;third-generation programming language;syntax;cone;ontology language;abstract family of languages;fifth-generation programming language;programming language;second-generation programming language;comparison of multi-paradigm programming languages;algorithm	NLP	-3.354854496404781	18.14825254502971	40952
fcb69bef02924d550b87b9740b90b750cf1a2916	scheduling under linear constraints	approximation algorithm;parallel machine scheduling;computational complexity;linear programming	We introduce a parallel machine scheduling problem in which the processing times of jobs are not given in advance but are determined by a system of linear constraints. The objective is to minimize the makespan, i.e., the maximum job completion time among all feasible choices. This novel problem is motivated by various real-world application scenarios. We discuss the computational complexity and algorithms for various settings of this problem. In particular, we show that if there is only one machine with an arbitrary number of linear constraints, or there is an arbitrary number of machines with no more than two linear constraints, or both the number of machines and the number of linear constraints are fixed constants, then the problem is polynomial-time solvable via solving a series of linear programming problems. If both the number of machines and the number of constraints are inputs of the problem instance, then the problem is NP-Hard. We further propose several approximation algorithms for the latter case.	approximation algorithm;combinatorial optimization;computational complexity theory;decision problem;job stream;linear programming;makespan;mathematical optimization;np-hardness;parallel computing;polynomial-time approximation scheme;scheduling (computing);time complexity	Kameng Nip;Zhenbo Wang;Zizhuo Wang	2016	European Journal of Operational Research	10.1016/j.ejor.2016.02.028	mathematical optimization;combinatorics;discrete mathematics;criss-cross algorithm;computer science;linear programming;cutting stock problem;mathematics;computational complexity theory;approximation algorithm	AI	16.024661358392795	10.424144238815227	40955
c8e38d6966073c7dc4dec84d586e2e7c9aa85c75	cycles and waiting times in symmetric exhaustive and gated multiserver multiqueue systems	gated service;media access protocol;walk times symmetric exhaustive multiserver multiqueue exhaustive service independent identically distributed random variables gated multiserver multiqueue systems gated service average server cycle vacation times approximate closed form expressions average customer waiting time one limited service discipline service times;application software;communication systems;queueing theory;queueing analysis communication systems bibliographies computer applications media access protocol application software stability analysis;average server cycle;bibliographies;computer applications;waiting time;approximate closed form expressions;average customer waiting time;random variable;stability analysis;independent identically distributed;service times;one limited service discipline;independent identically distributed random variables;symmetric exhaustive multiserver multiqueue;walk times;vacation times;queueing analysis;exhaustive service;gated multiserver multiqueue systems	The authors consider symmetric multiserver multiqueue systems in the cases of exhaustive and gated service disciplines, and present exact analytical results for the average server cycle and vacation times, as well as approximate closed-form expressions for the average customer waiting time, thus complementing the results obtained by the same authors (1990) for the one-limited service discipline. Arrival processes at each queue are assumed to be Poisson, with the same rate for all queues; service times and walk times are modeled with independent, identically distributed random variables with arbitrary distributions. The two cases in which at most one server or any number of servers can simultaneously attend a queue are considered. >		Marco Ajmone Marsan;Luís F. M. de Moraes;Susanna Donatelli;Fabio Neri	1992		10.1109/INFCOM.1992.263521	random variable;von neumann stability analysis;application software;real-time computing;computer science;distributed computing;computer applications;queueing theory;communications system;statistics	Logic	7.649708386515627	10.656885166880578	41025
76338f3ed739e7071bf480154e1b36385be2f4c5	two edge-disjoint hop-constrained paths and polyhedra	contrainte chaude;longueur chemin;nombre entier;programacion entera;polyedre;mathematiques discretes;camino grafo;temps polynomial;graph path;matematicas discretas;poliedro;condition necessaire suffisante;cutting;facet;discrete mathematics;polyhedron;facette;hot constraint;68wxx;programmation en nombres entiers;decoupage;90c57;algorithme;52bxx;politope;algorithm;integer;hop constraints;integer programming;90c27;90b10;necessary and sufficient condition;entero;68r10;faceta;polynomial time;chemin graphe;survivable network;troquelado;point of view;edge disjoint paths;condicion necesaria suficiente;disjoint paths;algoritmo;polytope;tiempo polinomial	Given a graph G with distinguished nodes s and t, a cost on each edge of G, and a fixed integer L ≥ 2, the two edge-disjoint hop-constrained paths problem is to find a minimum cost subgraph such that between s and t there exist at least two edge-disjoint paths of length at most L. In this paper, we consider that problem from a polyhedral point of view. We give an integer programming formulation for the problem when L = 2, 3. An extension of this result to the more general case where the number of required paths is arbitrary and L = 2, 3 is also given. We discuss the associated polytope, P (G,L), for L = 2, 3. In particular, we show in this case that the linear relaxation of P (G,L), Q(G,L), given by the trivial, the st-cut, and the so-called L-path-cut inequalities, is integral. As a consequence, we obtain a polynomial time cutting plane algorithm for the problem when L = 2, 3. We also give necessary and sufficient conditions for these inequalities to define facets of P (G,L) for L ≥ 2 when G is complete. We finally investigate the dominant of P (G,L) and give a complete description of this polyhedron for L ≥ 2 when P (G,L) = Q(G,L).	algorithm;cutting-plane method;existential quantification;hop;integer programming;linear programming relaxation;polyhedron;time complexity	David Huygens;Ali Ridha Mahjoub;Pierre Pesneau	2004	SIAM J. Discrete Math.	10.1137/S0895480102419445	integer;time complexity;polytope;combinatorics;discrete mathematics;facet;integer programming;mathematics;geometry;cutting;algorithm;polyhedron	Theory	22.870326603103074	29.062982831651663	41036
cd2818e481cafad6a4ce4aaa89e76ff3829089c2	exact solution of the sonet ring loading problem	optical network;lower and upper bound;branch and bound algorithm;exact solution;linear algorithm;integer;branch and bound;communication;programming	In this paper we address the problem of planning the capacity of the local rings in synchronous optical networks (SONET). We present efficient lower and upper bound procedures and a branch and bound algorithm which is able to find the exact solution of large instances, employing short computing times.	synchronous optical networking	Mauro Dell'Amico;Martine Labbé;Francesco Maffioli	1999	Oper. Res. Lett.	10.1016/S0167-6377(99)00031-0	mathematical optimization;combinatorics;discrete mathematics;branch and price;mathematics;branch and bound;branch and cut	Theory	20.866272019815682	11.416604614519862	41041
79aed7e52e90573d4c23a2f53a9e2b5a6f94719b	integer programming approaches to networks with equal-split restrictions	ospf;school districting;equal split;integer programming;dissertation;network flow;branch and cut		integer programming	Amandeep Parmar	2007			mathematical optimization;combinatorics;integer programming;branch and price;mathematics;algorithm;branch and cut	AI	22.42729641202929	8.689892956961975	41094
8ab3d249bfb8fcc46d040576b7ab3097c059bd37	an initial study of analytical approach for reconfiguration		Changes in distribution system such as integration of low-carbon technologies and sudden changes between generation and demand, force grid to quickly respond the changes for keeping the system reliable and sustainable. In grid operation reconfiguration is one of the tools that modifies radial structure of distribution feeder from time to time in order to improve operating conditions of system. Generally heuristic methods are used to change open-close status of switches to reconfigure the system. However, analyzing the network with analytical methods give opportunity to observe the effects of all system components from mathematical expressions. This paper gives a beginning of an analytical approach for reconfiguration problem. Analytical expressions for distributed load profile is developed to decide switch location to separate feeders and proposed method is implemented to a simple 12-bus system.		Av&#x015F;e Avbike Seker;Tuba G&#x00F6;zel;Mehmet Hakan Hocao&#x011D;lu	2018	2018 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)	10.1109/ISGTEurope.2018.8571440	grid;control reconfiguration;heuristic;expression (mathematics);control engineering;load profile;curve fitting;computer science	Robotics	5.001540642740089	7.173428702692906	41129
e4e62c325f06c98efa53e7d914511fa0d61901af	patterson-wiedemann construction revisited	algebraic approach;search space;boolean function;linear transformation	Abstract   In 1983, Patterson and Wiedemann constructed Boolean functions on  n  = 15 input variables having nonlinearity strictly greater than 2 n−1  − 2 n−1/2 . Construction of Boolean functions on odd number of variables with such high nonlinearity was not known earlier and also till date no other construction method of such functions is known. We note that the Patterson-Wiedemann construction can be understood in terms of interleaved sequences as introduced by Gong in 1995. We show that the Patterson-Wiedemann functions can be described as repetitions of a particular binary string. As example we elaborate the cases for  n  = 15,21. Under this framework, we map the problem of finding Patterson-Wiedemann functions into a problem of solving a system of linear inequalities over the set of integers and provide proper reasoning about the choice of the orbits. This, in turn, reduces the search space. Similar analysis also reduces the complexity of calculating generalized non-linearity for such functions. In an attempt to understand the above construction from the group theoretic view point, we characterize the group of all  G-F (2)-linear transformations of  GF (2 ab ) which acts on  PG (2, 2 a ).		Sugata Gangopadhyay;Pradipkumar H. Keskar;Subhamoy Maitra	2003	Electronic Notes in Discrete Mathematics	10.1016/S1571-0653(04)00540-2	mathematical optimization;combinatorics;discrete mathematics;boolean expression;mathematics;linear map;boolean function;algorithm	Theory	5.5377308134221614	18.121907380828333	41151
16dc59fa57d656762c0479de0e482fa15dca2987	simple and efficient fully-functional succinct trees	ordinal trees;succinct data structures	The fully-functional succinct tree representation of Navarro and Sadakane (ACM Transactions on Algorithms, 2014) supports a large number of operations in constant time using 2n + o(n) bits. However, the full idea it is hard to implement. Only a simplified version with O(lg n) operation time has been implemented and shown to be practical and competitive. We describe a new variant that is much simpler to implement and has worst-case time O(lg lg n) for the operations.	acm transactions on algorithms;algorithm;best, worst and average case;binary search algorithm;byte;cpu cache;cache (computing);disk sector;emoticon;experiment;extrapolation;file spanning;operation time;ordinal data;precomputation;range minimum query;time complexity	Gonzalo Navarro	2016	Theor. Comput. Sci.	10.1016/j.tcs.2016.04.031	succinct data structure;combinatorics;computer science;theoretical computer science;mathematics;programming language;algorithm	Theory	13.856137364717398	28.292853874845083	41152
1e6299a16447b91533f2f6229d0bbf7776e14ef5	consecutive optimization of decision trees concerning various complexity measures	decision tree;complexity measures;optimization;decision trees	In the paper algorithms are considered which allow to optimize decision trees consecutively againsts relatively different criterions. For decision tables over an arbitrary infinite restricted information system [4], these algorithms have polynomial time complexity.	decision tree	Mikhail Ju. Moshkov;Igor Chikalov	2004	Fundam. Inform.		optimal decision;decision tree model;decision tree learning;computer science;theoretical computer science;machine learning;decision tree;alternating decision tree;incremental decision tree;weighted sum model	Theory	17.423367869181057	24.713823399861965	41170
36e43457c0d7fd5a714cf08e22bafea1f07d5663	solving connectivity problems parameterized by treewidth in single exponential time	dynamic programming;randomized algorithms;connected dominating set;approximate algorithm;feedback vertex set;steiner trees;approximation algorithms;dynamic program;set theory;trees mathematics;polynomials;approximation theory;trees mathematics approximation theory computational complexity dynamic programming monte carlo methods set theory;exact algorithms treewidth xed parameter tractability randomized algorithms;computational complexity;heuristic algorithms;monte carlo algorithm;approximation algorithms heuristic algorithms dynamic programming educational institutions steiner trees monte carlo methods polynomials;cycle packing connectivity problems treewidth single exponential time dynamic programming techniques global requirement c tw v o 1 time monte carlo algorithms connectivity type problems hamiltonian path steiner tree feedback vertex set connected dominating set parameterized complexity exact algorithm approximate algorithm h minor free graphs planar graphs strong exponential time hypothesis cut count;treewidth;exact algorithms;data structure;monte carlo methods;hamiltonian path;xed parameter tractability	For the vast majority of local problems on graphs of small tree width (where by local we mean that a solution can be verified by checking separately the neighbourhood of each vertex), standard dynamic programming techniques give c^tw |V|^O(1) time algorithms, where tw is the tree width of the input graph G = (V, E) and c is a constant. On the other hand, for problems with a global requirement (usually connectivity) the best -- known algorithms were naive dynamic programming schemes running in at least tw^tw time. We breach this gap by introducing a technique we named Cut&Count that allows to produce c^tw |V|^O(1) time Monte Carlo algorithms for most connectivity-type problems, including Hamiltonian Path, Steiner Tree, Feedback Vertex Set and Connected Dominating Set. These results have numerous consequences in various fields, like parameterized complexity, exact and approximate algorithms on planar and H-minor-free graphs and exact algorithms on graphs of bounded degree. The constant c in our algorithms is in all cases small, and in several cases we are able to show that improving those constants would cause the Strong Exponential Time Hypothesis to fail. In contrast to the problems aiming to minimize the number of connected components that we solve using Cut&Count as mentioned above, we show that, assuming the Exponential Time Hypothesis, the aforementioned gap cannot be breached for some problems that aim to maximize the number of connected components like Cycle Packing.	approximation algorithm;connected component (graph theory);connected dominating set;dynamic programming;exptime;exponential time hypothesis;feedback vertex set;hamiltonian path;monte carlo method;parameterized complexity;set packing;steiner tree problem;time complexity;treewidth	Marek Cygan;Jesper Nederlof;Marcin Pilipczuk;Michal Pilipczuk;Johan M. M. van Rooij;Jakub Onufry Wojtaszczyk	2011	2011 IEEE 52nd Annual Symposium on Foundations of Computer Science	10.1109/FOCS.2011.23	hamiltonian path;mathematical optimization;combinatorics;discrete mathematics;feedback vertex set;data structure;steiner tree problem;dynamic programming;connected dominating set;mathematics;treewidth;randomized algorithm;computational complexity theory;approximation algorithm;algorithm;monte carlo algorithm;polynomial;monte carlo method;set theory;approximation theory	Theory	22.271365850489403	22.103231336187967	41228
279a03ac78998e9ae851bedc79877e6aee894012	finite state verifiers i: the power of interaction	verification;probabilistic automaton;machine turing;complexity theory;protocole transmission;temps polynomial;automata estado finito;sistema informatico;clase complejidad;cle publique;computer system;interactive proof systems;turing machine;probabilistic automata;systeme conversationnel;protocolo transmision;public key;classe complexite;complexity class;interactive system;criptografia;cryptography;finite state automata;automate probabiliste;polynomial time;llave publica;sistema conversacional;pushdown automata;finite state automaton;automata probabilista;cryptographie;systeme informatique;finite automaton;arthur merlin games;automate fini;verificacion;zero knowledge;lenguaje formal;maquina turing;formal language;systeme preuve;tiempo polinomial;transmission protocol;langage formel	An investigation of interactive proof systems (IPSs) where the verifier is a 2-way probabilistic finite state automaton (2pfa) is initiated. In this model, it is shown: (1) IPSs in which the verifier uses private randomization are strictly more powerful than IPSs in which the random choices of the verifier are made public to the prover. (2) IPSs in which the verifier uses public randomization are strictly more powerful than 2pfa's alone, that is, without a prover. (3) Every language which can be accepted by some deterministic Turing machine in exponential time can be accepted by some IPS. Additional results concern two other classes of verifiers: 2pfa's that halt in polynomial expected time, and 2-way probabilistic pushdown automata that halt in polynomial time. In particular, IPSs with verifiers in the latter class are as powerful as IPSs where verifiers are polynomial-time probabilistic Turing machines. In a companion paper [7], zero knowledge IPSs with 2pfa verifiers are investigated.	automata theory;average-case complexity;exptime;finite-state machine;halting problem;interactive proof system;polynomial;probabilistic turing machine;pushdown automaton;stack (abstract data type);symmetric multiprocessing;time complexity;zero-knowledge proof	Cynthia Dwork;Larry J. Stockmeyer	1992	J. ACM	10.1145/146585.146599	combinatorics;computer science;artificial intelligence;theoretical computer science;probabilistic automaton;mathematics;finite-state machine;programming language;algorithm	Theory	-0.31469517789961005	23.518670800819937	41237
03c4fc59fb2f11d1524c0d86cb3ae6509e52609f	stochastic matching with commitment	random graph;stochastic matching;probability pe;following stochastic optimization problem;optimal omniscient algorithm;possible edge;maximum matching;end point;factor algorithm	We consider the following stochastic optimization problem first introduced by Chen et al. in [6]. We are given a vertex set of a random graph where each possible edge is present with probability pe. We do not know which edges are actually present unless we scan/probe an edge. However whenever we probe an edge and find it to be present, we are constrained to picking the edge and both its end points are deleted from the graph. We wish to find the maximum matching in this model. We compare our results against the optimal omniscient algorithm that knows the edges of the graph and present a 0.573 factor algorithm using a novel sampling technique. We also prove that no algorithm can attain a factor better than 0.896 in this model.	algorithm;communication endpoint;entity–relationship model;matching (graph theory);mathematical optimization;optimization problem;random graph;sampling (signal processing);stochastic gradient descent;stochastic optimization;vertex (graph theory)	Kevin P. Costello;Prasad Tetali;Pushkar Tripathi	2012		10.1007/978-3-642-31594-7_69	edge contraction;mathematical optimization;combinatorics;discrete mathematics;feedback arc set;degree;edge space;edge cover;mathematics;matching	Theory	22.191551285603822	20.45555353607258	41360
e77ff477088520da0dec65603eeee76298e04501	traffic signal timing at isolated intersections using simulation optimization	protocols;optimization technique;optimal method;simulation;simulation optimization;predicate transition nets;osi;dynamic program;state dependence;concurrent execution;aspol;synchronization;technical report;petri nets;communication;modeling;architecture;steady state	Two innovative stochastic traffic signal optimization techniques for isolated intersections are discussed. The objective is to determine the optimum cycle and green phase lengths for signalized isolated traffic intersections. Determination of optimum cycle and green phase lengths is based on minimization of the total average delay at the intersection for a given period of observation. Traffic signal timing is formulated as a stochastic inventory problem, which is then solved by a combination of simulation and dynamic programming. The suitability of the optimization techniques for undersaturated and oversaturated flow conditions; and steady state and nonstationary queue conditions are discussed. The advantages of the techniques over most widely used signal optimization methods, and the application of the simulation optimization method in state dependent server-vacation signal timing are also discussed.	dynamic programming;mathematical optimization;server (computing);simulation;steady state	Anthony A. Saka;G. Anandalingam;Nicholas J. Garber	1986		10.1145/318242.318523	control engineering;synchronization;real-time computing;simulation;computer science;technical report;architecture;steady state	EDA	9.725423255132348	7.4943917699085665	41395
0177ac48cb2baa9f7279d432afc1e8480e6d7ed6	optimization analysis of an unreliable multi-server queue with a controllable repair policy	particle swarm optimization;quasi newton method;cost;controllable repair policy	This article deals with an infinite-capacity multi-server queueing system, in which the servers are assumed unreliable and may fail at any time. To conserve energy while delivering reliable service, a controllable repair policy is introduced. With such a policy, the failed servers will be sent to the repair facility only when the number of failed machines in the system arrives at a preset threshold value. A quasi-birth-and-death process is used to model the complex system and the stability condition is examined. The rate matrix is calculated approximately and steady-state stationary distributions are obtained by a matrix-analytic approach. The closed-form expressions of important system characteristics are presented. A cost model is constructed to determine the optimal repair policy, the optimal value of service rate and the optimal value of repair rate. Three heuristic algorithms are employed to deal with the optimization problem. Some numerical results are provided to compare the efficiency of two methods. & 2014 Elsevier Ltd. All rights reserved.	algorithm;analysis of algorithms;complex system;heuristic;mathematical optimization;numerical analysis;optimization problem;queueing theory;server (computing);stationary process;steady state	Chia-Huang Wu;Wen-Chiung Lee;Jau-Chuan Ke;Tzu-Hsin Liu	2014	Computers & OR	10.1016/j.cor.2014.03.018	mathematical optimization;simulation;quasi-newton method;computer science;mathematics;particle swarm optimization	Metrics	8.478337193548166	9.102993461212561	41407
3853e2a58fbaa71dc2d8e48a85e7bd8790181fe7	on finding minimum-diameter clique trees	clique tree;clique trees;minimum-diameter clique tree;acyclic hypergraphs;natural candidate;minimum diameter;linear-time algorithm;parallel computing;distinct clique-tree representation;chordal graph;chordal graphs;efficient algorithm;clique-tree representation;data structure;decision tree;parallel algorithm;knowledge base;greedy algorithm;knowledge based system;parallel computer	A clique-tree representation of a chordal graph often reduces the size of the data structure needed to store the graph, permitting the use of extremely efficient algorithms that take advantage of the compactness of the representation. Since some chordal graphs have many distinct clique-tree representations, it is interesting to consider which one is most desirable under various circumstances. A clique tree of minimum diameter (or height) is sometimes a natural candidate when choosing clique trees to be processed in a parallel-computing environment. This paper introduces a linear-time algorithm for computing a minimum-diameter clique tree. ACM CCS	algorithm;data structure;parallel computing;time complexity;tree decomposition	Jean R. S. Blair;Barry W. Peyton	1994	Nord. J. Comput.		clique;block graph;parallel processing;knowledge base;split graph;combinatorics;clique graph;discrete mathematics;data structure;k-tree;computer science;theoretical computer science;simplex graph;decision tree;clique-sum;mathematics;clique percolation method;moral graph;treewidth;chordal graph	Theory	23.813250812996987	27.118956356658238	41453
c41a252dc26a95900765562fc86be84a1ae1c033	optimal service rate perturbations of many server queues in heavy traffic	93e20;call centers;many server queues;60h30;diffusion processes and approximations;halfin whitt qed heavy traffic regime	An optimal control problem for a single customer class, many server queueing system of the type G/M/n + G I is considered, where the control corresponds to the service rate. An infinite horizon discounted cost functional which consists of a convex control cost, linear delay and idle server costs, and a linear abandonment cost is formulated. We study this problem in the heavy traffic regime originally proposed by Halfin and Whitt, where the arrival rates and the number of servers grow to infinity in concert. First we address the diffusion control problem (DCP) associated with the heavy traffic limit. By constructing a smooth solution to the associated Hamilton– Jacobi–Bellman equation, we obtain a feedback type optimal control for the DCP. We show that the value function of the DCP is an asymptotic lower bound for the value functions of the corresponding queueing control problems. We use the optimal control of the DCP to obtain an asymptotically optimal control policy for the queueing control problem.	asymptotically optimal algorithm;bellman equation;hamilton–jacobi–bellman equation;jacobi method;mathematical optimization;optimal control;queueing theory;server (computing)	Ananda Weerasinghe	2015	Queueing Syst.	10.1007/s11134-014-9423-9	real-time computing;simulation	Metrics	8.914071225676391	10.182542580949686	41500
42a1becf8247f3baaddeaa37d70153b042dbdaf3	a distributed algorithm for computing and updating the process number of a forest	search number;process number;pathwidth;connected component;distributed algorithm	In this paper, we present a distributed algorithm to compute various parameters of a tree such as the process number, the edge search number or the node search number and so the pathwidth. This algorithm requires n steps, an overall computation time of O(nlogn), andn messages of size log3n+3. We then propose a distributed algorithm to update the proc ess number (or the node search number, or the edge search number) of each component o f a forest after adding or deleting an edge. This second algorithm requires O(D) steps, an overall computation time of O(D logn), and O(D) messages of size log 3 n+ 3, whereD is the diameter of the modified connected component. Finally, we show how to extend our algorithms to trees and for ests of unknown size using messages of less than 2α+4+ ε bits, whereα is the parameter to be determined and ε = 1 for updates algorithms. Key-words: pathwidth, process number, search number, distributed alg orithm. MASCOTTE, INRIA, I3S(CNRS/UNSA), Sophia Antipolis, Franc e. {firstname.lastname@sophia.inria.fr} ∗ This work was partially funded by the European projects IST FET AEOLUSand COST 293 GRAAL , and done within the CRC CORSOwith France Telecom R&D. Un algorithme distribué pour le calcul et la mise à jour du process number d’une forêt Résumé : Dans cet article, nous présentons un algorithme distribué p ermettant de calculer divers paramètres d’un arbre tel le process number, la pathwidth et l’edge search number. Cet algorithme nécessiten étapes, a un temps d’exécution de O(nlogn) et génèren messages de taille log 3 n+ 3. Nous montrons ensuite comment il peut servir a mettre à jour l e p ocess number (ou la pathwidth ou l’edge search number) de chaque composante d’un forêt après l’ajout ou la suppression d’une arête. En fin on montre que cela peut être fait même si la taille de la fo rêt est inconnue. Mots-clés : pathwidth, process number, search number, algorithme dist ribué A distributed algorithm for the process number of a forest 3	computation;connected component (graph theory);council for educational technology;cyclic redundancy check;distributed algorithm;linear algebra;pathwidth;time complexity;zero suppression	David Coudert;Florian Huc;Dorian Mazauric	2008		10.1007/978-3-540-87779-0_36	pathwidth;distributed algorithm;mathematical optimization;combinatorics;discrete mathematics;connected component;computer science;mathematics;tree-depth;tree decomposition	Theory	20.153428019606075	27.691183531824166	41506
5a7a002da8f4bad22534d6265de5ad6181908989	a new staircase separator theorem	algoritmo paralelo;parallel algorithm;geometrie algorithmique;computational geometry;algorithme parallele;geometria computacional;algoritmo optimo;algorithme optimal;optimal algorithm;divide and conquer	The notion of staircase separator, introduced in 2], greatly facilitates the design of divide-and-conquer algorithms for problems on rectangles. We generalize the concept of staircase separator to k-perfect staircase separator, namely a set of staircase separators which partitions a set S of n axis-parallel, disjoint rectangles into k subsets of (almost) equal size. We derive an optimal O(log n) time parallel algorithm for computing a k-perfect staircase separator, using O(n) processors on the CREW PRAM model of computation. For a special case, where k = 2, this result provides a new bound of d n 2 e, in compared to d 7n 8 e in 2], on the quality of staircase separators for sets of rectangles.	apache axis;central processing unit;model of computation;parallel algorithm;parallel random-access machine	Viet Hai Nguyen	1997		10.1007/BFb0002769	mathematical optimization;combinatorics;parallel computing;divide and conquer algorithms;computational geometry;computer science;mathematics;parallel algorithm;algorithm	Theory	17.018912396912956	28.384395837961222	41520
d226153b7fa2b420f4dea1d81cd50cc87870c567	research on complex network topology model based information warfare system	random apollonian network information warfare network centric warfare complex network topology model;random apollonian network;complex networks;complex network;information warfare;topology model;trees mathematics;trees mathematics complex networks electronic warfare network theory graphs network topology;degree distribution;network topology;combat network representation complex network topology model information warfare system complex network theory warfare law network centric warfare military combat performance average path length cluster coefficient scale free degree distribution tree network random apollonian network;scale free;network centric warfare;clustering coefficient;electronic warfare;average path length;tree network;network theory graphs;complex networks radio access networks mathematical model bifurcation topology	The complex network theory provides the new ways to explore warfare law. The precondition of network-centric warfare is the construction of warfare network topology models. Studying the impact of network topology on military combat performance based on complex networks theory. A good warfare network needs small average path length, great cluster coefficient and scale-free degree distribution. The experimental results show that traditional tree network can not reflect the characteristics of the information warfare. We give some proposals to improve tree network and select random Apollonian network as the best representation of combat network.	apollonian network;average path length;coefficient;complex network;degree distribution;network theory;network topology;network-centric warfare;precondition	Su-Hong He;Lei Chen	2012	2012 9th International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2012.6234219	network formation;computer science;artificial intelligence;machine learning;network simulation;distributed computing;complex network;logical topology	HPC	-3.711910957647333	7.626403682320408	41525
a98b6f5346c16ed3d79cd0dda0e7f70a571d7558	on the relation between fuzzy max-archimedean t-norm relational equations and the covering problem	engineering;systeme equation;fuzzy set;procesamiento informacion;implementation;fuzzy relation;conjunto difuso;problema np duro;ensemble flou;max archimedean t norm composition;ingenierie;algorithme;resolucion problema;algorithm;np hard problem;sistema ecuacion;probleme recouvrement;problema recubrimiento;probleme np difficile;fuzzy relational equations;equation system;fuzzy constraint satisfaction;information processing;recouvrement ensemble;ingenieria;sistema difuso;systeme flou;set covering;cubierta conjunto;covering problem;fuzzy constraints;implementacion;traitement information;05b40;fuzzy system;problem solving;resolution probleme;algoritmo	The problem of solving a system of fuzzy relational equations with max-Archimedean t-norm composition is studied. It is shown that this problem is closely related to the covering problem, which belongs to the class of NP-hard problems. It is proved that there is a one-to-one correspondence between the minimal solutions of the equations and the irredundant coverings, as previously discovered by Markovskii [On the relation between equations with max-product composition and the covering problem, Fuzzy Sets and Systems, 153 (2005) 261-273] for fuzzy relational equations with max-product composition. Since max-product composition is a special case of max-Archimedean t-norm composition, this work extends Markovskii's work to fuzzy relational equations with max-Archimedean t-norm composition. An extension of Markovskii's algorithm is implemented, yielding a processing time linearly proportional to the square of the number of minimal solutions.	covering problems;t-norm	Jun-Lin Lin	2009	Fuzzy Sets and Systems	10.1016/j.fss.2009.01.012	simultaneous equations;information processing;type-2 fuzzy sets and systems;fuzzy classification;computer science;artificial intelligence;fuzzy number;calculus;np-hard;mathematics;fuzzy set;implementation;algorithm;fuzzy control system	DB	4.49485740991558	20.080515219417354	41532
8a4abf8a9552281c8f9db488183fb24e00b65b35	a queue with working breakdowns	markovian queue;partial breakdown of a server;waiting time distribution;steady state analysis	In this paper, we consider a new class of queueing models with working breakdowns. The system may become defective at any point of time when it is in operation. However, when the system is defective, instead of stopping service completely, the service continues at a slower rate. Using the probability generating function, we give the joint distribution of the server state and the number of customers in the system in steady state. We also derive the necessary and sufficient condition for the existence of the steady state. We study the waiting time distribution of our model. Finally, some performance measures and numerical examples are presented.	queue (abstract data type)	K. Kalidass;Ramanath Kasturi	2012	Computers & Industrial Engineering	10.1016/j.cie.2012.04.018	real-time computing;simulation;computer science;operations management;steady state	SE	8.250216007830614	10.622324269530026	41567
b8e9ef67a85ef8a9e3dcf64c77bc907f08f843a6	mixed integer programming approaches to exact minimization of total treatment time in cancer radiotherapy using multileaf collimators	minimisation;radioterapia;radiotherapy;constante tiempo;modelizacion;occupation time;minimization;total treatment time minimization;time constant;beam mechanics;heuristic method;exact solution;metodo heuristico;minimizacion;solucion exacta;radiotherapie;viga;modelisation;mixed integer program;programacion mixta entera;temps occupation;step and shoot;tiempo ocupacion;programmation partiellement en nombres entiers;mixed integer programming;radiation therapy;multileaf collimator;methode heuristique;poutre;solution exacte;modeling;intensity modulated radiation therapy;constante temps	The effectiveness of radiation therapy for cancer depends on the patient remaining still during treatment. It is thus important to minimize the total treatment time (TTT). When such treatment is delivered using multileaf collimators in ''step-and-shoot'' mode, it consists of a sequence of collimator configurations, or patterns; for each, the patient is exposed to radiation for a specified time, or beam-on time. The TTT can thus be divided into the total beam-on time and the time spent reconfiguring the collimators. The latter can reasonably be approximated by the number of patterns, multiplied by a constant overhead time per pattern. Previous approaches to this problem have all been heuristic; in particular none of them actually use the pattern overhead time to ascertain the best trade-off between beam-on time and number of patterns. In this paper, we develop exact solution approaches, based on mixed integer programming (MIP) formulations, which minimize the TTT. We consider direct solution of MIP formulations, and then exploit the bicriteria structure of the objective to derive an algorithm that ''steps up'' through the number of patterns used, leading to substantial computational savings.	integer programming;linear programming	Giulia M. G. H. Wake;Natashia Boland;Les S. Jennings	2009	Computers & OR	10.1016/j.cor.2007.10.027	mathematical optimization;radiation therapy;integer programming;mathematics;algorithm	Robotics	17.946987205643516	9.102924959473075	41586
2b49dfcac050500c3731f2677ba36ed636551d5f	assessing reliability of distributed units with respect to the provision of ancillary services	power feed in ancillary service products distributed units reliabilty reliability assessment power supply decentralization;power distribution reliability;power supplies to apparatus power distribution reliability;reliability frequency control power system reliability voltage control planning power generation reactive power;power supplies to apparatus	The energy system is due to substantial changes by reason of an ongoing decentralization of power supply. A challenge will be to provide ancillary services by distributed units since they are volatile regarding their power feed-in and hard to predict. This paper presents a method that allows for the evaluation of how reliable distributed units can participate in the provision of ancillary service products. This method can be used in order to assess unit coalitions with respect to their reliability.	categorization;computer simulation;energy systems language;monte carlo method;power supply	Marita Blank;Sebastian Lehnhoff	2013	2013 11th IEEE International Conference on Industrial Informatics (INDIN)	10.1109/INDIN.2013.6622926	reliability engineering;electronic engineering;engineering;operations management	Robotics	1.9343729399109286	6.436339812527946	41605
6750ba2b87fa0ef57fd448ffe6683bd29c50aadc	a randomized polynomial-time algorithm for the spanning hypertree problem on 3-uniform hypergraphs	random polynomials;cs cc;finite field;polynomial time algorithm;computational complexity;computer science;math co	Sergio Caracciolo, Gregor Masbaum, Alan D. Sokal, 4 and Andrea Sportiello Dip. Fisica, Università degli Studi di Milano, and INFN, via G. Celoria 16, 20133 Milano, Italy Institut de Mathématiques de Jussieu (UMR 7586 CNRS), Université Paris Diderot, Case 7012 Site Chevaleret, 75205 Paris Cedex 13, France Department of Physics, New York University, 4 Washington Place, New York, NY 10003, USA Department of Mathematics, University College London, London WC1E 6BT, UK (Dated: 13 December 2008)	rp (complexity);randomized algorithm;sergio verdú;time complexity	Sergio Caracciolo;Gregor Masbaum;Alan D. Sokal;Andrea Sportiello	2008	CoRR		combinatorics;discrete mathematics;computer science;mathematics;computational complexity theory;finite field;algorithm;algebra	ML	12.985473428630117	21.566391442099714	41612
384fffb5993a54ed9b28b3f1f133af75888af5d1	coupled and k-sided placements: generalizing generalized assignment	68w25 approximation algorithms	In modern data centers and cloud computing systems, jobs often require resources distributed across nodes providing a wide variety of services. Motivated by this, we study the Coupled Placement problem, in which we place jobs into computation and storage nodes with capacity constraints, so as to optimize some costs or profits associated with the placement. The coupled placement problem is a natural generalization of the widely-studied generalized assignment problem (GAP), which concerns the placement of jobs into single nodes providing one kind of service. We also study a further generalization, the k-Sided Placement problem, in which we place jobs into k-tuples of nodes, each node in a tuple offering one of k services. For both the coupled and k-sided placement problems, we consider minimization and maximization versions. In the minimization versions (MinCP and MinkSP), the goal is to achieve minimum placement cost, while incurring a minimum blowup in the capacity of the individual nodes. Our first main result is an algorithm for MinkSP that achieves optimal cost while increasing capacities by at most a factor of k+ 1, also yielding the first constant-factor approximation for MinCP. In the maximization versions (MaxCP and MaxkSP), the goal is to maximize the total weight of the jobs that are placed under hard capacity constraints. MaxkSP can be expressed as a k-column sparse integer program, and can be approximated to within a factor of O(k) factor using randomized rounding of a linear program relaxation. We consider alternative combinatorial algorithms that are much more efficient in practice. Our second main result is a local search based approximation algorithm that yields a 15approximation and O(k)-approximation for MaxCP and MaxkSP respectively. Finally, we consider an online version of MaxkSP and present algorithms that achieve logarithmic competitive ratio under certain necessary technical assumptions.	approximation algorithm;cloud computing;combinatorial optimization;competitive analysis (online algorithm);computation;data center;expectation–maximization algorithm;generalized assignment problem;integer programming;job stream;linear programming relaxation;local search (optimization);randomized rounding;sparse matrix	Madhukar R. Korupolu;Adam Meyerson;Rajmohan Rajaraman;Brian Tagiku	2015	Math. Program.	10.1007/s10107-015-0930-1	mathematical optimization;theoretical computer science;mathematics;distributed computing	Theory	19.101991558047153	14.585057823773518	41628
2467aa31a6c419ec9657019311b912016e40ae62	new bin packing fast lower bounds	bin packing problem;modelizacion;metodo caso peor;approximation asymptotique;optimisation;bin packing;optimizacion;complexite calcul;numerical method;lower bounds;relacion orden;problema relleno;ordering;modelisation;relation ordre;complejidad computacion;metodo numerico;computational complexity;borne inferieure;methode cas pire;probleme remplissage;optimization;asymptotic approximation;modeling;worst case method;methode numerique;lower bound;aproximacion asintotica;cota inferior	In this paper, we address the issue of computing fast lower bounds for the Bin Packing problem, i.e., bounds that have a computational complexity dominated by the complexity of ordering the items by non-increasing values of their volume. We introduce new classes of fast lower bounds with improved asymptotic worst-case performance compared to well-known results for similar computational effort. Experimental results on a large set of problem instances indicate that the proposed bounds reduce both the deviation from the optimum and the computational effort.	2.5d;best, worst and average case;bin packing problem;computation;computational complexity theory;experiment;lattice boltzmann methods;set packing	Teodor Gabriel Crainic;Guido Perboli;Miriam Pezzuto;Roberto Tadei	2007	Computers & OR	10.1016/j.cor.2006.02.007	mathematical optimization;combinatorics;bin packing problem;computer science;mathematics;asymptotic computational complexity;algorithm	AI	17.538336419743814	11.903347436616533	41655
e851e04667bc4e43f983f905e711298b9e64e6f4	intelligent simulation system for production scheduling	production scheduling		scheduling (computing);simulation	Dalibor Benic	1995			real-time computing;round-robin scheduling;fair-share scheduling;scheduling (production processes);two-level scheduling;dynamic priority scheduling;flow shop scheduling;computer science;rate-monotonic scheduling;fixed-priority pre-emptive scheduling	OS	12.248908188153058	5.912668722140365	41680
979ddecf9c50fed76e96b0c7a73d99272cb40600	minimizing harmonic distortion impact at distribution system with considering large-scale ev load behaviour using modified lightning search algorithm and pareto-fuzzy approach		This research is focusing on optimal placement and sizing of multiple variable passive filter (VPF) to mitigate harmonic distortion due to charging station (CS) at 449 bus distribution network.There are 132 units of CS which are scheduled based on user behaviour within 24 hours, with the interval of 15minutes. By considering the varying ofCS patterns andharmonic impact,Modified Lightning Search Algorithm (MLSA) is used to find 22 units of VPF coordination, so that less harmonics will be injected from 415V bus to the medium voltage network and power loss is also reduced. Power system harmonic flow, VPF, CS, battery, and the analysis will be modelled in MATLAB/m-file platform. High Performance Computing (HPC) is used to make simulation faster. Pareto-Fuzzy technique is used to obtain sizing of VPF from all nondominated solutions. From the result, the optimal placements and sizes of VPF are able to reduce the maximum THD for voltage and current and also the total apparent losses up to 39.14%, 52.5%, and 2.96%, respectively. Therefore, it can be concluded that the MLSA is suitable method to mitigate harmonic and it is beneficial in minimizing the impact of aggressive CS installation at distribution network.		Syed Norazizul Syed Nasir;Jasrul J. Jamian;Mohd Wazir Mustafa	2018	Complexity	10.1155/2018/6587493	total harmonic distortion;electric power system;harmonics;voltage;electronic filter;control theory;search algorithm;harmonic;pareto principle;mathematics	HPC	5.918587372237102	5.037985757213844	41701
8cfeb3d7364375076574bb62ee502db7466d9a4d	solving integer programs with a few important binary gub constraints	ordered set;integer program;branch and bound	During a branch and bound search of an integer program, decisions have to be taken about which subproblem to solve next and which variable or special ordered set to branch on. Both these decisions are usually based on some sort of estimated change in the objective caused by different branching. When the next subproblem is chosen, the estimated change in the objective is often found by summing the change caused by changing all integer variables with non-integer values, as if they were independent. For special ordered sets the estimation is done for each set as a whole. The purpose of this paper is to report some results from trying to do a simultaneous estimation for all the variables in a binary gub constraint. By this, the analysed problems contain one or a few constraints saying that the sum of n binary variables should be equal to m (< n).	branch and bound;integer programming;linear programming;special ordered set	Bjørn Nygreen	1993	Annals OR	10.1007/BF02024842	mathematical optimization;combinatorics;discrete mathematics;special ordered set;computer science;branch and price;mathematics;branch and bound;branch and cut	AI	24.37899111877343	10.787071092795216	41713
934fe0af64001d96c9f65e89b614f6514e1bd540	physical-aware long reach pon planning	genetic algorithm;optimization;prufer sequence;passive optical networks	To solve the planning in long reach PON, we develop a mathematical model to capture the internal constraints in cascade splitter scenarios. The model does not focus on the maximal transmission distance, but also takes into account other physical constraints (e.g. the power budget) and management requirements. Through analyzing the PON solution structure, a two-stage genetic algorithm with Prüfer sequence is proposed to solve this NP-hard planning problem. Prüfer sequence is used to keep the tree structure of PON during the optimization process. The correctness of the proposed algorithm is checked by the enumeration method. The impacts of ONU distribution and power budget on the cost and graph characteristics are studied as well. The simulations show that the ONUs with boundary distribution has a higher average cost than those with cluster distribution. In addition, as the power budget reduces, the average cost increases and the splitter connections tend to be tree topologies with more branches. B Rentao Gu rentaogu@bupt.edu.cn Xiaoxu Liu xiaoxuliu@bupt.edu.cn Yuefeng Ji jyf@bupt.edu.cn 1 Beijing University of Posts and Telecommunications, 10 Xitucheng Road, Haidian District, P.O. Box 90, 100876 Beijing, China 2 State Key Lab of Information Photonics and Optical Communications, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China	computation;computer cluster;correctness (computer science);demultiplexer (media file);genetic algorithm;graph (discrete mathematics);lumpers and splitters;mathematical model;mathematical optimization;maximal set;multicast;np-hardness;passive optical network;requirement;simulation;time complexity;tree structure	Rentao Gu;Xiaoxu Liu;Yuefeng Ji	2015	Telecommunication Systems	10.1007/s11235-015-0051-4	mathematical optimization;passive optical network;combinatorics;genetic algorithm;prüfer sequence;computer science;mathematics	HPC	21.44888294738396	8.59977268445171	41732
aa23b86d78a5dfa192b229afa40d33ba82bb9924	parameterized algorithms for inclusion of linear matchings	parameterized algorithm;related nesting-free 2-interval pattern;linear matchings;linear matching inclusion problem;order-preserving mapping;hardness result;parameterized complexity;linear matching;n vertex-disjoint edge	A  linear matching  consists of 2 n  vertices ordered linearly, together with  n  vertex-disjoint edges. In this article, we study the Linear Matching Inclusion problem, which takes two linear matchings, called the  pattern  and the  target , and asks if there is an order-preserving mapping of the pattern into the target. We consider several parameterizations of this problem, for which we obtain parameterized algorithms and hardness results. In addition, we settle the parameterized complexity of the related Nesting-Free 2-Interval Pattern problem.	linear algebra;matching (graph theory)	Sylvain Guillemot	2011		10.1007/978-3-642-25591-5_37	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	23.812559305190128	23.244122768697952	41750
3039c8b757a0a07e5782b2996c90ec8dd8de0ff0	adaptive penalties for evolutionary graph coloring	graph coloring;graph coloring problem;penalty function	In this paper we consider a problem independent constraint handling mechanism, Stepwise Adaptation of Weights (SAW) and show its working on graph coloring problems. SAWing technically belongs to the penalty function based approaches and amounts to modifying the penalty function during the search. We show that it has a twofold ben-eet. First, it proves to be rather insensitive to its technical parameters, thereby providing a general, problem independent way to handle constrained problems. Second, it leads to superior EA performance. In an extensive series of comparative experiments we show that the SAWing EA outperforms a powerful graph coloring heuristic algorithm, DSatur, on the hardest graph instances and has a linear scale-up behaviour.	algorithm;experiment;graph coloring;heuristic (computer science);linear scale;penalty method;stepwise regression	A. E. Eiben;J. K. van der Hauw	1997		10.1007/BFb0026593	graph power;mathematical optimization;factor-critical graph;combinatorics;fractional coloring;null graph;simplex graph;complete coloring;edge coloring;comparability graph;moser spindle;nowhere-zero flow;cubic graph;graph coloring;graph factorization;voltage graph;distance-hereditary graph;butterfly graph;list coloring;graph minor;greedy coloring;line graph	ML	22.74603069387482	21.695481497794486	41765
1cb4da63a1fe85cee431b9176331c2d118b9b3e7	on unapproximable versions of np-complete problems	randomized reduction;counting problems;68q99;permanente matriz;temps polynomial;unapproximable;complexite calcul;probleme np complet;graph clique;algorithme;permanent;computational complexity;polynomial time;68q15;algorithms;np complete;68q25;problema np completo;2sat;clique graphe;permanent matrice;clique;np complete problem;tiempo polinomial	We prove that all of Karp’s 21 original NP-complete problems have a version that is hard to approximate. These versions are obtained from the original problems by adding essentially the same simple constraint. We further show that these problems are absurdly hard to approximate. In fact, no polynomial-time algorithm can even approximate log(k) of the magnitude of these problems to within any constant factor, where log(k) denotes the logarithm iterated k times, unless NP is recognized by slightly superpolynomial randomized machines. We use the same technique to improve the constant such that MAX CLIQUE is hard to approximate to within a factor of n. Finally, we show that it is even harder to approximate two counting problems: counting the number of satisfying assignments to a monotone 2SAT formula and computing the permanent of -1, 0, 1 matrices.	approximation algorithm;clique problem;computing the permanent;constraint (mathematics);constraint algorithm;iteration;karp's 21 np-complete problems;max;np-completeness;polynomial;randomized algorithm;time complexity;monotone	David Zuckerman	1996	SIAM J. Comput.	10.1137/S0097539794266407	clique;mathematical optimization;combinatorics;discrete mathematics;np-complete;computer science;mathematics;algorithm	Theory	18.46179307374887	25.581743387755168	41769
a79612b4141700eb0c0a96860e7a3c88da995020	fast discovery of reliable subnetworks	social network services;graph theory;random graph;stochastic processes graph theory monte carlo methods random processes social networking online;approximation algorithms;efficient algorithm;construction industry;path covering;set covering problem;113 computer and information sciences;reliable subnetworks fast discovery;reliability theory;social network;approximation algorithms social network services computer network reliability computer science construction industry reliability theory;stochastic processes;random processes;social networking online;bernoulli random graph q;monte carlo simulation reliable subnetworks fast discovery path covering reliable subgraph problem social network bernoulli random graph q candidate paths stochastic search;experimental evaluation;computer science;reliable subgraph problem;a4 article in conference publication refereed;monte carlo simulation;candidate paths stochastic search;monte carlo methods;stochastic search;computer network reliability	We present a novel and efficient algorithm, Path Covering, for solving the most reliable subgraph problem. A reliable subgraph gives a concise summary of the connectivity between two given individuals in a social network. Formally, the given network is seen as a Bernoulli random graph G, and the objective is to find a subgraph H with at most B edges such that the probability that a path exists in H between the given two individuals is maximized. The algorithm is based on an efficient stochastic search of candidate paths, and the use of Monte-Carlo simulation to cast the problem as a set cover problem. Experimental evaluation on real graphs derived from DBLP bibliography database indicates superior performance of the proposed algorithm.	bernoulli polynomials;branch and bound;euler–bernoulli beam theory;experiment;graph (discrete mathematics);greedy algorithm;induced subgraph;monte carlo method;random graph;scalability;set cover problem;simulation;social network analysis;stochastic optimization	Petteri Hintsanen;Hannu Toivonen;Petteri Sevon	2010	2010 International Conference on Advances in Social Networks Analysis and Mining	10.1109/ASONAM.2010.39	stochastic process;mathematical optimization;combinatorics;computer science;theoretical computer science;machine learning;data mining;subgraph isomorphism problem;mathematics;induced subgraph isomorphism problem;induced path;statistics;monte carlo method	DB	12.96384317848059	14.255303333260926	41796
d5f491d5ac747b9341f27bda0571ba1c9a6f9c34	reducing power consumption in data center by predicting temperature distribution and air conditioner efficiency with machine learning	temperature sensors power demand temperature distribution servers data models atmospheric modeling temperature control;power consumption data center machine learning;power efficiency power consumption reduction data center temperature distribution prediction air conditioner efficiency machine learning air conditioner coordinated control;temperature distribution air conditioning computer centres control engineering computing learning artificial intelligence network servers power consumption power engineering computing;data center;machine learning;power consumption	To reduce the power consumption in data centers, the coordinated control of the air conditioner and the servers is required. It takes tens of minutes for changes of operational parameters of air conditioners including outlet air temperature and volume to be reflected in the temperature distribution in the whole data center. So, the proactive control of the air conditioners is required according to the prediction temperature distribution corresponding to the load on the servers. In this paper, the temperature distribution and the power efficiency of air conditioner were predicted by using a machine-learning technique, and also we propose a method to follow-up proactive control of the air conditioner under the predicted optimum condition. Consequently, by the follow-up proactive control of the air conditioner and the load of servers, power consumption reduction of 30% at maximum was demonstrated.	data center;machine learning;performance per watt	Yuya Tarutani;Kazuyuki Hashimoto;Go Hasegawa;Yutaka Nakamura;Takumi Tamura;Kazuhiro Matsuda;Morito Matsuoka	2016	2016 IEEE International Conference on Cloud Engineering (IC2E)	10.1109/IC2E.2016.39	control engineering;embedded system;real-time computing;engineering	HPC	4.660924819581211	5.918488657077275	41827
14b8a69f89dc3e8cf2cde36e13852fc4fbb82d47	the pos/neg-weighted median problem on block graphs with subgraph-shaped customers	calcul scientifique;location theory;analisis numerico;block graph;subgrafo;90b80;temps lineaire;linear time algorithm;tiempo lineal;analyse numerique;algorithme;algorithm;computacion cientifica;numerical analysis;sous graphe;linear time;vertex graph;edge graph;median problem;arete graphe;subgraph shaped customers;subgraph;scientific computation;vertice grafo;arista grafico;sommet graphe;algoritmo	In this paper we consider the pos/neg weighted 1-median problem on block graphs where the customers are modeled as subgraphs. Under the condition that the block graph has unit edge lengths and the median is restricted to the vertex of the block graph, we devise a linear time algorithm for this problem.	algorithm;facility location problem;point of sale;time complexity	Xiaoqin Zhang;Liying Kang;Yukun Cheng	2010	Computing	10.1007/s00607-010-0084-1	1-planar graph;block graph;time complexity;combinatorics;discrete mathematics;location theory;numerical analysis;vertex;mathematics;geometry;chordal graph;indifference graph;line graph;algorithm	Theory	23.287338152145164	30.10988870726536	41946
34621a42eebf6314c0145d2ba6b4602e12420bce	catalan structures and dynamic programming in h-minor-free graphs	parameterized complexity;longest path;minor free graphs;catalan structure	We give an algorithm that, for a fixed graph <i>H</i> and integer <i>k</i>, decides whether an <i>n</i>-vertex <i>H</i>-minor-free graph <i>G</i> contains a path of length <i>k</i> in 2<i>O</i>(√<i>k</i>). <i>n<sup>O</sup></i>(1) steps. Our approach builds on a combination of Demaine-Hajiaghayi's bounds on the size of an excluded grid in such graphs with a novel combinatorial result on certain branch decompositions of <i>H</i>-minor-free graphs. This result is used to bound the number of ways vertex disjoint paths can be routed through the separators of such decompositions. The proof is based on several structural theorems from the Graph Minors series of Robertson and Seymour. With a slight modification, similar combinatorial and algorithmic results can be derived for many other problems. Our approach can be viewed as a general framework for obtaining time 2<i><sup>O</sup></i>(√<i>k</i>). <i>n<sup>O</sup></i>(1) algorithms on <i>H</i>-minor-free graph classes.	algorithm;dynamic programming;routing	Frederic Dorn;Fedor V. Fomin;Dimitrios M. Thilikos	2008		10.1016/j.jcss.2012.02.004	1-planar graph;block graph;pathwidth;parameterized complexity;split graph;combinatorics;discrete mathematics;robertson–seymour theorem;cograph;universal graph;graph product;longest path problem;computer science;forbidden graph characterization;comparability graph;graph coloring;mathematics;modular decomposition;treewidth;partial k-tree;chordal graph;indifference graph;line graph;algorithm;planar graph	Theory	24.016180181508254	24.961020352704793	41994
be0f47d1511f7724f73e302994d7d2e7eeb4ed61	transformation between regular expressions and omega-automata	004;infinity regular expressions parity automata	We propose a new definition of regular expressions for describing languages of omega-words, called infinity-regular expressions. These expressions are obtained by adding to the standard regular expression on finite words an operator infinity that acts similar to the Kleene-star but can be iterated finitely or infinitely often (as opposed to the omega-operator from standard omega-regular expressions, which has to be iterated infinitely often). We show that standard constructions between automata and regular expressions for finite words can smoothly be adapted to infinite words in this setting: We extend the Glushkov construction yielding a simple translation of infinity-regular expressions into parity automata, and we show how to translate parity automata into infinity-regular expressions by the classical state elimination technique, where in both cases the nesting of the * and the infinity operators corresponds to the priority range used in the parity automaton. We also briefly discuss the concept of deterministic expressions that directly transfers from standard regular expressions to infinity-regular expressions.	automaton;chaitin's constant;regular expression;ω-automaton	Christof Löding;Andreas Tollkötter	2016		10.4230/LIPIcs.MFCS.2016.88	combinatorics;discrete mathematics;nondeterministic finite automaton;computer science;mathematics;generalized star height problem;algorithm;algebra	Logic	-1.6414101766929814	18.09466582232099	42068
f010d33e33a09993b160537045c0313f430d233d	scattered context grammars that erase nonterminals in a generalized k-limited way	grammar;nombre entier;produccion;68q42;frase;integer;sentence;grammaire;informatique theorique;entero;production;phrase;gramatica;computer theory;informatica teorica	A scattered context grammar erases nonterminals in a generalized k-limited way in a successful derivation, where k is a positive integer, if in every sentential form of a derivation, each of its substrings consisting of nonterminals from which the grammar derives empty strings is of length k or less. This paper demonstrates that if a scattered context grammar generates its sentences in this way, it can be converted to a scattered context grammar without erasing productions; in general, however, this is not possible.	formal grammar;graph coloring;terminal and nonterminal symbols	Alexander Meduna;Jirí Techet	2008	Acta Informatica	10.1007/s00236-008-0081-4	integer;natural language processing;grammar;mathematics;programming language;algorithm;head-driven phrase structure grammar	NLP	-1.1887632300824262	18.891310646929302	42089
06bfcd2bebdddf25c889d1a28743c8fd959683c1	a framework for the dynamic implementation of finite automata for performance enhancement	performance;hardcoding;conference paper;finite automata;processing speed;automata implementation	The aim of this work is to provide a model for the dynamic implementation of finite automata for enhanced performance. Investigations have shown that hardcoded finite automata outperforms the traditional table-driven implementation up to some threshold. Moreover, the kind of string being recognized plays a major role in the overall processing speed of the string recognizer. Various experiments are depicted to show when the advantages of using hardcoding as basis for implementing finite automata (instead of using the classical table-driven approach) become manifest. The model, a dynamic algorithm that combines both hardcoding and table-driven is introduced.	algorithm;automata theory;automaton;data structure;decision table;dynamic problem (algorithms);experiment;finite-state machine;hard coding;linked list;sparse matrix	Ernest Ketcha Ngassam;Bruce W. Watson;Derrick G. Kourie	2004		10.1142/S0129054105003753	combinatorics;simulation;performance;quantum finite automata;computer science;theoretical computer science;automata theory;ω-automaton;mathematics;finite-state machine;hard coding;algorithm	NLP	11.310384742601201	28.82649447215463	42131
8df12fa45dc1f1ddc7ddb100168d766fb1fa67f4	partiality, cartesian closedness and toposes	morphisme;morfismo;articulo sintesis;article synthese;category theory;informatique theorique;theorie categorie;morphism;teoria categoria;review;computer theory;informatica teorica	Presentation equationnelle des categories de morphismes partiels avec etablissement systematique des rapports entre ces structures et les classiques structures totales	cartesian closed category	Pierre-Louis Curien;Adam Obtulowicz	1989	Inf. Comput.	10.1016/0890-5401(89)90023-0	calculus;mathematics;algorithm;morphism;category theory	Logic	0.21383094907078878	16.905154724853354	42163
9560027dd4c24c296a3771b790ddc262753d2255	tabu search with feasible and infeasible searches for equitable coloring		The equitable coloring problem is a variant of the classical graph coloring problem that arises from a number of real-life applications where the cardinality of color classes must be balanced. In this paper, we present a highly effective hybrid tabu search method for the problem. Based on three complementary neighborhoods, the algorithm alternates between a feasible local search phase where the search focuses on the most relevant feasible solutions and an infeasible local search phase where a controlled exploration of infeasible solutions is allowed by relaxing the equity constraint. A novel cyclic exchange neighborhood is also proposed in order to enhance the search ability of the hybrid tabu search algorithm. Experiments on a set of 73 benchmark instances in the literature indicate that the proposed algorithm is able to find improved best solutions for 15 instances (new upper bounds) and matches the best-known solutions for 57 instances. Additional analyses show the interest of the cyclic exchange neighborhood and the hybrid scheme combining both feasible and infeasible local searches.	analysis of algorithms;benchmark (computing);computation;equitable coloring;graph coloring;local search (optimization);matching (graph theory);real life;search algorithm;tabu search	Wenyu Wang;Jin-Kao Hao;Qinghua Wu	2018	Eng. Appl. of AI	10.1016/j.engappai.2018.01.012	artificial intelligence;mathematical optimization;equitable coloring;cardinality;machine learning;tabu search;computer science;local search (optimization);graph coloring	AI	23.93562248058075	4.58721665946062	42173
0fd86e2f99cdff916a3d3253d9988aef1b67a49b	the ultrametric constraint and its application to phylogenetics	phylogenetic tree;most recent common ancestor;constraint programming;rooted tree;lower bound	A phylogenetic tree shows the evolutionary relationships among species. Internal nodes of the tree represent speciation events and leaf nodes correspond to species. A goal of phylogenetics is to combine such trees into larger trees, called supertrees, whilst respecting the relationships in the original trees. A rooted tree exhibits an ultrametric property; that is, for any three leaves of the tree it must be that one pair has a deeper most recent common ancestor than the other pairs, or that all three have the same most recent common ancestor. This inspires a constraint programming encoding for rooted trees. We present an efficient constraint that enforces the ultrametric property over a symmetric array of constrained integer variables, with the inevitable property that the lower bounds of any three variables are mutually supportive. We show that this allows an efficient constraint-based solution to the supertree construction problem. We demonstrate that the versatility of constraint programming can be exploited to allow solutions to variants of the supertree construction problem.	constraint programming;most recent common ancestor;phylogenetic tree;phylogenetics;supertree;tree (data structure);while	Neil C. A. Moore;Patrick Prosser	2008	J. Artif. Intell. Res.	10.1613/jair.2580	mathematical optimization;constraint programming;combinatorics;phylogenetic tree;supertree;most recent common ancestor;computer science;computational phylogenetics;tree rearrangement;k-ary tree;tree structure;upper and lower bounds;algorithm	AI	17.880145505254117	22.006578151050093	42192
d0c421ad4a2abb089dcc84b600ee100cb0f3bad4	learning first-order definite theories via object-based queries	query type;object-based query;pairing query;exact learning;first-order concept;first-order definite theory;imperfect teacher;new query type;membership query;equivalence query;human teacher	We study the problem of exact learning of first-order definite theories via queries, toward the goal of allowing humans to more efficiently teach first-order concepts to computers. Prior work has shown that first order Horn theories can be learned using a polynomial number of membership and equivalence queries [6]. However, these query types are sometimes unnatural for humans to answer and only capture a small fraction of the information that a human teacher might be able to easily communicate. In this work, we enrich the types of information that can be provided by a human teacher and study the associated learning problem from a theoretical perspective. First, we consider allowing queries that ask the teacher for the relevant objects in a training example. Second, we examine a new query type, called a pairing query, where the teacher provides mappings between objects in two different examples. We present algorithms that leverage these new query types as well as restrictions applied to equivalence queries to significantly reduce or eliminate the required number of membership queries, while preserving polynomial learnability. In addition, we give learnability results for certain cases of imperfect teachers. These results show, in theory, the potential for incorporating object-based queries into first-order learning algorithms in order to reduce human teaching effort.	algorithm;automated theorem proving;computer;first-order predicate;learnability;machine learning;object-based language;polynomial;query language;theory;turing completeness	Joseph Selman;Alan Fern	2011		10.1007/978-3-642-23808-6_11	artificial intelligence;theoretical computer science;machine learning;data mining;mathematics;algorithm;spatial query	AI	4.316419033074959	17.422113670270903	42202
4bc12a14e5ca50065db84fe72fc9dea0e67f5aa7	the product replacement algorithm is polynomial	symbol manipulation;heuristic;gap;state of the art analytic technique;group algebra packages;random component;random group elements;heuristic programming;random number generation;magma;polynomials mathematics heuristic algorithms algebra packaging upper bound costs random number generation nearest neighbor searches tail;group algebra;product replacement algorithm;group theory;polynomials;upper bound;graph connectivity;polynomial upper bound;random walk;generating spl kappa tuples;polynomial bounds;polynomial upper bound product replacement algorithm heuristic random group elements random walk generating spl kappa tuples random component group algebra packages gap magma graph connectivity state of the art analytic technique polynomial bounds sub exponential bounds;symbol manipulation random number generation heuristic programming group theory polynomials;sub exponential bounds	The product replacement algorithm is a heuristic designed to generate random group elements. The idea is to run a random walk on generating k-tuples of the group, and then output a random component. The algorithm was designed by Leedham-Green and Soicher ([31]), and further investigated in [12]. It was found to have an outstanding performance, much better than the the previously known algorithms (see [12, 22, 26]). The algorithm is now included in two major group algebra packages GAP [42] and MAGMA [10]. In spite of the many serious attempts and partial results, (see [6, 14, 15, 21, 22, 32, 39, 40]), the analysis of the algorithm remains difficult at best. For small values of k even graph connectivity becomes a serious obstacle (see [19, 37, 39, 40]). The most general results are due to Diaconis and Saloff–Coste [22], who used a state of the art analytic technique to obtain polynomial bounds in special cases, and (sub)-exponential bounds in general case. The main result of this paper is a polynomial upper bound for the cost of the algorithm, provided k is large enough.	connectivity (graph theory);freedman–diaconis rule;heuristic;magma;page replacement algorithm;polynomial	Igor Pak	2000		10.1109/SFCS.2000.892135	mathematical optimization;combinatorics;discrete mathematics;heuristic;random number generation;connectivity;group algebra;mathematics;magma;upper and lower bounds;group theory;random walk;algorithm;statistics;polynomial;algebra	Theory	19.455879799881775	21.76174328914508	42211
41c6cc510735f1cc8e43faf9d0600e11e84495f0	how hard are n2-hard problems?	quadratic time;limited nondeterminism;hardest problems solvable;sharply-bounded quantifiers;n2-hard problem	"""Many of the """"n2-hard"""" problems described by Gajentaan and Overmars can be solved using limited nondeterminism or other sharply-bounded quantifiers. Thus we suggest that problems are not among the hardest problems solvable in quadratic time"""	bounded quantifier;decision problem;time complexity	Stephen A. Bloch;Jonathan F. Buss;Judy Goldsmith	1994	SIGACT News	10.1145/181462.181465	combinatorics;calculus;mathematics;algorithm	Theory	7.064819861471705	19.715174181161576	42238
a04a7f7d161b0252423a2db7f287c4796fe6d45f	improving space efficiency with path length prediction for finding $k$  shortest simple paths	mathematics of computing;graph theory;analysis of algorithms and problem complexity;path and circuit problems;discrete mathematics;geometrical problems and computations;theory of computation;nonnumerical algorithms and problems;computations on discrete structures;graph algorithms	Finding \mbi k shortest simple paths in a directed graph is a fundamental problem in many engineering applications. Most existing algorithms such as Yen's algorithm and its variants have polynomial worst-case time complexity, but their average-case running time is very high. The heuristic algorithm MPS can run significantly faster in practice. However, it requires an excessive amount of memory space. In this paper, we provide a new heuristic algorithm that achieves high space efficiency while maintaining similar average-case running time. We first propose a sidetrack representation of path, with which a path can be stored in \mbi O(1) space. We then show how to categorize a candidate path as either partial or complete, and restrict the number of paths added to the queue. In addition, we provide an empirical equation that can very accurately predict the \mbi kth shortest path length, provided that a much smaller number of shortest paths have been found. Extensive experiments prove that our algorithm can achieve an \mbi O(n) speedup in practice over Yen's algorithm. In comparison with MPS, it runs up to three times faster and uses less space by an order of magnitude.	algorithm;best, worst and average case;categorization;combinatorial optimization;dspace;depth-first search;directed graph;experiment;heuristic (computer science);mps (format);mathematical optimization;out of memory;path (graph theory);polynomial;routing;shortest path problem;speedup;time complexity;worst-case scenario	Gang Feng	2014	IEEE Transactions on Computers	10.1109/TC.2013.136	mathematical optimization;combinatorics;discrete mathematics;theory of computation;graph theory;yen's algorithm;mathematics;k shortest path routing;algorithm	DB	19.88672979213586	21.341974024382985	42472
044997d92fa1de1a2898a0a72bc056eb877ebd9e	finding best swap edges minimizing the routing cost of a spanning tree	settore inf 01 informatica	Given an n-node, undirected and 2-edge-connected graph G=(V,E) with positive real weights on its m edges, given a set of k source nodes S⊆V, and given a spanning tree T of G, the routing cost from S of T is the sum of the distances in T from every source s∈S to all the other nodes of G. If an edge e of T undergoes a transient failure, and one needs to promptly reestablish the connectivity, then to reduce set-up and rerouting costs it makes sense to temporarily replace e by means of a swap edge, i.e., an edge in G reconnecting the two subtrees of T induced by the removal of e. Then, a best swap edge for e is a swap edge which minimizes the routing cost from S of the tree obtained after the swapping. As a natural extension, the all-best swap edges problem is that of finding a best swap edge for every edge of T, and this has been recently solved in O(mn) time and linear space. In this paper, we focus our attention on the relevant cases in which k=O(1) and k=n, which model realistic communication paradigms. For these cases, we improve the above result by presenting an $\widetilde{O}(m)$ time and linear space algorithm. Moreover, for the case k=n, we also provide an accurate analysis showing that the obtained swap tree is effective in terms of routing cost. Indeed, if the input tree T has a routing cost from V which is a constant-factor away from that of a minimum routing-cost spanning tree (whose computation is a problem known to be in APX), and if in addition nodes in T enjoys a suitable distance stretching property from a tree centroid (which can be constructively induced, as we show), then the tree obtained after the swapping has a routing cost from V which is still a constant-ratio approximation of that of a new (i.e., in the graph deprived of the failed edge) minimum routing-cost spanning tree.	apx;algorithm;approximation;computation;connectivity (graph theory);file spanning;graph (discrete mathematics);paging;routing;spanning tree;tree (data structure)	Davide Bilò;Luciano Gualà;Guido Proietti	2012	Algorithmica	10.1007/s00453-012-9674-y	mathematical optimization;combinatorics;minimum degree spanning tree;spanning tree;computer science;minimum spanning tree;k-ary tree;k-minimum spanning tree;mathematics;distributed minimum spanning tree;algorithm;shortest-path tree	Theory	20.871558104849587	24.087286039744118	42490
31634c36ff79316b062774f00cef57a51bde3fa8	on the complexity of combinatorial and metafinite generating functions of graph properties in the computational model of blum, shub and smale	quadratic programming;counting function;programmation quadratique;geometrie algorithmique;computer model;computational geometry;complejidad programa;optimisation combinatoire;construction graphe;multivariate polynomial;complexity class;informatique theorique;polynomial time;generating function;programacion cuadratica;geometria computacional;program complexity;combinatorial optimization;graph construction;construccion grafo;complexite programme;optimizacion combinatoria;computer theory;informatica teorica	We present a uniied framework for the study of the complexity of counting functions and multivariate polynomials such as the permanent and the hamiltonian in the computational model of Blum, Shub and Smale. For PI R we introduce complexity classes GenPI R and CGenPI R: The class GenPI R consists of the generating functions for graph properties (decidable in polynomial time) rst studied in the context of Valiant's VNP by B urgisser. CGenPI R is an extension of GenPI R where the graph properties may be subject to numeric constraints. We show that GenPI R CGenPI R EXPTI R and exhibit complete problems for each of these classes. In particular, for (n n) matrices M over IR, ham(M) is complete for GenPI R, but the exact complexity of per(M) 2 GenPI R remains open. Complete problems for CGenPI R are obtained by converting optimization problems which are hard to approximate, as studied by Zuckerman, into corresponding generating functions. Finally, we enlarge once more the class of generating functions by allowing additionally a kind of non-combinatorial counting. This results in a function class Met-GenPI R for which we also give a complete member: evaluating a polynomial in the zeros of another one and summing up the results. The class Met-GenPI R is also a generalization of ]PI R, introduced by Meer, Mee97]. Due to lack of space we will prove here only the Met-GenPI R result. In the full paper also the other theorems will be established rigorously.	approximation algorithm;blum blum shub;blum axioms;complexity class;computation;computational model;graph property;hamiltonian (quantum mechanics);mathematical optimization;polynomial;time complexity	Johann A. Makowsky;Klaus Meer	2000		10.1007/3-540-44622-2_27	time complexity;complexity class;generating function;combinatorics;computational geometry;combinatorial optimization;computer science;artificial intelligence;machine learning;mathematics;quadratic programming;algorithm;statistics	AI	15.70231619108918	19.968938550501626	42525
dde530d8d4e1ea297a04acccd50ac511c5fc54a1	realistic parallel algorithms: priority queue operations and selection for the bsp model	parallel algorithm;data type;priority queue;parallel implementation;optimal algorithm;data structure	In this paper, we explore parallel implementations of the abstract data type priority queue. We use the BSP* model, an extension of Valiant's BSP model which rewards blockwise communication, i.e. sending a few large messages instead of many small ones. We present two randomized approaches for diierent relations between the size of the data structure and the number of parallel updates to be performed. Both yield work optimal algorithms that need asymptotically less communication than computation time and use large messages. All previous work optimal algorithms need asymptotically as much communication as computation or do not consider blockwise communication. We use a work optimal randomized selection algorithm as a building block. This might be of independent interest. It uses less communication than computation time, if the keys are distributed at random. A similar selection algorithm was independently developed by Gerbessiotis and Siniolakis for the standard BSP model. We improve upon previous work by both reducing the amount of communication and by using large messages.	abstract data type;computation;data structure;parallel algorithm;priority queue;randomized algorithm;selection algorithm;time complexity	Armin Bäumker;Wolfgang Dittrich;Friedhelm Meyer auf der Heide;Ingo Rieping	1996		10.1007/BFb0024725	priority inheritance;double-ended queue;parallel computing;real-time computing;data structure;data type;double-ended priority queue;computer science;distributed computing;parallel algorithm;fork–join queue;programming language;priority queue;bulk synchronous parallel	PL	11.114048769030049	31.39922381329232	42537
220d758a62473f5ec14c55321b0dfbbf9b31d621	a parallel algorithm for finding congruent regions	algoritmo paralelo;vision ordenador;modele geometrique;parallel algorithm;shared memory;multiprocessor;time complexity;geometrie algorithmique;memoria compartida;communicating process;sistema informatico;computational geometry;transmission message;computer system;message transmission;algorithme parallele;computer vision;proceso comunicante;congruencia;complexite temps;processus communicant;geometria algoritmica;vision ordinateur;systeme informatique;multiprocesador;complejidad tiempo;congruence;memoire partagee;geometrical model;transmision mensaje;multiprocesseur;modelo geometrico	-In this paper, we study the problem for finding all the regions, which are congruent to a testing region R, in an input planar figure F. In a shared memory system with m processors, we propose an el~cient MAX { O(mn), O(n log n)} time parallel algorithm, where n, m are the numbers of edges of F and R, respectively. Furthermore, our algorithm does not require to read from or write into the same memory location simultaneously, hence it can be implemented on an exclusive-read, exclusive-write (EREW) model. I. I N T R O D U C T I O N Finding the congruent regions among geometric objects is a popular topic in computational geometry. In general, this problem arises in pattern recognition, computer vision, etc. Recently, some researchers have devoted themselves to investigating this problem [ 1-4]. Roughly speaking, two planar regions R and S are congruent if there exists a mapping, including a proper geometrical translation and/or rotation, which makes R onto S. A formal definition will be given in Section 2. In [3], they defined the congruent regions finding problem as follows: Given a planar figure F and a testing region R, determine whether R is congruent to any region of F, and then find all of them if they indeed exist. Figure 1 shows an example of this finding problem. Only the shadow regions bounded by edges (v0, 17) , (1.)7, 1)8) , ( 1 8 , 1)9) , ( I )9, V0) and bounded by (vl, v2), (v2, v3), (v3, v4), (v4, vl) are congruent to the testing region R. The value labeled with each edge represents the length of that edge. The investigation of VLSI technology has made progress in parallel operation that reveals a high degree of parallelism in multiprocessor systems. Basically, there are two different architectural models for multiprocessor systems. One of them is a tightly-coupled system where communication is through a shared memory. Thus, we also say that this system is a sharedmemory multiprocessor system. The other one is a loosely-coupled system where communication is done via an interconnection network, that is, this is a message-passing multiprocessor system. In a shared-memory parallel system, each processor can read from or write into any memory location, depending on whether concurrent read from or concurrent write into a memory is allowed or not. Therefore, a shared-memory parallel system can be further divided into the following four models: 1. Exclusive-Read, Exclusive-Write (EREW) model. No two processors are allowed to read from or write into the same memory location simultaneously. 2. Concurrent-Read, Exclusive-Write (CREW) model. * This work was supported in pan by the National Science Council of the Republic of China under Grant NSC 81-0416E-002-20. Processors are allowed to read from the same memory location, but no two processors are allowed to write into the same memory location simultaneously. 3. Exclusive-Read, Concurrent-Write (ERCW) model. Processors are allowed to write into the same memory location but no two processors are allowed to read from the same memory location simultaneously. 4. Concurrent-Read, Concurrent-Write (CRCW) model. Multiple processors are allowed to read from and write into the same memory location simultaneously. Among the schemes[ 1-4] mentioned above, only the method proposed in [ 3 ] adopts a parallel approach to solve this problem. In this paper, we propose a method rather in EREW model than in CREW model to find the congruent regions. Our algorithm requires only MAX { O(mn), O(n log n) } computation time, where n, m are the numbers of edges of the input planar figure F and the testing region R, respectively. Furthermore, Shih, Lee, and Yang's[3] results may contain some repetitive congruent regions. In our algorithm, we have solved this problem. The rest of this paper is organized as follows: In Section 2~ some essential definitions and notations of the geometric objects are described. In Section 3, we propose an efficient parallel algorithm for finding the congruent regions and analyze the time complexity. Finally, concluding remarks are given in Section 4. 2. P R E L I M I N A R I E S Before we embark on our study of an efficient parallel algorithm for finding congruent regions based on a shared-memory system, we first give some definitions, notations, and properties of the geometric objects. A graph G = (V, E) consists of a set V of elements called vertices and a set E of unordered pairs of members of V called edges. The vertices of the graph are shown as points, while the edges are shown as lines connecting pairs of points. The edge between the pair of vertices Va and vb is denoted by (va, v~). Here, we call the vertices va and Vb the endpoints of the edge (va, vb), and we say the edge (va, vh) is incident with the vertices va and v~. In addition, if an edge does not	central processing unit;computation;computational geometry;computer vision;degree of parallelism;exclusive or;graph (discrete mathematics);interconnection;max;memory address;message passing;multiprocessing;national supercomputer centre in sweden;parallel algorithm;parallel computing;parallel random-access machine;pattern recognition;shared memory;time complexity;vertex (graph theory);very-large-scale integration;virtual appliance	Chin-Laung Lei;Horng-Twu Liaw	1992	Computers & Graphics	10.1016/0097-8493(92)90006-H	time complexity;shared memory;multiprocessing;computational geometry;computer science;artificial intelligence;congruence;geometry;parallel algorithm;algorithm	Theory	18.384715925688628	29.24733757029275	42601
0b258247f3e85a176f1ed521a4adcbc555c2d380	on conditional branches in optimal decision trees	optimising compilers;fundamental programming abstraction;dynamic programming;microprocessors;decision tree;cost function;computational complexity decision trees dynamic programming microprocessor chips optimising compilers statistical distributions trees mathematics;decoding;dynamic programming algorithm;microprocessor operation;testing;trees mathematics;huffman codes;binary trees;computer architecture;conditional branch;statistical distributions;decision trees binary trees microprocessors switches dynamic programming testing probability distribution cost function heuristic algorithms decoding;computational complexity;heuristic algorithms;probability distribution;lookup table;performance bounds;trees mathematics computational complexity decision trees dynamic programming microprocessor chips optimising compilers statistical distributions;optimal alphabetic decision trees conditional branch fundamental programming abstraction probability distribution microprocessor operation space dynamic programming algorithm huffman codes decoding;switches;decision trees;fixed interval;encoding;program processors;decoding optimal alphabetic decision trees conditional branch fundamental programming abstraction probability distribution microprocessor operation space dynamic programming algorithm huffman codes;information theory;space dynamic programming algorithm;optimal alphabetic decision trees;microprocessor chips;binary tree	"""The decision tree is one of the most fundamental programming abstractions. A commonly used type of decision tree is the alphabetic binary tree, which uses (without loss of generality) """"less than"""" versus """"greater than or equal to"""" tests in order to determine one of n outcome events. The process of finding an optimal alphabetic binary tree for a known probability distribution on outcome events usually has the underlying assumption that the cost (time) per decision is uniform and thus independent of the outcome of the decision. This assumption, however, is incorrect in the case of software to be optimized for a given microprocessor, e.g., in compiling switch statements or in fine-tuning program bottlenecks. The operation of the microprocessor generally means that the cost for the more likely decision outcome can or will be less - often far less -than the less likely decision outcome. Here we formulate a variety of O(n3)-time O(n2)-space dynamic programming algorithms to solve such optimal binary decision tree problems, optimizing for the behavior of processors with predictive branch capabilities, both static and dynamic. In the static case, we use existing results to arrive at entropy-based performance bounds. Solutions to this formulation are often faster in practice than """";optimal""""; decision trees as formulated in the literature, and, for small problems, are easily worth the extra complexity in finding the better solution. This can be applied in fast implementation of decoding Huffman codes."""	algorithm;binary tree;bottleneck (software);central processing unit;code;compiler;decision tree learning;dynamic programming;huffman coding;microprocessor;switch statement	Michael B. Baer	2007	2007 IEEE International Symposium on Information Theory	10.1109/ISIT.2007.4557264	probability distribution;optimal decision;decision tree model;binary tree;decision tree learning;information theory;computer science;theoretical computer science;machine learning;decision tree;dynamic programming;incremental decision tree;mathematics;programming language;algorithm;weighted sum model;statistics;decision matrix	Theory	8.193449625459433	28.426183264575233	42635
888ee18f532c6648022e5233d655a71b9ab491ab	discovering best variable-length-don't-care patterns	algorithme rapide;dynamic programming;grafo aciclico;programacion dinamica;heuristic programming;index structure;chaine caractere;problema np duro;graphe acyclique;geometria variable;geometrie variable;variable length don t care vldc;acyclic graph;np hard problem;probleme np difficile;pattern matching;directed graph;fast algorithm;programmation heuristique;cadena caracter;graphe oriente;directed acyclic word graph;programmation dynamique;variable geometry;grafo orientado;appariement chaine;concordance forme;dy namic programming;string matching;algoritmo rapido;character string	A variable-length-don’t-care pattern (VLDC pattern) is an element of set Π = (Σ ∪{ })∗, where Σ is an alphabet and is a wildcard matching any string in Σ∗. Given two sets of strings, we consider the problem of finding the VLDC pattern that is the most common to one, and the least common to the other. We present a practical algorithm to find such best VLDC patterns exactly, powerfully sped up by pruning heuristics. We introduce two versions of our algorithm: one employs a pattern matching machine (PMM) whereas the other does an index structure called the Wildcard Directed Acyclic Word Graph (WDAWG). In addition, we consider a more generalized problem of finding the best pair 〈q, k〉, where k is the window size that specifies the length of an occurrence of the VLDC pattern q matching a string w. We present three algorithms solving this problem with pruning heuristics, using the dynamic programming (DP), PMMs and WDAWGs, respectively. Although the two problems are NP-hard, we experimentally show that our algorithms run remarkably fast.	algorithm;directed acyclic graph;dynamic programming;experiment;heuristic (computer science);np-hardness;pattern matching;regular expression	Shunsuke Inenaga;Hideo Bannai;Ayumi Shinohara;Masayuki Takeda;Setsuo Arikawa	2002		10.1007/3-540-36182-0_10	combinatorics;discrete mathematics;directed graph;string;computer science;artificial intelligence;dynamic programming;pattern matching;np-hard;mathematics;programming language;directed acyclic word graph;directed acyclic graph;algorithm;string searching algorithm	DB	15.511339907160744	26.965520980255416	42773
774fdd618a68317dda3b5e6d0f42f88d99064bb1	iterative devices generating infinite words	iterative gsm;dol sequences;infinite word;infinite words;iterative generators;tag devices	We consider various TAG-like devices that generate one-way infinite words in real time. The simplest types of these devices are equivalent to iterative morphisms (also called substitutions), automatic sequences and iterative DGSM’s. We consider also a few new types. Mainly we study the comparative power of these mechanisms and develop some techniques for proving that certain devices cannot produce a particular infinite word.	iterative method	Karel Culik;Juhani Karhumäki	1994	Int. J. Found. Comput. Sci.	10.1142/S0129054194000050	discrete mathematics;computer science;theoretical computer science;algorithm	Logic	-1.4825595151798703	18.419559184729486	42781
25ad5740b3ca5009046c1140af22f13b325d1f6f	guessing secrets efficiently via list decoding	list decoding;partial information;20 questions;epsis;error correcting codes;error correction code;biased spaces;k universal sets;decoding algorithms	We consider the guessing secrets problem defined by Chung et al. [2001]. This is a variant of the standard 20 questions game where the player has a set of k > 1 secrets from a universe of N possible secrets. The player is asked Boolean questions about the secret. For each question, the player picks one of the k secrets adversarially, and answers according to this secret.  We present an explicit set of O(log N) questions together with an efficient (i.e., poly(log N) time) algorithm to solve the guessing secrets problem for the case of 2 secrets. This answers the main algorithmic question left unanswered by Chung et al. [2001]. The main techniques we use are small &epsis;-biased spaces and the notion of list decoding.  We also establish bounds on the number of questions needed to solve the k-secrets game for k > 2, and discuss how list decoding can be used to get partial information about the secrets, specifically to find a small core of secrets that must intersect the actual set of k secrets.	algorithm;error guessing;list decoding;time complexity	Noga Alon;Venkatesan Guruswami;Tali Kaufman;Madhu Sudan	2002	ACM Trans. Algorithms	10.1145/1290672.1290679	list decoding;error detection and correction;computer science;theoretical computer science;mathematics;algorithm	Theory	9.847002646052822	24.736424418509223	42915
a5f0db4532e5d409222bd8ea2e8dcd40458ead31	clustered elias-fano indexes	inverted indexes;performance;elias fano encoding	State-of-the-art encoders for inverted indexes compress each posting list individually. Encoding clusters of posting lists offers the possibility of reducing the redundancy of the lists while maintaining a noticeable query processing speed.  In this article, we propose a new index representation based on clustering the collection of posting lists and, for each created cluster, building an ad hoc reference list with respect to which all lists in the cluster are encoded with Elias-Fano. We describe a posting lists clustering algorithm tailored for our encoder and two methods for building the reference list for a cluster. Both approaches are heuristic and differ in the way postings are added to the reference list: according to their frequency in the cluster or according to the number of bits necessary for their representation.  The extensive experimental analysis indicates that significant space reductions are indeed possible, beating the best state-of-the-art encoders.	acm transactions on information systems;alexander stepanov;algorithm;approximation algorithm;bibliographic index;byte;cluster analysis;database;encoder;fano's inequality;heuristic;hoc (programming language);overhead (computing);reference architecture;simd;selection algorithm;space–time tradeoff	Giulio Ermanno Pibiri;Rossano Venturini	2017	ACM Trans. Inf. Syst.	10.1145/3052773	redundancy (engineering);encoder;difference list;information retrieval;data mining;fold (higher-order function);cluster analysis;encoding (memory);computer science;heuristic;fano plane	Web+IR	8.253757471072996	31.195772271173833	43025
5450e83aa61da292a1d3b571e9651e08390b4c6c	due date assignments and scheduling a single machine with a general earliness/tardiness cost function	metodo polinomial;assignment problem;continuous function;temps polynomial;single machine scheduling;cost function;machine unique;gestion production;fonction continue;date echeance;funcion coste;fonction objectif;production management;objective function;polynomial time algorithm;due date assignment;single machine;maquina unica;funcion penalidad;funcion continua;polynomial method;scheduling;gestion produccion;due date;polynomial time;fonction cout;fecha vencimiento;funcion objetivo;fonction penalite;methode polynomiale;polynomial time algorithms;ordonnancement;reglamento;penalty function;tiempo polinomial	We study three different due date assignment problems in scheduling a single machine which differ from each other based upon the objective function and due date assignment method being used. Two different objective functions are considered. The first is a cost function that includes earliness, tardiness and due date assignment penalties and the second is a function that includes penalties due to the number of tardy jobs and due date assignments. We assume that the earliness, tardiness and due date assignment penalties are continuous and non-decreasing functions of the corresponding duration. The goal is to minimize each objective function for two different due date assignment methods. The first is a method in which the assigned due dates are restricted to be equal while the second is a method that allows us to assign different due dates to different jobs.	loss function;scheduling (computing)	Dvir Shabtay	2008	Computers & OR	10.1016/j.cor.2006.08.017	continuous function;time complexity;mathematical optimization;computer science;penalty method;mathematics;assignment problem;scheduling;algorithm	Arch	16.966008277406235	9.966314698618	43038
f051fedef4dbc4f71be86e443c5014b9c3daa347	optimal network topologies for mitigating security and epidemic risks		We consider networked environments under security and epidemic risks, where the probability of successful attack or infection at each vertex depends on the actions or states of its neighbors. In such settings, we consider the problem of designing an optimal network topology with a given number of vertices and edges in order to minimize the expected fraction of attacked or infected vertices. We show that such problems can be cast as minimizing the sum of a concave function of the vertex degrees, and generalize existing results on network design to obtain insights about the optimal network topologies. We first consider a class of interdependent security games where each vertex represents a user that invests in security to protect herself. The probability of successful attack at any given vertex is a function of the security investments in the neighborhood of that vertex. We introduce the notion of behavioral risk-attitudes, where each user perceives the security risks in a skewed manner (as prescribed by established models from the behavioral economics literature). We characterize an upper bound on the expected number of vertices that are successfully attacked under the Nash equilibrium security investments in such settings, and identify the network topologies that minimize this bound. We then consider the N-intertwined approximation of SIS epidemic dynamics, and characterize graphs that minimize (bounds on) the fraction of infected vertices in steady state.	approximation;concave function;interdependence;nash equilibrium;network planning and design;network topology;steady state;vertex (geometry);vertex (graph theory)	Ashish R. Hota;Shreyas Sundaram	2016	2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton)	10.1109/ALLERTON.2016.7852362	mathematical optimization;combinatorics;discrete mathematics;mathematics	ECom	-3.6665622332450147	5.169546764835565	43100
050d119f56306217500cfd17e95442c54a8e935b	fixed-parameter evolutionary algorithms and the vertex cover problem	evolutionary algorithms;fixed-parameter tractability;vertex cover;randomized algorithms	In this paper, we consider multi-objective evolutionary algorithms for the Vertex Cover problem in the context of parameterized complexity. We relate the runtime of our algorithms to the input size and the cost of a minimum solution and point out that the search process of evolutionary algorithms creates partial solutions that are similar to the effect of a kernelization (i.e. a special type of preprocessing from parameterized complexity). Based on this, we show that evolutionary algorithms solve the vertex cover problem efficiently if the size of a minimum vertex cover is not too large, i.e. the expected runtime is bounded by O(f(OPT) nc), where c is a constant and f a function that only depends on OPT. This shows that evolutionary algorithms are randomized fixed-parameter tractable algorithms for the vertex cover problem.	cobham's thesis;evolutionary algorithm;information;kernelization;parameterized complexity;preprocessor;randomized algorithm;vertex cover	Stefan Kratsch;Frank Neumann	2009	Algorithmica	10.1007/s00453-012-9660-4	mathematical optimization;combinatorics;discrete mathematics;feedback vertex set;vertex cover;edge cover;mathematics;kernelization;approximation algorithm;memetic algorithm	Theory	21.34309527371979	18.33403761861879	43122
25072501bdc0675bbd245bdd06245c210cde1b8a	maximum independent sets in subclasses of p5-free graphs	conjunto independiente;complexite;graphe minimal;procesamiento informacion;subgrafo;maximo;temps polynomial;algorithm analysis;independent set;complejidad;maximum;complexity;polynomial;68wxx;grafo minimo;qa76 electronic computers computer science computer software;ensemble independant;sous graphe;informatique theorique;polinomio;68r10;information processing;polynomial time;graph algorithm;analyse algorithme;ensemble independant maximal;resolubilite;subgraph;algorithme graphe;traitement information;polynome;graph algorithms;solvability;p5 free graphs;analisis algoritmo;resolubilidad;minimal graph;computer theory;tiempo polinomial;maximum independent set;informatica teorica	"""The class of P""""5-free graphs is the unique minimal class defined by a single connected forbidden induced subgraph for which the complexity status of the maximum independent set problem is unknown. In this paper, we prove polynomial-time solvability of the problem in two subclasses of P""""5-free graphs generalizing several previously known results."""	independent set (graph theory)	Vadim V. Lozin;Raffaele Mosca	2009	Inf. Process. Lett.	10.1016/j.ipl.2008.11.005	combinatorics;discrete mathematics;independent set;information processing;computer science;mathematics;maximal independent set;induced subgraph isomorphism problem;chordal graph;indifference graph;algorithm	DB	21.65670112084761	27.222910791500652	43144
f6ceee2daffdeccb3787eb234b53e69024bb4aca	integration of genetic algorithm and gantt chart for job shop scheduling in distributed manufacturing systems	gantt chart;job shop scheduling;distributed manufacturing system;multiple objectives;scheduling problem;genetic algorithm;production scheduling;process planning	In a distributed manufacturing environment, jobs in a batch could usually be manufactured in several available factories and thus have multiple alternative process plans. This paper presents a new approach to determine good combinations of factories (process plans) to manufacture the jobs and in the meantime generate good operation schedules. A genetic algorithm (GA), integrated with Gantt chart (GC), is proposed to derive the factory combination and schedule. The integration of GA–GC is proved to be efficient in solving small-sized or medium-sized scheduling problems for a distributed manufacturing system. Multiple objectives can be achieved, including minimizing makespan, job tardiness, or manufacturing cost. An illustrative example is given to demonstrate and evaluate the performance of the GA–GC approach. 2007 Published by Elsevier Ltd.	computation;distributed manufacturing;gantt chart;genetic algorithm;job scheduler;job shop scheduling;job stream;outsourcing;schedule (computer science);scheduling (computing);software release life cycle	H. Z. Jia;Jerry Y. H. Fuh;Andrew Y. C. Nee;Yunfeng Zhang	2007	Computers & Industrial Engineering	10.1016/j.cie.2007.06.024	fair-share scheduling;job shop scheduling;mathematical optimization;real-time computing;genetic algorithm;flow shop scheduling;computer science;gantt chart;engineering;rate-monotonic scheduling;operations management;genetic algorithm scheduling;scheduling;engineering drawing	Robotics	12.222085676375503	4.551951847383075	43185
96eb422f5682cdea00f8d857325fd8b503373cdc	fast reoptimization for the minimum spanning tree problem	optimal solution;metric graph;reoptimization;approximate algorithm;approximation algorithms;minimum spanning tree;lower bound	Minimum spanning tree is a classical polynomial problem very well known in operational research and in theoretical computer science. In this paper, we settle the reoptimization versions of this problem, which can be formulated as follows: given an instance of the problem for which we already know some optimal solution, and given some “small” perturbations on this initial instance, is it possible to compute a new (optimal or at least near-optimal) solution for the modified instance without ex nihilo computation? We focus on two kinds of modifications: node-insertions and node-deletions. For the former type of modifications, where k new nodes are inserted together with their incident edges, we first propose a fast strategy with complexity O(kn) which provides a max{2, 3 − (2/(k − 1))}-approximation ratio, in complete metric graphs. We then devise a more elaborated strategy that computes optimal solutions in any graph with complexity O(kn log n). When k nodes are deleted, we devise a strategy which in O(n) achieves approximation ratio bounded above by 2⌈|Lmax|/2⌉ in complete metric graphs, where Lmax is the longest deleted path and |Lmax| is the number of its edges. For any of the approximation strategies, we also provide lower bounds on their approximation ratios.	approximation algorithm;bridging (networking);computation;file spanning;graph (discrete mathematics);maxima and minima;minimum spanning tree;operations research;polynomial;theoretical computer science	Nicolas Boria;Vangelis Th. Paschos	2010	J. Discrete Algorithms	10.1016/j.jda.2009.07.002	mathematical optimization;combinatorics;discrete mathematics;minimum spanning tree;mathematics;upper and lower bounds;approximation algorithm;algorithm	Theory	22.345110175040315	19.58097744424202	43239
16029a6c98412c63d78c876723d5814ef3e103d3	a trade-off between length and width in resolution		We describe a family of CNF formulas in n variables, with small initial width, which have polynomial length resolution refutations. By a result of Ben-Sasson and Wigderson it follows that they must also have narrow resolution refutations, of width O( √ n logn). We show that, for our formulas, this decrease in width comes at the expense of an increase in size, and any such narrow refutations must have exponential length.	conjunctive normal form;polynomial;resolution (logic);time complexity	Neil Thapen	2014	Electronic Colloquium on Computational Complexity (ECCC)	10.4086/toc.2016.v012a005	combinatorics;mathematics;trade-off	Theory	10.230575750982956	19.312118201106188	43495
a02d879e90ce2efbb87854893c34dbe391e6c71f	distribution-free testing for monomials with a sublinear number of queries		We consider the problem of distribution-free testing of the class of monotone monomials and the class of monomials over n variables. While there are very efficient testers for a variety of classes of functions when the underlying distribution is uniform, designing distribution-free testers (which must work under an arbitrary and unknown distribution) tends to be more challenging. When the underlying distribution is uniform, Parnas et al. (SIAM J. Discr. Math., 2002) give a tester for (monotone) monomials whose query complexity does not depend on n, and whose dependence on the distance parameter is (inverse) linear. In contrast, Glasner and Servedio (Theory of Computing, 2009) prove that every distribution-free tester for monotone monomials as well as for general monomials must have query complexity Ω̃(n1/5) (for a constant distance parameter ε). In this paper we present distribution-free testers for these classes with query complexity Õ(n1/2/ε). We note that in contrast to previous results for distribution-free testing, our testers do not build on the testers that work under the uniform distribution. Rather, we define and exploit certain structural properties of monomials (and functions that differ from them on a non-negligible part of the input space), which were not used in previous work on property testing. ACM Classification: F.2.2, G.2.0, G.3 AMS Classification: 68Q25, 68W20, 68W25, 68W40	acm computing classification system;decision tree model;monomial;property testing;theory of computing;monotone	Elya Dolev;Dana Ron	2011	Theory of Computing	10.4086/toc.2011.v007a011	combinatorics;discrete mathematics;mathematics;monomial basis;algorithm	Theory	14.028572347979487	20.432113787598016	43510
1d15c6c8058adbdf7d9938f8f406fcac94cddd69	graph searching, elimination trees, and a generalization of bandwidth	graph search;arbre graphe;grafo triangular;elimination tree;largeur bande;recherche graphe;relation ordre partiel;descomposicion grafo;algorithmique;tree graph;relacion orden;ordering;natural extension;graph searching;relation ordre;matrice creuse;algorithmics;algoritmica;partial ordering;anchura banda;graphe triangule;bandwidth;tree decomposition;treewidth;relacion orden parcial;anchura arbol;sparse matrix computation;arbre elimination;sparse matrix;arbol grafo;largeur arborescente;graph decomposition;matriz dispersa;decomposition graphe;chordal graph;partial order	The bandwidth minimization problem has a long history and a number of practical applications. In this paper we introduce a natural extension of bandwidth to partially ordered layouts. We consider this extension from three main viewpoints: graph searching, tree decompositions, and elimination orderings. The three graph parameters pathwidth, profile, and bandwidth related to linear layouts can be defined by variants of graph searching using a standard fugitive. Switching to an inert fugitive, the two former parameters are extended to treewidth and fill-in, and our first viewpoint considers the analogous tree-like extension that arises from the bandwidth variant. Bandwidth also has a definition in terms of ordered path decompositions, and our second viewpoint extends this in a natural way to ordered tree decompositions. In showing that both extensions are equivalent we employ the third viewpoint of elimination trees, as used in the field of sparse matrix computations. We call the resulting parameter the treespan of a graph and prove some of its combinatorial and algorithmic properties.	computation;graph bandwidth;pathwidth;sparse matrix;tree (data structure);treewidth	Fedor V. Fomin;Pinar Heggernes;Jan Arne Telle	2003	Algorithmica	10.1007/s00453-004-1117-y	partially ordered set;mathematical optimization;combinatorics;discrete mathematics;directed graph;graph bandwidth;mathematics;geometry;tree-depth;algorithmics;complement graph;algorithm;ordered graph;tree decomposition	ML	23.2686673851525	27.113122332800636	43514
c68cc66b65e3644c6b3a803c89d6a99236065e6f	an exact algorithm for the node weighted steiner tree problem	branch and bound algorithm;benchmark problem;exponential family;real world application;exact algorithm;steiner tree problem;complete graph	The Node Weighted Steiner Tree Problem (NW-STP) is a generalization of the Steiner Tree Problem. A lagrangean heuristic presented in Engevall et al. (1998), and based on the work in Lucena (1992), solves the problem by relaxing an exponential family of generalized subtour elimination constraints and taking into account only the violated ones as the computation proceeds. In Engevall et al. (1998) the computational results refer to complete graphs up to one hundred vertices. In this paper, we present a branch-and-bound algorithm based on this formulation. Its performance on the instances from the literature confirms the effectiveness of the approach. The experimentation on a newly generated set of benchmark problems, more similar to the real-world applications, shows that the approach is still valid, provided that suitable refinements on the bounding procedures and a preprocessing phase are introduced. The algorithm solves to optimality all of the considered instances up to one thousand vertices, with the exception of 11 hard instances, derived from the literature of a similar problem, the Prize Collecting Steiner Tree Problem.	benchmark (computing);branch and bound;computation;embedded system;exact algorithm;experiment;heuristic;netware;preprocessor;sparse matrix;steiner tree problem;time complexity;tree (data structure);vertex (geometry);vertex (graph theory)	Roberto Cordone;Marco Trubian	2006	4OR	10.1007/s10288-005-0081-y	mathematical optimization;combinatorics;discrete mathematics;exponential family;exponential tree;steiner tree problem;mathematics;complete graph;branch and bound	AI	24.5185927139255	7.090546679479643	43516
50f870b3a68720f89b6f06d8300823af4f995cbe	approximations of the mean waiting time in an m/g/s queueing system	waiting time;queueing system	This paper considers the problem of obtaining approximate expressions for the first moment WGs of the stationary waiting time distribution in an M/G/s queueing system. Special attention is paid to the case G ≡ D, i.e., constant service times. Most known approximations are in fact heavy traffic approximations which have rather large relative errors in the light traffic case. In the present study both the light traffic and heavy traffic behavior of WGs (WDs) are taken into account. In order to obtain mean waiting time approximations it appears to be useful to introduce a quantity (the “normed cooperation coefficient”) which is inversely proportional to WGs and which is in some sense a measure for the “cooperation” between the servers of the service facility. A part of the paper is devoted to the analysis of this normed cooperation coefficient.	approximation;queueing theory	Onno J. Boxma;J. W. Cohen;N. Huffels	1979	Operations Research	10.1287/opre.27.6.1115	simulation;operations management;mathematics;queueing theory;operations research	Metrics	8.388207637919244	11.01012609048394	43579
12cb65a99829511fb5c56c8ed5b1ec4aecc8af03	three aspects of super-recursive algorithms and hypercomputation or finding black swans	recursive algorithm		hypercomputation;recursion;super-recursive algorithm	Mark Burgin;Allen Klinger	2004	Theor. Comput. Sci.	10.1016/j.tcs.2003.12.001	computer science;theoretical computer science;mathematics;programming language;algorithm;recursion	ECom	0.8748990910653104	23.4567807667508	43594
57879458b3e56d74c7c28118a5c664bc759c471a	quantum lower bound for recursive fourier sampling	lower bounds;query complexity;quantum computing	We revisit the oft-neglected ‘recursive Fourier sampling’ (RFS) problem, introduced by Bernstein and Vazirani to prove an oracle separation between BPP and BQP. We show that the known quantum algorithm for RFS is essentially optimal, despite its seemingly wasteful need to uncompute information. This implies that, to place BQP outside of PH [log] relative to an oracle, one needs to go outside the RFS framework. Our proof argues that, given any variant of RFS, either the adversary method of Ambainis yields a good quantum lower bound, or else there is an efficient classical algorithm. This technique may be of independent interest. Subject classifications: quantum computing, lower bounds, query complexity.	adversary (cryptography);bpp (complexity);bqp;decision tree model;phil bernstein;quantum algorithm;quantum computing;recursion;remote file sharing;universal quantification	Scott Aaronson	2002	Quantum Information & Computation		combinatorics;discrete mathematics;bqp;mathematics;quantum computer;quantum algorithm;physics;algorithm;quantum mechanics	Theory	10.719996188735465	21.5470697039083	43601
83128a78e662accbeff637467447001de9647b34	computing exact minimum cuts without knowing the graph		We give query-efficient algorithms for the global min-cut and the s-t cut problem in unweighted, undirected graphs. Our oracle model is inspired by the submodular function minimization problem: on query S ⊂ V , the oracle returns the size of the cut between S and V \ S. We provide algorithms computing an exact minimum s-t cut in G with Õ(n) queries, and computing an exact global minimum cut of G with only Õ(n) queries (while learning the graph requires Θ̃(n) queries). UC Berkeley, aviad@eecs.berkeley.edu. This research was supported by Microsoft Research PhD Fellowship. It was also supported in part by NSF grant CCF1408635 and by Templeton Foundation grant 3966. This work was done in part at the Simons Institute for the Theory of Computing. UC Berkeley, tschramm@cs.berkeley.edu. Supported by an NSF Graduate Research Fellowship (1106400). Princeton University, smweinberg@princeton.edu. Supported by NSF CCF-1717899. Work done in part while the author was a Research Fellow at the Simons Instutute for the Theory of Computing.	algorithm;cut (graph theory);graph (discrete mathematics);ibm notes;keneth alden simons;maxima and minima;microsoft research;minimum cut;submodular set function;theory of computing;uc browser	Aviad Rubinstein;Tselil Schramm;S. Matthew Weinberg	2018		10.4230/LIPIcs.ITCS.2018.39	degree (graph theory);submodular set function;discrete mathematics;minimum cut;combinatorics;graph cuts in computer vision;oracle;strength of a graph;mathematics;graph	Theory	21.231830090539837	20.09206816116949	43603
2155fd93d05333a4b11a0acc1b48f365edf1a1d2	solvability of word equations modulo finite special and confluent string-rewriting systems is undecidable in general	palabra finita;formal languages;mot fini;unification;rewrite systems;word equations;reecriture;string rewriting;decidibilidad;rewriting;decidabilite;word equation;lenguaje formal;formal language;finite word;unificacion;reescritura;decidability;langage formel	Abstract A finite, special, and confluent string-rewriting system S is constructed such that it is undecidable in general whether a word equation is solvable modulo S . Thus, (word) unification modulo S is undecidable.	decision problem;modulo operation;rewriting;semi-thue system;undecidable problem	Friedrich Otto	1995	Inf. Process. Lett.	10.1016/0020-0190(94)00208-G	formal language;discrete mathematics;computer science;mathematics;word problem;algorithm;algebra	DB	-2.559123907428564	19.75128395573415	43637
5ad368ae9efb61567e0947dfc76d35cd1885721b	transient analysis of a queue with system disasters and customer impatience	time dependent;exponential distribution;impatient customers;server breakdown;transient analysis;single server queue;confluent hypergeometric function;30b70;60k25;transient probabilities;generating function;confluent hypergeometric functions;continued fraction;continued fractions	A single server queue with Poisson arrivals and exponential service times is studied. The system suffers disastrous breakdowns at an exponential rate, resulting in the loss of all running and waiting customers. When the system is down, it undergoes a repair mechanism where the repair time follows an exponential distribution. During the repair time any new arrival is allowed to join the system, but the customers become impatient when the server is not available for a long time. In essence, each customer, upon arrival, activates an individual timer, which again follows an exponential distribution with parameter ?. If the system is not repaired before the customer's timer expires, the customer abandons the queue and never returns. The time-dependent system size probabilities are presented using generating functions and continued fractions.		R. Sudhesh	2010	Queueing Syst.	10.1007/s11134-010-9186-x	continued fraction;real-time computing;simulation;computer science;mathematics;statistics	Metrics	8.335716906508505	10.391778471308855	43648
81776ec63153547d7a4ef3cc8bd7a993b0c83458	fuel economy analysis of a through-the-road hybrid electric vehicle	torque;ice vehicle fuel economy analysis through the road hybrid electric vehicle emission reduction rear in wheel motors iwm ttr hev design fuel consumption new european drive cycle nedc internal combustion engine;in wheel motors hybrid electric vehicle fuel economy through the road hev;in wheel motors;hybrid electric vehicles ice torque mathematical model fuel economy;fuel economy;hybrid electric vehicle;through the road hev;hybrid electric vehicles air pollution control fuel economy;mathematical model;hybrid electric vehicles;ice	Dwindling environmental condition and the steady increment in fuel prices are two of the biggest oppressing factors for governments and vehicle manufacturers to excavate for suitable fossil fuel alternatives to power the vehicles of the future. Among several candidates, hybrid electric vehicle (HEV) appears to be a robust solution which has enabled vast improvements both in fuel economy and reduction in emissions to comply with stringent environmental policies almost immediately. Through-the-road (TtR) HEV with rear in-wheel motors (IWM) as a fairly recent concept in HEV design offers simplified configuration at lower cost compared to conventional HEV. However this trait comes with a slight compromise to the overall vehicle performance. Advantages and disadvantages of the TtR HEV design over other conventional HEV configurations are compared and discussed. A mathematical model of a TtR HEV is developed and its performance in terms of fuel consumption over the new European drive cycle (NEDC) is observed and analyzed via simulation and pitted against normal internal combustion engine (ICE) vehicle. Simulation result shows significant improvement in fuel consumption.	fossil;integrated woz machine;mathematical model;simulation	M. F. M. Sabri;K. A. Danapalasingam;M. F. Rahmat;Md Ridzuan Md Yusof	2015	2015 10th Asian Control Conference (ASCC)	10.1109/ASCC.2015.7244721	battery electric vehicle;miles per gallon gasoline equivalent;engineering;aeronautics;automotive engineering;forensic engineering;green vehicle	EDA	4.168446057435558	9.46400958211834	43715
7a580073350c33f3c734dea46d655e922630bd81	gene tree reconciliation including transfers with replacement is hard and fpt		Phylogenetic trees illustrate the evolutionary history of genes and species. In most cases, although genes evolve along with the species they belong to, a species tree and gene tree are not identical, because of evolutionary events at the gene level like duplication or transfer. These differences are handled by phylogenetic reconciliation, which formally is a mapping between gene tree nodes and species tree nodes and branches. We investigate models of reconciliation with a gene transfer that replaces existing gene, which is a biological important event but never included in reconciliation models. Also the problem is close to a dated version of the classical subtree prune and regraft (SPR) distance problem, where a pruned subtree has to be regrafted only on a branch closer to the root. We prove that the reconciliation problem including transfer and replacement is NP-hard, and that if speciations and transfers with replacement are the only allowed evolutionary events, then it is fixed-parameter tractable (FPT) with respect to the reconciliation’s weight. We prove that the results extend to the dated SPR problem.	algorithm;ambiguous name resolution;cobham's thesis;computational complexity theory;dynamic programming;lateral computing;lateral thinking;linear algebra;np-hardness;parameterized complexity;phylogenetic tree;phylogenetics;sensor;simulation;symbolic computation;tree (data structure);tree rearrangement	Damir Hasic;Eric Tannier	2017	CoRR		tree (data structure);combinatorics;mathematics;phylogenetic tree;gene;gene duplication	Comp.	17.65514085037992	21.896096711024146	43774
8b744d0023f90082d1e52b9b5e652dd16be1a7c3	green computing wanted: electricity consumptions in the it industry and by household computers in five major chinese cities	data centers green computing electricity consumptions it industry household computers energy consumption;energy efficiency;computers;environmental factors;green products;power consumption computer centres energy consumption environmental factors;industries;green computing energy electricity consumption it industry household computers energy efficiency;computer centres;household computers;electricity industries computers green products cities and towns energy efficiency energy consumption;energy electricity consumption;energy consumption;it industry;cities and towns;electricity;power consumption;green computing	Exhausted energy consumption becomes a world-wide issue nowadays. Computing contributes a large portion of energy consumption. The concept of green computing has been popularized. Along with the rapid development of China, energy issue becomes more and more important. We believe that green computing would play a very important role in China. However, past publications mainly focused on electricity consumption in data centers, while there are other important sources of electricity consumption in computing. The concept of green computing should be also applied to these sources. In this paper, we present and analyze the data on the electricity consumptions in the IT industry (including the telecommunication and computer industries) and by household computers in five major Chinese cities during 2005-2009. The analysis will demonstrate the necessity of green computing in the IT industry and in household computers in China.	computer;data center	Luyang Wang;Tao Wang	2011	2011 IEEE/ACM International Conference on Green Computing and Communications	10.1109/GreenCom.2011.46	engineering;operations management;economy;commerce	HPC	2.392096567143929	9.134490203886413	43782
61226c61d12eeaed93a71384c621c840d9297ca3	hierarchical production management applied to an iron and steel industry	continuous casting;iron;simulated annealing;production management;steel industry;approximation scheme;scheduling problem;local search	A scheduling problem arising in the iron and steel industry is discussed. It concerns the medium planning and the short-term scheduling of three tools: continuous-casting, strip mill and finishing, these three belonging to the hot unit of an iron and steel company. The strip mill is more constrained than the other two, it is therefore called the pivot, the continuous-casting tool is called the upstream tool and the finishing tool is called the downstream tool. A hierarchical approach consisting of two levels is designed. At each level of this hierarchy, the pivot is scheduled first followed by the other tools under the constraints of the pivot schedule. Methods are proposed to solve scheduling problems arising from this approach. Each of the methods is an approximation scheme because of the NP-hardness of the scheduling problems. Some of the approximation schemes are local search methods (simulated annealing improved by some specific techniques), others are specific constructive methods built to solve given problems. An interesting criterion is the following: the schedule of the pivot being given, the schedule of the upstream tool must begin as late as possible and the schedule of the downstream must end as soon as possible in order to minimize the inventory cost between the tools while minimizing the other costs of manufacturing such as the number of profile changes, the number of block changes, etc. The pivot medium-term solving is the most developed part of this paper and it is tested on some generated examples; the generator description and the numerical results are presented.	approximation;downstream (software development);local search (optimization);np-hardness;numerical analysis;pivot table;scheduling (computing);simulated annealing	Marie-Claude Portmann;Dominique Rohr	1995	J. Intelligent Manufacturing	10.1007/BF00123679	job shop scheduling;mathematical optimization;simulated annealing;computer science;engineering;local search;iron;engineering drawing	AI	14.078936209975918	4.348860037992962	43815
01d3a212e91014a1db96573ef42d31f5aabf4252	applications metaheuristics for the vehicle routing problem with stochastic demands	parallelisme;algorithm performance;vehicle routing problem;localization;heuristic method;metodo heuristico;localizacion;probleme tournee vehicule;probabilistic approach;problema ruta vehiculo;approche deterministe;fonction objectif;permutation;busca local;deterministic approach;resolucion problema;objective function;parallelism;localisation;paralelismo;biomimetique;resultado algoritmo;enfoque probabilista;approche probabiliste;permutacion;enfoque determinista;performance algorithme;funcion objetivo;methode heuristique;local search;recherche locale;problem solving;resolution probleme;biomimetics	In the vehicle routing problem with stochastic demands a vehicle has to serve a set of customers whose exact demand is known only upon arrival at the customer’s location. The objective is to find a permutation of the customers (an a priori tour) that minimizes the expected distance traveled by the vehicle. Since the objective function is computationally demanding, effective approximations of it could improve the algorithms’ performance. For the problem under study, we show that a good choice is using the length of the a priori tour as a fast approximation of the objective, to be used in the local search of the several metaheuristics analyzed. We also show that for the instances tested, our metaheuristics find better solutions with respect to a known effective heuristic and with respect to solving the problem as two related deterministic problems.	approximation;experiment;heuristic;local search (optimization);loss function;metaheuristic;optimization problem;travelling salesman problem;vehicle routing problem	Leonora Bianchi;Mauro Birattari;Marco Chiarandini;Max Manfrin;Monaldo Mastrolilli;Luís Paquete;Olivia Rossi-Doria;Tommaso Schiavinotto	2004		10.1007/978-3-540-30217-9_46	biomimetics;mathematical optimization;internationalization and localization;computer science;artificial intelligence;local search;vehicle routing problem;mathematics;permutation;deterministic system;algorithm	ECom	20.150166202562914	6.310276205357273	43825
04fbcd0b99762ffa1cc15798f9cfcaa72089c40c	residential energy consumption controlling techniques to enable autonomous demand side management in future smart grid communications	optimal energy consumption scheduling;power generation control;home appliances energy consumption schedules smart grids load modeling optimal scheduling;domestic appliances;demand side management;peak load demand;smart grid;smart power grids;household appliances residential energy consumption controlling techniques demand side management smart grid communications home appliances scheduling power system power generation system economical generation information technology communication technology optimal energy consumption scheduling peak to average ratio par;smart power grids demand side management domestic appliances power consumption power generation control power generation economics power generation scheduling;power generation scheduling;power consumption;smart grid demand side management optimal energy consumption scheduling peak load demand;power generation economics	This paper presents an overview of home appliances scheduling techniques to implement demand side management in smart grid. Increasing demand of consumers have affected the power system badly as power generation system faces a number of challenges both in quality and quantity. Economical generation and efficient consumption can solve this problem in future smart grid as it is integrated with information and communication technologies. Smart grid has opportunities to employ different pricing schemes which help also in increasing the efficiency of appliances scheduling techniques. Optimal energy consumption scheduling minimizes the energy consumption cost and reduces the Peak-to-Average Ratio (PAR) as well as peak load demand. In this work, we discuss different energy consumption scheduling schemes that schedule the household appliances in real-time to achieve minimum energy consumption cost and reduce peak demand to shape the load curve.	autonomous robot;load profile;real-time clock;scheduling (computing)	M. N. Ullah;Nadeem Javaid;I. Khan;Anzar Mahmood;M. U. Farooq	2013	2013 Eighth International Conference on Broadband and Wireless Computing, Communication and Applications	10.1109/BWCCA.2013.94	real-time computing;load balancing;telecommunications;computer science;peak demand;dynamic demand;smart grid	EDA	3.5007110664774195	5.448570534752493	43838
5ce81d502b3eeacd5e1c457aab929eb1e18d763f	the space complexity of k -tree isomorphism	space complexity	We show that isomorphism testing of k-trees is in the class StUSPACE(log n) (strongly unambiguous logspace). This bound follows from a deterministic logspace algorithm that accesses a strongly unambiguous logspace oracle for canonizing k-trees. Further we give a logspace canonization algorithm for k-paths.	algorithm;dspace;graph canonization;l (complexity)	Vikraman Arvind;Bireswar Das;Johannes Köbler	2007		10.1007/978-3-540-77120-3_71	combinatorics;discrete mathematics;l;computer science;mathematics;dspace;algorithm	Theory	19.63688641469891	24.582748459805547	43934
f438b991bf8b571ee199e4d289cbdcb0be8e899e	analysis of congestion periods of an m/m/infinity-queue	method of moments;laplace transform;queueing networks;universiteitsbibliotheek;approximation theory;recursion relation;congestion period;traffic congestion;c congestion period;laplace transforms;busy period;m m;c;problem solving;transient behavior	"""A c-congestion period of an m/m/~-queue is a period during which the number of customers in the system is continuously above level c. Interesting quantities related to a c-congestion period are, besides its duration D""""c, the total area A""""c above c, and the number of arrived customers N""""c. In the literature Laplace transforms for these quantities have been derived, as well as explicit formulae for their means. Explicit expressions for higher moments and covariances (between D""""c,N""""c and A""""c), however, have not been found so far. This paper presents recursive relations through which all moments and covariances can be obtained. Up to a starting condition, we explicitly solve these equations; for instance, we write ED""""c^2 explicitly in terms of ED""""0^2. We then find formulae for these starting conditions (which directly relate to the busy period in the m/m/~ queue). Finally, a c-intercongestion period is defined as the period during which the number of customers is continuously below level c. Also for this situation a recursive scheme allows us to explicitly compute higher moments and covariances. Additionally we present the Laplace transform of a so-called intercongestion triple of the three performance quantities. It is also shown that expressions for the quantities of a c-intercongestion period can be used in an approximation for the c-congestion period. This is especially useful as the expressions for the c-intercongestion period are numerically more stable than those for the c-congestion period."""	network congestion	Frank Roijers;Michel Mandjes;Hans van den Berg	2007	Perform. Eval.	10.1016/j.peva.2006.12.001	m/m/1 queue;mathematical optimization;combinatorics;calculus;mathematics;laplace transform;statistics	Crypto	8.521941885328312	11.522453730555481	43953
6a136433a3efa0eeacd7d7a3fa4f5c3d2fbc2aa4	parameterized algorithmics and computational experiments for finding 2-clubs	parameterized algorithmics;dual parameter;efficient exact algorithm;previous o;direct combinatorial algorithm;np-hard 2-club problem;previous parameterized complexity study;feedback edge set size;computational experiment;previous implementation;polynomial kernel;search tree algorithm	Given an undirected graph G = (V,E) and an integer ` ≥ 1, the NPhard 2-Club problem asks for a vertex set S ⊆ V of size at least ` such that the subgraph induced by S has diameter at most two. In this work, we extend previous parameterized complexity studies for 2-Club. On the positive side, we give polynomial-size problem kernels for the parameters feedback edge set size of G and size of a cluster editing set of G and present a direct combinatorial algorithm for the parameter treewidth of G. On the negative side, we first show that unless NP ⊆ coNP/poly, 2-Club does not admit a polynomial-size problem kernel with respect to the size of a vertex cover of G. Next, we show that, under the strong exponential time hypothesis, a previous O(2|V |−` · |V ||E|)-time search tree algorithm [Schäfer et al., Optim. Lett. 2012] cannot be improved and that, unless NP ⊆ coNP/poly, there is no polynomial-size problem kernel for the dual parameter |V | − `. Finally, we show that, in spite of this lower bound, the search tree algorithm for the dual parameter |V | − ` can be tuned into an efficient exact algorithm for 2-Club that outperforms previous implementations. Submitted: July 2013 Reviewed: May 2014 Revised: August 2014 Accepted: February 2015 Final: February 2015 Published: March 2015 Article type: Regular paper Communicated by: P. Mutzel E-mail addresses: sepp.hartung@tu-berlin.de (Sepp Hartung) christian.komusiewicz@tu-berlin.de (Christian Komusiewicz) andre.nichterlein@tu-berlin.de (André Nichterlein) 156 Hartung et al. Algorithms and Experiments for Finding 2-Clubs	algorithmics;co-np;combinatorial optimization;exact algorithm;exponential time hypothesis;feedback arc set;graph (discrete mathematics);kernel (operating system);list of algorithms;parameterized complexity;polynomial;search tree;slot 1;time complexity;treewidth;vertex cover	Sepp Hartung;Christian Komusiewicz;André Nichterlein	2015	J. Graph Algorithms Appl.	10.7155/jgaa.00352	algorithm engineering;algorithmics	AI	21.378825656876973	20.272031032194224	44010
51042abe91ef521afec4b6470fc6853d943374a1	explicit coordination for mpc-based distributed control with application to hydro-power valleys	reservoirs;prediction method;predictive control;hydroelectric power stations;large scale systems decomposition coordination control approach mpc based distributed control explicit interaction prediction method hydro power valleys constraint handling french main electricity provider linear mpc control;large scale system;vectors;reservoirs optimization vectors atmospheric modeling turbines real time systems face;coordinated control;constraint handling;real time implementation;face;optimization;atmospheric modeling;distributed control;power system control;predictive control distributed control hydroelectric power stations power system control;turbines;real time systems	This paper discusses a decomposition-coordination control approach for large-scale systems, based on distributed MPC controllers and a specific coordination, with an application to the control of a so-called Hydro-Power Valley. The coordination strategy here explored can be characterized as an explicit interaction-prediction method, in the sense that the coordinator distributes predicted interactions to each subsystem on the basis of the information collected from those subsystems on the one hand, and takes advantage of explicit solutions for linear MPC control to globally update those predictions on the other hand. It is emphasized in the paper how this makes the approach suitable for real-time implementation, constraint handling, and communication limitations. In particular promising simulation results are provided for an industrial based Hydro-Power Valley case-study, chosen for the purpose of illustration, but using real data from French main electricity provider EDF.	computational complexity theory;converge;distributed control system;earliest deadline first scheduling;interaction;mathematical optimization;optimization problem;real-time clock;real-time computing;real-time transcription;requirement;simulation	Jennifer Zarate Florez;John J. Martinez;Gildas Besançon;Damien Faille	2011	IEEE Conference on Decision and Control and European Control Conference	10.1109/CDC.2011.6160451	face;control engineering;atmospheric model;simulation;engineering;control theory;mathematics;model predictive control;reservoir	Robotics	5.813820575002478	5.8996758899809345	44036
e7f57aeeeca3c538eb80c086bce6b9a629ecff71	evolving smart grid information management cloudward: a cloud optimization perspective	smart power grids cloud computing power engineering computing power system management;smart grid cloud computing information management optimization;smart grid;power engineering computing;smart power grids;power system management;information management;cloud computing information technology information management optimization communication services;optimization;information storage smart grid information management cloudward cloud optimization power system communication technologies information technologies network resource optimization framework;cloud computing	Smart grid (SG) is a power system with advanced communication and information technologies integrated and leveraged. In this paper, we study an optimization problem of leveraging the cloud domain to reduce the cost of information management in the SG. We propose a cloud-based SG information management model and present a cloud and network resource optimization framework to solve the cost reduction problem in cloud-based SG information storage and computation.	cloud computing;computation;information management;mathematical optimization;optimization problem;suicidegirls	Xi Fang;Dejun Yang;Guoliang Xue	2013	IEEE Transactions on Smart Grid	10.1109/TSG.2012.2230198	simulation;cloud computing;computer science;electrical engineering;theoretical computer science;distributed computing;smart grid;information management	HPC	0.9467250359285879	4.913942804533098	44042
faea8370cf22086af44935d7b4f0b0150021dbf8	efficient enumeration of all minimal separators in a graph	efficient algorithm;connected component	Abstract   This paper presents an efficient algorithm for enumerating all minimal  a - b  separators separating given non-adjacent vertices  a   and   b  in an undirected connected simple graph  G  = ( V ,  E ), Our algorithm requires  O ( n  3  R   ab  ) time, which improves the known result of  O ( n  4  R   ab  ) time for solving this problem, where   ¦V¦= n and R     ab    is the number of minimal  a - b  separators. The algorithm can be generalized for enumerating all minimal  A - B  separators that separate non-adjacent vertex sets  A ,  B   V , and it requires  O ( n  2 ( n  −  n   A   −  n   b  ) R   AB  ) time in this case, where   n     a    = ¦A¦, n     B    = ¦B¦ and r     AB    is the number of all minimal  A − B  separators. Using the algorithm above as a routine, an efficient algorithm for enumerating all minimal separators of G separating G into at least two connected components is constructed. The algorithm runs in time  O ( n  3  R  +   Σ   +  n  4  R   Σ  ), which improves the known result of  O ( n  6  R   Σ  ) time, where  R   σ   is the number of all minimal separators of G and  R   Σ   R  +   Σ   = ∑ 1 i , v j ) ∉ E R v i v j     (n − 1)  2   − m)R     Σ   . Efficient parallelization of these algorithms is also discussed. It is shown that the first algorithm requires at most   O((  n  log n  )R     ab   )   time and the second one runs in time   O((  n  log n  )R     +      Σ   +n log nR     Σ   )   on a CREW PRAM with  O ( n  3 ) processors.		Hong Shen;Weifa Liang	1997	Theor. Comput. Sci.	10.1016/S0304-3975(97)83809-1	combinatorics;discrete mathematics;connected component;computer science;mathematics;algorithm	ECom	19.265958535403755	28.49830737471113	44151
5a7375f41ccac4360f18ded28a3089357db8483e	scheduling real-time computations with separation constraints	minimisation;systeme temps reel;minimization;systeme commande;sistema control;foret graphe;gestion labor;structure arborescente;sistema informatico;minimizacion;computer system;minimum distance constraint;separation;separacion;control system;gestion tâche;estructura arborescente;tree structure;distancia;bosque grafo;real time system;systeme informatique;sistema tiempo real;task scheduling;separation problem;forest graph;real time computing;distance;real time systems	Abstract   Given a graph and a positive integer  k , the Separation Problem is to find a linear layout for the vertices such that each pair of adjacent vertices has a distance of at least  k  in the layout. A polynomial time algorithm has been studied earlier for the special case when the graph is a directed forest. In this paper, we study the problem when the roots of the trees in the forest have different constraints on their earliest starting positions. We present an O( n  log  n ) algorithm for the problem with  n  vertices in the forest. We then use the algorithm to schedule real-time jobs with minimum distance constraints.	real-time transcription;scheduling (computing)	Ching-Chih Han;Kwei-Jay Lin	1992	Inf. Process. Lett.	10.1016/0020-0190(92)90091-9	minimisation;mathematical optimization;suurballe's algorithm;combinatorics;independent set;level structure;graph center;metric k-center;computer science;control system;path graph;mathematics;tree structure;path;wheel graph;distance;distance;algorithm	DB	22.510358164939223	28.701886303560663	44157
4f148bc05e8c22bfeb4568717c8bfa5c1cf5e4aa	upper and lower bounds on the cost of a map-reduce computation	two-round map-reduce algorithm;map-reduce computation;communication cost;hamming distance;one-round map-reduce algorithm;matrix multiplication;lower bound;reducer size;one-round algorithm;total communication	In this paper we study the tradeoff between parallelism and communication cost in a map-reduce computation. For any problem that is not “embarrassingly parallel,” the finer we partition the work of the reducers so that more parallelism can be extracted, the greater will be the total communication between mappers and reducers. We introduce a model of problems that can be solved in a single round of map-reduce computation. This model enables a generic recipe for discovering lower bounds on communication cost as a function of the maximum number of inputs that can be assigned to one reducer. We use the model to analyze the tradeoff for three problems: finding pairs of strings at Hamming distance d, finding triangles and other patterns in a larger graph, and matrix multiplication. For finding strings of Hamming distance 1, we have upper and lower bounds that match exactly. For triangles and many other graphs, we have upper and lower bounds that are the same to within a constant factor. For the problem of matrix multiplication, we have matching upper and lower bounds for one-round map-reduce algorithms. We are also able to explore two-round map-reduce algorithms for matrix multiplication and show that these never have more communication, for a given reducer size, than the best one-round algorithm, and often have significantly less.	computation;embarrassingly parallel;hamming distance;mapreduce;matrix multiplication algorithm;parallel computing	Foto N. Afrati;Anish Das Sarma;Semih Salihoglu;Jeffrey D. Ullman	2013	PVLDB	10.14778/2535570.2488334	combinatorics;discrete mathematics;mathematics;algorithm	DB	13.537192956909424	29.683536249124298	44201
4660ce42997d4056d4ad42e98569feb37b6b7d60	canonical representations of chain events	transformations mathematics;mathematical logic;automata;matrices mathematics;algebra;sequences mathematics;canonical representation	So far studies of canonical representations for regular events have essentially been restricted to definite events. In this paper two additional classes of events, namely normal and uniform chain events, are introduced for which unique canonical representations are shown to exist. Most of the algebraic properties of regular events required in this study are derived from a rather general system of postulates which also applies, e.g., to binary relations, Boolean matrices and their generalizations.	linear algebra	Michael Yoeli	1965	Information and Control	10.1016/S0019-9958(65)90094-X	canonical form;mathematical logic;discrete mathematics;computer science;pure mathematics;mathematics;automaton;canonical normal form;algorithm;algebra	Theory	-3.9172896245736695	17.399427329003796	44296
b0bbb0718e7b9bf755fd734bb2e84666f4800a35	multidimensional balanced allocation for multiple choice & (1 + beta) processes	balls and bins;upper bound;load balance;binomial distribution;multiple choice;data structure;lower bound;uniform distribution	Allocation of balls into bins is a well studied abstraction for load balancing problems. The literature hosts numerous results for sequential (single dimensional) allocation case when m balls are thrown into n bins; such as: for multiple choice paradigm the expected gap between the heaviest bin and the average load isO( log log(n) log(d) ) [4], (1+β) choice paradigm with O( log(n) β ) gap [10] as well as for single choice paradigm having O( √ m log(n) n ) gap [9]. However, for multidimensional balanced allocations very little is known. Mitzenmacher [6] proved O(log log(nD)) gap for the multiple choice strategy and O(log(nD)) gap for single choice paradigm (where D is the total number of dimensions with each ball having exactly f populated dimensions) under the assumption that for each ball f dimensions are uniformly distributed over the D dimensions. In this paper we study the symmetric multiple choice process for both unweighted and weighted balls as well as for both multidimensional and scalar modes. Additionally, we present the results on bounds on gap for the (1 + β) choice process with multidimensional balls and bins. In the first part of this paper, we study multidimensional balanced allocations for the symmetric d choice process with m >> n unweighted balls and n bins. We show that for the symmetric d choice process and with m = O(n), the upper bound (assuming uniform distribution of f populated dimensions over D total dimensions) on the gap is O(ln ln(n)) w.h.p.. This upper bound on the gap is within D/f factor of the lower bound. This is the first such tight result along with detailed analysis for d choice paradigm with multidimensional balls and bins. This improves upon the best known prior bound of O(log log(nD)) [6]. For the general case of m >> n the expected gap is bounded by O(ln ln(n)). For variable f and non-uniform distribution of the populated dimensions (using analysis for weighted balls), we obtain the upper bound on the expected gap as O(log(n)). Further, for the multiple round parallel balls and bins, using symmetric d-choice process in multidimensional mode, we show that the gap is also bounded by O(log log(n)) for m = O(n). The same bound holds for the expected gap when m >> n. Our analysis also has the following strong implications for the sequential scalar case. For the weighted balls and bins and general case m >> n, we show that the upper bound on the expected gap is O(log(n)) (assuming E[W ] = 1 and second moment of the weight distribution is finite) which improves upon the best prior bound of n (c depends on the weight distribution that has finite fourth moment) provided in [12]. Our analysis also provides a much easier and elegant proof technique (as compared to [4]) for theO(log log(n)) upper bound on the gap for scalar unweighted m >> n balls thrown into n bins using the symmetric multiple choice process. Moreover, we study multidimensional balanced allocations for the (1 + β) choice process and the multiple (d) choice process. We show that for the (1 + β) choice process and m = O(n) the upper bound (assuming uniform distribution of f populated dimensions over D total dimensions) on the gap is O( log(n) β ), which is within D/f factor of the lower bound. For fixed f with non-uniform distribution and for random f with Binomial distribution the expected gap remains O( log(n) β ) and is independent of the total number of balls thrown, m. This is the first such tight result along with detailed analysis for (1 + β) paradigm with multidimensional balls and bins.	load balancing (computing);population;programming paradigm	Ankur Narang;Sourav Dutta;Souvik Bhattacherjee	2011	CoRR		mathematical optimization;combinatorics;mathematics;statistics	Theory	15.429077714124816	15.049177507343023	44338
7246dcb89529f929f1f6b37acfcee2fabaf37fe2	reactive grasp for the strip-packing problem	bin packing problem;altura;algoritmo aleatorizado;decoupe non guillotine;algorithme glouton;heuristic method;prension;non guillotine cutting;problema relleno;metodo heuristico;corte no guillotina;algorithme randomise;cutting stock problem;gripping;optimisation combinatoire;hauteur;greedy randomized adaptive search procedure;probleme decoupe;computer experiment;parametre critique;parametro critico;randomized algorithm;greedy algorithm;probleme remplissage;algoritmo gloton;prehension;problema troquelado;heuristics;grasp;methode heuristique;combinatorial optimization;strip packing;height;critical parameter;optimizacion combinatoria	This paper presents a greedy randomized adaptive search procedure (GRASP) for the strip packing problem, which is the problem of placing a set of rectangular pieces into a strip of a given width and infinite length so as to minimize the required length. We investigate several strategies for the constructive and improvement phases and several choices for critical search parameters. We perform extensive computational experiments with wellknown instances which have been previously reported, first to select the best alternatives and then to compare the efficiency of our algorithm with other procedures. The results show that the GRASP algorithm outperforms recently reported metaheuristics.	best practice;computation;experiment;grasp;greedy algorithm;greedy randomized adaptive search procedure;linear algebra;metaheuristic;randomized algorithm;set packing;william l. burke	Ramón Alvarez-Valdés;Francisco Parreño;José Manuel Tamarit	2008	Computers & OR	10.1016/j.cor.2006.07.004	greedy randomized adaptive search procedure;mathematical optimization;height;greedy algorithm;bin packing problem;computer experiment;combinatorial optimization;computer science;cutting stock problem;heuristics;grasp;mathematics;randomized algorithm;algorithm	AI	21.422732264126626	6.985409885597456	44341
8b183ce3d3669819c3ba30be619bfc973ab6c4f2	approximation algorithms for max sat: yannakakis vs. goemans-williamson	computational complexity computability approximation theory;performance guarantee;approximate algorithm;approximation algorithms systems engineering and theory programming profession educational programs polynomials;computability;satisfiability;approximation theory;truth assignment approximation algorithms max sat maximum satisfiability problem clauses weights;computational complexity	MAX SAT (the maximum satisfiability problem) is stated as follows: given a set of clauses with weights, find a truth assignment that maximizes the sum of the weights of the satisfied clauses. In this paper, we consider approximation algorithms for MAX SAT proposed by Yannnkakis and Goemans-Williamson and present an approximation algorithm which is an improvement of Yannakakis' algorithm. Although Yannakakis' original algorithm has no better performance guarantee than Goemans-Williamson, our improved algorithm has a better performance guarantee and leads to a 0.770 approximation algorithm.	approximation algorithm;max;maximum satisfiability problem	Takao Asano	1997		10.1109/ISTCS.1997.595154	mathematical optimization;combinatorics;discrete mathematics;computer science;maximum satisfiability problem;mathematics;computability;computational complexity theory;minimax approximation algorithm;approximation algorithm;algorithm;satisfiability;approximation theory	Theory	14.768980126774029	18.629133828669648	44342
1314efd3927cb8e3343903b6e020791673156580	permasense: investigating permafrost with a wsn in the swiss alps	swiss alps;wireless sensor network;quality requirement;lessons learned;point of view;heat flux;data flow	Currently, there is a lack of stand-alone geo-monitoring systems for harsh environments that are easy to configure, deploy and manage, while at the same time adhering to science grade quality requirements. In a joint computer and geoscience project we have built and deployed a wireless sensor network for measuring permafrost related parameters. Using these high-precision data, geo-scientists will be able to calibrate their heat flux models in order to better predict the stability of steep rock slopes in the alps. In this paper we describe our system from a computer science and system point of view and report on some lessons learned, especially in the domain of sensor design, power-awareness and reliable data flow.	computer science;dataflow;requirement	Igor Talzi;Andreas Hasler;Stephan Gruber;Christian F. Tschudin	2007		10.1145/1278972.1278974	simulation;geography;hydrology;remote sensing	AI	3.4731664061102463	31.355772471352267	44392
d98c87eb56094e186634fc8ad6f802797ee7f2f3	the interval skip list: a data structure for finding all intervals that overlap a point	computational geometry;binary search tree;pattern matching;indexation;skip list;high level language;data structure;binary tree	A problem that arises in computational geometry, pattern matching, and other applications is the need to quickly determine which of a collection of intervals overlap a point. Requests of this type are called stabbing queries. A recently discovered randomized data structure called the skip list can maintain ordered sets eeciently, just as balanced binary search trees can, but is much simpler to implement than balanced trees. This paper introduces an extension of the skip list called the interval skip list, or IS-list, to support interval indexing. The IS-list allows stabbing queries and dynamic insertion and deletion of intervals. A stabbing query using an IS-list containing n intervals takes an expected time of O(log n). Inserting or deleting an interval in an IS-list takes an expected time of O(log 2 n) if the interval endpoints are chosen from a continuous distribution. Moreover, the IS-list inherits much of the simplicity of the skip list { it can be implemented in a relatively small amount of high-level language code compared with dynamic interval indexes based on balanced trees.	average-case complexity;c++;computation;computational geometry;data structure;dynamic data;high- and low-level;high-level programming language;insertion sort;interval arithmetic;language code;online and offline;overlap–add method;pattern matching;randomized algorithm;requests;segment tree;self-balancing binary search tree;skip list	Eric N. Hanson	1991		10.1007/BFb0028258	random binary tree;linear search;optimal binary search tree;cartesian tree;left-child right-sibling binary tree;segment tree;red–black tree;combinatorics;discrete mathematics;linked list;binary search tree;binary expression tree;data structure;binary tree;computational geometry;computer science;treap;order statistic tree;range tree;self-balancing binary search tree;pattern matching;pattern recognition;k-ary tree;interval tree;mathematics;tree;programming language;skip list;high-level programming language;tree traversal	Theory	14.593715090436435	28.410394186567533	44397
f3846a548f02579b6d0502273d7180a541a833e4	closed form solutions for the equilibrium probability distribution in the closed lu-kumar network under two buffer priority policies	automatic control;two static buffer priority policies;closed form solution;customer services;queueing theory;distributed computing;toeplitz matrices customer services queueing theory statistical distributions;computer networks;reduced dimension toeplitz matrix;statistical distributions;equilibrium probability distribution;probability distribution;first buffer first served policy;performance analysis;production systems;reduced dimension toeplitz matrix equilibrium probability distribution two static buffer priority policies two station closed reentrant lu kumar network first buffer first served policy;closed form solution probability distribution distributed computing automatic control automation throughput production systems computer networks performance analysis modeling;two station closed reentrant lu kumar network;toeplitz matrix;modeling;throughput;toeplitz matrices;automation	We seek closed form solutions for the equilibrium probability distribution of the two station closed reentrant Lu-Kumar network under two static buffer priority policies. For the last buffer first served (LBFS) policy, an explicit closed form is obtained. For the first buffer first served (FBFS) policy, sufficient structure exists for us to obtain expressions for many states, but a reduced dimension Toeplitz matrix must still be inverted for a complete solution. We use the results to compute the throughput and asymptotic losses of the system.	lu decomposition;reentrancy (computing);throughput;toeplitz hash algorithm	Seunghwan Jung;James R. Morrison	2010	IEEE ICCA 2010	10.1109/ICCA.2010.5524336	probability distribution;mathematical optimization;computer science;automatic control;mathematics;distributed computing;statistics	Metrics	7.9128996145299055	9.291529541245772	44415
26f2ce20e6b3dc6ecf1e90efee3da44b66fc90a0	finding top-k optimal sequenced routes		Motivated by many practical applications in logistics and mobility-as-a-service, we study the top-k optimal sequenced routes (KOSR) querying on large, general graphs where the edge weights may not satisfy the triangle inequality, e.g., road network graphs with travel times as edge weights. The KOSR querying strives to find the top-k optimal routes (i.e., with the top-k minimal total costs) from a given source to a given destination, which must visit a number of vertices with specific vertex categories (e.g., gas stations, restaurants, and shopping malls) in a particular order (e.g., visiting gas stations before restaurants and then shopping malls). To efficiently find the top-k optimal sequenced routes, we propose two algorithms PruningKOSR and StarKOSR. In PruningKOSR, we define a dominance relationship between two partially-explored routes. The partially-explored routes that can be dominated by other partially-explored routes are postponed being extended, which leads to a smaller searching space and thus improves efficiency. In StarKOSR, we further improve the efficiency by extending routes in an A manner. With the help of a judiciously designed heuristic estimation that works for general graphs, the cost of partially explored routes to the destination can be estimated such that the qualified complete routes can be found early. In addition, we demonstrate the high extensibility of the proposed algorithms by incorporating Hop Labeling, an effective label indexing technique for shortest path queries, to further improve efficiency. Extensive experiments on multiple real-world graphs demonstrate that the proposed methods significantly outperform the baseline method. Furthermore, when k = 1, StarKOSR also outperforms the state-of-the-art method for the optimal sequenced route queries.	algorithm;baseline (configuration management);experiment;extensibility;graph (discrete mathematics);heuristic;hop;logistics;mapreduce;microsoft outlook for mac;shortest path problem;social inequality	Huiping Liu;Cheqing Jin;Bin Yang;Aoying Zhou	2018	2018 IEEE 34th International Conference on Data Engineering (ICDE)	10.1109/ICDE.2018.00058	data mining;mathematical optimization;hop (networking);vertex (geometry);total cost;kosr;search engine indexing;computer science;shortest path problem;triangle inequality;heuristic	DB	23.75381455977574	7.323997509273676	44419
69f0397681fdfb1265a0bb1585c5cd37071a722e	parametric problems on graphs of bounded tree-width	graph theory;teoria grafo;algorithmique;algorithm complexity;complejidad algoritmo;satisfiability;theorie graphe;optimization problem;graphe pondere;complexite algorithme;algorithmics;algoritmica;polynomial time;weighted graph	We consider optimization problems on weighted graphs where vertex and edge weights are polynomial functions of a parameter lambda. We show that, if a problem satisfies certain regularity properties and the underlying graph has bounded tree-width, the number of changes in the optimum solution is polynomially bounded. We also show that the description of the sequence of optimum solutions can be constructed in polynomial time and that certain parametric search problems can be solved in O(n log n) time, where n is the number of vertices in the graph. Disciplines Theory and Algorithms This article is available at Iowa State University Digital Repository: http://lib.dr.iastate.edu/cs_techreports/88 Parametric Problems on Graphs of Bounded Tree-width TR 92-08 David Fernandez-Baca and Giora Slutzki	directed graph;mathematical optimization;optimization problem;parametric search;polynomial;time complexity;treewidth	David Fernández-Baca;Giora Slutzki	1994	J. Algorithms	10.1006/jagm.1994.1019	1-planar graph;time complexity;graph power;random regular graph;optimization problem;integral graph;mathematical optimization;factor-critical graph;combinatorics;discrete mathematics;independent set;graph bandwidth;graph theory;edge cover;graph automorphism;cubic graph;graph coloring;mathematics;voltage graph;tutte polynomial;windmill graph;butterfly graph;partial k-tree;algorithmics;line graph;algorithm;coxeter graph;satisfiability	Theory	20.847524879570678	20.150544659585243	44432
aa6b5cb0fd3b1131bca8aac9e6df8fba8e91fba0	algebraic characterizations of complexity-theoretic classes of real functions	algebraic characterization;real computation;recursive analysis;polynomial time;oracle turing machines	Recursive analysis is the most classical approach to model and discuss computations over the real numbers. Recently, it has been shown that computability classes of functions in the sense of recursive analysis can be defined (or characterized) in an algebraic machine independent way, without resorting to Turing machines. In particular nice connections between the class of computable functions (and some of its suband sup-classes) over the reals and algebraically defined (suband sup-) classes of R-recursive functions à la Moore 96 have been obtained. However, until now, this has been done only at the computability level, and not at the complexity level. In this paper we provide a framework that allows us to dive into the complexity level of real functions. In particular we provide the first algebraic characterization of polynomial-time computable functions over the reals. This framework opens the field of implicit complexity of analog functions, and also provides a new reading of some of the existing characterizations at the computability level.	computability;computable function;computation;linear algebra;polynomial;recursion (computer science);theory;time complexity;turing machine	Olivier Bournez;Walid Gomaa;Emmanuel Hainry	2011	IJUC		time complexity;combinatorics;discrete mathematics;turing reduction;computer science;mathematics;μ-recursive function;computable function;computable number;μ operator;algorithm;computable analysis	Theory	3.08804496932013	20.96586713469514	44461
6ac33dfedad1ef3f3857035ca01306425408530b	synchronized shuffles	shuffles;synchronized shuffles;gene linkage;genome shuffling	We extend the basic shuffle on words and languages, a well-known operation in theoretical computer science, by introducing three synchronized shuffles. These synchronized shuffles have some relevance to molecular biology since they may be viewed as the formal representations of various forms of gene linkage during genome shuffling. More precisely, each synchronized shuffle preserves the genetic backbone of the organisms, as well as the linked genes, by requiring the synchronization of some predefined genes while all other genes are arbitrarily shuffled.As for their mathematical properties, we prove that in a trio the closure under shuffle is equivalent to the closure under any of the synchronized shuffles studied here. Finally, based on this result, we present an algorithm for deciding whether a given regular language is synchronized shuffle closed. © 2005 Elsevier B.V. All rights reserved.	algorithm;automata theory;automaton;cone (formal languages);internet backbone;linkage (software);linux;object composition;operating system;regular language;relevance;theoretical computer science;unix;viz: the computer game	Maurice H. ter Beek;Carlos Martín-Vide;Victor Mitrana	2005	Theor. Comput. Sci.	10.1016/j.tcs.2005.04.007	discrete mathematics;mathematics;distributed computing;algorithm	Logic	2.0626226347143906	23.01848346333345	44483
dc084988dfa0ad3214221aac4f9ba66d1a64123a	commutative images of rational languages and the abelian kernel of a monoid	semilinear expressions;finite monoid;profinite topology;theorie groupe;ensemble semilineaire;monoid;rational expressions;palabra finita;semilinear set;mot fini;group theory;monoide;algorithme;algorithm;monoide fini;finite monoids;langage rationnel;rational languages;algorithms;topologie profinie;commutative images;lenguaje formal;teoria grupo;formal language;finite word;algoritmo;rational language;langage formel	Natural algorithms to compute rational expressions for recognizable languages, even those which work well in practice, may produce very long expressions. So, aiming towards the computation of the commutative image of a recognizable language, one should avoid passing through an expression produced this way. We modify here one of those algorithms in order to compute directly a semilinear expression for the commutative image of a recognizable language. We also give a second modification of the algorithm which allows the direct computation of the closure in the profinite topology of the commutative image. As an application, we give a modification of an algorithm for computing the Abelian kernel of a finite monoid obtained by the author in 1998 which is much more efficient in practice. Mathematics Subject Classification. 20M35, 68Q99.	algorithm;commutation theorem;computation;kernel (operating system);mathematics subject classification;recursively enumerable language	Manuel Delgado	2001	ITA	10.1051/ita:2001100	combinatorics;formal language;discrete mathematics;semiring;mathematics;monoid;group theory;trace theory;algorithm;algebra	PL	-2.9472713363574714	19.450554898152937	44556
a9074fbd052527d8d9ac2fe071255fc66f419da2	constructing genome scale suffix trees		Suffix trees have been the focus of significant research interest as they permit very efficient solutions to a range of string and sequence searching problems. Given a suffix tree that encodes a particular string, it is possible to solve problems such as searching for a specific pattern in time proportional to the length of the pattern rather than the length of the string. Suffix trees can also support inexact matching by dramatically improving the performance of dynamic programming. Therefore, suffix trees may enable a number of large scale bioinformatics problems to be solved more efficiently than previously thought. However, these benefits presume that a suffix tree of sufficient scale can be constructed. An inherent difficulty in suffix tree construction is that the tree construction requires a semi random walk over the tree as it is constructed. Therefore very large trees that will not fit in memory could take an unacceptably long time to construct due to excessive page faulting. In this paper we present a linear time construction algorithm that can construct suffix trees larger than memory using discrete sub-trees. The sub-trees can be constructed in parallel. The performance of the algorithm is evaluated using suffix trees constructed for chromosomes 1 and 12 of the human genome.	algorithm;best, worst and average case;bioinformatics;computer data storage;depth perception;dynamic programming;linear function;mathematical optimization;naivety;page fault;schmidt decomposition;semiconductor industry;suffix tree;thomas zaslavsky;time complexity	A. L. Brown	2004			suffix tree;longest common substring problem;genome;bioinformatics;biology;generalized suffix tree;suffix	Theory	10.276751755369954	27.601458044311684	44569
8c870020658b7783461224c6ac3004f04a5ef705	a survey on small fragments of first-order logic over finite words	monoids;piecewise testable languages;factorization forests;first order logic	We consider fragments of first-order logic over finite words. In particular, we deal with first-order logic with a restricted number of variables and with the lower levels of the alternation hierarchy. We use the algebraic approach to show decidability of expressibility within these fragments. As a byproduct, we survey several characterizations of the respective fragments. We give complete proofs for all characterizations and we provide all necessary background. Some of the proofs seem to be new and simpler than those which can be found elsewhere. We also give a proof of Simon’s theorem on factorization forests restricted to aperiodic monoids because this is simpler and sufficient for our purpose.	aperiodic graph;boolean circuit;bounded quantifier;cpu cache;circuit complexity;complexity class;computation;computational problem;decision problem;expressive power (computer science);fo (complexity);fallout 3;first-order logic;first-order predicate;first-order reduction;linear algebra;linear temporal logic;numerical analysis;ordered pair;parse tree;parsing;polynomial;presburger arithmetic;quantifier (logic);recurrence relation;regular language;syntactic monoid;top-down and bottom-up design;tracing (software);tree (data structure);tridiagonal matrix algorithm;turing completeness;unary operation	Volker Diekert;Paul Gastin;Manfred Kufleitner	2008	Int. J. Found. Comput. Sci.	10.1142/S0129054108005802	combinatorics;discrete mathematics;computer science;first-order logic;mathematics;monoid;algorithm;algebra	Logic	-3.300898519836844	19.746922057481022	44575
9e66ac8c7616713ec1c42326640ee6a105377617	minimum-energy broadcast and disk cover in grid wireless networks	minimisation;disque;heuristique;overall energy minimization;assignment;pire cas;optimal solution;energy;minimization;asignacion;solution optimale;disk;settore inf 01 informatica;ad hoc wireless network;temps polynomial;heuristica;49j30;transmission;energia;aproximacion;wireless network;assignation;restriction;minimizacion;reseau;by product;maillage;polynomial;product;red;disco;approximation;upper bound;grid;energie;construccion;celdarada;producto;energy consumption;sous produit;rejilla;informatique theorique;solucion optima;polinomio;subproducto;polynomial time;coste;grille;disk cover problem;range assignment;grid pattern;produit;heuristics;energy minimization;ad hoc wireless networks;covering problem;49k30;broadcast problem;borne superieure;polynome;construction;transmision;network;cota superior;computer theory;cout;tiempo polinomial;informatica teorica	The Minimum-Energy Broadcast problem is to assign a transmission range to every station of an ad-hoc wireless networks so that (i) a given source station is allowed to perform broadcast operations and (ii) the overall energy consumption of the range assignment is minimized. We prove a nearly tight asymptotical bound on the optimal cost for the MinimumEnergy Broadcast problem on square grids. We also derive near-tight bounds for the Bounded-Hop version of this problem. Our results imply that the best-known heuristic, the MST-based one, for the Minimum-Energy Broadcast problem is far to achieve optimal solutions (even) on very regular, well-spread instances: its worstcase approximation ratio is about π and it yields Ω( √ n) hops, where n is the number of stations. As a by product, we get nearly tight bounds for the Minimum Disk Cover problem and for its restriction in which the allowed disks must have non-constant radius. Finally, we emphasize that our upper bounds are obtained via polynomial time constructions.	approximation algorithm;asymptote;heuristic;hoc (programming language);hop;polynomial;time complexity	Tiziana Calamoneri;Andrea E. F. Clementi;Miriam Di Ianni;Massimo Lauria;Angelo Monti;Riccardo Silvestri	2008	Theor. Comput. Sci.	10.1016/j.tcs.2008.02.005	telecommunications;transmission;computer science;calculus;mathematics;algorithm;algebra	Theory	20.677410446945665	14.753922964867897	44609
06a86d98090c8256b58822ae2c44ac9e64890d87	boolean complexity classes vs. their arithmetic analogs	boolean circuits;complexity class	This paper provides logspace and small circuit depth analogs of the result of Valiant and Vazirani, which is a randomized (or nonuniform) reduction from $NP$ to its arithmetic analog $\plusminus P$. We show a similar randomized reduction between the Boolean classes $NL$ and semiunbounded fan-in Boolean circuits and their arithmetic counterparts. These reductions are based on the Isolation Lemma of Mulmuley, Vazirani and Vazirani. Combinatorically our results can be viewed as simple (logspace) transformations of existential quantifiers into counting quantifiers in graphs and shallow circuits.	boolean circuit;complexity class;fan-in;ketan mulmuley;l (complexity);randomized algorithm;universal quantification	Anna Gál;Avi Wigderson	1995	Random Struct. Algorithms	10.1002/(SICI)1098-2418(199608/09)9:1/2%3C99::AID-RSA7%3E3.0.CO;2-6	complexity class;circuit complexity;boolean algebra;boolean circuit;and-inverter graph;combinatorics;circuit minimization for boolean functions;discrete mathematics;boolean domain;boolean expression;product term;standard boolean model;computer science;maximum satisfiability problem;karp–lipton theorem;complexity index;mathematics;arithmetic circuit complexity;boolean function;boolean satisfiability problem;algorithm;two-element boolean algebra;parity function;tc0;algebra	Theory	8.220128929633152	22.130726145068202	44615
0c7b8ec5fe58bb3b2e3cd8982bff5272f5cb2557	on centralized smooth scheduling	resource scheduling;efficient algorithm;fair scheduling;packet switched;distributed environment;scheduling;aritmetica intervalo;interval arithmetic;arithmetique intervalle;ordonnancement;reglamento	This paper studies evenly distributed sets of natural numbers and their applications to scheduling in a centralized environment. Such sets, called smooth sets, have the property that their quantity within each interval is proportional to the size of the interval, up to a bounded additive deviation; namely, for ρ,Δ∈ℝ a set A of natural numbers is (ρ,Δ)-smooth if abs(|I|⋅ρ−|I∩A|)<Δ for any interval I⊂ℕ. The paper studies scheduling persistent clients on a single slot-oriented resource in a flexible and predictable manner. Each client γ has a given rate ρ γ that defines the share of the resource he is entitled to receive and the goal is a smooth schedule in which, for some predefined Δ, each client γ is served in a (ρ γ ,Δ)-smooth set of slots (natural numbers). The paper considers a centralized environment where a single algorithm computes the user of the current slot. It constructs a smooth schedule with a very efficient algorithm that computes the user of each slot in O(log log q) time and O(n) space, where n is the number of clients and q ≜max {ρ γ /ρ γ′ | γ,γ′∈Γ}; in many practical applications this O(log log q) value is actually a small constant. Our scheduling technique is based on a reduction from allocation of slots to allocation of sub-intervals of the unit interval. This technique naturally extends to the problem of scheduling multiple resources, even under the restriction that a client can be served concurrently by at most one resource. This paper constructs such a schedule in which the users of each slot are computed very fast—in O(mlog log q) time per slot and O(n) space where m is the number of resources; this result is a significant improvement on the prior fastest algorithm that produces such a schedule (actually of a special type—a P-fair schedule) in O(mlog n) time per slot and O(n) space. Moreover, the paper introduces a novel approach to multi-resource scheduling in which each resource independently computes, slot after slot, what client to serve in this slot. Under this approach the paper constructs a smooth schedule which is computed in O(n) space and O(log log q) time per slot.	algorithm;centralized computing;crew scheduling;ftc fair information practice;fastest;schedule (computer science);scheduling (computing);utility functions on indivisible goods	Ami Litman;Shiri Moran	2009	Algorithmica	10.1007/s00453-009-9360-x	mathematical optimization;real-time computing;computer science;distributed computing;interval arithmetic;scheduling;distributed computing environment	Embedded	14.272543443340764	11.917908822820861	44636
31bfd47b8850a32f90a90f07239a86315579450b	locating the largest word in a file using a modified memory	largest word;modified memory	Three algorithms are presented. One deals with locating the largest word in a file. The second and third deal with locating words greater or less than an arbitrary 2 ~. The algorithms use a memory that can read out a given bit of all words with one operation. With the first algorithm a time gain over a conventional system can be obtained equal to the quotient of the number of words divided by the number of bits.	algorithm	E. J. Gauss	1961	J. ACM	10.1145/321075.321085	theoretical computer science;database;programming language	Theory	10.84578562208308	28.13454390624706	44637
841c7841aae99d8051650084c57401df8bac1dcc	communication architecture for smart grid applications		The need to add intelligence to the existing power grid in order to operate as a cognitive, self-monitoring and selfhealing system has become imminent. The monolithic energy value chain comes with a lot of constraints such as elongated outage, electricity theft and low equipment optimization. The next-generation grid is a data-centric network with heterogeneous hierarchical interconnected layers. Network devices in the emerging grid need a standard platform for proper integration, monitoring and control. In this paper, a holistic smart grid architectural landscape that clearly separates the power and communication domains to enable “evolving smart grid” engineers provide efficient networking solutions is presented. The communication routes and device topologies for the six smart grid applications are described based on the IEEE Guide for Smart Grid Interoperability and National Institute of Standards and Technology frameworks. Also, the deployments of intelligent electronic devices for microgrid control, monitoring and islanding operations are highlighted.	downtime;end-to-end principle;grid network;holism;interoperability;mathematical optimization;microgrid;scalability	Michael Emmanuel;Winston Khoon Guan Seah;Ramesh Kumar Rayudu	2018	2018 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2018.8538472	grid;computer network;networking hardware;architecture;network topology;smart grid;interoperability;islanding;computer science;microgrid	HPC	0.1209971932178098	7.855315079582449	44649
2c777ef3ecfd1158c061c1a2293a973bb053b624	uniform characterizations of polynomial-query learnabilities	learning from example;metodo polinomial;query language;intellectual learning;relation equivalence;learning;condition necessaire suffisante;apprentissage intellectuel;query formulation;apprentissage conceptuel;polynomial query learning;pregunta documental;formulacion pregunta;contre exemple;formulation question;lenguaje interrogacion;question documentaire;aprendizaje;contraejemplo;apprentissage;equivalence relation;methode fingerprint;aprendizaje conceptual;computational theory and mathematics;polynomial method;informatique theorique;necessary and sufficient condition;learning from examples;metodo fingerprint;fingerprint method;query;concept learning;aprendizaje intelectual;langage interrogation;methode polynomiale;relacion equivalencia;apprentissage exemple;condicion necesaria suficiente;counterexample;computer theory;informatica teorica	We consider the exact learning in the query model. We deal with all types of queries introduced by Angluin: membership, equivalence, superset, subset, disjointness and exhaustiveness queries, and their weak (or restricted) versions where no counterexample is returned. For each of all possible combinations of these queries, we uniformly give complete characterizations of boolean concept classes that are learnable using a polynomial number of polynomial sized queries. Our characterizations show the equivalence between the learnability of a concept class C using queries and the existence of a good query for any subset H of C which is guaranteed to reject a certain fraction of candidate concepts in H regardless of the answer. As a special case for equivalence queries alone, our characterizations directly correspond to the lack of the approximate fingerprint property, which is known to be a sufficient and necessary condition for the learnability using equivalence queries.	approximation algorithm;concept class;fingerprint;learnability;polynomial;turing completeness	Yosuke Hayashi;Satoshi Matsumoto;Ayumi Shinohara;Masayuki Takeda	2003	Theor. Comput. Sci.	10.1016/S0304-3975(02)00177-9	combinatorics;discrete mathematics;concept learning;computer science;counterexample;mathematics;equivalence relation;algorithm;query language	Theory	4.4919390788645925	17.80724488791378	44653
2759eaf74dfdff42abd98c1a59a588ad7e09a4ee	set-cover-based critical implications selection to improvesat-based bounded model checking: extended abstract	satisfiability;bounded model checking;static implications	The effectiveness of Satisfiability (SAT)-based Bounded Model Checking (BMC) critically relies on the deductive power of the BMC instance. Although implication relationships have been used to help SAT solver to make more deductions, too many such implications would result in a large number of clauses and potentially degrade the underlying SAT solver performance. In this paper, we have formulated clause selection as a set-cover problem. Secondly, we have proposed a novel greedy strategy for optimal selection of static logic clauses. This technique maximizes the number of literals that can be deduced by the SAT solver during the Boolean Constraint Propagation (BCP) operation. Our strategy improves BMC by 1.74x against the case where all extended implications were added to the BMC instance. Compared with the original BMC without any implications, up to 55.32x speedup can be achieved.	boolean satisfiability problem;bulk copy program;dynamic logic (digital electronics);greedy algorithm;intelligent platform management interface;local consistency;model checking;set cover problem;solver;speedup	Mahmoud Elbayoumi;Michael S. Hsiao;Mustafa ElNainay	2013		10.1145/2483028.2483128	discrete mathematics;theoretical computer science;mathematics;algorithm;satisfiability	EDA	-2.1436697654279415	27.42349451472808	44711
a50cac166848dc4d0ee85ea68dc866ad9104b546	power scheduling in privacy enhanced microgrid networks with renewables and storage	microgrids home appliances privacy batteries conferences linear programming;smart meters power scheduling privacy enhanced microgrid networks smart grid sg proliferated data processing sound privacy measurement privacy aware microgrid power scheduling formulation renewable sources energy storage;smart power grids data privacy power engineering computing renewable energy sources scheduling smart meters	As many countries embark on a major transitioning to the Smart Grid (SG), realizing the benefits of the new paradigm depends on generation, collection, and usage of unprecedented amount of data. With such proliferated data processing, there are legitimate concerns that call for sound privacy measures to ensure proper safekeeping. A significant portion of the potential benefits of the SG initiative, thus, relies on devising convincing mechanisms to strengthen the privacy. As a new distribution subsystem, microgrids are expected to play a crucial role in the SG. In this paper, we develop a privacy-aware microgrid power scheduling formulation with renewable sources and energy storage where five different classes of appliances are prioritized by smart meters. Our analysis shows that there is a tradeoff between maximizing the power usage and privacy levels. Hence, it is not possible to find a solution that maximizes both objectives simultaneously. However, it is possible to achieve significantly higher levels of privacy preservation with moderate sacrifice from the power usage, especially when the number of users is high.	discharger;expectation–maximization algorithm;isoelastic utility;microgrid;numerical analysis;privacy;programming paradigm;scheduling (computing);smart meter;state of charge;suicidegirls	Arif Önder Isikman;Cankal Altun;Suleyman Uludag;Bülent Tavli	2016	2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC)	10.1109/CCNC.2016.7444814	embedded system;real-time computing;computer security	Metrics	1.7478147604563707	4.793712637649495	44810
7e35f236d6f4f116e3dab01479e26b9b0b2f1675	on non context-free grammar forms	context free language;context free grammar;strong normalization	A grammar formF defines via a so-calledinterpretation mechanism, a family of languages (F). In this paper we establish that for many grammar formsF, (the family of context-free languages) implies (F)= RE (the family of recursively enumerable sets). We conjecture that this is also true in general. Because of this, it seems necessary to use restricted interpretations for non context-free grammar forms, a form giving then rise to a family We compare the obvious alternatives for restricting interpretations and focus attention on two promising alternatives, Q (F) and st(F) and their combination Q, st(F). Using st-interpretations, surprising families can be generated and strong normal form results can be obtained. Closure results and decidability results are also given. UnderQ, st-interpretation, it is possible to characterize a number of well-known families of languages between CF and RE, including the families of EOL, ETOL, matrix and scattered context languages.	context-free grammar;context-free language;end-of-life (product);recursively enumerable set	Hermann A. Maurer;Martti Penttonen;Arto Salomaa;Derick Wood	1979	Mathematical systems theory	10.1007/BF01776580	combinatorics;operator-precedence grammar;computer science;mathematics;context-free language;abstract family of languages;context-free grammar;programming language;unrestricted grammar;algorithm	Theory	-4.130323271369118	17.171280943701827	44864
1d5572664ca6f072c9fab82b17ec303dc327afdf	electric vehicle smart charging aims for co2 emission reduction?	automobiles;estimation;stochastic processes;electric vehicles;production;electricity supply industry;load modeling	In this paper, a methodology for electric vehicle charging by minimizing CO2 emissions and minimizing charging electricity costs is presented in an actual Nordic electricity market environment. The target of the paper is to illustrate the difference of smart charging and dumb charging schemes from the perspectives of CO2 emissions and electricity end-user electricity costs. The study takes advantage of a national transportation survey and actual electricity market data including generation-type-specific CO2 information.	distributed manufacturing;extended validation certificate;home automation;marginal model;mathematical optimization	Ville Tikka;Jukka Lassila;Juha Haakana;Jarmo Partanen	2016	2016 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)	10.1109/ISGTEurope.2016.7856250	engineering;electrical engineering;operations management;electricity retailing;automotive engineering;stand-alone power system	EDA	3.7702784675982235	6.999090101892244	44928
8e5d04c8c175fabef6f8628e32e370990a3aae13	np-completeness of small conflict set generation for congruence closure	satisfiability modulo theories;decision procedures;congruence closure;complexity	The efficiency of satisfiability modulo theories (SMT) solvers is dependent on the capability of theory reasoners to provide small conflict sets, i.e. small unsatisfiable subsets from unsatisfiable sets of literals. Decision procedures for uninterpreted symbols (i.e. congruence closure algorithms) date back from the very early days of SMT. Nevertheless, to the best of our knowledge, the complexity of generating smallest conflict sets for sets of literals with uninterpreted symbols and equalities had not yet been determined, although the corresponding decision problem was believed to be NP-complete. We provide here an NP-completeness proof, using a simple reduction from SAT.	algorithm;boolean satisfiability problem;congruence of squares;decision problem;encode;literal (mathematical logic);mathematical optimization;modulo operation;np-completeness;satisfiability modulo theories;solver;zeller's congruence	Andreas Fellner;Pascal Fontaine;Bruno Woltzenlogel Paleo	2017	Formal Methods in System Design	10.1007/s10703-017-0283-x	completeness (statistics);computer science;decision problem;satisfiability modulo theories;algorithm;congruence (geometry)	Logic	6.312844217154518	19.366159699594014	45019
67f5356a572181d79c9dcd6b4afa1e290652c8c6	structural interactions of the recursively enumerable t- and w-degrees	logique mathematique;logica matematica;conjunto recursivamente enumerable;recursividad;mathematical logic;enrejado;recursivite;treillis;recursively enumerable set;recursivity;ensemble recursivement enumerable;lattice	On etudie les ensembles recursivement enumerables et leurs degres en analysant les interactions structurelles des degres de Turing recursivement enumerables et des degres des tables de verite faibles recursivement enumerables. On etablit une relation entre les semi-treillis associes	interaction;recursively enumerable set	Rodney G. Downey;Michael Stob	1986	Ann. Pure Appl. Logic	10.1016/0168-0072(86)90071-0	recursion;combinatorics;mathematical logic;discrete mathematics;recursively enumerable set;lattice;mathematics;programming language;algorithm;algebra	Logic	0.10544723842208159	17.164165682676757	45053
5ab2a32fd03e6acf73deb4bc4c5191872713df3d	the jevis service platform - distributed energy data acquisition and management	data acquisition	111.	data acquisition	Peter Palensky	2005			distributed generation;database;data acquisition;engineering	HPC	1.4012721245678261	8.831256467538793	45080
3fe1f41a99a65bc8149c5acfeeb45b51d3384b5b	an improved algorithm for the membership problem for extended regular expressions	expresion regular;palabra finita;chaine caractere;regular language;mot fini;automaton;concatenacion;concatenation;lenguaje racional;automata;automate;cadena caracter;langage rationnel;expression reguliere;regular expression;finite word;character string;langage regulier	Extended regular expressions (ERE) define regular languages using union, concatenation, repetition, intersection, and complementation operators. The fact ERE allow intersection and complementation makes them exponentially more succinct than regular expressions. The membership problem for extended regular expressions is to decide, given an expression r and a word w, whether w belongs to the language defined by r. Since regular expressions are useful for describing patterns in strings, the membership problem has numerous applications. In many such applications, the words w are very long and patterns are conveniently described using ERE, making efficient solutions to the membership problem of great practical interest. In this paper we introduce alternating automata with synchronized universality and negation, and use them in order to obtain a simple and efficient algorithm for solving the membership problem for ERE. Our algorithm runs in timeO(m ·n) and spaceO(m·n+k ·n), wherem is the length of r, n is the length ofw, and k is the number of intersection and complementation operators in r. This improves the best known algorithms for the problem.	algorithm;alternating finite automaton;automata theory;concatenation;decision problem;regular expression;regular language;universality probability	Orna Kupferman;Sharon Zuhovitzky	2002		10.1007/3-540-45687-2_37	arithmetic;combinatorics;computer science;artificial intelligence;mathematics;automaton;programming language;generalized star height problem;algorithm	Theory	-1.6027886004079532	19.913376482868596	45087
c4a022c96e3a4dbead0e053c99467c8ddc0e9504	johnson's rule, composite jobs and the relocation problem	minimisation;location problem;minimization;tiempo total acabamiento;probleme localisation;corresponding author;execution time;flowshop;temps total achevement;minimizacion;multiple machine;processing time;constrenimiento precedencia;resolucion problema;maquina multiple;makespan;scheduling;composite job;precedence constraint;contrainte precedence;scheduling problem;temps traitement;temps execution;problema localizacion;flowshop makespan johnson s rule composite job relocation problem;tiempo ejecucion;machine multiple;atelier monogamme;relocation problem;johnson s rule;article;tiempo proceso;journal magazine article;ordonnancement;flow shop;reglamento;problem solving;resolution probleme	Two-machine flowshop scheduling to minimize makespan is one of the most well-known classical scheduling problems. Johnson’s rule for solving this problem has been widely cited in the literature. We introduce in this paper the concept of composite job, which is an artificially constructed job with processing times such that it will incur the same amount of idle time on the second machine as that incurred by a chain of jobs in a given processing sequence. This concept due to Kurisu first appeared in 1976 to deal with the twomachine flowshop scheduling problem involving precedence constraints among the jobs. We show that this concept can be applied to reduce the computational time to solve some related scheduling problems. We also establish a link between solving the two-machine flowshop makespan minimization problem using Johnson’s rule and the relocation problem introduced by Kaplan. We present an intuitive interpretation of Johnson’s rule in the context of the relocation problem. 2007 Elsevier B.V. All rights reserved.	algorithm;computation;job scheduler;job stream;johnson's rule;kaplan–meier estimator;makespan;relocation (computing);rule 184;scheduling (computing);time complexity	T. C. Edwin Cheng;Bertrand M. T. Lin	2009	European Journal of Operational Research	10.1016/j.ejor.2007.11.035	job shop scheduling;minimisation;mathematical optimization;johnson's rule;flow shop scheduling;computer science;artificial intelligence;operations management;mathematics;scheduling;algorithm	AI	17.015437037591084	9.252542849577909	45103
fa52c5043af1b2046396c82f0e573084dcdc9d5e	the lagrangian relaxation method for solving integer programming problems	heuristic;branch and bound algorithm;programming integer algorithm branch and bound;programming integer algorithms;linear programming relaxation;integer program;programming integer algorithms heuristic;branch and bound;set cover;lower bound;management science;lagrangian relaxation	Your use of the JSTOR archive indicates your acceptance of JSTOR's Terms and Conditions of Use, available at http://www.jstor.org/page/info/about/policies/terms.jsp. JSTOR's Terms and Conditions of Use provides, in part, that unless you have obtained prior permission, you may not download an entire issue of a journal or multiple copies of articles, and you may use content in the JSTOR archive only for your personal, non-commercial use.	archive;download;integer programming;lagrangian relaxation;linear programming relaxation;relaxation (iterative method)	Marshall L. Fisher	2004	Management Science	10.1287/mnsc.1040.0263	mathematical optimization;randomized rounding;combinatorics;discrete mathematics;heuristic;integer programming;special ordered set;lagrangian relaxation;covering problems;linear programming relaxation;branch and price;mathematics;branch and bound;branch and cut	Comp.	23.413217548226765	10.334962613734067	45178
434cb6d2f3551d0706f18d6c837a18658efb04a4	hierarchical finite state controllers for generalized planning	info eu repo semantics conferenceobject	Finite State Controllers (FSCs) are an effective way to represent sequential plans compactly. By imposing appropriate conditions on transitions, FSCs can also represent generalized plans that solve a range of planning problems from a given domain. In this paper we introduce the concept of hierarchical FSCs for planning by allowing controllers to call other controllers. We show that hierarchical FSCs can represent generalized plans more compactly than individual FSCs. Moreover, our call mechanism makes it possible to generate hierarchical FSCs in a modular fashion, or even to apply recursion. We also introduce a compilation that enables a classical planner to generate hierarchical FSCs that solve challenging generalized planning problems. The compilation takes as input a set of planning problems from a given domain and outputs a single classical planning problem, whose solution corresponds to a hierarchical FSC.	compiler;finite-state machine;iterative deepening depth-first search;iterative method;machine learning;recursion;semantics (computer science);test-driven development	Javier Segovia Aguas;Sergio Jiménez Celorrio;Anders Jonsson	2016			mathematical optimization;discrete mathematics;computer science;artificial intelligence;mathematics;algorithm	AI	-2.693709562872224	10.227937073594221	45283
d7af8105d8aa574c493141242103f34e1396d0b6	diffusion approximation for a web-server system with proxy servers		It is an important and urgent Operations Research (OR) issue to evaluate the delay in a web-server system handling internet commerce real-time services. Usually, proxy servers in differently-located sites enable us to shorten the web-server access delay in order to guarantee the quality of real-time application services. However, there exists almost no literature on the queueing analyses for the web-server system with proxy servers. The goal of this paper is to provide a queueing analysis for the web-server system. We derive the statistics of the individual output processes from the proxy servers. Regarding the unfinished workload in the web-server system with input as a diffusion process, we derive a mean-delay explicit formula.	approximation;proxy server;web server	Yoshitaka Takahashi;Yoshiaki Shikata;Andreas Frey	2010		10.1007/978-3-642-20009-0_26	workload;mathematical optimization;the internet;mathematics;web server;heavy traffic approximation;diffusion process;queueing theory;proxy server;distributed computing;server	ECom	7.487230657480634	10.581230912222725	45310
64ee5099d6a68ea98158c9b27daadc6a9e144789	optimal trees for minimizing average individual updating cost	individual re keying;optimality;key tree;average case	Key tree is a popular model to maintain the security of group information sharing by using a tree structure to maintain the keys held by different users. Previously, researchers proved that to minimize the worst case updating cost in case of single user deletion, one needs to use a special 2-3 tree. In this paper, we study the average case for user update. We prove that in the optimal tree, the branching degree of every node can be bounded by 3 and furthermore the structure of the optimal tree can be pretty balanced. We also show the way to construct the optimal tree when there are loyal users in the group. Finally we discuss about the weighted case where different users have different probabilities to be the first one leaving the group. We design a polynomial time algorithm to construct the optimal tree when the number of different probabilities is a constant.		Sicen Guo;Minming Li;Yingchao Zhao	2015	Theor. Comput. Sci.	10.1016/j.tcs.2015.08.030	optimal binary search tree;left-child right-sibling binary tree;segment tree;mathematical optimization;combinatorics;discrete mathematics;vantage-point tree;exponential tree;trie;order statistic tree;incremental decision tree;k-ary tree;interval tree;mathematics;fractal tree index;search tree;tree;tree traversal;algorithm;avl tree	Theory	18.454724234162615	24.087527307330276	45414
c32c0f5928052bc78029f44f57933bc5a8709e57	analytical approximations to predict performance measures of markovian type manufacturing systems with job failures and parallel processing	performance measure;queuing network parametric decomposition web server assembly fork and join queues;service system;regression model;parametric decomposition;error correction;resource sharing;web server assembly;fork and join queues;queuing network;queuing networks;manufacturing system;simulation model;parallel processing	Manufacturing or service systems with multiple product classes, job circulation due to random failures, resources shared between product classes, and some portions of the manufacturing or assembly carried in series and the rest in parallel are commonly observed in real-life. The web server assembly is one such manufacturing system which exhibits the above characteristics. Predicting the performance measures of these manufacturing systems is not an easy task. The primary objective of this research was to propose analytical approximations to predict the flow times of the manufacturing systems, with the above characteristics, and evaluate its accuracy. The manufacturing system is represented as a network of queues. The parametric decomposition approach is used to develop analytical approximations for a system with arrival and service rates from a Markovian distribution. The results from the analytical approximations are compared to simulation models. In order to bridge the gap in error, correction terms were developed through regression modeling. The experimental study conducted indicates that the analytical approximations along with the correction terms can serve as a good estimate for the flow times of the manufacturing systems with the above characteristics.	approximation;parallel computing	Maria Hulett;Purushothaman Damodaran	2011	European Journal of Operational Research	10.1016/j.ejor.2011.01.034	shared resource;parallel processing;real-time computing;error detection and correction;computer science;marketing;operations management;simulation modeling;distributed computing;regression analysis;statistics;service system	Robotics	8.631705261598425	7.711365673187265	45467
05ea36ff4c99e6ff154bed4d96a1b1c6559e08cc	a knowledge-based energy management model that supports smart metering networks for korean residential energy grids	knowledge-based model;energy-efficient management;smart grid network;energy grid environment;smart metering network	The various energy management technologies that are required in order to deliver effective energy demand responses have resulted from the integrated use of digital technologies with energy grids. Therefore, the core technologies for smart metering infrastructure are regarded as a key issue in the design of future energy grids. The proposed knowledge-based model that supports advanced metering networks is capable of estimating energy consumption according to the characteristics of residential buildings. The energy consumption data is analyzed according to the residential building’s properties, which can significantly affect the energy consumption pattern. Therefore, appropriately designed models for energy consumption patterns with respect to identifying each energy consumption feature’s potential impact can be applied to create smart metering networks for future energy grid environments. This study introduces a knowledge-based model that considers both the energy and building management profiles. Then, case studies for the estimation of the energy consumption are presented. The proposed model could be effectively utilized in managing the energy demand response process with respect to market prices and residential energy shortages, and it provides a good reference for designing energy demand response strategies in Korean residential energy grid environments.	smart meter	Dongjun Suh;Ilmin Kim;Jinsul Kim	2017	Wireless Personal Communications	10.1007/s11277-015-3090-y	simulation;energy accounting;computer security;energy management	Mobile	1.4292569175958143	7.3023450780396	45478
fa2982071d26155d727f5ef576a8df8e9c7a1ebb	facility location problems with uncertainty on the plane	interval estimation;euclidean distance;robust optimization;interval data;objective function;polynomial algorithm;facility location problem;facility location	We consider single facility location problems (1-median and weighted 1-center) on a plane with uncertain weights and coordinates of customers (demand points). Specifically, for each customer, only interval estimates for its weight and coordinates are known. It is required to find a “minmax regret” location, i.e. tominimize theworst-case loss in the objective function value thatmay occur because the decision is madewithout knowing the exact values of customers’weights and coordinates that will get realized.Wepresent anO (n2 log2 n)algorithm for the interval dataminmax regret rectilinear 1-median problemand anO(n log n) algorithm for the interval dataminmax regret rectilinearweighted 1-center problem. For the case of Euclidean distances, we consider uncertainty only in customers’weights.We discuss possibilities of solving approximately the minmax regret Euclidean 1-median problem, and present an O(n22 (n) log2 n) algorithm for solving the minmax regret Euclidean weighted 1-center problem, where (n) is the inverse Ackermann function. © 2005 Elsevier B.V. All rights reserved.	1-center problem;ackermann function;algorithm;amortized analysis;binary logarithm;block cellular automaton;computation;computational geometry;emoticon;euclidean distance;extensibility;facility location problem;geometric median;local optimum;loss function;minimax;optimization problem;preprocessor;regret (decision theory);regular grid;sorting algorithm;triune continuum paradigm	Igor Averbakh;Sergey Bereg	2005	Discrete Optimization	10.1016/j.disopt.2004.12.001	mathematical optimization;combinatorics;discrete mathematics;robust optimization;facility location problem;mathematics;1-center problem	Theory	24.546559318688914	17.301087463378604	45489
b290ba0423ab04f92001803a50668abc7782cde2	mad-c: multi-stage approximate distributed cluster-combining for obstacle detection and localization		Efficient distributed multi-sensor monitoring is a key feature of upcoming digitalized infrastructures. We address the problem of obstacle detection, having as input multiple point clouds, from a set of laser-based distance sensors; the latter generate high-rate data and can rapidly exhaust baseline analysis methods, that gather and cluster all the data. We propose MAD-C, a distributed approximate method: it can build on any appropriate clustering, to process disjoint subsets of the data distributedly; MAD-C then distills each resulting cluster into a data-summary. The summaries, computable in a continuous way, in constant time and space, are combined, in an order-insensitive, concurrent fashion, to produce approximate volumetric representations of the objects. MAD-C leads to (i) communication savings proportional to the number of points, (ii) multiplicative decrease in the dominating component of the processing complexity and, at the same time, (iii) high accuracy (with RandIndex (u003e0.95)), in comparison to its baseline counterpart. We also propose MAD-C-ext, building on the MAD-C’s output, by further combining the original data-points, to improve the outcome granularity, with the same asymptotic processing savings as MAD-C.		Amir Keramatian;Vincenzo Gulisano;Marina Papatriantafilou;Philippas Tsigas;Yiannis Nikolakopoulos	2018		10.1007/978-3-030-10549-5_25	algorithm;spacetime;parallel computing;point cloud;granularity;obstacle;multiplicative function;cluster analysis;disjoint sets;computer science	Robotics	6.619372140012017	31.12993652591365	45492
ef0b92ac9be15dc8534cb978fc699482bb825db4	on guards and symbol dependencies in substring search	substring search;symbol dependency	Several ingenious and theoretically elegant principles for shifting a pattern (relative to text) during a pattern matching process have been devised during the last decade. Somewhat surprisingly, however, the fastest practical implementations do not try to maximize the length of the shift – on the contrary, they strip the components assisting in moving the pattern to a bare minimum. To compensate, at least partly, for the loss thus incurred, the concept of a guard has been introduced, the purpose of which is to detect a possible mismatch at a small computational cost before entering the actual match loop. In this paper, a comprehensive study of the factors having an effect on the selectivity of various guard strategies is given. Our aim is to complement the report of Smith [1] (Softw. Pract. Exper. , 24(4), 435–436 (1994)) and show that a fine-grained setting for this experiment is needed in order to detect detailed behaviour of the search process. Copyright 1999 John Wiley & Sons, Ltd.	algorithmic efficiency;fastest;john d. wiley;pattern matching;selectivity (electronic);string searching algorithm	Timo Raita	1999	Softw., Pract. Exper.	10.1002/(SICI)1097-024X(199909)29:11%3C931::AID-SPE264%3E3.0.CO;2-X	computer science;engineering;artificial intelligence;theoretical computer science;operating system;pattern matching;boyer–moore string search algorithm;programming language;algorithm	NLP	10.02615982587857	27.20849472661389	45509
aaee5cebf5d4c6b27b406d9bad1c492598f9d3e5	mergeable double-ended priority queues	performance;complexity;priority queue;double ended priority queues	We show that the leftist tree data structure may be adapted to obtain data structures that permit the double-ended priority queue operations Insert, DeleteMin, DeleteMax, and Merge to be done in O(log n) time where n is the size of the resulting queue. The operations FindMin and FindMax can be done in O(1) time. Experimental results are also presented.	priority queue	Seonghun Cho;Sartaj Sahni	1999	Int. J. Found. Comput. Sci.	10.1142/S0129054199000022	priority inheritance;double-ended queue;parallel computing;complexity;real-time computing;multilevel queue;performance;double-ended priority queue;computer science;distributed computing;queue management system;fork–join queue;queue;priority queue;priority ceiling protocol;algorithm	ECom	11.974192424467516	32.081818285322896	45577
dc03f4c1077b9b84889c25ad41fa5481d31b6746	describing the local structure of sequence graphs		Analysis of genetic variation using graph structures is an emerging paradigm of genomics. However, defining genetic sites on sequence graphs remains an open problem. Paten’s invention of the ultrabubble and snarl, special subgraphs of sequence graphs which can identified with efficient algorithms, represents important first step to segregating graphs into genetic sites. We extend the theory of ultrabubbles to a special subclass where every detail of the ultrabubble can be described in a series and parallel arrangement of genetic sites. We furthermore introduce the concept of bundle structures, which allows us to recognize the graph motifs created by additional combinations of variation in the graph, including but not limited to runs of abutting single nucleotide variants. We demonstrate linear-time identification of bundles in a bidirected graph. These two advances build on initial work on ultrabubbles in bidirected graphs, and define a more granular concept of genetic site.	algorithm;bidirected graph;graph (discrete mathematics);programming paradigm;time complexity	Yohei Rosen;Jordan M Eizenga;Benedict Paten	2017		10.1007/978-3-319-58163-7_2	block graph;pathwidth;topological graph theory;split graph;combinatorics;discrete mathematics;cograph;universal graph;bioinformatics;clique-width;forbidden graph characterization;comparability graph;mathematics;modular decomposition;partial k-tree;graph operations;indifference graph	ML	21.756017369167015	24.80238188939782	45578
00891201774b6e48f54a71693787efc07d7c83e0	fully homomorphic encryption without modulus switching from classical gapsvp		We present a new tensoring technique for LWE-based fully homomorphic encryption. While in all previous works, the ciphertext noise grows quadratically (B → B · poly(n)) with every multiplication (before “refreshing”), our noise only grows linearly (B → B · poly(n)). We use this technique to construct a scale-invariant fully homomorphic encryption scheme, whose properties only depend on the ratio between the modulus q and the initial noise level B, and not on their absolute values. Our scheme has a number of advantages over previous candidates: It uses the same modulus throughout the evaluation process (no need for “modulus switching”), and this modulus can take arbitrary form. In addition, security can be classically reduced from the worst-case hardness of the GapSVP problem (with quasi-polynomial approximation factor), whereas previous constructions could only exhibit a quantum reduction from GapSVP. ∗Stanford University, zvika@stanford.edu. Supported by a Simons Postdoctoral Fellowship and by DARPA.	approximation;best, worst and average case;ciphertext;homomorphic encryption;keneth alden simons;lattice problem;learning with errors;modulus of continuity;modulus robot;noise (electronics);polynomial;quasi-polynomial	Zvika Brakerski	2012		10.1007/978-3-642-32009-5_50	arithmetic;discrete mathematics;mathematics	Crypto	11.285880300344553	21.932102072683715	45598
5aebc7f066f475edc5e2c27e1daf694db2e82f29	on two-way sequential transductions of full semi-afl's		Abstract   Algebraic and grammatical characterizations of several classes of two-way sequential transductions of languages in a full semiAFL are presented. The algebraic characterizations are in terms of “generalized” replications involving homomorphisms and finite substitutions. The grammars are simple and are of the form found in parallel rewriting systems.	semiconductor industry;american fuzzy lop	Oscar H. Ibarra	1978	Theor. Comput. Sci.	10.1016/0304-3975(78)90019-1	combinatorics;discrete mathematics;mathematics;algorithm	ECom	-2.4312552081162617	19.464859003105467	45630
6bf42d57e96ae31e596aa7093f73b05cd58050c4	common due date scheduling problem with separate earliness and tardiness penalties	minimisation;minimization;heuristic method;metodo heuristico;date echeance;minimizacion;machine;experimental result;earliness;algorithme;algorithm;precocite;maquina;precocidad;funcion penalidad;scheduling;common due date;retard;due date;resultado experimental;branching method;scheduling problem;ordonamiento;methode heuristique;fonction penalite;resultat experimental;retraso;ordonnancement;penalty function;algoritmo	This paper considers the problem of linding an optimal schedule and a common due date for a set of jobs, in a static single machine system. The scheduling criterion is the minimization of the weighted sum of earliness and tardiness values. Different weights are considered as the earliness penalty and tardiness penalty, for each job. A branching procedure is presented for finding an optimal solution. An almost optimal heuristic is also presented.	heuristic;job stream;scheduling (computing);weight function	Parthasarati Dileepan	1993	Computers & OR	10.1016/0305-0548(93)90073-R	job shop scheduling;minimisation;mathematical optimization;machine;computer science;penalty method;mathematics;scheduling;algorithm	AI	17.347462186089256	9.52412952651215	45698
0bf40afedd83035c3333aaa1890b03d0864701d3	economy of description for basic constructions on rational transductions	rational transducers;state complexity;language operations	The state complexities of basic constructions on rational transductions are investigated. Given rational transductions, described by rational transducers, and an operation thereon we consider the number of states that is sufficient and necessary in the worst case to describe the resulting transduction. In particular, tight bounds are shown for inversion, union, weak intersection, concatenation, reversal, homomorphism, and composition, i.e., for some of those operations under which rational transductions are closed.	rational set	Henning Bordihn;Markus Holzer;Martin Kutrib	2002	Journal of Automata, Languages and Combinatorics	10.25596/jalc-2004-175	discrete mathematics;mathematics;algorithm	Logic	-1.4277093654759765	20.803619772029947	45699
ffb7fa0a9e90ff033b8e70d26d13c09d9950ca09	graph partitioning techniques for markov decision processes decomposition	graph partitioning;reasoning under uncertainty;markov decision process;markov decision processes	Recently, several authors have proposed serial decomposition techniques for solving approximately or exactly large Markov Decision Processes. Many of these techniques rely on a clever partitioning of the state space in roughly independent parts. The different parts only communicate through relatively few communicating states. The efficiency of these decomposition methods clearly depends on the size of the set of communicating states : the smaller, the better. However, the task of finding such a decomposition with few communicating states is often (if not always) left to the user. In this paper, we present automated decomposition techniques for MDPs. These techniques are based on methods which have been developed for graph partitioning problems.	graph partition;markov chain;markov decision process	Régis Sabbadin	2002			markov decision process;partially observable markov decision process;computer science;artificial intelligence;machine learning	Logic	16.701020936800884	32.05155072096159	45749
88cde15e886915694ef22e6ad13e2874679cd979	generalized powers of graphs and their algorithmic use	radio networks;modelizacion;assignment problem;multiplexage longueur onde;station radiodiffusion;coloracion grafo;probleme affectation;algorithmique;vertex;packet switching;conmutacion por paquete;algorithme;modelisation;algorithm;allocation frequence;coloration graphe;col;algorithmics;reseau radio;algoritmica;frequency assignment problem;frequency allocation;estructura datos;asignacion frecuencia;radio communication;problema asignacion;structure donnee;vertice;radiocommunication;radio station;graph model;modeling;data structure;commutation paquet;multiplaje longitud onda;estacion radiodifusion;radiocomunicacion;graph colouring;wavelength division multiplexing;algoritmo	Motivated by the frequency assignment problem in heterogeneous multihop radio networks, where different radio stations may have different transmission ranges, we introduce two new types of coloring of graphs, which generalize the well-known Distance-k-Coloring. Let G = (V, E) be a graph modeling a radio network, and assume that each vertex v of G has its own transmission radius r(v), a nonnegative integer. We define r-coloring (r-coloring) of G as an assignment Φ : V → {0, 1, 2, . . .} of colors to vertices such that Φ(u) = Φ(v) implies dG(u, v) > r(v) + r(u) (dG(u, v) > r(v) + r(u) + 1, respectively). The r-Coloring problem (the r-Coloring problem) asks for a given graph G and a radius-function r : V → N ∪ {0}, to find an r-coloring (an rcoloring, respectively) of G with minimum number of colors. Using a new notion of generalized powers of graphs, we investigate the complexity of the r-Coloring and r-Coloring problems on several families of graphs.	assignment problem;color;emoticon;graph coloring;radio broadcasting;whole earth 'lectronic link	Andreas Brandstädt;Feodor F. Dragan;Yang Xiang;Chenyu Yan	2006		10.1007/11785293_39	radio broadcasting;vertex;combinatorics;systems modeling;frequency allocation;data structure;telecommunications;computer science;mathematics;assignment problem;algorithmics;algorithm;packet switching;wavelength-division multiplexing	Theory	21.037163771845798	28.682278260634725	45752
3419e4107d3e4b6cb10eeb0fb3e7860318f7851b	the computational complexity of the relative robust shortest path problem with interval data	robust optimization;interval data;computational complexity;weighted graph;combinatorial optimization;shortest path problem	The paper deals with the relative robust shortest path problem in a directed arc weighted graph, where arc lengths are specified as intervals containing possible realizations of arc lengths. The complexity status of this problem has been unknown in the literature. We show that the problem is        -hard.	computational complexity theory;shortest path problem	Pawel Zielinski	2004	European Journal of Operational Research	10.1016/S0377-2217(03)00373-4	optimization problem;mathematical optimization;combinatorics;discrete mathematics;robust optimization;canadian traveller problem;widest path problem;constrained shortest path first;longest path problem;combinatorial optimization;pathfinding;euclidean shortest path;mathematics;shortest path problem;computational complexity theory;distance;k shortest path routing;shortest path faster algorithm	Theory	23.666841729645164	17.140245225707503	45759
3896c230a8acecfc62f39dbf6319ed7dd3ca83e0	quantum existence testing and its application for finding extreme values in unsorted databases	quantum counting;structured database queries;query processing;quantum existence testing;database management systems;grower searching algorithm;search algorithm;probability of error;quantum computing based solutions;counting search quantum existence testing;classical solution;search problems computational complexity database management systems error statistics parallel processing quantum computing query processing;search;unsorted databases;logarithmic search algorithm;extreme value;quantum computer;computational complexity;information processing;counting;error statistics;error probability quantum existence testing unsorted databases information processing computational complexity quantum computing based solutions grower searching algorithm parallel processing quantum counting logarithmic search algorithm structured database queries;error probability;search problems;quantum computing;database query;parallel processing	Many information processing and computing problems can be traced back to find the extreme value of a database or a function. Unfortunately, classical solutions suffer from high computational complexity if the database is unsorted or, equivalently, the function has many local minimum/maximum points. Proposed quantum computing-based solutions involve the repeated application of Grower's searching algorithm. In this paper, we introduce a new technique exploiting the parallel processing capabilities of quantum computing in a different way. We derive a special case of quantum counting - we call it quantum existence testing - which allows adapting the classical logarithmic search algorithm so that it is suitable for structured databases to unstructured ones. The paper analyzes the required number of database queries, the corresponding computational complexity, and the probability of error and their relationship	binary search algorithm;computational complexity theory;database;information processing;maxima and minima;parallel computing;quantum computing;search algorithm	Sándor Imre	2007	IEEE Transactions on Computers	10.1109/TC.2007.1032	parallel processing;discrete mathematics;quantum information;information processing;quantum complexity theory;computer science;theoretical computer science;probability of error;mathematics;quantum computer;quantum algorithm;algorithm;quantum phase estimation algorithm;statistics;quantum sort	DB	11.837776526482594	24.67790458261481	45763
cdd1c9bc8815f4ce5e3f7196f2dd43314f35cb27	a note on proving the strong np-hardness of some scheduling problems with start time dependent job processing times		In this paper, we show that the strong NP-hardness proofs of some scheduling problems with start time dependent job processing times presented in Gawiejnowicz (Eur J Oper Res 180:472–478, 2007) and Zhao and Tang (Optim Lett 5:183–190, 2011) are incorrect. Namely, the applied transformations from 4-Product problem to the considered scheduling problems are polynomial not pseudopolynomial. Thus, the related problems are NP-hard, but their complete computational status is still an open issue: ordinary or strongly NP-hard?	computation;np-hardness;polynomial;pseudo-polynomial time;scheduling (computing);strong np-completeness	Radoslaw Rudek	2012	Optimization Letters	10.1007/s11590-011-0330-2	mathematical optimization;mathematics;algorithm	Theory	18.498652777623025	11.328582601393238	45780
5c86b9cdab432c6dcb06eb188bbe019e961962a8	settling the randomized k-sever conjecture on some special metrics		The k-server problem is one of the most fundamental online problems, which is introduced by Manasse, McGeoch and Sleator [27, 28]. The problem is to schedule k mobile servers to serve a sequence of requests in a metric space with the minimum possible movement distance. The randomized k-sever conjecture states that there exists O(log k)-competitive randomized algorithms for the k-sever problem. The conjectures has been open for over 24 years. In this paper, we settle the randomized k-sever conjecture for the following metric spaces: line, circle, Hierarchically well-separated tree (HST), if k = 2 or n = k + 1 for arbitrary metric spaces. Specially, we show that there are O(log k)-competitive randomized k-sever algorithms for above metric spaces. For any general metric space with n points, we show that there is an O(log k log n)-competitive randomized k-sever algorithm, which improved the previous best competitive ratio O(log k log n log log n) by Nikhil Bansal et al. (FOCS 2011, pages 267276). Above algorithms refer to lazy algorithms, i.e., algorithms move only one sever to serve the requested point only if the requested point is not served. In addition, we still show that there exists a O(log k)-competitive randomized non-lazy algorithm for the k-sever problem.	catherine mcgeoch;competitive analysis (online algorithm);existential quantification;k-server problem;lazy evaluation;log-space reduction;randomized algorithm;randomized rounding;server (computing);symposium on foundations of computer science	Wenbin Chen	2014	CoRR		mathematical optimization;combinatorics;discrete mathematics;topology;mathematics	Theory	16.594839586244866	16.14535025708925	45811
450ebbb5ac60b70eb663a31d0a47820dc2994174	optimal sizing of energy storage systems for industrial production plants		Most developed countries around the world are seriously concerned about recent global warming, the depletion of fossil fuels and environmental degradation. So as to meet the environmental burden reduction targets set by different international agreements, manufacturing companies are seriously en- couraged to invest considerable efforts in the field of energy. Energy storage systems (ESS) have the potential to revolutionize the way in which electrical power grids are designed and operated. Presently, power grids require that the generation of electricity continuously balance the demand. The constant balanc- ing of supply and demand has significant operational and cost implications. In- corporation of storage devices into the grid should reduce this constraint by enabling electrical energy to be withdrawn from the grid when there is excess generation and held in reserve until needed. In this work we consider stationary applications with medium discharge time (minutes to hours), thus batteries have been considered. The object is to find the optimal sizing of the energy storage device (i.e. batteries) with which it is possible to minimize the cost of energy in a production plant.		Simone Zanoni;Beatrice Marchi	2014		10.1007/978-3-662-44736-9_42	simulation;engineering;electrical engineering;operations management	Robotics	2.997556242270775	7.38936213001318	45824
d3b2dca73184f990f0bdb6e65cd4090cb7876173	duel and sweep algorithm for order-preserving pattern matching		Given a text T and a pattern P over alphabet Σ, the classic exact matching problem searches for all occurrences of pattern P in text T . Unlike exact matching problem, order-preserving pattern matching (OPPM) considers the relative order of elements, rather than their real values. In this paper, we propose an efficient algorithm for OPPM problem using the “duel-and-sweep” paradigm. Our algorithm runs in O(n+m logm) time in general and O(n + m) time under an assumption that the characters in a string can be sorted in linear time with respect to the string size. We also perform experiments and show that our algorithm is faster that KMP-based algorithm. Last, we introduce the two-dimensional order preserved pattern matching and give a duel and sweep algorithm that runs in O(n) time for duel stage and O(nm) time for sweeping time with O(m) preprocessing time.	algorithm;experiment;klee's measure problem;pattern matching;preprocessor;programming paradigm;time complexity	Davaajav Jargalsaikhan;Diptarama;Yohei Ueki;Ryo Yoshinaka;Ayumi Shinohara	2018		10.1007/978-3-319-73117-9_44	combinatorics;time complexity;discrete mathematics;pattern matching;mathematics;algorithm;alphabet	Theory	13.391891460890578	27.15123583218179	45834
727218d1ef745da7f2c58fccdcad7092bd50c484	an optimal drum scheduling algorithm	traveling salesman problem;graph theory;disk scheduling;rotational latency analysis;disk scheduling drum scheduling file scheduling graph theory rotational latency analysis theory of scheduling traveling salesman problem;scheduling algorithm;file scheduling;drum scheduling;computational complexity;theory of scheduling	Suppose a set of N records must be read or written from a drum, fixed-head disk, or similar storage unit of a computer system. The records vary in length and are arbitrarily located on the surface of the drum. The problem considered here is to find an algorithm that schedules the processing of these records with the minimal total amount of rotational latency (access time), taking into account the current position of the drum. This problem is a special case of the traveling salesman problem. The algorithm that is developed has the attractive property of exhibiting a computational complexity on the order of N log N.	access time;algorithm;computational complexity theory;computer;hard disk drive performance characteristics;scheduling (computing);travelling salesman problem	Samuel H. Fuller	1972	IEEE Transactions on Computers	10.1109/T-C.1972.223472	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;open-shop scheduling;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;graph theory;theoretical computer science;operating system;two-level scheduling;distributed computing;least slack time scheduling;lottery scheduling;travelling salesman problem;computational complexity theory;round-robin scheduling;scheduling;multiprocessor scheduling;algorithm;i/o scheduling	Theory	15.831505046279602	10.98027817605383	45840
3fe4e3989382708c120688f29a522a68de886fcd	the bqp-hardness of approximating the jones polynomial	lie algebra;representation theory;roots of unity;jones polynomial;quantum physics;computational complexity;hardness of approximation	Following the work by Kitaev, Freedman and Wang [1], Aharonov, Jones and Landau [3] recently gave an explicit and efficient quantum algorithm for approximating the Jones polynomial of the plat closure of a braid, at the kth root of unity, for constant k. The universality proof of Freedman, Larsen and Wang [2] implies that the problem which these algorithms solve is BQP-hard. The fact that this is the only non-trivial BQP-complete problem known today motivates a deep investigation of this topic. A natural question which was raised in [3] is the following. The results of [3] actually gave efficient algorithms also in the case of asymptotically growing k’s up to k which is polynomial in the size of the braid. However, the results of [2] only imply universality in the case of constant k, via the SolovayKitaev theorem; The application of this theorem relies heavily on the fact that the generators of the groups in question are fixed. The question of the complexity of the problems with asymptotically growing k was thus left open. In this paper we resolve this question and prove that the Jones polynomial approximation problem is BQP-complete also for asymptotically growing k (bounded by a polynomial). To do this we introduce some new techniques for analyzing universality in quantum computation, which enable us to apply Solovay-Kitaev indirectly. As a side benefit, we reprove the density theorem of [2] using quite elementary arguments; this hopefully sheds light on the reason that these problems are indeed quantum-hard. email: itaia@cs.huji.ac.il	aharonov–bohm effect;approximation algorithm;audio feedback;bqp;bell's theorem;braid;computation;email;jones calculus;jones polynomial;quantum algorithm;quantum computing;root of unity;universal turing machine;universality probability	Dorit Aharonov;Itai Arad	2006	CoRR	10.1088/1367-2630/13/3/035019	lie algebra;representation theory;root of unity;hardness of approximation;computational complexity theory;jones polynomial;physics;quantum mechanics	Theory	10.772102177014213	20.59751260699059	45854
5580d2cb50cdc01297dc192e2b4b69f8e98d72e2	the 1-versus-2 queries problem revisited	bounded queries;efficient algorithm;complexity class;computational complexity;complexity classes;polynomial time;randomized algorithm;zero error algorithms	The 1-versus-2 queries problem, which has been extensively studied in computational complexity theory, asks in its generality whether every efficient algorithm that makes at most 2 queries to a Σ k p -complete language L k has an efficient simulation that makes at most 1 query to L k . We obtain solutions to this problem for hypotheses weaker than previously considered. We prove that: (I) For each k≥2, $\mathrm{P}^{\Sigma^{p}_{k}[2]}_{tt}\subseteq \mathrm{ZPP}^{\Sigma^{p}_{k}[1]}\Rightarrow \mathrm{PH}=\Sigma^{p}_{k}$ , and (II) P tt NP[2] ⊆ZPPNP[1] ⇒PH=S 2 p . Here, for any complexity class $\mathcal{C}$ and integer j≥1, we define $\mathrm{ZPP}^{\mathcal{C}[j]}$ to be the class of problems solvable by zero-error randomized algorithms that run in polynomial time, make at most j queries to $\mathcal{C}$ , and succeed with probability at least 1/2+1/poly(⋅). This same definition of $\mathrm{ZPP}^{\mathcal{C}[j]}$ , also considered in Cai and Chakaravarthy (J. Comb. Optim. 11(2):189–202, 2006), subsumes the class of problems solvable by randomized algorithms that always answer correctly in expected polynomial time and make at most j queries to $\mathcal{C}$ . For each k≥2, $\mathrm{P}^{\Sigma^{p}_{k}[2]}_{tt}\subseteq \mathrm{ZPP}^{\Sigma^{p}_{k}[1]}\Rightarrow \mathrm{PH}=\Sigma^{p}_{k}$ , and P tt NP[2] ⊆ZPPNP[1] ⇒PH=S 2 p . Hemaspaandra, Hemaspaandra, and Hempel (SIAM J. Comput. 28(2):383–393, 1998), for k>2, and Buhrman and Fortnow (J. Comput. Syst. Sci. 59(2):182–194, 1999), for k=2, had obtained the same consequence as ours in (I) using the stronger hypothesis $\mathrm{P}^{\Sigma^{p}_{k}[2]}_{tt}\subseteq \mathrm{P}^{\Sigma^{p}_{k}[1]}$ . Fortnow, Pavan, and Sengupta (J. Comput. Syst. Sci. 74(3):358–363, 2008) had obtained the same consequence as ours in (II) using the stronger hypothesis P tt NP[2] ⊆PNP[1]. Our results may also be viewed as steps towards obtaining solutions to arguably the most general form of the 1-versus-2 queries problem: For any k≥1, whether $\mathrm{P}^{\Sigma^{p}_{k}[2]}_{tt}$ can be simulated in $\mathrm{BPP}^{\Sigma^{p}_{k}[1]}$ .	bpp (complexity);complexity class;computation;computational complexity theory;decision problem;foremost;graph coloring;ph (complexity);phone connector (audio);polynomial;randomized algorithm;resolution (logic);simulation;time complexity;truth-table reduction;turing reduction;zpp (complexity)	Rahul Tripathi	2007	Theory of Computing Systems	10.1007/s00224-008-9126-x	complexity class;combinatorics;discrete mathematics;computer science;mathematics;algorithm	Theory	8.48727944813552	20.352258177477875	45856
804e48f4f9a17c9b1ca6e0470132ff6fb00a43b5	inapproximability results on stable marriage problems	cardinal number;mujer;woman;stable matching;hombre;problema np duro;np hard problem;nombre cardinal;numero cardinal;femme;probleme np difficile;human;preferencia;stable marriage problem;incomplete preferences;preference;homme	The stable marriage problem has received considerable attention both due to its practical applications as well as its mathematical structure. While the original problem has all participants rank all members of the opposite sex in a strict order of preference, two natural variations are to allow for incomplete preference lists and ties in the preferences. Both variations are polynomially solvable by a variation of the classical algorithm of Gale and Shapley. On the other hand, it has recently been shown to be NP-hard to find a maximum cardinality stable matching when both of the variations are allowed. We show here that it is APX-hard to approximate the maximum cardinality stable matching with incomplete lists and ties. This holds for some very restricted instances both in terms of lengths of preference lists, and lengths and occurrences of ties in the lists. We also obtain an optimal Ω(N) hardness results for ’minimum egalitarian’ and ’minimum regret’	apx;approximation algorithm;decision problem;hardness of approximation;mathematical structure;np-hardness;stable marriage problem;wish list	Magnús M. Halldórsson;Kazuo Iwama;Shuichi Miyazaki;Yasufumi Morita	2002		10.1007/3-540-45995-2_48	combinatorics;stable marriage problem;artificial intelligence;mathematics;algorithm	ECom	18.211724482539978	17.787724715432205	45928
1ada189ad7673dbe5b4a6e6018ab7544c5c62452	families of noncounting languages and their learnability from positive data	local languages;reversible languages;learnability from positive data;finite elasticity;noncounting languages	This paper introduces some subclasses of noncounting languages and presents some results on the learnability of the classes from positive data. We first establish several relationships among the language classes introduced and the class of reversible languages. Especially, we introduce the notion of local parsability, and define a class (k, l)-CLTS, which is a subclass of the class of concatenations of strictly locally testable languages. We show its close relation to the class of reversible languages. We then study on the relationship between the closure of the Boolean operations and the learnability in the limit from positive data only. Further, we explore the learnability question of some subclasses of noncounting languages in the model of identification in the limit from positive data. In particular, we show that, for each k, l≥1, (k, l)-CLTS is identifiable in the limit from positive data using reversible automata with the conjectures updated in polynomial time. Some possible applications of the result are also briefly discussed.	learnability	Satoshi Kobayashi;Takashi Yokomori	1996	Int. J. Found. Comput. Sci.	10.1142/S0129054196000221	combinatorics;discrete mathematics;mathematics;cone;abstract family of languages;algorithm	AI	-3.13014712857905	16.708629310839687	45960
657dd61d751c6154f06a346065f2c1dacca6e956	on (1, epsilon)-restricted max-min fair allocation problem		We study the max-min fair allocation problem in which a set of m indivisible items are to be distributed among n agents such that the minimum utility among all agents is maximized. In the restricted setting, the utility of each item j on agent i is either 0 or some non-negative weight w_j. For this setting, Asadpour et al. [TALG, 2012] showed that a certain configuration-LP can be used to estimate the optimal value within a factor of 4 + delta, for any delta u003e 0, which was recently extended by Annamalai et al. [SODA 2015] to give a polynomial-time 13-approximation algorithm for the problem. For hardness results, Bezakova and Dani [SIGecom Exch., 2005] showed that it is NP-hard to approximate the problem within any ratio smaller than 2.rnrnIn this paper we consider the (1, epsilon)-restricted max-min fair allocation problem, in which for some parameter epsilon in (0, 1), each item j is either heavy (w_j = 1) or light (w_j = epsilon). We show that the (1, epsilon)-restricted case is also NP-hard to approximate within any ratio smaller than 2. Hence, this simple special case is still algorithmically interesting.rnrnUsing the configuration-LP, we are able to estimate the optimal value of the problem within a factor of 3 + delta, for any delta u003e 0. Extending this idea, we also obtain a quasi-polynomial time (3 + 4 epsilon)-approximation algorithm and a polynomial time 9-approximation algorithm. Moreover, we show that as epsilon tends to 0, the approximation ratio of our polynomial-time algorithm approaches 3 + 2 sqrt{2} approx 5.83.		T.-H. Hubert Chan;Zhihao Gavin Tang;Xiaowei Wu	2016		10.4230/LIPIcs.ISAAC.2016.23	time complexity;combinatorics;computer science;special case	ECom	17.479254714052963	15.429955119410042	45963
bd653733434470f3b066601477e60b2ccc5d0fe8	initial validation of mobile-structural health monitoring method using smartphones		The structural health monitoring system has made great development nowadays, especially on bridge structures. Meanwhile, most SHM systems reported were designed, integrated, and installed into large-scale infrastructures by professionals and equipped with expensive sensors, data acquisition devices, data transfer systems, and so forth. And it is impossible to install SHM system for every civilian building. For this status, a kind of new idea for structural health monitoring using smartphone is introduced in this paper. A smartphone, with embedded responding SHM software and inner sensors or external sensors, can be used not only as a single wireless sensor node but also as a mini-SHM system. The method is described in detail, and then the swing test, cable force test in laboratory, and cable force test on an actual bridge based on the iPhone were conducted to validate the proposed method. The experimental results show that Mobile-SHM using smartphone is feasible. The realization of Mobile-SHM method using smartphones may be considered as a milestone in making SHM popular in the lives of people.	smartphone	Yan Yu;Ruicong Han;Xuefeng Zhao;Xingquan Mao;Wei-Tong Hu;Dong Jiao;Mingchu Li;Jinping Ou	2015	IJDSN	10.1155/2015/274391	embedded system;simulation;computer security	HCI	1.3290362917059078	30.680601453782707	45974
65ca68701d9ad609599e9e8a34d5c0b04de098b1	a human-in-the-loop architecture for mobile network: from the view of large scale mobile data traffic	human-in-the-loop;data traffic pattern;data traffic usage behavior;mobile networks	Unlike other radio signal services, 5G is anticipated to play a huge role in offering services to heterogeneous networks, technologies, and devices operating in different geographic regions to fulfill the high expectation of users with relatively low energy consumption, which implies the necessity for moving from a system-centric design to a more user- or even human- and data- centric design paradigm “to keep the human in the loop” in future network. It drives us to design a system with capacity to allocate network resource dynamically according to feedback from users. This paper presents a Human-In-The-Loop architecture for mobile network that discovers users’ needs on network resource by understanding data traffic usage behavior of users. Based on real data traffic of mobile network, we analyze data traffic patterns of heavy and normal users from the view of online browsing behavior and urban functional area to explain how and why the data traffic is consumed. Then we propose a Latent Dirichlet Allocation model based solution to correlate data traffic, user behavior, and urban ecology to gain deep insights into spatio-temporal dynamic of data traffic usage behavior for different groups of users. Drawing upon results from a comprehensive study of users in a metropolitan city in China, we achieve a broad understanding about the difference of data traffic usage patterns of heavy and normal user: (1) besides the amount of generated data traffic, two groups of users can be easily distinguished by usage behavior of limited number of applications at midnight, (2) the functions of locations have huge impact on data usage patterns of users, which implies that urban ecology will shape users’ online behavior. The results of this work can potentially be exploited to help to allocate network resource, improve Quality of Experience according to users’ needs, and even design the future network.		Yuanyuan Qiao;Jianyang Yu;Wenhui Lin;Jie Yang	2018	Wireless Personal Communications	10.1007/s11277-017-5049-7	computer science;mobile database;mobile search;public land mobile network;computer network;radio access network;heterogeneous network;floating car data;small cell;mobile computing;distributed computing	Mobile	-1.9912300994909895	28.76262374026447	46074
188478e4e98ae3fb7dd8aae19fed77ccd0375f36	on validating boolean optimizers	boolean optimization;optimisation;tree searching boolean functions optimisation;boolean functions;proof traces boolean optimization;satisfiability;artificial intelligent;branch and bound search boolean optimizer validation iterative calls np oracle;pseudo boolean optimization;binary search;tree searching;branch and bound;proof traces	Boolean optimization finds a wide range of application domains, that motivated different organizations of Boolean optimizers. Some of the most successful approaches are based on iterative calls to an NP oracle. The increasing use of Boolean optimizers in practical settings raises the question of confidence in computed results. Recent work studied the validation of Boolean optimizers based on branch-and-bound search. This paper complements existing work, and develops methods for validating Boolean optimizers based on iterative calls to an NP oracle. Preliminary results indicate that the impact of the proposed method in overall performance is negligible.	algorithm;boolean satisfiability problem;branch and bound;iterative method;mathematical optimization;oracle machine;overhead (computing);solver	António Morgado;Joao Marques-Silva	2011	2011 IEEE 23rd International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2011.157	boolean algebra;boolean circuit;and-inverter graph;circuit minimization for boolean functions;discrete mathematics;boolean expression;standard boolean model;computer science;artificial intelligence;maximum satisfiability problem;theoretical computer science;karp–lipton theorem;machine learning;cook–levin theorem;mathematics;boolean function;boolean satisfiability problem;branch and bound;algorithm;short-circuit evaluation;binary search algorithm;satisfiability	EDA	12.977668339260104	17.246400186164315	46099
f4d0bae00de5ddd583272b208f9efe5ce2f354c9	a simulated annealing algorithm for the maximum planar subgraph problem	simulated annealing algorithm;simulated annealing;maximum planar subgraph;graph planarization;greedy randomized adaptive search procedure;branch and cut;heuristic algorithm	In this paper, we introduce a new heuristic algorithm for finding maximum planar subgraphs of a graph. Our algorithm is based on the simulated annealing optimization scheme. We compare the quality of the solutions and running times of our algorithm with greedy randomized adaptive search procedure (GRASP) and branch-and-cut heuristics. We show that simulated annealing is an efficient method to find planar subgraphs with a large number of edges. The algorithm clearly outperforms earlier heuristic algorithms; it is faster and its solution quality is better. The algorithm is very simple, although it needs an implementation for the planarity test.	algorithm;planarization;simulated annealing	Timo Poranen	2004	Int. J. Comput. Math.	10.1080/00207160410001684352	greedy randomized adaptive search procedure;mathematical optimization;combinatorics;greedy algorithm;simulated annealing;hill climbing;machine learning;mathematics;best-first search;adaptive simulated annealing;search algorithm	Theory	24.278687116068028	5.6794254195565195	46129
0569123b5117efe7c64de8d6888ed2461d7a2746	predicting the number of distinct elements in a multiset	decision tree;complexity;comparison;multiset;predicting problem;oracle argument	The bounds of the number of comparisons are obtained for the problem of determining whether the number of distinct elements in a given multiset is no more than a given threshold value. Those bounds are asymptotically optimal within constant factors. Two models of the algorithm are considered to derive those bounds.		Kohei Noshita	1982	SIAM J. Comput.	10.1137/0211052	partition problem;combinatorics;discrete mathematics;complexity;computer science;decision tree;mathematics;algorithm	Theory	17.276141500668228	20.911156000493428	46130
dc0b3326a3b56d554a87ca8357abea22e69906f2	mobility aware scheduling for imbalance reduction through charging coordination of electric vehicles in smart grid	vanet;smart grid;scheduling;electric vehicle	Electric vehicles (EVs) are being introduced by different manufacturers as an environment-friendly alternative to vehicles with internal combustion engines. The number of EVs is expected to grow rapidly in the coming years which will act as distributed loads in the demand side of the smart grid. On the supply side, an aggregator has to predict a load schedule 12–36 h in advance to charge the EVs and purchase energy accordingly from the day-ahead market. The goal of the aggregator is to schedule the EVs at different charging stations along the route of the EVs for charging so that the energy imbalance between the energy purchased and the energy consumed by the EVs is minimized while maximizing the number of EVs charged. In this work, we refer to this problem as the  Bounded Maximum Energy Usage Maximum EV Charging Problem  where mobile EVs communicate their charging preferences to the aggregator and the aggregator schedules EVs to different charging stations in their route so as to maximize both the purchased energy utilization (and therefore, minimum energy imbalance) and the number of EVs charged. We first prove that the problem is NP-complete. A pseudo-polynomial algorithm is proposed for a restricted version of the problem that can act as an upper bound for the energy usage. We also give an upper bound for the number of EVs charged. An offline and an online heuristic are then proposed to solve the problem. Detailed simulation results in different city traffic scenarios are presented to show the performance of the algorithms.	scheduling (computing)	Joy Chandra Mukherjee;Saurabh Shukla;Arobinda Gupta	2015	Pervasive and Mobile Computing	10.1016/j.pmcj.2014.12.004	vehicular ad hoc network;simulation;computer science;operating system;smart grid;scheduling;computer security	HCI	6.147864814730317	6.413288679991913	46138
5571bb63986a8937610129902d4b51103b3ca1c9	classifying molecular sequences using a linkage graph with their pairwise similarities	dynamic programming;graph theory;recouvrement graphe;escherichia coli;cubierta grafo;secuencia aminoacido;programacion dinamica;teoria grafo;approximate algorithm;sequence aminoacide;aminoacid sequence;clique problem;sequence similarity;bacterie;probleme np complet;protein sequence;aproximacion;triangle inequality;graph clique;chaine caractere;dynamic program;protein sequence classification;classification;theorie graphe;enterobacteriaceae;approximation;algorithme;algorithm;graph covering;multi domain;cadena caracter;programmation dynamique;tratamiento caracter;problema np completo;bacteria;clique graphe;evolutionary process;grafo completo;complete graph;graphe complet;clasificacion;traitement caractere;local alignment;np complete problem;character processing;character string;algoritmo	This paper presents a method for classifying a large and mixed set of uncharacterized sequences provided by genome projects. As the measure of sequence similarity, we use similarity score computed by a method based on the dynamic programming (DP), such as the Smith–Waterman local alignment algorithm. Although comparison by DP based method is very sensitive, when given sequences include a family of sequences that are much diverged in evolutionary process, similarity among some of them may be hidden behind spurious similarity of some unrelated sequences. Also the distance derived from the similarity score may not be metric (i.e., triangle inequality may not hold) when some sequences have multi-domain structure. To cope with these problems, we introduce a new graph structure called p-quasi complete graph for describing a family of sequences with a con dence measure. We prove that a restricted version of the pquasi complete graph problem (given a positive integer k, whether a graph contains a 0.5-quasi complete subgraph of which size ¿k or not) is NP-complete. Thus we present an approximation algorithm for classifying a set of sequences using p-quasi complete subgraphs. The e ectiveness of our method is demonstrated by the result of classifying over 4000 protein sequences on the Escherichia coli genome that was completely determined recently. c © 1999—Elsevier Science B.V. All rights reserved	approximation algorithm;cluster analysis;dspace;dynamic programming;hierarchical clustering;homology (biology);linkage (software);multi-function printer;np-completeness;naruto shippuden: clash of ninja revolution 3;national institute of genetics;peptide sequence;qualitative comparative analysis;randomness;regular expression;sensor;sequence alignment;smith–waterman algorithm;social inequality;weatherstar	Hideo Matsuda;T. Ishihara;Akihiro Hashimoto	1999	Theor. Comput. Sci.	10.1016/S0304-3975(98)00091-7	clique;combinatorics;discrete mathematics;np-complete;string;bacteria;biological classification;computer science;clique problem;graph theory;approximation;dynamic programming;smith–waterman algorithm;protein sequencing;triangle inequality;mathematics;escherichia coli;complete graph;algorithm	Comp.	16.60976308932567	24.95682929908152	46170
6a21da6b815344ca1c52f6425625bf679964aed7	vpspace and a transfer theorem over the complex field	effondrement;bss model;temps polynomial;espace polynomial;complexite calcul;valiant s model;modelo blum shub smale;polynomial;probleme decision;decision problem;complejidad computacion;complexite algebrique;computational complexity;informatique theorique;polinomio;polynomial time;modele blum shub smale;model of computation;collapse;algebraic complexity;polynome;desmoronamiento;12dxx;parc;blum shub smale model;computer theory;tiempo polinomial;informatica teorica	"""We extend the transfer theorem of [14] to the complex field. That is, we investigate the links between the class VPSPACE of families of polynomials and the Blum-Shub-Smale model of computation over C. Roughly speaking, a family of polynomials is in VPSPACE if its coefficients can be computed in polynomial space. Our main result is that if (uniform, constant-free) VPSPACE families can be evaluated efficiently, then the class PAR""""C of decision problems that can be solved in parallel polynomial time over the complex field collapses to P""""C. As a result, one must first be able to show that there are VPSPACE families which are hard to evaluate in order to separate P""""C from NP""""C, or even from PAR""""C."""	transfer function	Pascal Koiran;Sylvain Perifel	2009	Theor. Comput. Sci.	10.1016/j.tcs.2009.08.026	model of computation;time complexity;combinatorics;computer science;decision problem;mathematics;computational complexity theory;algorithm;polynomial;algebra;collapse	Theory	5.809638006576348	22.670840083969637	46202
c72239b1f741da99fb2cbb12cc936dba8e9c097c	sequence independent lifting for mixed integer programs with variable upper bounds	polyhedral theory;probleme charge fixe;programacion entera;polyedre;capsula convexa;poliedro;fixed charge problem;problema np duro;polyhedron;valid inequalities;programmation en nombres entiers;enveloppe convexe;upper bound;np hard problem;mixed integer program;programacion mixta entera;integer programming;probleme np difficile;mathematical programming;problema carga fija;programmation partiellement en nombres entiers;mixed integer programming;convex hull;programmation mathematique;programacion matematica	We investigate the convex hull of the set defined by a single inequality with continuous and binary variables with variable upper bound constraints. We extend the traditional flow cover inequality, and show that it is valid for a restriction of the set in which some variables are fixed. We also give conditions under which this inequality is facet-defining and, when it is not, we show how it can be lifted to obtain valid inequalities for the entire set using sequence independent lifting. In general, computing the lifting function is NP-hard, but under an additional restriction on the cover we obtain a closed form. Finally, we show how these results imply and extend known results about the single node fixed charge flow polyhedron.	lifting scheme;linear programming	Sergey Shebalov;Diego Klabjan	2006	Math. Program.	10.1007/s10107-005-0664-6	mathematical optimization;combinatorics;discrete mathematics;integer programming;convex hull;np-hard;mathematics;upper and lower bounds;polyhedron	Logic	24.244349850997093	12.862509401764212	46291
f3f4f516915f0588573c38f4a3a15bcf213034fc	some properties of finite special string-rewriting systems	theorie groupe;monoid;automatic proving;sistema informatico;chaine caractere;computer system;demostracion automatica;group theory;monoide;congruencia;demonstration automatique;rewrite systems;reecriture;cadena caracter;systeme informatique;decidibilidad;rewriting;decidabilite;teoria grupo;congruence;reescritura;decidability;character string	This paper investigates decision problems of finite, special string-rewriting systems . There are two main results . The first one is that the word problem for a finite, special string-rewriting system T on alphabet A is reducible to its restricted version: given a word w, is w congruent to any fixed element z on A? Another is a Markov type theorem : a property P is undecidable for finite, special string-rewriting systems if P implies any fixed Markov property of finitely presented special monoids and there exists a finite, special string-rewriting system R on alphabet C with the property that a finite, special string-rewriting system T on A has P whenever M(A ;T) is isomorphic to M(C ; R) .	decision problem;ibm system r;markov chain;markov property;rewriting;semi-thue system;undecidable problem	Liqing Zhang	1992	J. Symb. Comput.	10.1016/0747-7171(92)90012-S	decidability;discrete mathematics;string;rewriting;congruence;mathematics;monoid;group theory;algorithm;algebra	Theory	-2.6063956466077496	20.03568889078123	46408
a854bc4ff16b44c2f52a9d6f3b0c5966959af9a7	context-free ambiguity detection using multi-stack pushdown automata		We propose a method for detecting ambiguity in context-free grammars using multi-stack pushdown automata. Since the ambiguity problem is undecidable in general, we use restricted MPDAs that have a limited configuration space. The analysis might thus not be complete, but it is able to detect both ambiguity and unambiguity. Our method is general in the type of automata used. We discuss the suitability of existing MPDAs in our setting and present a new class called bounded-balance MPDAs. These MPDAs allow for infinitely deep nesting/nesting intersection, as long as the nesting depth differences within each scope stay within the balance bound. We compare our contributions to various related MPDAs and ambiguity detection methods.	pushdown automaton;stack (abstract data type)	Hendrikus J. S. Basten	2016		10.1007/978-3-662-53132-7_1	deterministic pushdown automaton;discrete mathematics;deterministic context-free grammar;nested word;theoretical computer science;pushdown automaton;embedded pushdown automaton;algorithm	Vision	-3.8613993389831056	22.04527398069874	46442
dd83491c5a7a0ef4b3a1ce0b15835221b9be7744	programmed mutagenesis is a universal model of computation	universal turing machine;dna computing;model of computation;dna sequence	Programmed mutagenesis is a DNA computing system that uses cycles of DNA annealing, ligation, and polymerization to implement programatic rewriting of DNA sequences. We report that programmed mutagenesis is theoretically universal by showing how Minsky's 4-symbol 7-state Universal Turing Machine [11] can be implemented using a programmed mutagenesis system. Each step of the Universal Turing Machine is implemented by four cycles of programmed mutagenesis, and progress is guaranteed by the use of alternate sense strands for each rewriting cycle. The full version of the proof will appear in the special issue of TOCS.	model of computation;turing completeness	Julia Khodor;David Kenneth Gifford	2001		10.1007/3-540-48017-X_28	bioinformatics;theoretical computer science;mathematics;algorithm	Theory	1.7679118623015067	24.198199403657206	46484
679da1856cf5e881a4b9d819eac7a60d636d4722	perceptual secret sharing scheme based on boolean operations and random grids		In this paper, a new perceptual secret sharing (PSS) scheme is developed based on Boolean operations and random grids. In the developed scheme, the secret image is shared among n shadows using (l, n, n) threshold scheme, while the restored secret image is restored from l out of n shadows. P(l, n, n) threshold is satisfied in this developed scheme, by acquiring this property no information recovery occurs when less than l shares are stacked, imperfect recovery occurs when more than l but less than n shares are presented and perfect recovery occurs when n shares are collected.	boolean algebra;secret sharing	Xuehu Yan;Yuliang Lu;Lintao Liu;Song Wan;Wanmeng Ding;Hanlin Liu	2016		10.1007/978-3-319-72998-5_9	computer science;distributed computing;secret sharing;boolean operations in computer-aided design	Crypto	4.544975245680799	29.044595281112557	46515
57208604290b73486b556028331b60bdb1f7541e	exact algorithms for minimum routing cost trees	camino mas corto;shortest path;appel procedure;network design;alignement sequence;heuristic method;exact solution;plus court chemin;metodo heuristico;valeur consigne;solucion exacta;alineacion secuencia;calcul biologique;multigraph;branch and bound method;llamada procedimiento;metodo branch and bound;multigrafo;exact algorithm;valor consigna;set point;encaminamiento;sequence alignment;methode heuristique;methode separation et evaluation;forwarding;multigraphe;solution exacte;biological computation;computational biology;procedure call;acheminement;branch and price	Given a set of points and distances between them, a basic problem in network design calls for selecting a graph connecting them at a minimum total routing cost, that is, the sum over all pairs of points of the length of their shortest path in the graph. In this paper, we describe some branch-and-bound algorithms for the exact solution of a relevant special case arising when the graph has to be a tree. One of the enhancements to our algorithms is the use of “LP shortcutting,” which we introduce as a general-purpose technique for speeding up the search. Besides network design, we show how trees of small routing cost find useful application in computational biology, where they can be used to determine good alignments of genomic sequences. This leads to a novel alignment heuristic that we analyze in our computational section. © 2002 Wiley Periodicals, Inc.	algorithm;branch and bound;computational biology;general-purpose markup language;heuristic;john d. wiley;network planning and design;routing;shortest path problem	Matteo Fischetti;Giuseppe Lancia;Paolo Serafini	2002	Networks	10.1002/net.10022	mathematical optimization;network planning and design;combinatorics;biological computation;computer science;branch and price;multigraph;sequence alignment;mathematics;shortest path problem;algorithm	Theory	21.45586796593234	12.296581442253016	46521
eaf11eef41a9dc3c281748fa097b3283498cf192	an analytical comparison of the lp relaxations of integer models for the k-club problem	integer programming;formulations;k clubs;clique relaxations;combinatorial optimization	Given an undirected graph G=(V,E), a k-club is a subset of nodes that induces a subgraph with diameter at most k. The k-club problem is to find a maximum cardinality k-club. In this study, we use a linear programming relaxation standpoint to compare integer formulations for the k-club problem. The comparisons involve formulations known from the literature and new formulations, built in different variable spaces. For the case k=3, we propose two enhanced compact formulations. From the LP relaxation standpoint these formulations dominate all other compact formulations in the literature and are equivalent to a formulation with a non-polynomial number of constraints. Also for k=3, we compare the relative strength of LP relaxations for all formulations examined in the study (new and known from the literature). Based on insights obtained from the comparative study, we devise a strengthened version of a recursive compact formulation in the literature for the k-club problem (ku003e1) and show how to modify one of the new formulations for the case k=3 in order to accommodate additional constraints recently proposed in the literature.		Maria Teresa Almeida;Filipa Duarte de Carvalho	2014	European Journal of Operational Research	10.1016/j.ejor.2013.08.004	mathematical optimization;combinatorics;integer programming;combinatorial optimization;formulation;mathematics;algorithm	Logic	23.65321805273447	16.348337025711487	46535
0cbe5416fdd230be7aba342a239824a9b17e7223	genetic search with dynamic operating disciplines	juste a temps;produccion;machine unique;performance;date echeance;algoritmo genetico;genetics;discipline dynamique;single machine;scheduling;robustesse;due date;algorithme genetique;production;fecha vencimiento;genetic algorithm;robustness;penalite;ordonamiento;just in time;justo en tiempo;rendimiento;ordonnancement;robustez	This study extends the idea of genetic search to include the selection of specific operating procedures and disciplines during the course of evolution. Operating disciplines are allowed to change and evolve to better suit the search effort. The two major benefits anticipated are performance and robustness. Performance is measured by the goodness of the solution and by the computational effort required to obtain the solution. Robustness is related to the performance of the methodology for a wide range of optimization problems. A robust methodology is one which is not adversely affected by a prespecified operating discipline parameter. In this perspective, robustness is related to the generality of the methodology: its ability to perform well even when the search effort starts in a state not suitable for the specific conditions of the problem at hand. The methodology is demonstrated and evaluated by implementing a known-to-be-difficult class of scheduling problems, the single-machine deterministic scheduling problems in which the objective is to minimize both the earliness and the tardiness.	computation;computer performance;genetic algorithm;mathematical optimization;operating system;optimization problem;robustness (computer science);scheduling (computing)	Sencer Yeralan;C.-S. Lin	1994	Computers & OR	10.1016/0305-0548(94)90022-1	simulation;genetic algorithm;performance;computer science;operations research;scheduling;robustness	AI	19.861320339427287	6.130408668953123	46553
b41ca71fc1f899ac6255f05cf370194bcbef07dc	nonterminal complexity of tree controlled grammars	tree controlled grammars;formal languages;descriptional complexity;controlled language;formal language;regulated rewriting	This paper studies the nonterminal complexity of tree controlled grammars. It is proved that the number of nonterminals in tree controlled grammars without erasing rules leads to an infinite hierarchy of families of tree controlled languages, while every recursively enumerable language can be generated by a tree controlled grammar with erasing rules and at most nine nonterminals. © 2011 Elsevier B.V. All rights reserved.	controlled grammar;recursion;recursively enumerable language;terminal and nonterminal symbols	Sherzod Turaev;Jürgen Dassow;Mohd Hasan Selamat	2011	Theor. Comput. Sci.	10.1016/j.tcs.2011.06.033	natural language processing;context-sensitive grammar;tree-adjoining grammar;indexed grammar;formal language;discrete mathematics;l-attributed grammar;terminal and nonterminal symbols;phrase structure grammar;computer science;regular tree grammar;mathematics;context-free grammar;algorithm	Logic	-1.9627290042555567	19.275472449835227	46571
d4a0228dbd09674002e7f3fb35d0ca318b5e7fa3	developments and applications of multi-rate simulation	power supplies;analytical models;control systems;virtual test bed;underwater unmanned vehicle multi rate simulation techniques computer simulation large scale dynamic systems numerical integration method esl simulation language virtual test bed;converters;underwater vehicles;application software;vtb;underwater vehicles digital simulation integration large scale systems remotely operated vehicles;real time;dynamic system;remotely operated vehicles;integration;underwater unmanned vehicle;unmanned vehicles;simulation experiment;computational modeling computer simulation vehicle dynamics application software partitioning algorithms underwater vehicles batteries switches sampling methods power supplies;large scale;computational modeling;simulation technique;numerical integration method;numerical integration;batteries;multi rate simulation techniques;vtb multi rate real time esl;mathematical model;real time implementation;sampling methods;multi rate;esl;switches;esl simulation language;real time application;computer simulation;large scale dynamic systems;vehicle dynamics;non real time;digital simulation;large scale systems;partitioning algorithms;real time systems	Multi-rate simulation techniques offer advantages to the computer simulation of large scale dynamic systems. Each part of the system is solved using the most appropriate time step and numerical integration method. The approach can be particularly advantageous in real-time applications, where it is essential to complete each set of calculations in the allotted real-time interval. The ESL Simulation language has parallel segment features which makes it particularly suited to the realization of multi-rate simulations. Experiences of using ESL and the Virtual Test Bed (VTB) to realize a multi-rate simulation of an underwater unmanned vehicle (UUV) are described. A non-real-time version of the simulation with 5 different frame rates has achieved speed increases of the order of 500 times with no significant loss of accuracy, making a real-time implementation feasible.This research has included analysis of the stability of multi-rate methods and these are summarized in the paper.	computer simulation;dynamical system;numerical analysis;numerical integration;real-time clock;simulation language;uncrewed vehicle	J. G. Pearce;Roy E. Crosbie;John J. Zenor;Richard Bednar;Dale Word;Narain G. Hingorani	2009	2009 11th International Conference on Computer Modelling and Simulation	10.1109/UKSIM.2009.23	control engineering;embedded system;simulation;engineering	Robotics	0.8230534344538066	28.04028538201157	46600
aa08cf069794da905164632b079d438ffacc2f9d	network design via core detouring for problems without a core	virtual private network;optimal solution;network design;approximate algorithm;approximation algorithms;rent or buy;random sampling;complex network;buy at bulk;computer sciences;core detouring;virtual private;steiner tree;network;facility location	Some of the currently best-known approximation algorithms for network design are based on random sampling. One of the key steps of such algorithms is connecting a set of source nodes to a random subset of them. In a recent work [Eisenbrand,Grandoni,Rothvoß,Schäfer-SODA’08], a new technique, core-detouring, is described to bound the mentioned connection cost. This is achieved by defining a sub-optimal connection scheme, where paths are detoured through a proper connected subgraph (core). The cost of the detoured paths is bounded against the cost of the core and of the distances from the sources to the core. The analysis then boils down to proving the existence of a convenient core. For some problems, such as connected facility location and single-sink rent-or-buy, the choice of the core is obvious (i.e., the Steiner tree in the optimum solution). Other, more complex network design problems do not exhibit any such core. In this paper we show that core-detouring can be nonetheless successfully applied. The basic idea is constructing a convenient core by manipulating the optimal solution in a proper (not necessarily trivial) way. We illustrate that by presenting improved approximation algorithms for two well-studied problems: virtual private network design and single-sink buy-at-bulk.	approximation algorithm;complex network;monte carlo method;network planning and design;sampling (signal processing);steiner tree problem;virtual private network	Fabrizio Grandoni;Thomas Rothvoß	2010		10.1007/978-3-642-14165-2_42	sampling;mathematical optimization;network planning and design;combinatorics;steiner tree problem;computer science;facility location problem;mathematics;distributed computing;approximation algorithm;complex network	Theory	22.684104307778764	18.441577523094946	46632
79ffb5fc2ef821971cedd9a69ecd29e0a8c4553c	transient and stationary waiting times in (max, +)-linear systems with poisson input	power series;file attente;tiempo espera;poisson process;queueing network;serie taylor;red petri;proceso llegada;series expansion;stochastic petri net;ecuacion vectorial;queueing networks;queue;equation recurrence;analyticity;poisson input;red cola espera;linear system;arrival process;temps attente;processus arrivee;algorithme;waiting times;algorithm;discrete event system;desarrollo serie;evolution equation;stochastic petri nets;reseau file attente;waiting time;recurrence equation;taylor series expansion;proceso poisson;vectorial recurrence equation;equation vectorielle;vector equation;petri net;fila espera;reseau petri;developpement serie;processus poisson;ecuacion recurrencia;algoritmo;taylor series	We consider a certain class of vectorial evolution equations, which are linear in the (max,+) semi-eld. They can be used to model several types of discrete event systems, in particular stochastic service systems where we assume that the arrival process of customers (tokens, jobs, etc.) is Poisson. Under natural Cramer type conditions on certain variables, we show that the expected waiting time which the n-th customer has to spend in a given subarea of such a system can be expanded analytically in an innnite power series with respect to the arrival intensity. Furthermore, we state an algorithm for computing all coeecients of this series expansion and derive an explicit nite representation formula for the remainder term. We also give an explicit nite expansion for expected stationary waiting times in (max,+)-linear systems with deterministic service. Temps d'attente transitoires et stationnaires des systtmes (max; +)-linnaires avec des entrres formant un processus de Poisson RRsumm : Nous considdrons une classe d''quations d''volution vectorielles qui sont linnaires dans le semi-anneau (max; +), avec des entrres formant un processus ponctuel de Poisson. Cette classe contient plusieurs exemples de systtmes vnements discrets dont la classe des graphes d''vnements stochastiques. Sous des hypothhses de type Cramer sur les variables allatoires ddcrivant les temporisations in-ternes, nous montrons que le vecteur des temps d'attente dans un tel systtme admet un ddveloppement analytique en l'intensitt du processus de Poisson. Nous donnons aussi un algorithme pour le calcul des coeecients de ce ddveloppement, et une reprrsentation explicite de l'erreur commise en remplaaant la ssrie par une somme nie. titre d'illustration, nous donnons une reprrsentation explicite du temps d'attente moyen dans le cas particulier oo les temporisations internes sont ddterministes.	algorithm;linear algebra;reactions to the november 2015 paris attacks;semiconductor industry;series expansion;stationary process;triple des	François Baccelli;Sven Hasenfuss;Volker Schmidt	1997	Queueing Syst.	10.1023/A:1019141510202	combinatorics;discrete mathematics;stochastic petri net;taylor series;calculus;mathematics	Theory	9.27121151422766	12.672455164887767	46701
4788588d7e40ef6a148d7b1f4aaf3a96e36418c1	comparing hierarchical data in external memory	sequence comparison;labeled tree;hierarchical data;external memory;external memory algorithms;shortest path problem	We present an external-memory algorithm for computing a minimum-cost edit script between two rooted, ordered, labeled trees. The I/O, RAM, and CPU costs of our algorithm are, respectively, 4mn+7m+5n, 6S, andO(MN+(M+N )S1:5), where M and N are the input tree sizes, S is the block size, m = M=S, and n = N=S. This algorithm can make effective use of surplus RAM capacity to quadratically reduce I/O cost. We extend to trees the commonly used mapping from sequence comparison problems to shortest-path problems in edit graphs.	autoregressive integrated moving average;auxiliary memory;block size (cryptography);central processing unit;computer data storage;data mining;graph reduction;hierarchical database model;input/output;out-of-core algorithm;pattern matching;random-access memory;shortest path problem	Sudarshan S. Chawathe	1999			computer science;theoretical computer science;database;shortest path problem;algorithm;hierarchical database model	DB	13.968631651584433	28.52448895537163	46721
4353dacdb44195fd4a97ad847c04937f2b0f58a3	vehicle routing, scheduling and dispatching system based on hims model	hierarchical multiplex structure;fuzzy set;probleme livraison;vehiculo caminero;vehicule routier;routing;routage;vehicle routing;conjunto difuso;ensemble flou;complex method;constraint satisfaction;optimisation combinatoire;satisfaction contrainte;metodo complex;scheduling;methode complex;dispatching problem;ordonamiento;satisfaccion restriccion;combinatorial optimization;road vehicle;ordonnancement;problema reparto;optimizacion combinatoria;enrutamiento	A concept of the VRSDP/SD problem and its formularization are proposed in order to bridge the gap between conventional methods and complex situations in the real world. A HIMS model is also proposed for the VRSDP/SD problem. Experiments with two cases (full or partial working), are performed. The experimental results and the evaluations by experts from practice show that the HIMS model provides a feasible, fast, and efficient tool for the real world problem.	vehicle routing problem	Kaoru Hirota;Fangyan Dong;Kewei Chen;Yasufumi Takama	2002		10.1007/3-540-45631-7_11	mathematical optimization;routing;simulation;constraint satisfaction;combinatorial optimization;computer science;artificial intelligence;fuzzy set;scheduling	EDA	19.39277453817464	6.381622398139033	46748
4d6798b3918d6aac78c80e6231256ce0bd2b53ea	implementing heapsort with (n logn - 0.9n) and quicksort with (n logn + 0.2n) comparisons	performance;scheduling;algorithms;online algorithms;experimentation	With refinements to the <i>WEAK-HEAPSORT</i> algorithm we establish the general and practical relevant sequential sorting algorithm <i>INDEX-WEAK-HEAPSORT</i> with exactly <i>n</i>⌈log <i>n</i>⌉ - 2<sup>⌈log <i>n</i>⌉</sup> + 1 ≤ <i>n</i> log <i>n</i>-0.9<i>n</i> comparisons and at most <i>n</i> log <i>n</i> + 0.1<i>n</i> transpositions on any given input. It comprises an integer array of size <i>n</i> and is best used to generate an index for the data set. With <i>RELAXED-WEAK-HEAPSORT</i> and <i>GREEDY-WEAK-HEAPSORT</i> we discuss modifications for a smaller set of pending element transpositions.If extra space to create an index is not available, with <i>QUICK-WEAK-HEAPSORT</i> we propose an efficient <i>QUICKSORT</i> variant with <i>n</i> log <i>n</i> + 0.2<i>n</i> + <i>o(n)</i> comparisons on the average. Furthermore, we present data showing that <i>WEAK-HEAPSORT, INDEX-WEAK-HEAPSORT</i> and <i>QUICK-WEAK-HEAPSORT</i> compete with other performant <i>QUICKSORT</i> and <i>HEAPSORT</i> variants.	heapsort;quicksort;sorting algorithm	Stefan Edelkamp;Patrick Stiegeler	2002	ACM Journal of Experimental Algorithmics	10.1145/944618.944623	online algorithm;mathematical optimization;combinatorics;performance;computer science;theoretical computer science;scheduling;algorithm	Theory	13.636331237757155	24.899623999487265	46774
003ecf8da50abd24513feef9d792c515fb986388	social choice under metric preferences: scoring rules and stv		We consider voting under metric preferences: both voters and candidates are associated with points in a metric space, and each voter prefers candidates that are closer to her to ones that are further away. In this setting, it is often desirable to select a candidate that minimizes the sum of distances to the voters. However, common voting rules operate on voters’ preference rankings and therefore may be unable to identify the best candidate. A relevant measure of the quality of a voting rule is then its distortion, defined as the worst-case ratio between the performance of a candidate selected by the rule and that of an optimal candidate. Anshelevich, Bhardwaj and Postl (2015) show that some popular rules such as Borda and Plurality do badly in this regard: their distortion scales linearly with the number of candidates. On the positive side, Anshelevich et al. identify a few voting rules whose distortion is bounded by a constant; however, these rules are rarely used in practice. In this paper, we analyze the distortion of two widely used (classes of) voting rules, namely, scoring rules and Single Transferable Vote (STV). We show that all scoring rules have super-constant distortion, answering a question that was left open by Anshelevich et al.; however, we identify a scoring rule whose distortion is asymptotically better than that of Plurality and Borda. For STV, we obtain an upper bound of O(lnm), where m is the number of candidates, as well as a super-constant lower bound; thus, STV is a reasonable, though not a perfect rule from this perspective.	best practice;best, worst and average case;distortion;list of sega arcade system boards	Piotr Skowron;Edith Elkind	2017			artificial intelligence;machine learning;computer science;social choice theory	AI	17.506853115936522	17.082728143808197	46790
4c7758781feaad94e203305ddef7226b605f6481	periodic network optimization with different arc frequencies	periodic scheduling;networks;fixed time;hermite normal form;waiting time;mathematical model;network optimization;rail;branch and bound;programming	For a fixed time interal served railway system we consider the problem to find a timetable such that for a selected class of change possibilities the arising waiting time is minimal. As a mathematical model to deal with such problems, we introduce “periodic networks”. The general discussion of this concept allows to give formulas for network caused waiting times at all junctions. Based on this results we formulate the optimization task to find timetables which minimize a global objective depending on all local waiting times, In general, these “periodic programs” are NP-hard. We present a branch and bound approach. As shown by computational results for the case of a linear objective, the use of the Hermite normal form considerably improves the performance of the algorithm. For unconstrained problems WC give a polynomially working method to find the lexicographic best solution.	algorithm;branch and bound;computation;lexicography;mathematical model;mathematical optimization;np-hardness;schedule;writing commons	Karl Nachtigall	1996	Discrete Applied Mathematics	10.1016/0166-218X(95)00073-Z	programming;mathematical optimization;combinatorics;mathematical model;mathematics;branch and bound;algorithm;algebra;hermite normal form	Theory	15.634852299942809	9.241151821143436	46879
a79627760e1f93f58a50fb197016c1dde7d30dd2	a simple greedy algorithm for finding functional relations: efficient implementation and average case analysis	base relacional dato;fonction booleenne;functional dependencies;approximate algorithm;algorithme glouton;approximation algorithm;exact solution;boolean function;average case analysis;relational database;functional dependency;efficient implementation;computer experiment;dependance fonctionnelle;funcion booliana;informatique theorique;decouverte connaissance;algoritmo aproximacion;recouvrement ensemble;base donnee relationnelle;greedy algorithm;algoritmo gloton;descubrimiento conocimiento;dependencia funcional;set covering;cubierta conjunto;algorithme approximation;set cover;scientific knowledge;analyse en moyenne;functional dependence;computer theory;knowledge discovery;informatica teorica	Inferring functional relations from relational databases is important for the discovery of scientific knowledge because many experimental data are represented in the form of tables and many rules are represented in the form of functions. A simple greedy algorithm has been known as an approximation algorithm for this problem. This paper presents an efficient implementation of the algorithm. This paper also shows that the algorithm can identify an exact solution for simple functions if input data for each function are generated uniformly at random and the size of the domain is bounded by a constant. Results of computational experiments using artificially generated data are presented to verify the approach.	best, worst and average case;greedy algorithm;set cover problem	Tatsuya Akutsu;Satoru Miyano;Satoru Kuhara	2003	Theor. Comput. Sci.	10.1016/S0304-3975(02)00183-4	combinatorics;greedy algorithm;ramer–douglas–peucker algorithm;computer science;mathematics;fsa-red algorithm;functional dependency;approximation algorithm;algorithm	Theory	15.837603254081177	24.82507783670011	46890
c7a6c87cd87653d92ce4cf00f1fb2ad25cda1c59	a sharp threshold for the renameable-horn and the q-horn properties	assignment;probleme satisfiabilite;sharp satisfiability threshold q horn;asignacion;random formula;probability;formule aleatoire;seuil;sharp satisfiability threshold;assignation;threshold;satisfiability;q horn;sat;development tool;renameable horn;propriete horn;informatique theorique;horn property;problema satisfactibilidad;probabilidad;probabilite;umbral;satisfiability problem;computer theory;informatica teorica	The sharp Satisfiability threshold is well known for random k-SAT formulas and is due to certain minimality and monotonic properties mentioned in this manuscript and reported in Chandru and Hooker [J. Assoc. Comput. Mach. 38 (1991) 205-221]. Whereas the Satisfiability threshold is on the probability that a satisfying assignment exists, we find that sharp thresholds also may be determined for certain formula structures, for example, the probability that a particular kind of cycle exists in a random formula. Such structures often have a direct relationship on the hardness of a formula because it is often the case that the presence of such a structure disallows a formula from a known, easily solved class of Satisfiability problems. We develop tools that should assist in determining threshold sharpness for a variety of applications. We use the tools to show a sharp threshold for the q-Horn and renameable-Horn properties.		Nadia Creignou;Hervé Daudé;John V. Franco	2005	Discrete Applied Mathematics	10.1016/j.dam.2005.05.005	combinatorics;computer science;calculus;probability;assignment;mathematics;boolean satisfiability problem;programming language;algorithm	Crypto	5.453769678308593	22.084515221997567	46927
a359d506d288a4837a5e41069d63ca11a1c23ef6	a topological treatment of early-deciding set-agreement	pire cas;distributed system;topology;protocols;consensus;systeme reparti;nombre entier;time complexity;optimistic algorithm;topologie;distributed computing;synchronous;protocolo;local decision;calculo automatico;synchrone;68wxx;computing;topologia;algorithme;calcul automatique;algorithm;integer;complexite temps;sistema repartido;sincronico;protocole;consenso;informatique theorique;early decision;envoi message;entero;k set agreement;borne inferieure;message passing;decision;calculo repartido;coordinacion;agreement problem;complejidad tiempo;communication;comunicacion;68q85;calcul reparti;lower bound;68m14;coordination;cota inferior;computer theory;algoritmo;consensus problem;informatica teorica	The k-set-agreement problem consists for a set of n processes to agree on less than k among n possibly different Values, each initially known to only one process. The problem is at the heart of distributed computing and generalizes the celebrated consensus problem.		Rachid Guerraoui;Maurice Herlihy;Bastian Pochon	2009	Theor. Comput. Sci.	10.1016/j.tcs.2008.10.002	consensus;computer science;artificial intelligence;mathematics;algorithm	ECom	4.761756598406058	25.748831008691052	46997
77a27c7e9d4b1961414b6a907be0b5190e5a069d	a kleene theorem for splitable signals	transition state;theorie automate;procesamiento informacion;sistema temporizado;timed system;formal languages;regular language;satisfiability;lenguaje racional;expression reguliere signal;informatique theorique;estado transitorio;signal constant par morceau;information processing;piecewise constant signal;langage rationnel;systeme temporise;automata theory;teoria automata;timed automata;traitement information;lenguaje formal;regular expression;etat transition;formal language;signal regular expression;computer theory;informatica teorica;langage formel	In this paper, we consider timed automata for piecewise constant signals and prove that they recognize exactly the denoted by signal regular expressions with intersection and renaming. The main differences from the usual timed are: time elapses on transitions (passing through a state is instantaneous), signals may be split on a run on an auto constraints on transitions correspond to unions of open intervals but should be satisfied on closed intervals. This ma rendez-vous impossible. The paper stresses on the similarities and differences from the usual model.  2003 Elsevier B.V. All rights reserved.	automata theory;kleene star;regular expression;timed automaton	Jérôme Olivier Durand-Lose	2004	Inf. Process. Lett.	10.1016/j.ipl.2003.11.010	formal language;discrete mathematics;information processing;computer science;mathematics;timed automaton;algorithm	Logic	-2.2489513264597036	20.631144416134294	47044
6ff92aacafa3a1b28a9615e8673921c8951a9695	optimal intervention for incentivizing the adoption of commercial electric vehicles	incentive schemes electric vehicles environmental economics;commercial electric vehicles greenhouse gas emission reduction public charging stations mathematical model investment commercial ev purchase social planner carbon tax optimal budget balanced intervention policy;charging stations;electric vehicles;mathematical model;charging stations carbon tax electric vehicles buildings mathematical model;carbon tax;buildings	While electric vehicles (EVs) have great potential in reducing greenhouse gas emissions, successful EV adoption depends largely on the availability of public charging stations. The lack of charging stations poses an even more serious problem for the adoption of commercial EVs (e.g., trucks used for freight transportation), because the (commercial EV) fleet planner needs to build their own specialized charging stations, requiring additional investment in commercial EV purchase. This paper presents a first mathematical model and rigorous analysis for incentivizing the adoption of commercial EVs. We propose an intervention policy for the social planner (e.g., the government) to promote commercial EV adoption. The intervention policy includes a subsidy for EV purchase (i.e., expenditure) and a carbon tax for gas emissions (i.e., income). We propose provably fast algorithms for the social planner to find the optimal budget-balanced intervention policy. We analyze in detail the effect of the intervention policy on commercial EV adoption, and prove that the proposed intervention policy achieves higher commercial EV adoption rates.	algorithm;electric sheep;extended validation certificate;mathematical model;time complexity;usb	Yuanzhang Xiao;Mihaela van der Schaar	2015	2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP)	10.1109/GlobalSIP.2015.7418247	marketing;operations management;business;commerce	Visualization	4.73473125370872	8.331534374789857	47081
9fb600b699fd83edecee65aba40db5e7923acae1	a single tape deterministic turing machine of adaptive deterministic routing algorithm designed for torus network	turing machine	An image processing apparatus reads and processes images on the documents successively presented to an original image reading section by means of an ADF. The operation of the image processing apparatus is controlled by a control section provided therein. The control section creates a management table for each document for storing processing information related to a document reading action, and manages the documents based on the content of the management tables. Consequently, the image processing apparatus can readily and precisely carry out the recovery when the documents or sheets are jammed.	algorithm;deterministic routing;turing machine	Nitin;Gitanjali Chauhan;Vivek Kumar Sehgal;Rohit Sharma;Abhishek Gupta;Aditya Patel;Amanpreet Singh Arora;Aprajita Gupta;Utkarsh Shrivastava;Rajan Vaish	2009			image processing;probabilistic turing machine;dtime;universal turing machine;deterministic routing;deterministic algorithm;dspace;turing machine;algorithm;computer science	Theory	9.767762823150148	28.293972664260117	47099
52d8050962dde1b14de8ac1765e946035a9b6b60	instruction sequence expressions for the secure hash algorithm sha-256	universiteitsbibliotheek	The secure hash function SHA-256 is a function on bit strings. This means that its restriction to the bit strings of any given length can be computed by a finite instruction sequence that contains only instructions to set and get the content of Boolean registers, forward jump instructions, and a termination instruction. We describe such instruction sequences for the restrictions to bit strings of the different possible lengths by means of uniform terms from an algebraic theory.	algorithm;cryptographic hash function;sha-2	Jan A. Bergstra;Kees Middelburg	2013	CoRR		hash function;cityhash;computer science;theoretical computer science;algorithm	Theory	-2.2203344592415832	24.53528460427792	47140
550da657fdc54f1c524557faecee56a223a3152e	interactive proofs and approximation: reduction from two provers in one round	optimisation;longest path;polynomials approximation algorithms error probability intelligent networks optimization methods high performance computing;theorem proving;function approximation;computational complexity;interactive proofs;polynomial time;network flow;one round proof systems hard to approximate problems systems of representatives network flow longest paths polynomial time approximation np;hardness of approximation;theorem proving computational complexity function approximation optimisation	We present hard to approximate problems in the following areas: systems of representatives, network ow, and longest paths in graphs. In each case we show that there exists some > 0 such that polynomial time approximation to within a factor of 2 n of the optimal implies that NP has quasi polynomial time deterministic simulations. The results are derived by reduction from two prover, one round proof systems, and exemplify the ability of such reductions to yield hardness of approximations results for many di erent kinds of problems. Department of Computer Science & Engineering, Mail Code 0114, University of California at San Diego, 9500 Gilman Drive, La Jolla, CA 92093. E-mail: mihir@cs.ucsd.edu	approximation algorithm;computer science;exemplification;geforce 9 series;interactive proof system;jolla;longest path problem;polynomial;quasi-polynomial;simulation;time complexity	Mihir Bellare	1993		10.1109/ISTCS.1993.253462	time complexity;mathematical optimization;combinatorics;discrete mathematics;flow network;np;longest path problem;function approximation;computer science;mathematics;automated theorem proving;hardness of approximation;computational complexity theory;l-reduction;approximation algorithm;algorithm	Theory	12.876910853916232	21.711686070379898	47150
2fabe52a58d5f4407142f78b794b5f717e03eba3	short proofs of the pigeonhole formulas based on the connection method	proof complexity;automated theorem proving;lower bound	Quadratic proofs of pigeonhole formulas are presented using connection method proof techniques. The interest of this result derives from the fact that for this class of formulas exponential lower bounds are known for the length of resolution refutations.	pigeonhole sort;time complexity	Wolfgang Bibel	1990	Journal of Automated Reasoning	10.1007/BF00244489	discrete mathematics;computer science;artificial intelligence;mathematics;automated theorem proving;upper and lower bounds;programming language;proof complexity;algorithm	Theory	7.578182858544328	21.420523535124826	47166
c6e56ade4d196d7a39093f378f300cc5505ff66e	c-planarity of extrovert clustered graphs	graph theory;analyse amas;cluster graph;teoria grafo;temps polynomial;graph drawing;time complexity;probleme np complet;structure arborescente;metodo arborescente;p 180 cluster;grafo monton;classification;theorie graphe;isomorphism;graphe amas;isomorfismo;graph isomorphism;representacion de grafos;complexite temps;cluster analysis;estructura arborescente;graphe planaire;g 770 planarity testing;tree structure;polynomial time;tree structured method;analisis cluster;problema np completo;methode arborescente;isomorphisme;grafo planario;complejidad tiempo;clasificacion;planar graph;np complete problem;trace de graphes;tiempo polinomial	A clustered graph has its vertices grouped into clusters in a hierarchical way via subset inclusion, thereby imposing a tree structure on the clustering relationship. The c-planarity problem is to determine if such a graph can be drawn in a planar way, with clusters drawn as nested regions and with each edge (drawn as a curve between vertex points) crossing the boundary of each region at most once. Unfortunately, as with the graph isomorphism problem, it is open as to whether the cplanarity problem is NP-complete or in P. In this paper, we show how to solve the c-planarity problem in polynomial time for a new class of clustered graphs, which we call extrovert clustered graphs. This class is quite natural (we argue that it captures many clustering relationships that are likely to arise in practice) and includes the clustered graphs tested in previous work by Dahlhaus, as well as Feng, Eades, and Cohen. Interestingly, this class of graphs does not include, nor is it included by, a class studied recently by Gutwenger et al.; therefore, this paper offers an alternative advancement in our understanding of the efficient drawability of clustered graphs in a planar way. Our testing algorithm runs in O(n) time and implies an embedding algorithm with the same time complexity.	algorithm;cluster analysis;graph isomorphism problem;karp's 21 np-complete problems;planarity;time complexity;tree structure	Michael T. Goodrich;George S. Lueker;Jonathan Z. Sun	2005		10.1007/11618058_20	1-planar graph;time complexity;pathwidth;combinatorics;discrete mathematics;independent set;topology;graph product;longest path problem;graph theory;hopcroft–karp algorithm;forbidden graph characterization;metric dimension;graph coloring;mathematics;maximal independent set;graph isomorphism;modular decomposition;chordal graph;indifference graph;book embedding;algorithm;planar graph	Theory	23.0937527082155	28.189317107270494	47233
1608c2d41e8c77b39b45e33411563d1eb1ec5f48	indexing text using the ziv-lempel trie	succinct data structures;succinct data structure;index compression;compressed pattern matching;text compression;compressed text;pattern matching;indexation;self indexing;data structure	Let a text of u characters over an alphabet of size be compressible to n symbols by the LZ78 or LZW algorithm. We show that it is possible to build a data structure based on the Ziv-Lempel trie that takes 4n log 2 n(1 + o(1)) bits of space and reports the R occurrences of a pattern of length m in worst case time O(m 2 log(mm) + (m + R) log n).	algorithm;best, worst and average case;data structure;lz77 and lz78;lempel–ziv–welch;trie	Gonzalo Navarro	2004	J. Discrete Algorithms	10.1016/S1570-8667(03)00066-2	succinct data structure;data structure;computer science;y-fast trie;theoretical computer science;pattern recognition;data mining;programming language	Theory	12.506734995015155	27.33676081782649	47250
7314175e13d6146d8aa3c33dc6005b3aa3becdad	the alternating stock size problem and the gasoline puzzle	004;approximation algorithms stock size problem scheduling with non renewable resources	Given a set S of integers whose sum is zero, consider the problem of finding a permutation of these integers such that: (i) all prefixes of the ordering are non-negative, and (ii) the maximum value of a prefix sum is minimized. Kellerer et al. referred to this problem as the stock size problem and showed that it can be approximated to within 3/2. They also showed that an approximation ratio of 2 can be achieved via several simple algorithms.#R##N##R##N#We consider a related problem, which we call the alternating stock size problem, where the number of positive and negative integers in the input set S are equal. The problem is the same as above, but we are additionally required to alternate the positive and negative numbers in the output ordering. This problem also has several simple 2-approximations.  We show that it can be approximated to within 1.79.#R##N##R##N#Then we show that this problem is closely related to an optimization version of the gasoline puzzle due to Lovasz, in which we want to minimize the size of the gas tank necessary to go around the track. We present a 2-approximation for this problem, using a natural linear programming relaxation whose feasible solutions are doubly stochastic matrices. Our novel rounding algorithm is based on a transformation that yields another doubly stochastic matrix with special properties, from which we can extract a suitable permutation.		Alantha Newman;Heiko Röglin;Johanna Seif	2016		10.4230/LIPIcs.ESA.2016.71	optimization problem;mathematical optimization;partition problem;combinatorics;computer science;cutting stock problem;mathematics;subset sum problem;algorithm	Crypto	18.708838063773534	13.648459832088804	47333
75a77e94f84ed0ccd59642d32d49c7a62fc3d048	edge-disjoint spanners in tori	distance function;subgrafo;dimension;reseau;three dimensional;red;connected graph;multi dimensional;toro;sous graphe;torus;tore;ensemble contour;68r10;retard;three dimensional calculations;edge graph;edge set;distancia;arete graphe;subgraph;retraso;graph spanner;calcul 3 dimensions;graphe connexe;calcul 2 dimensions;distance;arista grafico;torus network;network;grafo conexo;two dimensional calculations	A spanning subgraph S = (V , E ) of a connected graph G = (V , E) is an (x + c)-spanner if for any pair of vertices u and v, dS(u, v) ≤ dG(u, v) + c where dG and dS are the usual distance functions in G and S, respectively. The parameter c is called the delay of the spanner. We study edge-disjoint spanners in graphs in multi-dimensional tori. We show that each two-dimensional torus has a set of two edge-disjoint spanners of delay approximately the size of the smaller dimension. Moreover, we show that this delay is close to the best possible. In three-dimensional tori, we find a set of three edge-disjoint spanners with delay approximately the sum of the sizes of the two smaller dimensions when all dimensions are of even size. Surprisingly, we also find a set of two edge-disjoint spanners in three-dimensional tori of constant delay. In d-dimensional tori, we show that for any k ≤ d/5, there is a set of k edge-disjoint spanners with delay depending only on k and the size of the smaller k dimensions. Crown Copyright© 2008 Published by Elsevier B.V. All rights reserved.	connectivity (graph theory);crown group;edge dominating set;emoticon;file spanning	Arthur L. Liestman;Thomas C. Shermer;Ladislav Stacho	2009	Discrete Mathematics	10.1016/j.disc.2008.04.063	three-dimensional space;combinatorics;grid network;topology;metric;connectivity;torus;mathematics;geometry;dimension;distance	Theory	23.706423941086165	30.521524798516634	47414
b5b6d01beef5fa4058b6a565b26173298f2f413f	decision algorithms for fibonacci-automatic words, ii: related sequences and avoidability	automatic sequence;decision procedure;finite automata;fibonacci representation;palindrome;avoidability in words	We use a decision procedure for the “Fibonacci-automatic” words to solve problems about a number of different sequences. In particular, we prove that there exists an aperiodic infinite binary word avoiding the pattern xxxR. This is the first avoidability result concerning a nonuniform morphism proven purely mechanically.	algorithm;decision problem	Chen Fei Du;Hamoon Mousavi;Eric Rowland;Luke Schaeffer;Jeffrey Shallit	2017	Theor. Comput. Sci.	10.1016/j.tcs.2016.10.005	arithmetic;combinatorics;discrete mathematics;palindrome;computer science;mathematics;finite-state machine;algorithm;algebra	Theory	-0.5359815590439573	20.455527447469784	47416
825f4c5825a87df0a66d0640fa29308553270689	a greedy algorithm estimating the height of random trees	arbre graphe;selfsimilarity;graph theory;random graph;unicidad solucion;limit distribution;tree graph;algorithme glouton;05c05;loi limite;solution uniqueness;integral equations;random tree;grafo aleatorio;greedy algorithms;graphe aleatoire;theorie graphe;unicite solution;autosimilitud;05c80;equation integrale;greedy algorithm;algoritmo gloton;autosimilitude;68q25;arbol grafo;ley limite;random trees	The behaviour of a greedy algorithm which estimates the height of a random labelled rooted tree is studied. A self-similarity argument is used to characterize the limit distribution of the length H of the path found by such an algorithm in a random rooted tree as the unique solution of an integral equation. Furthermore, it is shown that lim n!1 E H p n = p 2 2 p 2 ln(3 + 2 p 2) = 2 : 353139::: ; i.e. the expected length of the path constructed by the algorithm is roughly 93% of the expected height of a random rooted tree.	expanded memory;greedy algorithm;self-similarity	Tomasz Luczak	1998	SIAM J. Discrete Math.	10.1137/S0895480193258960	mathematical optimization;combinatorics;greedy algorithm;discrete mathematics;graph theory;mathematics	Theory	23.307024817562237	31.42368764767341	47461
26cc79ca8facef2ceb5d65ed3e0fda14dea9cdd4	efficient solutions to hard computational problems by p systems with symport/antiport rules and membrane division	subset sum problem;cell like p system;membrane division;qsat problem;symport antiport rule	P systems are computing models inspired by some basic features of biological membranes. In this work, membrane division, which provides a way to obtain an exponential workspace in linear time, is introduced into (cell-like) P systems with communication (symport/antiport) rules, where objects are never modified but they just change their places. The computational efficiency of this kind of P systems is studied. Specifically, we present a (uniform) linear time solution to the NP-complete problem, Subset Sum by using division rules for elementary membranes and communication rules of length at most 3. We further prove that such P system allowing division rules for non-elementary membranes can efficiently solve the PSPACE-complete problem, QSAT in a uniform way.	computation (action);computational problem;inspiration function;np-completeness;p system;pspace-complete;physical object;rule (guideline);solutions;tissue membrane;true quantified boolean formula;workspace;antiporter activity;exponential;symporter activity	Bosheng Song;Mario J. Pérez-Jiménez;Linqiang Pan	2015	Bio Systems	10.1016/j.biosystems.2015.03.002	combinatorics;discrete mathematics;computer science;mathematics;subset sum problem;algorithm	Theory	1.69495945775124	24.557446918284487	47591
43f1dfd61f966a0c7831065c6ddb491c060194b4	modeling and simulation of a microgrid as a stochastic hybrid system	distributed power generation;probability;wind turbines stochastic processes probabilistic logic microgrids mathematical model generators;stochastic processes distributed power generation energy management systems power generation dispatch power generation scheduling power grids probability;energy management systems;stochastic processes;simulation microgrids stochastic hybrid systems modeling;power generation scheduling;power grids;power generation dispatch;discrete dynamics microgrid simulation stochastic hybrid system small scale local energy grids distribution grid mg energy management system multiple generation dispatching mg scheduling probabilistic elements shs models continuous dynamics	Microgrids (MGs) are small-scale local energy grids. While dedicated to cover local power needs, their structure and operation is usually quite complex. Complexity arises due to a number of factors: in the first instance, a variety of operational modes - among them, MGs can be considered to be operated autonomously whenever the main distribution grid is not available; furthermore, the heterogeneity of energy types in a MG - not exclusively electrical energy, but also thermal for instance; also, the different functions that a MG energy management system has to fulfill - like coordination and dispatching of multiple generation, transfer, transformation and storage devices; finally, the external and internal random factors that affect operations. All these aspects make control and scheduling of a MG quite a challenging task. On the other hand, this widespread complexity leaves much room for improvement on the current state of the art. An advancement on the state of the art requires the development of a realistic model of the system at hand. This work puts forward a model of a MG that is based on the framework of Stochastic Hybrid Systems (SHS). SHS models can capture the interaction between probabilistic elements and discrete and continuous dynamics, and thus promise to be able to tame the complexity of the systems discussed above. This work displays the outcomes of model simulations and discusses potential development of general analysis and synthesis approaches over SHS models (e.g., based on model checking and on approximate dynamic programming) for typical challenges in MGs.	approximation algorithm;complexity;dynamic programming;hybrid system;mathematical optimization;mg (editor);microgrid;model checking;scheduling (computing);secure hash standard;simulation;tame	Martin Strelec;Karel Macek;Alessandro Abate	2012	2012 3rd IEEE PES Innovative Smart Grid Technologies Europe (ISGT Europe)	10.1109/ISGTEurope.2012.6465655	control engineering;simulation;engineering;operations management	AI	6.389091607892177	4.261118134230627	47631
ab967f7aae1f3af28fe68f3133e0f2059013882a	the bottom-up position tree automaton, the father automaton and their compact versions		The conversion of a given regular tree expression into a tree automaton has been widely studied. However, classical interpretations are based upon a Top-Down interpretation of tree automata. In this paper, we propose new constructions based on the Gluskov’s one and on the one of Ilie and Yu one using a Bottom-Up interpretation. One of the main goals of this technique is to consider as a next step the links with deterministic recognizers, consideration that cannot be performed with classical Top-Down approaches. Furthermore, we exhibit a method to factorize transitions of tree automata and show that this technique is particularly interesting for these constructions, by considering natural factorizations due to the structure of regular expression.	aggregate data;finite-state machine;heuristic;microsoft word for mac;morphic (software);rsa problem;regular expression;regular tree grammar;top-down and bottom-up design;tree automaton	Samira Attou;Ludovic Mignot;Djelloul Ziadi	2018	CoRR		discrete mathematics;combinatorics;automaton;regular expression;mathematics;top-down and bottom-up design;factorization;tree automaton	Logic	-1.3415278817187366	19.14388895758718	47732
9d77bf8150558f2a007e980f3ab4611b81a3fcf7	new collapse consequences of np having small circuits	language class;polynomial size circuits;algorithm complexity;temps polynomial;complexite calcul;complejidad algoritmo;language theory;clase complejidad;randomised algorithms;np complete problems;algorithme randomise;teoria lenguaje;randomized computation;lowness;03d10;complejidad computacion;theory of computing;classe complexite;complexite algorithme;complexity class;computational complexity;classe langage;03d15;polynomial time;68q15;68q10;advice classes;theorie langage;clase lenguaje;tiempo polinomial	We show that if a self-reducible set has polynomial-size circuits, then it is low for the probabilistic class ZPP (NP). As a consequence we get a deeper collapse of the polynomial-time hierarchy PH to ZPP(NP) under the assumption that NP has polynomial-size circuits. This improves on the well-known result in Karp and Lipton [ Proceedings of the 12th ACM Symposium on Theory of Computing, ACM Press, New York, 1980, pp. 302--309] stating a collapse of PH to its second level $\Sigmap_2$ under the same assumption. Furthermore, we derive new collapse consequences under the assumption that complexity classes like UP, FewP, and C=P have polynomial-size circuits. Finally, we investigate the circuit-size complexity of several language classes. In particular, we show that for every fixed polynomial s, there is a set in ZPP(NP) which does not have O(s(n))-size circuits.		Johannes Köbler;Osamu Watanabe	1998	SIAM J. Comput.	10.1137/S0097539795296206	time complexity;complexity class;np-complete;computer science;philosophy of language;calculus;mathematics;computational complexity theory;algorithm	Theory	7.803713498846213	20.91125531338803	47736
5a82126437c4231d7848ab10414d9fc45f0d5aa2	maximum minimal vertex cover parameterized by vertex cover		The parameterized complexity of problems is often studied with respect to the size of their optimal solutions. However, for a maximization problem, the size of the optimal solution can be very large, rendering algorithms parameterized by it inefficient. Therefore, we suggest studying the parameterized complexity of maximization problems with respect to the size of the optimal solutions to their minimization versions. We examine this suggestion by considering the Maximum Minimal Vertex Cover (MMVC) problem, which has applications to wireless ad hoc networks and whose minimization version, Vertex Cover, is one of the most studied problems in the field of parameterized complexity. We first present tight conditional lower bounds for the running time of any algorithm for MMVC or its weighted variant. Next, we develop a parameterized approximation algorithm for MMVC and its weighted variant. The approximation ratio of this algorithm cannot be achieved by polynomial-time algorithms unless P = NP, and its running...	vertex cover	Meirav Zehavi	2017	SIAM J. Discrete Math.	10.1137/16M109017X	edge cover;vertex;neighbourhood	Theory	21.289492770120443	19.0990779266939	47750
5ce2dc2cb9d34b008b4f0b35e66359eeae8045bf	cycle detection, order finding and discrete log with jumps		Let S be a finite set. Given a function f : S → S and an element a ∈ S, define f(a) = a and f (a) = f(f i−1(a)) for all i ≥ 1. Let s ≥ 0 and r > 0 be the smallest integers such that f(a) = f(a). Determining s and r, given a ∈ S and a black-box oracle to f , is the cycle-detection problem. When f is bijective (i.e., f is a permutation of S), the order-finding problem is to find the smallest r > 0 such that f(a) = a, and the discrete-log problem is, given an additional element b ∈ S, to find the smallest k ≥ 0 such that f(a) = b. We study the query complexity of these problems with oracles that allow “jumps” to distant positions in the sequence ā , f(a)f(a)f(a) · · · ∈ S∗ at unit cost. Specifically, for every m ∈ N the oracle O f is defined, which for every a ∈ S allows to look ahead at any position i < m in the sequence ā; that is, O f (a, i) = f (a) for every (a, i) ∈ S × [m]. We show that with an unrestricted oracle O∞ f , the cycle-detection and order-finding problems can be solved using O(log s+log r/ log log log r) and O(log r/ log log log r) queries, respectively, regardless of |S|. This is nearly optimal, as we also prove lower bounds of Ω(log s + log r/ log log r) and Ω(log r/ log log r) queries. Interestingly, for the discrete-log problem, our results combined with the algorithm of Sutherland [8] imply a lower bound of Ω( √ r/ log r) queries (where r is the size of the cycle to which both a and b belong), which is tight up to the log r factor. This contrasts with the fact that, with generic group-operation oracles, the problems of order finding and discrete log are known to have polynomially related query complexities. We also provide algorithms and lower bounds for general oracles O f , m ∈ N, improving results from earlier work. In particular, with m = poly(r), our lower bound for order-finding improves the previous bound of Ω̃(r) queries, proved by Cleve [2], to Ω̃(r), which is nearly optimal.	algorithm;black box;cycle detection;decision tree model;discrete logarithm;oracle machine	Sourav Chakraborty;David García-Soriano;Arie Matsliah	2011			combinatorics;discrete mathematics;calculus;mathematics	Theory	12.973772177428128	25.620507740048403	47766
391327e462cf8041df5f2e8b9f1c024ff30de971	w-hardness under linear fpt-reductions: structural properties and further applications	clase complejidad;problema np duro;combinatorial problem;np hard problem;probleme combinatoire;problema combinatorio;classe complexite;complexity class;probleme np difficile;borne inferieure;lower bound;structural properties;cota inferior	The notion of linear fpt-reductions has been recently used to derive strong computational lower bounds for well-known NP-hard problems. In this paper, we formally investigate the notions of W [t]-hardness and W [t]-completeness under the linear fpt-reduction, and study structural properties of the corresponding complexity classes. Additional complexity lower bounds on important computational problems are also es-	complexity class;computational problem;linear logic;np-hardness;parameterized complexity	Jianer Chen;Xiuzhen Huang;Iyad A. Kanj;Ge Xia	2005		10.1007/11533719_98	complexity class;computer science;calculus;np-hard;mathematics;upper and lower bounds;algorithm	Theory	15.680725580813112	19.700199292943356	47778
fa84ed1d1a9756b9ffb12dbeea91c97bcbb3babd	consistent rounding of edge weights in graphs		Often, the edge weights of graphs are given in implicitly infinite or overly high precision (think of Euclidean lengths) which leads to both theoretical as well as practical challenges. In this paper we investigate how to round edge weights of a given graph G(V,E,w) such that the rounded weights of paths satisfy certain consistency criteria. Natural consistency criteria are, for example, preserving optimality of paths, and bounding relative change in weight after the rounding procedure. Low precision edge weights allow for more space efficient implementations, faster arithmetic operations, and in general more stable and efficient algorithms. We present an ILP based rounding approach as well as a greedy rounding heuristic. We show experimentally for large road networks and grid graphs that our new rounding approaches are significantly better than common deterministic or randomized rounding schemes.	approximation error;breadth-first search;chroma subsampling;data structure;experiment;greedy algorithm;heuristic (computer science);radix sort;randomized rounding;relative change and difference;round-off error;shortest path problem;sorting;time complexity	Stefan Funke;Sabine Storandt	2016			grid;discrete mathematics;round-off error;heuristic;mathematical optimization;greedy algorithm;randomized rounding;euclidean geometry;rounding;graph;mathematics	ML	21.33827032535351	21.500918463358865	47819
7f33b694df05c3573d40fa328f2fb3991ef5ebda	on the algorithmic complexity of k-tuple total domination	k;block graph;total domination;algorithm;cactus;np complete;undirected path graph	For a fixed positive integer k, a k-tuple total dominating set of a graph G is a subset D ⊆ V (G) such that every vertex of G is adjacent to at least k vertices in D. The k-tuple total domination problem is to determine a minimum k-tuple total dominating set of G. This paper studies k-tuple total domination from an algorithmic point of view. In particular, we present a linear-time algorithm for the k-tuple total domination problem for graphs in which each block is a clique, a cycle or a complete bipartite graph, which include trees, block graphs, cacti and block-cactus graphs. We also establish NP-completeness of the k-tuple total domination problem in undirected path graphs.	algorithm;analysis of algorithms;computational complexity theory;dominating set;graph (discrete mathematics);np-completeness;path (graph theory);time complexity	James K. Lan;Gerard J. Chang	2014	Discrete Applied Mathematics	10.1016/j.dam.2014.04.007	block graph;combinatorics;discrete mathematics;np-complete;topology;mathematics;algorithm	Theory	24.186210607636333	26.57913755622117	47877
8711e77ffe0d527ab649e98bfed14613e82f0031	a top-down error-correcting parser for a context-sensitive language	top down;error correction	Abstract#R##N##R##N#A context-free grammar, a stochastic grammar, and a context-free tree grammar have been used in the past in the syntactic approach to pattern recognition. However, since a pattern is primarily context-dependent, some top-down and bottom-up parsers have been proposed for context-sensitive language (CSL). Although the bottom-up version of the error-correcting parser for CSL has been known, it has a disadvantage in that it converts an input string of length n into a string of length (n + 1) k + n (k is the maximum number of consecutive deletions of terminal symbols). As a result, this paper proposes a top-down ECP (error-correcting parser) for a context-sensitive language.	context-sensitive language;error detection and correction;top-down and bottom-up design	Hironari Kobayashi;Mitsuru Ikeda;Eiichi Tanaka	1986	Systems and Computers in Japan	10.1002/scj.4690170510	natural language processing;parser combinator;error detection and correction;speech recognition;lalr parser;canonical lr parser;ll grammar;parsing expression grammar;operator-precedence grammar;computer science;parsing;glr parser;top-down and bottom-up design;programming language;attribute grammar;recursive descent parser;top-down parsing;statistics;lr parser;simple lr parser	NLP	-0.41870162766422825	18.50460141563557	47892
bab1e30313aa50ad174b89a8ad747caab2757158	a multicast problem with shared risk cost		In this paper, we study a minimum cost multicast problem on a network with shared risk link groups (SRLGs). Each SRLG contains a set of arcs with a common risk, and there is a cost associated with it. The objective of the problem is to find a multicast tree from the source to a set of destinations with minimum transmission cost and risk cost. We present a basic model for the multicast problem with shared risk cost (MCSR) based on the well-known multicommodity flow formulation for the Steiner tree problem (Goemans and Myung in Networks 1:19–28, 1993; Polzin and Daneshmand in Discrete Applied Mathematics 112(1–3): 241–261, 2001). We propose a set of strong valid inequalities to tighten the linear relaxation of the basic model. We also present a mathematical model for undirected MCSR. The computational results of real life test instances demonstrate that the new valid inequalities significantly improve the linear relaxation bounds of the basic model, and reduce the total computation time by half in average.	computation;graph (discrete mathematics);internet backbone;lagrangian relaxation;linear programming relaxation;mathematical model;multicast;real life;routing;shared risk resource group;steiner tree problem;test case;time complexity;whole earth 'lectronic link	Zhe Liang;W. Art Chaovalitwongse	2012	Optimization Letters	10.1007/s11590-011-0283-5	mathematical optimization;combinatorics;mathematics;distributed computing	Theory	23.20106029887699	17.288724586363344	47916
c216593460643ddc88c3479e67757848a2f44ab4	algorithms to compute the lyndon array		In the Lyndon array λ = λx[1..n] of a string x = x[1..n], λ[i] is the length of the longest Lyndon word starting at position i of x. The computation of λ has recently become of great interest, since it was shown (Bannai et al., The “Runs” Theorem) that the runs in x are computable in linear time from λx. Here we describe two algorithms for computing λx based on previous results known in different context, but for which no explicit exposition in this context had been given. These two algorithms execute in O(n) time in the worst case. The third algorithm presented that executes in Θ(n) time had been suggested and discussed previously, and we provide a more substantial discussion and prove of correctness for one of its steps. This algorithm achieves its linearity at the expense of prior computation of both the suffix array and the inverse suffix array of x. We then go on to sketch a new algorithm and its two variants that avoids prior computation of global data structures and indicate that in worst-case these algorithms perform in O(n log n) time.	algorithm;best, worst and average case;computable function;computation;data structure;run time (program lifecycle phase);suffix array;time complexity	Frantisek Franek;A. S. M. Shohidull Islam;Mohammad Sohel Rahman;William F. Smyth	2016			mathematical optimization;combinatorics;computer science;theoretical computer science;mathematics;compressed suffix array;algorithm;statistics;sparse array	Theory	12.601394605073507	23.772410652925423	47943
af15925281f9842419121799772f1adfc3653e35	heuristics for the maximization of operating rooms utilization using simulation	workload;operating room;no determinismo;tiempo iniciacion;tiempo total acabamiento;statistical simulation;healthcare;bloc operatoire;temps polynomial;execution time;gestion labor;resource allocation;heuristic method;simulation;machine parallele;temps total achevement;problema np duro;metodo heuristico;temps mise en route;probabilistic approach;processing time;np hard problem;setup time;simulacion estadistica;non determinism;gestion tâche;makespan;non determinisme;probleme np difficile;simulation statistique;scheduling;enfoque probabilista;approche probabiliste;polynomial time;stochastic times;charge travail;quirofano;temps traitement;temps execution;parallel machines;optimization;heuristics;asignacion recurso;methode heuristique;task scheduling;allocation ressource;tiempo ejecucion;carga trabajo;tiempo proceso;ordonnancement;reglamento;tiempo polinomial	This paper addresses the problem of maximizing the utilization of operating rooms, which is translated to jobs scheduling in an identical parallel machine environment with sequence-dependent setup times and an objective of minimizing the makespan. The jobsâ processing times and setup times are stochastic for better depiction of the real world. This is a non-deterministic polynomial time (NP)-hard problem, and in this paper a new heuristic is developed and compared to existing ones using simulation and optimization. The results and analysis obtained from the computational experiments proved the superiority of the proposed algorithm Longest Expected Processing with Setup Time (LEPST) over the other algorithms presented.	expectation–maximization algorithm;heuristic (computer science);simulation	Jean-Paul M. Arnaout	2010	Simulation	10.1177/0037549709352497	time complexity;job shop scheduling;simulation;resource allocation;computer science;heuristics;np-hard;scheduling;algorithm	Arch	17.294626902750164	9.840870344881733	47950
a28df75f614790b16859d3c0cc8225cc920798b4	average case polyhedral complexity of the maximum stable set problem	004;polyhedral approximation extended formulation stable sets	We study the minimum number of constraints needed to formulate random instances of the maximum stable set problem via LPs (more precisely, linear extended formulations), in two distinct models. In the uniform model, the constraints of the LP are not allowed to depend on the input graph, which should be encoded solely in the objective function. There we prove a super-polynomial lower bound with overwhelming probability for every LP that is exact for a randomly selected set of instances with a natural distribution. In the non-uniform model, the constraints of the LP may depend on the input graph, but we allow weights on the vertices. The input graph is sampled according to the Erdos-Renyi model. There we obtain upper and lower bounds holding with high probability for various ranges of p. We obtain a super-polynomial lower bound all the way from essentially p = polylog(n) / n to p = 1 / log n. Our upper bound is close as there is only an essentially quadratic gap in the exponent, which also exists in the worst case model. Finally, we state a conjecture to close the gap both in the average-case and worst-case models.	polyhedral	Gábor Braun;Samuel Fiorini;Sebastian Pokutta	2014		10.4230/LIPIcs.APPROX-RANDOM.2014.515	mathematical optimization;combinatorics;discrete mathematics;mathematics	ECom	19.632507191666818	18.56493713437502	48014
922c6a0961af9279d2c59c024b84aedd6fe0cdd4	on the complexity of scheduling unit-time jobs with or-precedence constraints	workload;tiempo total acabamiento;completion time;gestion labor;time complexity;machine unique;complexite calcul;machine parallele;temps total achevement;temps achevement;problema np duro;constrenimiento precedencia;polynomial time algorithm;np hard problem;o r;complejidad computacion;complexite temps;single machine;maquina unica;gestion tâche;makespan;precedence constraints;or networks;probleme np difficile;computational complexity;scheduling;charge travail;precedence constraint;contrainte precedence;parallel machines;task scheduling;complejidad tiempo;carga trabajo;tiempo acabado;ordonnancement;network computing;reglamento	We present various complexity results for scheduling unit-time jobs subject to O R-precedence constraints. We prove that minimizing the total weighted completion time is strongly NP-hard, even on a single machine. In contrast, we give a polynomial-time algorithm for minimizing the makespan and the total completion time on identical parallel machines. © 2004 Elsevier B.V. All rights reserved.	algorithm;job stream;makespan;np-hardness;polynomial;scheduling (computing);strong np-completeness;time complexity	Berit Johannes	2005	Oper. Res. Lett.	10.1016/j.orl.2004.11.009	time complexity;job shop scheduling;real-time computing;computer science;np-hard;computational complexity theory;scheduling;algorithm	AI	16.867994928159227	10.586896889678403	48018
87c9e2c65c928208b0aad8109b216711510f1686	parallel recognition algorithms for chordal_planar graphs and planar k-trees	algoritmo paralelo;grafo aciclico;hamiltonian cycle;grafo triangular;parallel algorithm;cycle hamiltonien;machine parallele;distributed computing;graphe acyclique;k trees;parallel random access machine;acyclic graph;algorithme parallele;ciclo hamiltoniano;acceso aleatorio;graphe planaire;directed graph;graphe oriente;edge graph;time use;graphe triangule;calculo repartido;arete graphe;parallel machines;grafo orientado;grafo planario;random access;calcul reparti;planar graph;arista grafico;chordal graph;acces aleatoire	This paper presents parallel algorithms for recognizing chordal_planar graphs and planar k-trees. Both the algorithms run in O(log^2n) time using O(n+m) processors on a concurrent-read and concurrent-write (CRCW), parallel random access machine (PRAM) model, where n and m are, respectively, the number of nodes and edges in the graph.The novelty of our chordal_planar graph recognition algorithm lies in that it is based on an elegant structural characterization of chordal_planar graphs proposed in this paper. Moreover, it is simpler than separately testing chordality and planarity. Our planar k-trees recognition algorithm is based on a new characterization of k-trees presented in this paper.	algorithm	Bhawani Sankar Panda;Sajal K. Das	2005	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2005.04.002	hamiltonian path;outerplanar graph;apollonian network;combinatorics;discrete mathematics;directed graph;computer science;theoretical computer science;planar straight-line graph;mathematics;parallel algorithm;parallel random-access machine;chordal graph;directed acyclic graph;random access;planar graph	HPC	18.855582157891106	28.823653238238318	48025
2c1eefbe6d436148d44bfb8d9a7f726ae81cd403	computing cycle covers without short cycles	recouvrement graphe;cubierta grafo;approximate algorithm;subgrafo;travelling salesman problem;arbre maximal;problema viajante comercio;decision problem;graph covering;arbol maximo;probleme commis voyageur;sous graphe;cycle graphe;polynomial time;cycle graph;spanning tree;subgraph;lower bound;ciclo diagrama	A cycle cover of a graph is a spanning subgraph where each node is part of exactly one simple cycle. Ak-cycle cover is a cycle cover where each cycle has length at least k. We call the decision problems whether a directed or undirected graph has a k-cycle coverk-DCC andk-UCC. Given a graph with edge weights one and two, Mink-DCC and Min-k-UCC are the minimization problems of finding ak-cycle cover with minimum weight. We present factor 4/3 approximation algorithms for Mink-DCC with running timeO(n) (independent of k). Specifically, we obtain a factor 4/3 approximation algorithm for the asymmetric travelling salesperson p roblem with distances one and two and a factor 2/3 approximation algorithm for the directed path packing problem with the same running time. On the other hand, we s how thatk-DCC is NP-complete fork ≥ 3 and that Mink-DCC has no PTAS for k ≥ 4, unless P = NP . Furthermore, we design a polynomial time factor 7/6 approximation algorithm for Min-k-UCC. As a lower bound, we prove that Mink-UCC has no PTAS for k ≥ 12, unlessP = NP.	approximation algorithm;cycle (graph theory);decision problem;edge cycle cover;file spanning;graph (discrete mathematics);max–min inequality;minimum weight;np-completeness;np-hardness;p versus np problem;ptas reduction;path (graph theory);polynomial;set packing;time complexity;unified code count (ucc);vertex cycle cover	Markus Bläser;Bodo Manthey	2001		10.1007/3-540-44676-1_31	time complexity;mathematical optimization;combinatorics;discrete mathematics;feedback arc set;vertex cover;spanning tree;edge cover;decision problem;cycle graph;mathematics;upper and lower bounds;travelling salesman problem;approximation algorithm;algorithm	Theory	23.878616135684478	21.027679626887064	48063
9675d09e0af07aa58ce5a313e59df126195de745	output string languages of compositions of deterministic macro tree transducers	formal language hierarchies;macro tree transducers;formal language	The composition of total deterministic macro tree transducers gives rise to a proper hierarchy with respect to their output string languages (these are the languages obtained by taking the yields of the output trees). There is a language not in this hierarchy which can be generated by a (quite restricted) nondeterministic string transducer, namely, a two-way generalized sequential machine. Similar results hold for attributed tree transducers, for controlled EDT0L systems, and for YIELD mappings (which proves properness of the IO-hierarchy). Witnesses for the properness of the macro tree transducer hierarchy can already be found in the latter three hierarchies. © 2002	arithmetical hierarchy;attribute grammar;chomsky hierarchy;context-free language;emoticon;flight dynamics (fixed-wing aircraft);formal language;gio;graph coloring;hasse diagram;light-emitting electrochemical cell;mathematical induction;meaning–text theory;regular language;surround sound;top-down and bottom-up design;transducer;usb hub;xfig	Joost Engelfriet;Sebastian Maneth	2002	J. Comput. Syst. Sci.	10.1006/jcss.2001.1816	formal language;discrete mathematics;computer science;mathematics;programming language;algorithm	Theory	-2.7281443736841138	20.46259026820974	48089
704be0c391d41504185ac3c0a58859b08f1d0fb7	efficient subgraph matching using topological node feature constraints	graph matching;topological node features;subgraph isomorphism	This paper presents techniques designed to minimise the number of states which are explored during subgraph isomorphism detection. A set of advanced topological node features, calculated from nneighbourhood graphs, is presented and shown to outperform existing features. Further, the pruning effectiveness of both the new and existing topological node features is significantly improved through the introduction of strengthening techniques. In addition to topological node features, these strengthening techniques can also be used to enhance application-specific node labels using a proposed novel extension to existing pruning algorithms. Through the combination of these techniques, the number of explored search states can be reduced to near-optimal levels. & 2014 Elsevier Ltd. All rights reserved.	algorithm;pruning (morphology);subgraph isomorphism problem	Nicholas Dahm;Horst Bunke;Terry Caelli;Yongsheng Gao	2015	Pattern Recognition	10.1016/j.patcog.2014.05.018	combinatorics;discrete mathematics;computer science;machine learning;subgraph isomorphism problem;mathematics;induced subgraph isomorphism problem;matching	AI	19.069105915897758	20.711501285207525	48110
fcc27ddab422dca156fd0071577e8027b0058e86	optimality conditions in preference-based spanning tree problems	arbre graphe;criterio optimalidad;modelizacion;multiple criteria analysis;multicriteria analysis;multiobjective programming;programmation multiobjectif;tree graph;minimum weight spanning tree;arbre maximal;multiple criteria analysis preference modelling multiobjective spanning tree problems;preference modelling;modelisation;condicion optimalidad;condition optimalite;arbol maximo;preferencia;preference;optimality criterion;analisis multicriterio;spanning tree;analyse multicritere;multiobjective spanning tree problems;critere optimalite;arbol grafo;modeling;optimality condition;programacion multiobjetivo	Spanning tree problems defined in a preference-based environment are addressed. In this approach, optimality conditions for the minimum-weight spanning tree problem (MST) are generalized for use with other, more general preference orders. The main goal of this paper is to determine which properties of the preference relations are sufficient to assure that the set of 'most-preferred' trees is the set of spanning trees verifying the optimality conditions. Finally, algorithms for the construction of the set of spanning trees fulfilling the optimality conditions are designed, improving the methods in previous papers.	spanning tree	Sergio Alonso-Rodríguez;Miguel Ángel Domínguez-Ríos;Marcos Colebrook;Antonio Sedeño-Noda	2009	European Journal of Operational Research	10.1016/j.ejor.2008.07.042	mathematical optimization;combinatorics;discrete mathematics;systems modeling;spanning tree;minimum spanning tree;mathematics;distributed minimum spanning tree;tree	Theory	22.687873824752625	11.400297957621538	48115
960da4c5086051ca34870202a64be841f4c64591	stochastic machine minimization with constant service times	minimisation;politica optima;minimization;ley uniforme;exponential distribution;ley exponencial;random timer;loi exponentielle;nonpreemptive scheduling;constant job times;minimizacion;optimal policy;scheduling;parallel machines;ordonamiento;systeme parallele;parallel system;stochastic model;politique optimale;loi uniforme;modelo estocastico;modele stochastique;ordonnancement;sistema paralelo;uniform distribution	We consider the nonpreemptive scheduling of n â¥ 1 jobs on identical, parallel machines. With job running times all given by some constant, the objective is to minimize the expected number of machines needed throughout a schedule subject to the following waiting-time constraints. At time 0, a timer with random initial value W is started; after time W all jobs must either be finished or running on a machine. The value of W is not known in advance, but its distribution is made available to the scheduler.#R##N##R##N#In general, if job running times are random, there might be situations in which, after running jobs on a given number of machines, it would be desirable to activate new machines, because the remaining times of unfinished jobs are stochastically too large compared to the time remaining on the timer. A principal result of this paper is that randomness of job running times is essential to such situations; if running times are deterministic, then irrespective of the distribution of W, an optimal policy initially assigns jobs to some number of machines kn which depends on the distribution of W, and maintains that number while there are jobs available, until the timer has expired, at which point any remaining, as yet unscheduled jobs are assigned to new, unused machines.#R##N##R##N#This paper also analyzes the dependence of kn and the minimal expected cost on the parameters of the timer distribution when W is either exponentially distributed or uniformly distributed on a finite interval. The determination of kn turns out to have an intriguing number-theoretic flavor.		Edward G. Coffman;Leopold Flatto;Paul E. Wright	1993	Math. Oper. Res.	10.1287/moor.18.2.300	exponential distribution;minimisation;mathematical optimization;real-time computing;stochastic modelling;mathematics;distributed computing;uniform distribution;scheduling;statistics	Theory	10.626643835582836	10.698581592055566	48167
60bffa38ad0af807ecbba2df3311bd82d3d4105e	which is the fairest (rent division) of them all? [extended abstract]		What is a fair way to assign rooms to several housemates, and divide the rent between them? This is not just a theoretical question: many people have used the Spliddit website to obtain envy-free solutions to rent division instances. But envy freeness, in and of itself, is insufficient to guarantee outcomes that people view as intuitive and acceptable. We therefore focus on solutions that optimize a criterion of social justice, subject to the envy freeness constraint, in order to pinpoint the “fairest” solutions. We develop a general algorithmic framework that enables the computation of such solutions in polynomial time. We then study the relations between natural optimization objectives, and identify the maximin solution, which maximizes the minimum utility subject to envy freeness, as the most attractive. We demonstrate, in theory and using experiments on real data from Spliddit, that the maximin solution gives rise to significant gains in terms of our optimization objectives. Finally, a user study with Spliddit users as subjects demonstrates that people find the maximin solution to be significantly fairer than arbitrary envy-free solutions; this user study is unprecedented in that it asks people about their real-world rent division instances. Based on these results, the maximin solution has been deployed on Spliddit since April 2015.	computation;experiment;mathematical optimization;minimax;time complexity;usability testing	Ya'akov Gal;Moshe Mash;Ariel D. Procaccia;Yair Zick	2017		10.24963/ijcai.2017/678	artificial intelligence;applied mathematics;machine learning;computer science	ECom	14.315848043455459	13.384279839854239	48195
81874f4dad5c7fb278f857584bf7ee142e3c9758	an o(n^lg k . 2^n/2) time and o(k . 2^n/k) space algorithm for certain np-complete problems			algorithm;karp's 21 np-complete problems	Jozef Vyskoc	1987	Theor. Comput. Sci.			Theory	17.310438907617577	20.357244719122615	48252
d4d25952c74dcb2a9cf07dd6367828045aa1cd75	distributed multifrontal factorization using clique trees	clique trees;multifrontal factorization		tree decomposition	Alex Pothen;Chunguang Sun	1991			mathematical optimization;combinatorics;discrete mathematics	NLP	20.008151861219755	30.390956225371518	48278
b58e81b0ca0190c110a8d4d4a41ccbc5435c5851	structural health monitoring in wireless sensor networks by the embedded goertzel algorithm	goertzel algorithm;random access memory;transmissibility functions goertzel algorithm structural health monitoring wireless sensor networks;monitoring wireless sensor networks algorithm design and analysis acceleration accelerometers real time systems random access memory;sink node;truss structure;offline analysis;data locality;real time;data collection;structural damage detection;distributed approach;cyber physical systems;acceleration;damage detection;wireless sensor network;transmissibility functions;wireless sensor networks condition monitoring structural engineering supports;local structure;condition monitoring;monitoring;structural engineering;embedded goertzel algorithm;cyber physical system;sensor nodes;structural health monitoring;supports;distributed approach structural health monitoring wireless sensor networks embedded goertzel algorithm civil infrastructures structural damage detection structural damage localization sensor nodes transmissibility functions sink node offline analysis cyber physical system truss structure;accelerometers;structural damage localization;algorithm design;life span;algorithm design and analysis;wireless sensor networks;civil infrastructures;real time systems	Structural health monitoring aims to provide an accurate diagnosis of the condition of civil infrastructures during their life-span by analyzing data collected by sensors. To this purpose, detection and localization of damages are fundamental tasks. This paper introduces a wireless sensor network for structural damage detection and localization in which the sensor nodes, in order to estimate the energies of specific frequency bands, process the acceleration data locally in real-time using the Goertzel algorithm. The nodes then share their results inside the network and exploit them to compute transmissibility functions, which can be exploited as damage indicators and for correctly localizing damages within the monitored structure. The use of the embedded Goertzel algorithm prevents the nodes from transmitting large volumes of acceleration data to the sink node for off-line analysis, reducing the latency and increasing the life time of the cyber-physical system by 80 % and 52 %, respectively. The tests performed on a truss structure confirm the capability of the distributed approach in correctly detecting and localizing structural damages.	centralized computing;cyber-physical system;domain analysis;embedded system;frequency band;goertzel algorithm;internationalization and localization;kilobyte;online and offline;piezoelectricity;real-time clock;sensor;super high material cd;transmissibility (structural dynamics);transmitter	Maurizio Bocca;Janne Toivola;Lasse Eriksson;Jaakko Hollmén;Heikki N. Koivo	2011	2011 IEEE/ACM Second International Conference on Cyber-Physical Systems	10.1109/ICCPS.2011.19	structural engineering;embedded system;algorithm design;real-time computing;wireless sensor network;computer science;engineering;cyber-physical system;computer security	Embedded	2.358540104852624	31.68122818882656	48300
afae4bc3ce511123e6ae409858d704526f6e930d	efficient lifting of map lp relaxations using k-locality		Inference in large scale graphical models is an important task in many domains, and in particular for probabilistic relational models (e.g,. Markov logic networks). Such models often exhibit considerable symmetry, and it is a challenge to devise algorithms that exploit this symmetry to speed up inference. Here we address this task in the context of the MAP inference problem and its linear programming relaxations. We show that symmetry in these problems can be discovered using an elegant algorithm known as the kdimensional Weisfeiler-Lehman (k-WL) algorithm. We run k-WL on the original graphical model, and not on the far larger graph of the linear program (LP) as proposed in earlier work in the field. Furthermore, the algorithm is polynomial and thus far more practical than other previous approaches which rely on orbit partitions that are GI complete to find. The fact that k-WL can be used in this manner follows from the recently introduced notion of k-local LPs and their relation to Sherali Adams relaxations of graph automorphisms. Finally, for relational models such as Markov logic networks, the benefits of our approach are even more dramatic, as we can discover symmetries in the original domain graph, as opposed to running lifting on the much larger grounded model.	algorithm;graphical model;graphical user interface;lambda lifting;lifting scheme;linear programming;locality of reference;map;markov chain;markov logic network;polynomial	Martin Mladenov;Kristian Kersting;Amir Globerson	2014				ML	13.993875110019728	16.85808640020462	48344
1d8221e49030f3a9c0ed149eb9c55a6bf48a9ec3	minimum description length and compositionality	artificial intelligent;minimum description length	In [12] we have shown that the standard definition of compositionality is formally vacuous; that is, any semantics can be easily encoded as a compositional semantics. We have also shown that when compositional semantics is required to be ”systematic”, it is possible to introduce a non-vacuous concept of compositionality. However, a technical definition of systematicity was not given in that paper; only examples of systematic and non-systematic semantics were presented. As a result, although our paper clarified the concept of compositionality, it did not solve the problem of the systematic assignment of meanings. In other words, we have shown that the concept of compositionality is vacuous, but we have not replaced it with a better definition; a definition that would both be mathematically correct and would satisfy the common intuitions that there are parts of grammars which seem to have compositional semantics, and others, like idioms, that do not. We present such a non-vacuous definition of compositionality in this chapter. Compositionality has been defined as the property that the meaning of a whole is a function of the meaning of its parts (cf. e.g. [6], pp.24-25). A slightly less general definition, e.g. [8], postulates the existence of a homomorphism from syntax to se-	definition;hoc (programming language);maximal set;minimum description length;programming idiom;standard-definition television	Wlodek Zadrozny	2000	CoRR		natural language processing;minimum description length;computer science;artificial intelligence;theoretical computer science;algorithm;principle of compositionality	PL	-3.735031073351805	14.840085920236463	48356
12e709f0f8b9e922e0ca1b01eb13440d98b96242	interactions in transport networks	transportation networks;lagrangian duality;optimisation;routing;interaction;graphical models;interaction pattern;electrical circuit;interactive graphics;flow control	We present a model that captures basic interactions occurring in transport networks, including routing and flow control. Many network processes can be seen as solving an optimisation problem, or seeking a balance between competing interests. The problem structure is illustrated by means of a 'component graph', which dictates the communication and interaction patterns between different parts of the system. We show how the same formalism also captures interactions in electrical circuits.	interaction;transport layer security	Nigel G. Walker;Marc Wennink	2005	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2005.05.018	electrical network;mathematical optimization;routing;interaction;simulation;computer science;theoretical computer science;flow control;graphical model	ECom	7.755021052949865	6.538809161373373	48380
6846c0376f4f8357831f6f1569d753a0268c0d5f	an approximability-related parameter on graphs - properties and applications	computer and information science	We introduce a binary parameter on optimisation problems called separation. The parameter is used to relate the approximation ratios of different optimisation problems; in other words, we can convert approximability (and nonapproximability) result for one problem into (non)-approximability results for other problems. Our main application is the problem (weighted) maximum H-colourable subgraph (MAX H -COL), which is a restriction of the general maximum constraint satisfaction problem (MAX CSP) to a single, binary, and symmetric relation. Using known approximation ratios for MAX k-CUT, we obtain general asymptotic approximability results for MAX H -COL for an arbitrary graph H . For several classes of graphs, we provide near-optimal results under the unique games conjecture. We also investigate separation as a graph parameter. In this vein, we study its properties on circular complete graphs. Furthermore, we establish a close connection to work by Šámal on cubical colourings of graphs. This connection shows that our parameter is closely related to a special type of chromatic number. We believe that this insight may turn out to be crucial for understanding the behaviour of the parameter, and in the longer term, for understanding the approximability of optimisation problems such as MAX H -COL.	approximation algorithm;constraint satisfaction problem;graph coloring;mathematical optimization;max;unique games conjecture	Robert Engström;Tommy Färnqvist;Peter Jonsson;Johan Thapper	2015	Discrete Mathematics & Theoretical Computer Science			Theory	21.695212948711905	23.051613616227055	48381
912e2823762b0eb551336ba26e87e01dcea7cbb7	complexity of quantum uniform and nonuniform automata	modelizacion;lenguaje programacion;fonction booleenne;diagrama binaria decision;diagramme binaire decision;programming language;automata estado finito;language theory;boolean function;metric;funcion n variables;teoria lenguaje;modelisation;quantum computation;n variable function;funcion booliana;finite automata;borne inferieure;langage programmation;fonction n variables;metrico;finite automaton;automate fini;calcul quantique;calculo cuantico;modeling;theorie langage;metrique;lower bound;cota inferior;binary decision diagram	We present two different types of complexity lower bounds for quantum uniform automata (finite automata) and nonuniform automata (OBDDs). We call them “metric” and “entropic” lower bounds in according to proof technique used. We present explicit Boolean functions that show that these lower bounds are tight enough.#R##N##R##N#We show that when considering “almost all Boolean functions” on n variables our entropic lower bounds gives exponential (2c(δ)(n−−logn)) lower bound for the width of quantum OBDDs depending on the error δ allowed.#R##N##R##N#Next we consider “generalized measure-many” quantum automata. It is appeared that for uniform and nonuniform automata (for space restricted models) their measure-once and measure-many models have different computational power.	automaton;quantum	Farid M. Ablayev;Aida Gainutdinova	2005		10.1007/11505877_7	combinatorics;discrete mathematics;systems modeling;metric;quantum finite automata;computer science;philosophy of language;mathematics;finite-state machine;boolean function;upper and lower bounds;quantum computer;binary decision diagram;algorithm	Theory	5.563719625541429	22.551998590250573	48383
5f3907700d1eab315f5b862be21e4d473a9863eb	separating sublinear time computations by approximate diameter	modelizacion;algoritmo aleatorizado;metric space;borne erreur;espace metrique;time complexity;espacio metrico;computer model;clase complejidad;pregunta documental;plan randomise;diametre;algorithme randomise;diameter;optimisation combinatoire;modelisation;sublinear time algorithm;temps calcul;aleatorizacion;plan aleatorizado;classe complexite;complexity class;randomized design;randomized algorithm;query;randomisation;diametro;error bound;tiempo computacion;separation of complexity classes;computation time;randomization;combinatorial optimization;modeling;requete;optimizacion combinatoria;limite error	We study sublinear time complexity and algorithm to approximate the diameter for a sequence  S =  p  1  p  2 ?  p   n  of points in a metric space, in which every pair of two consecutive points  p   i  and  p   i + 1 in the sequence  S has the same distance. The diameter of  S is the largest distance between two points  p   i  and  p   j  in  S . The approximate diameter problem is investigated under deterministic, zero error randomized, and bounded error randomized models. We obtain a class of separations about the sublinear time computations using various versions of the approximate diameter problem based on the restriction about the format of input data.	time complexity	Bin Fu;Zhiyu Zhao	2008		10.1007/978-3-540-85097-7_8	combinatorics;discrete mathematics;combinatorial optimization;diameter;mathematics;algorithm	Theory	17.795201173684845	25.766774328022212	48411
79a891e8e56b1fb40cdfd200f7613c6ac8e76e18	a framework for in-place graph algorithms		Read-only memory (ROM) model is a classical model of computation to study time-space tradeoffs of algorithms. A classical result on the ROM model is that any algorithm to sort n numbers using O(s) words of extra space requires Ω(n2/s) comparisons for lg n ≤ s ≤ n/ lg n2 and the bound has also been recently matched by an algorithm. However, if we relax the model, we do have sorting algorithms (say Heapsort) that can sort using O(n lg n) comparisons using O(lg n) bits of extra space, even keeping a permutation of the given input sequence at anytime during the algorithm. We address similar relaxations for graph algorithms. We show that a simple natural relaxation of ROM model allows us to implement fundamental graph search methods like BFS and DFS more space efficiently than in ROM. By simply allowing elements in the adjacency list of a vertex to be permuted, we show that, on an undirected or directed connected graph G having n vertices and m edges, the vertices of G can be output in a DFS or BFS order using O(lg n) bits of extra space and O(n3 lg n) time. Thus we obtain similar bounds for reachability and shortest path distance (both for undirected and directed graphs). With a little more (but still polynomial) time, we can also output vertices in the lex-DFS order. As reachability in directed graphs (even in DAGs) and shortest path distance (even in undirected graphs) are NL-complete, and lex-DFS is P-complete, our results show that our model is more powerful than ROM if L 6= P. En route, we also introduce and develop algorithms for another relaxation of ROM where the adjacency lists of the vertices are circular lists and we can modify only the heads of the lists. Here we first show a linear time DFS implementation using n + O(lg n) bits of extra space. Improving the extra space exponentially to only O(lg n) bits, we also obtain BFS and DFS albeit with a slightly slower running time. Both the models we propose maintain the graph structure throughout the algorithm, only the order of vertices in the adjacency list changes. In sharp contrast, for BFS and DFS, to the best of our knowledge, there are no algorithms in ROM that use even O(n1− ) bits of extra space; in fact, implementing DFS using cn bits for c < 1 has been mentioned as an open problem. Furthermore, DFS (BFS, respectively) algorithms using n + o(n) (o(n), respectively) bits of extra use Reingold’s [JACM, 2008] or Barnes et al’s reachability algorithm [SICOMP, 1998] and hence have high runtime. Our results can be contrasted with the recent result of Buhrman et al. [STOC, 2014] which gives an algorithm for directed st-reachability on catalytic Turing machines using O(lg n) bits with catalytic space O(n2 lg n) and time O(n9). 1 This work was partially supported by JST CREST Grant Number JPMJCR1402, Japan. 2 We use lg to denote logarithm to the base 2. © Sankardeep Chakraborty, Anish Mukherjee, Venkatesh Raman, and Srinivasa Rao Satti; licensed under Creative Commons License CC-BY 26th Annual European Symposium on Algorithms (ESA 2018). Editors: Yossi Azar, Hannah Bast, and Grzegorz Herman; Article No. 13; pp. 13:1–13:16 Leibniz International Proceedings in Informatics Schloss Dagstuhl – Leibniz-Zentrum für Informatik, Dagstuhl Publishing, Germany 13:2 A Framework for In-place Graph Algorithms 2012 ACM Subject Classification Mathematics of computing → Graph algorithms, Theory of computation → Models of computation	adjacency list;anytime algorithm;be file system;best-first search;binary number;breadth-first search;carrier-to-noise ratio;connectivity (graph theory);depth-first search;directed graph;disc filing system;esa;graph (discrete mathematics);graph theory;graph traversal;hannah dee;heapsort;informatics;journal of the acm;lex (software);linear programming relaxation;model of computation;nl (complexity);nl-complete;p-complete;polynomial;raman scattering;reachability;read-only memory;siam journal on computing;shortest path problem;sorting algorithm;supratik chakraborty;symposium on theory of computing;theory of computation;time complexity;turing machine;yossi matias	Sankardeep Chakraborty;Anish Mukherjee;Venkatesh Raman;S. Srinivasa Rao	2018		10.4230/LIPIcs.ESA.2018.13	combinatorics;discrete mathematics;computer science;graph	Theory	20.457792974538584	22.413586026117134	48454
1b2e7a6e96f3b36fdabdd5411608ca263cbd28f1	on dynamics of automata with a stack	03c;pushdown automaton;periodic configuration;positive expansivity;68q05;dynamical system;03d10;shadowing;68q45;68q10;semi conjugacy	In this paper we introduce a new dynamical system of a pushdown automaton, called automaton with a stack (AS). We prove that every AS has a periodic configuration by construction of it. Next, we define a special case of an AS, called AS with finite memory and we prove that the AS has a finite memory if and only if it is positively expansive. Furthermore, we prove that every AS with finite memory has shadowing property. Having these two properties, we set a finite-to-one map between an AS with finite memory and some vertex subshift, which gives us a semi-conjugacy between these two systems. Additionally, we define an algorithm to decide if a given graph G describes some AS with finite memory and to calculate maximal depth of a stack.	algorithm;dynamical system;maximal set;pushdown automaton;semiconductor industry;stack (abstract data type)	Lukasz Czech	2015	Int. J. Comput. Math.	10.1080/00207160.2014.914508	deterministic pushdown automaton;combinatorics;mathematical analysis;nested stack automaton;discrete mathematics;nondeterministic finite automaton;dynamical system;two-way deterministic finite automaton;deterministic finite automaton;probabilistic automaton;deterministic automaton;mathematics;timed automaton;pushdown automaton;embedded pushdown automaton;algorithm;algebra	Logic	-1.5807810194652276	22.22782849206035	48473
