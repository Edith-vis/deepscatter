id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
c64bf198a5c397db6a923f8da1da5b855274a905	efficient hierarchical method for background subtraction	modelizacion;moving object;contrast histogram;teledetection;metodo adaptativo;background modeling;video surveillance;deteccion blanco;televigilancia;hierarchized structure;technique video;structure hierarchisee;methode adaptative;segmentation;blanco movil;tecnica video;detection cible;modelisation;detection objet;histogram;remote supervision;histogramme;telesurveillance;hierarchical background modeling;remote sensing;non stationary background;adaptive method;background subtraction;teledeteccion;pattern recognition;cible mobile;video technique;histograma;modeling;target detection;estructura jerarquizada;segmentacion;moving target;quantitative evaluation;object detection	Detecting moving objects by using an adaptive background model is a critical component for many vision-based applications. Most background models were maintained in pixel-based forms, while some approaches began to study block-based representations which are more robust to non-stationary backgrounds. In this paper, we propose a method that combines pixel-based and block-based approaches into a single framework. We show that efficient hierarchical backgrounds can be built by considering that these two approaches are complementary to each other. In addition, a novel descriptor is proposed for block-based background modeling in the coarse level of the hierarchy. Quantitative evaluations show that the proposed hierarchical method can provide better results than existing single-level approaches. 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	background subtraction;consistency model;feed forward (control);ip camera;multi-level cell;newton's method;pattern recognition;performance;pixel;scalability;sensor;speedup;stationary process	Yu-Ting Chen;Chu-Song Chen;Chun-Rong Huang;Yi-Ping Hung	2007	Pattern Recognition	10.1016/j.patcog.2006.11.023	computer vision;systems modeling;background subtraction;computer science;pattern recognition;histogram;segmentation;statistics;computer graphics (images)	Vision	46.952712521139645	-58.900230709140104	16238
1171e8a96ffb15fdb265aaba02be014a38137ad5	probabilistic deformation models for challenging periocular image verification	training;iris recognition;a posteriori probability estimation periocular image verification periocular region biometric trait human authentication one to one image matching unconstrained imaging conditions appearance variation nonuniform illumination variation motion blur defocus blur off axis gaze nonstationary pattern deformation periocular probabilistic deformation models ppdm gaussian markov random field distortion tolerant similarity metric;deformable models;probes;face recognition;markov processes gaussian processes image matching image restoration;face;iris recognition probes deformable models face training correlation face recognition;correlation	The periocular region as a biometric trait has recently gained considerable traction, especially under challenging scenarios where reliable iris information is not available for human authentication. In this paper, we consider the problem of one-to-one (1 : 1) matching of highly nonideal periocular images captured in-the-wild under unconstrained imaging conditions. Such images exhibit considerable appearance variations, including nonuniform illumination variations, motion and defocus blur, off-axis gaze, and nonstationary pattern deformations. To address these challenges, we propose periocular probabilistic deformation models (PPDMs) that: 1) reduce the image matching problem to matching local image regions and 2) approximate the periocular distortions by local patch level spatial translations whose relationships are modeled by a Gaussian Markov random field. Given a periocular image pair, we determine the distortion-tolerant similarity metric by regularizing local match scores by the maximum aposteriori probability estimate of the relative local deformations between them. Unlike the existing global periocular image matching techniques, by accounting for local image deformations in the periocular matching process, PPDM exhibits greater tolerance to pattern variations. We demonstrate the effectiveness of our model via extensive evaluation on a large number of in-the-wild periocular images. We find that PPDMs outperform many benchmark 1 : 1 image matching techniques (improving verification rates at 0.1% false accept rate by ~30% over previous work and ~40% when compared with the best baseline) in challenging scenarios leading to state-of-the-art verification performance on multiple real-world periocular data sets.	approximation algorithm;authentication;baseline (configuration management);benchmark (computing);biometrics;captcha;computation;discriminative model;distortion;estimation theory;experiment;facial recognition system;gaussian blur;ibm websphere extreme scale;image registration;markov chain;markov random field;modality (human–computer interaction);one-to-one (data model);optic axis of a crystal;patch (computing);svl;traction teampage	Jonathon M. Smereka;Vishnu Naresh Boddeti;B. V. K. Vijaya Kumar	2015	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2015.2434271	facial recognition system;face;computer vision;speech recognition;pattern recognition;iris recognition;mathematics;correlation	Vision	43.2175460029223	-52.18918790661106	16255
2d1faa15680ca82456ba1c32cc4eb431a28ff662	advance on curvelet application to prostate cancer tissue image classification		The approach of multi-resolution curvelet transform has been applied in our study of computer-aided classification of four critical Gleason patterns in prostate histological images. In the current study, we consider the maximum curvelet coefficients for the texture feature extraction to obtain more discriminative capability. A two-level classifier is re-designed, its excellent performance has been demonstrated.	coefficient;computer vision;curvelet;feature extraction;gleason's theorem;statistical classification	Wen-Chyi Lin;Ching-Chung Li;Jonathan I. Epstein;Robert Veltri	2017	2017 IEEE 7th International Conference on Computational Advances in Bio and Medical Sciences (ICCABS)	10.1109/ICCABS.2017.8114306	discriminative model;curvelet;feature extraction;prostate;artificial intelligence;gleason scores;prostate cancer;classifier (linguistics);contextual image classification;biology;pattern recognition	Robotics	34.177014807569314	-74.72019531681786	16273
23139cf6228053980eeffd42573c61fe5d658004	recognition-based segmentation of on-line cursive handwriting		This paper introduces a new recognition-based segmentation approach to recognizing on-line cursive handwriting from a database of 10,000 English words. The original input stream of z, y pen coordinates is encoded as a sequence of uniform stroke descriptions that are processed by six feed-forward neural-networks, each designed to recognize letters of different sizes. Words are then recognized by performing best-first search over the space of all possible segmentations. Results demonstrate that the method is effective at both writer dependent recognition (1.7% to 15.5% error rate) and writer independent recognition (5.2% to 31.1% error rate).	artificial neural network;best-first search;database;online and offline;stream (computing)	Nicholas S. Flann	1993			natural language processing;speech recognition;intelligent character recognition;computer science;pattern recognition	ML	32.590783376803174	-66.99204931710103	16318
879d486a44a2bfa536c1041f2e8897fced37b2f6	automated detection and segmentation of vascular structures of skin lesions seen in dermoscopy, with an application to basal cell carcinoma classification		Blood vessels are important biomarkers in skin lesions both diagnostically and clinically. Detection and quantification of cutaneous blood vessels provide critical information toward lesion diagnosis and assessment. In this paper, a novel framework for detection and segmentation of cutaneous vasculature from dermoscopy images is presented and the further extracted vascular features are explored for skin cancer classification. Given a dermoscopy image, we segment vascular structures of the lesion by first decomposing the image using independent-component analysis into melanin and hemoglobin components. This eliminates the effect of pigmentation on the visibility of blood vessels. Using k-means clustering, the hemoglobin component is then clustered into normal, pigmented, and erythema regions. Shape filters are then applied to the erythema cluster at different scales. A vessel mask is generated as a result of global thresholding. The segmentation sensitivity and specificity of 90% and 86% were achieved on a set of 500 000 manually segmented pixels provided by an expert. To further demonstrate the superiority of the proposed method, based on the segmentation results, we defined and extracted vascular features toward lesion diagnosis in basal cell carcinoma (BCC). Among a dataset of 659 lesions (299 BCC and 360 non-BCC), a set of 12 vascular features are extracted from the final vessel images of the lesions and fed into a random forest classifier. When compared with a few other state-of-art methods, the proposed method achieves the best performance of 96.5% in terms of area under the curve (AUC) in differentiating BCC from benign lesions using only the extracted vascular features.	area under curve;basal (phylogenetics);blood vessel tissue;blood supply aspects;bricx command center;cluster analysis;dermatologic disorders;dermoscopy;erythema;experimental organism basal cell carcinoma;extraction;independent component analysis;k-means clustering;melanins;pigmentation;pixel;quantitation;random forest;segmentation action;sensitivity and specificity;silo (dataset);structure of broca's area;thresholding (image processing);biologic segmentation;statistical cluster	Pegah Kharazmi;Mohammed I. AlJasser;Harvey Lui;Z. Jane Wang;Tim K. Lee	2017	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2016.2637342	lesion;computer vision;artificial intelligence;independent component analysis;random forest;computer science;skin cancer;thresholding;basal cell carcinoma;erythema;pathology;segmentation	Vision	35.69480032329658	-76.21768115309703	16326
ed7eefa17985e039e6ea330d05c90df6427f2b28	perceiving digital image watermark detection as image classification problem using support vector machines	support vector machine;image classification		digital image;support vector machine	Patrick Hang Hui Then;Wang Yin Chai	2005			automatic image annotation;binary image;digital image processing;digital image;computer science;watermark;computer vision;image processing;image analysis;feature detection (computer vision);artificial intelligence;pattern recognition	Vision	41.383827148619616	-65.63213168131443	16352
a7a461720026a80b52d599cae1efec7742da2813	a deep primal-dual network for guided depth super-resolution		In this paper we present a novel method to increase the spatial resolution of depth images. We combine a deep fully convolutional network with a non-local variational method in a deep primal-dual network. The joint network computes a noise-free, highresolution estimate from a noisy, low-resolution input depth map. Additionally, a highresolution intensity image is used to guide the reconstruction in the network. By unrolling the optimization steps of a first-order primal-dual algorithm and formulating it as a network, we can train our joint method end-to-end. This not only enables us to learn the weights of the fully convolutional network, but also to optimize all parameters of the variational method and its optimization procedure. The training of such a deep network requires a large dataset for supervision. Therefore, we generate high-quality depth maps and corresponding color images with a physically based renderer. In an exhaustive evaluation we show that our method outperforms the state-of-the-art on multiple benchmarks.	benchmark (computing);calculus of variations;depth map;diffusing update algorithm;display resolution;end-to-end principle;first-order predicate;mathematical optimization;nonlocal lagrangian;super-resolution imaging;synthetic intelligence;variational method (quantum mechanics)	Gernot Riegler;David Ferstl;Matthias Rüther;Horst Bischof	2016	CoRR		computer vision;computer science;theoretical computer science;machine learning	Vision	52.565589470327936	-72.69560571482668	16366
c7afef7cdc3ed2d31be64854355d425bb93426ad	a color grouping method for detection of object regions based on local saliency	image segmentation;computer vision;image colour analysis;feature extraction;object detection	The detection of object regions based on local saliency has been with great interest in computer vision for its potential contributions to applications, such as recognition, because objects of interest could be contained in salient regions. However, regions are extracted from local salient locations by simple procedures without the global inference, resulting in poor segmentation of possible objects. In this paper, a two-strategy has been proposed to introduce local saliency into foreground subtraction, a color grouping method. By using only color information and no prior higher level knowledge about objects and scenes, multiple foreground regions are extracted simultaneously according to visual attention based salient locations. The prominence score is defined to further evaluate these regions for their possibility to contain objects of interest.	color	Jiayun Wu;Kah-Bin Lim	2012		10.1109/ICARCV.2012.6485322	computer vision;feature extraction;computer science;machine learning;pattern recognition;image segmentation	Vision	38.42383981054757	-54.69719897418578	16419
b85159ae39067dee3032782f08ae4b1a6d1aa9d9	hacdb: handwritten arabic characters database for automatic character recognition	g400 computer science;handwriting recognition;image segmentation;g500 information systems;word segmentation hacdb handwritten arabic character database automatic offline arabic handwriting recognition handwritten arabic character shapes overlapping characters word testing word training;database arabic character recognition;shape databases handwriting recognition character recognition training educational institutions testing;word processing handwriting recognition handwritten character recognition image segmentation visual databases;handwritten character recognition;word processing;visual databases	Automatic off-line Arabic handwriting recognition based on segmentation still faces big challenges. A database, covering all shapes of handwritten Arabic characters, is required to facilitate the recognition process. This paper introduces a new database for handwritten Arabic characters (HACDB), designed to cover all shapes of Arabic characters including overlapping ones. It contains 6,600 shapes of characters written by 50 writers. This database can be used for training and testing the words for their recognition after segmentation. Also, it presents the possibility for comparing different approaches and evaluate their accuracy on a common base.	bibliographic database;database;handwriting recognition;online and offline;optical character recognition	Ahmed Lawgali;Maia Angelova;Ahmed Bouridane	2013	European Workshop on Visual Information Processing (EUVIP)		natural language processing;speech recognition;document processing;intelligent character recognition;intelligent word recognition;pattern recognition	Vision	33.04668947958013	-66.2564891976486	16541
cbb7b63be7a358de39baf3d48edbdbf2c557c524	the quotient image: class-based re-rendering and recognition with varying illuminations	illumination invariant signature image quotient image class based re rendering class based recognition varying illuminations image based recognition lambertian surface classes human faces;object recognition;face recognition;image recognition lighting rendering computer graphics image databases image generation image analysis humans face photometry layout;image based rendering;rendering computer graphics;visual recognition;illumination invariance;photometric alignment;face recognition rendering computer graphics object recognition	The paper addresses the problem of “class-based” imagebased recognition and rendering with varying illumination. The rendering problem is defined as follows: given a single input image of an object, and a sample of images with varying illumination conditions of other objects of the same general class, re-render the input image to simulate new illumination conditions. The class-based recognition problem is similarly defined: given a single image of an object in a database of images of other objects, some of them are multiply sampled under varying illumination, identify (match) any novel image of that object under varying illumination with the single image of that object in the database. We focus on Lambertian surface classes, and in particular the class of human faces. The key result in our approach is based on a definition of an illumination invariant signature image which enables an analytic generation of the image space with varying illumination. We show that a small database of objects — in our experiments as few as two objects — is sufficient for generating the image space with varying illumination of any new object of the class from a single input image of that object. In many cases the recognition results outperform by far conventional methods and the re-rendering is of remarkable quality considering the size of the database of example images and the mild pre-process required for making the algorithm work.	algorithm;autostereogram;experiment;lambertian reflectance;preprocessor;simulation	Amnon Shashua;Tammy Riklin-Raviv	2001	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.908964	facial recognition system;computer vision;feature detection;image-based modeling and rendering;binary image;rendering;image processing;computer science;cognitive neuroscience of visual object recognition;multimedia;3d single-object recognition;automatic image annotation;image-based lighting;computer graphics (images)	Vision	42.1988158877083	-52.97196599660419	16542
d88142f29a3919f3951ce63381f5c74789c2ce80	bark identification using improved statistical radial binary patterns		In this paper, we explore the texture representation at high scale levels for the application of tree bark identification. We mainly propose an Improved Statistical Radial Binary Pattern (ISRBP) texture descriptor, by introducing a new representation of the scale-space to encode large macrostructures with a low-dimensional representation. The proposed descriptor has advantages of a compact and information-preserving description of large macrostructures, computational simplicity, no preprocessing stage, enhanced texture representativeness and discriminative power. We conducted comprehensive experiments on different bark datasets, and the results show the effectiveness of the new representation of scale-space. In addition, the combination of different statistical radial descriptors provides competitive to high identification rates than state-of-the-art LBP texture descriptors.	algorithmic efficiency;encode;experiment;local binary patterns;preprocessor;radial (radio);radial basis function;scale space;texton	Safia Boudra;Itheri Yahiaoui;Ali Behloul	2018	2018 International Conference on Content-Based Multimedia Indexing (CBMI)	10.1109/CBMI.2018.8516536	discriminative model;grayscale;binary pattern;feature extraction;artificial intelligence;binary number;cognitive neuroscience of visual object recognition;preprocessor;texture descriptor;pattern recognition;computer science	Vision	30.738725928640754	-55.21532636559726	16546
16f2dca5fa64ce02da0d0c8daaeb2b2cbe405fd7	3d facial expression recognition using distance features and lbp features based on automatically detected keypoints	mouth;face recognition;three dimensional displays;feature extraction;solid modeling;lips;nose	The 3D facial surface demonstrates rich information about human beings' expressions. However, methods to recognize humans' facial expression are mainly still focusing on 2D images, which is not robust to pose and lighting conditions. In this paper, the problem of the person-independent facial expression recognition is addressed on basis of the line segments connected by specific 3D automatically detected facial keypoints and LBP features of depth images around the automatically detected facial keypoints. Using a Support Vector Machine classifier, the recognition rate reaches up to 92.1% on the BU-3DFE database. Comparative analysis shows that our method outperforms the competitor approaches using similar experimental settings, which proves the effectiveness of our method for 3D facial expression recognition.	3d modeling;belief propagation;experiment;facial recognition system;local binary patterns;semiconductor industry;support vector machine	Nan Sheng;Yiheng Cai;Changfei Zhan;Changyan Qiu;Yize Cui;Xurong Gao	2016	2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)	10.1109/CISP-BMEI.2016.7852743	facial recognition system;computer vision;feature extraction;computer science;machine learning;pattern recognition;three-dimensional face recognition;solid modeling;face hallucination	Vision	32.223054188321605	-58.256094964303635	16548
af66fa60819f4ffe0e22bce950f9dfdb64557115	coronary plaque boundary enhancement in ivus image by using a modified perona-malik diffusion filter	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	We propose a modified Perona-Malik diffusion (PMD) filter to enhance a coronary plaque boundary by considering the conditions peculiar to an intravascular ultrasound (IVUS) image. The IVUS image is commonly used for a diagnosis of acute coronary syndrome (ACS). The IVUS image is however very grainy due to heavy speckle noise. When the normal PMD filter is applied for speckle noise reduction in the IVUS image, the coronary plaque boundary becomes vague. For this problem, we propose a modified PMD filter which is designed in special reference to the coronary plaque boundary detection. It can then not only reduce the speckle noise but also enhance clearly the coronary plaque boundary. After applying the modified PMD filter to the IVUS image, the coronary plaque boundaries are successfully detected further by applying the Takagi-Sugeno fuzzy model. The accuracy of the proposed method has been confirmed numerically by the experiments.	acute coronary syndrome;anisotropic diffusion;dental plaque;diffusion magnetic resonance imaging;experiment;intravascular ultrasound;noise reduction;numerical analysis;pmd;senile plaques;vagueness;interest	Syaiful Anam;Eiji Uchino;Noriaki Suetake	2014		10.1155/2014/740627	biology;medical research;medicine;pathology;computer science;bioinformatics	Vision	37.99832345328574	-78.40516023865818	16549
af6bd93ac3fbb29ce7c989afacbc1ef02a1e3bd8	stereo matching by integrating piecewise surfaces matched in subranges of depth	dynamic programming;continuity;stereo images;interpolation;image segmentation;image matching;layout;data mining;iterative methods;laplace equations;stereo matching;layout pixel image segmentation data mining stereo vision laplace equations interpolation feature extraction computer science iterative methods;surface matching;feature extraction;pixel;stereo image processing;stereo vision;epipolar lines;epipolar lines piecewise surfaces stereo matching problem stereo images continuity;computer science;piecewise surfaces;stereo matching problem;image sequences	A new approach is proposed to deal with the stereo matching problem. Based on the assumption that the scene is composed of some piecewise continuous surfaces, two stereo images can be considered to be composed ofpatches which can be matched continuously between two images. To find the matching of such patches, we divide the range of the depth in the scene into small intervals, and find continuous matchings of segments on the epipolar line in each small interval. Then the continuously matched segments are merged into patches, by considering the continuity between epipolar lines. The ma,tchings of patches obtained in individual intervals, which may partially conflict or overlap with each other, are integrated to obtain the matchings of patches in the whole scene by considering the consistency among the matchings of patches.	computer stereo vision;epipolar geometry;line level;matching (graph theory);scott continuity	Caihua Wang;Keiichi Abe	1996		10.1109/ICPR.1996.546062	layout;computer vision;mathematical optimization;feature extraction;interpolation;computer science;stereopsis;machine learning;dynamic programming;mathematics;geometry;iterative method;image segmentation;pixel	Vision	49.713706552286375	-53.42506965796813	16560
d7f4180c8ab01a71f0def93cf81c8c5d9b9ebe8d	a single-scan algorithm for connected components labelling in a traffic monitoring application	binary image;visual surveillance;fast algorithm;traffic monitoring;connected component	This paper presents a fast algorithm based on sequential local operations which aims at labelling connected components in binary images. While classical algorithms scan the image twice and utilize an equiv alencetable to store and resolve lable redundancies, our method performs just a single scan, relying on the idea of labelling a whole blob at a time. In this way, we avoid label redundancies. As a consequence, the use od both equivalence tables and algorithms to resolve them becomes unnecessary. This leads our labelling algorithm to attain even more significant performances in the case of image characterized by blobs generating a large number of label equivalences. The proposed labelling algorithm has been successfully utilized in our visual surveillance system.	algorithm;connected component (graph theory)	Alessandro Bevilacqua;Alessandro Lanza;Giorgio Baccarani;Riccardo Rovatti	2003		10.1007/3-540-45103-X_90	computer vision;connected component;binary image;computer science;theoretical computer science;machine learning;mathematics;algorithm	ML	48.06168313956549	-55.270335653217636	16570
d71283d303a745d08789f01ce5fa1f59a349277b	edge detection operators for angular data	circular quasi ranges;edge detection operators;hue images;image segmentation;image segmentation image colour analysis edge detection;image edge detection detectors color area measurement signal processing filters statistics image segmentation dispersion signal detection;angular data;edge detection;qualitative criteria edge detection operators angular data vector direction color image processing circular dispersion angular edges hue images circular quasi ranges noisy angular signals quantitative criteria;color image processing;qualitative criteria;noisy angular signals;image colour analysis;circular dispersion;quantitative criteria;vector direction;angular edges	"""Physical quantities referring to angles, like vector direction, color hue etc., are periodic in nature. Due to this periodicity edge detectors proposed for data on the line cannot be used to detect edges in angle-related signals. In this paper we use estimators of circular dispersion to introduce edge detectors for angular signals and discuss their application in edge detection on hue images. Extensions of the notion of quasi-range to circular data are also proposed. These """"circular"""" quasi-ranges have good and user-controlled properties as edge detectors on noisy angular signals. The performance of the proposed edge operators is evaluated on angular edges, using both qualitative and quantitative criteria."""	angularjs;edge detection	Nikos Nikolaidis;Ioannis Pitas	1995		10.1109/ICIP.1995.537438	computer vision;edge detection;computer science;mathematics;image segmentation;canny edge detector;direction vector	AI	51.284952988305015	-65.63696776642105	16593
274d1ef1201836250e6a4be0f34a013ebc90cc24	complex conditional generative adversarial nets for multiple objectives detection in aerial images		Simultaneously detection and evaluation of small regions of interest from aerial images is successfully achieved by conditional generative adversarial nets (cGAN). As novelty, the paper proposes a cheap and accurate method based on a cGAN structure, containing two generators, and graphics processing units (GPU) to segment small flooded areas and respectively, roads from images taken by unmanned aerial vehicles. In the learning phase the weights for the discriminator and the two generators are established by a back propagation method. The real mask is created by using information of the color components R, G, B, H and a voting scheme in a supervised process. A set of 40 images were used for the learning phase and another set of 100 images were used for method validation. The method presents the advantages of accuracy and time processing (especially in the operational phase).		Dan Popescu;Loretta Ichim;Andrei Docea	2018		10.1007/978-3-030-04212-7_59	generative grammar;novelty;artificial intelligence;adversarial system;discriminator;backpropagation;pattern recognition;graphics;voting;computer science	Vision	28.105021205331454	-54.44226733004785	16660
8b2b046cb6908db1abfa6f909710a09f7d8e7d89	a family of shape ellipticity measures for galaxy classification	image processing;94a08;ellipticity measure;shape;62h30;68u10;object classification	A new family of shape ellipticity measures is introduced. Each measure from the family distinguishes among the ellipses with different axis length ratios. This is not case for existing ellipticity measures. The new measures are theoretically well founded, which helps us to better understand their behavior and suitability to certain applications. All measures from the family are invariant with respect to translation, rotation, and scaling transformations; range over $(0,1]$; and pick the value 1 only for the ellipses with a specific ratio between minor and major axis lengths. The measures from the new family are applied to the galaxy classification tasks. The 100% classification rate was achieved by using a $k$-NN classifier. Only six parameters (feature vector components), computed from three different ellipticity measures, were used. Based on 100 mutually independent experiments, an average classification rate of 95.6% was obtained. Previously accuracies of 92.3% and 95.1% were obtained using nearest nei...		Mehmet Ali Aktas;Jovisa D. Zunic	2013	SIAM J. Imaging Sciences	10.1137/120866026	computer vision;combinatorics;topology;image processing;shape;mathematics;geometry	Theory	44.99836509785058	-63.57670177894626	16664
214b66b0dd3c693af70217a014abc5eef76f0ab5	chinese text distinction and font identification by recognizing most frequently used characters	feature extraction;pattern recognition;text distinction;template matching;character recognition;font identification	In this study, the method of implementing the three functions that can offer great help for a traditional OCCR (Optical Chinese Character Recognition) system is proposed: (1) to identify the font used in a document; (2) to detect and recognize the most frequently used (MFU) characters; and (3) to distinguish between the machine-printed and hand-written characters. According to the study investigated by Chang and Chen (Proceedings of the ICCC, 1994, pp. 310–316), about 20% of Chinese characters in a text document are predominated by the top-40 MFU characters. If those MFU characters in a text document can be detected before adopting the traditional OCCR method, there will be great savings in computation time.#R##N##R##N#The proposed method for character detection consists of the following three stages: the stage of segmentation, the stage of feature extraction, and the stage of classification. In the first stage, based on the concept of projection profile, the method presented by Wang et al. (Pattern Recognition 30 (1997) 1213) is utilized to segment characters individually from the input text document. In the second stage, three different types of features are introduced, including the density of black pixels, the projection profile code, and the modified skeleton template. These features are used to check whether the segmented character is semi-matched or fully-matched with the MFU template. Finally, in the last stage, based on the matching result, three different algorithms for implementing the aforementioned functions are provided. Experimental results are given in this study to demonstrate the practicality and superiority of the proposed method.		Chi-Fang Lin;Yu-Fan Fang;Yau-Tarng Juang	2001	Image Vision Comput.	10.1016/S0262-8856(00)00082-2	arithmetic;computer vision;speech recognition;template matching;feature extraction;computer science;pattern recognition	Vision	34.05738115447423	-65.11044228820286	16666
9652445dcd673b6b69f5b844f8ef1b1626d4b8c2	automated detection of bone metastatic changes using serial ct scans	longitudinal ct scans;bone metastases;registration;follow up ct scan;quantitative imaging	Bone metastases resulting from a primary tumor invasion to the bone are common and cause significant morbidity in advanced cancer patients. Although the detection of bone metastases is often straightforward, it is difficult to identify their spread and track their changes, particularly in early stages. This paper presents a novel method that automatically finds the changes in appearance and the progress of bone metastases using longitudinal CT images. In contrast to previous methods based on nodule detection within a specific bone site in an individual CT scan, the approach in the present study is based on the subtraction between two registered CT volumes. The volumes registered using the proposed weighted-Demons registration and symmetric warping were subtracted with minimizing noise, and the Jacobian and false positive suppressions were performed to reduce false alarms. The proposed method detects the changes in bone metastases within 3min for entire chest bone structures covering the spine, ribs, and sternum. The method was validated based on 3-fold cross validation using the radiologists' markings of 459 lesions in 24 subjects and was performed with a sensitivity of 92.59%, a false positive volume of 2.58%, and 9.71 false positives per patient. Note that 113 lesions (24%) missed by the radiologists were identified by the present system and confirmed to be true metastases. Indeed, three patients diagnosed initially as normal, having no metastatic difference, by radiologists were found to be abnormal using the proposed system. Automatic detection method of bone metastatic changes in the entire chest bone was developed. Weighted Demons, symmetric warping, following false positive suppressions, and their parallel computing implementation enabled precise and fast computation of delicate changes in serial CT scans. The cross validation proved that this method can be quite useful for assisting radiologists in sensing minute metastatic changes from early stage.		Jihun Oh;Gyehyun Kim;Jaesung Lee;Min-Su Cheon;Yongsup Park;Sewon Kim;Jonghyon Yi;Ho Yun Lee	2017	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2016.11.007	radiology;medicine;pathology;nuclear medicine	Visualization	38.0344494869724	-79.89179215006969	16671
689d6d40222f27f3fe5fb98680224be8aede3f19	model-based similarity estimation of multidimensional temporal sequences	busqueda informacion;document multimedia;information retrieval;estudio comparativo;maquina vector soporte;interrogation base donnee;support vector regression;interrogacion base datos;multimedia document;archive;feature space;multidimensional feature sequences;similitude;etude comparative;machine vecteur support;large scale;base donnee multimedia;analisis regresion;simulation time warp;archivo;recherche information;busqueda por contenido;image sequence;multimedia communication;signal classification;multimedia databases;similarity;comparative study;classification signal;similarity estimation in a model space;analyse regression;regression analysis;secuencia imagen;support vector machine;similitud;classification automatique;time warp simulation;communication multimedia;automatic classification;clasificacion automatica;content based retrieval;database query;recherche par contenu;temporal aspects;sequence image;documento multimedia	Content-based queries in multimedia sequence databases where information is sequential is a tough issue, especially when dealing with large scale applications. One of the key points is similarity estimation between a query sequence and elements of the database. In this paper, we investigate two ways to compare multimedia sequences, one – that comes from the literature – being computed in the feature space while the other one is computed in a model space, leading to a representation less sensitive to noise. We compare these approaches by testing them on a real audio dataset, which points out the utility of working in the model space.	distortion;feature vector;mp3;performance;sequence database;similarity measure;temporal database;theory	Romain Tavenard;Laurent Amsaleg;Guillaume Gravier	2009	Annales des Télécommunications	10.1007/s12243-009-0091-4	support vector machine;speech recognition;computer science;artificial intelligence;data mining	DB	42.498435312703826	-60.85040743207979	16698
1e0dd12f2bff234a4df71641bc95068733506858	handwritten word spotting with corrected attributes	word spotting;multi writer;hidden markov models histograms training calibration computational modeling writing correlation;query processing;query processing document image processing;handwritten word spotting;canonical correlation analysis handwritten word spotting corrected attributes multiwriter word spotting document images attributes based approach word images fixed length representation query by string calibration scheme;cca;cca word spotting multi writer attibutes;canonical correlation analysis;attributes;document image processing;attibutes	We propose an approach to multi-writer word spotting, where the goal is to find a query word in a dataset comprised of document images. We propose an attributes-based approach that leads to a low-dimensional, fixed-length representation of the word images that is fast to compute and, especially, fast to compare. This approach naturally leads to an unified representation of word images and strings, which seamlessly allows one to indistinctly perform query-by-example, where the query is an image, and query-by-string, where the query is a string. We also propose a calibration scheme to correct the attributes scores based on Canonical Correlation Analysis that greatly improves the results on a challenging dataset. We test our approach on two public datasets showing state-of-the-art results.	query by example	Jon Almazán;Albert Gordo;Alicia Fornés;Ernest Valveny	2013	2013 IEEE International Conference on Computer Vision	10.1109/ICCV.2013.130	natural language processing;canonical correlation;speech recognition;computer science;pattern recognition;mathematics;statistics	Vision	28.736415138848116	-67.01513709830103	16753
14eb84090e86f04c3a2838bd8f205bb003c37c93	assessment of the quality of handwritten signatures based on multiple correlations	handwriting recognition;handwritten character recognition correlation methods feature extraction handwriting recognition;correlation methods;handwritten signature signature assessment discriminatory power publicly available databases multifeature vector totally ordered bin boundaries quality bins automatic signature verification engines dynamic signature features static signature features utility prediction automated biometric recognition systems individual biometric sample quality assurance multiple correlations;feature extraction;correlation feature extraction training accuracy predictive models handwriting recognition static var compensators;handwritten character recognition	Assuring the quality of individual biometric samples is important for maintaining the discriminatory power of biometric recognition systems as biometric data of low-quality are likely to be mismatched. This paper presents an investigation into the assessment of the quality of handwritten signatures, predicting the performance or 'utility' of individual signature samples in automated biometric recognition. The prediction of utility is based on multiple correlations with static and dynamic signature features. First, the utility of handwritten signature samples from publicly available databases is assessed by comparing them with each other using commercial automatic signature verification engines. The samples are classified into four quality bins (excellent, adequate, marginal, and unacceptable quality) with totally ordered bin boundaries. Then, the correlation of multiple static and dynamic signature features with utility is analysed to find features that can be used for predicting the utility of samples. Our results show that it is possible to predict the utility of handwritten signature samples using a multi-feature vector.	biometric device;biometrics;database;electronic signature;feature vector;marginal model	Richard M. Guest;Olaf Henniger	2013	2013 International Conference on Biometrics (ICB)	10.1109/ICB.2013.6613011	speech recognition;feature extraction;computer science;machine learning;pattern recognition;data mining;handwriting recognition;signature recognition	Vision	29.21680792014149	-63.739338680093844	16757
2fe6210474555d56caebad38e6a421ef8e66ab70	evaluating the angular sensitivity of corner detectors	corner mcnemar;edge detection;biomedical imaging;computer vision;qa75 electronic computers computer science;internal angles angular sensitivity corner detectors;feature extraction;s test angular sensitivity;detectors sensitivity image edge detection shape biomedical imaging computer vision feature extraction corner mcnemar;detectors sensitivity image edge detection shape biomedical imaging computer vision feature extraction	Several popular corner detectors were evaluated on imagery containing corners with a variety of internal angles. Even in a noise-free environment, differences in performance were found. A null hypothesis approach was taken in evaluating whether these performance differences were significant, taking into account correctly the size of the dataset and the number of discrepancies. It was found that some of these performance differences are statistically significant, allowing recommendations to be made regarding which detectors should be used when a problem has corners of known internal angles.	algorithm;angularjs;corner detection;harris affine region detector;harris functional;performance;receiver operating characteristic;sensor;tomasi–kanade factorization	Nadia Kanwal;Shoaib Ehsan;Erkan Bostanci;Adrian F. Clark	2011	2011 IEEE International Conference on Virtual Environments, Human-Computer Interfaces and Measurement Systems Proceedings	10.1109/VECIMS.2011.6053856	medical imaging;corner detection;computer vision;edge detection;feature extraction;computer science;interest point detection	Visualization	37.11000765388841	-71.2904792640007	16788
e6f757a05740a1093b6f5be83a67fb2d5413314e	detection of postmenopausal alteration of bone structure in digitized x-rays	parametric model;x ray imaging;digital camera;false alarm rate;trabecular bone;fractal dimension;region of interest;x rays	The goal of this research is to investigate the effectiveness of trabecular bone characterization in X-ray images acquired by consumer digital cameras from the radiological films by the joint use of fractal and statistic parameters. We propose the classification of patients in the pre- and post-menopausal groups, based on the trabecular structure of the calcaneum bone. The bone structure is locally characterized in clinically-significant regions of interest by the usual fractal dimension and a parametric model of the gray-level histogram. The classification yields a 8.33% miss-detection and 16.66% false alarm rate.		Constantin Vertan;Ion Stefan;Laura Florea	2007		10.1007/978-3-540-74272-2_35	computer vision;parametric model;constant false alarm rate;mathematics;fractal dimension;statistics;region of interest	Theory	37.50000216720773	-75.03771782741886	16840
5446a77f81f17c5b501aa44d803a507f5712f049	compression-based clustering of video human activity using an ascii encoding		Human Activity Recognition (HAR) from videos is an important area of computer vision research with several applications. There are a wide number of methods to classify video human activities, not without certain disadvantages such as computational cost, dataset specificity or low resistance to noise, among others. In this paper, we propose the use of the Normalized Compression Distance (NCD), as a complementary approach to identify video-based HAR. We have developed a novel ASCII video data format, as a suitable format to apply the NCD in video. For our experiments, we have used the Activities of Daily Living Dataset, to discriminate several human activities performed by different subjects. The experimental results presented in this paper show that the NCD can be used as an alternative to classical analysis of video HAR.		Guillermo Sarasa;Aaron Montero;Ana Granados;Francisco B. Rodríguez	2018		10.1007/978-3-030-01421-6_7	image processing;pattern recognition;artificial intelligence;encoding (memory);normalized compression distance;dendrogram;activity recognition;cluster analysis;ascii;computer science	Vision	27.320607826078582	-58.2369253035272	16882
4c6a325d7d8d0eb75dd8e19da458ba40061f8c89	point-tracked quantitative analysis of left ventricular surface motion from 3-d image sequences	motion analysis;three dimensional imaging;nuclear magnetic resonance imaging;image tridimensionnelle;computerized axial tomography;tomodensitometria;vision ordenador;medical imagery;motion study;informatica biomedical;funcion ventricular izquierda;biomedical data processing;image motion analysis;analyse surface;3d imaging;myocardial injury;validacion;analisis forma;analisis cuantitativo;cardiac function;informatique biomedicale;biomechanics;hombre;estudio movimiento;image analysis image motion analysis image sequence analysis motion analysis image sequences myocardium shape magnetic resonance imaging computed tomography motion detection;left ventricular;indexing terms;computer vision;imageria rmn;tomodensitometrie;circulatory system;analyse quantitative;medical diagnostic imaging point tracked quantitative analysis left ventricular surface motion 3 d image sequences mri ct left ventricular regional function point correspondence maps noninvasive algorithm derived results motion trajectories implanted imaging opaque markers canine model imaging modalities subpixel accuracy motion parameters path length thickness changes myocardial injury area postmortem analysis ttc staining pearson product moment correlation value myocardial tissue;medical image processing;analisis superficie;etude mouvement;human;computerised tomography;imagerie medicale;quantitative analysis;tridimensional image;fonction ventriculaire gauche;validation;vision ordinateur;imagerie rmn;pattern analysis;imageneria medical;left ventricle performance;shape modeling;computerised tomography image motion analysis biomechanics image sequences medical image processing biomedical mri;appareil circulatoire;aparato circulatorio;algorithms animals computer graphics computer simulation dogs humans image processing computer assisted magnetic resonance imaging myocardial contraction myocardial infarction reference values sensitivity and specificity tomography x ray computed ventricular function left;analyse forme	Proposes and validates the hypothesis that one can use differential shape properties of the myocardial surfaces to recover dense field motion from standard three-dimensional (3-D) image sequences (MRI and CT). Quantitative measures of left ventricular regional function can be further inferred from the point correspondence maps. The noninvasive, algorithm-derived results are validated on two levels. First, the motion trajectories are compared to those of implanted imaging-opaque markers of a canine model in two imaging modalities, where subpixel accuracy is achieved. Second, the validity of using motion parameters (path length and thickness changes) for detecting myocardial injury area is tested by comparing algorithms derived results to postmortem analysis TTC staining of myocardial tissue, where the achieved Pearson product-moment correlation value is 0.968.	autopsy;cardiomyopathies;implants;inference;map;myocardium;pixel;sensor;staining method;thickness (graph theory);algorithm	Pengcheng Shi;Albert J. Sinusas;R. Todd Constable;Erik L. Ritman;James S. Duncan	2000	IEEE Transactions on Medical Imaging	10.1109/42.832958	stereoscopy;computer vision;index term;cardiac function curve;computer science;quantitative analysis;biomechanics;surface weather analysis;circulatory system;nuclear medicine	Vision	45.04820457561717	-79.73009370045763	16889
f1e2f0d8440de2e3c3c43ebea3ecf8522ac0532f	automatic detection of blood vessel in retinal images		Automatic detection of retinal blood vessels and measurement of vessel diameter are very much important for the diagnosis and the treatment of different ocular diseases including diabetic retinopathy (DR), glaucoma and hypertension. In this paper, we present a novel method to detect blood vessels in the fundus retinal images. The proposed method consists of three main steps. The first step is pre-processing of retinal image to improve the retinal images by evaluation of several image enhancement techniques. In the second step, the vesselness filter is usually used to enhance the blood vessels. Finally Hessian multiscale enhancement filter is designed from the adaptive thresholding of the output of the vesselness filter for vessels detection. The performance of algorithms is compared and analyzed on three publicly available databases (DRIVE, STARE and CHASE_DB) of retinal images using a number of measures, which include accuracy, sensitivity, and specificity.	algorithm;benchmark (computing);database;hessian;image editing;preprocessor;sensitivity and specificity;thresholding (image processing)	Abderrahmane Elbalaoui;Mohamed Fakir;Khaddouj Taifi;Abdelkarim Merbouha	2016	2016 13th International Conference on Computer Graphics, Imaging and Visualization (CGiV)	10.4018/IJHISI.2017010102	computer vision	Vision	37.0343335850564	-76.05088667079455	17054
012c5d5a413382a1d7cd2f0268f89954aa3760a9	a two-phase genetic algorithm for image registration		"""Image Registration (IR) is the process of aligning two (or more) images of the same scene taken at different times, different viewpoints and/or by different sensors. It is an important, crucial step in various image analysis tasks where multiple data sources are integrated/fused, in order to extract high-level information.  Registration methods usually assume a relevant transformation model for a given problem domain. The goal is to search for the """"optimal"""" instance of the transformation model assumed with respect to a similarity measure in question.  In this paper we present a novel genetic algorithm (GA)-based approach for IR. Since GA performs effective search in various optimization problems, it could prove useful also for IR. Indeed, various GAs have been proposed for IR. However, most of them assume certain constraints, which simplify the transformation model, restrict the search space or make additional preprocessing requirements. In contrast, we present a generalized GA-based solution for an almost fully affine transformation model, which achieves competitive results without such limitations using a two-phase method and a multi-objective optimization (MOO) approach.  We present good results for multiple dataset and demonstrate the robustness of our method in the presence of noisy data."""	genetic algorithm;high- and low-level;image analysis;image registration;mathematical optimization;multi-objective optimization;preprocessor;problem domain;requirement;robustness (computer science);sensor;signal-to-noise ratio;similarity measure;software release life cycle;two-phase commit protocol;two-phase locking	Sarit Chicotay;Eli David;Nathan S. Netanyahu	2017		10.1145/3067695.3076017	mathematical optimization;genetic algorithm;computer science;machine learning;robustness (computer science);pattern recognition;artificial intelligence;similarity measure;affine transformation;image registration;multi-objective optimization;problem domain;optimization problem	AI	46.58147367415171	-54.21590015486548	17072
7fdf8e2393ee280c9a3aeb94aae375411358e45a	real-time traffic sign recognition from video by class-specific discriminative features	libre mercado;driver assistance;teletrafic;analisis imagen;traitement signal;evaluation performance;metodo estadistico;vision ordenador;analisis componente principal;polygonal shape;forma poligonal;learning algorithm;performance evaluation;image processing;learning;distance transformation;evaluacion prestacion;representation image;computer vision based driver assistance;forme polygonale;real time traffic;procesamiento imagen;transformation distance;statistical method;algorithme apprentissage;region interes;traitement image;similitude;colour distance transform;marche concurrentiel;computer vision;aprendizaje;discriminant analysis;analyse discriminante;vecino mas cercano;analisis discriminante;apprentissage;teletrafico;representation signal;methode statistique;image representation;forward feature selection;traffic sign recognition;feature extraction;signal processing;principal component analysis;region of interest;signal representation;signal classification;poursuite cible;similarity;teletraffic;analyse composante principale;classification signal;discriminative local regions;plus proche voisin;aide a la conduite;nearest neighbour;image analysis;vision ordinateur;feature selection;systeme information conducteur;similitud;open market;region interet;extraction caracteristique;classification automatique;temporal integration;target tracking;distance transform;automatic classification;imagen color;algoritmo aprendizaje;procesamiento senal;clasificacion automatica;analyse image;driver information systems;transformacion distancia;image couleur;color image;interest region	In this paper we address the problem of traffic sign recognition. Novel image representation and discriminative feature selection algorithms are utilised in a traditional three-stage framework involving detection, tracking and recognition. The detector captures instances of equiangular polygons in the scene which is first appropriately filtered to extract the relevant colour information and establish the regions of interest. The tracker predicts the position and the scale of the detected sign candidate over time to reduce computation. The classifier compares a discrete-colour image of the observed sign with the model images with respect to the class-specific sets of discriminative local regions. They are learned off-line from the idealised template sign images, in accordance with the principle of one-vs-all dissimilarity maximisation. This dissimilarity is defined based on the so-called Colour Distance Transform which enables robust discrete-colour image comparisons. It is shown that compared to the well-established feature selection techniques, such as Principal Component Analysis or AdaBoost, our approach offers a more adequate description of signs and involves effortless training. Upon this description we have managed to build an efficient road sign recognition system which, based on a conventional nearest neighbour classifier and a simple temporal integration scheme, demonstrates a competitive performance in the experiments involving real traffic video.	adaboost;color image;distance transform;eclipse;feature extraction;feature selection;real-time transcription;spatial variability;traffic sign recognition	Andrzej Ruta;Yongmin Li;Xiaohui Liu	2010	Pattern Recognition	10.1016/j.patcog.2009.05.018	computer vision;image analysis;speech recognition;similarity;open market operation;color image;image processing;feature extraction;computer science;artificial intelligence;similitude;signal processing;traffic sign recognition;distance transform;feature selection;principal component analysis;region of interest	Vision	46.12038802802354	-58.633179628636775	17087
1d0c4aa08d983f5d6af123cd22de23d2456a3dfa	gp-based secondary classifiers	genetic program;handwritten digit recognition;genetic programming;classification;secondary classifiers;feature selection;digital image	Genetic programming (GP) is used to evolve secondary classifiers for disambiguating between pairs of handwritten digit images. The inherent property of feature selection accorded by GP is exploited to make sharper decision between conflicting classes. Classification can be done in several steps with an available feature set and a mixture of strategies. A two-step classification strategy is presented in this paper. After the first step of the classification using the full feature set, the high confidence recognition result will lead to an end of the recognition process. Otherwise a secondary classifier designed using a sub-set of the original feature set and the information available from the earlier classification step will help classify the input further. The feature selection mechanism employed by GP selects important features that provide maximum separability between classes under consideration. In this way, a sharper decision on fewer classes is obtained at the secondary classification stage. The full feature set is still available in both stages of classification to retain complete information. An intuitive motivation and detailed analysis using confusion matrices between digit classes is presented to describe how this strategy leads to improved recognition performance. In comparison with the existing methods, our method is aimed for increasing recognition accuracy and reliability. Results are reported for the BHA test-set and the NIST test-set of handwritten digits. 2004 Published by Elsevier Ltd on behalf of Pattern Recognition Society.	algorithm;computation;confusion matrix;experiment;feature selection;feature vector;finite-state machine;fitness function;formal methods;genetic programming;iterative method;linear separability;pattern recognition;test-and-set	Ankur Teredesai;Venu Govindaraju	2005	Pattern Recognition	10.1016/j.patcog.2004.06.010	genetic programming;feature;biological classification;computer science;machine learning;pattern recognition;data mining;feature selection;feature;digital image	Vision	26.75150667678612	-62.06582128390757	17098
dacd326a38d9ed7ef5e672b8b1f4c7e3a1a5ee90	c-cnn: cascaded convolutional neural network for small deformable and low contrast object localization	convolution neural network;deep learning;small deformable and low contrast detection	Traditionally, the normalized cross correlation (NCC) based or shape based template matching methods are utilized in machine vision to locate an object for a robot pick and place or other automatic equipment. For stability, well-designed LED lighting must be mounted to uniform and stabilize lighting condition. Even so, these algorithms are not robust to detect the small, blurred, or large deformed target in industrial environment. In this paper, we propose a convolutional neural network (CNN) based object localization method, called C-CNN: cascaded convolutional neural network, to overcome the disadvantages of the conventional methods. Our C-CNN method first applies a shallow CNN densely scanning the whole image, most of the background regions are rejected by the network. Then two CNNs are adopted to further evaluate the passed windows and the windows around. A relatively deep model net-4 is applied to adjust the passed windows at last and the adjusted windows are regarded as final positions. The experimental results show that our method can achieve real time detection at the rate of 14FPS and be robust with a small size of training data. The detection accuracy is much higher than traditional methods and state-of-the-art methods.	algorithm;artificial neural network;convolutional neural network;cross-correlation;experiment;graphics processing unit;machine vision;microsoft windows;neural correlates of consciousness;object detection;real-time computing;smt placement equipment;template matching	Xiaojun Wu;Xiaohao Chen;Jinghui Zhou	2017		10.1007/978-981-10-7299-4_2	convolutional neural network;cross-correlation;smt placement equipment;deep learning;machine vision;template matching;computer vision;training set;artificial intelligence;pattern recognition;mathematics	AI	29.129657048298316	-55.65331956147787	17165
92722bba39059210484b723184431fc177ed31cc	dominant color extraction based on dynamic clustering by multi-dimensional particle swarm optimization	color distance metric;quantization;pattern clustering;premature convergence;color space;search space;color;multidimensional particle swarm optimization;data mining;fuzzy set theory;global best particle;pattern clustering colour graphics content based retrieval fuzzy set theory particle swarm optimisation;dynamic clustering;multi dimensional;indexes;distance measurement;particle swarm optimizer;fractional global best formation;image color analysis;human visual system;particle swarm optimization;indexation;visual scenery;distance metric;image analysis;dominant color extraction;dominant color descriptor;clustering methods;colour graphics;particle swarm optimisation;content based retrieval;dynamic clustering color particle swarm optimization;fuzzy model;particle swarm optimization data mining image color analysis extraterrestrial measurements information resources information retrieval image retrieval content based retrieval humans visual system;fuzzy model dominant color extraction dynamic clustering multidimensional particle swarm optimization image analysis content based retrieval visual scenery human visual system fractional global best formation global best particle color distance metric	Color is the major source of information widely used in image analysis and content-based retrieval. Extracting dominant colors that are prominent in a visual scenery is of utter importance since human visual system primarily uses them for perception. In this paper we address dominant color extraction as a dynamic clustering problem and use techniques based on Particle Swarm Optimization (PSO) for finding optimal (number of) dominant colors in a given color space, distance metric and a proper validity index function. The first technique, so-called Multi-Dimensional (MD) PSO, re-forms the native structure of swarm particles in such a way that they can make inter-dimensional passes with a dedicated dimensional PSO process. Therefore, in a multidimensional search space where the optimum dimension is unknown, swarm particles can seek both positional and dimensional optima. Nevertheless, MD PSO is still susceptible to premature convergences due to lack of divergence. To address this problem we then present Fractional Global Best Formation (FGBF) technique, which basically collects all promising dimensional components and fractionally creates an artificial global-best particle (aGB) that has the potential to be a better “guide” than the PSO’s native gbest particle. We finally propose an efficient color distance metric, which uses a fuzzy model for computing color (dis-) similarities over HSV (or HSL) color space. The comparative evaluations against MPEG-7 dominant color descriptor show the superiority of the proposed technique.	cluster analysis;color space;converge;database index;experiment;ground truth;human visual system model;image analysis;information source;k-means clustering;local optimum;mpeg-7;mathematical optimization;molecular dynamics;particle swarm optimization;stochastic optimization;telecommunications link;true dc	Serkan Kiranyaz;Stefan Uhlmann;Moncef Gabbouj	2009	2009 Seventh International Workshop on Content-Based Multimedia Indexing	10.1109/CBMI.2009.11	database index;computer vision;image analysis;quantization;metric;computer science;artificial intelligence;machine learning;fuzzy set;color space;human visual system model;particle swarm optimization;premature convergence	Robotics	41.79514955446364	-62.26329228643428	17211
5e14734249b478135c55acd0e74812536dc01b97	patch-based reconstruction of surfaces undergoing different types of deformations		We deal with the reconstruction of surfaces that deform under a variety of conditions. The deformation can range from no extension to a certain degree of extensibility. The deformed surface is reconstructed from a single image, given a 3D reference shape. This shape corresponds to the undeformed state of the surface and can be computed using any appropriate technique. In particular, we use homographies defined from two views of the surface. To proceed with the 3D reconstruction of the deformed surface, we assume that the deformations are locally homogeneous and that the overall surface deformation can be obtained by combining the local homogeneous deformations. For this purpose, the surface is split into small patches. For each patch, a mapping between the undeformed and the deformed shapes is computed. The mapping is specified by using the quadratic deformation model Fayad et al. (Proceedings of British Machine Vision Conference (BMVC), 2004). As a result, given the undeformed shape, we define an optimization procedurewhose goal is to estimate the 3Dpositions of deformed points in each image. The optimization is performed on each patch, independently of the others. The experimental results show that this approach allows precise reconstruction of a wide class of real deformations.	3d reconstruction;autostereogram;british machine vision conference;extensibility;mathematical optimization;patch (computing);patch cable;shape context	S. Jafar Hosseini;Helder Araújo	2017	Signal, Image and Video Processing	10.1007/s11760-017-1079-6	topology;mathematics;geometry	Vision	53.502612797356164	-52.21078411614702	17222
9d791e47d486fc8adacbdc564b47c82fc2d4f366	multispectral image indexing based on vector lifting schemes	geophysical image processing;copula theory;image coding;image resolution;image databases;multispectral imaging indexing image retrieval image databases spatial resolution image coding image resolution wavelet transforms content based retrieval spatial databases;multiresolution decomposition;multiscale representation;remote sensing geophysical image processing image representation image retrieval indexing;lifting scheme;cross component dependencies multispectral image indexing vector lifting scheme multiscale representation multiresolution decomposition copula function image retrieval;wavelet transforms;wavelet transform;indexing;image representation;remote sensing;multispectral images;copula function;indexation;spatial databases;distributed models;copula theory image retrieval wavelet transform vector lifting scheme cross component dependencies;multispectral image indexing;cross component dependencies;vector lifting scheme;content based retrieval;multispectral imaging;spatial resolution;image retrieval	In this work, we are interested in extracting salient signatures from multiscale representations of multispectral images for retrieval applications. The contribution of this paper consists in focusing on a special multiresolution decomposition based on the concept of Vector Lifting Scheme (VLS) which offers the advantage of simultaneously capturing the spatial and the cross-spectral redundancies of any multicomponent image. Within each subband, the joint distribution of the resulting coefficients stacked through the spectral components is modeled by a multivariate function driven by an appropriately chosen copula function. The parameters of such distribution model are chosen as relevant signatures of the image. Experimental results indicate an improvement in the retrieval performances when using the VLS instead of the conventional wavelet transform.	antivirus software;coefficient;electronic signature;lifting scheme;multispectral image;norm (social);performance;von luschan's chromatic scale;wavelet transform	Sarra Sakji-Nsibi;Amel Benazza-Benyahia	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5417418	multispectral image;computer vision;image resolution;image retrieval;pattern recognition;mathematics;information retrieval;remote sensing;wavelet transform	Vision	37.7266093377027	-61.153892161440346	17227
521482c2089c62a59996425603d8264832998403	landmark localization on 3d/4d range data using a shape index-based statistical shape model with global and local constraints	face and expression analysis;deformable models;4d range data;landmark localization;statistical shape models;3d range data	lijun@cs.binghamton.edu (Lijun Yin) Abstract In this paper we propose a novel method for detecting and tracking facial landmark features on 3D static and 3D dynamic (a.k.a. 4D) range data. Our proposed method involves fitting a shape indexbased statistical shape model (SI-SSM) with both global and local constraints to the input range data. Our proposed model makes use of the global shape of the facial data as well as local patches, consisting of shape index values, around landmark features. The shape index is used due to its invariance to both lighting and pose changes. The fitting is performed by finding the correlation between the shape model and the input range data. The performance of our proposed method is evaluated in terms of various geometric data qualities, including data with noise, incompletion, occlusion, rotation, and various facial motions. The accuracy of detected features is compared to the ground truth data as well as to start of the art results. We test our method on five publicly available 3D/4D databases: BU-3DFE, BU-4DFE, BP4D-Spontaneous, FRGC 2.0, and Eurecom Kinect Face Dataset. The efficacy of the detected landmarks is validated through applications for geometric based facial expression classification for both posed and spontaneous expressions, and head pose estimation. The merit of our method is manifested as compared to the state of the art feature tracking methods.	database;feature detection (computer vision);feature detection (web development);ground truth;hidden surface determination;image noise;kinect;machine learning;motion estimation;real-time clock;sensor;spontaneous order;statistical shape analysis	Shaun J. Canavan;Peng Liu;Xing Zhang;Lijun Yin	2015	Computer Vision and Image Understanding	10.1016/j.cviu.2015.06.006	active shape model;point distribution model;computer vision;pattern recognition;data mining	Vision	43.606930550708384	-52.54110759940223	17293
cf78e8b1713ee1711419d7adeb6b5919795cbcbd	a bayesian topological framework for the identification and reconstruction of subcellular motion		Microscopy imaging allows detailed observations of intracellular movements and the acquisition of large datasets that can be fully analyzed only by automated algorithms. Here, we develop a computational method for the automatic identification and reconstruction of trajectories followed by subcellular particles captured in microscopy image data. The method operates on stacks of raw image data and computes the complete set of contained trajectories. The method utilizes topological data analysis and standard image processing techniques and makes no assumptions about the underlying dynamics besides continuity. We test the developed method successfully against artificial and experimental datasets. Application of the method on the experimental data reveals good agreement with manual tracking and benchmarking yields performance scores competitive to the existing state-of-the-art tracking methods.	algorithm;automatic identification and data capture;image processing;raw image format;scott continuity;topological data analysis	Ioannis Sgouralis;Andreas Nebenführ;Vasileios Maroulas	2017	SIAM J. Imaging Sciences	10.1137/16M1095755	experimental data;mathematics;image processing;benchmarking;topological data analysis;computer vision;artificial intelligence;bayesian probability	Vision	40.68613547154883	-73.21760625478801	17312
c6c22f56a0fe5428b6b76c6f023727c7222af80c	improved extraction algorithm of outside dividing lines in watershed segmentation based on pso algorithm for froth image of coal flotation	threshold optimization;image segmentation;froth image in coal floatation;distance transform;particle swarm optimization algorithm;on class variance maximum otsu method	It is difficult to exact accurate bubble size and to make image recognition more reliable for forth image of coal floatation because of low contrast and blurry edges in froth image. An improved method of getting outside dividing lines in watershed segmentation was proposed. In binarization image processing, threshold was optimized applying particle swarm optimization algorithm(PSO)combining with 2-D maximum entropy based gray level co-occurrence matrix. After distance transform, outside dividing lines have been exacted by watershed segmentation. By comparison with Otsu method, the segmentation results have shown that the gotten external watershed markers are relatively accurate, reasonable. More importantly, under segmentation and over segmentation were avoided using the improved method. So it can be proved that extraction algorithm of outside dividing lines based on PSO is effective in image segmentation	algorithm;image segmentation;phase-shift oscillator;watershed (image processing)	Mu-ling Tian;Jie-ming Yang	2014	Journal of Multimedia	10.4304/jmm.9.2.325-332	computer vision;computer science;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;distance transform;scale-space segmentation	Vision	43.4660964366587	-68.4365048408973	17342
6f9299c5b75e9d5e4597f6c6ca704fc0a52bf219	hierarchical bayesian inference for the eeg inverse problem using realistic fe head models: depth localization and source separation for focal primary currents	hierarchical bayesian modeling;fully bayesian inference;eeg inverse problem;current density reconstruction;depth localization;wasserstein distance	The estimation of the activity-related ion currents by measuring the induced electromagnetic fields at the head surface is a challenging and severely ill-posed inverse problem. This is especially true in the recovery of brain networks involving deep-lying sources by means of EEG/MEG recordings which is still a challenging task for any inverse method. Recently, hierarchical Bayesian modeling (HBM) emerged as a unifying framework for current density reconstruction (CDR) approaches comprising most established methods as well as offering promising new methods. Our work examines the performance of fully-Bayesian inference methods for HBM for source configurations consisting of few, focal sources when used with realistic, high-resolution finite element (FE) head models. The main foci of interest are the correct depth localization, a well-known source of systematic error of many CDR methods, and the separation of single sources in multiple-source scenarios. Both aspects are very important in the analysis of neurophysiological data and in clinical applications. For these tasks, HBM provides a promising framework and is able to improve upon established CDR methods such as minimum norm estimation (MNE) or sLORETA in many aspects. For challenging multiple-source scenarios where the established methods show crucial errors, promising results are attained. Additionally, we introduce Wasserstein distances as performance measures for the validation of inverse methods in complex source scenarios.		Felix Lucka;Sampsa Pursiainen;Martin Burger;Carsten H. Wolters	2012	NeuroImage	10.1016/j.neuroimage.2012.04.017	econometrics;mathematical optimization;machine learning;mathematics;statistics	Comp.	49.78569065237435	-79.70402873440453	17346
f506abb215a049d741fa0664180e7e91aa8d675b	recognizing characters in scene images	adaptive thresholding;image segmentation;image processing;character pattern extraction;scene image;optical character recognition;seuillage adaptatif;procesamiento imagen;image scene;indexing terms;traitement image;relajacion;multisegment characters;reconnaissance caractere;relaxational approach;adaptative thresholding;image segmentation optical character recognition;segmentation image;pattern recognition;relaxation;character recognition image recognition layout image segmentation optical character recognition software laboratories pattern recognition humans manufacturing automation noise shaping;reconnaissance forme;scene images;relaxational approach character recognition scene images image segmentation adaptive thresholding multisegment characters;reconocimiento patron;character recognition;reconocimiento caracter;extraction forme caractere	An effective algorithm for character recognition in scene images is studied. Scene images are segmented into regions by an image segmentation method based on adaptive thresholding. Character candidate regions are detected by observing gray-level differences between adjacent regions. To ensure extraction of multisegment characters as well as single-segment characters, character pattern candidates are obtained by associating the detected regions according to their positions and gray levels. A character recognition process selects patterns with high similarities by calculating the similarities between character pattern candidates and the standard patterns in a dictionary and then comparing the similarities to the thresholds. A relaxational approach to determine character patterns updates the similarities by evaluating the interactions between categories of patterns, and finally character patterns and their recognition results are obtained. Highly promising experimental results have been obtained using the method on 100 images involving characters of different sizes and formats under uncontrolled lighting. >		Jun Ohya;Akio Shio;Shigeru Akamatsu	1994	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.273729	computer vision;speech recognition;index term;image processing;computer science;relaxation;pattern recognition;thresholding;image segmentation;optical character recognition	Vision	37.123130409879444	-64.62879769647351	17375
ba48aa6f770c617f77a4d2e284c2426ab5683629	the entering and exiting management system by person specification using deep-cnn		We developed a system to manage time when students stayed at a laboratory. In order to eliminate the cumbersome authentication operation at the time of entering and exiting a laboratory, the duration that students stayed is collected by facial detection, facial recognition using the Deep-CNN, and entering and exiting detection. We narrowed the range of the facial image, increased the speed of facial detection processing, and transformed geometrically to improve facial recognition accuracy. As a result, the success rate of the facial recognition of five target people was about 97%. Further, the entering and exiting detection rate was about 84% by insertion of an entering and exiting end and by scoring using the recognition result of images. Thus, we could confirm that our system is practical.	authentication;face detection;facial recognition system;management system	Hiroto Kizuna;Hiroyuki Sato	2017	2017 Fifth International Symposium on Computing and Networking (CANDAR)	10.1109/CANDAR.2017.40	face detection;support vector machine;feature extraction;management system;facial recognition system;computer vision;computer science;authentication;artificial intelligence	Mobile	30.48893759822287	-60.34379585675904	17402
7d794c823b7b7a1ca1ef4a3c1d6b9b7c772d9dde	a new definition of shape similarity	border;directional codes;least squares;shape;shape similarity;major axis;region;shape distance;reference points	Two reference points of a region are defined which do not depend on the position, size and orientation of the region. Reference points are used to get borders on the basis of which the shape distance and shape similarity are defined.	semantic similarity	Swapan K. Parui;D. Dutta Majumder	1982	Pattern Recognition Letters	10.1016/0167-8655(82)90049-6	active shape model;computer vision;region;topology;shape;shape analysis;mathematics;geometry;topological skeleton;least squares;semi-major axis;geometric shape	Vision	42.18468973728874	-59.03066246092267	17434
21192392ae88e9bc8093b05d9b44d18c6b5eb3cd	rs-mssf frame: remote sensing image classification based on extraction and fusion of multiple spectral-spatial features		Classifying remote sensing images with high spectral and spatial resolution became an important topic and challenging task in computer vision and remote sensing (RS) fields because of their huge dimensionality and computational complexity. Recently, many studies have already demonstrated the efficiency of employing spatial information where a combination of spectral and spatial information in a single classification framework have attracted special attention because of their capability to improve the classification accuracy. Shape and texture features are considered as two important types of spatial features in various applications of image processing. In this study, we extracted multiple features from spectral and spatial domains where we utilized texture and shape features, as well as spectral features, in order to obtain high classification accuracy. The spatial features considered in this study are produced by Gray Level Co-occurrence Matrix (GLCM) and Extended Multi-Attribute Profiles (EMAP), while, the extraction of deep spectral features is done by Stacked Sparse Autoencoders. The obtained spectral-spatial features are concatenated directly as a simple feature fusion and are fed into the Support Vector Machine (SVM) classifier. We tested the proposed method on hyperspectral (HS) and multispectral (MS) images where the experiments demonstrated significantly the efficiency of the proposed framework in comparison with some recent spectral-spatial classification methods and with different classification frameworks based on the used extractors.		Hanane Teffahi;Hongxun Yao	2018		10.1007/978-3-030-00767-6_54	support vector machine;computer vision;image processing;artificial intelligence;remote sensing;computer science;multispectral image;spatial analysis;contextual image classification;pattern recognition;hyperspectral imaging;curse of dimensionality;image resolution	Robotics	31.109610526045675	-55.397620421074556	17456
d5156d278063e5f8b3e79e85c0056b0cca644732	feature extraction from biological motion of human gait patterns for emotion discrimination	high dimensionality;independent component analysis;biological motion;feature extraction	We study a method of a feature extraction to discriminate emotions of human from a sensing data of human gait patterns as ”Biological motion data”. We assume that the high–dimensional biological motion data are generated by low–dimensional features whose components are statistically independent. So we use a method of independent component analysis to extract the features. The extracted feature is evaluated by a discriminated result of the given biological motion data which identified five types of categories, ”Anger”, ”Grief”, ”Disgust”, ”Joy” and ”Fear”. We achieve 40% accuracy for 5–classes of emotion discrimination with 3 actors’ biological motion data.	feature extraction;independent component analysis	Hidenori Maruta;Masahiro Ishii	2007			independent component analysis;computer vision;biological motion;feature extraction;computer science;machine learning;pattern recognition	Robotics	25.552298322076545	-63.87891749051604	17501
3990777bfc01ff364a096933f28a199748e2ce8b	a region-based retrieval system for heliophysics imagery		We introduce the creation of a new Content-Based Image Retrieval (CBIR) System for regions of interest (ROIs) in solar images. Regions are characterized by statistical features derived from general-purpose image parameters extracted in near real-time from the large-scale data stream of the Solar Dynamics Observatory (SDO) mission. This work formulates our region representation process, which includes contentbased feature extraction and the derivation of various metadata features for complementary spatiotemporal similarity search capabilities. Preliminary work uses a well-established dataset of labeled event regions for supervised evaluation through event classification and retrieval performance. Feature selection is performed to reduce overall dimensionality for more effective and efficient classification and retrieval. Results show promising CBIR capabilities for region-based querying (RBQ) demands over solar image repositories.	artificial neural network;baseline (configuration management);content-based image retrieval;deep learning;dimensionality reduction;feature extraction;feature selection;general-purpose modeling;neural coding;real-time clock;real-time computing;region of interest;scalability;similarity search;sparse matrix	Michael A. Schuh;Dustin Kempton;Rafal A. Angryk	2017			natural language processing;artificial intelligence;computer science;heliophysics	Vision	27.146102751528296	-54.55388926278697	17506
5221cfa3aa6f7827b01014be464ac69ff9e8d722	coronary cine-angiography segmentation incorporating low-rank priori	image segmentation;cine coronary angiography robust principal component analysis low rank alternating direction method image segmentation;medical image processing angiocardiography image segmentation image sequences;biomedical imaging;video sequence frame coronary cine angiography segmentation low rank priori;convex functions;principal component analysis;robustness;optimization;biomedical imaging robustness principal component analysis image segmentation optimization convex functions	In this paper, a new approach of segmenting cine coronary angiography is proposed. Rather than treating each frame of a video sequence individually and applying the segmentation on them separately, our approach tackles the segmentation of all the frames as a whole via incorporating the prior knowledge that the background components in all frames have much strong correlation mutually than vessels do, so our approach is global in the time dimension. We have applied this approach to the segmentation of clinical data and obtain encouraging result.	computed tomography angiography;intra-frame coding;sparse matrix	Xu Zhang;Jiasong Wu;Yang Chen;Guanyu Yang;Jean-Louis Coatrieux;Huazhong Shu	2014	2014 7th International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2014.7002764	convex function;medical imaging;image texture;computer vision;mathematical optimization;computer science;machine learning;segmentation-based object categorization;pattern recognition;mathematics;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation;robustness;principal component analysis	Vision	43.63244401440182	-75.28143349749934	17542
3fe09d5267cf3f3e2aea7cd54c32cdd87c014d99	face recognition using fisher linear discriminant analysis and support vector machine	fisher linear discriminant analysis;high dimensionality;linear discriminate analysis;face recognition;pattern classification;support vector machine	A new face recognition method is presented based on Fisher’s Linear Discriminant Analysis (FLDA) and Support Vector Machine (SVM). The FLDA projects the high dimensional image space into a relatively low-dimensional space to acquire most discriminant features among the different classes. Recently, SVM has been used as a new technique for pattern classification and recognition. We have used SVM as a classifier, which classifies the face images based on the extracted features. We have tested the potential of SVM on the ORL face database. The experimental results show that the proposed method provides higher recognition rates compared to some other existing methods.	facial recognition system;linear discriminant analysis;support vector machine	Sweta Thakur;Jamuna Kanta Sing;Dipak Kumar Basu;Mita Nasipuri	2009		10.1007/978-3-642-03547-0_30	facial recognition system;support vector machine;kernel fisher discriminant analysis;speech recognition;feature vector;computer science;machine learning;pattern recognition;optimal discriminant analysis;linear discriminant analysis;relevance vector machine;structured support vector machine;multiple discriminant analysis;fisher kernel	Vision	33.59669604389418	-58.38616142473302	17544
4e74fb5ab3f37ab1d124f523fcaad2b7f9e1b26f	location and recognition of legal amounts on chinese bank cheques	chinese character text;image recognition;image strings;image segmentation;alphanumeric bank cheques;optical character recognition;text analysis;image segmentation cheque processing optical character recognition artificial intelligence;satisfiability;law;cheque processing;optical character recognition software;legal factors;machine intelligence;law legal factors image segmentation image analysis character recognition pattern recognition machine intelligence optical character recognition software image recognition text analysis;legal amounts recognition;pattern recognition;image strings legal amounts recognition chinese bank cheques chinese cheque processing system alphanumeric bank cheques chinese character text;artificial intelligence;chinese cheque processing system;image analysis;character recognition;chinese bank cheques	This paper describes a Chinese cheque pmcedng system CUITenty under development at the Centre for Pattern Recognition and Machine Intelligence (CEN’PARh4.I). The infixmation on Chinese bank cheques is not the same as that on alphanumeric bank cheques. The legal amount in a Chinese bank cheque is the Chinese characta text associated with each currency unit, viz. (dollar), % (ten cents) and a (cent). Thispaperdiscussesatechniqueus~eachcurrencyunitasakeywordto locatelextnrd the legal amount in bank cheques. In the analysis and tecogDition process, the system tries to locate the smallest cunrenty units in the image and identifies it first. Th~the~trieStolocatethe~estriogSassociatedwitheach currency unit. Each image string is separatedand~Next ,asetofrufesand~~areappl iedtorecognizethe chatacterS. Inorder to choose the correct one, the mognbd charader string is acceptedonly ifit satisfies all the conditions governed by rules. K e y w o r d s : d o c r r m e n t u n ~ ’ cheque pmes iq , OCR, block location, segmentation	optical character recognition;pattern recognition;tree traversal;viz: the computer game	Chiu L. Yu;Ching Y. Suen;Yuan Yan Tang	1997		10.1109/ICDAR.1997.620570	computer vision;magnetic ink character recognition;image analysis;speech recognition;computer science;artificial intelligence;pattern recognition;image segmentation;optical character recognition;satisfiability	AI	34.19517208233128	-66.46591001629983	17546
2953e8f20b3cc22fba6cdd78f8974a8db47aa945	parallel recognition of idealised line characters	retina;conventional technique;idealise line;idealise character;closed line	The aim is to design a machine which is able to learn a number of idealised characters and to recognise them, irrespective of their size, position and context on an infinite retina. If the number of characters which such a machine can possibly learn to recognise is astronomical, it is not practical to use separate templates for every possible character. It is more economical to use, instead, templates for various parts, called features, of characters. In recognising a number of characters simultaneously, without scanning, the question arises of how to tell which feature belongs to which character of figure on the retina. In particular, if a given character is not present but all its features are included in nonsense figures simultaneously present on the retina then the machine must not indicate the presence of the given character. The technique which overcomes this difficulty employs overlapping features which must be mutually consistent for recognition. This consistency technique is assessed by comparison with a more conventional technique, and the work is restricted to closed line characters which are not subject to deformations or mutilations.	clinical use template;nonsense mutation;personality character;retina;significant figures	Julian R. Ullmann	1965	Kybernetik	10.1007/BF00306418	arithmetic;mathematics	Graphics	27.859052348251826	-70.17909987583387	17553
17fe6bb485a9188f597a735c2e154526f3041327	quality-based iris segmentation-level fusion	signal image and speech processing;systems and data security;security science and technology;iris biometrics;fusion;segmentation;endnotes;quality;pubications;communications engineering networks	Iris localisation and segmentation are challenging and critical tasks in iris biometric recognition. Especially in non-cooperative and less ideal environments, their impact on overall system performance has been identified as a major issue. In order to avoid a propagation of system errors along the processing chain, this paper investigates iris fusion at segmentation-level prior to feature extraction and presents a framework for this task. A novel intelligent reference method for iris segmentation-level fusion is presented, which uses a learning-based approach predicting ground truth segmentation performance from quality indicators and model-based fusion to create combined boundaries. The new technique is analysed with regard to its capability to combine segmentation results (pupillary and limbic boundaries) of multiple segmentation algorithms. Results are validated on pairwise combinations of four open source iris segmentation algorithms with regard to the public CASIA and IITD iris databases illustrating the high versatility of the proposed method.	algorithm;biometrics;database;feature extraction;ground truth;open-source software;software propagation	Peter Wild;Heinz Hofbauer;James M. Ferryman;Andreas Uhl	2016	EURASIP J. Information Security	10.1186/s13635-016-0048-x	computer vision;speech recognition;fusion;scale-space segmentation;segmentation;computer security	Vision	29.834500850564773	-62.06261021751325	17583
401f0162f90fff83dab2bfd58b9a499ddc0f3f27	signature recognition with a hybrid approach combining modular neural networks and fuzzy logic for response integration	image features;neural networks;fuzzy integral;fuzzy logic;hybrid approach;fuzzy inference system;pattern recognition;hough transform;modular architecture;modular neural network	This chapter describes a modular neural network (MNN) with fuzzy integration for the problem of signature recognition. Currently, biometric identification has gained a great deal of research interest within the pattern recognition community. For instance, many attempts have been made in order to automate the process of identifying a person’s handwritten signature; however this problem has proven to be a very difficult task. In this work, we propose a MNN that has three separate modules, each using different image features as input, these are: edges, wavelet coefficients, and the Hough transform matrix. Then, the outputs from each of these modules are combined using a Sugeno fuzzy integral and a fuzzy inference system. The experimental results obtained using a database of 30 individual’s shows that the modular architecture can achieve a very high 99.33% recognition accuracy with a test set of 150 images. Therefore, we conclude that the proposed architecture provides a suitable platform to build a signature recognition system. Furthermore we consider the verification of signatures as false acceptance, false rejection and error recognition of the MNN.	antivirus software;artificial neural network;biometrics;coefficient;fuzzy logic;hough transform;inference engine;modular neural network;neural networks;pattern recognition;rejection sampling;signature recognition;test set;transformation matrix;wavelet	Mónica Beltrán;Patricia Melin;Leonardo Trujillo	2009		10.1007/978-3-642-04514-1_10	fuzzy electronics;adaptive neuro fuzzy inference system;fuzzy classification;artificial intelligence;neuro-fuzzy;machine learning;pattern recognition;time delay neural network;fuzzy associative matrix;fuzzy control system;hybrid system	Vision	26.969376203206572	-62.98856169932245	17618
ed0c0d0130eed4e9d3f6d8c7e6b3a6145bb07623	a semi-automatic image analysis tool for biomarker detection in immunohistochemistry analysis	object detection biology computing image colour analysis molecular biophysics;biology computing;sirius red;color;image color analysis training biological tissues deconvolution immune system liver accuracy;dab;immunohistochemistry;stained color separation semi automatic image analysis tool biomarker detection immunohistochemistry analysis digitized tissue slide analysis pathologists computer assisted image analysis technology diagnosis accuracy stains detection stains separation color deconvolution;image colour analysis;molecular biophysics;biomarker;color immunohistochemistry biomarker dab sirius red;image analysis;object detection	Digitized tissue slide analysis allows the Pathologists to use computer assisted image analysis technology to reduce time cost and increase the accuracy of diagnosis. In this paper, we present an ease to use semi-automatic tool which can detect and separate stains in tissue samples correctly. This statistical model based tool has been applied to detecting different kinds of stains. Multiple evaluation processes are implemented to demonstrate the robustness, accuracy and usefulness of this tool. Experimental results show that the tool performs significantly better than established popular methods such as color deconvolution and CMYK in stained color separation.	color;deconvolution;design of the fat file system;discrepancy function;experiment;ground truth;image analysis;inter-process communication;pixel;semiconductor industry;sensor;statistical model;wysiwyg	Jie Shu;Guoping Qiu;Mohammad Ilyas	2013	2013 Seventh International Conference on Image and Graphics	10.1109/ICIG.2013.197	immunohistochemistry;computer vision;image analysis;computer science;biomarker;molecular biophysics	Robotics	38.55503393252836	-74.65151177897187	17622
7738d7ddcc8969f73d1c1b757294009dea8c5eb2	local voxelizer: a shape descriptor for surface registration	shape descriptor surface registration scan alignment 3d reconstruction	Surface registration brings multiple scans into a common coordinate system by aligning their overlapping components. This can be achieved by finding a few pairs of matched points on different scans using local shape descriptors and employing the matches to compute transformations to produce the alignment. By defining a unique local reference frame (LRF) and attaching an LRF to shape descriptors, the transformation can be computed using only one match based on aligning the LRFs. This paper proposes a local voxelizer descriptor, and the key ideas are to define a unique LRF using the support around a basis point, to perform voxelization for the local shape within a cubical volume aligned with the LRF, and to concatenate local features extracted from each voxel to construct the descriptor. An automatic rigid registration approach is given based on the local voxelizer and an expanding strategy that merges descriptor representations of aligned scans. Experiments show that our registration approach allows the acquisition of 3D models of various objects, and that the local voxelizer is robust to mesh noise and varying mesh resolution, in comparison to two state-of-the-art shape descriptors.	3d modeling;concatenation;iterative closest point;point cloud;reference frame (video);shape context;voxel	Peng Song	2015	Computational Visual Media	10.1007/s41095-015-0019-z	computer vision;computer science	Vision	42.2073573665316	-55.48110011381372	17644
7390d36b680d9080336faad67ca4be0a724f901f	a shape-guided deformable model with evolutionary algorithm initialization for 3d soft tissue segmentation	statistical shape model;posterior probability;shape similarity;soft tissue;evolutionary algorithm;local search;deformable model	We present a novel method for the segmentation of volumetric images, which is especially suitable for highly variable soft tissue structures. Core of the algorithm is a statistical shape model (SSM) of the structure of interest. A global search with an evolutionary algorithm is employed to detect suitable initial parameters for the model, which are subsequently optimized by a local search similar to the Active Shape mechanism. After that, a deformable mesh with the same topology as the SSM is used for the final segmentation: While external forces strive to maximize the posterior probability of the mesh given the local appearance around the boundary, internal forces governed by tension and rigidity terms keep the shape similar to the underlying SSM. To prevent outliers and increase robustness, we determine the applied external forces by an algorithm for optimal surface detection with smoothness constraints. The approach is evaluated on 54 CT images of the liver and reaches an average surface distance of 1.6 +/- 0.5 mm in comparison to manual reference segmentations.	anatomy, regional;ct scan;curve fitting;evolutionary algorithm;local search (optimization);muscle rigidity;physical object;statistical model;statistical shape analysis;tension;biologic segmentation;soft tissue	Tobias Heimann;Sascha Münzing;Hans-Peter Meinzer;Ivo Wolf	2007	Information processing in medical imaging : proceedings of the ... conference	10.1007/978-3-540-73273-0_1	active shape model;computer vision;mathematical optimization;computer science;local search;evolutionary algorithm;mathematics;posterior probability;soft tissue;statistics	Vision	42.07036308728233	-78.01346751841004	17658
0a2e7211cdbfe33c37de308e98902913bee7f9c4	retrieval of overlapping and touching objects using hidden markov models	object recognition;pattern clustering;unsupervised clustering;hidden markov model;invariance;rotation invariance;markov model;hidden markov models;polar subsampling overlapping objects retrieval touching objects retrieval hidden markov models content based retrieval image retrieval unsupervised clustering color space position space feature extraction;pattern matching hidden markov models image retrieval content based retrieval object recognition pattern clustering feature extraction invariance;pattern matching;feature extraction;hidden markov models image retrieval information retrieval image databases shape measurement mice feature extraction spatial databases sampling methods computer science;content based image retrieval;em algorithm;content based retrieval;k means clustering;image retrieval	In this paper a content-based image retrieval system for overlapping and touching objects based on hidden Markov models is introduced. In a first step unsupervised clustering in the color and position space is performed in order to separate the objects. The clusters are handed over to the feature extraction, which is basically a polar subsampling and finally rotation invariant Markov models are trained on those features. After presenting a query object, the HMMs which represent the individual clusters in the images are matched against the feature sequence calculated on the query image. Those database elements whose corresponding Markov models generated the highest similarity scores are retrieved. Three different clustering techniques, namely k-means clustering, LBG-algorithm and EM-algorithm are evaluated. Retrieval efficiencies up to 56.25% have been achieved on this challenging task.	chroma subsampling;cluster analysis;content-based image retrieval;expectation–maximization algorithm;feature extraction;hidden markov model;k-means clustering;linde–buzo–gray algorithm;location-based game;markov chain;position and momentum space	Stefan Müller;Frank Wallhoff;Gerhard Rigoll	2001		10.1109/ICIP.2001.958605	computer vision;expectation–maximization algorithm;feature extraction;computer science;invariant;cognitive neuroscience of visual object recognition;machine learning;pattern matching;pattern recognition;markov model;hidden markov model;k-means clustering	Vision	37.969152432456	-57.49197952089177	17664
c269acf0b5a46a7b354cc70e3cdb37b8ed943571	an unsupervised approach to determination of main subject regions in images with low depth of field	unsupervised learning;bivariate kurtosis;pattern clustering;image segmentation;low depth of field images unsupervised approach main subject region segmentation defocused background blurring level bivariate kurtosis dct blocks photographic image clustering method;blurring level;training;depth of field;defocused background;low depth of field images;discrete cosine transforms image segmentation distance measurement lenses clustering algorithms training classification algorithms;photographic image;distance measurement;statistical analysis;discrete cosine transforms;clustering method;classification algorithms;lenses;clustering algorithms;unsupervised learning discrete cosine transforms image segmentation pattern clustering statistical analysis;main subject region segmentation;unsupervised approach;dct blocks	In this paper, we propose an unsupervised approach to separate focused main subject regions from defocused background. This algorithm first computes the blurring level using the bivariate kurtosis of all 8 times 8 DCT blocks of a photographic image with low depth of field. Then these blocks are clustered to blurry regions and sharp regions. The sharp regions are considered the main subject regions. This is a fast unsupervised approach to detect the main subject regions in photographic images with low depth of field. Experimental results show that the presented method provides higher speed than the multiresolution wavelet-based segmentation method.	algorithm;bivariate data;coefficient;discrete cosine transform;k-means clustering;unsupervised learning;wavelet	Chi Zhang;Hongbin Zhang	2008	2008 IEEE 10th Workshop on Multimedia Signal Processing	10.1109/MMSP.2008.4665156	unsupervised learning;computer vision;computer science;machine learning;pattern recognition;depth of field;lens;mathematics;image segmentation;cluster analysis	Vision	44.896298097903376	-66.64009950077205	17729
2bcb1c752663fc9650d71c341aa1708c6642cc85	understanding affective content of music videos through learned representations	learning feature representations;affect analysis;support vector machine;convolutional neural network	In consideration of the ever-growing available multimedia data, annotating multimedia content automatically with feeling(s) expected to arise in users is a challenging problem. In order to solve this problem, the emerging research field of video affective analysis aims at exploiting human emotions. In this field where no dominant feature representation has emerged yet, choosing discriminative features for the effective representation of video segments is a key issue in designing video affective content analysis algorithms. Most existing affective content analysis methods either use low-level audio-visual features or generate hand-crafted higher level representations based on these low-level features. In this work, we propose to use deep learning methods, in particular convolutional neural networks (CNNs), in order to learn mid-level representations from automatically extracted low-level features. We exploit the audio and visual modality of videos by employing Mel-Frequency Cepstral Coefficients (MFCC) and color values in the RGB space in order to build higher level audio and visual representations. We use the learned representations for the affective classification of music video clips. We choose multi-class support vector machines (SVMs) for classifying video clips into four affective categories representing the four quadrants of the Valence-Arousal (VA) space. Results on a subset of the DEAP dataset (on 76 music video clips) show that a significant improvement is obtained when higher level representations are used instead of low-level features, for video affective content analysis.	algorithm;artificial neural network;bag-of-words model in computer vision;color;convolution;convolutional neural network;deep learning;generalized valence bond;high- and low-level;mel-frequency cepstrum;modality (human–computer interaction);optical flow;restricted boltzmann machine;semantic role labeling;support vector machine;video clip	Esra Acar;Frank Hopfgartner;Sahin Albayrak	2014		10.1007/978-3-319-04114-8_26	support vector machine;computer vision;computer science;machine learning;pattern recognition;multimedia;convolutional neural network	AI	26.33343281119224	-55.27551808083232	17750
d80519408e329d6e23f1a642e5362acbee7a9664	disguise detection and face recognition in visible and thermal spectrums	image matching;image classification;visual databases face recognition image classification image matching;face face recognition databases support vector machines training histograms biomedical imaging;face recognition;iiitd in and beyond visible spectrum disguise database disguise detection thermal spectrum visible spectrum face recognition face verification face obfuscation multispectrum face images anavrta local facial regions classification nonbiometric classes biometric patches facial feature extraction facial feature matching;visual databases	Face verification, though for humans seems to be an easy task, is a long-standing research area. With challenging covariates such as disguise or face obfuscation, automatically verifying the identity of a person is assumed to be very hard. This paper explores the feasibility of face verification under disguise variations using multi-spectrum (visible and thermal) face images. We propose a framework, termed as Aravrta1, which classifies the local facial regions of both visible and thermal face images into biometric (regions without disguise) and non-biometric (regions with disguise) classes. The biometric patches are then used for facial feature extraction and matching. The performance of the algorithm is evaluated on the IHTD In and Beyond Visible Spectrum Disguise database that is prepared by the authors and contains images pertaining to 75 subjects with different kinds of disguise variations. The experimental results suggest that the proposed framework improves the performance compared to existing algorithms, however there is a need for more research to address this important covariate.	algorithm;approximation algorithm;artifact (software development);authentication;belief propagation;biometrics;database;facial recognition system;feature extraction;local binary patterns;open research;patch (computing);sample rate conversion	Tejas I. Dhamecha;Aastha Nigam;Richa Singh;Mayank Vatsa	2013	2013 International Conference on Biometrics (ICB)	10.1109/ICB.2013.6613019	facial recognition system;computer vision;contextual image classification;face detection;speech recognition;computer science;pattern recognition;three-dimensional face recognition	Vision	33.10141535149824	-59.69426546686291	17884
6ea0d627d38c6f9482159e10c303fe58245f3fb8	automatic eye detection using intensity filtering and k-means clustering	mimica;filtering;evaluation performance;filtrage;analyse amas;medicion automatica;performance evaluation;image processing;accentuation image;illumination;algorithme k moyenne;gabor transform;eye detection;mimique;evaluacion prestacion;filtrado;procesamiento imagen;gabor transformation;automatic measurement;mesure automatique;qualite image;traitement image;image enhancement;cluster analysis;robustesse;image quality;signal classification;transformation gabor;classification signal;algoritmo k media;robustness;k means algorithm;analisis cluster;calidad imagen;neighborhood operator;facial expression;classification automatique;automatic classification;eclairement;clasificacion automatica;k means clustering;transformacion gabor;alumbrado;robustez	This paper proposes a novel eye detection method, which can locate the accurate positions of the eyes from frontal face images. The proposed method is robust to pose changes, different facial expressions and illumination variations. Initially, it utilizes image enhancement, Gabor transformation and cluster analysis to extract eye windows. It then localizes the pupil centers by applying two neighborhood operators within the eye windows. Experiments with the color FERET and the LFW (Labeled Face in the Wild) datasets (including a total of 3587 images) are used to evaluate this method. The experimental results demonstrate the consistent robustness and efficiency of the proposed method.	cluster analysis;k-means clustering	Zhiming Qian;Dan Xu	2010	Pattern Recognition Letters	10.1016/j.patrec.2010.05.012	computer vision;speech recognition;image processing;computer science;machine learning;k-means clustering	Vision	44.94324736091818	-60.67324414484218	17989
8e577569dac46d6fdacc722dd680d290a43ab385	segmentation of infant brain mr images based on adaptive shape prior and higher-order mgrf	shape recognition biomedical mri brain gaussian processes image segmentation markov processes neurophysiology paediatrics;brain modeling shape image segmentation three dimensional displays magnetic resonance imaging databases;infant brain mr image segmentation modified hausdorff distance dice coefficient infant 3d mr brain scans third order families mgrf spatial interaction model higher order markov gibbs random field spatial interaction model infant mris lcdg linear combination of discrete gaussians infant brain signals empirical grey level distribution spatial interaction features voxel wise image intensities higher order visual appearance characteristics coaligned training images 3d infant mr brain images brain structures higher order mgrf adaptive shape prior;infant brain segmentation adaptive shape higher order mgrf	This paper introduces a new framework for the segmentation of different brain structures from 3D infant MR brain images. The proposed segmentation framework is based on a shape prior built using a subset of co-aligned training images that is adapted during the segmentation process based on higher-order visual appearance characteristics of infant MRIs. These characteristics are described using voxel-wise image intensities and their spatial interaction features. In order to more accurately model the empirical grey level distribution of infant brain signals, a Linear Combination of Discrete Gaussians (LCDG) is used that has positive and negative components. Also to accurately account for the large inhomogeneity in infant MRIs, a higher-order Markov Gibbs Random Field (MGRF) spatial interaction model that integrates third- and fourth-order families with a traditional second-order model is proposed. The proposed approach was tested on 40 in-vivo infant 3D MR brain scans, having their ground truth created by an expert radiologist, using three metrics: the Dice coefficient, the 95-percentile modified Hausdorff distance, and the absolute brain volume difference. Experimental results promise an accurate segmentation of infant MR brain images compared to current open source segmentation tools.	grayscale;ground truth;hausdorff dimension;image segmentation;markov chain;markov random field;open-source software;radiology;sørensen–dice coefficient;video-in video-out;voxel	Marwa Ismail;Mahmoud Mostapha;Ahmed Soliman;Matthew Nitzken;Fahmi Khalifa;Ahmed Elnakib;Georgy L. Gimel'farb;Manuel Casanova;Ayman El-Baz	2015	2015 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2015.7351623	computer vision;machine learning	Vision	44.64419238335082	-78.00467717272083	18074
7f6eb2d0b959d03aeb66f0603c6500adbc09d4f6	the role of the complex extended textural microstructure co-occurrence matrix in the unsupervised detection of the hcc evolution phases, based on ultrasound images	hepatocellular carcinoma hcc;complex extended textural microstructure co occurrence matrix cetmcm;evolution phases;unsupervised classification;ultrasound images	The hepatocellular carcinoma (HCC) is a frequent malignant liver tumour and one of the main causes of death. Detecting the HCC evolution phases is an important issue, aiming the early diagnosis of this tumour and patient monitoring with maximum accuracy. Our objective is to discover the evolution stages of HCC, through unsupervised classification techniques, using advanced texture analysis methods. In this work, we assessed the role that the Haralick features derived from the Complex Extended Textural Microstructure Co-occurrence Matrices (CETMCM) have in the unsupervised detection of the HCC evolution stages. A textural model for these phases was also generated. The obtained results were validated by supervised classifiers, well known for their performance, such as the Multilayer Perceptron (MLP), Support Vector Machines (SVM), respectively decision trees and they were also compared with the previously obtained results in this domain. The final classification accuracy was about 90%.	co-occurrence matrix;data (computing);decision tree;document-term matrix;evolution;human-centered computing;local binary patterns;machine learning;multilayer perceptron;quad flat no-leads package;robert haralick;supervised learning;support vector machine;unsupervised learning	Delia Mitrea;Sergiu Nedevschi;Radu Badea	2016		10.5220/0005825506980705	computer vision;machine learning;pattern recognition	ML	33.83901686717574	-74.08471370668221	18097
0ddd206cd04ce351434e25dde747b3b318afe719	fast local binary pattern: application to document image retrieval		The volume of digitised documents is increasing every day. Thus, designing a fast document image retrieval method for the large volume of document images, especially when the document images are also large in size, is of high demand. As feature extraction is one of the important steps in every document image retrieval system, a feature extraction technique with a low computing time and small feature number has a direct effect on the speed of the retrieval system. In this paper, we propose a non-parametric texture feature extraction method based on summarising the local grey-level structure of the image. To extract the proposed features, the input image is, at first, divided into a set of overlapping patches of equal size. The peripheral pixels of the centre pixel in a patch are used to extract two sets of patterns. The patterns are derived from the vertical & horizontal, and diagonal & off-diagonal pixels of the patch, separately. From each set of pixels, 15 different local binary patterns are extracted in our proposed feature extraction method. Two histograms of the local binary patterns are then created and concatenated to obtain 30 features called fast local binary pattern (F-LBP). To evaluate the efficiency of the proposed feature extraction method, MTDB and ITESOFT databases were considered for experimentation. The proposed F-LBP provided promising results with lower computing time as well as smaller memory space consumption compared to other variation of LBP methods.	algorithm;binary pattern (image generation);concatenation;dspace;database;feature extraction;feature vector;image retrieval;level structure;local binary patterns;parallel computing;peripheral;pixel	Fahimeh Alaei;Alireza Alaei;Umapada Pal;Michael Blumenstein	2017	2017 International Conference on Image and Vision Computing New Zealand (IVCNZ)	10.1109/IVCNZ.2017.8402464	artificial intelligence;image retrieval;concatenation;pattern recognition;computer vision;computer science;pixel;diagonal;histogram;local binary patterns;feature extraction;memory management	Vision	36.559564569319654	-60.151330560891196	18108
f0a8241e2b9c2cabec6618289ffa6d3b0edd75dd	a novel model for multi-label image annotation		Multi-label image annotation is one of the most important open problems in machine learning and computer vision. In this paper, we propose a novel model for image annotation. Unlike existing works that usually use conventional visual features to annotate images, this paper adopts features based on convolutional neural network (CNN), which have shown potential to achieve outstanding performance. In particular, we use CNN to extract image features with higher semantic meaning and apply them to the image annotation method – Tag Propagation (TagProp). Experimental results on four challenging datasets indicate that our model makes a marked improvement as compared to the current state-of-the-art.	artificial neural network;automatic image annotation;biological neural networks;computer vision;convolutional neural network;machine learning;multi-label classification;software propagation;tag cloud	Xinjian Wu;Li Zhang;Fanzhang Li;Bangjun Wang	2018	2018 24th International Conference on Pattern Recognition (ICPR)	10.1109/ICPR.2018.8546110	automatic image annotation;feature (computer vision);computer vision;convolutional neural network;feature extraction;visualization;artificial intelligence;semantics;pattern recognition;statistical classification;computer science	Vision	26.891833807255075	-52.797302636172475	18162
2d83ab1404aad81bd7d3f7ef877e7ee95e9c14ed	stroke risk stratification and its validation using ultrasonic echolucent carotid wall plaque morphology: a machine learning paradigm	far;ultrasound;precision of merit;segmentation;roc;machine learning;carotid wall;stroke;near	Stroke risk stratification based on grayscale morphology of the ultrasound carotid wall has recently been shown to have a promise in classification of high risk versus low risk plaque or symptomatic versus asymptomatic plaques. In previous studies, this stratification has been mainly based on analysis of the far wall of the carotid artery. Due to the multifocal nature of atherosclerotic disease, the plaque growth is not restricted to the far wall alone. This paper presents a new approach for stroke risk assessment by integrating assessment of both the near and far walls of the carotid artery using grayscale morphology of the plaque. Further, this paper presents a scientific validation system for stroke risk assessment. Both these innovations have never been presented before. The methodology consists of an automated segmentation system of the near wall and far wall regions in grayscale carotid B-mode ultrasound scans. Sixteen grayscale texture features are computed, and fed into the machine learning system. The training system utilizes the lumen diameter to create ground truth labels for the stratification of stroke risk. The cross-validation procedure is adapted in order to obtain the machine learning testing classification accuracy through the use of three sets of partition protocols: (5, 10, and Jack Knife). The mean classification accuracy over all the sets of partition protocols for the automated system in the far and near walls is 95.08% and 93.47%, respectively. The corresponding accuracies for the manual system are 94.06% and 92.02%, respectively. The precision of merit of the automated machine learning system when compared against manual risk assessment system are 98.05% and 97.53% for the far and near walls, respectively. The ROC of the risk assessment system for the far and near walls is close to 1.0 demonstrating high accuracy.		Tadashi Araki;Pankaj K. Jain;Harman S. Suri;Narendra D. Londhe;Nobutaka Ikeda;Ayman El-Baz;Vimal K. Shrivastava;Luca Saba;Andrew Nicolaides;Shoaib Shafique;John R. Laird;Ajay Gupta;Jasjit S. Suri	2017	Computers in biology and medicine	10.1016/j.compbiomed.2016.11.011	radiology;stroke;pathology;machine learning;ultrasound;segmentation;genetics;surgery	AI	35.643510194370435	-77.82167712307758	18192
f9a10801db1148a4935688a93236bf208099887f	brain decoding for brain mapping: definition, heuristic quantification, and improvement of interpretability in group meg decoding		In the last century, a huge multi–disciplinary scientific endeavor is devoted to answer the historical questions in understanding the brain functions. Among the statistical methods used for this purpose, brain decoding provides a tool to predict the mental state of a human subject based on the recorded brain signal. Brain decoding is widely applied in the contexts of brain–computer interfacing, medical diagnosis, and multivariate hypothesis testing on neuroimaging data. In the latest case, linear classifiers are generally employed to discriminate between experimental conditions. Then, the derived weights are visualized in the form of brain maps to further study the spatio–temporal patterns of the underlying neurophysiological activity. It is well known that the brain maps derived from weights of linear classifiers are hard to interpret because of high correlations between predictors, low signal–to–noise ratio, across–subject variability, and the high dimensionality of the neuroimaging data. Therefore, improving the interpretability of brain decoding approaches is of primary interest in many neuroimaging studies. Despite extensive studies of this type, at present, there is no formal definition for interpretability of multivariate brain maps. As a consequence, there is no quantitative measure for evaluating the interpretability of different brain decoding methods. In this thesis, as the primary contribution, we propose a theoretical definition of interpretability in linear brain decoding; we show that the interpretability of multivariate brain maps can be decomposed into their reproducibility and representativeness. As an application of the proposed definition, we exemplify a heuristic for approximating the interpretability in multivariate analysis of evoked magnetoencephalography (MEG) responses. We propose to combine the approximated interpretability and the generalization performance of the model into a new multi–objective criterion for model selection. Our results, for the simulated and real MEG data, show that optimizing the hyper–parameters of the regularized linear classifier based on the proposed criterion results in more informative multivariate brain maps. More importantly, the presented definition provides the theoretical background for quantitative evaluation of interpretability, and hence, facilitates the development of more effective brain decoding algorithms in the future. As the secondary contribution, we present an application of multi–task joint feature learning for group–level multivariate pattern recovery in single–trial MEG decoding. The proposed method allows for recovering sparse yet consistent patterns across different subjects, and therefore enhances the interpretability of the decoding model. We evaluated the performance of the multi–task joint feature learning in terms of generalization, reproducibility, and quality of pattern recovery against traditional single–subject and pooling approaches on both simulated and real MEG datasets. Our experimental results demonstrate that the multi–task joint feature learning framework is capable of recovering meaningful patterns of varying spatio–temporally distributed brain activity across individuals while still maintaining excellent generalization performance. The presented methodology facilitates the application of brain decoding for characterizing the fine–level distinctive patterns of brain activity in group–level inference on neuroimaging data.	approximation algorithm;brain mapping;decoding methods;electroencephalography;exemplification;feature learning;heuristic;information;linear classifier;magnetoencephalography;map;mental state;model selection;sparse matrix;spatial variability;theoretical definition	Seyed Mostafa Kia	2017			magnetoencephalography;model selection;multivariate analysis;artificial intelligence;machine learning;multivariate statistics;interpretability;linear classifier;feature learning;computer science;brain mapping	ML	24.81813652361786	-77.35350102306147	18215
d650af9cd707637de3b1fb47b9b299d1502a7234	un panorama des techniques de suivi visuel temps réel pour la réalité augmentée	interfase usuario;vision ordenador;pistage;realite virtuelle;realidad virtual;user interface;real time;localization;rastreo;virtual reality;localizacion;computer vision;realite augmentee;realidad aumentada;localisation;temps reel;poursuite cible;3d tracking;tiempo real;interface utilisateur;vision ordinateur;3d vision;augmented reality;target tracking;real time application;2d tracking;tracking	Augmented Reality has now progressed to the point where real -time applications are being considered and needed. At the same time it is import ant that synthetic elements are rendered and aligned in the scene in an accurate and visually acceptable way. In order to address these issues, a real-time, robust and efficient trac king algorithm have to be considered. The tracking of objects in the scene amounts to calculating t he location (or pose) between the camera and the scene. MOTS-CLÉS :Réalité augmentée, suivi 2D, suivi 3D, vision par ordinateu r	algorithm;augmented reality;linear algebra;real-time clock;synthetic data;trac	Éric Marchand;Muriel Pressigout	2009	Technique et Science Informatiques	10.3166/tsi.28.921-943	augmented reality;simulation;internationalization and localization;computer science;operating system;virtual reality;tracking;user interface;computer graphics (images)	Vision	49.065408283643364	-56.505739484816814	18220
e5057ef168bde0d98bd5ab455a86d8657f00ed3b	a novel method in extracranial removal of brain mr images	issn 1877 0509;0801 artificial intelligence and image processing;magnetic resonance image;college of science and engineering;medical image processing;0802 computation theory and mathematics;contour generator;morphological algorithm;gvf snake model	O This paper proposes an automatic morphologybased algorithm to generate the initial contour for active contour model to implement the removal. O Experimental result shows that with simple steps and little time, the proposed algorithm can finish the segmentation task successfully, and is of good robustness as well as high accuracy.	active contour model;algorithm;contour line	Jiahua Du;Gansen Zhao;Hao Lan Zhang;Jing He;Xiaoli Jin	2014		10.1016/j.procs.2014.05.372	computer vision;simulation;computer science;artificial intelligence;magnetic resonance imaging;machine learning;data mining	Robotics	41.31699650495738	-76.11998562730105	18236
32739092345eba41bfa95c5a69517ac997730cba	on non-linear characterization of tissue abnormality by constructing disease manifolds	protocols;biological tissues;brain;treatment effect;disease progression;manifolds;support vector machines;tissue deterioration;training;support vector machines biological tissues biomedical measurement biomedical mri brain diseases learning artificial intelligence magnetic resonance spectroscopy medical image processing;magnetic resonance spectroscopy;semisupervised method;disease treatment;multiparametric magnetic resonance feature;spectrum;lesions;magnetic resonance;medical image processing;tumors;diseases;diseases lesions manifolds support vector machines multiple sclerosis magnetic resonance pathology protocols support vector machine classification biomedical imaging;support vector machine;learning artificial intelligence;multiple sclerosis;biomedical measurement;sclerosis patient;sclerosis patient tissue deterioration tissue abnormality disease progression disease treatment semisupervised method multiparametric magnetic resonance feature support vector machine nonlinear manifold brain;nonlinear manifold;tissue abnormality;biomedical mri	Tissue deterioration as induced by disease can be viewed as a continuous change of tissue from healthy to diseased and hence can be modeled as a non-linear manifold with completely healthy tissue at one end of the spectrum and fully abnormal tissue such as lesions, being on the other end. The ability to quantify this tissue deterioration as a continuous score of tissue abnormality will help determine the degree of disease progression and treatment effects. We propose a semi-supervised method for determining such an abnormality manifold, using multi-parametric magnetic resonance features incorporated into a support vector machine framework in combination with manifold regularization. The position of a tissue voxel on this spatially and temporally smooth manifold, determines its degree of abnormality. We apply the framework towards the characterization of tissue abnormality in brains of multiple sclerosis patients followed longitudinally, to obtain a voxel-wise score of abnormality called the tissue abnormality map, thereby obtaining a voxel-wise measure of disease progression.	color gradient;manifold regularization;matrix regularization;nonlinear system;resonance;semi-supervised learning;semiconductor industry;support vector machine;voxel	Nematollah Batmanghelich;Ragini Verma	2008	2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2008.4563027	nuclear magnetic resonance spectroscopy;support vector machine;computer science;magnetic resonance imaging;machine learning	Vision	26.974043508863414	-78.21486370385452	18238
dfe592b2853a8ab6fe9dca9f7b9f9318ba082a72	fuzzy 2d-lda face recognition based on sub-image		This paper proposes a novel method for face recognition, called, sub-image-based fuzzy 2D Linear Discriminant Analysis (subimage-F2DLDA) based on sub-image method, 2-Dimensional Linear Discriminant Analysis (2D-LDA) and fuzzy set theory. We first partition the whole training image set into several different sub-image sets by dividing each image into sub-images and collecting the same location together, and then redefine the within-class matrix and between-class matrix for each sub-image set, which can be computed by incorporating the membership degree matrix using fuzzy k-nearest neighbor(FKNN). Finally, we construct a nearest classifier based on fuzzy 2DLDA for each sub-image set. We construct experiments on Yale A, Extended Yale B and ORL face databases, and the results show that the proposed approach achieves better performance than compared methods on face recognition.	facial recognition system	Xingrui Zhang;Yulian Zhu;Xiaohong Chen	2017		10.1007/978-3-319-68935-7_36	artificial intelligence;computer science;machine learning;fuzzy logic;pattern recognition;partition (number theory);facial recognition system;fuzzy set;matrix (mathematics);division (mathematics);linear discriminant analysis;degree matrix	Vision	34.38303268066489	-58.79297442308788	18256
94b9c96c7933f5e7104af74f81642f1beb9c5842	adaptive selection of non-target cluster centers for k-means tracker	pattern clustering;target tracking object detection pattern classification pattern clustering;color;pixel classification;k means;distance measurement;object tracking k means tracker adaptive non target cluster center selection method pixel classification;image color analysis;pixel;object tracking;pattern classification;robustness;search problems;target tracking;processing speed;fixed interval;object detection;target tracking sampling methods clustering algorithms robustness layout computer vision shape apertures color	Hua et al. have proposed a stable and efficient tracking algorithm called ldquoK-means trackerrdquo[2, 3, 5]. This paper describes an adaptive non-target cluster center selection method that replaces the one used in k-means tracker where non-target cluster center are selected at fixed interval. Non-target cluster centers are selected from the ellipse that defines the area for searching the target object in K-means tracker by checking whether they have significant effects for the pixel classification and are dissimilar to any of the already-selected non-target cluster centers. This ensures that all important non-target cluster centers will be picked up while avoiding selecting redundant non-target clusters. Through comparative experiments of object tracking, we confirmed that both the robustness and the processing speed could be improved with our method.	algorithm;cluster analysis;experiment;k-means clustering;pixel	Hiroshi Oike;Haiyuan Wu;Toshikazu Wada	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761323	computer vision;computer science;machine learning;video tracking;pattern recognition;mathematics;pixel;robustness;k-means clustering	Robotics	41.1747875925174	-54.59444386729966	18302
2f356425c0d5cdcd2c455dff7d33adb53e119e46	motion image segmentation using global criteria and dp	dynamic programming;weightlifting motion data motion image segmentation global criteria motion sequence temporal constraints dynamic programming;image motion analysis;image segmentation;probability density function;image segmentation humans motion analysis computer vision video sequences image recognition image motion analysis layout hidden markov models dynamic programming;image sequences dynamic programming image motion analysis image segmentation;linear approximation;dynamic program;data mining;transient analysis;motion sequence;temporal constraints;motion segmentation;feature extraction;motion image segmentation;weightlifting motion data;image sequences;global criteria	We propose methods for segmenting a motion sequence into motion primitives, taking into account temporal constraints (continuity along the time axis). In the proposed methods, dynamic programming (DP) is used on a motion feature sequence to allow for the effects of these constraints on the results of the segmentation. The methods do not require such a running window along the time axis, as is typical for the usual methods, and thus they can be applied to the segmentation of transient motions. The results of comparative experiments using several motion features and segmentation methods on weightlifting motion data demonstrate the effectiveness of the proposed methods.	apache axis;dynamic programming;experiment;image segmentation;scott continuity	Takumi Kobayashi;Fumito Yoshikawa;Nobuyuki Otsu	2008	2008 8th IEEE International Conference on Automatic Face & Gesture Recognition	10.1109/AFGR.2008.4813437	computer vision;mathematical optimization;quarter-pixel motion;pattern recognition;motion estimation;mathematics;motion field;scale-space segmentation	Robotics	48.564982159924696	-53.32162704823167	18361
68c5c3a220cf99d6d95793ed9fddac40e170369c	signal plus noise models in shape classification	vision ordenador;classification;form classification;computer vision;shape classification;robustesse;robustness;vision ordinateur;clasificacion;robustez;classification forme	-In this study we show how a signal plus noise formulation can be used to improve the performance of auto-regressive shape classifiers in environments with time varying noise characteristics. Variations of this type may be due to changes in atmospheric conditions or the relative effect of discretization errors. This approach is compared to existing methodologies using a number of noisy templates in a cluttered environment. Typical applications are to aircraft identification and automatic signature validation. Shape Classification Signal plus noise Auto-regressive process Robustness	autoregressive model;discretization	Richard H. Glendinning	1994	Pattern Recognition	10.1016/0031-3203(94)90162-7	computer vision;biological classification;computer science;machine learning;pattern recognition;mathematics;robustness	Vision	46.77821401441647	-59.53402058552888	18371
8ffee10729edc2b589491ae797802bf193b5b3d1	noise reduction in small-animal pet images using a multiresolution transform		In this paper, we address the problem of denoising reconstructed small animal positron emission tomography (PET) images, based on a multiresolution approach which can be implemented with any transform such as contourlet, shearlet, curvelet, and wavelet. The PET images are analyzed and processed in the transform domain by modeling each subband as a set of different regions separated by boundaries. Homogeneous and heterogeneous regions are considered. Each region is independently processed using different filters: a linear estimator for homogeneous regions and a surface polynomial estimator for the heterogeneous region. The boundaries between the different regions are estimated using a modified edge focusing filter. The proposed approach was validated by a series of experiments. Our method achieved an overall reduction of up to 26% in the %STD of the reconstructed image of a small animal NEMA phantom. Additionally, a test on a simulated lesion showed that our method yields better contrast preservation than other state-of-the art techniques used for noise reduction. Thus, the proposed method provides a significant reduction of noise while at the same time preserving contrast and important structures such as lesions.	adaptive histogram equalization;algorithm;ct scan;contourlet;curvelet;experiment;fast fourier transform;genetic heterogeneity;image noise;image registration;multiresolution analysis;nema (machine);noise reduction;organ;pattern recognition;phantom reference;phantoms, imaging;polyethylene terephthalate;polynomial;positron-emission tomography;positrons;preprocessor;preservation technique;radioactivity;std bus;sample variance;shearlet;smoothing (statistical technique);tomography, emission-computed, single-photon;wavelet	Jose Manuel Mejía Muñoz;Humberto de Jesús Ochoa Domínguez;Osslan Osiris Vergara-Villegas;Leticia Ortega Maynez;Boris Mederos	2014	IEEE Transactions on Medical Imaging	10.1109/TMI.2014.2329702	computer vision;artificial intelligence;noise reduction;mathematics	Vision	50.132417715101624	-77.62236138442826	18405
4340f1067c0cc11f3efee75e001a31502d9fe4f2	probabilistic odf estimation from reduced hardi data with sparse regularization	probabilistic orientation distribution;fast computation;real hardi data;data measurement;high angular resolution diffusion;probabilistic odf;probabilistic odf estimation;reduced hardi data;diffusion tensor imaging;sparse regularization;inverse problem;spherical wavelets;higher amount	High Angular Resolution Diffusion Imaging (HARDI) demands a higher amount of data measurements compared to Diffusion Tensor Imaging (DTI), restricting its use in practice. We propose to represent the probabilistic Orientation Distribution Function (ODF) in the frame of Spherical Wavelets (SW), where it is highly sparse. From a reduced subset of measurements (nearly four times less than the standard for HARDI), we pose the estimation as an inverse problem with sparsity regularization. This allows the fast computation of a positive, unit-mass, probabilistic ODF from 14-16 samples, as we show with both synthetic diffusion signals and real HARDI data with typical parameters.	computation;diffusion tensor imaging;echo-planar imaging;legendre wavelet;matrix regularization;rice tungro spherical virus;sparse matrix;subgroup;synthetic data	Antonio Tristán-Vega;Carl-Fredrik Westin	2011	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-23629-7_23	computer vision;mathematical optimization;pattern recognition;mathematics	Vision	49.6889481375448	-79.40219548529419	18419
eef7d879f6c6cbe5fa39667e1f8ec2e9dc0b4327	surface orientation driven 3d rigid registration method	stereographic projection rigid registration gauss map surface orientation;lungs;training;computational geometry;biomedical imaging;medical imaging surface orientation driven 3d rigid registration method surface based method rotation transformation sum of the squares minimization spatial modality elimination gauss map surface curvature distribution measurement gauss sphere stereographic projection spherical statistics bifacial plane iterated algorithm lung triangular surface registration block statistic medical images registration technology;lung;iterative methods;surface treatment;shape;medical image processing;image registration;stereo image processing;shape face biomedical imaging surface treatment lungs training robustness;stereographic projection;robustness;face;stereo image processing computational geometry image registration iterative methods lung medical image processing;rigid registration;surface orientation;gauss map	In this paper, we propose a new surface-based method to solve the rotation transformation of 3D rigid registration. Different from the criterion that minimize the sum of the squares of the errors between the corresponding parts of objects, here we estimate the spatial modalities of objects by their orientations. In details, Gauss map of surface is introduced to measure the distribution of surface curvature. To depict the characters of surface, we add sign weights to Gauss sphere according to the local total curvature. The stereographic projection is utilized to transform the spherical statistics to bifacial plane. As well, an optimization solution is done by iterated algorithm. We applied our proposed method on lung triangular surface registration. The experiments were completed by mutual information of block statistic.	algorithm;experiment;iteration;iterative closest point;mathematical optimization;mutual information;robustness (computer science);sampling (signal processing);stereoscopy	Guangxu Li;Hyoungseop Kim;Joo Kooi Tan;Seiji Ishikawa	2012	2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/ICSMC.2012.6377933	face;computer vision;topology;stereographic projection;computational geometry;shape;image registration;mathematics;geometry;iterative method;robustness	Robotics	45.934637050842795	-75.96979033194322	18421
b574c507d500609f24d7dd791988a358bf141441	offline handwritten arabic cursive text recognition using hidden markov models and re-ranking	traitement signal;handwriting recognition;learning;caracter manuscrito;mirror image;hidden markov model;manuscript character;modele markov variable cachee;off line;database;base dato;probabilistic approach;similitude;off line arabic handwritten recognition;algorithme;aprendizaje;algorithm;accuracy;apprentissage;reconnaissance ecriture;precision;reconnaissance caractere;hidden markov models;arabic;machine learning;enfoque probabilista;approche probabiliste;feature extraction;signal processing;signal classification;similarity;base de donnees;pattern recognition;classification signal;arabe;reconnaissance forme;image en miroir;similitud;extraction caracteristique;classification automatique;reconocimiento patron;electronic computers computer science;fuera linea;automatic classification;imagen en espejo;procesamiento senal;caractere manuscrit;clasificacion automatica;character recognition;re ranking;hidden markov models hmm;handwritten character recognition;reconocimiento caracter;reconnaissance caractere manuscrit;electrical engineering electronics nuclear engineering;hors ligne;algoritmo	a Faculty of Science and Information Technology, Al-Zaytoona University of Jordan, Amman, Jordan b School of Informatics, University of Bradford, Bradford BD7 1DP, United Kingdom c Information & Computer Science Department, King Fahd University of Petroleum & Minerals, Dhahran 31261, Saudi Arabia d Centre for excellence in Signal and Image Processing, Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, G1 1XW, United Kingdom	baseline (configuration management);computer science;dynamic bayesian network;electrical engineering;ground truth;hidden markov model;image processing;informatics;international conference on document analysis and recognition;markov chain;online and offline;optical character recognition;pattern recognition;substring	Jawad Hasan Yasin AlKhateeb;Jinchang Ren;Jianmin Jiang;Husni Al-Muhtaseb	2011	Pattern Recognition Letters	10.1016/j.patrec.2011.02.006	speech recognition;computer science;artificial intelligence;machine learning;pattern recognition;accuracy and precision;hidden markov model	NLP	29.387301434170205	-66.14839767551527	18438
f08eac341b058164cc427756fad129d82209edc8	performance evaluation of neural networks for shape identification in image processing	object recognition;performance evaluation;image processing;neural nets;gray level performance evaluation shape identification image processing artificial neural networks shape recognition image text analysis geometrical shapes;training;shape recognition;fuzzy logic;error analysis;artificial neural networks;shape;image text analysis;genetic algorithm;nns;neurons;gray level;neural networks shape image processing artificial neural networks image recognition image analysis fuzzy logic genetic algorithms analytical models predictive models;geometrical shapes;shape identification;algorithm design and analysis;biological neural networks;artificial neural network;neural network;shape recognition nns artificial neural network;performance evaluation image processing neural nets object recognition	The emergence of artificial neural networks in image processing has led to improvements in shape recognition. We can analyze text and various geometrical shapes in image where image is represented in gray level. We trained the neural network to identify a particular shape in image. Recently Artificial Neural Network (ANN), Fuzzy Logic and Genetic Algorithm have been employed to assist the diagnosis task and to interpret the shape recognition. The first goal of this paper is to apply neural network. The second goal of this paper is to utilize neural network approaches to and compare various algorithms. We have used a NN to identify the Shape Recognition in Image Processing. This paper presents the simulation results in analyzing the shape and comparison of various algorithms in predicting the shape and its error performance are reviewed.	emergence;fuzzy logic;genetic algorithm;grayscale;image processing;neural networks;performance evaluation;simulation	G. K. Rajini;G. Ramachandra Reddy	2010	2010 International Conference on Signal Acquisition and Processing	10.1109/ICSAP.2010.64	neural gas;fuzzy logic;algorithm design;computer vision;cellular neural network;genetic algorithm;shape;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;time delay neural network;artificial neural network	Robotics	30.586703279424476	-65.89145341291244	18464
74087a27b8647a611df6bec83e2c5238e1bbc2bb	an elasticity-based region model and its application to the estimation of the heart deformation in tagged mri	mr images elasticity based region model heart deformation tagged mri deformable model textured object image sequence tracking edge intensity elastic region snake like rigidity constraints boundaries displacement estimation finite element method heart contraction tagged magnetic resonance imaging contour tracking;edge detection;cardiology;biomechanics;motion estimation;finite element method;magnetic resonance image;mr imaging;finite element analysis medical image processing biomedical mri image sequences motion estimation biomechanics cardiology edge detection;medical image processing;image sequence;deformable models heart magnetic resonance imaging state estimation myocardium electronic mail image sequences data mining intersymbol interference image processing;finite element analysis;deformable model;biomedical mri;image sequences	We propose a novel deformable model to assess the deformation of a textured object in an image sequence by simultaneously tracking edge and intensity information. The proposed model is defined as an elastic region with snake-like rigidity constraints at its boundaries. By regularizing the displacement estimation with an elasticity-based constraint, this model is able to assess physically realistic deformations inside a region. By incorporating rigidity constraint at its boundaries, it can also accurately track edges. The numerical implementation of the model is performed using the finite element method. The good behavior of the proposed model is illustrated on synthetic images which simulates the heart contraction in tagged magnetic resonance imaging (MRI). The contour tracking abilities of the model are also illustrated on standard MR images.	elasticity (data store)	Fabrice Vincent;Patrick Clarysse;Pierre Croisille;Isabelle E. Magnin	2000		10.1109/ICIP.2000.901037	computer vision;simulation;computer science;biomechanics;finite element method;computer graphics (images)	Vision	46.11906846228894	-73.9431451562649	18478
ab68837d09986c592dcab7d08ee6dfb40e02916f	enhanced face preprocessing and feature extraction methods robust to illumination variation		This paper presents an enhanced facial preprocessing and feature extraction technique for an illumination-roust face recognition system. Overall, the proposed face recognition system consists of a novel preprocessing descriptor, a differential two-dimensional principal component analysis technique, and a fusion module as sequential steps. In particular, the proposed system additionally introduces an enhanced center-symmetric local binary pattern as preprocessing descriptor to achieve performance improvement. To verify the proposed system, performance evaluation was carried out using various binary pattern descriptors and recognition algorithms on the extended Yale B database. As a result, the proposed system showed the best recognition accuracy of 99.03% compared to other approaches, and we confirmed that the proposed approach is effective for consumer applications.	algorithm;amiga enhanced chip set;binary pattern (image generation);facial recognition system;feature extraction;illumination (image);local binary patterns;performance evaluation;preprocessor;principal component analysis	Dong-Ju Kim;Myoung-Kyu Sohn;Hyunduk Kim;Nuri Ryu	2014		10.1007/978-3-319-11289-3_23	computer vision;pattern recognition	Vision	33.29379380177981	-59.04894845364653	18545
2cfb0894bf804182c571a82bdf61f95ce0ac3fa6	on the use of gradient space eigenvalues for rotation invariant texture classification	eigenvalues and eigenfunctions;eigenvalues and eigenfunctions surface texture testing cameras photometry filtering frequency domain analysis geometry image texture lighting;texture classification;eigenvalues and eigenfunctions image texture image classification;standard deviation;image classification;image texture gradient space eigenvalues image rotation invariant texture classification surface rotation isotropic feature grey level images photometric stereo;eigenvalues;image texture;rotation invariance;photometric stereo	Many image-rotation invariant texture classification approaches have been presented previously. This paper proposes a novel scheme that is surface-rotation invariant. It uses the eigenvalues of a surface’s gradient-space distribution as its features. Unlike the partial derivatives, from which they are computed, these eigenvalue features are invariant to surface rotation. First we show that a simple classifier using a single isotropic feature (grey-level standard deviation) is not invariant to surface rotation. Then a practical surface rotation invariant classifier that uses photometric stereo to estimate surface derivatives is developed. Results for both classifiers are presented.	gradient;photometric stereo;statistical classification	Mike J. Chantler;Ged McGunnigle	2000		10.1109/ICPR.2000.903697	image texture;computer vision;contextual image classification;topology;photometric stereo;eigenvalues and eigenvectors;computer science;mathematics;geometry;standard deviation;texture filtering	Vision	40.97207290729586	-60.91713862474395	18554
0b92f95c8a81217d73b032a56abd747049bd6df9	why are images smooth?	natural image statistics;local repetition lemma	It is a well observed phenomenon that natural images are smooth, in the sense that nearby pixels tend to have similar values. We describe a mathematical model of images that makes no assumptions on the nature of the environment that images depict. It only assumes that images can be taken at different scales (zoom levels). We provide quantitative bounds on the smoothness of a typical image in our model, as a function of the number of available scales. These bounds can serve as a baseline against which to compare the observed smoothness of natural images.	baseline (configuration management);mathematical model;pixel	Uriel Feige	2015		10.1145/2688073.2688075	computer vision;computer science;mathematics;geometry	ML	52.70097581132258	-54.48964906342767	18572
06f222b86fd827779440717a47c1f3103d2c09f1	a knowledge based boundary delineation from left ventriculograms		Automated left ventricle ( L V ) boundary delineation f r o m contrast ventriculograms has been studied for decades. Unfortunately , n o accurate methods have ever been reported. A n e w knowledge based multi-stage method t o automatically delineate the L V boundary a t end diastole and end systole i s discussed in this paper. I t has a m e a n absolute boundary error of about Z m m and a n associated ejection fraction error of about 6%. T h e method makes extensive use o f knowledge about L V shape and m o v e m e n t . T h e processing includes a mul t i image pixel region classification, a shape regress ion and a rejection classification. T h e method was trained and tested o n a database of 375 studies whose ED and ES boundary have been manual ly traced as t h e ground truth . T h e cross-validated results presented in this paper shows that the accuracy i s close t o and slightly above interobserver variability.	clinical decision support system;ground truth;heart rate variability;inter-rater reliability;logical volume management;pixel;rejection sampling;shape analysis (digital geometry);spatial variability;statistical classification	Lei Sui;Florence H. Sheehan;Robert M. Haralick	2000			pixel;computer vision;end diastole;cross-validation;ground truth;ejection fraction;ventricle;mathematics;end systole;pattern recognition;artificial intelligence	Vision	32.766109621274964	-78.59733063001275	18595
72a91266d5e67ece26cd7e3035853b70f71134d3	application of laplacian mixture model to image and video retrieval	database indexing;busqueda informacion;transformation ondelette;tiempo respuesta;modelizacion;utilisation information;analisis contenido;reponse temporelle;video databases;evaluation performance;uso informacion;multimedia;modeling scheme;performance evaluation;image processing;image databases;video indexing and retrieval feature extraction image indexing and retrieval laplacian mixture model;information use;recherche image;information retrieval;information visuelle;evaluacion prestacion;texture image;extraction forme;laplacian;procesamiento imagen;laplacian mixture model nonlinear approach audio information image retrieval texture information video databases modeling scheme wavelet coefficient distributions image video retrieval;user feedback;video retrieval;response time;image indexing;indexing and retrieval;data mining;traitement image;wavelet transforms database indexing image retrieval laplace transforms;similitude;image texture;laplacian mixture model;temps reponse;modelisation;wavelet transforms;feature vector;laplace equations image retrieval information retrieval wavelet coefficients indexing feature extraction image databases visual databases wavelet transforms data mining;video indexing;wavelet coefficient distributions;laplacien;laplace equations;content analysis;informacion visual;laplaciano;wavelet transform;senal video;signal video;extraccion forma;indexing;time response;mixture model;laplace transforms;recherche information;visual information;feature extraction;indexation;comportement utilisateur;nonlinear approach;similarity;video indexing and retrieval;indizacion;audio information;pattern recognition;video signal;teoria mezcla;texture information;user behavior;transformacion ondita;reconnaissance forme;experimental evaluation;similitud;extraction caracteristique;analyse contenu;reconocimiento patron;image video retrieval;respuesta temporal;video database;mixture theory;modeling;theorie melange;pattern extraction;wavelet coefficients	In this paper, we study the peaky nature of wavelet coefficient distributions. The study shows that the wavelet coefficients cannot be effectively modeled by a single distribution. We then propose a new modeling scheme based on a Laplacian mixture model and apply it to the indexing and retrieval of image and video databases. In this work, the parameters of the model are first used to represent texture information in image retrieval. Then we explore its application to video retrieval. Traditionally, visual information is used for video indexing and retrieval. However, in some cases audio information is more helpful for finding clues to the video events. The proposed feature extraction scheme is based on the fundamental property of the wavelet transform. Therefore, it can also be adopted to analyze the audio contents of the video data. The experimental evaluation indicates the high discriminatory power of the proposed feature set. The dimension of the extracted feature vector is low, which is important for the retrieval efficiency of the system in terms of response time. User feedback is used to enhance the retrieval performance by modifying the system parameters according to the users' behavior. A nonlinear approach for defining the similarity between the two images is also explored in this work.	coefficient;computational complexity theory;database;feature extraction;feature vector;image noise;image retrieval;information retrieval;mixture model;multimodal interaction;nonlinear system;relevance feedback;response time (technology);sound card;wavelet transform	Tahir Amin;Mehmet Zeytinoglu;Ling Guan	2007	IEEE Transactions on Multimedia	10.1109/TMM.2007.906587	computer vision;visual word;content analysis;image processing;image retrieval;computer science;machine learning;pattern recognition;term discrimination;vector space model;information retrieval;wavelet transform;divergence-from-randomness model	Vision	43.03613529875343	-61.46071344066419	18623
25a17a5ac1426dce8023aa1e6a44156cc3002198	design of a mathematical expression recognition system	mathematical expressions;scientific documents;image segmentation feature extraction character recognition document image processing;image segmentation;rule based;character segmentation;page segmentation;layout;optical character recognition software;image segmentation character recognition text recognition labeling error correction optical character recognition software layout graphics equations image edge detection;image edge detection;error correction;feature extraction;mathematical expression recognition;document image processing;heuristic rules;text recognition;character recognition;graphics;labeling;mathematical equations understanding mathematical expression recognition mathematical expressions page segmentation labeling character segmentation feature extraction heuristic rules scientific documents;mathematical equations understanding	We present a system to segment and recognize texts andmathematical expressions in a document. The system can be divided into six stages: page segmentation and labeling, character segmentation, feature extraction, character recognition, expression formation, and error correction and expression extraction. In expression formation, we build a symbol relation tree for each text line to represent the relationships among the symbols in the text line. Some heuristic rules based on the primitive tokens are used to correct the recognition errors in a text line. We extract all mathematical expressions according to some basic expression forms. Our database consists of 190 symbols in the current stage. The average recognition rate is about 96.16%.	error detection and correction;feature extraction;heuristic;optical character recognition;sequence labeling	Hsi-Jian Lee;Jiumn-Shine Wang	1995		10.1109/ICDAR.1995.602097	rule-based system;layout;computer vision;labeling theory;error detection and correction;speech recognition;feature extraction;computer science;graphics;expression;machine learning;pattern recognition;image segmentation	AI	35.442232667493094	-66.41508293288346	18627
e471b415a78a9c8a17ae06ad57254b9523916b7a	lbp based line-wise script identification	least squares approximations;document analysis;support vector machines;optical character recognition;multi script ocr;image texture;lbp;document image processing;texture measures;text detection;databases histograms training testing support vector machines image segmentation feature extraction;script identification;visual databases;ocr lbp based line wise script identification multiscript document analysis text portion script features printed script identification texture analysis local pattern histogram local binary patterns script stroke direction distribution least square support vector machine ls svm identifier training database google translator;visual databases document image processing image texture least squares approximations optical character recognition support vector machines text detection;lbp script identification multi script ocr document analysis texture measures	Script identification is an important step in multi-script document analysis. As different textures present in text portion of a script are the main distinct features of the script, in this paper, we proposed a new algorithm for printed script identification based on texture analysis. Since local patterns is a unifying concept for traditional statistical and structural approaches of texture analysis, here the basic idea is to use the histogram of the local patterns as description of the script stroke directions distribution which is the characteristic of every script. As local pattern, the basic version of the Local Binary Patterns (LBP) and a modified version of the Orientation of the Local Binary Patterns (OLBP) are proposed. A Least Square Support Vector Machine (LS-SVM) is used as identifier. The scheme has been verified on two databases. The first or training database is a database with 200 sheets of 10 different scripts. The scripts font is provided by the Google translator. The second or test database has been obtained by scanning different newspapers and books. It contains 5 common scripts among 10 different scripts of the first database. From the experiment we obtained encouraging results.	algorithm;book;concatenation;database;identifier;local binary patterns;printing;support vector machine	Miguel Angel Ferrer-Ballester;Aythami Morales;Umapada Pal	2013	2013 12th International Conference on Document Analysis and Recognition	10.1109/ICDAR.2013.81	image texture;support vector machine;computer vision;speech recognition;computer science;machine learning;pattern recognition;optical character recognition	DB	34.06368048428526	-64.8199349075037	18633
be9b118ae97a4020736b56a6406d140ea6dda71a	multi-label image annotation based on multi-model	rsa;image annotation;multi label;multi model;mnkda;mfbsa	Image automatic annotation is a promising and essential step for semantic image retrieval, and it's still a challenge because of the open problem of semantic gap. Recently, most of image annotation approaches paid more attention to detect single label for an image, but in fact they are multi-label learning problems. In this paper, we propose a new multi-model method for image multi-label annotation, which includes two different models for foreground and background semantic detection in terms of their distinct characters of semantic and visual features respectively, and a semantic correlation analysis model for refining the annotation results. A new visual saliency analysis algorithm based on multi-feature is proposed to obtaining the salient object, and multiple Nyström-approximating kernel discriminant analysis is used to acquire foreground semantic concept. Region semantic analysis is proposed to get annotation words of background, and semantic correlation matrix constructed by Latent Semantic Analysis is used to remove the unreliable labels. Experimental results show that our multi-model image labeling method could achieve promising performance for multi-labeling, and outperform previous methods on benchmark datasets.	algorithm;automatic image annotation;benchmark (computing);image retrieval;latent semantic analysis;linear discriminant analysis;multi-label classification;pascal	Jing Zhang;Weiwei Hu	2013		10.1145/2448556.2448577	computer vision;semantic similarity;semantic computing;image retrieval;computer science;pattern recognition;probabilistic latent semantic analysis;automatic image annotation;information retrieval	Vision	31.326009684292394	-54.105240228172946	18669
c2b300d64503cef62d4acb70fa03e2fe5bb9e3ef	a comparative study between parametric blur estimation methods	estimation method;autoregressive moving average processes;arma model;image restoration;noise robustness comparative study parametric blur estimation methods pattern recognition image quality blurred image noisy image digital image restoration original image estimation observed image blur parameters identification parametric arma modeling accuracy modeling assumptions support size;noise parameter estimation image restoration pattern recognition autoregressive moving average processes;image restoration degradation pattern recognition image analysis pattern analysis digital images linear approximation convolution noise robustness information analysis;comparative study;pattern recognition;digital image;parameter estimation;noise	In pattern recognition problems, the effectiveness of the analysis depends heavily on the quality of the image to be processed. This image may be blurred and/or noisy and the goal of digital image restoration is to find an estimate of the original image. A fundamental issue in this process is the blur estimation. When the blur is not readily avalaible, it has to be estimated from the observed image. Two main approaches can be found in the literature. The first one identify the blur parameters before any restoration whereas the second one realizes these two steps jointly. We present a comparative study of several parametric blur estimation methods, based on a parametric ARMA modeling of the image, belonging to the first approach. Our purpose is to evaluate the acuracy of the various methods, on which the restoration procedure relies, and their robustness to modeling assumptions, noise, and size of support.	circuit restoration;digital image;gaussian blur;image restoration;pattern recognition	Sophie Chardon;Benoit Vozel;Kacem Chehdi	1999		10.1109/ICASSP.1999.757530	autoregressive–moving-average model;image restoration;computer vision;feature detection;computer science;noise;comparative research;gaussian blur;pattern recognition;mathematics;estimation theory;digital image;statistics	Vision	53.28169835699794	-66.23258082113666	18756
47b824f48bea97d56bf5b64f222ef134af352ee3	a segmentation and classification scheme for single tooth in microct images based on 3d level set and k-means++	k means;level set;classification;tooth	Accurate classification of different anatomical structures of teeth from medical images provides crucial information for the stress analysis in dentistry. Usually, the anatomical structures of teeth are manually labeled by experienced clinical doctors, which is time consuming. However, automatic segmentation and classification is a challenging task because the anatomical structures and surroundings of the tooth in medical images are rather complex. Therefore, in this paper, we propose an effective framework which is designed to segment the tooth with a Selective Binary and Gaussian Filtering Regularized Level Set (GFRLS) method improved by fully utilizing 3 dimensional (3D) information, and classify the tooth by employing unsupervised learning i.e., k-means++ method. In order to evaluate the proposed method, the experiments are conducted on the sufficient and extensive datasets of mandibular molars. The experimental results show that our method can achieve higher accuracy and robustness compared to other three clustering methods.		Liansheng Wang;Shusheng Li;Rong-Zhen Chen;Sze-Yu Liu;Jyh-Cheng Chen	2017	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2016.05.005	computer vision;medicine;biological classification;computer science;level set;dentistry;tooth;k-means clustering	Vision	37.984890481064646	-77.74902915120018	18770
08ff0058f2f4b33e35eb72a9b6732ed14dcc314d	segmentation of serial mri of tbi patients using personalized atlas construction and topological change estimation	biological patents;topology;brain;brain injuries;biomedical journals;probability;image segmentation;traumatic brain injury;atlas construction;text mining;treatment efficacy;europe pubmed central;citation search;biomechanics;biomedical imaging;longitudinal mri;citation networks;blood vessel;magnetic resonance image;hemorrhaging;mr imaging;estimation;research articles;lesions;topological change estimation;abstracts;topology biomechanics biomedical mri blood vessels brain image segmentation injuries medical image processing neurophysiology patient treatment probability;medical image processing;magnetic resonance imaging;open access;injuries;life sciences;clinical guidelines;patient treatment;atlas construction 4d pathology segmentation longitudinal mri topological change estimation;neurophysiology;brain injury;full text;4d pathology segmentation;rest apis;lesions image segmentation hemorrhaging estimation biomedical imaging brain injuries magnetic resonance imaging;orcids;blood vessels;temporally independent segmentations personalized atlas construction topological change estimation traumatic brain injury personalized therapy personalized assessment longitudinal 4d magnetic resonance imaging longitudinal brain mr image segmention impact force effect tissue skull blood vessels recovery processing probability 4d information yields;europe pmc;biomedical research;biomedical mri;bioinformatics;literature search	Traumatic brain injury (TBI) due to falls, car accidents, and warfare affects millions of people annually. Determining personalized therapy and assessment of treatment efficacy can substantially benefit from longitudinal (4D) magnetic resonance imaging (MRI). In this paper, we propose a method for segmenting longitudinal brain MR images with TBI using personalized atlas construction. Longitudinal images with TBI typically present topological changes over time due to the effect of the impact force on tissue, skull, and blood vessels and the recovery process. We address this issue by defining a novel atlas construction scheme that explicitly models the effect of topological changes. Our method automatically estimates the probability of topological changes jointly with the personalized atlas. We demonstrate the effectiveness of this approach on MR images with TBI that also have been segmented by human raters, where our method that integrates 4D information yields improved validation measures compared to temporally independent segmentations.	accidental falls;atlases;blood vessel;brain injuries;cervical atlas;chimeric antigen receptor;estimated;magnetic resonance imaging;patients;personalization;traumatic brain injury	Bo Wang;Marcel Prastawa;Suyash P. Awate;Andrei Irimia;Micah C. Chambers;Paul M. Vespa;John D. Van Horn;Guido Gerig	2012	2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2012.6235764	estimation;radiology;medicine;pathology;computer science;magnetic resonance imaging;probability;mathematics;image segmentation;statistics;medical physics	Vision	40.847746783201444	-80.08872854336177	18829
204b9d2da639c7c5e6f802429ee623dac1e23847	design of a feature set for face recognition problem	reconnaissance visage;dimensionalidad;analisis componente principal;high dimensionality;analisis estadistico;image processing;facies;redundancia;image databank;dimension reduction;pertinencia;procesamiento imagen;dimensionality;curse of dimensionality;feature space;traitement image;reduction dimension;face recognition;redundancy;statistical analysis;dimensionnalite;principal component analysis;pertinence;banco imagen;banque image;analyse statistique;analyse composante principale;pattern recognition;reduccion dimension;feature selection;reconnaissance forme;relevance;reconocimiento patron;dimensional reduction;redondance	An important problem in face recognition is the design of the feature space which represents the human face. Various feature sets have been and are continually being proposed for this purpose. However, there exists no feature set which gives a superior and consistent recognition performance on various face databases. Concatenating the popular features together and forming a high dimensional feature space introduces the curse of dimensionality problem. For this reason, dimensionality reduction techniques such as Principal Component Analysis is utilized on the feature space. In this study, first, some of the popular feature sets used in face recognition literature are evaluated over three popular face databases, namely ORL [1], UMIST [2], and Yale [3]. Then, high dimensional feature space obtained by concatenating all the features is reduced to a lower dimensional space by using the Minimal Redundancy Maximal Relevance [4] feature selection method in order to design a generic and successful feature set. The results indicate that mRMR selects a small number of features which are satisfactory and consistent in terms of recognition performance, provided that the face database is statistically stable with sufficient amount of data.	facial recognition system	Emre Akbas;Fatos T. Yarman-Vural	2006		10.1007/11902140_27	computer vision;curse of dimensionality;feature vector;feature;image processing;feature extraction;computer science;machine learning;pattern recognition;mathematics;feature selection;k-nearest neighbors algorithm;feature;feature model;dimensionality reduction	Vision	43.846028005627296	-60.304340245751405	18907
bc955487a0b8d2fae3f2f44320389a12ae28f0f5	face sketch–photo synthesis and retrieval using sparse representation	image retrieval face recognition image enhancement image representation;vectors face dictionaries feature extraction training educational institutions image retrieval;sparse representation face sketch photo synthesis sketch photo based retrieval sparse neighbor selection;computer science and information systems;training;patch derivative based sparse representation sketch based face photo retrieval photo based face sketch retrieval system sketch photo synthesis method sparse neighbor selection sns pseudoimage sparse representation based enhancement sre coupled sparse representation model mapping sketch patch photo patch;sparse neighbor selection;journal article;sketch photo based retrieval;image enhancement;face recognition;vectors;image representation;feature extraction;dictionaries;face;face sketch photo synthesis;sparse representation;image retrieval	Sketch-photo synthesis plays an important role in sketch-based face photo retrieval and photo-based face sketch retrieval systems. In this paper, we propose an automatic sketch-photo synthesis and retrieval algorithm based on sparse representation. The proposed sketch-photo synthesis method works at patch level and is composed of two steps: sparse neighbor selection (SNS) for an initial estimate of the pseudoimage (pseudosketch or pseudophoto) and sparse-representation-based enhancement (SRE) for further improving the quality of the synthesized image. SNS can find closely related neighbors adaptively and then generate an initial estimate for the pseudoimage. In SRE, a coupled sparse representation model is first constructed to learn the mapping between sketch patches and photo patches, and a patch-derivative-based sparse representation method is subsequently applied to enhance the quality of the synthesized photos and sketches. Finally, four retrieval modes, namely, sketch-based, photo-based, pseudosketch-based, and pseudophoto-based retrieval are proposed, and a retrieval algorithm is developed by using sparse representation. Extensive experimental results illustrate the effectiveness of the proposed face sketch-photo synthesis and retrieval algorithms.	algorithm;database;facial recognition system;noise reduction;patch (computing);sketch;sparse approximation;sparse matrix;windows photo gallery	Xinbo Gao;Nannan Wang;Dacheng Tao;Xuelong Li	2012	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2012.2198090	face;computer vision;visual word;feature extraction;image retrieval;computer science;machine learning;pattern recognition;sparse approximation	Vision	35.952262696978444	-54.62969210325985	18914
77596577a6ac7fdc9948a65db09ea2f6927d7fdf	euclidean image embedding in view of similarity ranking in auction search by image		We propose an Euclidean embedding image representation, which serves to rank auction item images through wide range of semantic similarity spectrum, in the order of the relevance to the given query image much more effective than the baseline method in terms of a graded relevance measure. Our method uses three stream deep convolutional siamese networks to learn a distance metric and we leverage search query logs of an auction item search of the largest auction service in Japan. Unlike previous approaches, we define the inter-image relevance on the basis of user queries in the logs used to search each auction item, which enables us to acquire the image representation preserving the features concerning user intents in real e-commerce world.	baseline (configuration management);e-commerce;relevance;semantic similarity	Riku Togashi;Hideyuki Maeda;Vibhor Kanojia;Kousuke Morimoto;Sumio Fujita	2017		10.1145/3041021.3054262	semantic similarity;world wide web;metric (mathematics);computer science;web search query;data mining;information retrieval;euclidean geometry;embedding;ranking	Web+IR	33.292501835443986	-53.3337478764327	18991
af9f9827c36ea9f27513ae6b7e17c4535b2857fe	applying local cooccurring patterns for object detection from aerial images	geographic information system;local cooccurring patterns;aerial image;colour cooccurrence histogram;local features;swimming pool detection;conference proceeding;object detection	Developing a spatial searching tool to enhance the search capabilities of large spatial repositories for Geographical Information System (GIS) update has attracted more and more attention. Typically, objects to be detected are represented by many local features or local parts. Testing images are processed by extracting local features which are then matched with the object’s model image. Most existing work that uses local features assumes that each of the local features is independent to each other. However, in many cases, this is not true. In this paper, a method of applying the local cooccurring patterns to disclose the cooccurring relationships between local features for object detection is presented. Features including colour features and edge-based shape features of the interested object are collected. To reveal the cooccurring patterns among multiple local features, a colour cooccurrence histogram is constructed and used to search objects of interest from target images. The method is demonstrated in detecting swimming pools from aerial images. Our experimental results show the feasibility of using this method for effectively reducing the labour work in finding man-made objects of interest from aerial images.	aerial photography;computer mouse;geographic information system;object detection;randomness;semiconductor industry;sensor;test set	Wenjing Jia;David Tien;Xiangjian He;Brian A. Hope;Qiang Wu	2007		10.1007/978-3-540-76414-4_47	computer vision;geography;pattern recognition;data mining	Vision	38.4928218278064	-55.75306268538159	19009
0d837c2b9d71358342681daf4515e86c7c7e859c	return of grid seams: a superpixel algorithm using discontinuous multi-functional energy seam carving	image segmentation lattices image edge detection computer vision optimization image color analysis computational modeling;image segmentation computer vision edge detection image representation image resolution;grid seam return berkeley segmentation dataset structural information unified multifunctional energy textural variations rgs return of grid seams image characteristics energy function edge information superpixel accuracy global spatial constraints improved image structure preservation superpixel generation depth estimation object segmentation object recognition computer vision applications image representation discontinuous multifunctional energy seam carving superpixel algorithm;multi functional superpixels seam carving discontinuous	Superpixels have been widely used for compact image representation in a large number of computer vision applications such as object recognition, segmentation, and depth estimation. Recently, a novel seam carving approach for superpixel generation called Grid Seams was introduced that significantly improved image structure preservation while maintaining global spatial constraints. While Grid Seams was able to achieve state-of-the-art superpixel accuracy, it only took advantage of rudimentary edge information in its energy function and as such did not account for other important image characteristics such as texture. Motivated by this, we present Return of Grid Seams (RGS), a novel extension of Grid Seams that takes advantage of not only structural variations, but also textural variations (in the form of texture distinctiveness) into a unified multi-functional energy along with global spatial constraints. Furthermore, RGS incorporates discontinuous seams in the optimization process to allow for greater flexibility in preserving structural information. Experimental results using the Berkeley Segmentation Dataset show that RGS is able to outperform Grid Seams as well as a number of other seam carving based superpixel methods.	algorithm;computer vision;mathematical optimization;outline of object recognition;remote graphics software;seam carving	Parthipan Siva;Christian Scharfenberger;Ibrahim Ben Daya;Akshaya Kumar Mishra;Alexander Wong	2015	2015 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2015.7351017	image texture;computer vision;feature detection;computer science;pattern recognition;image segmentation;computer graphics (images)	Vision	38.02861054227753	-56.39690479895037	19037
1e2e0c80f5f16e2236d2966894e90061066bacb1	iot-based image recognition system for smart home-delivered meal services		Population ageing is an important global issue. The Taiwanese government has used various Internet of Things (IoT) applications in the “10-year long-term care program 2.0”. It is expected that the efficiency and effectiveness of long-term care services will be improved through IoT support. Home-delivered meal services for the elderly are important for home-based long-term care services. To ensure that the right meals are delivered to the right recipient at the right time, the runners need to take a picture of the meal recipient when the meal is delivered. This study uses the IoT-based image recognition system to design an integrated service to improve the management of image recognition. The core technology of this IoT-based image recognition system is statistical histogram-based k-means clustering for image segmentation. However, this method is time-consuming. Therefore, we proposed using the statistical histogram to obtain a probability density function of pixels of a figure and segmenting these with weighting for the same intensity. This aims to increase the computational performance and achieve the same results as k-means clustering. We combined histogram and k-means clustering in order to overcome the high computational cost for k-means clustering. The results indicate that the proposed method is significantly faster than k-means clustering by more than 10 times.	aerial photography;algorithmic efficiency;cluster analysis;computation;computer vision;experiment;home automation;image segmentation;internet of things;k-means clustering;kinetic monte carlo;pixel;unmanned aerial vehicle	Hsiao-Ting Tseng;Hsin-Ginn Hwang;Wei-Yen Hsu;Pei-Chin Chou;I-Chiu Chang	2017	Symmetry	10.3390/sym9070125	market segmentation;pixel;computer vision;k-means clustering;home automation;cluster analysis;data mining;histogram;artificial intelligence;image segmentation;weighting;computer science	ML	41.098748344405415	-68.92163663589638	19084
bda30fcf11e24170fc80a170d8a5207815f6700c	shape metamorphism using p-laplacian equation	intermediate shape;source shape;infinite laplacian equation;implicit scalar function;new regularization term;shape metamorphism;implicit function;intermediate solution;p-laplacian equation;regularization term;target shape;algorithms;laplacian;shape;scalars;metamorphism;pattern recognition	We present a new approach for shape metamorphism, which is a process of gradually changing a source shape (known) through intermediate shapes (unknown) into a target shape (known). The problem, when represented with implicit scalar function, is under-constrained, and regularization is needed. Using the p-Laplacian equation (PLE), we generalize a series of regularization terms based on the gradient of the implicit function, and we show that the present methods lack additional constraints for a more stable solution. The novelty of our approach is in the deployment of a new regularization term when p /spl rarr/ /spl infin/ which leads to the infinite Laplacian equation (ILE). We show that ILE minimizes the supremum of the gradient and prove that it is optimal for metamorphism since intermediate solutions are equally distributed along their normal direction. Applications of the proposed algorithm for 2D and 3D objects are demonstrated.	algorithm;approximation;design for manufacturability;gradient;integrated language environment;laplacian matrix;matrix regularization;morphing;normal (geometry);numerical analysis;numerical method;software deployment	Ge Cong;Mehmet Esser;Bahram Parvin;George Bebis	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1333694	mathematical optimization;laplace operator;mathematical analysis;shape;mathematics;geometry;metamorphism	Vision	52.27408148274123	-71.26529515717834	19143
1e996289ca441a3a5762906da8823e93e5ff81bb	a simple and efficient method for global handwritten word recognition applied to brazilian bankchecks	cheque processing handwritten character recognition genetic algorithms pattern classification;nearest neighbor method;cheque processing;pattern classification;word recognition;genetic algorithm;genetic algorithms;handwritten word recognition;nearest neighbor handwritten word recognition brazilian bankcheck digitized word image genetic algorithm;handwritten character recognition;handwriting recognition genetic algorithms feature extraction nearest neighbor searches testing image converters spatial databases law legal factors shape	A simple and efficient method for the recognition of isolated handwritten words in Brazilian bankchecks is proposed. For this end, the global word recognition technique was adopted. It relies mainly on topological features to identify the shape of the digitized word images. A genetic algorithm (GA) was used to select those features that best represent each word class and the nearest neighbor method was used as a classification means. The experimental results obtained in our laboratory present a higher average classification rate than a previous work that used the same database.	genetic algorithm;nearest neighbor search;software release life cycle	Lee Luan Ling;Stela Isernhagen	2005	Eighth International Conference on Document Analysis and Recognition (ICDAR'05)	10.1109/ICDAR.2005.31	speech recognition;genetic algorithm;feature;intelligent character recognition;computer science;intelligent word recognition;machine learning;pattern recognition	Vision	32.44214762907024	-65.67834329972811	19217
df410f97c1c131796e52b2b4c50989d8b93fda99	minutiae based thermal human face recognition using label connected component algorithm	biometric;minutiae points	In this paper, a thermal infra red face recognition system for human identification and verification using blood perfusion data and back propagation feed forward neural network is proposed. The system consists of three steps. At the very first step face region is cropped from the colour 24-bit input images. Secondly face features are extracted from the croped region, which will be taken as the input of the back propagation feed forward neural network in the third step and classification and recognition is carried out. The proposed approaches are tested on a number of human thermal infra red face images created at our own laboratory. Experimental results reveal the higher degree performance.	24-bit;algorithm;artificial neural network;backpropagation;biometrics;experiment;facial recognition system;feature extraction;minutiae;multilayer perceptron;software propagation	Ayan Seal;Suranjan Ganguly;Debotosh Bhattacharjee;Mita Nasipuri;Dipak Kumar Basu	2013	CoRR		computer vision;speech recognition;artificial intelligence	Vision	32.95900093193022	-69.77953469730666	19253
3db934422981d0a0d56a105089f7387ca004ff44	a novel descriptor optimization method for multispectral images	histograms;electronic mail;principal component analysis histograms feature extraction shape electronic mail optimization image edge detection;principal component analysis descriptor optimization multispectral images lghd log gabor histogram descriptor pca;shape;image edge detection;feature extraction;principal component analysis;principal component analysis image processing optimisation;optimization;lghd multispectral feature descriptor pca descriptor optimization	This paper presents an optimized descriptor method for multispectral images. The method proposed is based on LGHD (Log-Gabor Histogram Descriptor)[1]. Initially, all feature points are detected from Long wave Infrared and Visible spectrum images, and descripted by LGHD, then PCA (Principal Component Analysis) is used to reduce the dimension of the two different descriptors, finally the optimized descriptors are used to match the points. Experimental results show that proposed approach achieves a better matching performance than LGHD.	mathematical optimization;multispectral image;principal component analysis	Zhitao Fu;Bin Luo;Chun Wu;Qianqing Qin	2016	2016 International Conference on Computer, Information and Telecommunication Systems (CITS)	10.1109/CITS.2016.7546457	computer vision;gloh;machine learning;pattern recognition;mathematics	Vision	35.55958038754232	-59.376294232123705	19279
8c71d5e3776b5d79e42daa2ea513da06ee990756	car plate character extraction under complicated environment	image recognition;automobiles;license plate recognition system;car plate character extraction;character recognition licenses image edge detection computer science vehicles software systems image recognition labeling application software monitoring;geometrical characteristic;feature extraction;geometrical characteristic car plate character extraction license plate recognition system projection image;projection image;license plate recognition;character recognition;extraction method;road vehicles;image recognition automobiles character recognition feature extraction	License plate recognition (LPR) system has many applications. Character extraction is a key step in LPR system. The proposed character extraction method in this paper is mainly according to plate's geometrical characteristic and supplementary with the scan of projection image. Subsequently, locate the plate character sequence, then do more jobs on false characters elimination and verify the validity of extracted characters. The above methods lead to an ideal character extraction result, which leads higher recognition accuracy of the LPR system		Sanyuan Zhang;Mingli Zhang;Xiuzi Ye	2004		10.1109/ICSMC.2004.1401277	computer vision;speech recognition;feature extraction;computer science;pattern recognition	EDA	35.33989769357609	-64.13710188322034	19295
020d6bbf1bed270572a943ec570a19a1afbe5b83	classification of urban scenes from geo-referenced images in urban street-view context	spatial pyramid matching;visualization histograms encoding kernel vegetation mapping feature extraction dictionaries;street level images;image classification;learning artificial intelligence geographic information systems image classification;semantic image classification;intraclass variability street view georeferenced image urban scene classification urban street view context semantic image classification bossa representation bag of words model bow model spatial pyramid matching scheme kernel based machine learning large scale urban environment;geographic information systems;kernel based machine learning;learning artificial intelligence;visual words;kernel based machine learning semantic image classification street level images visual words spatial pyramid matching	This paper addresses the challenging problem of scene classification in street-view georeferenced images of urban environments. More precisely, the goal of this task is semantic image classification, consisting in predicting in a given image, the presence or absence of a pre-defined class (e.g. shops, vegetation, etc.). The approach is based on the BOSSA representation, which enriches the Bag of Words (BoW) model, in conjunction with the Spatial Pyramid Matching scheme and kernel-based machine learning techniques. The proposed method handles problems that arise in large scale urban environments due to acquisition conditions (static and dynamic objects/pedestrians) combined with the continuous acquisition of data along the vehicle's direction, the varying light conditions and strong occlusions (due to the presence of trees, traffic signs, cars, etc.) giving rise to high intra-class variability. Experiments were conducted on a large dataset of high resolution images collected from two main avenues from the 12th district in Paris and the approach shows promising results.	bag-of-words model in computer vision;experiment;google street view;ground truth;heart rate variability;image resolution;machine learning;super paper mario;support vector machine	Corina Iovan;David Picard;Nicolas Thome;Matthieu Cord	2012	2012 11th International Conference on Machine Learning and Applications	10.1109/ICMLA.2012.171	computer vision;contextual image classification;visual word;computer science;artificial intelligence;machine learning;pattern recognition;geographic information system	Vision	32.76497551793256	-52.76292996378732	19361
3ecfdf2f8c6c6d826824a4ce534f4e4816b2d6ab	nonrigid registration and classification of the kidneys in 3d dynamic contrast enhanced (dce) mr images	biological patents;biomedical journals;tissues;text mining;europe pubmed central;citation search;image classification;citation networks;non rigid image registration;dynamic contrast enhanced dce mri;research articles;abstracts;magnetic resonance imaging;image registration;open access;life sciences;clinical guidelines;image analysis;full text;rest apis;kidney;orcids;europe pmc;biomedical research;bioinformatics;literature search	We have applied image analysis methods in the assessment of human kidney perfusion based on 3D dynamic contrast-enhanced (DCE) MRI data. This approach consists of 3D non-rigid image registration of the kidneys and fuzzy C-mean classification of kidney tissues. The proposed registration method reduced motion artifacts in the dynamic images and improved the analysis of kidney compartments (cortex, medulla, and cavities). The dynamic intensity curves show the successive transition of the contrast agent through kidney compartments. The proposed method for motion correction and kidney compartment classification may be used to improve the validity and usefulness of further model-based pharmacokinetic analysis of kidney function.	anatomical compartments;body tissue;contrast media;contrast ratio;dynamic splints;image analysis;image registration;kidney diseases;morphologic artifacts;multi-compartment model;muscle rigidity;renal tissue;registration - actclass	Xiaofeng Yang;Pegah Ghafourian;Puneet Sharma;Khalil Salman;Diego R. Martín;Baowei Fei	2012	Proceedings of SPIE--the International Society for Optical Engineering	10.1117/12.912190	contextual image classification;text mining;image analysis;image registration;magnetic resonance imaging;data mining	Vision	42.49175322057943	-79.27963869592216	19377
62d37831e00bc0511480f7cb78874ffb30331382	estimating fingerprint deformation	doigt;variabilidad;image processing;distorsion non lineaire;procesamiento imagen;distorsion no lineal;proceso adquisicion;acquisition process;traitement image;nonlinear distortion;aproximacion esplin;empreinte digitale;plaque mince;image acquisition;spline approximation;approximation spline;non linear distortion;fingerprint;finger;thin plate;huella digital;variability;dedo;variabilite;deformable model;thin plate spline;processus acquisition;placa delgada	Fingerprint matching is affected by the nonlinear distortion introduced in fingerprint impressions during the image acquisition process. This nonlinear deformation causes fingerprint features such as minutiae points and ridge curves to be distorted in a complex manner. In this paper we develop an average deformation model for a fingerprint impression (baseline impression) by observing its relative distortion with respect to several other impressions of the same finger. The deformation is computed using a Thin Plate Spline (TPS) model that relies on ridge curve correspondences between image pairs. The estimated average deformation is used to distort the minutiae template of the baseline impression prior to matching. An index of deformation has been proposed to select the average deformation model with the least variability corresponding to a finger. Preliminary results indicate that the average deformation model can improve the matching performance of a fingerprint matcher.	baseline (configuration management);computational anatomy;distortion;fingerprint recognition;minutiae;nonlinear system;pixel;spatial variability;thin plate spline	Arun Ross;Sarat C. Dass;Anil K. Jain	2004		10.1007/978-3-540-25948-0_35	fingerprint;computer vision;nonlinear distortion;image processing;computer science;mathematics;geometry;thin plate spline	Vision	51.71508002415781	-57.20429165278658	19396
44a14e1d4fac3a1731b1c96fcd70939a99aad6ff	computing the q-index for tsallis nonextensive image segmentation	tsallis entropy tsallis nonextensive image segmentation shannon information theory image processing boltzaman gibbs entropy q index parameter;databases;image segmentation entropy image processing thermodynamics humans computer graphics artificial intelligence image analysis information analysis statistics;image segmentation;long range interaction;image segmentation entropy;indexing terms;tsallis entropy image segmentation q entropy;image processing and analysis;radio frequency;image edge detection;indexation;thermodynamics;ground truth;humans;entropy;tsallis entropy;q entropy;information theory	The concept of entropy based on Shannon Theory of Information has been applied in the field of image processing and analysis since the work of T. Pun [1]. This concept is based on the traditional Boltzaman-Gibbs entropy, proposed under the classical thermodynamic. On the other hand, it is well known that this old formalism fails to explain some physical system if they have complex behavior such as long rang interactions and long time memories. Recently, studies in mechanical statistics have proposed a new kind of entropy, called Tsallis entropy (or non-extensive entropy), which has been considered with promising results on several applications in order to explain such phenomena. The main feature of Tsallis entropy is the $q$-index parameter, which is close related to the degree of system nonextensivity. In 2004 was proposed[2] the first algorithm for image segmentation based on Tsallis entropy. However, the computation of the q-index was already an open problem. On the other hand, in the field of image segmentation it is not an easy task to compare the quality of segmentation results. This is mainly due to the lack of an image ground truth based on human reasoning. In this paper, we propose the first methodology in the field of image segmentation for q-index computation and compare it with other similar approaches using a human based segmentation ground truth. The results suggest that our approach is a forward step for image segmentation algorithms based on Information Theory.	algorithm;computation;entropy (information theory);formal system;ground truth;image processing;image segmentation;information theory;interaction;shannon (unit);tsallis entropy	Paulo S. Rodrigues;Gilson A. Giraldi	2009	2009 XXII Brazilian Symposium on Computer Graphics and Image Processing	10.1109/SIBGRAPI.2009.23	artificial intelligence;machine learning;segmentation-based object categorization;pattern recognition;mathematics	Vision	48.4764046650875	-69.76334999108997	19448
2ff58d1db02b73ecb26da1227b512ce1d8d57208	effective scene matching with local feature representatives	pattern clustering;pattern clustering image matching image representation;approximation algorithms;image matching;earth;computer vision;distance measurement;local features;image representation;feature extraction;classification algorithms;affinity propagation;clustering algorithms;modified earth mover distance scene matching method local feature representative digital photo image cluster center set affinity propagation algorithm;layout clustering algorithms earth image matching voting quantization aggregates image databases spatial databases image recognition;matching method	Scene matching measures the similarity of scenes in photos and is of central importance in applications where we have to properly organize large amount of digital photos by scene categories. In this paper, we present a novel scene matching method using local features representatives. For a given image, its scene is compactly represented as a set of cluster centers, called local feature representatives, where the clusters are obtained using the affinity propagation (AP) algorithm to aggregate local features according to their spatial closeness and appearance similarity. The similarity of scenes in two images is then measured by a modified Earth Mover Distance (EMD) between their corresponding sets of local feature representatives. Empirical experiments on real world photos shows that our method is comparable to the state-of-the-arts.	affinity propagation;aggregate data;algorithm;centrality;experiment;scene graph;software propagation	Shugao Ma;Weiqiang Wang;Qingming Huang;Shuqiang Jiang;Wen Gao	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761568	statistical classification;computer vision;feature extraction;computer science;machine learning;pattern recognition;mathematics;earth;cluster analysis;approximation algorithm;affinity propagation	Vision	38.05271416845674	-56.56773549413468	19469
e3bad13d99f6db001f44ab68f0054c0cd000e5b6	identification of font styles and typefaces in printed korean documents	coreano;keyword;document imprime;optical character recognition;caracter impreso;printed character;palabra clave;mot cle;korean;reconnaissance caractere;printed document;documento impreso;coreen;reconocimento optico de caracteres;caractere imprime;character recognition;reconocimiento caracter;reconnaissance optique caractere	This paper proposes a system for the extraction of typographical attributes, such as font style and typeface, that can be used to improve the performance of OCR and keyword spotting technologies on printed Korean document images. Three typographical features have been devised and experimented with 7,200 Korean word images. The individual accuracies for font style identification and typeface identification are 97.2% and 99.1%, respectively.		C. B. Jeong;H. K. Kwag;S. H. Kim;J. S. Kim;S. C. Park	2003		10.1007/978-3-540-24594-0_69	speech recognition;computer science;optical character recognition;korean	HCI	34.31793634630235	-67.0236681343913	19542
c65c10bd3a76485a0e66bab172318df31236c4af	detection of architectural distortion in mammograms using fractal analysis	databases;power spectrum;breast;fractal dimension;distortion;texture analysis;biopsy;region of interest;indexation;computing systems;mammography;digital database for screening mammography;fractal analysis;pathology	Several studies have demonstrated the fractal properties of screening mammograms. The purpose of this study was to investigate fractal texture analysis for the automated detection of architectural distortion (AD) in screening mammograms. The study was based on the Digital Database for Screening Mammography (DDSM). Initially, a database of 708 mammographic regions with confirmed pathology was created. They were all 512x512 pixel regions of interest (ROIs). The ROI size was determined empirically. Fifty-two regions were extracted around biopsy-proven architectural distortion. The remaining 656 ROIs depicted normal breast parenchyma. Fractal analysis was performed on each ROI at multiple resolutions (512x512, 256x256, 128x128, and 64x64). The fractal dimension of each ROI was calculated using the circular average power spectrum technique. Overall, the average fractal dimension (FD) estimate of the normal ROIs was statistically significantly higher than the average FD of the ROIs with AD. This result was consistent across all resolutions. However, best detection performance was achieved when the fractal dimension was estimated on ROIs subsampled with a factor of 2 (ROC area index Az=0.89±0.02). Specifically, there was perfect performance in fatty breasts (Az=1.0), Az=0.95±0.02 in fibroglandular breasts, Az=0.84±0.05 in heterogeneous breasts, and Az=0.66±0.10 in dense breasts. Overall, the present study demonstrates that the presence of AD disrupts the normal parenchymal structure, thus resulting in a lower fractal dimension. Consequently, fractal texture analysis could play an important role in the development of computer-assisted detection tools tailored towards architectural distortion.© (2005) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	distortion;fractal analysis	Georgia D. Tourassi;Nevine H. Eltonsy;Adel Said Elmaghraby;Carey E. Floyd	2005		10.1117/12.593823	computer vision;simulation;mathematics;multimedia	HCI	35.3713046967218	-77.30344530357259	19589
7247aebdfe095d101e44cd73077216b2be4f23e2	mapping lidc, radlex™, and lung nodule image features	image features;north america;digital imaging;lung;image data;imaging informatics;chest ct;probabilistic model;image interpretation;lidc;automatic annotation;radiographic image interpretation;semantic;digital image;computer assisted;lung image database consortium;radlex;reporting	Ideally, an image should be reported and interpreted in the same way (e.g., the same perceived likelihood of malignancy) or similarly by any two radiologists; however, as much research has demonstrated, this is not often the case. Various efforts have made an attempt at tackling the problem of reducing the variability in radiologists’ interpretations of images. The Lung Image Database Consortium (LIDC) has provided a database of lung nodule images and associated radiologist ratings in an effort to provide images to aid in the analysis of computer-aided tools. Likewise, the Radiological Society of North America has developed a radiological lexicon called RadLex. As such, the goal of this paper is to investigate the feasibility of associating LIDC characteristics and terminology with RadLex terminology. If matches between LIDC characteristics and RadLex terms are found, probabilistic models based on image features may be used as decision-based rules to predict if an image or lung nodule could be characterized or classified as an associated RadLex term. The results of this study were matches for 25 (74%) out of 34 LIDC terms in RadLex. This suggests that LIDC characteristics and associated rating terminology may be better conceptualized or reduced to produce even more matches with RadLex. Ultimately, the goal is to identify and establish a more standardized rating system and terminology to reduce the subjective variability between radiologist annotations. A standardized rating system can then be utilized by future researchers to develop automatic annotation models and tools for computer-aided decision systems.	classification;consortium;heart rate variability;interpretation process;lexicon;lung diseases;neoplasms;nomenclature;plant nodule;radiology;rule (guideline);spatial variability;sports rating system;structure of parenchyma of lung	Pia Opulencia;David S. Channin;Daniela Stan Raicu;Jacob D. Furst	2010	Journal of Digital Imaging	10.1007/s10278-010-9285-6	statistical model;computer vision;pathology;computer science;data mining;digital imaging;feature;digital image	Vision	33.00987458572826	-79.44594619300685	19604
c315e2b3e23f54fc5df67d3310ad6f89dc8d5cc9	selection of the best representative feature and membership assignment for content-based fuzzy image database	busqueda informacion;analisis contenido;contenu image;image content;base donnee;distance minimale;image processing;recherche image;algorithme glouton;image databank;information retrieval;logique floue;image database;database;procesamiento imagen;base dato;logica difusa;traitement image;minimal distance;fuzzy logic;content analysis;minimum distance;recherche information;banco imagen;banque image;greedy algorithm;algoritmo gloton;analyse contenu;content based image retrieval;contenido imagen;fuzzy database;content based retrieval;recherche par contenu;distancia minima;image retrieval	A major design issue in content-based image retrieval system is the selection of the feature set. This study attacks the problem of finding a discriminative feature for each class, which is optimal in some sense. The class-dependent feature is, then, used to calculate the membership value of each object class for content-based fuzzy image retrieval systems. The Best Representative Feature (BRF) for each class is identified in a training stage. Then, using the BRF of each object class, the segment groups in the images are labeled by the membership values of each object class. The segment groups are obtained in a greedy algorithm by minimizing the distance between each training object and the segment groups, using the BRF. This minimum distance is taken as the membership value of the training object for that particular segment group. Finally, the query object is matched to each segment group in a fuzzy database using the membership values of segment groups. The BRF is selected among the MPEG-7 descriptors. The proposed scheme yields substantially better retrieval rates compared to the available fixed feature content-based image retrieval systems.		Mutlu Uysal;Fatos T. Yarman-Vural	2003		10.1007/3-540-45113-7_15	fuzzy logic;computer vision;greedy algorithm;content analysis;image processing;image retrieval;computer science;artificial intelligence;pattern recognition;data mining;database;mathematics;information retrieval	DB	43.72787143735781	-60.894903305597616	19642
8c549c049352733ffefadc60f11abbd54c9480d7	image re-ranking with an alternating optimization	visual word selection;image re ranking;alternating optimization	In this work, we propose an efficient image re-ranking method, without additional memory cost compared with the baseline method~\cite{philbin2007object}, to re-rank all retrieved images. The motivation of the proposed method is that, there are usually many visual words in the query image that only give votes to irrelevant images. With this observation, we propose to only use visual words which can help to find relevant images to re-rank the retrieved images. To achieve the goal, we first find some similar images to the query by maximizing a quadratic function when given an initial ranking of the retrieved images. Then we select query visual words with an alternating optimization strategy: (1) at each iteration, select words based on the similar images that we have found and (2) in turn, update the similar images with the selected words. These two steps are repeated until convergence. Experimental results on standard benchmark datasets show that the proposed method outperforms spatial based re-ranking methods.	baseline (configuration management);benchmark (computing);iteration;mathematical optimization;quadratic function;relevance	Shanmin Pang;Jianru Xue;Zhanning Gao;Qi Tian	2014		10.1145/2647868.2655004	computer vision;machine learning;pattern recognition;data mining	AI	35.70326612431384	-55.05925185315976	19720
3377d56732c432bf42d6627b0fa25ff91286548c	robust facial pose estimation using landmark selection method for binocular stereo vision		In this paper, we present a robust framework for facial pose estimation from binocular stereoscopic vision. Unlike prior work on the facial pose estimation that employs the whole landmarks even located in the wrong position, we propose a landmark selection method to remove the erroneous landmarks for better performance, especially in the large facial pose case. For this purpose, we train a convolutional neural network (CNN) in order to measure the confidence of each facial landmark detected by using a well-known landmark detection algorithm. Also, by fitting selected landmarks to 3D space, our framework becomes more robust even when a small number of landmarks are selected. Due to the absence of public dataset for the binocular stereo facial pose, we construct facial pose data sets using a motion sensor for performance validation. In our experiments, our method achieves the higher accuracy of the pose estimation than the previous method, especially for large facial pose cases.		Jaeseong Park;Suwoong Heo;Kyungjune Lee;Hyewon Song;Sanghoon Lee	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451443	computer vision;robustness (computer science);convolutional neural network;pattern recognition;artificial intelligence;small number;solid modeling;pose;computer science;stereopsis	Vision	43.56420058630731	-52.676425263898	19733
b2588d7f8baa44a672790377dfecdf7a17e9a327	classification of mild cognitive impairment and alzheimer's disease with machine-learning techniques using 1h magnetic resonance spectroscopy data	single layer perceptron;magnetic resonance spectroscopy;info eu repo semantics article;machine learning;alzheimer s disease;metabolite	Several magnetic resonance techniques have been proposed as non-invasive imaging biomarkers for the evaluation of disease progression and early diagnosis of Alzheimer’s Disease (AD). This work is the first application of the Proton Magnetic Resonance Spectroscopy H-MRS data and machine-learning techniques to the classification of AD. A gender-matched cohort of 260 subjects aged between 57 and 99 years from the Alzheimer’s Disease Research Unit, of the Fundación CIEN-Fundación Reina Sofía has been used. A single-layer perceptron was found for AD prediction with only two spectroscopic voxel volumes (Tvol and CSFvol) in the left hippocampus, with an AUROC value of 0.866 (with TPR 0.812 and FPR 0.204) in a filter feature selection approach. These results suggest that knowing the composition of white and grey matter and cerebrospinal fluid of the spectroscopic voxel is essential in a H-MRS study to improve the accuracy of the quantifications and classifications, particularly in those studies involving elder patients and neurodegenerative diseases.	color gradient;feature selection;feedforward neural network;film-type patterned retarder;machine learning;minimal recursion semantics;perceptron;receiver operating characteristic;resonance;voxel	Cristian R. Munteanu;Carlos Fernandez-Lozano;Virginia Mato Abad;Salvador Pita Fernández;Juan Alvarez-Linera;Juan Antonio Hernández Tamames;Alejandro Pazos	2015	Expert Syst. Appl.	10.1016/j.eswa.2015.03.011	nuclear magnetic resonance spectroscopy;computer science;artificial intelligence;machine learning	ML	29.69268821625363	-77.63565247162892	19744
215274a720921554f32aeb8fe634b48ae59790e6	fast lead star detection in entertainment videos	sports videos lead star detection entertainment videos key frame extraction spectral clustering technique video summarization snippet detection;video summarization;motion pictures;video signal processing;spectral clustering technique;videos motion pictures face detection layout tv motion detection computer science clustering algorithms runtime watches;snippet detection;video signal processing entertainment feature extraction object detection;sports videos;sports video;spectral clustering;general methods;lead;feature extraction;dictionaries;entertainment videos;key frame extraction;face;tv;entertainment;object detection;videos;lead star detection	Video can be summarized in many forms. One natural possibility that has been well explored is extracting key frames in shots or scenes, and then creating thumbnails. Another natural alternative that has been surprisingly ill-explored is to locate “lead stars” around whom the action revolves. Though scarce and far between, available techniques for detecting lead stars is usually video specific. In this paper, we highlight the importance of lead star detection, and present a generalized method for detecting snippets around lead actors in entertainment videos. Applications that naturally make use of this method include locating action around the ‘player of the match’ in sports videos, lead actors in movies and TV shows, and guest-host snippets in TV talk shows. Additionally, our method is considerably faster than the state-of-art spectral clustering technique with comparable accuracy.	algorithm;cluster analysis;computation;key frame;sensor;spectral clustering;stellar classification;thumbnail	Nithya Manickam;Sharat Chandran	2009	2009 Workshop on Applications of Computer Vision (WACV)	10.1109/WACV.2009.5403086	face;computer vision;lead;entertainment;feature extraction;computer science;machine learning;multimedia;spectral clustering;computer graphics (images)	Vision	36.84230722897204	-54.23566560088529	19839
527bdd756b86381dd63273c5a2e7da50df9d9c53	performance evaluation of narrow band methods for variational stereo reconstruction		Convex relaxation techniques allow computing optimal or near-optimal solutions for a variety of multilabel problems in computer vision. Unfortunately, they are quite demanding in terms of memory and computation time making them unpractical for large-scale problems. In this paper, we systematically evaluate to what extent narrow band methods can be employed in order to improve the performance of variational multilabel optimization methods. We review variational methods, we present a narrow band formulation and demonstrate with a number of quantitative experiments that the narrow band formulation leads to a reduction in memory and computation time by orders of magnitude while preserving almost the same quality of results. In particular, we show that this formulation allows computing stereo depth maps for 6 Mpixels aerial image pairs on a single GPU in around one minute.	aerial photography;calculus of variations;computation;computer memory;computer vision;convex optimization;correspondence problem;depth map;depth perception;experiment;graphics processing unit;linear programming relaxation;mathematical optimization;performance evaluation;pixel;quality of results;requirement;time complexity;variational principle	Franz Stangl;Mohamed Souiai;Daniel Cremers	2013		10.1007/978-3-642-40602-7_20	computer vision;optics	Vision	53.62964928671944	-73.37401316767917	19861
8007e0ab71d1860cc9f2c933e3b2938288400244	desiccation diagnosis in lumbar discs from clinical mri with a probabilistic model	gibbs distribution;intervertebral disc;probability;computer aided diagnosis;lumbar intervertebral disc diseases;probability biomedical mri diseases medical image processing;contextual information;clinical mri;lumbar discs;desiccation diagnosis;probabilistic model;accuracy;back;magnetic resonance imaging pain neural networks degenerative diseases back spine magnetic field measurement testing computer science context modeling;medical image processing;magnetic resonance imaging;pixel;clinical t2 weighted mri desiccation diagnosis clinical mri probabilistic model lower back pain lumbar intervertebral disc diseases contextual information gibbs distribution;mri;pain;diseases;clinical t2 weighted mri;back pain;cross validation;context modeling;lower back pain;context;desiccation diagnosis computer aided diagnosis mri lumbar discs;biomedical mri	Lumbar intervertebral disc diseases are among the main causes of lower back pain (LBP). Desiccation is a common disease resulting from various reasons and ultimately most people are affected by desiccation at some age. We propose a probabilistic model that incorporates intervertebral disc appearance and contextual information for automating the diagnosis of lumbar disc desiccation. We utilize a Gibbs distribution for processing localized lumbar intervertebral discs' appearance and contextual information. We use 55 clinical T2-weighted MRI for lumbar area and achieve over 96% accuracy on a cross validation experiment.	cross-validation (statistics);desiccation;local binary patterns;statistical model	Raja' S. Alomari;Jason J. Corso;Vipin Chaudhary;Gurmeet Dhillon	2009	2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2009.5193105	statistical model;radiology;medicine;pathology;boltzmann distribution;magnetic resonance imaging;probability;mathematics;accuracy and precision;context model;pixel;cross-validation;surgery;statistics	Vision	34.66756136416976	-78.45814845525544	19971
e1433bd8436f1f8494586025f388f184f40f1bb2	brain differences visualized in the blind using tensor manifold statistics and diffusion tensor imaging	log euclidean tensor denoising;symmetric positive definite;brain;white matter;diffusion tensor images;geodesic anisotropy;differential geometry;medical image processing biomechanics biomedical mri brain deformation differential geometry image registration;biomechanics;geodesic anisotropy tensor manifold statistics diffusion tensor imaging magnetic resonance imaging white matter fiber structure multidirectional water diffusion fractional anisotropy brain morphological changes log euclidean tensor denoising image registration deformation noneuclidean manifold riemannian manifold hotelling t 2 test;white matter fiber structure;brain morphological changes;noneuclidean manifold;magnetic resonance image;multidirectional water diffusion;hotelling t 2 test;deformation;medical image processing;riemannian manifold;magnetic resonance imaging;image registration;visualization tensile stress statistics diffusion tensor imaging anisotropic magnetoresistance magnetic resonance imaging 1f noise symmetric matrices testing euclidean distance;fractional anisotropy;diffusion tensor imaging;tensor manifold statistics;diffusion tensor;biomedical mri	Diffusion tensor magnetic resonance imaging (DTI) reveals the local orientation and integrity of white matter fiber structure based on imaging multidirectional water diffusion. Group differences in DTI images are often computed from single scalar measures, e.g., the Fractional Anisotropy (FA), discarding much of the information in the 6-parameter symmetric diffusion tensor. Here, we compute multivariate 6D tensor statistics to detect brain morphological changes in 12 blind subjects versus 14 sighted controls. After Log-Euclidean tensor de- noising, images were fluidly registered to a common template. Fluidly-convected tensor signals were re-oriented by applying the local rotational and translational component of the deformation. Since symmetric, positive- definite matrices form a non-Euclidean manifold, we applied a Riemannian manifold version of the Hotelling's T2 test to the logarithms of the tensors, using a log- Euclidean metric. Statistics on the full 6D tensor-valued images outperformed univariate analysis of scalar images, such as the FA and the geodesic anisotropy (GA).	anisotropy, fluorescence;clinical use template;diffusion tensor imaging;euclidean distance;fractional anisotropy;genetic translation process;geodesic grid;magnetic resonance imaging;registration;software release life cycle;tissue fiber;visually impaired persons;white matter;manifold	Agatha D. Lee;Natasha Lepore;Franco Lepore;Flamine Alary;Patrice Voss;Yi-Yu Chou;Caroline C. Brun;Marina Barysheva;Arthur W. Toga;Paul M. Thompson	2007	2007 Frontiers in the Convergence of Bioscience and Information Technologies	10.1109/FBIT.2007.52	topology;tractography;mathematics;geometry;tensor density;nuclear magnetic resonance	Vision	44.44508455256196	-79.19587334378383	19979
32b2853f8bff14f8425a428fd736972c98ac325a	multiscale keypoint analysis with triangular biorthogonal wavelets via redundant lifting	multiscale keypoint analysis uniform distribution cumulative local energy distribution multiscale decomposition isotropic directional components redundant lifting triangular biorthogonal wavelets;redundant transform keypoint discrete wavelet transform triangular lattice lifting;image processing discrete wavelet transforms;lattices discrete wavelet transforms image edge detection feature extraction signal resolution	This paper presents an efficient approach for multiscale keypoint detection based on triangular biorthogonal wavelets. The detection scheme is simple and thus fast as only three isotropic directional components of an image obtained by multiscale decomposition with the triangular biorthogonal wavelets are used for keypoint localization at each scale. Redundant lifting is also considered and can be applied directly to calculate cumulative local energy distribution that is derived from the correction of the three directional components at each scale. This gives the efficient and accurate localization of keypoints including scale information. An experimental result shows that our method is better in the sense of the uniform distribution of keypoints compared with the conventional wavelet-based approach.	lifting scheme;wavelet	Kensuke Fujinoki	2014	2014 22nd European Signal Processing Conference (EUSIPCO)		wavelet;computer vision;mathematical optimization;discrete mathematics;second-generation wavelet transform;mathematics;discrete wavelet transform;lifting scheme	Vision	51.38661373967518	-66.00794517590451	20004
74b7f180e7f941fd8a1786dec07e9a52cbbdf3ad	calculation of bedding angles inclination from drill core digital images	image analysis;hough transform;digital image	In this paper, we describe a new technique for the automatic orientation of bedding in drill core from digital images. Images are planar pictures of the drill core, and we show that it is possible to determine layer orientation without rotating the core on the full circumference. More precisely, we show that angle information can be extracted by applying image processing and a mathematical description of bedding trace on the core. The angles’ estimation is done by adapting the Hough transform technique. This work is part of a more important project of our laboratory that aims to develop a drill core image analysis software.	anomaly detection;core image;digital image;hough transform;image analysis;image processing;maxima;planar (computer graphics);raw image format	Thomas Quiniou;Nazha Selmaoui-Folcher;Christine Laporte-Magoni;Michel Allenbach	2007			hough transform;computer vision;image analysis;computer science;digital image;computer graphics (images)	Graphics	43.514982173687045	-69.36941529420466	20027
c91c30087880291f5809efe4f7f3a27dba86fafb	a framework for optimizing measurement weight maps to minimize the required sample size	clinical data;image features;sample size;weight map;data collection;numerical optimization;magnetic resonance image;articular cartilage;cartilage;osteoarthritis;magnetic resonance imaging;clinical study;synthetic data	We propose a fully automatic statistical framework for identifying the non-negative, real-valued weight map that best discriminate between two groups of objects. Given measurements on a spatially defined grid, a numerical optimization scheme is used to find the weight map that minimizes the sample size required to discriminate the two groups. The weight map produced by the method reflects the relative importance of the different areas in the objects, and the resulting sample size reduction is an important end goal in situations where data collection is difficult or expensive. An example is in clinical studies where the cost and the patient burden are directly related to the number of participants needed for the study. In addition, inspection of the weight map might provide clues that can lead to a better clinical understanding of the objects and pathologies being studied. The method is evaluated on synthetic data and on clinical data from knee cartilage MRI. The clinical data contain a total of 159 subjects aged 21-81 years and ranked from zero to four on the Kellgren-Lawrence osteoarthritis severity scale. Compared to a uniform weight map, we achieve sample size reductions up to 58% for cartilage thickness measurements. Based on quantifications from both morphometric and textural based imaging features, we also identify the most pathological areas in the articular cartilage.		Arish A. Qazi;Dan R. Jørgensen;Martin Lillholm;Marco Loog;Mads Nielsen;Erik Dam	2010	Medical image analysis	10.1016/j.media.2010.01.004	sample size determination;radiology;pathology;magnetic resonance imaging;mathematics;feature;statistics;synthetic data;data collection	ML	33.265684563017246	-79.63718961191171	20053
2227e7d972ab2716fbb9b7c2d7ce54ca484a5c2c	feature matching by searching maximum clique on high order association graph	obstacle detection feature matching searching high order association graph computer vision subgraph isomorphism relational graphs node representation projective invariant values maximum edge weighted clique planar 3d surface reconstruction autonomous moving vehicle;moving object;graph theory;projective invariant values;obstacle detection;maximum clique problem;image matching;planar 3d surface reconstruction;vehicle detection;mobile robots;remotely operated vehicles;feature matching;surface reconstruction;searching;computer vision joining processes equations surface reconstruction land vehicles remotely operated vehicles road vehicles mobile robots object detection vehicle detection;higher order;computer vision;autonomous moving vehicle;maximum clique;robot vision;robot vision feature extraction image matching graph theory image reconstruction search problems image representation object detection mobile robots collision avoidance;image representation;feature extraction;image reconstruction;relational graphs;land vehicles;dynamic equation;joining processes;high order association graph;search problems;collision avoidance;node representation;point of view;object detection;maximum edge weighted clique;road vehicles;subgraph isomorphism	In this work we consider the most important problem in computer vision of performing matching among elementary features of objects when observed from different points of view. We formulate the problem in terms of subgraph isomorphism between relational graphs characterized by nodes representing interested object features and linking edges weighted by projective invariant values. The matching involves determination of all nodes in the association graph mutually compatible according to the similarity of the imposed invariant relations encoded on the edges. The solution requires us to determine subsets of nodes totally interconnected by edges with highest weights. Moreover, in most contexts, relations among more than two features can be involved, giving rise to association graphs of higher order. Recently it has been recognized that a particular class of dynamical equations are able to solve the maximum clique problem in an optimal manner. In our work, we have extended and applied such results to solve the most general problem of searching for the maximum edge-weighted clique on high-order association graphs. Moreover we have applied the method to a classical problem in computer vision of planar 3D surface reconstruction which is of fundamental importance for an autonomous moving vehicle in order to accomplish some elementary tasks, such as detection of ground floor obstacles or independent moving objects.	clique (graph theory)	Antonella Branca;Ettore Stella;Arcangelo Distante	1999		10.1109/ICIAP.1999.797669	iterative reconstruction;remotely operated underwater vehicle;mobile robot;computer vision;combinatorics;higher-order logic;surface reconstruction;feature extraction;computer science;graph theory;machine learning;subgraph isomorphism problem;mathematics;induced subgraph isomorphism problem;maximum common subgraph isomorphism problem	DB	49.784384594132334	-52.55278234007924	20073
2e627d234ee261917544882fa3e7de600b2f9e39	carved visual hulls for image-based modeling	complex shape;modelizacion;dynamic programming;iterative method;image tridimensionnelle;programacion dinamica;modele geometrique;silhouette;image processing;geometrie solide;coupe graphe;procesamiento imagen;geometria solidos;dynamic program;image based modeling;traitement image;multiple view;metodo iterativo;modelisation;refinement method;corte grafo;forma compleja;methode iterative;graph cut;solid modeling;silhouettes;programmation dynamique;visual hull graph cuts;visual hull;stereo;vue multiple;multi view stereo;tridimensional image;global optimization;methode raffinement;geometric constraints;modeling;multi view;metodo afinamiento;graph cuts;forme complexe;solid geometry;silueta;imagen tridimensional;vista multiple;geometrical model;rim;surface approximation;modelo geometrico	This article presents a novel method for acquiring high-quality solid models of complex 3D shapes from multiple calibrated photographs. After the purely geometric constraints associated with the silhouettes found in each image have been used to construct a coarse surface approximation in the form of a visual hull, photoconsistency constraints are enforced in three consecutive steps: (1) the rims where the surface grazes the visual hull are first identified through dynamic programming; (2) with the rims now fixed, the visual hull is carved using graph cuts to globally optimize the photoconsistency of the surface and recover its main features; (3) an iterative (local) refinement step is finally used to recover fine surface details. The proposed approach has been implemented, and experiments with seven real data sets are presented, along with qualitative and quantitative comparisons with several state-of-the-art image-based-modeling algorithms.	algorithm;approximation;baseline (configuration management);bundle adjustment;cut (graph theory);dynamic programming;experiment;iterative method;lambertian reflectance;photogrammetry;refinement (computing);sparse matrix;visual hull	Yasutaka Furukawa;Jean Ponce	2008	International Journal of Computer Vision	10.1007/s11263-008-0134-8	computer vision;cut;image processing;solid geometry;mathematics;geometry;global optimization	Vision	51.27117391421422	-56.46766090455373	20089
e02c10c13cbface90b40a4950e302d5dcdfa0a07	a study of friction ridge distortion effect on automated fingerprint identification system - database evaluation		Fingerprint identification is an important part of forensic science (e.g. criminal investigations or identity verification). Friction ridge impressions left at the crime scene can be affected by the nonlinear distortion due to elasticity of the skin, pressure changes or finger movement during deposition. These deformations affect relative distances between fingerprint features such as minutiae point, ridge frequency and orientation, which eventually leads to difficulties in establishing a positive match between impressions of the same finger.	automated fingerprint identification;distortion	Lukasz Hamera;Lukasz Wieclaw	2018		10.1007/978-3-319-99954-8_3	ridge;crime scene;fingerprint;computer science;artificial intelligence;nonlinear distortion;pattern recognition;automated fingerprint identification;distortion;minutiae	Vision	32.10766254787123	-63.02623391123334	20255
f9a0bf6f12681ef7d2dd9851f8e3a34d8b1bcce0	wavelet-based despeckling of medical ultrasound images with the symmetric normal inverse gaussian prior	normal inverse gaussian distribution;medical ultrasound images;medical ultrasonography;symmetric normal inverse gaussian distribution;image processing;gaussian processes;normal inverse gaussian;homomorphic framework;bayes methods;speckle noise;visual quality symmetric normal inverse gaussian prior medical ultrasound images wavelet based despeckling medical ultrasonography speckle noise automatic image processing tasks bayesian wavelet based maximum a posteriori denoiser homomorphic framework local neighbors signal to noise ratio;maximum likelihood estimation;visual quality;bayesian maximum a posteriori estimator;wavelet transforms;ultrasound imaging;ultrasound image;wavelet transform;automatic image processing tasks;local neighbors;medical image processing;wavelet transforms bayes methods biomedical ultrasonics gaussian processes image denoising maximum likelihood estimation medical image processing;wavelet based despeckling;bayesian maximum a posteriori estimator ultrasound image speckle noise wavelet transform symmetric normal inverse gaussian distribution;bayesian wavelet based maximum a posteriori denoiser;ultrasonography;image denoising;signal to noise ratio;symmetric normal inverse gaussian prior;biomedical imaging ultrasonic imaging medical diagnostic imaging ultrasonography speckle image processing bayesian methods wavelet coefficients reflectivity signal to noise ratio;biomedical ultrasonics	A major problem in medical ultrasonography is the inherent corruption of ultrasound images with speckle noise that severely hampers the diagnosis and automatic image processing tasks. In this paper, an efficient wavelet-based method is proposed for despeckling medical ultrasound images. A closed-form Bayesian wavelet-based maximum a posteriori denoiser is developed in a homomorphic framework, based on modelling the wavelet coefficients of the log-transform of the reflectivity with a symmetric normal inverse Gaussian (SNIG) prior. A simple method is presented for obtaining the parameters of the SNIG prior using local neighbors. Thus, the proposed method is spatially adaptive. Experiments are carried out using synthetically speckled and real ultrasound images, and the results show that the proposed method performs better than several other existing methods in terms of the signal-to-noise ratio and visual quality.	adaptive histogram equalization;coefficient;experiment;image processing;medical ultrasound;noise reduction;signal-to-noise ratio;wavelet	Md. Imamul Hassan Bhuiyan;M. Omair Ahmad;M. N. Shanmukha Swamy	2007	2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07	10.1109/ICASSP.2007.366009	computer vision;ultrasonography;pattern recognition;mathematics;statistics;wavelet transform	Robotics	50.60581496349422	-76.39066394160916	20259
445aae6346c7d84aab8dd4ae5b7fffcd50fc601f	ein wissensbasiertes system zur automatischen extraktion von semantischen informationen aus digitalen fernerkundungsdaten		The aim of this thesis is to take a close look at the possibilities for automatic extraction of semantic information from remote sensing data. The approach deals both with the aspects of extraction of special types of objects by using image processing operators and further processing of these results on a symbolic level. The operative system that has been developed integrates a priori knowledge and semantic features of the objects to generate a consistent overall interpretation of a scene presented in digital form. The hierarchical interpretation employs previous knowledge of the objects and their geometrical, topographical and radiometric form in the different remote sensors as well as the topological relations between the objects. The hierarchical approach focusses the viewing of large format structures down to smaller details. This hierarchy increases the efficiency of the analysis, since for one object of a certain detail level only associated sub-hypothesis have to be generated. Each hypothesis consists of a holistic and a structural method. The related applications of these methods are called by a problem-independent analysis process. The holistic part comprises an image processing operator that is specific to the hypothesis’ class of objects. The parameters of the operator are adapted to the actual context of the object extraction. The structural verification values and groups the sub-hypotheses with regard to a more abstract form. The knowledge that is used, is introduced in form of a semantic net. This explicit form of represented knowledge offers a structured description of the knowledge base. Available knowledge from already existing interpretations or geographical databases can be integrated into the analysis. The integration of multi-sensorial and multi-spectral data, even with different resolutions, is consequently processed in the system.	database;holism;image processing;interpretation (logic);knowledge base;metric;operating system;semantic network;sensor;topography	Jürgen Bückner	2003				DB	47.685606264049895	-60.78457946134702	20332
4830eba7379fb9ad1d8f26aeed4092c5b5fb8cb8	unified layout analysis and text localization framework	databases;image segmentation;edge detection;visualization	A technique appropriate for extracting textual information from documents with complex layouts, such as newspapers and journals, is presented. It is a combination of a foreground analysis and a text localization method. The first one is used to segment the page in text and nontext blocks, whereas the second one is used to detect text that may be embedded inside images, charts, diagrams, tables, etc. Detailed experiments on two public databases showed that mixing layout analysis and text localization techniques can lead to improved page segmentation and text extraction results.		Nikos Vasilopoulos;Ergina Kavallieratou	2017	J. Electronic Imaging	10.1117/1.JEI.26.1.013009	computer vision;visualization;edge detection;computer science;pattern recognition;image segmentation;scale-space segmentation;information retrieval	Theory	36.541944101475735	-65.47797309226839	20367
7ceef645cb31dad57f123282bfc0286db5e8fd6a	canny edge detection enhancement by scale multiplication	scale multiplication;algorithms artificial intelligence image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval pattern recognition automated signal processing computer assisted subtraction technique;methode echelle multiple;edge detection;image synthetique;multiscale analysis;metodo escala multiple;indexing terms;multiplication echelle;deteccion contorno;detection contour;image enhancement;image enhancement edge detection;detection filter canny edge detection enhancement scale multiplication edge maps detection criterion localization criterion;pattern recognition;image edge detection finite impulse response filter detectors gaussian processes noise robustness signal synthesis filtering noise reduction signal detection gaussian noise;index terms edge detection;multiscale method;multiscale analysis index terms edge detection scale multiplication;reconnaissance forme;reconocimiento patron	The technique of scale multiplication is analyzed in the framework of Canny edge detection. A scale multiplication function is defined as the product of the responses of the detection filter at two scales. Edge maps are constructed as the local maxima by thresholding the scale multiplication results. The detection and localization criteria of the scale multiplication are derived. At a small loss in the detection criterion, the localization criterion can be much improved by scale multiplication. The product of the two criteria for scale multiplication is greater than that for a single scale, which leads to better edge detection performance. Experimental results are presented.	canny edge detector;detectors;edge detection;experiment;map;maxima and minima;multiplication;synthetic intelligence;thresholding (image processing);hearing impairment	Paul Bao;Lei Zhang;Xiaolin Wu	2005	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2005.173	computer vision;speech recognition;edge detection;index term;computer science;theoretical computer science;pattern recognition;mathematics;canny edge detector	Vision	53.74494571145923	-66.83523148223863	20434
12f81b51a01afcf81e5447f0e9a831683a7bec3f	a probabilistic approach to simultaneous segmentation, object recognition, 3d localization, and tracking using stereo	vision system;object recognition;vision ordenador;analisis escena;pistage;analyse scene;image segmentation;modelo 3 dimensiones;modele 3 dimensions;localization;occultation;environmental conditions;rastreo;three dimensional model;localizacion;robotics;probabilistic approach;computer vision;stereophonie;localisation;segmentation image;tomographie;stereophony;service robot;pattern recognition;robotica;vision ordinateur;vision artificielle;robotique;reconnaissance forme;reconocimiento patron;ocultacion;tomografia;artificial vision;tomography;estereofonia;tracking;scene analysis;vision artificial	Vision systems for service robotics applications have to cope with varying environmental conditions, partial occlusions, complex backgrounds and a large number of distractors (clutter) present in the scene. This paper presents a new approach targeted at such application scenarios that combines segmentation, object recognition, 3D localization and tracking in a seamlessly integrated fashion. The unifying framework is the probabilistic representation of various aspects of the scene. Experiments indicate that this approach is viable and gives very satisfactory results.	clutter;condensation algorithm;experiment;feature extraction;mathematical model;memory segmentation;mobile manipulator;outline of object recognition;robotics;statistical model;stereoscopy;testbed;wavelet	Georg von Wichert	2001		10.1007/3-540-45404-7_14	computer vision;simulation;internationalization and localization;occultation;computer science;cognitive neuroscience of visual object recognition;tracking;tomography;image segmentation	Robotics	47.64801740782863	-57.82569474743448	20476
82e289f8c62970f24ee9b524ee123a6d0a77283d	computer-aided diagnosis system for tissue characterization of brain tumor on magnetic resonance images		The manual analysis of brain tumor on magnetic resonance (MR) images is time-consuming and subjective. Thus, to avoid human errors in brain tumor diagnosis, this paper presents an automatic and accurate computer-aided diagnosis (CAD) system based on ensemble classifier for the characterization of brain tumors on MR images as benign or malignant. Brain tumor tissue was automatically extracted from MR images by the proposed segmentation technique. A tumor is represented by extracting its texture, shape, and boundary features. The most significant features are selected by using information gain-based feature ranking and independent component analysis techniques. Next, these features are used to train the ensemble classifier consisting of support vector machine, artificial neural network, and \(k\)-nearest neighbor classifiers to characterize the tumor. Experiments were carried out on a dataset consisting of T1-weighted post-contrast and T2-weighted MR images of 550 patients. The developed CAD system was tested using the leave-one-out method. The experimental results showed that the proposed segmentation technique achieves good agreement with the gold standard and the ensemble classifier is highly effective in the diagnosis of brain tumor with an accuracy of 99.09 % (sensitivity 100 % and specificity 98.21 %). Thus, the proposed system can assist radiologists in an accurate diagnosis of brain tumors.	resonance	Megha P. Arakeri;G. Ram Mohana Reddy	2015	Signal, Image and Video Processing	10.1007/s11760-013-0456-z	computer vision	ML	34.67396319621845	-76.6909806335071	20480
2574be27eb48a3b07778680b846b220274bc4c62	a versatile model-based visibility measure for geometric primitives	model based reasoning;visibilite;g740 computer vision;visibilidad;industrie automobile;raisonnement base sur modele;image processing;capsula convexa;automotive industry;h670 robotics and cybernetics;procesamiento imagen;traitement image;enveloppe convexe;visibility;industria automovil;convex hull;automobile industry	In this paper, we introduce a novel model-based visibility measure for geometric primitives called visibility map. It is simple to calculate, memory efficient, accurate for viewpoints outside the convex hull of the object and versatile in terms of possible applications. Several useful properties of visibility maps that show their superiority to existing visibility measures are derived. Various example applications from the automotive industry where the presented measure is used successfully conclude the paper.	convex hull;geometric primitive;lookup table;map;outline of object recognition;rendering (computer graphics);viewing cone	Marc M. Ellenrieder;Lars Krüger;Dirk Stößel;Marc Hanheide	2005		10.1007/11499145_68	computer vision;simulation;image processing;computer science;automotive industry;artificial intelligence	Vision	49.92826296074119	-58.24817889786253	20498
160acdb1af2b3982d5134ef309ed2a51d53bf862	a new approach of gray images binarization for artificial vision systems with threshold methods		This paper presents some aspects of the (gray level) image binarization methods used in artificial vision systems. It is introduced a new approach of gray level image binarization for artificial vision systems dedicated to the specific class of applications for moving scene in industrial automation – temporal thresholding. In the first part of the paper are remarked some limitations of using the global optimum thresholding in gray level image binarization. In the second part of this paper are presented some aspects of the dynamic optimum thresholding method for gray level image binarization. In the third section are introduced the concepts of temporal histogram and temporal thresholding, starting from classic methods of global and dynamic optimal thresholding of the gray level images. In the final part are presented some practical aspects of the temporal thresholding method in artificial vision applications for the moving scene in robotic automation class; highlighting the influence of the acquisition frequency on the methods results. 1 IMAGE BINARIZATION WITH GLOBAL THRESHOLD Threshold methods are defined as starting from the analyse of the values of a function T of the type: T = T [x, y, p(x, y), f(x, y)] (1) Where: f(x, y) – represents the intensity value of the image element located on the co-ordinates (x, y); p(x,y) – represents the local properties of the specific point (like the average intensity of a region centred in the co-ordinates (x, y)). T – is the binarization threshold The goal is to obtain from an original gray level image, a binary image g(x, y) defined by: ⎩⎨ ⎧ ≤ > = T y x f T y x f y x g ) , ( for 0 ) , ( for 1 ) , ( (2) For T a function only of f(x, y), the obtained threshold is called global threshold. In the case of T a function of both f(x, y) and p(x, y), the obtained threshold is named local threshold. In the case of T a function of all f(x, y), p(x, y), x and y, the threshold is a dynamic threshold. 1.1 Intensity Level on Normal Distribution Assumption Gray level histogram represents the probability density function of the intensity values of the image. In order to simplify the explanations, we suppose the image histogram of the gray levels is composed from two values combined with additive Gaussian noise: The first segment of the image histogram corresponds to the background points – the intensity levels are closer to the lower limit of the range (the background is dark) The second segment of the image histogram corresponds to the object points – the intensity levels are closer to the upper limit of the intensity range (the objects are bright). The problem is to estimate a value of the threshold T for which the image elements with an intensity value lower than T will contain background points and the pixels with the intensity value greater than T will contain object points, with a minimum error. For a real image, the partitioning between the 11 Hossu A. and Hossu D. (2008). A NEW APPROACH OF GRAY IMAGES BINARIZATION FOR ARTIFICIAL VISION SYSTEMS WITH THRESHOLD METHODS. In Proceedings of the Fifth International Conference on Informatics in Control, Automation and Robotics RA, pages 11-16 DOI: 10.5220/0001477200110016 Copyright c © SciTePress two brightness levels is not so simple and also not so accurate. The partitioning is fully accurate only if the two modes of the bimodal histogram are not overlapped. The classification is defined as the process of the distribution of the pixels in classes. The goal of the binarization process is the minimisation of the error of classification. The optimum binarization threshold is located in the intersection position of the two normal distributions. The estimation of the error of classification is obtained from the area of the overlapped segments: image size B A E + = (3) Suppose the image contains two intensity level values affected with additive Gaussian noise. The mixture probability density function is: ) ( ) ( ) ( 2 2 1 1 x p P x p P x p + = (4) Where: x – the random value representing the intensity level, p1(x), p2(x) – are the probability density functions, P1, Pp2are the a priori probabilities of the two intensity levels (P1 +P2= 1). For the normal distribution case on the two brightness levels:	binary image;computer vision;gaussian blur;global optimization;grayscale;html element;image histogram;image resolution;informatics;pixel;robotic automation software;robotics;thresholding (image processing);traffic collision avoidance system;utility functions on indivisible goods	Andrei Hossu;Daniela Hossu	2008			engineering;control theory;coupling;push–pull output;data transmission;mode (statistics);integrated circuit;computer vision;electrical engineering;open collector;artificial intelligence	Robotics	46.252719748067534	-65.63002372152695	20550
ad58610e04b2354f710050a0be9415b21b1809f7	accurate localization of edges in noisy volume images	edge detection;medical image;gaussian function edge localisation noisy volume images medical imaging 3d edge detection gaussian detector;medical image processing;gaussian distribution medical image processing edge detection stereo image processing noise;stereo image processing;image edge detection detectors image processing space technology biomedical imaging magnetic resonance imaging joining processes satellite navigation systems australia laplace equations;gaussian distribution;noise	Advances in medical imaging modalities have made it possible to acquire volume images. One of the key steps used to split the raw volume image into meaningful sub-volumes is 3D edge detection. This paper describes a new approach for 3D edge detection. It is based on the 2D hybrid edge detector, which consists of a combination of the first and second order differential edge detectors. It was shown in the 2D case that the combination of the two differential edge detectors gave an accurate edge localisation whilst maintaining immunity to the noise in the image. Results using the 3D hybrid edge detector based on synthetic and real images are presented. They are also compared to the results using the 3D gradient of the Gaussian detector and the 3D Laplacian of the Gaussian detector.		Pi-chi Chou;Mohammed Bennamoun	2000		10.1109/ICPR.2000.903028	normal distribution;computer vision;feature detection;scale space;edge detection;image gradient;image processing;computer science;noise;morphological gradient;deriche edge detector;gaussian blur;digital image processing;mathematics;canny edge detector;marr–hildreth algorithm	Vision	48.28972615615463	-75.35523288072227	20590
d9f0640716ec25278e6f1a4fdda5596660504c54	a correlated parts model for object detection in large 3d scans	computer graphics i 3 5 computational geometry and object modeling object hierarchies;object recognition;image processing and computer vision i 4 8;artificial intelligence i 2 10;image processing and computer vision i 4 8 scene analysis object recognition;shape;object hierarchies;artificial intelligence i 2 10 vision and scene understanding shape;computational geometry and object modeling;vision and scene understanding;computer graphics i 3 5;scene analysis	This paper addresses the problem of detecting objects in 3D scans according to object classes learned from sparse user annotation. We model objects belonging to a class by a set of fully correlated parts, encoding dependencies between local shapes of different parts as well as their relative spatial arrangement. For an efficient and comprehensive retrieval of instances belonging to a class of interest, we introduce a new approximate inference scheme and a corresponding planning procedure. We extend our technique to hierarchical composite structures, reducing training effort and modeling spatial relations between detected instances. We evaluate our method on a number of real-world 3D scans and demonstrate its benefits as well as the performance of the new inference algorithm.	3d film;3d printing;approximation algorithm;blackwell (series);data transfer object;eurographics;experiment;instance (computer science);maxima and minima;microsoft windows;object detection;scalability;sensor;sparse matrix;test set;thread (computing)	Martin Sunkel;Silke Jansen;Michael Wand;Hans-Peter Seidel	2013	Comput. Graph. Forum	10.1111/cgf.12040	computer vision;method;image-based modeling and rendering;deep-sky object;object model;shape;computer science;theoretical computer science;cognitive neuroscience of visual object recognition;machine learning;mathematics;geometry;3d single-object recognition;computer graphics (images)	ML	36.948140346953274	-53.17924148455186	20624
5e2ce58291aad139a4fc0c1371801473947f2c88	diagnosis of lung nodule using independent component analysis in computerized tomography images	pulmonary nodule;independent component analysis;lung nodule diagnosis;computerized tomography;texture analisys;support vector machine	This paper analyzes the application of Independent Component Analysis to the characterization of lung nodules as malignant or benign in computerized tomography images. The characterization method is based on a process that verifies which combination of measures, from the proposed measures, has been best able to discriminate between the benign and malignant nodules using Support Vector Machine. In order to verify this application we also describe tests that were carried out using a sample of 38 nodules: 29 benign and 9 malignant. The methodology reaches 100% of Specificity, 98.34% of Sensitivity and 96.66% of accuracy. Thus, preliminary results of this approach are very promising in contributing to pulmonary nodules diagnosis, but it will be necessary to test it in larger series and to make associations with other quantitative imaging methods in order to improve global performance.	ct scan;independent component analysis;tomography	Cristiane C. S. da Silva;Daniel Duarte Costa;Aristófanes Corrêa Silva;Allan Kardec Barros	2007		10.1007/978-3-540-69162-4_55	independent component analysis;support vector machine;computer science;machine learning	ML	34.43600073679371	-76.13137189706904	20709
72954f681a30ce3d8416086357cb85bbb20e3b7a	sensitivity analysis of mapping local image features into conceptual categories	etude utilisation;image features;analisis estadistico;automatic image annotation;estudio utilizacion;image database;image classification;image;result;independent component analysis;image annotation;texture features;representacion de las informaciones;carta de datos;region segmentation;statistical analysis;machine learning;indexing;imagen;sensitivity analysis;local features;feature extraction;mappage;indexation;information representation;analyse statistique;indizacion;resultado;feature selection;ground truth;principle component analysis;mapping;resultat;representation information;use study;design methodology;image retrieval	Purpose – Image classification or more specifically, annotating images with keywords is one of the important steps during image database indexing. However, the problem with current research in terms of image retrieval is more concentrated on how conceptual categories can be well represented by extracted, low level features for an effective classification. Consequently, image features representation including segmentation and low‐level feature extraction schemes must be genuinely effective to facilitate the process of classification. The purpose of this paper is to examine the effect on annotation effectiveness of using different (local) feature representation methods to map into conceptual categories.Design/methodology/approach – This paper compares tiling (five and nine tiles) and regioning (five and nine regions) segmentation schemes and the extraction of combinations of color, texture, and edge features in terms of the effectiveness of a particular benchmark, automatic image annotation set up. Differen...		Chih-Fong Tsai;David C. Yen	2008	Library Hi Tech	10.1108/07378830810880351	image texture;independent component analysis;computer vision;search engine indexing;contextual image classification;feature detection;design methods;ground truth;feature extraction;computer science;image;pattern recognition;data mining;automatic image annotation;sensitivity analysis;feature;principal component analysis	Logic	43.39499063490293	-61.54677914919831	20752
ae1fdc607b12382f107a53ef6decccae401c4d38	adaptive sharpening of multimodal distributions	computer vision and robotics autonomous systems;histograms;kernel;standards;iterative decoding;datorseende och robotik autonoma system;kernel standards sociology smoothing methods iterative decoding histograms;medicinsk bildbehandling;smoothing methods;population code adaptive sharpening multimodal distribution gauss markov theorem estimation theory monomodal gaussian distribution standard error standard deviation image processing gray value color distribution displacement distribution motion estimation channel representation histogram;medical image processing;image processing error analysis estimation theory gaussian distribution;signal restoration probability density function signal reconstruction;sociology	In this work we derive a novel framework rendering measured distributions into approximated distributions of their mean. This is achieved by exploiting constraints imposed by the Gauss-Markov theorem from estimation theory, being valid for mono-modal Gaussian distributions. It formulates the relation between the variance of measured samples and the so-called standard error, being the standard deviation of their mean. However, multi-modal distributions are present in numerous image processing scenarios, e.g. local gray value or color distributions at object edges, or orientation or displacement distributions at occlusion boundaries in motion estimation or stereo. Our method not only aims at estimating the modes of these distributions together with their standard error, but at describing the whole multi-modal distribution. We utilize the method of channel representation, a kind of soft histogram also known as population codes, to represent distributions in a non-parametric, generic fashion. Here we apply the proposed scheme to general mono- and multimodal Gaussian distributions to illustrate its effectiveness and compliance with the Gauss-Markov theorem.	approximation algorithm;code;displacement mapping;estimation theory;experiment;image processing;markov chain;modal logic;motion estimation;multimodal interaction;numerical analysis;numerical integration;standard streams	Freddie Åström;Michael Felsberg;Hanno Scharr	2015	2015 Colour and Visual Computing Symposium (CVCS)	10.1109/CVCS.2015.7274890	computer vision;mathematical optimization;mathematics;statistics	Vision	51.49492155836673	-70.41654944370633	20754
37b5e40c42ef9e247171893e1179fb0034a1e153	automatically computed markers for the 3d watershed segmentation	skeleton graph mesh segmentation watershed transformation markers;image segmentation;skeleton shape covariance matrix application software computer graphics visualization reverse engineering semiconductor device modeling iterative methods floods;computer graphics;indexing terms;markers;watershed transform;mesh generation computer graphics image segmentation;watershed segmentation;mesh segmentation;skeleton graph;mesh generation;mesh segmentation automatically computed marker 3d watershed transformation;watershed transformation	This paper presents a new approach to the mesh segmentation based on watershed transformation. We propose an original method to compute markers from the topological information of the mesh. The skeleton of the mesh allows the interpretation of the meaningful parts and the watershed transformation builds the boundaries of theses parts. Our method, which combines the patch-type and the part-type segmentation approaches, is particularly well adapted to the problematic of meaningful part segmentation.	watershed (image processing)	Sébastien Delest;Romuald Boné;Hubert Cardot	2007	2007 IEEE International Conference on Image Processing	10.1109/ICIP.2007.4379639	computer vision;watershed;computer science;theoretical computer science;machine learning;segmentation-based object categorization;image segmentation;scale-space segmentation;computer graphics (images)	Robotics	46.65415945044824	-70.71430914170634	20792
da7d75a156161f13d1e8b6462bc381a700595b7e	image thresholding using ant colony optimization	image segmentation;ant colony optimization;image processing;design engineering;null;gray scale;systems engineering and theory;ant colony optimization image segmentation pixel image processing algorithm design and analysis design engineering systems engineering and theory gray scale machine vision humans;machine vision;pixel;humans;algorithm design and analysis	This study is an investigation of the application of ant colony optimization to image thresholding. This paper presents an approach where one ant is assigned to each pixel of an image and then moves around the image seeking low grayscale regions. Experimental results demonstrate that the proposed ant-based method performs better than other two established thresholding algorithms. Further work must be conducted to optimize the algorithm parameters, improve the analysis of the pheromone data and reduce computation time. However, the study indicates that an ant-based approach has the potential of becoming an established image thresholding technique.	algorithm;ant colony optimization algorithms;computation;grayscale;mathematical optimization;pixel;thresholding (image processing);time complexity	Alice R. Malisia;Hamid R. Tizhoosh	2006	The 3rd Canadian Conference on Computer and Robot Vision (CRV'06)	10.1109/CRV.2006.42	algorithm design;computer vision;feature detection;ant colony optimization algorithms;machine vision;image processing;computer science;artificial intelligence;machine learning;balanced histogram thresholding;thresholding;image segmentation;pixel;grayscale	Vision	43.0232829961914	-68.50393249887124	20840
398b7d89dd25e013e61bbc85360ca917b4a72e87	analysis of time domain information for footstep recognition	conferenceobject;time domain;bookpart	This paper reports an experimental analysis of footsteps as a biometric. The focus here is on information extracted from the time domain of signals collected from an array of piezoelectric sensors. Results are related to the largest footstep database collected to date, with almost 20,000 valid footstep signals and more than 120 persons, which is well beyond previous related databases. Three feature approaches have been extracted, the popular ground reaction force (GRF), the spatial average and the upper and lower contours of the pressure signals. Experimental work is based on a veri cation mode with a holistic approach based on PCA and SVM, achieving results in the range of 5 to 15% EER depending on the experimental conditions of quantity of data used in the reference models.	biometrics;database;enhanced entity–relationship model;holism;piezoelectricity;principal component analysis;sensor	Rubén Vera-Rodríguez;John S. D. Mason;Julian Fiérrez;Javier Ortega-Garcia	2010		10.1007/978-3-642-17289-2_47	computer vision;speech recognition;time domain;computer science;data mining	ML	31.848609800020427	-60.27496488757054	20861
0dea5fe1d36caf8a931f487fac712ee2dd6059e9	machine vision algorithms on a color blindness plate	human visual system;machine vision;pattern recognition	This paper presents a new approach including passive and actrive processes to deal with the image segmentation and pattern recognition to a color blindness plate (CBP). The CBP is well-known satisfactory way of testing the degree of color blindness happened in the human visual system. The image of CBP is very complex. It includes not only the colors but also the disconnected size-varied dots. It is very difficult by using a conventional machine vision algorithm to recognize the meaningful pattern (e.g., a figure) from such a CBP image. The proposed machine vision algorithms provide a new solution to this problem.	algorithm;color;image segmentation;machine vision;pattern recognition	Yung-Sheng Chen;Yu-Chang Hsu	1994			computer vision;machine vision;computer science;artificial intelligence;human visual system model;computer graphics (images)	Vision	45.62152295492464	-66.17427149118039	20865
35842a91d7c8a6ad405d2ecd3157f84602ea496f	algorithm performance contest	performance measure;image recognition;misdetection rates binary shape recognition symbol recognition image flow estimation groundtruth confusion matrices false alarm rates;technology;confusion matrices;groundtruth;false alarm rate;shape recognition;noise generators;teknikvetenskap;testing;packaging;binary shape recognition;computer vision;misdetection rates;engineering and technology;teknik och teknologier;shape;image sequences computer vision image recognition;intelligent systems;sun;pattern recognition;false alarm rates;noise shaping;computer science;image flow estimation;image sequences;symbol recognition;shape noise shaping image recognition packaging testing noise generators intelligent systems laboratories computer science sun	This contest involved the running and evaluation of computer vision and pattern recognition techniques on different data sets with known groundtruth. The contest included three areas; binary shape recognition, symbol recognition and image flow estimation. A package was made available for each area. Each package contained either real images with manual groundtruth or programs to generate data sets of ideal as well as noisy images with known groundtruth. They also contained programs to evaluate the results of an algorithm according to the given groundtruth. These evaluation criteria included the generation of confusion matrices, computation of the misdetection and false alarm rates and other performance measures suitable for the problems. This paper summarizes the data generation for each area and experimental results for a total of six participating algorithms.	algorithm;computation;computer vision;confusion matrix;handwriting recognition;pattern recognition	Selim Aksoy;Ming Ye;Michael L. Schauf;Mingzhou Song;Yalin Wang;Robert M. Haralick;Jim R. Parker;Juraj Pivovarov;Dominik Royko;Changming Sun;Gunnar Farnebäck	2000		10.1109/ICPR.2000.903054	computer vision;speech recognition;noise shaping;intelligent decision support system;shape;computer science;machine learning;technology	Vision	31.169995403917195	-68.86283252918616	20887
ee87aa52d9642607d86f011c0d7326c4bdc63121	automatic detection of facial midline as a guide for facial feature extraction	facial feature extraction;automatic detection	We propose a novel approach for the detection of the facial midline from a frontal face image. The use of a midline as a guide reduces the computation time required for facial feature extraction (FFE) because midline is able to restrict multi-dimensional searching process into one-dimensional search. The proposed method detects facial midline from the edge image as the symmetry axis using a new application of the the generalized Hough transformation to detect the symmetry axis. Experimental results on the FERET database indicate that the proposed algorithm can accurately detect facial midline over many different scales and rotation. The total computational time for facial feature extraction has been reduced by a factor of 280 using midline detected by this method.	algorithm;apache axis;computation;feret (facial recognition technology);feret database;feature extraction;hough transform;time complexity	Nozomi Nakao;Wataru Ohyama;Tetsushi Wakabayashi;Fumitaka Kimura	2007			computer science	Vision	42.046725502796086	-58.278797038162274	20907
f8a750e63e78b42d1398c1c3d17526eb27a04dc0	chapter generation for digital video recorder based on perceptual clustering	pattern clustering;automatic chapter generating technique perceptual clustering digital video recorder chapter generation two staged hierarchy rule based processes;layout sections object oriented modeling regions face detection tv image recognition data mining robustness hidden markov models;video recording pattern clustering;video signal processing;two staged hierarchy chapter generation digital video recorder perceptual clustering automatic chapter generating technique;rule based;digital video recorder;general techniques;indexing terms;region of interest;video recording;clustering algorithms layout image edge detection data mining robustness image converters target recognition tv broadcasting regions histograms;video signal processing video recording pattern clustering	We propose a novel automatic chapter generating technique for digital video recorder (DVR) based on a perceptual clustering. Clustering with two-staged hierarchy is introduced for the first time, showing better performance than previous approaches without requiring any rule-based processes like recognition or modeling. Implementation into our DVR is planned.	cluster analysis;digital video recorder;logic programming	Masaki Yamauchi;Masayuki Kimura;Jun Ohmiya;Junji Nishikawa;Ichiro Okabayashi	2006	IEEE Transactions on Consumer Electronics	10.1109/TCE.2006.1649665	rule-based system;computer vision;index term;computer science;video tracking;multimedia;video processing;computer graphics (images);region of interest	Vision	37.97115159032091	-64.63625724008453	21022
d67132304ca462c6675228b494442123a0157451	analyzing fmri experiments with structural adaptive smoothing procedures	functional mri;signal detection;local likelihood;active region;time series;spatially adaptive smoothing;statistical analysis;noise reduction;functional magnetic resonance images;brain imaging;adaptive smoothing;signal to noise ratio;random field	Data from functional magnetic resonance imaging (fMRI) consist of time series of brain images that are characterized by a low signal-to-noise ratio. In order to reduce noise and to improve signal detection, the fMRI data are spatially smoothed. However, the common application of a Gaussian filter does this at the cost of loss of information on spatial extent and shape of the activation area. We suggest to use the propagation-separation procedures introduced by Polzehl, J., Spokoiny, V. (2006). Propagation-separation approach for local likelihood estimation. Probab. Theory Relat. Fields, in print. instead. We show that this significantly improves the information on the spatial extent and shape of the activation region with similar results for the noise reduction. To complete the statistical analysis, signal detection is based on thresholds defined by random field theory. Effects of adaptive and non-adaptive smoothing are illustrated by artificial examples and an analysis of experimental data.	afni;approximation algorithm;biologic preservation;cerebral cortex;column (database);detection theory;dominance, ocular;estimated;experiment;gaussian blur;magnetic resonance imaging;noise reduction;normal statistical distribution;ps (unix);quantum field theory;r language;relocation (computing);relocation of home or business;section 508 amendment to the rehabilitation act of 1973;signal detection (psychology);signal-to-noise ratio;smoothing (statistical technique);software propagation;time series;fmri;format	Karsten Tabelow;Jörg Polzehl;Henning U. Voss;Vladimir G. Spokoiny	2006	NeuroImage	10.1016/j.neuroimage.2006.06.029	econometrics;random field;computer science;machine learning;time series;noise reduction;signal-to-noise ratio;statistics;neuroimaging;smoothing;detection theory	ML	51.4211087317714	-76.57570651639018	21029
9050383a9275978df4c3a3d7dac534cc7a99a5e7	a practical guide to marker based and hybrid visual registration for ar industrial applications	confort;analisis imagen;modelizacion;comfort;pistage;informatique mobile;realite virtuelle;image processing;realidad virtual;modelo autorregresivo;maintenance;analisis forma;real time;rastreo;virtual reality;procesamiento imagen;inicializacion;traitement image;marqueur;autoregressive model;modelisation;realite augmentee;realidad aumentada;hybrid approach;marcador;analisis regresion;hybrid method;robustesse;temps reel;mantenimiento;tiempo real;industrial application;analyse regression;robustness;image analysis;regression analysis;pattern analysis;marker;augmented reality;mobile computing;modele autoregressif;modeling;comodidad;analyse image;initialization;initialisation;mobile augmented reality;analyse forme;tracking;robustez	This paper presents two visual registration solutions for a mobile augmented reality system. The first one is a marker based solution whereas the second one is a hybrid approach. The hybrid method combines a coded marker technique for the initialization in the first frame, and a markerless registration in the next frames thanks to a 3-D model based tracking method. Because this mobile augmented reality system is designed for use in the industrial context of maintenance assistance for instance- robustness, accuracy, real-time and user comfort are the main concerns. For the different stages of the proposed solutions, various algorithms were evaluated to determine which one offers the best robustness and efficiency.		Steve Bourgeois;Hanna Martinsson;Quoc-Cuong Pham;Sylvie Naudet	2005		10.1007/11556121_82	computer vision;augmented reality;initialization;image analysis;simulation;systems modeling;image processing;computer science;artificial intelligence;virtual reality;tracking;autoregressive model;programming language;mobile computing;regression analysis;robustness	Robotics	47.84777898144523	-57.08824367624347	21031
b3ff9471cfecbfb338ef8565ecc16c35d701eef6	kernel maximum mean discrepancy for region merging approach	region merging	Kernel methods are becoming increasingly challenging for use in a wide variety of computer vision applications. This paper introduces the use of Kernel MaximumMean Discrepancy (KMMD) for region merging process. KMMD is a recent unsupervised kernel-based method commonly used in analysing and comparing distributions. We propose a region merging approach based on the KMMD framework which aims at improving the quality of an initial segmentation result. The performance of the proposed method has been compared with four states of the art region merging methods over a test of Berkeley image segmentation data set by means of the probabilistic rand index and variation of information errors. Experiments show that our approach succeeds in achieving a segmentation quality equal to or greater than the referenced methods.	cluster analysis;computer vision;connected component (graph theory);connected-component labeling;discrepancy function;experiment;image segmentation;kernel (operating system);kernel method;rand index;variation of information	Alya Slimene;Ezzeddine Zagrouba	2013		10.1007/978-3-642-40246-3_59	computer science	Vision	32.398014860172296	-54.307111669884534	21052
3dee9ab9b36fae4131cb15cd0bb19bc4860ae0ed	co-occurrence of local anisotropic gradient orientations (collage): distinguishing tumor confounders and molecular subtypes on mri		We introduce a novel biologically inspired feature descriptor, Co-occurrence of Local Anisotropic Gradient Orientations (CoLlAGe), that captures higher order co-occurrence patterns of local gradient tensors at a pixel level to distinguish disease phenotypes that have similar morphologic appearances. A number of pathologies (e.g. subtypes of breast cancer) have different histologic phenotypes but similar radiographic appearances. While texture features have been previously employed for distinguishing subtly different pathologies, they attempt to capture differences in global intensity patterns. In this paper we attempt to model CoLlAGe to identify higher order co-occurrence patterns of gradient tensors at a pixel level. The assumption behind this new feature is that different pathologies, even though they may have very similar overall texture and appearance on imaging, at a local scale, will have different co-occurring patterns with respect to gradient orientations. We demonstrate the utility of CoLIAGe in distinguishing two subtly different types of pathologies on MRI in the context of brain tumors and breast cancer. In the first problem, we look at CoLlAGe for distinguishing radiation effects from recurrent brain tumors over a cohort of 40 studies, and in the second, discriminating different molecular subtypes of breast cancer over a cohort of 73 studies. For both these challenging cohorts, CoLlAGe was found to have significantly improved classification performance, as compared to the traditional texture features such as Haralick, Gabor, local binary patterns, and histogram of gradients.	brain neoplasms;brain tumor, recurrent;gradient;inspiration function;mammary neoplasms;mental orientation;phenotype;subtype (attribute)	Prateek Prasanna;Pallavi Tiwari;Anant Madabhushi	2014	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-319-10443-0_10	computer vision;pathology	ML	31.94422083929	-77.70291315891751	21085
9b36175205b56b0f934b4de5d49b4058879bad97	precise and fast form identification method by using adaptive base lines for matching	presentacion documento;document structure;estructura de documento;document analysis;algoritmo adaptativo;structure document;document layout;presentation document;adaptive algorithm;analyse documentaire;algorithme adaptatif;traitement document;analisis documental;document processing;processing speed;tratamiento documento	Conventional form identification methods have been based on the normalization of an input image. So, if the base for normalization is different from that of the true model, it is difficult to identify its form. In this paper, we propose a form identification method, which prevents the difference from spreading throughout the process. In the method, the local ruled line structures are analyzed exhaustively by varying a pair of base lines of an input image and a model.The process is realized efficiently by generating the correspondence possibilities between ruled lines, and grouping these possibilities. We registered 100 models with a dictionary, and experimented on form identification under the various conditions. The result shows that the method has high accuracy and practical processing speed.		Hiroaki Takebe;Yutaka Katsuyama;Satoshi Naoi	1998		10.1007/3-540-63931-4_208	speech recognition;document processing;computer science;document structure description;algorithm	Vision	35.74846874952669	-67.19214473506575	21102
afd2b86c6593a150a0866f3e2f010968f333535b	artistic instance-aware image filtering by convolutional neural networks		In the recent years, public use of artistic effects for editing and beautifying images has encouraged researchers to look for new approaches to this task. Most of the existing methods apply artistic effects to the whole image. Exploitation of neural network vision technologies like object detection and semantic segmentation could be a new viewpoint in this area. In this paper, we utilize an instance segmentation neural network to obtain a class mask for separately filtering the background and foreground of an image. We implement a top prior-mask selection to let us select an object class for filtering purpose. Different artistic effects are used in the filtering process to meet the requirements of a vast variety of users. Also, our method is flexible enough to allow the addition of new filters. We use pretrained Mask R-CNN instance segmentation on the COCO dataset as the segmentation network. Experimental results on the use of different filters are performed. System’s output results show that this novel approach can create satisfying artistic images with fast operation and simple interface. Keywords—artistic effect, digital art, instance segmentation, convolutional neural networks	artificial neural network;convolutional neural network;neural networks;object detection;requirement	Milad Tehrani;Mahnoosh Bagheri;Mahdi Ahmadi;Alireza Norouzi;Nader Karimi;S Abdolvahab Samavi	2018	CoRR		object class;convolutional neural network;filter (signal processing);artificial neural network;object detection;artificial intelligence;pattern recognition;computer science;digital art;segmentation	Vision	27.07020437609969	-55.36852795687868	21207
e7bad0510c8c7571d329b2c14c3810fee90ee97d	facial feature representation and face recognition with neighborhood-based binary patterns		This paper presents a study based on the facial feature representation and facial image recognition using the Neighborhood-based Binary Patterns (NBP). Images can be represented as binary code sequences and classified with the related method which is successful in representation of textural features, robust to gray level color changes and can be invariant to the rotation. In proposed study, face images are processed with the simple texture analysis operator of the NBP method and then divided into different number of blocks. Facial feature vectors are generated from the binary code sequences which are obtained by using the intensity values and neighborhood information of the facial image blocks. In order to classify facial images, simple matching coefficient is calculated and K-nearest neighbor (KNN) classifier is performed. Accuracy, precision, recall and F-measure values are measured and compared in performance evaluation tests of the proposed face recognition system. Experimental results observed on the Yale face database show that NBP method has superior performance for representation of facial features and for face recognition than the well-known methods in literature.	facial recognition system	Abbas Memis	2018		10.1109/SIU.2018.8404167	pattern recognition;binary code;computer vision;operator (computer programming);facial recognition system;computer science;artificial intelligence;noise measurement;simple matching coefficient;feature vector;invariant (mathematics);binary number	Vision	35.615703076222914	-59.02568913357457	21224
38cba2bd0233c1f4319de9f5ac40573c1e53bef9	classification of mitotic cells - potentials beyond the limits of small data sets		Tumor diagnostics are based on histopathological assessments of tissue biopsies of the suspected carcinogen region. One standard task in histopathology is counting of mitotic cells, a task that provides great potential to be improved in speed, accuracy and reproducability. The advent of deep learning methods brought a significant increase in precision of algorithmic detection methods, yet it is dependent on the availability of large amounts of data, completely capturing the natural variability in the material. Fully segmented images are provided by the MITOS dataset with 300 mitotic events. The ICPR2012 dataset provides 326 mitotic cells and in AMIDA2014 dataset, 550 mitotic cells for training and 533 for testing. In contrast to these datasets, a dataset with high number of mitotic events is missing. For this, either one of two pathologist annotated at least 10 thousand cell images for cells of the type mitosis, eosinophilic granulocyte and normal tumor cell from canine mast cell tumor whole-slide images, exceeding all publicly available data sets by approximately one order of magnitude. We tested performance using a standard CNN approach and found accuracies of up to 0.93.	deep learning;radio masts and towers;spatial variability	Maximilian Krappmann;Marc Aubreville;Andreas K. Maier;Christof Bertram;Robert Klopfleisch	2018		10.1007/978-3-662-56537-7_66		ML	31.941240776292993	-76.10867893232356	21249
0e18c7929167b88b41338f56bb184eaee9577bd9	employing a fish-eye for scene tunnel scanning	navegacion;alignement;zona urbana;vision ordenador;analisis escena;analyse scene;image processing;visualizacion;echantillonnage;oeil de poisson;zone urbaine;procesamiento imagen;archive;traitement image;tunnels;computer vision;sampling;navigation;visualization;internet;visualisation;indexing;archivo;oclusion hidrogeno;indexation;field of view;alineamiento;indizacion;fish eye;urban area;vision ordinateur;tunnel;muestreo;tunel;3d structure;alignment;scene analysis	This work employs a fish-eye to scan cityscapes along a street and register scenes in a compact scene tunnel image. A fish-eye has complete field of view along a route. We mount the fish-eye camera on a vehicle and estimate its pose initially with respect to the vehicle by referring to 3D structure lines of such as roads and buildings on a street. Sampling curves are then allocated in the image frame for dynamic scanning route scenes as the vehicle moves forward. The accurate alignment of the curves ensures less distortion of shapes in the scene tunnel image. We also analyze the scanned results and evaluate alignments of the sampling curves to improve the scanning. The resulting scene tunnel is a continuous archive of the entire route in a city, which can be used for environment visualization and assessment, Internet based virtual navigation, city information indexing, etc.	archive;cryptographic hash function;distortion;hdmi;image scanner;internationalization and localization;pose (computer vision);sampling (signal processing);stationary process	Jiang Yu Zheng;Shigang Li	2006		10.1007/11612032_52	computer vision;visualization;image processing;computer science;computer graphics (images)	Vision	48.94454013384396	-56.497480222326374	21260
1e20107f5e076fb9feff35e7e054cce207a49058	player classification in interactive sport scenes using prior information region space analysis and number recognition	optical character recognition;prior information;prior knowledge;rogue candidate removal player classification interactive sports prior information region space analysis number recognition region adjacency graph picture trees optical character recognition recognition histograms temporal analysis;trees mathematics;region adjacency graph;layout information analysis tree graphs optical character recognition software character recognition statistics data mining histograms robustness merging;sport optical character recognition tracking trees mathematics feature extraction visual databases object detection;feature extraction;temporal analysis;sport;tracking;object detection;visual databases	This paper proposes using a novel region space technique to track sport persons for the purpose of extracting their shirt numbers and use this to provide augmented information to the viewer. The region adjacency graph and picture trees are used to perform a search for an object using prior knowledge from a scene description. Once the candidate object has been extracted the subspace is examined for alphanumeric characters, which are then characterized by optical character recognition. Rogue candidates may be removed based on the recognition histograms with improved robustness using temporal analysis.	optical character recognition;rogue	Ernesto L. Andrade;Ekram Khan;John C. Woods;Mohammed Ghanbari	2003		10.1109/ICIP.2003.1247198	computer vision;feature;feature extraction;computer science;sport;machine learning;pattern recognition;tracking;optical character recognition	Vision	39.021359192929154	-53.91175442303318	21288
1b0084d77dc0ab701dd60a73ed7e3b9966c3d91f	image-based quality monitoring system of limestone ore grades	analisis imagen;modelizacion;ore grade prediction;industrie extractive;analisis componente principal;control de calidad;industria extractiva;image segmentation;ore;image processing;segmentacion de imagenes;color;random sampling;localization;extraction forme;metodo imagen;procesamiento imagen;localizacion;texture features;qualite image;traitement image;modelisation;feature vector;mining industry;monitoring system;localisation;analisis morfologico;monitoring;extraccion forma;stratified random sampling;mineral;calcaire;principal component analysis;image quality;muestreo aleatorio;image method;segmentation image;morphological analysis;minerai;analyse composante principale;controle qualite;analyse morphologique;couleur;image analysis;calidad imagen;calcareo;monitorage;neural network model;reseau neuronal;monitoreo;quality control;off line monitoring;methode image;limestone;echantillonnage aleatoire;modeling;analyse image;pattern extraction;red neuronal;simulation environment;variance;neural network;variancia;principal component	"""In this study, an image analysis-based ore quality monitoring system was developed. The study was conducted at a limestone mine located in India. The samples were collected based on a stratified random sampling method, and images of these samples were taken in a simulated environment in a laboratory. The image preprocessing and segmentation were performed using different segmentation methods to extract morphological, colour and textural features. A total of 189 features was extracted during this study. Principal components analysis was conducted to reduce the feature vector for modeling purposes. Five principal components, which were extracted from the feature vectors, captured 95% of the total feature variance. A neural network model was used as a mapping function for ore grade prediction. The five principal components were used as input, and four grade attributes of limestone (CaO, Al""""2O""""3, Fe""""2O""""3 and SiO""""2) were used as output. The developed model was then used for day to day quality monitoring at 3 different face locations of the mine. Results revealed that this technique can be successfully used for ore grade monitoring at the mine level in a controlled environment."""		Snehamoy Chatterjee;Ashis Bhattacherjee;Biswajit Samanta;Samir Kumar Pal	2010	Computers in Industry	10.1016/j.compind.2009.10.003	computer science;machine learning;artificial neural network;principal component analysis	Logic	45.53407494365725	-61.75019747085979	21293
7f0362d1a95c4e5a01fbfa7a4e5acb9d320f7af6	a curvature based approach for the automated screening of retinopathy of prematurity in preterm infants		Retinopathy of Prematurity (ROP) is a curable retinal disorder which mainly affects premature infants. The early treatment of the disease starts with the diagnosis of Plus disease which is characterised by excessive tortuosity and dilation of the retinal blood vessels. The method used for the disease diagnosis involves a retinal specialist, to visually compare the fundus vasculature with a gold standard image. This technique often lead to errors due to inter expert variability in the final diagnostic decision. So there arises the need for a computer aided system for the early detection of the disease. In the presented work, the presence of ROP is investigated by evaluating the retinal blood vessel tortuosity in the fundus images using a curvature based method. The method includes vessel delineation using COSFIRE filters followed by quantification of its tortuosity. The developed system is tested on a private dataset consisting of 35 images. The result obtained shows that the reported system achieves a sensitivity and specificity of 0.88 and 0.94 respectively.	cosfire;dilation (morphology);heart rate variability;retinal implant;sensitivity and specificity	R Sivakumar;V Veena;Renu John	2017	2017 13th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)	10.1109/SITIS.2017.88	retinopathy of prematurity;ophthalmology;artificial intelligence;pattern recognition;tortuosity;computer science;curvature;retinal;retinal blood vessels;fundus (eye);retinal blood vessel tortuosity;retinal disorder	EDA	35.62069918693357	-78.61496386071731	21322
a743d82fb1dfce6c54ab68b5e2804498a1325f89	deep representation via convolutional neural network for classification of spatiotemporal event streams		Abstract Different from traditional frame-based cameras, event-based dynamic vision sensor (DVS) converts the visual information into spatiotemporal event streams. Convolutional neural networks (CNNs) have recently achieved outstanding classification performance while require a very large number of annotated samples. However, a lack of available large-scale event-stream datasets prevents application of CNNs to classification of such event streams. In this work, we show how the deep representation learned with an originally optimized CNN is efficiently transferred to the event-stream classification tasks. In our classification method, a spike-event temporal coding is used to encoding the spike-event information of each pixel. This temporal coding mechanism is implemented based on the subthreshold dynamic of the leaky integrate-and-fire (LIF) model. Three popular event-stream datasets were used to evaluate the performance of the proposed method. Results show that the proposed method leads to significantly improved classification accuracy, outperforming the current state of the art methods on the three event-stream datasets. Besides, the robustness of our method was verified in the MNIST-DVS dataset when Gaussian temporal noises were added to the timestamps of the events. Finally, we find that fine tuning with a small amount of event-stream data would improve the classification performance. This work can be easily extended to more complex scenarios and more fascinating and potential visual applications.	artificial neural network;convolutional neural network	Hongmin Li;Guoqi Li;Xiangyang Ji;Luping Shi	2018	Neurocomputing	10.1016/j.neucom.2018.02.019	timestamp;streams;robustness (computer science);machine learning;pixel;convolutional neural network;fine-tuning;artificial intelligence;encoding (memory);mathematics;gaussian;pattern recognition	ML	26.89730671697405	-52.70882519737754	21341
b3712d6fe50cc1e8892203c35dee5c499423da95	fuzzy logic classification in image processing	image processing;real time;fuzzy logic;production and process control;classification system;process control;pattern recognition;expert knowledge	Abstract   Image comparison and classification systems based on conventional two-valued logic are mostly not flexible enough while evaluating a “human-decision”-based classification result. Using such systems, it is additionally very hard to represent the experts knowledge in order to calculate the result in video real time because of the amount of data to be processed: In this paper image pre-processing methods are investigated in order to evaluate global image describing parameters which are presented to the classifier. Several classification methods are examined and compared with respect to a fast and human-decision-based evaluation of the degree of similarity between images and patterns.	fuzzy logic;image processing	Reiner Fageth;William G. Allen;Uwe Jäger	1996	Fuzzy Sets and Systems	10.1016/0165-0114(95)00235-9	fuzzy logic;computer vision;image processing;fuzzy classification;computer science;artificial intelligence;machine learning;process control;data mining	Robotics	41.36713269733343	-67.56403386869009	21354
9ea0785c52b24a9a18a8d415d4f0fc3af9bc622a	texture classification using dominant neighborhood structure	texture classification dominant local binary pattern dlbp dominant neighborhood structure dns local binary pattern lbp rotation invariance;image features;vertical science platform;image texture feature extraction image classification;dominant local binary pattern dlbp;texture classification;pixel feature extraction accuracy noise noise measurement redundancy robustness;image classification;local binary pattern;texture features;noise measurement;lbp extension texture classification accuracy global image feature image pixel texture image dominant neighborhood structure global rotation invariant feature local binary pattern local texture feature lbp method method classification accuracy;image texture;dominant neighborhood structure dns;accuracy;rotation invariance;research paper;redundancy;patents;feature extraction;pixel;local binary pattern lbp;research platform;robustness;journals;classification accuracy;researchers network;noise	This paper proposes a new approach to extract global image features for the purpose of texture classification. The proposed texture features are obtained by generating an estimated global map representing the measured intensity similarity between any given image pixel and its surrounding neighbors within a certain window. The intensity similarity map is an average representation of the texture-image dominant neighborhood similarity. The estimated dominant neighborhood similarity is robust to noise and referred to as image dominant neighborhood structure. The global rotation-invariant features are then extracted from the generated image dominant neighborhood structure. Features obtained from the local binary patterns (LBPs) are then extracted in order to supply additional local texture features to the generated features from the dominant neighborhood structure. Both features complement each other. The experimental results on representative texture databases show that the proposed method is robust to noise and can achieve significant improvement in terms of the obtained classification accuracy in comparison to the LBP method. In addition, the method classification accuracy is comparable to the two recent LBP extensions: dominant LBP and completed LBP.	belief propagation;class;complement system proteins;database;experiment;extraction;facial recognition system;image noise;local binary patterns;pixel;support vector machine;texture filtering	Fakhry M. Khellah	2011	IEEE Transactions on Image Processing	10.1109/TIP.2011.2143422	image texture;computer vision;contextual image classification;local binary patterns;feature extraction;computer science;noise measurement;noise;machine learning;pattern recognition;mathematics;accuracy and precision;redundancy;feature;pixel;robustness	Vision	37.88496937041588	-59.372159309073524	21370
4b900a5071f1e6c26d4c41345e6dbe29065b28f1	a new approach to reference point location in fingerprint recognition	fingerprint identification;fingerprint recognition	Fingerprint matching is one of the most important problems in Fingerprint Identification System (AFIS). In this paper a new method of the reference point alignment has been presented. A new approach of reference point localization is based on so-called identification masks which have been composed on the basis of analysis of biometric characteristic of human finger. Construction of such masks has been presented. Experiments show that our approach locates a unique reference point with high accuracy for all types of fingerprints. Generally, fingerprint matching consists with three steps: core (reference) point detection, filter the image using a bank Gabor filters, and comparison with imprint pattern. It seems, that today, the Gabor filtering gives the best results in fingerprint recognition. The proposed method was evaluated and tested on various fingerprint images, included in the FVC2000 fingerprint database. Performed results with representative investigations have been compared.	biometrics;experiment;fingerprint recognition;gabor filter;point location	Piotr Porwik;Lukasz Wieclaw	2004	IEICE Electronic Express		fingerprint;computer vision;speech recognition;computer science;pattern recognition;mathematics;fingerprint recognition	Vision	34.45763613069383	-62.492770003274266	21386
85bdb8c55f52d3d14f74f40ef101a74b02b2879c	color texture analysis based on fractal descriptors	complexity;classification;fractal dimension;color texture analysis;feature extraction	Color texture classification is an important step in image segmentation and recognition. The color information is especially important in textures of natural scenes, such as leaves surfaces, terrains models, etc. In this paper, we propose a novel approach based on the fractal dimension for color texture analysis. The proposed approach investigates the complexity in R, G and B color channels to characterize a texture sample. We also propose to study all channels in combination, taking into consideration the correlations between them. Both these approaches use the volumetric version of the Bouligand–Minkowski Fractal Dimension method. The results show a advantage of the proposed method over other color texture analysis methods. & 2011 Elsevier Ltd. All rights reserved.	analysis of algorithms;channel (digital image);dilation (morphology);electronic signature;fractal dimension;gabor wavelet;image segmentation;pattern recognition	André Ricardo Backes;Dalcimar Casanova;Odemir Martinez Bruno	2012	Pattern Recognition	10.1016/j.patcog.2011.11.009	color histogram;image texture;computer vision;complexity;fractal analysis;feature extraction;biological classification;computer science;machine learning;pattern recognition;mathematics;fractal dimension;texture compression;texture filtering;algorithm;computer graphics (images)	Vision	37.16789582262161	-59.9621439765752	21403
5450ec6304140736d3c202811b4dc1f56b9f49ff	umbilics and lines of curvature for shape interrogation	forma libre;concepcion asistida;computer aided design;vision ordenador;umbilics;lines of curvature;cad;free form;monge form;shape recognition;courbure;taylor expansion;computer vision;forme libre;perturbacion;coordinate transformation;cagd;pattern recognition;conception assistee;curvatura;curvature;vision ordinateur;reconnaissance forme;numerical experiment;perturbation;reconocimiento patron;parametric surface;vision;umbilic;singular point	Copyright (c) 1996 Elsevier Science B.V. All rights reserved. This paper describes a method to extract the generic features of free-form parametric surfaces for shape interrogation. The umbilical points, which are the singular points of the orthogonal net of lines of curvature, have generic features and may act like fingerprints for shape recognition. We investigate the generic features of the umbilics and behavior of lines of curvature which pass through an umbilic on a parametric free-form surface. Our method is based on a coordinate transformation to set the parametric surface in Monge form and on a Taylor expansion to compute the angles of the tangent lines to the lines of curvatures at an umbilic. We also develop a novel and practical criterion which assures the existence of local extrema of principal curvature functions at umbilical points. Finally, numerical experiments illustrate how the generic features of the umbilics can be applied for surface recognition.		Takashi Maekawa;Franz-Erich Wolter;Nicholas M. Patrikalakis	1996	Computer Aided Geometric Design	10.1016/0167-8396(95)00018-6	vision;singular point of a curve;perturbation;umbilical point;taylor series;coordinate system;computer aided design;parametric surface;cad;mathematics;geometry;curvature	Graphics	49.520637622085395	-60.444773826850984	21404
e34d1e719d175e558b6cf7fd827063f195458c9e	accurate on-road vehicle detection with deep fully convolutional networks		Vision-based on-road vehicle detection is one of the key problems for autonomous vehicles. Conventional vision-based on-road vehicle detection methods mainly rely on hand-crafted features, such as SIFT and HOG. These hand-crafted features normally require expensive human labor and expert knowledge. Also, they suffer from poor generalization and slow running speed. Therefore, they are difficult to be applied in realistic application which demands accurate and fast detection in all kinds of unpredictable complex environmental conditions. This paper presents a framework utilizing fully convolutional networks (FCN) to produce bounding boxes with high confidence to contain a vehicle, and bounding box location refinement with SVM to further improve localization accuracy. Experiments on the PASCAL VOC 2007 and LISA-Q benchmarks show that using high-level semantic vehicle confidence obtained by FCN, higher precision and recall are achieved. Additionally, FCN enables whole image inference, which makes the proposed method much faster than the object proposal or hand-crafted feature based detectors.	convolutional neural network	Zequn Jie;Wen Feng Lu;Francis Eng Hock Tay	2016		10.1007/978-3-319-41920-6_50	embedded system;telecommunications	AI	28.93103870088114	-53.242925509746776	21427
9ca3b82cce551d3e4c44dde401ea70ec7498f37a	object feature extraction for image retrieval based on quadtree segmented blocks	object feature extraction;image segmentation;quadtree decomposition;homogeneous blocks object feature extraction image retrieval quadtree segmented blocks quadtree decomposition image segmentation;data mining;homogeneous blocks;visualization;feature extracting;vector quantization;image color analysis;feature extraction;pixel;quadtree segmented blocks;vector quantizer;content based image retrieval;content based retrieval;quadtree decomposition vector quantization content based image retrieval feature extracting;quadtrees;quadtrees content based retrieval feature extraction image retrieval image segmentation;feature extraction image retrieval image segmentation computer science data mining humans visual perception clustering algorithms vector quantization information retrieval;image retrieval	This study proposed a new object feature extraction method that employs the quadtree decomposition. In the proposed method, we segmented the image into variable sized blocks, named homogeneous blocks, which are the units of feature extraction process. Because the quadtree decomposition can highlight the details of images, more feature information can be extracted from the visual important objects than from the monotone areas of the image. The experimental results show the image retrieval performance is effectively improved as compared with the pixel based method.	feature extraction;image retrieval;pixel;quadtree;monotone	Shou-Yi Tseng;Zhi-Yu Yang;Wen-Hsuan Huang;Chin-Yi Liu;Yi-Huei Lin	2009	2009 WRI World Congress on Computer Science and Information Engineering	10.1109/CSIE.2009.662	computer vision;feature detection;visualization;feature extraction;image retrieval;computer science;machine learning;pattern recognition;image segmentation;feature;information retrieval;vector quantization;pixel	AI	39.1730427235933	-62.55304118019748	21433
48683eac121f1a8b38e77bc0f3b39dedfbdbdc74	feature facial image recognition using vq histogram in the dct domain	reconnaissance visage;databases;quantization;image recognition;image numerique;image processing;0705p;data compression;low frequency;0130c;transformation cosinus discrete;quantification;traitement image;algorithme;histogram;face recognition;vector quantization;histogramme;methode domaine frequence;discrete cosine transforms;frequency domain method;imaging;imagen numerica;basse frequence;reconnaissance image;formation image;algorithms;baja frecuencia;digital image;metodo dominio frecuencia;facial recognition systems;4230v;histograma;compression donnee;quantification vectorielle	In this paper, a novel algorithm using vector quantization (VQ) method for facial image recognition in DCT domain is presented. Firstly, feature vectors of facial image are generated by using DCT (Discrete Cosine transform) coefficients in low frequency domains. Then codevector referred count histogram, which is utilized as a very effective personal feature value, is obtained by Vector Quantization (VQ) processing. Publicly available AT&T database of 40 subjects with 10 images per subject containing variations in lighting, posing, and expressions, is used to evaluate the performance of the proposed algorithm. Experimental results show face recognition using proposed feature vector is very efficient. The highest average recognition rate of 94.8% is obtained.	algorithm;coefficient;computer vision;discrete cosine transform;facial recognition system;feature vector;jpeg;return loss;vector quantization	Qiu Chen;Koji Kotani;Feifei Lee;Tadahiro Ohmi	2010		10.1117/12.855647	computer vision;speech recognition;artificial intelligence;mathematics;feature	Vision	44.452892551357294	-60.480901068044325	21439
eb37382fa53046dbca468ee90582f1d968b405f6	a new method for sclera vessel recognition using olbp	institute for integrated and intelligent systems;conference output;faculty of science environment engineering and technology;computer vision;080104	This paper proposes a new sclera vessel recognition technique. The vesselpatterns of sclera are unique for each individual and this can be utilized to identify a person uniquely. In this research we have used a time adaptive active contour-based region growing technique for sclera segmentation. Prior to that, we have made some tonal and illumination correction to get a clearer sclera area without the distributing vessel structure. This is because the presence of complex vessel structures occasionally affects the region-growing process. The sclera vessels are not prominent in the images, so in order to make them clearly visible, a local image enhancement process using a Haar high pass filter is incorporated. To get the total orientation of the vessels, we have used Orientated Local Binary Pattern (OLBP). The OLBP images of each class are used for template matching for classification by calculating the minimum Hamming Distance. We have used the UBIRIS version 1 dataset for the experimentation of our research. The proposed approach has achieved high recognition accuracy employing the above-mentioned dataset.		Abhijit Das;Umapada Pal;Miguel Angel Ferrer-Ballester;Michael Blumenstein	2013		10.1007/978-3-319-02961-0_46	simulation;engineering;biological engineering;mechanical engineering	Vision	36.58574383105083	-71.1331207255812	21509
502b26ade3b9ef37a871b362adadb2504831aba6	unsupervised perceptual segmentation of natural color images using fuzzy-based hierarchical algorithm	color space;texture features;geometric feature;color image	This paper proposes unsupervised perceptual segmentation of natural color images using a fuzzy-based hierarchical algorithm. L*a*b* color space is used to represent color features and statistical geometrical features are adopted as texture features. A fuzzy-based homogeneity measure makes a fusion of color features and texture features. Proposed hierarchical segmentation method is performed in four stages: simple splitting, local merging, global merging and boundary refinement. Experiments on segmentation of natural color images are presented to verify the effectiveness of the proposed method in obtaining perceptual segmentation.		Junji Maeda;Akimitsu Kawano;Sato Saga;Yukinori Suzuki	2007		10.1007/978-3-540-73040-8_47	color histogram;image texture;computer vision;color image;computer science;machine learning;pattern recognition;mathematics;image segmentation;color space;scale-space segmentation	Vision	43.450931280631636	-66.6167400351305	21524
e44ec3356c327a0ad04568b90a02ab74843480de	classification of brain mri tumor images: a hybrid approach		Abstract Nowadays, brain tumor has been proved as a life threatening disease which cause even to death. Various classification techniques have been identified for Brain MRI Tumor Images. In this paper brain tumor from MR Images with the help of hybrid approach has been carried out. This hybrid approach includes discrete wavelet transform (DWT) to be used for extraction of features, Genetic algorithm for diminishing the number of features and support vector machine (SVM) for brain tumor classification. Images are downloaded from SICAS Medical Image Repository which classified images as benign or malign type. The proposed hybrid approach is implemented in MATLAB 2015a platform. Parameters used for analyzing the images are given as: entropy, smoothness, root mean square error (RMS), kurtosis and correlation. The simulation analysis approach results shows that hybrid approach offers better performance by improving accuracy and minimizing the RMS error in comparison with the state-of-the-art techniques in the similar context.		Sanjeev Kumar;Chetna Dabas;Sunila Godara	2017		10.1016/j.procs.2017.11.400	machine learning;support vector machine;genetic algorithm;smoothness;kurtosis;discrete wavelet transform;root-mean-square deviation;computer science;pattern recognition;mean squared error;artificial intelligence	Vision	33.665201290017265	-73.53127317576953	21534
de643349105320cd312afd257687cac3d1f0bf42	r-plus: a riemannian anisotropic edge detection scheme for vascular segmentation	curve evolution;edge detection;local structure;riemannian manifold;vessel segmentation	In this paper, detection of edges in oriented fields is addressed. In some applications such as vessel segmentation because of the intrinsic orientation of the structures, edge detection is only demanded in a particular subspace. This is specially usefull when a curve evolution is chosen for segmentation since gradients in parallel to vessel orientation may stop the contour. An anisotropic edge detection scheme is generalized on a Riemannian manifold using the local structure tensor. The method is the generalization of the PLUS operator proposed for accurate curved edge detection. Examples are given and the comparison is made with the state-of-the-art flux maximizing flow which indicates that significant improvements in terms of leakage minimization and thiner vessel delineation is achievable using our methodology.		Ali Gooya;Takeyoshi Dohi;Ichiro Sakuma;Hongen Liao	2008	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-540-85988-8_32	computer vision;mathematical optimization;edge detection;topology;computer science;mathematics;geometry	Vision	51.53308444968283	-71.41956536481736	21659
0f3525bd5a1fb3bab662af1b817c6ed949e332fc	improved pupil center localization method for eye-gaze tracking-based human-device interaction	human computer interaction;image segmentation;gaze tracking;infrared imaging gaze tracking human computer interaction image segmentation;blob centroid pupil center localization method eye gaze tracking based human device interaction pc localization method input infrared eye image binarization binary pixels binary image stack blob shape aspect ratio blob moments blob circularity;infrared imaging;filtering shape iris recognition estimation conferences educational institutions cameras	This paper presents an improved pupil center (PC) localization method for eye-gaze tracking. In the proposed method, an input infrared eye image is repeatedly binarized with a finite number of different thresholds to produce a stack of binary images. Among all the blobs, which are groups of connected binary pixels in the binary image stack, we find a blob whose shape is the most similar to pupil, in terms of the size, the aspect ratio, the moments, and the circularity. Consequently, the centroid of the final resultant blob is regarded as the PC location. Experimental results show that the proposed method outperforms conventional ones.	binary image;circular definition;eye tracking;pixel;resultant	Kang-A. Choi;Seung-Jin Baek;Chunfei Ma;Seung Shin Park;Sung-Jea Ko	2014	2014 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2014.6776111	corner detection;computer vision;blob detection;computer science;image segmentation;computer graphics (images)	Robotics	41.21635892875922	-54.13688040013895	21662
1bbc3a1756b384491c8acd4feb73a7130a7b9067	robust face recognition system using a reliability feedback		In the real world there are a variety of lighting conditions, and there exist many directional lights as well as ambient lights. These directional lights cause partial dark and bright regions on faces. Even if auto exposure mode of cameras is used, those uneven pixel intensities are left, and in some cases satu- rated pixels and black pixels appear. In this paper we propose robust face rec- ognition system using a reliability feedback. The system evaluates the reliability of the input face image using prior distributions of each recognition feature, and if the reliability of the image is not enough for face recognition, it capture mul- tiple images by changing exposure parameters of cameras based on the analysis of saturated pixels and black pixels. As a result the system can cumulates simi- larity scores of enough amounts of reliable recognition features from multiple face images. By evaluating the system in an office environment, we can achieve three times better EER than the system only with auto exposure control.		Shotaro Miwa;Shintaro Watanabe;Makito Seki	2013		10.1007/978-3-642-39342-6_20	computer vision;simulation;computer graphics (images)	Robotics	42.2852912155171	-52.35284886942066	21674
6066e42d43d6133406199266a96f323a82aa04bd	verification of dynamic curves extracted from static handwritten scripts	handwriting analysis;evaluation performance;handwriting recognition;document analysis;performance evaluation;stroke recovery;automatic assessment;caracter manuscrito;hidden markov model;text processing;evaluacion prestacion;manuscript character;modele markov variable cachee;performance comparison;analisis objetivos;probabilistic approach;estimation algorithm;algorithme;algorithm;dynamic information;accuracy;reconnaissance ecriture;precision;hidden markov models;enfoque probabilista;approche probabiliste;pattern recognition;ground truth;reconnaissance forme;document and text processing;reconocimiento patron;caractere manuscrit;estimating pen trajectories of static scripts;analyse objective;objective analysis;algoritmo	Static handwritten scripts originate as images on documents and do not, by definition, contain any dynamic information. To improve the accuracy of static handwriting recognition systems, many techniques aim to estimate dynamic information from the static scripts. Mostly, the pen trajectories of the scripts are estimated. However, the efficacy of the resulting pen trajectories are rarely evaluated quantitatively. This paper proposes a protocol for the objective evaluation of automatically determined pen trajectories. A hidden Markov model is derived from a ground-truth trajectory. An estimated trajectory is then matched to the derived model. Statistics describing substitution, insertion and deletion errors are then computed from this match. The proposed algorithm is especially useful for performance comparisons between different pen trajectory estimation algorithms.		Emli-Mari Nel;Johan A. du Preez;Ben M. Herbst	2008	Pattern Recognition	10.1016/j.patcog.2008.05.005	computer vision;speech recognition;computer science;artificial intelligence;machine learning;pattern recognition;accuracy and precision;algorithm;hidden markov model;statistics	Vision	34.72030558141287	-68.47550572354723	21697
5771e5e0ba8d9a426ae4b2aa8326906c7decc3db	the image representation of auricular points resistance mapping	triangle patch interpolation;interpolation;decoding;clinical application;grayscale mapping;resistance;organ disease;topographic map;gray scale;topographical mapping;medical image processing diseases image representation interpolation;image color analysis;image representation;medical image processing;pixel;immune system;diseases;pseudocolor image;triangle patch interpolation image representation auricular points resistance mapping organ disease pseudocolor image topographical mapping grayscale mapping;auricular points resistance mapping;image representation immune system gray scale diseases interpolation electrical resistance measurement back biomedical engineering pixel pediatrics;color image	The resistances of auricular points provide a diagnosis method to organ diseases clinically. In order to represent the resistances of auricular points and their distribution intuitionally, and help doctors’ diagnose in clinical application, this study used pseudo-color image to represent the resistance topographical mapping of auricular points. Firstly, transfer the resistances of auricular points on the auricle to the color value (or grayscale) according to the pseudo-color (or grayscale) mapping functions. Then, calculate each pixel’s RGB value in the image according to the triangle patch interpolation algorithm. The resistance topographical mapping was used to represent the resistances of auricular points. Also, it realized to highlight a specific neural subarea or anatomic subarea. This study supplied the quantitative detection and visual evidence for the clinical detection and diagnosis. Keywords-auricular points’ resistance; pseudo-color mapping; grayscale mapping; triangle patch interpolation	algorithm;color image;color mapping;grayscale;interpolation;pixel;sensor;topography	Qin Gong;Xi Chen;Jinglei Liu	2009	2009 2nd International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2009.5305702	computer vision;topographic map;immune system;color image;interpolation;computer science;resistance;pixel;grayscale;statistics;computer graphics (images)	Robotics	38.161072856431424	-77.57306228765334	21727
55b20b285621df57f831d6ebc92a0b9c2d7a8ee1	an automated volumetric segmentation system combining multiscale and statistical reasoning	image features;image recognition;object recognition;image coding;image segmentation;image resolution;markov random field model;gaussian processes;bayes methods;bayesian inference;bayesian methods;mri data automated volumetric segmentation system multiscale reasoning statistical reasoning fast unsupervised method automated volumetric image segmentation algorithm automatic parameter estimation optimal segment number selection bayesian inference wavelet domain gaussian mixture modeling gmm baseline scene estimate spatial correlations markov random field model mrfm three dimensional biomedical image volumes inherent image features identification pet image volumes;gmm;biomedical imaging;inference mechanisms;automated volumetric image segmentation algorithm;gaussian mixture modeling;three dimensional;positron emission tomography;markov random field;mri data;wavelet transforms;gaussian mixture model;pet image volumes;mrfm;spatial correlation;positron emission tomography image segmentation medical image processing gaussian processes bayes methods inference mechanisms markov processes feature extraction image recognition object recognition biomedical mri;image segmentation wavelet transforms image analysis image resolution computer science bayesian methods biomedical imaging pixel image coding humans;inherent image features identification;feature extraction;medical image processing;pixel;statistical reasoning;image analysis;optimal segment number selection;humans;three dimensional biomedical image volumes;markov processes;computer science;wavelet domain;fast unsupervised method;spatial correlations;baseline scene estimate;multiscale reasoning;automated volumetric segmentation system;automatic parameter estimation;biomedical mri	An automated volumetric image segmentation algorithm is proposed. This method is fast and unsupervised, automatically estimating required parameters including optimal segment number selection using Bayesian inference. In the wavelet domain, Gaussian mixture modeling (GMM) is used to achieve a baseline scene estimate. This estimate is then refined to consider spatial correlations using a Markov random field model (MRFM). The application of this system to three-dimensional biomedical image volumes is discussed. This approach delivers promising results in terms of the identification of inherent image features.	algorithm;baseline (configuration management);bayes factor;bayesian approaches to brain function;brain implant;image segmentation;jaccard index;markov chain;markov random field;polyethylene terephthalate;unsupervised learning;volumetric display;wavelet	David W. G. Montgomery;Abbes Amira;Fionn Murtagh	2005	2005 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2005.1465455	three-dimensional space;computer vision;spatial correlation;image analysis;image resolution;feature extraction;bayesian probability;computer science;generalized method of moments;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;mixture model;gaussian process;mathematics;image segmentation;markov process;bayesian inference;feature;pixel;statistics;wavelet transform	Vision	44.05079382553864	-76.8698575164763	21739
7cd5fe9fc792c633a0304a668808bc02ba953b37	boundary detection of optic disk by a modified asm method	optic disk;asm;fundus image;blood vessel;automatic detection;principal component analysis;shape parameter;boundary detection;pca;active shape model	A new algorithm to automatically detect the boundary of optic disk in color fundus images is proposed. The optic disk is located by principal component analysis (PCA) based model, which is employed to initialize active shape model (ASM) to detect the disk boundary. ASM is modi%ed with two aspects: one is the self-adjusting weight in the transformation from shape space to image space; the other is exclusion of outlying points in obtaining shape parameters. The modi%cations make the proposed algorithm more robust and converge faster than the original ASM method, especially in the case where the edge of optic disk is weak or occluded by blood vessels. ? 2003 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	active shape model;algorithm;converge;feature extraction;mad;pattern recognition;pixel;principal component analysis	Huiqi Li;Opas Chutatape	2003	Pattern Recognition	10.1016/S0031-3203(03)00052-9	computer vision;computer science;machine learning;mathematics;statistics;principal component analysis	Vision	44.319953924919496	-65.18761485902695	21750
4e74f61f566e569477f4ce4483d61c8962b09452	diagnostic efficacy of multiple mri parameters in differentiating benign vs. malignant thyroid nodules	diffusion weighted imaging;magnetic resonance imaging;thyroid carcinoma;thyroid nodule	BACKGROUND Diffusion weighted imaging (DWI) has a good diagnostic value for malignant thyroid nodules, but the published protocols suffer from flaws and focus on the apparent diffusion coefficient (ADC). This study investigated the diagnostic performance of multiple MRI parameters in differentiating malignant from benign thyroid nodules.   METHODS This was a retrospective study of 181 consecutive patients (148 benign and 111 malignant nodules, confirmed by pathological results). The patients underwent conventional MRI, DWI, and dynamic contrast-enhanced MRI before surgery. The chi-square test and the Student t test were used to compare the conventional features and ADC value between malignant and benign groups. Multivariate logistic regression was used to identify the independent predictors and to construct a model. Receiver operator characteristic (ROC) curve analysis was used to assess the diagnostic performance of the independent variables and model.   RESULTS Tumor diameter, ADC value, cystic degeneration, pseudocapsule sign, high signal cystic area on T1-weighted imaging, ring sign in the delayed phase, and irregular shape showed significant differences between two groups (all P < 0.05). The multivariable analysis revealed that ADC value (OR = 694.006, P < 0.001), irregular shape (OR = 32.798, P < 0.001), ring sign in the delayed phase (OR = 20.381, P = 0.004), and cystic degeneration (OR = 8.468, P = 0.016) were independent predictors. Among them, ADC performed the best in discriminating benign from malignant nodules, with an area under the curve (AUC) of 0.95, 0.90 sensitivity, and 0.91 specificity. When the independent factors were combined, the diagnostic performance was improved with an AUC of 0.99, 0.97 sensitivity, and 0.95 specificity.   CONCLUSIONS ADC value could discriminate between benign and malignant thyroid nodules with a good performance. Subjective features such as the ring sign, irregular shape, and cystic degeneration associated with malignant thyroid nodules could provide complementary information for differentiation.		Hao Wang;Ran Wei;Weiyan Liu;Yongqi Chen;Bin Song	2018		10.1186/s12880-018-0294-0		HCI	29.28531651015684	-80.05650141772512	21784
a61b8accbbee6b7893746283cb3e801dd5a1dfa5	character and text recognition of khmer historical palm leaf manuscripts		This paper presents methods for two historical document analysis tasks on digitized Khmer palm leaf manuscripts. The first task consisting of isolated character recognition is conducted utilizing different types of neural network architectures such as CNN, LSTM-RNN, and a combination of both. The second task focuses on recognizing word/text image patches of variable length and simultaneously localizing each glyph in the text image. For this task, according to the characteristic of Khmer writing system, both one-dimensional and two-dimensional RNN are used.		Dona Valy;Michel Verleysen;Sophea Chhun;Jean-Christophe Burie	2018	2018 16th International Conference on Frontiers in Handwriting Recognition (ICFHR)	10.1109/ICFHR-2018.2018.00012	natural language processing;artificial intelligence;computer science;pattern recognition;artificial neural network;historical document;glyph;writing system;palm	Robotics	33.87360480030011	-66.51714464065077	21811
09e44c2562f9859eb18079792708e69c8652a24e	rotation-free online handwritten chinese character recognition using two-stage convolutional neural network		Handwritten Chinese character recognition (HCCR) is a major research area in pattern recognition. Although recent years have seen tremendous improvement in the use of deep neural networks in handwriting recognition, unconstrained handwriting recognition remains an open problem. Considering the problem of rotated handwritten Chinese character recognition, we propose a two-stage convolutional neural network combined with path signature features to achieve high-accuracy rotation-free HCCR. For handwritten Chinese characters whose rotation angle is up to ±45°, the recognition rate can reach 97.38% on the ICDAR-2013 online HCCR competition dataset, which is comparable to the accuracy achieved by several state-of-the-art methods for non-rotated characters, thus showing the effectiveness of the proposed method.		Zhe Li;Lianwen Jin;Songxuan Lai	2018	2018 16th International Conference on Frontiers in Handwriting Recognition (ICFHR)	10.1109/ICFHR-2018.2018.00044	artificial intelligence;convolutional neural network;machine learning;pattern recognition;computer science;chinese characters;artificial neural network;open problem;handwriting recognition	Vision	29.115154838302463	-54.502882520480064	21812
d11bae711e216937655e84ea35ebea9124fe599a	an effective non-ht circle detection for centers and radii	image edge detection noise pattern recognition machine learning moon cybernetics transforms;image processing;edge detection;natural images;partial circle circle detection center detection radius detection concentric circle;machine learning;detection algorithm;pattern recognition;natural images non ht circle detection algorithm partially circular components gradient vector edge point feature circle energy distribution map radius detection gradient magnitudes feature circle radius synthetic images;object detection;object detection edge detection image processing	We present a non-HT circle detection algorithm applied to search the centers and radii of circular or partially circular components present in the image. The line coincident with the gradient vector of each edge point and passing through the corresponding edge point is defined first. Then, for every pixel in the image, the number of the lines passing through this pixel is defined as the energy of the pixel. The feature circle energy (FCE) distribution map of the whole image is therefore obtained and the local maxima are corresponding to the centers of potential circles. For the detection of radius, the gradient magnitudes in assigned region are accumulated and its variation defined as the feature circle radius (FCR) is computed who has maximum when the radius of the region is equal to that of the circle. Synthetic images and natural images are used to test the capability of the proposed method. The experimental results indicate that the presented algorithm has excellent performance for detection of single circle, multiple circles, concentric circles and partial circles, and also good accuracy despite the presence of different noises.	algorithm;gradient;maxima and minima;pixel;the circle (file system);thematic map	Li-Qin Jia;Hongmin Liu;Zhiheng Wang;Hong Chen	2011	2011 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2011.6016769	computer vision;feature detection;edge detection;image processing;computer science;midpoint circle algorithm;mathematics;geometry	Vision	45.092519143902386	-65.0508614319729	21817
5d50bc560af1573e1071e83cbc7a50333dd55d08	depth-aware salient object detection using anisotropic center-surround difference	center surround difference;salient object detection;期刊论文;depth map	Most previous works on salient object detection concentrate on 2D images. In this paper, we propose to explore the power of depth cue for predicting salient regions. Our basic assumption is that a salient object tends to stand out from its surroundings in 3D space. To measure the object-to-surrounding contrast, we propose a novel depth feature which works on a single depth map. Besides, we integrate the 3D spatial prior into our method for saliency refinement. By sparse sampling and representing the image using superpixels, our method works very fast, whose complexity is linear to the image resolution. To segment the salient object, we also develop a saliency based method using adaptive thresholding and GrabCut. The proposed method is evaluated on two large datasets designed for depth-aware salient object detection. The results compared with several state-of-the-art 2D and depth-aware methods show that our method has the most satisfactory overall performance.	depth map;experiment;grabcut;high-level programming language;image resolution;linear programming;object detection;refinement (computing);sampling (signal processing);sparse matrix;thresholding (image processing)	Ran Ju;Yang Liu;Tongwei Ren;Ling Ge;Gangshan Wu	2015	Sig. Proc.: Image Comm.	10.1016/j.image.2015.07.002	computer vision;machine learning;pattern recognition;depth map	Vision	46.31440212223358	-68.28220207034306	21918
4d9dbffe79f1e3109ef5124475a4c48940d8b9f0	towards machine learning prediction of deep brain stimulation (dbs) intra-operative efficacy maps		Deep brain stimulation (DBS) has the potential to improve the quality of life of people with a variety of neurological diseases. A key challenge in DBS is in the placement of a stimulation electrode in the anatomical location that maximizes efficacy and minimizes side effects. Pre-operative localization of the optimal stimulation zone can reduce surgical times and morbidity. Current methods of producing efficacy probability maps follow an anatomical guidance on magnetic resonance imaging (MRI) to identify the areas with the highest efficacy in a population. In this work, we propose to revisit this problem as a classification problem, where each voxel in the MRI is a sample informed by the surrounding anatomy. We use a patch-based convolutional neural network to classify a stimulation coordinate as having a positive reduction in symptoms during surgery. We use a cohort of 187 patients with a total of 2,869 stimulation coordinates, upon which 3D patches were extracted and associated with an efficacy score. We compare our results with a registration-based method of surgical planning. We show an improvement in the classification of intraoperative stimulation coordinates as a positive response in reduction of symptoms with AUC of 0.670 compared to a baseline registration-based approach, which achieves an AUC of 0.627 (p < 0.01). Although additional validation is needed, the proposed classification framework and deep learning method appear well-suited for improving pre-surgical planning and personalize treatment strategies.	artificial neural network;baseline (configuration management);convolutional neural network;deep brain stimulation;deep learning;machine learning;patch (computing);personalization;resonance;sacral nerve stimulation;side effect (computer science);the quality of life;voxel	Camilo Bermudez;William Rodriguez;Yuankai Huo;Allison E. Hainline;Rui Li;Robert Shults;Pierre D. DHaese;Peter E. Konrad;Benoit M. Dawant;Bennett A. Landman	2018	CoRR			ML	29.57762455104255	-77.66142726323336	21946
088bfd70085dc7112e45de113c6756cd68ccc254	hep-2 cell classification and segmentation using motif texture patterns and spatial features with random forests	image segmentation;support vector machines;training;vegetation;radio frequency;imaging;pattern recognition	Human epithelial (HEp-2) cell specimens are obtained from indirect immunofluorescence (IIF) imaging for diagnosis and management of autoimmune diseases. Analysis of HEp2 cells is important and in this work we consider automatic cell segmentation and classification using spatial and texture pattern features and random forest classifiers. In this paper, we summarize our efforts in classification and segmentation tasks proposed in ICPR 2016 contest. For the cell level staining pattern classification (Task 1), we utilized texture features such as rotational invariant co-occurrence (RIC) versions of the well-known local binary pattern (LBP), median binary pattern (MBP), joint adaptive median binary pattern (JAMBP), and motif labels (ML) along with other optimized features. We report the classification results utilizing different classifiers such as the k-nearest neighbors (kNN), support vector machine (SVM), and random forest (RF). We obtained the best accuracy of 94.26% for six cell classes with RIC-LBP combined with a motif pattern co-occurrence labels (MCL). For specimen level staining pattern classification (Task 2) we utilize a combination RIC-LBP with RF classifier and obtain 80% accuracy for seven classes. For cell segmentation (Task 4), we use our optimized multiscale spatial feature bank along with RF classifier for pixel-wise labeling to achieve an F-measure of 84.26% for 1008 images.	belief propagation;binary pattern (image generation);biological specimen;emoticon;iif;k-nearest neighbors algorithm;local binary patterns;macintosh common lisp;million book project;motif;new general catalogue;pixel;radio frequency;random forest;statistical classification;support vector machine;whole earth 'lectronic link	V. B. Surya Prasath;Yasmin M. Kassim;Zakariya A. Oraibi;Jean-Baptiste Guiriec;Adel Hafiane;Guna Seetharaman;Kannappan Palaniappan	2016	2016 23rd International Conference on Pattern Recognition (ICPR)	10.1109/ICPR.2016.7899614	medical imaging;support vector machine;computer vision;computer science;machine learning;pattern recognition;image segmentation;radio frequency;vegetation	Vision	35.587369830032245	-73.26161860099852	21963
86fb9490735dd4f19f66b71f26d74aabac86de1c	analysis and selection of features for the fingerprint vitality detection	doigt;analisis estadistico;rubber;securite;analisis estructural;biometrie;biometrics;biometria;feature vector;captador medida;empreinte digitale;analyse syntaxique;measurement sensor;capteur mesure;statistical analysis;analisis sintaxico;syntactic analysis;safety;analyse statistique;pattern recognition;caoutchouc;fingerprint;finger;huella digital;reconnaissance forme;caucho;analyse structurale;reconocimiento patron;structural analysis;dedo;seguridad;fingerprint verification	Although fingerprint verification systems have attained a good performance, researchers recently pointed out their weakness under fraudulent attacks by fake fingers. In fact, the acquisition sensor can be deceived by fake fingerprints created with liquid silicon rubber. Among the solutions to this problem, the software-based ones are the cheapest and less intrusive. They use feature vectors made up of measures extracted from one or multiple impressions (static measures) or multiple frames (dynamic measures) of the same finger in order to distinguish live and fake fingers. In this paper, we jointly use both static and dynamic features and report an experimental investigation aimed to compare them and select the most effective ones.	fingerprint	Pietro Coli;Gian Luca Marcialis;Fabio Roli	2006		10.1007/11815921_100	natural rubber;speech recognition;computer science;artificial intelligence	Vision	31.116162698837964	-63.46148415704174	21976
b6143283f53fbac1973607855a5f3402179ff2fe	automatic classification of colorectal and prostatic histologic tumor images using multiscale multispectral local binary pattern texture features and stacked generalization		This paper proposes a new multispectral multiscale local binary pattern feature extraction method for automatic classification of colorectal and prostatic tumor biopsies samples. A multilevel stacked generalization classification technique is also proposed and the key idea of the paper considers a grade diagnostic problem rather than a simple malignant versus tumorous tissue problem using the concept of multispectral imagery in both the visible and near infrared spectra. To validate the proposed algorithm performances, a comparative study against related works using multispectral imagery is conducted including an evaluation on three different multiclass datasets of multispectral histology images: two representing images of colorectal biopsies one dataset was acquired in the visible spectrum while the second captures near-infrared spectra. The proposed algorithm achieves an accuracy of 99.6% on the different datasets. The results obtained demonstrate the advantages of infrared wavelengths to capture more efficiently the most discriminative information. The results obtained show that our proposed algorithm outperforms other similar methods.		Remy Peyret;Ahmed Bouridane;Fouad Khelifi;Muhammad Atif Tahir;Somaya Al-Máadeed	2018	Neurocomputing	10.1016/j.neucom.2017.05.010	local binary patterns;discriminative model;machine learning;multispectral image;feature extraction;pattern recognition;computer vision;artificial intelligence;computer science	Vision	34.24493641123414	-75.0625162811789	22007
567d7fd70b4ae964b748195fc4ab0998dfd19e24	on hierarchical palmprint coding with multiple features for personal identification in large databases	level 2;fuzzy set;image coding;palmprint classification hierarchical palmprint coding automatic personal identification security systems biometric technology identity authentication feature extraction feature representation coarse to fine matching global geometry based key point distance global texture energy fuzzy interest line local directional texture energy similarity measurement fuzzy set guided search texture measurement;biometrics access control;biometrie;biometrics;biometria;conjunto difuso;image classification;ensemble flou;palmprint classification;indexing terms;classification;fuzzy set theory;spatial databases biometrics feature extraction fingerprint recognition authentication image databases data security indexing testing error analysis;energy levels;automatic recognition;image representation;pattern matching;feature extraction;identification;indexation;feature extraction and representation;guided search;equal error rate;secure system;pattern recognition;identificacion;concordance forme;reconnaissance forme;extraction caracteristique;biometric identification;reconocimiento patron;visual databases biometrics access control feature extraction image representation fuzzy set theory image coding image classification;texture measurement;high performance;similarity measure;clasificacion;journal magazine article;reconocimiento automatico;level 1;reconnaissance automatique;visual databases	"""Automatic personal identification is a significant component of security systems with many challenges and practical applications. The advances in biometric technology have led to the very rapid growth in identity authentication. This paper presents a new approach to personal identification using palmprints. To tackle the key issues such as feature extraction, representation, indexing, similarity measurement, and fast search for the best match, we propose a hierarchical multifeature coding scheme to facilitate coarse-to-fine matching for efficient and effective palmprint verification and identification in a large database. In our approach, four-level features are defined: global geometry-based key point distance (Level-1 feature), global texture energy (Level-2 feature), fuzzy """"interest"""" line (Level-3 feature), and local directional texture energy (Level-4 feature). In contrast to the existing systems that employ a fixed mechanism for feature extraction and similarity measurement, we extract multiple features and adopt different matching criteria at different levels to achieve high performance by a coarse-to-fine guided search. The proposed method has been tested in a database with 7752 palmprint images from 386 different palms. The use of Level-1, Level-2, and Level-3 features can remove candidates from the database by 9.6%, 7.8%, and 60.6%, respectively. For a system embedded with an Intel Pentium III processor (500 MHz), the execution time of the simulation of our hierarchical coding scheme for a large database with 10/sup 6/ palmprint samples is 2.8 s while the traditional sequential approach requires 6.7 s with 4.5% verification equal error rate. Our experimental results demonstrate the feasibility and effectiveness of the proposed method."""	authentication;biometrics;database;embedded system;feature extraction;fingerprint;run time (program lifecycle phase);simulation	Jane You;Adams Wai-Kin Kong;David Zhang;King Hong Cheung	2003	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2003.821978	computer vision;computer science;pattern recognition;data mining;fuzzy set;biometrics	EDA	34.9662877474688	-61.327139944984	22014
02a9a57c0b9b12012e96422d66de7ec42b98d4fd	human face detection in color images	statistical moment;t technology general;t technology;skin classifier;histogram based approach;human skin;feature based approach;lookup table;face detection;skin segmentation;color image;ellipse fitting	In this paper we have used a simple and efficient color-based approach to segment human skin pixels from background, using a 2D histogram-based approach as a preprocess stage for human face detection. For skin segmentation, a total of 446,007 skin samples from the training set is manually cropped from the RGB color images, to calculate three lookup tables based on the relationship between each pair of the triple components (R, G, B). Derivation of skin classifier rules from the lookup tables are based on how often each attribute value (interval) occurs, and their associated certainty values. For face detection, we assume the face-appearance as blob-like, and that the face has an approximately elliptical shape. Accordingly, an ellipse-fitting algorithm is appropriate, which is based on statistical moments, and those blobs that have an elliptical shape are retained as face candidates.	face detection	Ihab Zaqout;Roziati Zainuddin;Sapian Baba	2004	Advances in Complex Systems	10.1142/S021952590400024X	computer vision;face detection;color image;lookup table;computer science;machine learning;pattern recognition	Vision	38.45425314428476	-64.37741939813814	22020
e5d34274ca10c1f1710f68dcefe0364705dd760d	vesselness based feature extraction for endoscopic image analysis	feature extraction image segmentation detectors surgery biomedical imaging blood vessels sun;vesselness based feature extraction computational complexity feature point detector vbsd vesselness based branching segment detection vbct vesselness based circle test vascular feature vascular branching points blood vessels endoscopic image analysis;medical image processing biomedical optical imaging blood vessels endoscopes feature extraction	Distinctive features are crucial to many tasks in computer assisted minimally invasive surgeries (MIS). Most existing methods are difficult to extract distinctive features in MIS images. For better analysis of MIS images, we resort to blood vessels that are abundant and distinctive on the tissue surfaces. Based on vascular branching points, we propose a new type of vascular feature, branching segment. Two novel methods, Vesselness Based Circle Test (VBCT) and Vesselness based Branching Segment Detection (VBSD) are proposed to detect branching points and branching segments respectively. In the experiments, the performance of VBCT and VBSD is evaluated with in vivo images and VBCT is compared with other state-of-the-art feature point detectors. The numerical results verify that branching points and branching segments are highly repeatable under different viewpoints. Moreover, the computational complexity of VBCT and VBSD is linear to the number of pixels. As supplements to other types of feature point detectors, VBCT and VBSD provide researchers new tools for endoscopic image analysis.	computational complexity theory;experiment;feature extraction;image analysis;minimally invasive education;numerical analysis;pixel;sensor;video-in video-out	Bingxiong Lin;Yu Sun;Jaime Sánchez;Xiaoning Qian	2014	2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2014.6868114	computer vision;pathology	Vision	39.93525697574653	-75.98569424675048	22053
2508ebf6f0014ed9634626e5c4005d214afe4999	a new fingerprint matching approach using level 2 and level 3 features	level 2;false reject rate;high resolution;fingerprint matching;level 3;public domain;performance improvement;minutia based approach;feature extraction;error rate;pores and ridges;fingerprint identification;false accept rate;level 1	Fingerprint friction ridge details are generally described in a hierarchical order at three levels, namely, Level 1 (pattern), Level 2 (minutiae points) and Level 3 (pores and ridge shape). Although high resolution sensors (~ 1000dpi) have become commercially available and have made it possible to reliably extract Level 3 features, most Automated Fingerprint Identification Systems (AFIS) employ only Level 1 and Level 2 features. As a result, increasing the scan resolution does not provide any matching performance improvement. We develop a matcher that utilizes Level 3 features, including pores and ridge contours, in conjunction with level 2 features (minutiae) for matching. The aim is to reduce the error rates, namely FAR (False Acceptance Rate) and FRR (False Rejection Rate) in the existing minutiae based systems. The hierarchical matcher has been tested on two diverse databases in public domain. The obtained results are promising and verify our claim.	automated fingerprint identification;cpu cache;database;fingerprint recognition;image resolution;minutiae;rejection sampling;sensor	Rohollah Moosavi Tayebi;Samaneh Mazaheri;Bahram Sadeghi Bigham	2011		10.1145/1992896.1992906	fingerprint;public domain;speech recognition;image resolution;feature extraction;word error rate;computer science;machine learning;pattern recognition;data mining	Vision	32.785687490967156	-62.619122028029985	22093
382e7334c83c4dfd39a8acaf0c6ec5e38f224a5e	shape prior criterion based on tchebichef moments in variational region growing	3d segmentation;shape constraints;mice;shape description shape prior criterion tchebichef moments variational region growing 3d segmentation feature extraction bimodal segmentation functional;image segmentation;regionbased approach;shape image segmentation merging equations image processing data mining pixel statistics deformable models biomedical imaging;region based approach;segmentation;tchebichef moments;shape;evolution equation;shape constraint segmentation region growing regionbased approach tchebichef moments;shape constraint;three dimensional displays;feature extraction;pixel;shape priors;shape description;region growing;kidney;image segmentation feature extraction	Region growing has become a popular method for 3D segmentation. Starting from a seed, this approach allows one to extract a region by merging all its neighbors and comparing the extracted region to a reference. Here, we present an alternative approach to constrain the evolution of the region growing method in respect to a fixed reference shape. This approach is based on a shape description by the Tchebichef moments. The evolution equation minimizes a function that represents the distance between the evolving region and the reference shape. Experimental results show the ability of our method to drive the segmentation towards a desired shape in 2D and 3D data. Finally, we apply our shape prior conjointly to a bimodal segmentation functional, showing its benefits on segmentation results.	region growing;variational principle	Jean-Loïc Rose;Chantal Revol-Muller;Delphine Charpigny;Christophe Odet	2009	2009 16th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2009.5413477	computer vision;mathematical optimization;feature extraction;shape;computer science;machine learning;pattern recognition;mathematics;region growing;image segmentation;scale-space segmentation;segmentation;pixel	Vision	43.92883043805018	-75.18638055843263	22129
1b8a9b12a5a44accad93a6ce382b2a6f4d6346fe	an image smoothing operator for fast and accurate scale space approximation	image smoothing;box filter;sift image smoothing scale space box filter gaussian filter;low pass image filtering gaussian image smoothing fast scale space approximation accurate scale space approximation scale invariant feature point extraction box filter computational complexity keypoint repeatability feature detection scenario sift features;image filtering approximation theory feature extraction;scale space;sift;smoothing methods kernel convolution visualization feature extraction computational complexity;gaussian filter	Gussian image smoothing is a fundamental operation in the extraction of scale-invariant feature points. Its computation, however, can be too expensive in some resource-constrained scenarios. Alternative solutions such as the box filter can be computed more efficiently, at the cost of a loss in feature repeatibility under some conditions. In this paper we propose a fast and accurate image smoothing operator based on integral images. It has the same order of computational complexity as the box filter, but provides much more accurate visual results and improved keypoint repeatability, which is confirmed in a feature detection scenario using SIFT features.	approximation;computation;computational complexity theory;feature detection (computer vision);feature detection (web development);image editing;repeatability;scale space;scale-invariant feature transform;smoothing;thinking outside the box	Maxim Karpushin;Giuseppe Valenzise;Frédéric Dufaux	2016	2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2016.7471999	edge-preserving smoothing;computer vision;mathematical optimization;feature detection;scale space;computer science;gaussian blur;pattern recognition;scale-invariant feature transform;mathematics;gaussian filter;feature;smoothing	Robotics	51.08884370443535	-65.02844980476107	22148
5f2cfda3a70473e1537c2a3adea85be6671500a1	fisher tensors for classifying human epithelial cells	texture classification;human epithelial cell type 2 hep 2;journal article;riemannian manifolds;region covariance descriptor;fisher vectors;bag of visual words	Analyzing and classifying Human Epithelial type 2 (HEp-2) cells using Indirect Immunofluorescence protocol has been the golden standard for detecting connective tissue diseases such as Rheumatoid Arthritis. However, this suffers from numerous shortcomings such as being subjective as well as time and labor intensive. Recently, several studies explore the advantages of artificial systems to automate the process, not only to reduce the test turn-around time but also to deliver more consistent results. In this paper, we extend the conventional bag of word models from Euclidean space to non-Euclidean Riemannian manifolds and utilize them to classify the HEp-2 cells. The main motivation comes from the observation that HEp-2 cells can be efficiently described by symmetric positive definite matrices which lie on a Riemannian manifold. With this motivation, we first discuss an intrinsic bag of Riemannian words model. We then propose Fisher tensors which can in turn encode additional information about the distribution of the signatures in a bag of word model. Experiments on two challenging HEp-2 images datasets, namely ICPRContest and SNPHEp-2 show that the proposed methods obtain notable improvements in discrimination accuracy, in comparison to baseline and several state-of-the-art methods. The proposed framework, while hand-crafted towards cell classification, is a generic framework for object recognition. This is supported by assessing the performance of our proposal on a challenging texture classification task.		Masoud Faraki;Mehrtash Tafazzoli Harandi;Arnold Wiliem;Brian C. Lovell	2014	Pattern Recognition	10.1016/j.patcog.2013.10.011	computer vision;computer science;machine learning;pattern recognition;mathematics;bag-of-words model in computer vision;statistics	Vision	31.339184124146218	-54.95676148013236	22155
7f686252eb3b32c64d145fddebb19dec20a3f546	an improved palmprint recognition system using iris features	g400 computer science;g600 software engineering	This paper presents a bimodal biometric recognition system based on the extracted features of the human palmprint and iris using a new graph-based approach termed Fisher locality preserving projections (FLPP). This new technique employs two graphs with the first being used to characterize the within-class compactness and the second dedicated to the augmentation of the between-class separability. By applying the FLPP, only the most discriminant and stable palmprint and iris features are retained. FLPP was implemented on the frequency domain by transforming the extracted region of interest extraction of both biometric modalities using Fourier transform. Subsequently, the palmprint and iris features vectors obtained are matched with their counterpart in the templates databases and the obtained scores are fused to produce a final decision. The proposed combination of palmprint and iris patterns has shown an excellent performance compared to unimodal palmprint biometric recognition. The system was evaluated on a database of 108 subjects and the experimental results show that our system performs very well and achieves a high accuracy expressed by an equal error rate of 0.00%.	archive;biometrics;database;discriminant;enhanced entity–relationship model;fingerprint;linear separability;locality of reference;principal component analysis;region of interest	Moussadek Laadjel;Ahmed Bouridane;Omar Nibouche;Fatih Kurugollu;Somaya Al-Máadeed	2011	Journal of Real-Time Image Processing	10.1007/s11554-011-0230-9	computer vision;speech recognition;computer science;pattern recognition	Vision	33.98310289652863	-59.862546423419886	22195
3bdaf59665e6effe323a1b61308bcac2da4c1b73	2d spherical spaces for objects recognition under harsh lighting conditions	object recognition;robot vision;visual databases lighting object detection object recognition robot vision;lighting object recognition harmonic analysis robots surface treatment power harmonic filters training;lighting;autonomous robot 2d spherical space object recognition harsh lighting conditions surface illumination recovery cast shadows object spherical space property robot intelligence robot manipulation object detection object reference images scene lighting environment matching database albedo surface normals scene lighting direction illumination coefficients real time processing speed small image size;object detection;visual databases	For an object recognition task in an unknown environment, we propose a novel approach for illumination recovery of surface with cast shadows and specularities by using the object spherical spaces properties. Robust objects recognition in complex environment is fundamental to robot intelligence and manipulation. The proposed method is done for reducing the illumination effects on the objects detection and recognition processes. In this work, objects reference images are regenerated to match the scene lighting environment to increase the success rate of the recognition process. First, a database is generated by computing the albedo and surface normals from captured 2D images of the target objects. Next, the scene lighting direction and illumination coefficients are estimated. Finally, by using the calculated spherical spaces properties we regenerate objects reference data to match the search area illumination condition. In this work, practical real time processing speed and small image size were considered when designing the framework. In contrast to other techniques, our work requires no 3D models for the objects training process and takes images from a single camera as an input. Using our proposed 2D Spherical Spaces experimentally showed noticeable improvements in an objects identification task performed by an autonomous robot in a harshly illuminated environment.	3d modeling;autonomous robot;coefficient;cognitive robotics;computation;experiment;global illumination;image resolution;information;normal (geometry);outline of object recognition;real-time computing;requirement;spaces	Amr Almaddah;Yasushi Mae;Kenichi Ohara;Tatsuo Arai	2012	2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2012.6343736	computer vision;deep-sky object;cognitive neuroscience of visual object recognition;lighting;3d single-object recognition;image-based lighting;computer graphics (images)	Vision	42.93426857606657	-52.98999354479356	22200
19b0ed9b64a3e975dc6690d3cdefa90120dd4d51	automatic text area segmentation in natural images	urdu text;image segmentation;uniform texture text segmentation;hierarchical method;training;text analysis;natural images;simple graphics;indexing terms;automatic text area segmentation;text segmenation;simple graphics automatic text area segmentation natural images hierarchical method urdu text english text text segmenation contrasting color;object segmentation;distance measurement;shape;image color analysis;pixel;text analysis image segmentation natural scenes;pattern recognition;contrasting color;image segmentation testing graphics shape image databases wire robustness computer vision design methodology licenses;convex hull;uniform texture;text segmentation;natural scenes;english text	"""We present a hierarchical method for segmenting text areas in natural images. The method assumes that the text is written with a contrasting color on a more or less uniform background. No assumption is made regarding the language or character set used to write the text. In particular, the text can contain simple graphics or symbols. The key feature of our approach is that we first concentrate on finding the background of the text, before testing whether there is actually text on the background. Since uniform areas are easy to find in natural images, and since text backgrounds define areas which contain """"holes"""" (where the text is written) we thus look for uniform areas containing """"holes"""" and label them as text backgrounds candidates. Each candidate area is then further tested for the presence of text within its convex hull. We tested our method on a database of 65 images including English and Urdu text. The method correctly segmented all the text areas in 63 of these images, and in only 4 of these were areas that do not contain text also segmented."""	character encoding;convex hull;graphics;symbol (formal)	Syed Ali Raza Jafri;Mireille Boutin;Edward J. Delp	2008	2008 15th IEEE International Conference on Image Processing	10.1109/ICIP.2008.4712475	text segmentation;text simplification;computer vision;text mining;speech recognition;index term;shape;computer science;convex hull;noisy text analytics;pattern recognition;image segmentation;pixel	Vision	35.768597721919875	-66.35530525630546	22223
2af586c64c32baeb445992e0ea6b76bbbbc30c7f	massive parallelization of approximate nearest neighbor search on kd-tree for high-dimensional image descriptor matching	approximate nearest neighbor search;parallel algorithm;image descriptor matching;gpu;cuda;kd tree	To overcome the high computing cost associated with high-dimensional digital image descriptor matching, this paper presents a massively parallel approximate nearest neighbor search (ANNS) on  K -dimensional tree (KD-tree) on the modern massively parallel architectures (MPA). The proposed algorithm is of comparable quality to traditional sequential counterpart on central processing unit (CPU). However, it achieves a high speedup factor of 121 when applied to high-dimensional real-world image descriptor datasets. The algorithm is also studied for factors that impact its performance to obtain the optimal runtime configurations for various datasets. The performance of the proposed parallel ANNS algorithm is also verified on typical 3D image matching scenarios. With the classical local image descriptor signature of histograms of orientations (SHOT), the parallel image descriptor matching can achieve speedup of up to 128. Our implementation will potentially benefit realtime image descriptor matching in high dimensions.	approximation algorithm;nearest neighbor search;parallel computing;visual descriptor	Linjia Hu;Saeid Nooshabadi	2017	J. Visual Communication and Image Representation	10.1016/j.jvcir.2017.01.013	mathematical optimization;gloh;computer science;theoretical computer science;machine learning;k-d tree;parallel algorithm	Vision	39.58293845952395	-55.600223406701886	22326
21338de468b3ad49b4b8fc0bda53167ed569ade6	intensity gradient based registration and fusion of multi-modal images	distance measure;perforation;image registration;mutual information;image similarity	A particular problem in image registration arises for multimodal images taken from different imaging devices and/or modalities. Starting in 1995, mutual information has shown to be a very successful distance measure for multi-modal image registration. However, mutual information has also a number of well-known drawbacks. Its main disadvantage is that it is known to be highly non-convex and has typically many local maxima. This observation motivate us to seek a different image similarity measure which is better suited for optimization but as well capable to handle multi-modal images. In this work we investigate an alternative distance measure which is based on normalized gradients and compare its performance to Mutual Information. We call the new distance measure Normalized Gradient Fields (NGF).	gradient;image registration;mathematical optimization;maxima and minima;modal logic;multimodal interaction;mutual information;numerous;similarity measure;registration - actclass	Eldad Haber;Jan Modersitzki	2006	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/11866763_89	computer vision;mathematical optimization;image registration;pattern recognition;mathematics;mutual information;statistics	Vision	48.792537453165316	-75.01339541383523	22386
28a93188d10789a9c68da8cc51551c2e83a3c132	a segmentation method based on region information and edge information	equation derivee partielle;analisis imagen;image tridimensionnelle;partial differential equation;ecuacion derivada parcial;image numerique;diffusing image;image segmentation;image processing;edge detection;niveau gris;ruido;procesamiento imagen;ct image reconstruction;segmentation;traitement image;diffusion coefficient;extraccion;deteccion contorno;region analysis;detection contour;reconstruction image;supresion;reconstruccion imagen;image reconstruction;bruit;region;imagen numerica;tridimensional image;image analysis;digital image;analyse image;edge analysis;segmentacion;extraction;imagen tridimensional;noise;seed extraction;suppression	Abstract#R##N##R##N#This paper proposes a segmentation method based on region information and edge information. The method consists of three steps: (1) a connected component which is a part of an object is extracted as a seed by using a simple process such as a histogram analysis; (2) this seed is expanded repeatedly; and (3) to evaluate the possibility of the expansion, the uniformity of gray levels (region information) and checking the presence of border pixels (edge information) are used.#R##N##R##N##R##N##R##N#Although the method can be considered as a kind of region expansion, the significant features are that it contains the growth of a seed and the edge information (a part of control information) to expand the region repeatedly. The former gives preliminary information on approximate gray levels of an object and extracts the object as a connected component, and the latter makes the edge information more useful. Although the usefulness of the edge information in a conventional region-and-edge integrated method such as the superslice algorithm depends greatly on its region segmentation, the use of such methods can be avoided in the proposed method, since both the region and edge information are used simultaneously for the control conditions of the region expansion. The method is justified experimentally by using synthetic images and actual images in two and three dimensions.		Hao Jiang;Hidetomo Suzuki;Jun-ichiro Toriwaki	1993	Systems and Computers in Japan	10.1002/scj.4690240305	iterative reconstruction;computer vision;extraction;image analysis;region;edge detection;image processing;computer science;noise;artificial intelligence;fick's laws of diffusion;region growing;image segmentation;segmentation;partial differential equation;digital image	NLP	47.49077167949419	-64.23014482246828	22407
b491b2d171ebea8a89c991262d12aeaafdcbaca9	simplified version of white wine grape berries detector based on svm and hog features		The detection of grapes in real scene images is a serious task solved by researches dealing with precision viticulture. Our research has shown that in the case of white wine varieties, grape berry detectors based on a support vector machine classifier in combination with a HOG descriptor are very efficient. In this paper, simplified versions of our original solutions are introduced. Our research showed that skipping contrast normalization by image preprocessing accelerates the detection process; however, the performance of the detectors is not negatively influenced by this modification.		Pavel Skrabanek;Filip Majerík	2016		10.1007/978-3-319-33625-1_4	support vector machine;normalization (statistics);precision viticulture;detector;white wine;artificial intelligence;preprocessor;classifier (linguistics);pattern recognition;computer science	Vision	32.513504224579385	-56.8769654868073	22428
a87889d6ce969ce04324973cc679bdfef0f0644b	maximum entropy spectral models for color constancy in the presence of interreflections		Interreflections in a scene can be exploited to improve upon surface and illuminant spectral estimation. In this paper, we present a novel maximum entropy approach to spectral color constancy in the presence of interreflections. Previous approaches employ linear model representations of surface and illuminant spectra. Such representations are not always practical as a database of spectra has to be specified in advance in the corresponding algorithms. The proposed approach has a major advantage over previous algorithms in that it requires only camera sensor responses from the mutual illumination or edge region of a folded surface and from the far from the edge regions to estimate surface and illuminant spectra. We demonstrate the feasibility of the approach while assuming a one-bounce, two-zone model of mutual illumination. We test our approach in both simulation and experiment. In the case of one surface patch in a scene, when the color constancy problem has no solution, we are able to obtain promising results. Introduction It has been shown that the human visual system makes use of mutual illumination information in color perception [1, 2]. However, there has been little work in the computer vision literature which exploits mutual illumination to improve upon color perception. In this work, we address the problem of spectral color constancy while making use of mutual illumination information. The problem of spectral color constancy lies in computing a surface reflectance spectrum that is independent of the spectrum of light incident on the surface. Most color constancy approaches with interreflections use spectral models for the surfaces and the illuminant, while employing finite-dimensional linear model representations for these spectra. In [3], Funt et al. assumed a one-bounce, two-zone model of interreflections. The one-bounce model takes into account the light reflected off one surface that bounces onto the other. The two zones comprise that in the mutual illumination region, also called the edge, and that far from this region. By taking mutual illumination into account, they effectively added a sensor class to Maloney and Wandell’s approach [4]. This is important because one more basis function can then be used to model the surface spectrum, given the restrictions on the number of basis functions in Maloney and Wandell’s approach. Drew and Funt [5] extended Funtet al.’s [3] approach to account for multiple zones, using the radiosity method from [6]. They also proposed the variational approach [7] that does not assume diffuse-illumination, a twopatches limit, or locations with negligible interreflection as in the previous approaches. It still assumes a one-bounce model of interreflection, however. Harder [8] investigated interreflections while assuming known illumination in addition to Lambertian surfaces. All the mentioned approaches use three basis functions for each of the surface and illuminant spectra. The only exception is in Harder’s work [8] where the illuminant spectrum is assumed to be known, which is not the case in this paper. Such a small number of basis functions may not be enough to provide an accurate representation of surface spectra. Moreover, all these approaches require the database of surface and illuminant spectra to be specified in advance in order to obtain the basis functions for the linear model representations. Such a requirement places these approaches at a major disadvantage as databases might not be available in advance. Even if they are available, they might not be consistent with the data in a certain application. We propose a novel approach that estimates surface and illuminant spectra in the presence of interreflections given only camera sensor responses. This approach is based on the color constancy technique introduced in [9] in which the surface and illuminant spectra are represented by maximum entropy models, and therefore do not require a set of basis functions to be specified in advance. Maximum entropy models were successfully used to estimate Munsell patch reflectance spectra given only photoreceptor responses in [10]. The use of maximum entropy models was inspired by Jaynes, who stated that a physical quantity frequently observed in practice will tend to a value that can be produced in the largest number of ways [11]. In the case of physical processes representing spectra, many surfaces observed in o ur everyday-life surroundings have spectra of high entropy, as opposed to monochromatic surfaces which have low entropy spectra [10]. The illuminant spectra are also represented by maximum entropy models as they are observed in our everyday-life surroundings and therefore can be produced in a large number of ways [9]. In this paper, the proposed approach is explained and derived. To this end, diffuse-illumination and a Mondrian scene composed of matte, Lambertian surfaces are assumed. The light illuminating a Mondrian scene is assumed to be locally constant. This means that the spectral characteristics of the light vary slowly. As for the interreflections, a one-bounce, two-zone model is assumed. Next, the performance of the approach is analyzed in simulation and then in experiment. In particular, in the case of one surface patch in the scene, it is shown how exploiting interreflection information improves upon spectral estimation. Moreover, while, to the knowledge of the authors, none of the previous approaches provided surface or illuminant spectral estimates for real images, such spectra are shown in this paper. Maximum Entropy Spectral Based Color Constancy with Interreflections The proposed color constancy approach aims at recovering surface and illuminant spectra in the presence of interreflections given only camera sensor responses. We assume a one-bounce,	algorithm;basis function;color vision;computer vision;database;experiment;global illumination;image sensor;lambertian reflectance;linear model;matte display;mondrian olap server;monochrome;mutual exclusion;radiosity (computer graphics);simulation;spectral density estimation;variational principle	Sandra Skaff;James J. Clark	2008			principle of maximum entropy;computer vision;computer science;artificial intelligence;color constancy	Vision	53.566091847794745	-56.88887737527484	22484
a67687e595b95068e86f9d9732c30d778c1e7850	region graphs for organizing image collections	local relationship;image set reduction;image domain;graph structure;image region;region graph;meaningful data structure;background clutter;canonical view selection;large image collection;image-based navigation	In this paper we consider large image collections and their organization into meaningful data structures upon which applications can be build (e.g. navigation or reconstruction). In contrast to structures that only reflect local relationships between pairs of images we propose to account for the information an image brings to a collection with respect to all other images. Our approach builds on abstracting from image domains and focusing on image regions, thereby reducing the influence of outliers and background clutter. We introduce a graph structure based on these regions which encodes the overlap between them. The contribution of an image to a collection is then related to the amount of overlap of its regions with the other images in the collection. We demonstrate our graph based structure with several applications: image set reduction, canonical view selection and image-based navigation. The data sets used in our experiments range from small examples to large image collections with thousands of images.	clutter;data structure;experiment;organizing (structure)	Alexander Ladikos;Edmond Boyer;Nassir Navab;Slobodan Ilic	2010		10.1007/978-3-642-35740-4_19	computer vision;feature detection;computer science;data mining;information retrieval	Vision	44.222687777469915	-55.988511658139274	22518
dffbb31e6bec2bcd1a2c8327dddd8be864024213	a phase-based active contour model for segmentation of breast ultrasound images	biological tissues;speckle;breast ultrasound bus images image segmentation active contour local phase level set;image segmentation;edge detection;mathematical analysis;speckle biological tissues biomedical ultrasonics edge detection image segmentation mammography mathematical analysis medical image processing;medical image processing;local region based segmentation energy phase based active contour model breast ultrasound image segmentation speckle noises low contrast boundaries blurry boundaries bus images boundary extraction pbac model local phase information phase asymmetry approach robustness intensity inhomogeneity phase based edge indicator level set formulation;image edge detection image segmentation active contours ultrasonic imaging nonhomogeneous media solid modeling level set;mammography;biomedical ultrasonics	Due to the speckle noises, low contrast and blurry boundaries in breast ultrasound (BUS) images, extraction of the boundaries in BUS images is always a challenging task. To solve this problem, a novel phase-based active contour (PBAC) model is proposed. First, we utilize the local phase information and apply the phase asymmetry approach to form a new edge indicator, which dramatically increases the robustness to intensity inhomogeneous. Then, a novel phase-based edge indicator is incorporated into a various level set formulation with the local region-based segmentation energy. Experiments are performed on both synthetic and real BUS images. The results show that the proposed PBAC model outperforms the state-of-art methods both qualitatively and quantitatively.	active contour model;experiment;gradient;synthetic intelligence	Lingyun Cai;Yuanyuan Wang	2013	2013 6th International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2013.6746913	speckle pattern;computer vision;edge detection;computer science;segmentation-based object categorization;image segmentation;optics;scale-space segmentation	Vision	45.93874077994552	-73.03175952409721	22556
c61d18e14d0b06b37e3b13d9f1205f1da55bdcaf	svm-based characterisation of liver cirrhosis by singular value decomposition of glcm matrix	liver cirrhosis;b mode ultrasound;bhattacharyya distance;divergence;singular value decomposition;support vector machine classifier;svd;computer aided diagnostic system;fisher discriminant ratio	Early diagnosis of liver cirrhosis is essential as cirrhosis is an irreversible disease most often seen as precursor to development of hepatocellular carcinoma. Early diagnosis helps radiologist in better disease management by adequate scheduling of treatment options. In the present work, features derived from GLCM mean matrix, GLCM range matrix and singular value decomposition of GLCM matrix have been used along with SVM classifier for designing an efficient computer-aided diagnostic system to characterise normal and cirrhotic liver. The study has been carried out on 120 regions of interest ROIs extracted from 31 clinically acquired B-mode liver ultrasound images. It is observed that the first four singular values obtained by singular value decomposition of GLCM matrix result in highest accuracy and sensitivity of 98.33% and 100%, respectively. The promising results obtained by the proposed computer-aided diagnostic system indicate its usefulness to assist radiologists in diagnosis of liver cirrhosis.	singular value decomposition	Jitendra Virmani;Vinod Kumar;Naveen Kalra;Niranjan Khandelwal	2013	IJAISC	10.1504/IJAISC.2013.053407	speech recognition;pattern recognition;singular value decomposition;statistics	Vision	33.95675154585259	-77.28767219138098	22579
e886fff5a8b078d924d19d76f6261419e2d22a71	pedestrian detection system using cascaded boosting with invariance of oriented gradients	cascaded adaboost detector;pedestrian safety;poison control;injury prevention;safety literature;histogram of orientated gradients;traffic safety;injury control;home safety;injury research;safety abstracts;human factors;occupational safety;gaussian weighted window;pedestrian detection;safety;safety research;accident prevention;violence prevention;bicycle safety;poisoning prevention;falls;ergonomics;suicide prevention	This study presents a novel learning-based pedestrian detection system capable of automatically detecting individuals of different sizes and orientations against a wide variety of backgrounds, including crowds, even when the individual is partially occluded. To render the detection performance robust toward the effects of geometric and rotational variations in the original image, the feature extraction process is performed using both rectangular- and circular-type blocks of various sizes and aspect ratios. The extracted blocks are rotated in accordance with their dominant orientation(s) such that all the blocks extracted from the input images are rotationally invariant. The pixels within the cells in each block are then voted into rectangular- and circular-type 9-bin histograms of oriented gradients (HOGs) in accordance with their gradient magnitudes and corresponding multivariate Gaussian-weighted windows. Finally, four cell-based histograms are concatenated using a tri-linear interpolation technique to form one 36-dimensional normalized HOG feature vector for each block. The experimental results show that the use of the Gaussian-weighted window approach and tri-linear interpolation technique in constructing the HOG feature vectors improves the detection performance from 91% to 94.5%. In the proposed scheme, the detection process is performed using a cascaded detector structure in which the weak classifiers and corresponding weights of each stage are established using the AdaBoost self-learning algorithm. The experimental results reveal that the cascaded structure not only provides a better detection performance than many of the schemes presented in the literature, but also achieves a significant reduction in the computational time required to classify each input image.	image gradient;pedestrian detection	Chi-Chen Raxle Wang;Jin-Yi Wu;Jenn-Jier James Lien	2009	IJPRAI	10.1142/S0218001409007363	computer vision;simulation;suicide prevention;artificial intelligence;human factors and ergonomics;injury prevention;machine learning;data mining;computer security	ML	33.70303432669752	-57.19524363257292	22680
09fabc607f78ec173cbb795ebe913aa5765660cc	on the use of spectral minutiae in high-resolution palmprint recognition	optimisation;image matching;statistical analysis fingerprint identification image matching image representation nonlinear distortion optimisation palmprint recognition spectral analysis;smc high resolution palmprint recognition minutiae based fingerprint recognition minutiae translation minutiae rotation spectral minutiae based matching key parameter optimization eer palmprint database thupalmlab location based spectral minutiae representation complex spectral minutiae representation fvc2002 db2a fingerprint database statistical analysis nonlinear distortion sml;nonlinear distortion;statistical analysis;image representation;fingerprint recognition databases educational institutions statistical analysis nonlinear distortion optimization fingers;high resolution palmprints spectral minutiae fingerprints;palmprint recognition;spectral analysis;fingerprint identification	The spectral minutiae representation has been proposed as a novel method to minutiae-based fingerprint recognition, which can handle minutiae translation and rotation and improve matching speed. As high-resolution palmprint recognition is also mainly based on minutiae sets, we apply spectral minutiae representation to palmprints and implement spectral minutiae based matching. We optimize key parameters for the method by experimental study on the characteristics of spectral minutiae using both fingerprints and palmprints. However, experimental results show that spectral minutiae representation has much worse performance for palmprints than that for fingerprints. EER 15.89% and 14.2% are achieved on the public high-resolution palmprint database THUPALMLAB using location-based spectral minutiae representation (SML) and the complex spectral minutiae representation (SMC) respectively while 5.1% and 3.05% on FVC2002 DB2A fingerprint database. Based on statistical analysis, we find the worse performance for palmprints mainly due to larger non-linear distortion and much larger number of minutiae.	distortion;enhanced entity–relationship model;experiment;fingerprint recognition;image resolution;minutiae;nonlinear system;stellar classification	Ruifang Wang;Raymond N. J. Veldhuis;Daniel Ramos-Castro;Luuk J. Spreeuwers;Julian Fiérrez;Haiyun Xu	2013	2013 International Workshop on Biometrics and Forensics (IWBF)	10.1109/IWBF.2013.6547308	computer vision;speech recognition;geography;pattern recognition	Vision	35.23738658200512	-61.48869584294959	22744
0bdea185468a9e0694ed2ef0e347434916e03eb3	dream2s: deformable regions driven by an eulerian accurate minimization method for image and video segmentation	level sets;partial differential equation;active contour;image segmentation;face segmen tation;level set;shape gradient;video segmentation;boundary functionals;energy function;region segmentation;shape optimization;evolution equation;partial differential equations;shape derivative;region functionals;covariance matrix determinant;region based active contours;energy minimization;covariance matrix	This paper deals with image and video segmentation using active contours. We propose a general form for the energy functional related to region-based active contours. We compute the associated evolution equation using shape derivation tools and accounting for the evolving region-based terms. Then we apply this general framework to compute the evolution equation from functionals that include various statistical measures of homogeneity for the region to be segmented. Experimental results show that the determinant of the covariance matrix appears to be a very relevant tool for segmentation of homogeneous color regions. As an example, it has been successfully applied to face segmentation in real video sequences.		Stéphanie Jehan-Besson;Michel Barlaud;Gilles Aubert	2003	International Journal of Computer Vision	10.1023/A:1023031708305	computer vision;mathematical optimization;level set;segmentation-based object categorization;mathematics;geometry;image segmentation;scale-space segmentation;partial differential equation	Vision	49.64725621786334	-71.14666329001722	22745
618962ca58459376f36668de2a87d7934f10f823	a computer vision approach to air flow analysis	motion analysis;moving image;analisis imagen;vision ordenador;movimiento;aplicacion;image processing;learning;real time;three dimensional shape;3 d motion analysis;procesamiento imagen;shape recovery;object motion learning;motion;imagen movil;traitement image;forma tridimensional;velocity field;image mobile;air flow;computer vision;aprendizaje;apprentissage;forme tridimensionnelle;campo flujo;air flow analysis;flow field;surface model;mouvement;temps reel;self organizing map;champ ecoulement;tiempo real;image analysis;self organized map;vision ordinateur;reseau neuronal;application;analyse image;red neuronal;3 d shape recovery;neural network	Abstract   This paper describes a computer vision system for analysing air flows. The main idea of the system is to use a trace gas to visualize the air flow and to determine the air flow by analysing the trace gas and its movement via computer vision and neural network techniques. The analysis process is based on three major stages: first, an image pair series is taken from the traced air flow; second, the 3-D shapes of trace gas objects at each image pair instant are recovered; and third, the air flow velocity field is calculated via the Self-Organizing Map from the recovered 3-D surface models of the trace gas objects. The system can be used to measure air flow profiles, to determine air flow velocities and volume fluxes, and to estimate how small (e.g. dust) particles move within the flow.	computer vision;data-flow analysis	Jukka Heikkonen	1996	Pattern Recognition Letters	10.1016/0167-8655(95)00133-6	computer vision;vector field;image analysis;self-organizing map;image processing;computer science;motion;airflow;computer graphics (images)	Vision	46.37472615560297	-57.77609959918825	22751
5adcac7d15ec8999fa2beb62f0ddc6893884e080	a review on fingerprint orientation estimation	structure tensor;orientation;local estimation;fingerprint;orientation estimation;global modeling	Fingerprint orientation plays important roles in fingerprint enhancement, fingerprint classification, and fingerprint recognition. This paper critically reviews the primary advances on fingerprint orientation estimation. Advantages and limitations of existing methods have been addressed. Issues on future development have been discussed. Copyright © 2010 John Wiley & Sons, Ltd.	categorization;fingerprint recognition;john d. wiley;perturbation theory	Zujun Hou;Wei-Yun Yau;Yue Wang	2011	Security and Communication Networks	10.1002/sec.209	fingerprint;computer vision;speech recognition;computer science;artificial intelligence;orientation;structure tensor	Mobile	28.540779011038616	-61.61183853034449	22765
21503df232daeb5ae72f396b382f9b403468064a	evaluation of image segmentation and filtering with ann in the papaya leaf		Precision agriculture is area with lack of cheap technology. The refinement of the production system brings large advantages to the producer and the use of images makes the monitoring a more cheap methodology. Macronutrients monitoring can to determine the health and vulnerability of the plant in specific stages. In this paper is analyzed the method based on computational intelligence to work with image segmentation in the identification of symptoms of plant nutrient deficiency. Artificial neural networks are evaluated for image segmentation and filtering, several variations of parameters and insertion impulsive noise were evaluated too. Satisfactory results are achieved with artificial neural for segmentation same with high noise levels.	angular defect;artificial neural network;computational intelligence;filter (signal processing);image segmentation;production system (computer science);rl (complexity);refinement (computing)	Maicon A. Sartin;Alexandre C. R. da Silva	2014	CoRR	10.5121/ijcsit.2014.6104	data mining;grayscale;digital image processing;computer science;rgb color model;filter (signal processing);image segmentation;precision agriculture;computational intelligence;hue	AI	35.42067467998129	-74.32055066449678	22766
2e101eede9ad75362f6624ceccbe054ea4b0c01b	analysis of area-based image matching under perspective distortion for a planar object model	performance measure;autocorrelation function;cross correlation;image matching;distortion;signal to noise ratio;monte carlo simulation;image modeling;object model	ge s a e Abstract. This paper presents predicted performance for twodimensional cross correlation where two images taken from a planar object model differ by a general perspective geometric transformation. The study shows there exists a window size that will maximize or minimize certain performance parameters for a given perspective distortion. The analysis also indicates many performance criteria have an optimum window size if the geometric distortion includes rotation or scale, but for a given perspective distortion where pitch angle is the only parameter, these measures are not appreciably optimized by any given correlation window size. The performance measures examined are expected peak value, peak-to-sidelobe ratio, probability of correct acquisition (PCA) and false acquisition (PFA), registration error covariance, and average signal-to-noise ratio. The results use statistically consistent image models with arbitrary autocorrelation functions. Monte Carlo simulation verification of theoretical predictions is performed and results are extended to a variety of common area-based image matching techniques. © 1999 SPIE and IS&T. [S1017-9909(99)00101-4]	autocorrelation;cross-correlation;data acquisition;distortion;facial recognition system;image registration;monte carlo method;pitch (music);predictive failure analysis;signal-to-noise ratio;simulation;window function	W. Bryan Bell;Venkat Devarajan;Steven J. Apollo	1999	J. Electronic Imaging	10.1117/1.482714	computer vision;object model;distortion;autocorrelation;computer science;cross-correlation;pattern recognition;mathematics;signal-to-noise ratio;statistics;monte carlo method	Vision	43.82816188199896	-55.740312369171974	22774
7af538209e5fdee8da40ae114a700c605ca3fb43	wavelet approximation-based affine invariant shape representation functions	transformation ondelette;transformation affine;fonction representation forme;algorithms artificial intelligence image enhancement image interpretation computer assisted information storage and retrieval numerical analysis computer assisted pattern recognition automated signal processing computer assisted;image matching;analisis forma;index terms wavelet transform;indexing terms;invariants;wavelet transforms;approximation theory;shape representation;approximation theory wavelet transforms image representation image matching;wavelet transform;approximation coefficients wavelet transforms affine invariant functions shape representation;invariants index terms wavelet transform shape representation affine transformation;image representation;affine transformation;pattern analysis;transformacion ondita;wavelet transformation;transformacion afin;analyse forme;shape wavelet transforms noise shaping robust stability mpeg 7 standard noise level image segmentation cascading style sheets dynamic programming electric shock	In this paper, new wavelet-based affine invariant functions for shape representation are presented. Unlike the previous representation functions, only the approximation coefficients are used to obtain the proposed functions. One of the derived functions is computed by applying a single wavelet transform; the other function is calculated by applying two different wavelet transforms with two different wavelet families. One drawback of the previously derived detail-based invariant representation functions is that they are sensitive to noise at the finer scale levels, which limits the number of scale levels that can be used. The experimental results in this paper demonstrate that the proposed functions are more stable and less sensitive to noise than the detail-based functions.	approximation;coefficient;exhibits as topic;hausdorff dimension;image noise;matching;mpeg-7;wavelet transform	Ibrahim El Rube;Maher Ahmed;Mohamed S. Kamel	2006	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2006.43	wavelet;computer vision;mathematical analysis;discrete mathematics;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;cascade algorithm;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;wavelet transform	Vision	50.23157694991635	-64.42012265413196	22811
c9f449a6b91a9b699b7b9bc3bd0b258c7c50968f	distributed intrinsic functional connectivity patterns predict diagnostic status in large autism cohort	autism spectrum disorder;conditional random forest;diagnostic prediction;intrinsic functional connectivity;machine learning;resting-state fmri	Diagnosis of autism spectrum disorder (ASD) currently relies on behavioral observations because brain markers are unknown. Machine learning approaches can identify patterns in imaging data that predict diagnostic status, but most studies using functional connectivity MRI (fcMRI) data achieved only modest accuracies of 60-80%. We used conditional random forest (CRF), an ensemble learning technique protected against bias from feature correlation (which exists in fcMRI matrices). We selected 252 low-motion resting-state functional MRI scans from the Autism Brain Imaging Data Exchange, including 126 typically developing (TD) and 126 ASD participants, matched for age, nonverbal IQ, and head motion. A matrix of functional connectivities between 220 functionally defined regions of interest was used for diagnostic classification. In several runs, we achieved accuracies of 92-99% for classifiers with >300 features (most informative connections). Features, including pericentral somatosensory and motor regions, were disproportionately informative. Findings differed partially from a previous study in the same sample that used feature selection with random forest (which is biased by feature correlations). External validation in a smaller in-house data set, however, achieved only 67-71% accuracy. The large number of features in optimal models can be attributed to etiological heterogeneity under the clinical ASD umbrella. Lower accuracy in external validation is expected due to differences in unknown composition of ASD variants across samples. High accuracy in the main data set is unlikely due to noise overfitting, but rather indicates optimized characterization of a given cohort.		Afrooz Jahedi;Chanond A. Nasamran;Brian Faires;Juanjuan Fan;Ralph-Axel Müller	2017	Brain connectivity	10.1089/brain.2017.0496	neuroscience;autism;random forest;developmental psychology;resting state fmri;autism spectrum disorder;ensemble learning;asd;neuroimaging;psychology;artificial intelligence;pattern recognition;correlation	ML	24.661260200043056	-78.12521681855553	22876
9d8a50dcf1c545c7afc089a8032c20a58a90823f	automatic recognition of microcalcifications in mammography images through fractal texture analysis		Mammography images are widely used for detection of microcalcifications (MCs), which constitute the early stage of breast cancer. Moreover, these images allow the medical specialist to perform a timely diagnosis and to prevent complications in patients. Automatic identification of MCs in mammography images may be useful as a decision support given by a specialist. In this paper, we construct a mammography image database with medical validation and expert labeling. The test subjects are from a local population located in the Eje cafetero, Colombia. Also, we present a methodology for automatic recognition of microcalcifications based on segmentation with fractal texture analysis (SFTA) and a support vector machine (SVM). For a comparison framework with the state of the art, we compare our methodology with the local binary patterns (LBP) method, that is widely applied in digital images processing. Results show that SFTA methodology for recognition of MCs achieves an accuracy over 92.5% improving significatively when compared to LBP. Also, our database satisfies the epidemiological parameters to represent a local population.	decision support system;digital image;feature detection (computer vision);feature detection (web development);feature extraction;fractal;local binary patterns;sampling (signal processing);statistical model;support vector machine	Hernán Darío Vargas Cardona;Álvaro Orozco;Mauricio A. Álvarez	2014		10.1007/978-3-319-14364-4_81	computer vision	AI	35.14296522565069	-74.76901633674333	22889
00bb6936ca96542916bb8456876d1f61fb838057	adding curvature to minimum description length shape models	cost function;correspondence problem;shape modelling;face recognition;minimum description length;silhouettes;curvature;shape modeling;point correspondence problem	The Minimum Description Length (MDL) approach to shape modelling seeks a compact description of a set of shapes in terms of the coordinates of marks on the shapes. It has been shown that the mark positions resulting from this optimisation to a large extent solve the so-called point correspondence problem: How to select points on shapes defined as curves so that the points correspond across a data set. However, this MDL approach does not capture important shape characteristics related to the curvature of the curves, and occasionally it places marks in obvious conflict with the human notion of point correspondence. This paper shows how the MDL approach can be fine-tuned by adding a term to the cost function expressing the mismatch of curvature features across the data set. The method is illustrated on silhouettes of adult heads. The MDL method is able to solve the point correspondence problem and a classification of the heads into male and female improves dramatically when using the MDL-generated marks.	correspondence problem;loss function;mdl (programming language);mathematical optimization;minimum description length	Hans Henrik Thodberg;Hildur Ólafsdóttir	2003		10.5244/C.17.26	facial recognition system;computer vision;mathematical optimization;minimum description length;topology;computer science;machine learning;mathematics;geometry;curvature;correspondence problem	Vision	47.64088480814557	-53.55738928243878	22920
9dc5b1487f4f78f24b7e53a4ccfee5e7608dfdad	fast compressed domain copy detection with motion vector imaging		With an increasing number of videos uploaded to the Internet, how to fast detect copy videos in compressed domain has been paid greater attention to. Many researchers have tried using information in motion vector to be the feature. However, in these methods motion vectors are used as histogram, which lacks structural information in detail. To address this problem, in this paper we propose a new way of using Motion Vector Imaging. We first extract motion vector from a compressed video, and then project them onto a canvas to generate a MVI which contains detail motion information. Based on these MVIs, a siamese deep neural network is utilized to train on pairs from dataset and one side of the network is applied to extract features. Finally, a cascade system using MVI model and I frames is used to do fast copy detection. Results on public dataset CC_WEB_VIDEO show that MVI can achieve high recall rate and precision rate at a high speed.	artificial neural network;data compression;deep learning;internet;sensitivity and specificity;world wide web	Yuanyuan Yang;Yixiong Zou;Yemin Shi;Qingsheng Yuan;Yaowei Wang;Yonghong Tian	2018	2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)	10.1109/MIPR.2018.00086	the internet;decoding methods;motion vector;feature extraction;artificial neural network;hidden markov model;computer science;upload;artificial intelligence;pattern recognition;histogram	Vision	27.12711654569411	-54.899825305469626	22931
ded3e219b2d6564deb5758211037e5af4774547d	estimation of fractal dimension in different color model			fractal dimension	Sumitra Kisan;Sarojananda Mishra;Ajay Chawda;Sanjay Nayak	2018	IJKDB	10.4018/IJKDB.2018010106	machine learning;color model;computer science;artificial intelligence;fractal dimension	Vision	41.83104346477769	-65.70909960565673	22942
6cc2b8af76d4a3866e63801bd2f5cb89e7f32dd8	a general framework and new alignment criterion for dense optical flow	art;image motion analysis;mathematics;image processing;optical computing;image motion analysis anisotropic magnetoresistance geometrical optics optical computing computer vision smoothing methods image processing mathematics art optical devices;computer vision;smoothing methods;anisotropic magnetoresistance;optical flow;optical devices;geometrical optics	The problem of dense optical flow computation is addressed from a variational viewpoint. A new geometric framework is introduced. It unifies previous art and yields new efficient methods. Along with the framework a new alignment criterion suggests itself. It is shown that the alignment between the gradients of the optical flow components and between the latter and the intensity gradients is an important measure of the flow’s quality. Adding this criterion as a requirement in the optimization process improves the resulting flow. This is demonstrated in synthetic and real sequences.	anisotropic diffusion;computation;embedded system;gradient;mathematical optimization;matrix regularization;optical flow;synthetic intelligence;variational principle	Rami Ben-Ari;Nir A. Sochen	2006	2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)	10.1109/CVPR.2006.25	magnetoresistance;geometrical optics;computer vision;image processing;computer science;theoretical computer science;optical flow;mathematics;geometry;optical computing	Vision	53.212139135129796	-71.9868387981262	22950
a2ef355ad21daab7748267e4ee8a27a0f07b6b4d	three dimensional gesture recognition using modified matching algorithm	utilisation information;image tridimensionnelle;interfase usuario;analisis componente principal;uso informacion;human computer interaction;reconnaissance geste;image processing;traitement image stereoscopique;information use;user interface;gesture;extraction forme;procesamiento imagen;traitement image;three dimensional;color segmentation;extraccion forma;principal component analysis;image sequence;stereo image processing;analyse composante principale;tridimensional image;interface utilisateur;secuencia imagen;information system;imagen color;pattern extraction;geste;gesture recognition;systeme information;image couleur;sequence image;imagen tridimensional;color image;gesto;sistema informacion	User-friendly Human-Computer interaction becomes more important accordance with rapid development of various information systems. In this paper we describe a three-dimensional gesture recognition algorithm and a system that adopts the algorithm for non-contact human-computer interaction. From sequence of stereo images, five feature regions are extracted with simple color segmentation algorithm and then those are used for three dimensional locus calculation processing. However, the result is not so stable, noisy, that we introduce principal component analysis method to get more robust gesture recognition results. This method can overcome the weakness of conventional algorithms since it directly uses three-dimensional information for human gesture recognition.	algorithm;gesture recognition;pattern matching	Hwan-Seok Yang;Jong-Min Kim;Seung-Kyu Park	2005		10.1007/11539117_34	three-dimensional space;computer vision;color image;image processing;computer science;gesture recognition;user interface;gesture;information system;principal component analysis;computer graphics (images)	Robotics	45.82974449389497	-59.227312403356876	22996
1ac96dad8885fdc66050008f09f7b90580af34b4	a model-free approach for posture classification	image motion analysis;thinning operator;human body structures;image classification;human target recognition posture classification model free approach human body structures digital images motion detection synthetic representation thinning operator geometrical analysis;model free approach;human target recognition;image representation;feature extraction;human body;feature extraction gesture recognition object detection image motion analysis image representation image classification;digital image;digital images;motion detection;gesture recognition;synthetic representation;geometrical analysis;object detection;humans skeleton motion analysis motion detection image analysis digital images target recognition layout surveillance performance analysis;posture classification;pose estimation	This paper describes a peculiar methodology for identifying and classifying the human body structures depicted in digital images. The methodology is articulated in a number of successive steps: an initial process of motion detection recognises human targets into the examined scene; subsequently, a synthetic representation of the previously detected human figures is obtained in form of skeleton, by means of a thinning operator. Finally, the pose estimation step is performed on the basis of a geometrical analysis conducted over a set of features related to the extracted skeletons. Experimental evidence of the appropriateness of the overall methodology is also presented.	digital image;norm (social);poor posture;statistical classification;synthetic intelligence;thinning	Ciro Castiello;Tiziana D'Orazio;Anna Maria Fanelli;Paolo Spagnolo;Maria Alessandra Torsello	2005	IEEE Conference on Advanced Video and Signal Based Surveillance, 2005.	10.1109/AVSS.2005.1577280	computer vision;speech recognition;computer science;pattern recognition;gesture recognition;digital image	Vision	40.84478154056356	-52.30235757515496	22998
4b37768ed4ed2f02268e3a429d7f93735f0bea41	effect of input size on the classification of lung nodules using convolutional neural networks		Recent studies have shown that lung cancer screening using annual low-dose computed tomography (CT) reduces lung cancer mortality by 20% compared to traditional chest radiography. Therefore, CT lung screening has started to be used widely all across the world. However, analyzing these images is a serious burden for radiologists. The number of slices in a CT scan can be up to 600. Therefore, computer-aided-detection (CAD) systems are very important for faster and more accurate assessment of the data. In this study, we proposed a framework that analyzes CT lung screenings using convolutional neural networks (CNNs) to reduce false positives. We trained our model with different volume sizes and showed that volume size plays a critical role in the performance of the system. We also used different fusions in order to show their power and effect on the overall accuracy. 3D CNNs were preferred over 2D CNNs because 2D convolutional operations applied to 3D data could result in information loss. The proposed framework has been tested on the dataset provided by the LUNA16 Challenge and resulted in a sensitivity of 0.831 at 1 false positive per scan.	artificial neural network;ct scan;computer-aided design;convolutional neural network;information;radiography;tomography	Gorkem Polat;Yesim Serinagaoglu Dogrusoz;Ugur Halici	2018	2018 26th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2018.8404659	cancer;computer vision;computer science;artificial intelligence;image segmentation;pattern recognition;convolutional neural network;lung cancer screening;lung cancer;computed tomography;false positive paradox;lung	HPC	32.237472382945064	-76.2671889163263	22999
9fe0721373c36ee56cfb0a166e2f5e1e63df38c6	similarity-based retrieval of images using color histograms	analisis imagen;similarity metric;quantization;vision ordenador;image processing;color space;representation image;procesamiento imagen;color histogram;traitement image;computer vision;image representation;algorithms;image analysis;vision ordinateur;imagen color;analyse image;content based retrieval;image couleur;color image;image retrieval	The color histogram of an image has been widely used as a feature descriptor for the image in content-based retrieval applications. In this paper, some results from our investigation efforts into the usage are reported. We outline three typical color space quantization schemes used in our experiments and introduce the soft-decision histogramming method to eliminate the discontinuity problem in traditional color histogram population process. Then, to improve the effectiveness of color histogram based retrieval algorithms, several similarity metrics are proposed for comparing color histograms, including three special forms of the Kantorovich metric.	algorithm;color depth;color histogram;color space;experiment;population process;reflections of signals on conducting lines;visual descriptor	Keshi Chen;Stephen Demko;Ruifeng Xie	1999		10.1117/12.333885	color histogram;computer vision;color quantization;color normalization;histogram matching;mathematics;histogram equalization;information retrieval;computer graphics (images)	Vision	43.02809924416636	-61.61114496957527	23010
8667d6bff7e2c4477195b8bdead8fd13b54cb5f7	integrated feature exploration for handwritten devanagari numeral recognition		In this paper, the statistical feature extraction techniques are explored, incrementally combined using different methods and analyzed for the recognition of isolated offline handwritten Devanagari numerals. The techniques selected are zoning, directional distance distribution, Zernike moments, discrete cosine transform, and Gabor filter that encapsulate the mutually exclusive statistical features like average pixel densities, directional distribution, orthogonal invariant moments, elementary frequency components, and space frequency component, respectively. The standard benchmark handwritten Devanagari numeral database provided by ISI, Kolkata, is used for the experimentation and 1-nearest neighbor and support vector machine for classification. The accuracy achieved with individual feature extraction techniques ranges from 86.87% to 98.96%. Further, features are integrated with methods like feature concatenation, majority voting, and a new proposed methodology by us named winners pooling. The maximum recognition obtained through feature integration is 99.14%.		Shraddha Arya;Indu Chhabra;Gurpreet Singh Lehal	2017		10.1007/978-981-10-7895-8_12	numeral system;support vector machine;zernike polynomials;gabor filter;concatenation;feature extraction;discrete cosine transform;artificial intelligence;invariant (mathematics);pattern recognition;mathematics	Vision	35.514889393919304	-60.103767580193036	23022
38192a0f9261d9727b119e294a65f2e25f72d7e6	facial feature point detection: a comprehensive survey		This paper presents a comprehensive survey of facial feature point detection with the assistance of abundant manually labeled images. Facial feature point detection favors many applications such as face recognition, animation, tracking, hallucination, expression analysis and 3D face modeling. Existing methods can be categorized into the following four groups: constrained local model (CLM)-based, active appearance model (AAM)-based, regression-based, and other methods. CLM-based methods consist of a shape model and a number of local experts, each of which is utilized to detect a facial feature point. AAM-based methods fit a shape model to an image by minimizing texture synthesis errors. Regression-based methods directly learn a mapping function from facial image appearance to facial feature points. Besides the above three major categories of methods, there are also minor categories of methods which we classify into other methods: graphN. Wang VIPS Lab, School of Electronic Engineering, Xidian University, 710071, Xi’an, P. R. China E-mail: nannanwang.xidian@gamil.com X. Gao VIPS Lab, School of Electronic Engineering, Xidian University, 710071, Xi’an, P. R. China E-mail: xbgao@mail.xidian.edu.cn D. Tao Centre for Quantum Computation & Intelligent Systems, Faculty of Engineering & Information Technology, University of Technology, Sydney, 235 Jones Street, Ultimo, NSW 2007, Australia E-mail: Dacheng.Tao@uts.edu.au X. Li School of Computer Science and Information Systems, Birkbeck College, University of London, Malet Street, London, WC1E 7HX, U.K. E-mail: xuelong@dcs.bbk.ac.uk ical model-based methods, joint face alignment methods, independent facial feature point detectors, and deep learning-based methods. Though significant progress has been made, facial feature point detection is limited in its success by wild and real-world conditions: variations across poses, expressions, illuminations, and occlusions. A comparative illustration and analysis of representative methods provide us a holistic understanding and deep insight into facial feature point detection, which also motivates us to explore promising future directions.	active appearance model;categorization;channel length modulation;computation;computer science;computer vision;database;deep learning;electronic engineering;facial recognition system;feature learning;graphical model;graphical user interface;holism;information systems;jones calculus;linear algebra;pixel;radiation pattern;scale-invariant feature transform;sensor;texture synthesis;vips (software);ical	Nannan Wang;Xinbo Gao;Dacheng Tao;Xuelong Li	2018	Neurocomputing	10.1016/j.neucom.2017.05.013	machine learning;artificial intelligence;animation;deep learning;facial recognition system;pattern recognition;active appearance model;face hallucination;parametric statistics;nonparametric statistics;computer science;graphical model	Vision	30.610239618797745	-56.501745559955715	23031
edf53544c2f67971bd535b9b9c2f6da23eaed232	image segmentation by means of fuzzy entropy measure	analisis imagen;evaluation function;image segmentation;image processing;edge detection;algoritmo borroso;procesamiento imagen;segmentation;traitement image;search trees;optimal path;fuzzy algorithm;algorithme flou;image analysis;analyse image;segmentacion;control strategy;problem solving	The paper describes an algorithm for image segmentation using fuzzy entropy measure. The relation between the fuzzy entropy of an image domain and the fuzzy entropy of its subdomains is explored as a uniformity predicate. With the aim of implementing the model, we have introduced a well known technique of Problem Solving. The most important roles of our model are played by the Evaluation Function (EF) and the Control Strategy. So the EF is related to the ratio between the fuzzy entropy of one region or zone of the picture and the fuzzy entropy of the entire picture. The Control Strategy determines the optimal path in the search tree (quadtree) so that the nodes of the optimal path have minimal fuzzy entropy. The paper shows some comparisons between the proposed algorithm and classical edge detection techniques.	image segmentation	Cecilia Di Ruberto;Michele Nappi;Sergio Vitulano	1997		10.1007/3-540-63507-6_204	computer vision;mathematical optimization;combinatorics;image analysis;edge detection;binary entropy function;defuzzification;image processing;fuzzy mathematics;fuzzy classification;computer science;principle of maximum entropy;fuzzy number;machine learning;evaluation function;fuzzy measure theory;mathematics;image segmentation;segmentation;maximum entropy spectral estimation;fuzzy set operations	NLP	45.78705230946471	-64.209032279587	23040
290bbfcbeba3f9bcb80049fe7a0d47d9a1baa0ed	automation of pavement surface crack detection with a matched filtering to define the mother wavelet function used	automation abstracts noise continuous wavelet transforms;binary image postprocessing automatic pavement surface crack detection matched filtering mother wavelet function pavement surface images continuous wavelet transform complex coefficient maps angle information modulus information road texture maximal wavelet coefficient values;wavelet transforms crack detection image filtering image matching image texture mechanical engineering computing roads	This paper presents a new approach in automation for crack detection on pavement surface images. The method is based on the continuous wavelet transform. In the first step, a 2D continuous wavelet transform for several scales is per-formed. Complex coefficient maps are built. The angle and modulus information are used to keep significant coefficients. The mother wavelet function is defined using a matched filtering, thus the method is self-adapted to the road texture. No user intervention is needed. Then, wavelet coefficients maximal values are searched and their propagation through scales is analyzed. Finally, a post-processing gives a binary image which indicates the presence or not of cracks on the pavement surface image.	automation;binary image;coefficient;continuous wavelet;map;matched filter;maximal set;modulus of continuity;software propagation;video post-processing;wavelet transform	Peggy Subirats;Jean Dumoulin;Vincent Legeay;Dominique Barba	2006	2006 14th European Signal Processing Conference		wavelet;computer vision;electronic engineering;speech recognition;second-generation wavelet transform;continuous wavelet transform;cascade algorithm;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;wavelet transform	Robotics	51.15909156889164	-66.22435585135479	23044
207844ec15f1a53c5df9d45bb6271123e1262540	texture analysis of the media-layer of the left and right common carotid artery	gray level difference statistics correlation texture analysis media layer left common carotid artery right common carotid artery intima media thickness cardiovascular disease texture feature extraction longitudinal section ultrasound images symptomatic subjects automatic segmention snakes segmentation system;ultrasonic imaging blood vessels cardiovascular system diseases feature extraction image segmentation medical image processing statistical analysis;ultrasonic imaging image segmentation carotid arteries correlation media feature extraction atherosclerosis	The intima-media thickness (IMT) of the common carotid artery (CCA) is a well-known indicator of cardiovascular disease (CVD). The objective of this study was to investigate the application of texture analysis of the medial layer (ML) of the CCA, and how texture features vary between the left and right carotid sides, as well as how these are affected by CVD. The study was performed on 200 longitudinal-section ultrasound images from 150 normal subjects, and 50 symptomatic subjects suffering with CVD. The ML was segmented automatically by a snakes segmentation system and 61 different texture features were extracted. This study showed that only the gray level difference statistics (GLDS) correlation measure of the ML component could be used to differentiate between normal subjects, and subjects suffering with CVD for either the left or the right CCA sides. We furthermore found that a number of texture features were significantly different between the left and the right CCA sides. We have found no other studies in the literature where these findings could be compared to. These findings should be further validated on a larger number of subjects as well as combined with additional risk factors.	grayscale;medial graph;thickness (graph theory)	Niki Georghiou;Maura Griffin;Efthyvoulos C. Kyriacou;Andrew Nicolaides;Constantinos S. Pattichis	2014	IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)	10.1109/BHI.2014.6864456	radiology;medicine;pathology;surgery	HCI	37.7749633210536	-77.54947181409032	23208
b11451a43895ae89d115c1fe0f45813127df6061	a real-time hand tracker using variable-length markov models of behaviour	modelizacion;filtering;interfase usuario;vision ordenador;filtrage;pistage;mise a jour;human computer interaction;estimation mouvement;reconnaissance geste;image processing;modelo markov;variable length markov models;behavioral analysis;user interface;fitts law;relacion orden;gesture;real time;estimacion movimiento;filtrado;stochastic simulation;rastreo;procesamiento imagen;ordering;motion estimation;probabilistic approach;traitement image;computer vision;man machine system;actualizacion;modelisation;posture;relation ordre;recognition;markov model;behaviour modelling;analyse tâche;particle filter;enfoque probabilista;approche probabiliste;task analysis;robustesse;temps reel;analyse comportementale;retard;postura;hand tracking;comparative method;particle filtering;tiempo real;sistema hombre maquina;robustness;interface utilisateur;analisis conductual;vision ordinateur;latency;modele markov;visual tracking;retraso;drag and drop;modeling;geste;variable length markov;models;gesture recognition;updating;tracking;gesto;robustez;systeme homme machine	We present a novel approach for visual tracking of structured behaviour as observed in human–computer interaction. An automatically acquired variable-length Markov model is used to represent the high-level structure and temporal ordering of gestures. Continuous estimation of hand posture is handled by combining the model with annealed particle filtering. The stochastic simulation updates and automatically switches between different model representations of hand posture that correspond to distinct gestures. The implementation executes in real time and demonstrates significant improvement in robustness over comparable methods. We provide a measurement of user performance when our method is applied to a Fitts’ law drag-and-drop task, and an analysis of the effects of latency that it introduces. 2007 Elsevier Inc. All rights reserved.	drag and drop;fitts's law;high- and low-level;human–computer interaction;level structure;markov chain;markov model;network switch;particle filter;poor posture;real-time clock;simulation;video tracking	Nikolay Stefanov;Aphrodite Galata;Roger J. Hubbold	2007	Computer Vision and Image Understanding	10.1016/j.cviu.2006.10.017	computer vision;simulation;particle filter;image processing;computer science;artificial intelligence;gesture recognition	Vision	46.63485475955755	-56.83515859577327	23245
59c058f6b3abf076a3c8cd2840f8489dee6777ac	comparison of convolutional neural network models for food image classification		According to some estimates of World Health Organization (WHO), in 2014, more than 1.9 billion adults aged 18 years and older were overweight. Overall, about 13% of the worldu0027s adult population (11% of men and 15% of women) were obese. 39% of adults aged 18 years and over (38% of men and 40% of women) were overweight. The worldwide prevalence of obesity more than doubled between 1980 and 2014. The purpose of this study is to design a convolutional neural network model and provide a food dataset collection to distinguish the nutrition groups which people take in daily life. For this aim, both two pretrained models Alexnet and Caffenet were finetuned and a similar structure was trained with dataset. Food images were generated from Food-11, FooDD, Food100 datasets and web archives. According to the test results, finetuned models provided better results than trained structure as expected. However, trained model can be improved by using more training examples and can be used as specific structure for classification of nutrition groups.	computer vision;convolutional neural network	Gozde Ozsert Yigit;Buse Melis Ozyildirim	2018	J. Information Telecommunication	10.1080/24751839.2018.1446236	convolutional neural network;obesity;artificial neural network;machine learning;contextual image classification;overweight;population;computer science;artificial intelligence	AI	27.62443302734451	-76.45844502864173	23317
8140cdf50ef53f323e196c653b4b7409d99eacb9	a study of affine matching with bounded sensor error	perspective projection;affine transformation;false positive;coordinate system	Affine transformations of the plane have been used in a number of model-based recognition systems. Because the underlying mathematics are based on exact data, in practice various heuristics are used to adapt the methods to real data where there is positional uncertainty. This paper provides a precise analysis of affine point matching under uncertainty. We obtain an expression for the range of affine-invariant values that are consistent with a given set of four points, where each image point lies in an ∈-disc of uncertainty. This range is shown to depend on the actualx-y-positions of the data points. In other words, given uncertainty in the data there are no representations that are invariant with respect to the Cartesian coordinate system of the data. This is problematic for methods, such as geometric hashing, that are based on affine-invariant representations. We also analyze the effect that uncertainty has on the probability that recognition methods using affine transformations will find false positive matches. We find that there is a significant probability of false positives with even moderate levels of sensor error, suggesting the importance of good verification techniques and good grouping techniques.		W. Eric L. Grimson;Daniel P. Huttenlocher;David W. Jacobs	1992		10.1007/3-540-55426-2_34	mathematical optimization;combinatorics;discrete mathematics;perspective;affine coordinate system;type i and type ii errors;coordinate system;affine arithmetic;affine transformation;harris affine region detector;mathematics;affine shape adaptation;statistics	Vision	43.50842281814829	-54.80337644719348	23357
62ca1ff1a72602eaecfe4b5ba04363e50bc53cc1	curved inertia frames and the skeleton sketch: finding salient frames of reference	perceptual phenomena;image coding;environment bias computer vision shape description skeleton sketch salient frames of reference curved inertia frames curved axes of inertia saliency measure canonical description perceptual phenomena grouping based on symmetry;curved axes of inertia;working environment noise;computational geometry;filters;reference frame;curved inertia frames;computerised pattern recognition;skeleton sketch;shape measurement;grouping based on symmetry;skeleton;environment bias;computer vision;canonical description;salient frames of reference;artificial intelligence;noise shaping;visual perception;saliency measure;humans;shape description;frame of reference;skeleton shape measurement humans artificial intelligence laboratories working environment noise noise shaping image coding computer vision filters;visual perception computational geometry computer vision computerised pattern recognition	"""In this paper we introduce the Curved Inertia Frames (CI? a novel definition of curved axis of inertia. e present a scheme for finding a frame of reference of a shape in an image based on such a definition and we discuss how the frame can be used to describe the shape. The scheme assigns a saliency measure to each component of the reference frame that is a measure of its relevance, so that large and central parts play a more central role in the description of the shape. The scheme also computes a major axis that is used to organize the description of the shape, so that a canonical description can be obtained. One of the remarkable features of the scheme is its tolerance to noisy and spurious data. Several perceptual phenomena observed in humans such as grouping based on symmetry and environmental bias in shape description can be reproduced naturally in this scheme. The scheme also supports other o p erations such as finding the most """"interesting"""" point in the image or defining what is inside and what is outside an object. An extension of the scheme to find high, long and smooth curves on an arbitrary surface is presented. The extension is illustrated on the problem of finding salient blobs in images and it is suggested that similar schemes be used in other early and middle level vision tasks."""	apache axis;reference frame (video);relevance	J. Brian Subirana-Vilanova	1990		10.1109/ICCV.1990.139622	reference frame;frame of reference;computer vision;noise shaping;visual perception;computational geometry;computer science;mathematics;geometry;skeleton	Vision	49.15439460487564	-61.613644051036204	23361
c2e9bbea6335a313d3fc250ee7aeff547c0a9f62	a cybernetic multiresolution system for disparity estimation in stereo vision	cybernetics;simulated annealing algorithm;disparity estimation;simulation;simulated annealing;info eu repo semantics article;energy function;stereo vision;visual perception;geometric constraints;design methodology	Patricia Compañ, Rosana Satorre y Ramón Rizo {patricia, rosana, rizo}@dccia.ua.es Grupo i3a: Informática Industrial e Inteligencia Artificial Departamento de Ciencia de la Computación e Inteligencia Artificial Universidad de Alicante Abstract This paper presents a new stereo correspondence algorithm based on an integrated model that incorporates different modules corresponding to every stage. Firstly, original images are scaled in order to reduce its size. A disparity map, which is the basis of the process, is obtained from these reduced images. The disparity map is obtained by building and minimizing an energy function under a multiresolution scheme. The energy function integrates grey level characteristics, non parametric transforms, edges, smoothness and unicity. The disparity obtained at each level of resolution is interpolated and incorporated to the next level. Our model produces a dense disparity map. The algorithm has been tested with several kinds of real images to show its flexibility and a metrics to evaluate the quality of a disparity map is proposed.	algorithm;cybernetics;grayscale;interpolation;linear algebra;map;mathematical optimization;stereopsis	Patricia Compañ;Rosana Satorre;Ramón Rizo Aldeguer	2006	Kybernetes	10.1108/03684920610662610	computer vision;simulation;simulated annealing;cybernetics;computer science;artificial intelligence	Vision	50.4632876692211	-59.28008159679603	23402
bd11ea664a047371bd304f2cbd11888c34191228	erratum to: a comprehensive survey of handwritten document benchmarks: structure, usage and evaluation	signal image and speech processing;biometrics;pattern recognition;image processing and computer vision			Muhammad Rashid Hussain;Ahsen Raza;Imran Siddiqi;Khurram Khurshid;Chawki Djeddi	2016	EURASIP J. Image and Video Processing	10.1186/s13640-016-0142-5	computer vision;speech recognition;computer science;archaeology;digital image processing;pattern recognition;biometrics	Networks	34.36193840119274	-62.863424551012244	23407
53ec13ff5d716a64f647a3b323e17b390a841c33	iris recognition system design and development of large animals for tracing source of infection	animals;image preprocessing;image coding;matching operation;design engineering;iris recognition system design;biometrics access control;edge detection;image matching;prototypes;infection virus;iris recognition;design optimization;large animal infection source tracing;hamming distance;image edge detection;system design;feature extraction;medical image processing;mathematical model;pattern recognition;diseases;veterinary medicine;infectious disease iris recognition system design large animal infection source tracing edge detection encoding image preprocessing feature extraction matching operation hamming distance infection virus;humans;infectious disease;iris;encoding;veterinary medicine biometrics access control diseases edge detection feature extraction image coding image matching medical image processing;iris recognition animals diseases image edge detection prototypes humans image coding hardware design optimization design engineering;hardware	Iris recognition system design and development of large animals is used to make the large animals be recognizable and traceability from the farm to the slaughterhouse. We can identify the animals when people find it carrying infectious diseases. On the basis of experiments on cows, this paper introduces the iris recognition system design; and we mainly introduce the algorithms of edge detection and iris-encoding used in this system. Iris images are acquired by special capture device. The images will be translated to iris encoding by image preprocessing, feature extraction and matching operations. By calculating the hamming distance between iris-encoding of different individuals, we can distinguish different individuals. The result of the iris recognition can help us to identify where the animals carrying infection virus come from, and then find the source of infection.	algorithm;edge detection;experiment;feature extraction;hamming distance;iris recognition;matching (graph theory);preprocessor;systems design;traceability	Xiaoqiang Wang;Lindu Zhao;Qiang Kong	2009	2009 International Joint Conference on Computational Sciences and Optimization	10.1109/CSO.2009.271	computer vision;hamming distance;multidisciplinary design optimization;speech recognition;edge detection;feature extraction;infectious disease;computer science;mathematical model;iris recognition;prototype;encoding;statistics;systems design	Vision	36.562403145538305	-72.75402348256395	23418
f0dbc1a754a858a1df2909ba2cd03a3c06451070	early identification of mild cognitive impairment using incomplete random forest-robust support vector machine and fdg-pet imaging	robust optimization;fdg pet;alzheimer s disease;mild cognitive impairment	Alzheimer's disease (AD) is the most common type of dementia and will be an increasing health problem in society as the population ages. Mild cognitive impairment (MCI) is considered to be a prodromal stage of AD. The ability to identify subjects with MCI will be increasingly important as disease modifying therapies for AD are developed. We propose a semi-supervised learning method based on robust optimization for the identification of MCI from [18F]Fluorodeoxyglucose PET scans. We extracted three groups of spatial features from the cortical and subcortical regions of each FDG-PET image volume. We measured the statistical uncertainty related to these spatial features via transformation using an incomplete random forest and formulated the MCI identification problem under a robust optimization framework. We compared our approach to other state-of-the-art methods in different learning schemas. Our method outperformed the other techniques in the ability to separate MCI from normal controls.		Shen Lu;Yong Xia;Tom Weidong Cai;Michael J. Fulham;David Dagan Feng	2017	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2017.01.001	robust optimization;artificial intelligence	ML	26.06181248586422	-78.01952299330098	23447
058d0f273d7a607efc5f477e3ff8a802c95019b9	tracking in low frame rate video: a cascade particle filter with discriminative observers of different life spans	modelizacion;filtre particule;longevidad;sudden variation;cascade circuit;clutter;motion continuity;echantillonnage multiple;pistage;video signal processing importance sampling object detection particle filtering numerical methods target tracking;image processing;longevite;video signal processing;surveillance;search space;longevity;analisis forma;motion vision and scene understanding;rastreo;procesamiento imagen;muestreo multiple;variacion brusca;discriminative observers;intelligence artificielle;filtro particulas;probabilistic approach;motion;traitement image;observador;embedded system;circuit cascade;modelisation;observateur;fouillis echo;abrupt motion;senal video;signal video;particle filter;enfoque probabilista;approche probabiliste;cascade particle filter;confusion eco;object tracking;echantillonnage importance;multiple sampling;poursuite cible;inferencia;video signal;particle tracking particle filters target tracking costs face detection monte carlo methods cameras real time systems embedded system surveillance;artificial intelligence;vision and scene understanding;pattern analysis;algorithms artificial intelligence discriminant analysis image enhancement image interpretation computer assisted imaging three dimensional motion pattern recognition automated reproducibility of results sensitivity and specificity subtraction technique video recording;inteligencia artificial;variation brusque;particle tracking;particle filters;target tracking;scene understanding;importance sampling;face detection;low frame rate video;modeling;observer;importance sampling low frame rate video cascade particle filter discriminative observers object tracking motion continuity search space fast appearance variation;life span;discriminative model;monte carlo methods;cameras;inference;circuito cascada;analyse forme;tracking;object detection;particle filtering numerical methods;fast appearance variation;real time systems	Tracking object in low frame rate video or with abrupt motion poses two main difficulties which most conventional tracking methods can hardly handle: 1) poor motion continuity and increased search space; 2) fast appearance variation of target and more background clutter due to increased search space. In this paper, we address the problem from a view which integrates conventional tracking and detection, and present a temporal probabilistic combination of discriminative observers of different lifespans. Each observer is learned from different ranges of samples, with different subsets of features, to achieve varying level of discriminative power at varying cost. An efficient fusion and temporal inference is then done by a cascade particle filter which consists of multiple stages of importance sampling. Experiments show significantly improved accuracy of the proposed approach in comparison with existing tracking methods, under the condition of low frame rate data and abrupt motion of both target and camera.	cascade device component;categories;clutter;detectors;discriminative model;experiment;importance sampling;increment;inference;online and offline;particle filter;physical object;profiling (computer programming);sampling (signal processing);sampling - surgical action;scott continuity;software propagation;tracking system;observers	Yuan Li;Haizhou Ai;Takayoshi Yamashita;Shihong Lao;Masato Kawade	2007	2007 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/TPAMI.2008.73	computer vision;simulation;particle filter;image processing;computer science;video tracking;mathematics;statistics;computer graphics (images)	Vision	47.16592418255804	-56.68342548857229	23539
8e09fc9b7cff81a9641bc9d6d4663058a0efb0b9	an experimental study of alternative shape-based image retrieval techniques	delaunay triangulation;object database;multimedia application;similarity retrieval;shape representation;fourier descriptors;shape similarity;shape based image retrieval;similarity measure;image retrieval	Besides traditional applications (e.g., CAD/CAM and Trademark registry), new multimedia applications such as structured video, animation, and MPEG-7 standard require the storage and management of well-defined objects. These object databases are then queried and searched for different purposes. A sample query might be “find all the scenes that contain a certain object.” Shape of an object is an important feature for image and multimedia similarity retrievals. Therefore, in this study we focus on shape-based object retrieval and conduct a comparison study on four of such techniques (i.e., Fourier descriptors, grid based, Delaunay triangulation, and our proposed MBC-based methods (e.g., MBC-TPVAS)). We measure the effectiveness of the similarity retrieval of the four different shape representation methods in terms of recall and precision. Our results show that the similarity retrieval accuracy of our method (MBC-TPVAS) is as good as that of the other methods, while it observes the lowest computation cost to generate the shape signatures of the objects. Moreover, it has low storage requirement, and a comparable computation cost to compute the similarity between two shape signatures. In addition, MBC-TPVAS requires no normalization of the objects, and is the only method that has direct support for S-RST query types. In this paper, we also propose a new shape description taxonomy.	algorithm;antivirus software;bounding sphere;computation;computer-aided design;database;delaunay triangulation;experiment;goto;image retrieval;intel matrix raid;java;low-energy adaptive clustering hierarchy;mbc-55x;mpeg-7;minimal instruction set computer;precision and recall;semantic similarity;type signature	Cyrus Shahabi;Maytham Safar	2006	Multimedia Tools and Applications	10.1007/s11042-006-0070-y	active shape model;computer vision;visual word;delaunay triangulation;image retrieval;computer science;pattern recognition;information retrieval	DB	39.1479443455323	-59.19823536368866	23549
77d81146484a521eadd0d3df53e26d6aef328560	computer-aided detection of mammographic masses based on content-based image retrieval	databases;vector spaces;computer aided diagnosis;receiver operator characteristic;euclidean distance;receivers;feature vector;medical diagnostics;biopsy;region of interest;indexation;computer aided detection;breast mass;mammography;content based image retrieval;cad systems;pathology;leave one out	A method for computer-aided detection (CAD) of mammographic masses is proposed and a prototype CAD system is presented. The method is based on content-based image retrieval (CBIR). A mammogram database containing 2000 mammographic regions is built in our prototype CBIR-CAD system. Every region of interested (ROI) in the database has known pathology. Specifically, there are 583 ROIs depicting biopsy-proven masses, and the rest 1417 ROIs are normal. Whenever a suspicious ROI is detected in a mammogram by a radiologist, it can be submitted as a query to this CBIRCAD system. As the query results, a series of similar ROI images together with their known pathology knowledge will be retrieved from the database and displayed in the screen in descending order of their similarities to the query ROI to help the radiologist to make the diagnosis decision. Furthermore, our CBIR-CAD system will output a decision index (DI) to quantitatively indicate the probability that the query ROI contains a mass. The DI is calculated by the query matches. In the querying process, 24 features are extracted from each ROI to form a 24-dimensional vector. Euclidean distance in the 24-dimensional feature vector space is applied to measure the similarities between ROIs. The prototype CBIR-CAD system is evaluated based on the leave-one-out sampling scheme. The experiment results showed that the system can achieve a receiver operating characteristic (ROC) area index AZ =0.84 for detection of mammographic masses, which is better than the best results achieved by the other known mass CAD systems.© (2007) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	content-based image retrieval	Renchao Jin;Bo Meng;Enmin Song;Xiangyang Xu;Luan Jiang	2007		10.1117/12.709773	computer vision;computer science;data mining;multimedia	Vision	35.37370247575896	-77.46347273928092	23573
e62d3871f31040ef3df006617120bebf97591721	localized multiscale texture based retrieval of neurological image	neurodegenerative disorders;neurological image retrieval;data management;different irregular to regular shape padding methods;medical disorders;positron emission tomography;orthographic projection method;feature extraction transforms neuroimaging image retrieval positron emission tomography educational institutions;computational complexity;feature extraction;neuroimaging;transforms;localized multiscale texture;content based image retrieval framework;localized multiscale discrete curvelet transform;content based retrieval;data retrieval;computational complexity localized multiscale texture neurological image retrieval data management data retrieval content based image retrieval framework localized multiscale discrete curvelet transform feature extraction different irregular to regular shape padding methods neurodegenerative disorders orthographic projection method;medical disorders computational complexity content based retrieval feature extraction image retrieval;image retrieval	The volume and complexity of neurological images have significantly increased, which leads to challenges in efficient data management and retrieval. In this paper, we developed a new content-based image retrieval framework with the localized multiscale Discrete Curvelet Transform (DCvT) features extracted from parametric neurological images. We also compared the performance of three different irregular-to-regular shape padding methods. 142 patient data with neurodegenerative disorders were used in the evaluation. The preliminary results show that our proposed framework supports fast neuroimaging retrieval, and the orthographic projection method can reduce the computational complexity and has a great potential to improve the retrieval for indefinite cases.	computational complexity theory;content-based image retrieval;curvelet;orthographic projection	Sidong Liu;Lei Jing;Tom Weidong Cai;Lingfeng Wen;Stefan Eberl;Michael J. Fulham;David Dagan Feng	2010	2010 IEEE 23rd International Symposium on Computer-Based Medical Systems (CBMS)	10.1109/CBMS.2010.6042649	computer vision;feature extraction;image retrieval;data management;computer science;pattern recognition;database;computational complexity theory;data retrieval;information retrieval;neuroimaging	Vision	32.83064209770268	-71.78443653260358	23588
703edfa29e349e2267ef408527b30ba1609e2de6	bag: a binary descriptor for rgb-d images combining appearance and geometric cues		Feature matching forms the basis for numerous computer vision applications. With the rapid development of 3D sensors, the availability of RGB-D images has been increased stably. Compared to traditional 2D images, the additional depth images in RGB-D images can provide more geometric information. In this paper, we propose a new efficient binary descriptor (namely BAG) for RGB-D image representation by combining appearance and geometric cues. Experimental results show that the proposed BAG descriptor produces better feature matching performance with faster matching speed and less memory than the existing methods.	computer vision;fastest;sensor;speeded up robust features	Xiuzi Xiao;Songhua He;Yulan Guo;Min Lu;Jun Zhang	2016		10.1007/978-981-10-5230-9_7	local binary patterns;computer vision;binary number;rgb color model;artificial intelligence;computer science	Vision	33.73757857811061	-52.54708925787636	23622
2544ad4062c3667429d37c711beefefb43c1045b	color-based watershed segmentation of low-altitude aerial images	mathematical morphology;image segmentation;computational geometry;aerial image;large scale;image colour analysis;image reconstruction;watershed segmentation;mathematical morphology image colour analysis image segmentation image reconstruction computational geometry;morphology color based watershed segmentation low altitude aerial images catchment basin merging algorithm area based segmentation 3d reconstruction geometry color similarity large scale urban scenes;image segmentation merging shape measurement convergence image reconstruction shape control image storage topology algorithm design and analysis large scale systems	In this paper we introduce the color-based catchment basin merging algorithm, an area-based segmentation approach that is specifically designed to segment low-altitude aerial images, as a preprocessing step to 3D reconstruction. This approach extends the watershed-based catchment basin merging algorithm, which is purely geometric, by introducing color similarity as an additional criterion to decide on the merging of evolving regions. Experiments performed with real aerial images of varied nature demonstrate that this modification eliminates over-segmentation problems of the existing algorithm, allowing large-scale urban scenes to be segmented in an accurate, reliable and fully automatic way.	3d reconstruction;aerial photography;algorithm;experiment;preprocessor;watershed (image processing)	Adriano B. Huguet;Marcos C. de Andrade;Rodrigo L. Carceroni;Arnaldo de Albuquerque Araújo	2004	Proceedings. 17th Brazilian Symposium on Computer Graphics and Image Processing	10.1109/SIBGRA.2004.1352954	image texture;computer vision;range segmentation;watershed;geography;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation;computer graphics (images)	Vision	47.783290764754064	-67.754523095818	23634
e9609ae83ae3d8637bdb3f5e5c22458b69feafb3	dynamic adaptation of cooperative agents for mri brain scans segmentation	tratamiento automatico;nuclear magnetic resonance imaging;aide diagnostic;outil logiciel;informatica biomedical;software tool;image numerique;biomedical data processing;imagineria rmn;metodologia;image processing;systeme nerveux central;topographie;genie biomedical;automatic segmentation;informatique biomedicale;procesamiento imagen;cooperative agents;hombre;segmentation;encefalo;topography;traitement image;methodologie;radiometry;sistema nervioso central;automatic processing;biomedical engineering;encephale;herramienta controlada por logicial;imagen numerica;human;computer aid;asistencia ordenador;ingenieria biomedica;imagerie rmn;radiometrie;digital image;radiometria;methodology;traitement automatique;dynamic adaptation;assistance ordinateur;segmentacion;central nervous system;topografia;diagnostic aid;homme;ayuda diagnostica;brain vertebrata	To cope with the difficulty of MRI brain scans automatic segmentation, we need to constrain and control the selection and the adjustment of processing tools depending on the local image characteristics. To extract domain and control knowledge from the image, we propose to use situated cooperative agents whose dedicated behavior, i.e. segmentation of one type of tissue, is dynamically adapted with respect to their position in the image. Qualitative maps are used as a common framework to represent knowledge. Constraints that drive the agents behavior, based on topographic relationships and radiometric information, are gradually gained and refined during the segmentation progress. Incremental refinement of the segmentation is obtained through the combination, distribution and opposition of solutions concurrently proposed by the agents, via respectively three types of cooperation: integrative, augmentative and confrontational. We report in detail our multi-agent approach and results obtained on MRI brain scans.	map;multi-agent system;refinement (computing);situated;topography	Nathalie Richard;Michel Dojat;Catherine Garbay	2001		10.1007/3-540-48229-6_48	computer vision;simulation;radiometry;image processing;computer science;artificial intelligence;central nervous system;topography;segmentation-based object categorization;methodology;scale-space segmentation;segmentation;digital image	AI	46.17270538360931	-79.00989542763458	23661
48d59cb6619693f1810e53ad951c8a79b418d03d	using geometric properties for automatic object positioning	relative position;vision ordenador;posicionamiento;image processing;procesamiento imagen;traitement image;computer vision;algorithme;algorithm;algebraic geometry;positioning;pattern recognition;invariante;geometria algebraica;vision ordinateur;reconnaissance forme;reconocimiento patron;invariant;geometrie algebrique;positionnement;algoritmo	This paper presents an application of some recent results in computer vision, in particular the use of geometric properties. The problem we examine here is the accurate positioning of an object with respect to another, say a tool. Such applications could be used in complex and hazardous environments like nuclear plants. Because high accuracy in positioning is our goal here, we suppose that the objects have planar faces on which targets can be put. Without loss of generality, we have used only two objects in our experiments. Throughout this paper, we have called them the reference object and the unknown object respectively. The positions of the targets of the reference object with their associated projective invariants are computed in an off-line stage. Hence, given at least two images of the two objects, we can automatically identify the reference object points in the images and reconstruct the points of the unknown object relative to the reference object. The experiments show that a precision of 0.1 mm in relative positioning can be reached for an object observed at a distance of 2 m.		Boubakeur Boufama;Roger Mohr;Luce Morin	1998	Image Vision Comput.	10.1016/S0262-8856(97)00047-4	computer vision;method;simulation;pose;object model;image processing;algebraic geometry;computer science;artificial intelligence;invariant;mathematics	Robotics	49.24239713192611	-57.86548049503814	23692
df62cc4549d6ca8c9564283ea7aac272e3e99b30	the location and recognition of chinese vehicle license plates under complex backgrounds	character segmentation;character recognition;artificial neural network;license plate location	This paper presents the algorithms to locate license plate and recognize the characters on it. These algorithms have three advantages. First, they have strong robustness to against many noises and disturbances. Second, the methods can deal with license plates with different colors. Third, the recognition methods based on artificial neural network are suitable for Chinese characters.		Guangmin Sun;Gang Li;Lei Xu;Jing Wang	2009	Journal of Multimedia	10.4304/jmm.4.6.442-449	computer vision;speech recognition;computer science;artificial intelligence;machine learning;artificial neural network	Vision	34.999097493278995	-64.26906236170788	23765
f16734df67272c0af55f1038ce58b9baf8aeec34	fpga-based real-time citrus classification system	computer vision;computer architecture;yttrium;image color analysis;real time citrus classification system hardware resource utilization spartan 6 fpga color images hardware architecture field programmable gate array embedded color based citrus selection system computer vision operators automatic grading machine computer vision algorithms manual inspection visual inspection fruit grading mexico citrus industry;image color analysis computer architecture hardware field programmable gate arrays yttrium computer vision equations;field programmable gate arrays;production engineering computing agricultural products computer vision field programmable gate arrays image classification image colour analysis inspection;hardware	Commonly, in the citrus industry in Mexico, fruit grading is performed by humans through visual inspection. Manual inspection implies several problems in maintaining grading consistency and sorting uniformity. Citrus classification is normally achieved based on external visible criteria, such as size, shape and color. This problem has been addressed using computer vision algorithms, but an automatic grading machine based on computer vision usually requires large computational resources in order to perform the classification due to the complexity of the computer vision operators. This paper describes an embedded color-based citrus selection system implemented on a field programmable gate array (FPGA) device. Experimental results show that the proposed hardware architecture is able to process 720p color images at 30 fps. The proposed architecture was validated on a Spartan-6 FPGA and the hardware resource utilization is reported.	algorithm;circuit complexity;computational resource;computer vision;embedded system;field-programmable gate array;image resolution;real-time clock;sorting;visual inspection	Marco Aurelio Nuño-Maganda;Yahir Hernandez-Mier;César Torres-Huitzil;Josue Jimenez-Arteaga	2014	2014 IEEE 5th Latin American Symposium on Circuits and Systems	10.1109/LASCAS.2014.6820292	embedded system;computer vision;simulation;computer science	Vision	40.44969906914802	-67.16660034009521	23792
1975f82af16251f7bab71c6c98ea4cc86fff593a	unsupervised segmentation of markov random fields corrupted by nonstationary noise	hidden markov models markov processes image segmentation bayes methods context adaptation models image restoration;unsupervised segmentation hidden markov fields hmfs nonstationary noise triplet markov fields tmfs;image segmentation;unsupervised learning gaussian processes hidden markov models image segmentation;bayes methods;image restoration;hidden markov models;unsupervised segmentation gaussian densities nonstationary noise markov random fields;markov processes;adaptation models;context	Hidden Markov fields have been widely used in image processing thanks to their ability to characterize spatial information. In such models, the process of interest X is hidden and is to be estimated from an observable process Y . One common way to achieve the associated inference tasks is to define, on one hand, the prior distribution p(x); and on the other hand, the noise distribution p(y/x). While it is commonly established that the prior distribution is given by a Markov random field, the noise distribution is usually given through a set of Gaussian densities; one per each label. Hence, observed pixels belonging to the same class are assumed to be generated by the same Gaussian density. Such assumption turns out, however, to be too restrictive in some situations. For instance, due to light conditions, pixels belonging to a same label may present quite different visual aspects. In this letter, we overcome this drawback by considering an auxiliary field U in accordance with the triplet Markov field formalism. Experimental results on simulated and real images demonstrate the interest of the proposed model with respect to the common hidden Markov fields.	emoticon;hidden markov model;image processing;markov chain;markov random field;observable;pixel;semantics (computer science);triplet state	Ahmed Habbouchi;Mohamed El Yazid Boudaren;Amar Aissani;Wojciech Pieczynski	2016	IEEE Signal Processing Letters	10.1109/LSP.2016.2609887	forward algorithm;image restoration;computer vision;markov chain;maximum-entropy markov model;markov kernel;partially observable markov decision process;markov property;viterbi algorithm;computer science;machine learning;hidden semi-markov model;pattern recognition;mathematics;markov algorithm;image segmentation;markov process;markov model;hidden markov model;variable-order markov model	Vision	50.880175845832596	-69.4476429309578	23796
38e0330cf87e0648fa76f1e87bdde57b3b66c56d	a content-based image retrieval scheme using an encrypted difference histogram in cloud computing		Content-based image retrieval (CBIR) has been widely used in many applications. Large storage and computation overheads have made the outsourcing of CBIR services attractive. However, the privacy issues brought by outsourcing have become a big problem. In this paper, a secure CBIR scheme based on an encrypted difference histogram (EDH-CBIR) is proposed. Firstly, the image owner calculates the order or disorder difference matrices of RGB components and encrypts them by value replacement and position scrambling. The encrypted images are then uploaded to the cloud server who extracts encrypted difference histograms as image feature vectors. To search similar images, the query image is encrypted by the image users as the image owner does, and the query feature vector is extracted by the cloud server. The Euclidean distance between query feature vector and image feature vector is calculated to measure the similarity. The security analysis and experiments demonstrate the usability of the proposed scheme.	cloud computing;computation;content-based image retrieval;encryption;euclidean distance;experiment;feature (computer vision);feature vector;privacy;server (computing);usability	Dandan Liu;Jian Shen;Zhihua Xia;Xingming Sun	2017	Information	10.3390/info8030096	data mining;computer science;information retrieval;image retrieval;content-based image retrieval;cloud computing;encryption;rgb color model;feature vector;histogram;feature detection (computer vision)	Vision	39.09800740037859	-59.210395386189035	23818
157d2c6dd8c9999b251099ef4211cff8030ae486	invariance properties of gabor filter-based features-overview and applications	reconnaissance visage;analisis contenido;traitement signal;object recognition;deteccion blanco;articulo sintesis;image processing;analisis textura;article synthese;biometrie;biometrics;biometria;procesamiento imagen;invarianza;reconnaissance objet;gabor filters;filtro gabor;traitement image;image texture;detection cible;invariance;detection objet;gabor filter;content analysis;texture analysis;automatic recognition;face recognition;iris ojo;feature extraction;signal processing;filtre gabor;face recognition gabor filter based features image processing feature extraction texture analysis;pattern recognition;gabor filters image processing feature extraction lighting object detection two dimensional displays signal processing context awareness image texture analysis iris;rotation scaling and translation;feature extraction gabor filters image texture face recognition;reconnaissance forme;iris oeil;extraction caracteristique;analyse contenu;algorithms artificial intelligence face humans image enhancement image interpretation computer assisted information storage and retrieval pattern recognition automated reproducibility of results sensitivity and specificity;reconocimiento patron;review;procesamiento senal;target detection;analyse texture;literature survey;object detection;reconocimiento automatico;reconnaissance automatique;object recognition feature extraction gabor filters image processing invariance object detection;iris eye	For almost three decades the use of features based on Gabor filters has been promoted for their useful properties in image processing. The most important properties are related to invariance to illumination, rotation, scale, and translation. These properties are based on the fact that they are all parameters of Gabor filters themselves. This is especially useful in feature extraction, where Gabor filters have succeeded in many applications, from texture analysis to iris and face recognition. This study provides an overview of Gabor filters in image processing, a short literature survey of the most significant results, and establishes invariance properties and restrictions to the use of Gabor filters in feature extraction. Results are demonstrated by application examples.	facial recognition system;feature extraction;gabor filter;image processing	Joni-Kristian Kämäräinen;Ville Kyrki;Heikki Kälviäinen	2006	IEEE Transactions on Image Processing	10.1109/TIP.2005.864174	image texture;computer vision;speech recognition;content analysis;image processing;feature extraction;computer science;invariant;cognitive neuroscience of visual object recognition;signal processing;pattern recognition;gabor wavelet;biometrics	Vision	44.89185193463291	-59.73528731882029	23857
b373122c54c32e4777eacad637b67f8e2a5e7ef0	multiplex image representation for enhanced recognition		A multiscale approach to exploiting existing image descriptors (LBP and HOG) is proposed recently in order to enhance face recognition performance (Ubiquitous computing and ambient intelligence. Personalisation and user adapted services. Springer, 532–539, 2014) and (A multiscale method for HOG-based face and palmprint recognition. Technical report, Ulster University, 2015), where multiple single-sourced, spatially-varied feature vectors at different scales are calculated from images and then fused through an image distance function. This multiscale approach has led to significant improvements in face recognition over the single scale approach. In this paper we present an analysis of this multiscale approach from feature engineering perspective and evaluation result for the image distance function on palmprint recognition, thus providing an insight into and also extending the applicability of this approach. We also present a new method of utilising these spatially-varied feature vectors from an image—joining these feature vectors head to tail to form a larger feature vector which is used as a multiplex representation of the image. Such an image representation can then be used by any vector-based feature extraction and classification algorithms. This representation scheme is evaluated experimentally in face recognition, and the results show this scheme is competitive to the distance-based method having the additional advantage of being usable in a wider range of machine learning algorithms. The main contributions of this paper are (1) an insight into this multiscale approach to utilising existing image descriptors such as LBP and HOG; (2) a new method of using these multiple feature vectors; and (3) extension of the multiscale approach to palmprint recognition.	multiplexing	Xin Wei;Hui Wang;Gongde Guo;Huan Wan	2018	Int. J. Machine Learning & Cybernetics	10.1007/s13042-015-0427-5	feature (computer vision);feature (machine learning);feature extraction;feature detection (computer vision);feature vector;feature engineering;computer vision;statistical classification;computer science;technical report;pattern recognition;artificial intelligence	AI	30.85410264333993	-55.02568177241986	23872
ec7c66d34d72f18b5eee13d1d9290b1c25f6fca4	binary distance transform to improve feature extraction		To recognize textures many methods have been developed along the years. However, texture datasets may be hard to be classified due to artefacts such as a variety of scale, illumination and noise. This paper proposes the application of binary distance transform on the original dataset to add information to texture representation and consequently improve recognition. Texture images, usually in grayscale, suffers a binarization prior to distance transform and one of the resulted images are combined with original texture to improve the amount of information. Four datasets are used to evaluate our approach. For Outex dataset, for instance, the proposal outperforms all rates, improvements of an up to 10%, compared to traditional approach where descriptors are applied on the original dataset, showing the importance of this approach.	binary image;computer vision;data pre-processing;distance transform;euclidean distance;feature extraction;grayscale;local binary patterns;naive bayes classifier;preprocessor	Mariane Barros Neiva;Antoine Manzanera;Odemir Martinez Bruno	2016	CoRR		computer vision;pattern recognition;data mining	Vision	36.09700316911827	-60.15438509626989	23884
b2be025c2a0789b3afca7780d2dc8b791e91d82c	robust contour tracking by combining region and boundary information	video surveillance feature extraction motion estimation object detection object tracking probability;evaluation performance;texture;kernel;video surveillance;deteccion blanco;probability;performance evaluation;estimacion densidad;tracking feature extraction level set bayesian methods image color analysis robustness;complexite calcul;motion information robust contour tracking object tracking model region feature extraction boundary based object detector complex scenes monochrome surveillance systems probability models energy function;methode noyau;surveillance system;kernel density estimation;color;bayes methods;methode bayes;estimation densite;evaluacion prestacion;weighting;contour evolution;level set;motion estimation;ponderacion;energy function;detection cible;captador medida;detection objet;density estimation;equation evolution;complejidad computacion;measurement sensor;radio frequency;capteur mesure;monitoring;evolution equation;computational complexity;image color analysis;feature extraction;pixel;metodo nucleo;object tracking;energy functional;poursuite cible;kernel density estimate;textura;level set bayesian model contour evolution energy functional feature fusion kernel density estimation;kernel method;robustness;ecuacion evolucion;feature fusion;ponderation;monitorage;0707d;target tracking;probability model;monitoreo;target detection;object detection;bayesian model	This paper presents a new object tracking model that systematically combines region and boundary features. Besides traditional region features (intensity/color and texture), we design a new boundary-based object detector for accurate and robust tracking in low-contrast and complex scenes, which usually appear in the commonly used monochrome surveillance systems. In our model, region feature-based energy terms are characterized by probability models, and boundary feature terms include edge and frame difference. With a new weighting term, a novel energy functional is proposed to systematically combine the region and boundary-based components, and it is minimized by a level set evolution equation. For an efficient computational cost, motion information is utilized for new frame level set initialization. Compared with region feature-based models, the experimental results show that the proposed model significantly improves the performance under different circumstances, especially for objects in low-contrast and complex environments.	algorithmic efficiency;contour line;feature model;monochrome;pixel;weight function	Ling Cai;Lei He;Takayoshi Yamashita;Yiren Xu;Yuming Zhao;Xin Yang	2011	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2011.2133550	kernel density estimation;computer vision;speech recognition;computer science;pattern recognition;mathematics;statistics	Vision	46.781284153135864	-58.38506966755979	23962
8a47ab7b7a29c4a7f1ac5b0e44881ecdd4b64f8e	analysis of the magnetoacoustic tomography with magnetic induction	stability;iterative reconstruction;35r30;linear convergence;92c55;conductivity imaging;65n21;hybrid imaging	Magnetoacoustic tomography with magnetic induction (MAT-MI) is a coupled-physics medical imaging modality for determining conductivity distribution in biological tissue. The capability of MATMI to provide high-resolution images has been demonstrated experimentally. MAT-MI involves two steps. The first step is a well-posed inverse source problem for acoustic wave equations, which has been well studied in the literature. This paper concerns mathematical analysis of the second step, a quantitative reconstruction of the conductivity from knowledge of the internal data recovered in the first step, using techniques such as time reversal. The problem is modeled by a system derived from Maxwell’s equations. We show that a single internal data determines the conductivity. A global Lipschitz-type stability estimate is obtained. A numerical approach for recovering the conductivity is proposed, and results from computational experiments are presented.	acoustic cryptanalysis;ct scan;computation;experiment;image resolution;maxwell (microarchitecture);medical imaging;modality (human–computer interaction);numerical analysis;t-symmetry;tomography;well-posed problem	Lingyun Qiu;Fadil Santosa	2015	SIAM J. Imaging Sciences	10.1137/15M1012323	iterative reconstruction;mathematical optimization;radiology;stability;mathematics;rate of convergence;statistics	Vision	51.71833659863579	-79.88991189903233	24016
8b9f8333cf3546c86535b131eb2464cdaee75824	pose-corrected face processing on video sequences for webcam-based remote biometric authentication	databases;face processing;biometric authentication;biometrics;video	In this paper we describe a framework aimed to perform face-based biometric user authentication for web-resources through client-server secured sessions. A novel front-end for face video sequences processing is developed in which face detection and shot selection is performed at client-side while statistical multi-shot pose-corrected face verification is performed at server-side. We explain all the image processing steps, from the acquisition to the decision, paying special attention to a PDM-based pose correction subsystem and a GMM-based sequence decision test. The pose correction relies on projecting a face-shape mesh onto the set of PDM eigenvectors and back-projecting it after changing the coefficients associated to pose variation. The aligned and discriminatively selected texture features form the observation vectors ready to be pluged into a GMM based likelihood ratio for statistical decision. Tests over known databases show the reliability of The authors are with the Departamento de Teoŕıa de la Señal y Comunicaciones, ETSI Telecomunicación, Universidad de Vigo, 36310 Vigo, Spain. Phone: +34 986 812664. Fax: +34 986 812116. E-mails: {jalba,danisub,eargones,eli,eotero,carmen}@gts.tsc.uvigo.es. Corresponding author. E-mail: jalba@gts.tsc.uvigo.es This work was supported with funds provided partially by the Spanish ministry of education under project TEC2005-07212/TCM and the European sixth framework programme under the Network of Excellence BIOSECURE (IST-2002-507604)	authentication;biometrics;client-side;client–server model;coefficient;database;discriminative model;face detection;fax;google map maker;image processing;linear algebra;server (computing);server-side;speaker recognition;statistical model;webcam	José Luis Alba-Castro;Daniel González-Jiménez;Enrique Argones-Rúa;Elisardo González-Agulla;Enrique Otero Muras;Carmen García-Mateo	2008	J. Electronic Imaging	10.1117/1.2891038	computer vision;simulation;speech recognition;computer science;biometrics	Vision	28.497447096637707	-64.17917664733231	24043
5a103354ca720903f22c11e0a091803b6eab2162	spider specie identification and verification based on pattern recognition of it cobweb	expert systems;cobwebs;pattern recognition;biometrics on animals;artificial intelligence;spider specie recognition;identification verification approaches	0957-4174/$ see front matter 2013 Elsevier Ltd. A http://dx.doi.org/10.1016/j.eswa.2013.01.024 ⇑ Corresponding author. Tel.: +34 928452864; fax: E-mail addresses: jrticay@idetic.eu (J.R. Ticay-Riva Pozo-Baños), william.eberhard@gmail.com, william.eb hard), jalonso@dsc.ulpgc.es (J.B. Alonso), ctravieso@ds Biodiversity conservation is a global priority where the study of every type of living form is a fundamental task. Inside the huge number of the planet species, spiders play an important role in almost every habitat. This paper presents a comprehensive study on the reliability of the most used features extractors to face the problem of spider specie recognition by using their cobwebs, both in identification and verification modes. We have applied a preprocessing to the cobwebs images in order to obtain only the valid information and compute the optimal size to reach the highest performance. We have used the principal component analysis (PCA), independent component analysis (ICA), Discrete Cosine Transform (DCT), Wavelet Transform (DWT) and discriminative common vectors as features extractors, and proposed the fusion of several of them to improve the system’s performance. Finally, we have used the Least Square Vector Support Machine with radial basis function as a classifier. We have implemented K-Fold and Hold-Out crossvalidation techniques in order to obtain reliable results. PCA provided the best performance, reaching a 99.65% ± 0.21 of success rate in identification mode and 99.98% ± 0.04 of the area under de Reveicer Operating Characteristic (ROC) curve in verification mode. The best combination of features extractors was PCA, DCT, DWT and ICA, which achieved a 99.96% ± 0.16 of success rate in identification mode and perfect verification. 2013 Elsevier Ltd. All rights reserved.	discrete cosine transform;discrete wavelet transform;fax;habitat;independent computing architecture;independent component analysis;mail (macos);pattern recognition;preprocessor;principal component analysis;radial (radio);radial basis function;receiver operating characteristic	Jaime Roberto Ticay-Rivas;Marcos del Pozo-Baños;William G. Eberhard;Jesús B. Alonso;Carlos Manuel Travieso-González	2013	Expert Syst. Appl.	10.1016/j.eswa.2013.01.024	speech recognition;computer science;artificial intelligence;machine learning;pattern recognition;expert system	AI	31.719834544006453	-61.36980067817595	24061
cfeb26245b57dd10de8f187506d4ed5ce1e2b7dd	capsnet comparative performance evaluation for image classification.		Image classification has become one of the main tasks in the field of computer vision technologies. In this context, a recent algorithm called CapsNet that implements an approach based on activity vectors and dynamic routing between capsules may overcome some of the limitations of the current state of the art artificial neural networks (ANN) classifiers, such as convolutional neural networks (CNN). In this paper, we evaluated the performance of the CapsNet algorithm in comparison with three well-known classifiers (Fisherfaces, LeNet, and ResNet). We tested the classification accuracy on four datasets with a different number of instances and classes, including images of faces, traffic signs, and everyday objects. The evaluation results show that even for simple architectures, training the CapsNet algorithm requires significant computational resources and its classification performance falls below the average accuracy values of the other three classifiers. However, we argue that CapsNet seems to be a promising new technique for image classification, and further experiments using more robust computation resources and refined CapsNet architectures may produce better outcomes.	algorithm;artificial neural network;computation;computational resource;computer vision;convolutional neural network;experiment;face (geometry);performance evaluation;routing	Rinat Mukhometzianov;Juan Carrillo	2018	CoRR		machine learning;convolutional neural network;artificial neural network;artificial intelligence;pattern recognition;computation;contextual image classification;computer science;residual neural network;adaptive routing	Vision	26.854520878227934	-57.09305806001398	24086
2d8ad2e93fc8032f0996e9b6543dc7f2fb305aaf	texture-based classification of atherosclerotic carotid plaques	carotid endarterectomy;shape parameters texture based classification atherosclerotic carotid plaques stroke risk manually segmented plaque images spatial gray level dependence matrices medical diagnostic imaging gray level difference statistics neighborhood gray tone difference matrix statistical feature matrix laws texture energy measures fractal dimension texture analysis fourier power spectrum;fractals;high resolution;ultrasonic imaging feature extraction statistical analysis shape measurement morphology high resolution imaging image segmentation energy measurement power measurement fractals;confidence measure;indexing terms;texture features;power spectrum;image texture;fractal dimension;ultrasound imaging;texture analysis;first order;feature extraction;medical image processing;modular system;diseases;shape parameter;medical image processing image texture diseases fractals feature extraction biomedical ultrasonics;k nearest neighbor;self organized map;carotid stenosis;modular neural network;biomedical ultrasonics;algorithms cluster analysis coronary artery disease humans image enhancement image interpretation computer assisted nerve net pattern recognition automated reproducibility of results sensitivity and specificity signal processing computer assisted ultrasonography	There are indications that the morphology of atherosclerotic carotid plaques, obtained by high-resolution ultrasound imaging, has prognostic implications. The objective of this study was to develop a computer-aided system that will facilitate the characterization of carotid plaques for the identification of individuals with asymptomatic carotid stenosis at risk of stroke. A total of 230 plaque images were collected which were classified into two types: symptomatic because of ipsilateral hemispheric symptoms, or asymptomatic because they were not connected with ipsilateral hemispheric events. Ten different texture feature sets were extracted from the manually segmented plaque images using the following algorithms: first-order statistics, spatial gray level dependence matrices, gray level difference statistics, neighborhood gray tone difference matrix, statistical feature matrix, Laws texture energy measures, fractal dimension texture analysis, Fourier power spectrum and shape parameters. For the classification task a modular neural network composed of self-organizing map (SOM) classifiers, and combining techniques based on a confidence measure were used. Combining the classification results of the ten SOM classifiers inputted with the ten feature sets improved the classification rate of the individual classifiers, reaching an average diagnostic yield (DY) of 73.1%. The same modular system was implemented using the statistical k-nearest neighbor (KNN) classifier. The combined DY for the KNN system was 68.8%. The results of this paper show that it is possible to identify a group of patients at risk of stroke based on texture features extracted from ultrasound images of carotid plaques. This group of patients may benefit from a carotid endarterectomy whereas other patients may be spared from an unnecessary operation.	artificial neural network;atherosclerosis;biological neural networks;carotid endarterectomy;carotid stenosis;cerebrovascular accident;classification;dental plaque;diagnostic techniques, ophthalmological;extraction;first-order predicate;fractal dimension;grayscale;image resolution;image texture;k-nearest neighbors algorithm;mathematical morphology;medical ultrasound;modular neural network;organizing (structure);patients;pioneer plaque;self-organization;self-organizing map;senile plaques;single linkage cluster analysis;spectral density;ultrasonography	Christina I. Christodoulou;Constantinos S. Pattichis;Marios Pantziaris;Andrew Nicolaides	2003	IEEE Transactions on Medical Imaging	10.1109/TMI.2003.815066	image texture;computer vision;speech recognition;index term;image resolution;fractal;feature extraction;computer science;artificial intelligence;first-order logic;mathematics;fractal dimension;shape parameter;spectral density;k-nearest neighbors algorithm;statistics	ML	36.28910869758118	-77.61589377034564	24093
8c8031d26553b7394f64686dadf8df289d173b31	three-dimensional motion analysis of scene containing multiple moving objects from image sequence and depth	motion analysis;analisis imagen;moving object;analisis escena;analyse scene;movimiento;gradient method;depth;segmentation;motion;three dimensional;methode gradient;metodo gradiente;mouvement;image sequence;profundidad;image analysis;secuencia imagen;profondeur;analyse image;segmentacion;sequence image;scene analysis	Optical flow analysis is a powerful means to extract an object from the dynamic image. but it can also recover the three-dimensional structure. However, in practice, there are many cases where the optical flow is difficult to obtain or the motion of the object does not permit a unique interpretation. Based on the gradient method,this paper proposes a method of three-dimensional motion analysis for multiple moving objects which may include an object for which a. unique interpretation of the motion is difficult. By the gradient method, the threedimensional motion parameters of a rigid object can be estimated without using the optical flow as a least-square-error solution for the system of linear equations, if the three-dimensional structure of the object is already given. sum error in the estimation, the image plane is segmented if it contains regions of different motions. If the motions are recognized as being similar, the regions are merged. Thus, the object is extracted by iterating the segmentation and merge on the image plane. The uniqueness of the motion is evaluated by the condition number for the coefficient matrix of the system equations. If the motion of the extracted object can be interpreted uniquely, the displacement vector can be determined accurately by iterating the estimation of the object motion. Not only can it extract an object,	coefficient;condition number;data-flow analysis;displacement mapping;gradient method;image plane;interpretation (logic);linear equation;optical flow;system of linear equations	Masanobu Yamamoto	1987	Systems and Computers in Japan	10.1002/scj.4690180505	three-dimensional space;computer vision;structure from motion;image analysis;computer science;gradient method;motion;motion estimation;mathematics;geometry;3d single-object recognition;motion field;segmentation;linear motion;computer graphics (images)	Robotics	50.71305384658349	-56.84580738666588	24117
7103186bfb64f3b40d662f46eb2348b7d829a139	a colour object search algorithm	search algorithm;area of interest;computer science and informatics	In this paper a colour object search algorithm is presented. Given an image, areas of interest are generated (for each database model) by isolating regions whose colours are similar to model colours. Since the model may exist at one or more of these region locations, each is examined individually. At each region location the object size is estimated and a growing process initiated to include all pixels with model colours. Growing is terminated when a match measure (based on object size and the number of pixels with each model colour) is maximised; if it ex ceeds a predefined threshold then the object is assumed to be present. Several experiments are presented which demonstrate the algorithm’s robustness to scale, affine object distortion, varying illumination, image clutter and occlusion.	clutter;color;database model;distortion;experiment;pixel;search algorithm	Paul A. Walcott;Tim J. Ellis	1998		10.5244/C.12.30	computer vision;computer science;colour look-up table;machine learning;mathematics;search algorithm;computer graphics (images)	Vision	43.52913232752587	-55.16316520575887	24132
9327c8fc5cae081f4ef34d5a0115197f03dc526a	biometric recognition of surgically altered periocular region: a comprehensive study	databases;surgery eyelids feature extraction face databases shape face recognition;iris recognition biometrics access control face recognition;degraded identification performance biometric recognition surgically altered periocular region periocular recognition schemes performance identification fusion algorithms;face recognition;shape;feature extraction;surgery;face;eyelids	Wide acceptance of biometrics as an authentication mode has led to investigation of multiple modalities such as face, periocular, iris for the long term robustness. Due to various deformities arising out of deteriorating health, need for enhancing the beauty by choice or to fix the injury as a result of trauma or aging, people tend to undergo surgery. However, such surgeries do not guarantee the restoration of physical biometric characteristics (face, periocular, iris etc.) to original appearance and thereby impacting the performance in biometric identifications. Among many physical biometric characteristics, periocular recognition is widely accepted for authentication purposes. This work studies the impact of periocular surgeries on biometric performance. To this extent, we introduce a new large scale periocular surgery database comprising of 402 unique periocular images acquired before and after the surgery. This is the first work that provides comprehensive study on evaluating the impact of surgeries in periocular region on periocular recognition. Extensive experiments are carried out on a newly created dataset using 11 different state-of-art periocular recognition schemes. Further, we also explore score level fusion of these algorithms. Results obtained on the newly created large scale database indicate the degraded identification performance of both the state-of-art and fusion algorithms.	algorithm;authentication;biometrics;circuit restoration;experiment	Kiran B. Raja;Ramachandra Raghavendra;Christoph Busch	2016	2016 International Conference on Biometrics (ICB)	10.1109/ICB.2016.7550070	facial recognition system;face;computer vision;speech recognition;feature extraction;shape;computer science;three-dimensional face recognition;geometry	Vision	30.063042865430745	-61.589194664775256	24147
e139de8dfb9a1ae5a879331c204e858d95cc28a5	robust recognition of chess-boards under deformation	robust recognition vertex feature detection camera calibration 3d objects chess board pattern 2d square mesh structure warped grid grid structure chess board vertices deformation;camera calibration grid finding rotational constraints structured light surface reconstruction;deformation;feature extraction;mesh generation;calibration;cameras;object detection;object detection calibration cameras deformation feature extraction mesh generation	Current methods for formation of detected chess-board vertices into a grid structure tend to be weak in situations with a warped grid, and false and missing vertex-features. In this paper we present a highly robust, yet efficient, scheme suitable for inference of regular 2D square mesh structure from vertices recorded both during projection of a chess-board pattern onto 3D objects, and in the more simple case of camera calibration. Examples of the method's performance in a lung function measuring application, observing chess-boards projected on to patients' chests, are given. The method presented is resilient to significant surface deformation, and tolerates inexact vertex-feature detection. This robustness results from the scheme's novel exploitation of feature orientation information.	camera resectioning;feature detection (computer vision);feature detection (web development);vertex (geometry)	Stuart Bennett;Joan Lasenby	2013	2013 IEEE International Conference on Image Processing	10.1109/ICIP.2013.6738546	mesh generation;computer vision;calibration;feature extraction;computer science;machine learning;pattern recognition;mathematics;deformation	Robotics	48.9051958394149	-52.694614334685355	24178
c7ba171d07855ea52678c3ebac031b42742a8c54	a hybrid method for text line extraction in handwritten document images		Text line segmentation in handwritten document image, as one of the preliminarily steps for document image recognition, is a challenging problem. In this paper, a hybrid method for text line extraction in handwritten document images is presented. Initially, a connected component (CC) labelling method following by a CC filtering is employed to extract a set of CCs from the input document image. A new distance measure is introduced to compute normal distances between the extracted CCs. By traversing the normal distance matrix from both the right and left directions, half-chains of CCs are constructed. The CCs half-chains are merged to obtain CCs full-chains. From the extracted full-chains separator lines are obtained. A gradient metric is proposed to detect and remove touching text lines. Using remaining separator lines the adaptive projection profile of the image is computed. Based on the projection profile, coarse text line extraction is performed. Finally, a fine text lines extraction is performed by applying a postprocessing step. To evaluate the method, two benchmarks named ICDAR2013 handwriting segmentation contest, and Kannada datasets composed of handwritten document images in English, Greek, Bengali, and Kannada languages were considered for experimentation. Experimental results indicate a promising performance was obtained compared to some of the state-of-the-art methods.		Ehsan Kiumarsi;Alireza Alaei	2018	2018 16th International Conference on Frontiers in Handwriting Recognition (ICFHR)	10.1109/ICFHR-2018.2018.00050	kannada;artificial intelligence;pattern recognition;computer science;filter (signal processing);handwriting;distance matrix;connected component	Vision	36.24494280859321	-65.98851288745597	24179
21a1c8a5da79cfd8411907f64e5612f7fb31d81e	a fuzzy based model to identify printed sinhala characters	intersection measurement fuzzy based model printed sinhala characters identification character recognition techniques english language asian language sinhala character recognition feature extraction fuzzy inference system distance measurement;testing;character recognition feature extraction accuracy fuzzy logic optical character recognition software testing shape;fuzzy logic;optical character recognition software;accuracy;shape;feature extraction;optical character recognition feature extraction fuzzy reasoning;feature extraction ocr optical character recognition fis fuzzy inference system image processing;character recognition	Character recognition techniques for printed documents are widely used for English language. However, the systems that are implemented to recognize Asian languages struggle to increase the accuracy of recognition. Among other Asian languages (such as Arabic, Tamil, Chinese), Sinhala characters are unique, mainly because they are round in shape. This unique feature makes it a challenge to extend the prevailing techniques to improve recognition of Sinhala characters. Therefore, a little attention has been given to improve the accuracy of Sinhala character recognition. A novel method, which makes use of this unique feature, could be advantageous over other methods. This paper describes the use of a fuzzy inference system to recognize Sinhala characters. Feature extraction is mainly focused on distance and intersection measurements in different directions from the center of the letter making use of the round shape of characters. The results showed an overall accuracy of 90.7% for 140 instances of letters tested, much better than similar systems.	effective method;feature extraction;fuzzy logic;inference engine;optical character recognition;printing	G. I. Gunarathna;M. A. P. Chamikara;Roshan G. Ragel	2014	7th International Conference on Information and Automation for Sustainability	10.1109/ICIAFS.2014.7069553	computer vision;speech recognition;feature;feature extraction;intelligent character recognition;computer science;intelligent word recognition;pattern recognition	AI	33.3362458126641	-66.41236077652246	24190
56fc94e1406eb78b819cbbcc19b992024f9b35e1	closed contour shape descriptors with high compression properties based on the discrete hartley transform	info eu repo semantics bookpart		contour line;discrete hartley transform;hartley (unit)	Pere Martí-Puig;Ramón Reig Bolaño;Jaume Danés	2013		10.3233/978-1-61499-320-9-115	computer vision;discrete mathematics;theoretical computer science;mathematics	Vision	50.57575461111069	-62.955614416131205	24235
1b0183f57ad347a647f0f0c826c61c2a53ab61d8	negative selection with high-dimensional support for keystroke dynamics	human computer interaction;negative selection;neural nets;security of data human computer interaction neural nets;detectors training heuristic algorithms algorithm design and analysis databases accuracy feature extraction;keystroke dynamics;artificial immune systems;security of data;auto associative neural networks immune negative selection algorithms high dimensional support keystroke dynamics identity theft digital identity user behavior analysis behavioral intrusion detection user recognition typing rhythm high dimensional spaces;negative selection keystroke dynamics artificial immune systems	Computing and communication systems have been expanding and bringing a number of advancements to our way of life. However, this technological evolution has also contributed to the rise of the identity theft, mainly due to the advent of the digital identity. An alternative to overcome this problem is by the analysis of the user behavior, known as behavioral intrusion detection. Among the possible aspects to be analysed, this work focuses on the keystroke dynamics, which consists of recognizing users by their typing rhythm. This paper draws a comparison between some novelty detectors applied to keystroke dynamics: immune negative selection algorithms and auto-associative neural networks. Issues regarding the use of negative selection in high dimensional spaces are discussed and an alternative to deal with this problem is presented.	algorithm;artificial neural network;digital identity;event (computing);intrusion detection system;keystroke dynamics;novelty detection;sensor	Paulo Henrique Pisani;Ana Carolina Lorena	2012	2012 Brazilian Symposium on Neural Networks	10.1109/SBRN.2012.15	keystroke dynamics;computer science;artificial intelligence;machine learning;computer security;negative selection;artificial neural network	Security	25.95179241358088	-65.27034832267726	24258
eb31e6232541e15f455942bedaabad11e2d946df	image-based diagnostic aid for interstitial lung disease with secondary data integration	databases;software;clinical data;interstitial lung disease;high resolution;multimedia;data integrity;computed tomography;tissues;lung;high resolution computed tomography;decision support system;texture analysis;pilot project;medical diagnostics;pulmonary disorders;feature extraction;region of interest;database construction;decision support systems;visual features;computing systems;diagnostics;quantitative image analysis;similar case retrieval;content based image retrieval;chest high resolution ct;multimedia database;data acquisition;chest;diseases and disorders;data integration;knowledge base	ABSTRACT Interstitial lung diseases (ILDs) are a relatively heterogeneous group of around 150 illnesses with often veryunspecic symptoms. The most complete imaging method for the characterisation of ILDs is the high-resolutioncomputed tomography (HRCT) of the chest but a correct interpretation of these images is dicu lt even forspecialists as many diseases are rare and thus little exp erience exists. Moreover, i nterpreting HRCT imagesrequires knowledge of the context dened by clinical data of the studied case. A comput erised diagnostic aid toolbased on HRCT images with associated medical data to retrieve similar cas es of ILDs from a dedicated databasecan bring quick and precious information for example for emergency radiologists. The experience from a pilotproject highlighted the need for detailed database containing high-quality annotations in addition to clinicaldata.The state of the art is studied to identify requirements for image based diagnostic aid for interstitial lungdisease with secondary data integration. The data acquisition steps are detailed. The selection of the mostrelevant clinical parameters is done in collaboration with lung specialists from current literature, along withknowledge bases of computer based diagnostic decision support systems. In order to perform high qualityannotations of the interstitial lung tissue in the HRCT images an annotation software and its own le formatis implemented for DICOM images. A multimedia database is implemented to store ILD cases with clinicaldata and annotated image series. Cases from the University & University Hospitals of Geneva (HUG) areretrospectively and prospectively co llected to populate the database. Currently, 59 cases with certied diagnosisand their clinical parameters are stored in the database as well as 254 image series of which 26 have their regionsof interest annotated.The available data was used to test primary visual features for the classication of lung tissue patterns. Thesefeatures show good discriminative properties for the separation of ve classes of visual observations.Keywords: Quantitative image analysis, database construction, content based image retrieval, feature extrac-tion, texture analysis, chest high resolution CT, similar case retrieval.		Adrien Depeursinge;Henning Müller;Asmâa Hidki;Pierre-Alexandre Poletti;Alexandra Platon;Antoine Geissbühler	2007		10.1117/12.709533	medicine;pathology;data mining;biological engineering	AI	33.73053389714261	-79.34109526772164	24284
a5b006b3f9b67df2c2efdf7b67f2f2ecee1680b8	using 3d contours and their relations for cognitive vision and robotics	visual hierarchy;histograms;grasping;cognitive systems;learning;3d visualization;edge detection;color;object coding cognitive vision robotics 3d visual contours object level operations similarity assessment grasping visual descriptor visual hierarchy;object coding;robotics;data mining;similarity assessment;visualization;robot vision;robot vision cognitive systems edge detection;visual descriptor;3d visual contours;3d contours;cognitive vision;three dimensional displays;human visual system;robots;cognitive robotics robot vision systems histograms humans shape object recognition computer vision visual system layout robustness;object level operations	In this work, we make use of 3D visual contours carrying geometric as well as appearance information. Between these contours, we define 3D relations that encode structural information relevant to object-level operations such as similarity assessment and grasping. We show that this relational space can also be used as input features for learning which we exemplify for the grasping of unknown objects. Our representation is motivated by the human visual system in two respects. First, we make use of a visual descriptor that is motivated by hyper-columns in V1. Secondly, the contours can be seen as one stage in a visual hierarchy bridging between local symbolic descriptors to higher level stages of processing such as object coding and grasping.	bridging (networking);column (database);encode;exemplification;human visual system model;hyper-heuristic;modal logic;robotics;visual descriptor;visual hierarchy	Emre Baseski;Leon Bodenhagen;Nicolas Pugeault;Sinan Kalkan;Justus H. Piater;Norbert Krüger	2009	2009 24th International Symposium on Computer and Information Sciences	10.1109/ISCIS.2009.5291815	computer vision;visualization;computer science;machine learning;robotics	Robotics	36.72246700589327	-53.48257612919271	24287
5028602055f02249456bb401af813155279ffd00	3-d maximum a posteriori estimation for single photon emission computed tomography on massively-parallel computers	radioisotope scanning and imaging;image tridimensionnelle;radioisotope scanning and imaging computerised tomography;maximization test;resolution;high resolution;emission computed tomography;radiology and nuclear medicine;photon;implementation;tomocentelleografia;mathematical logic;statistical model;three dimensional;parallel computation;positron emission tomography;foton;algorithme;algorithm;ejecucion;maximum a posteriori estimation single photon emission computed tomography image reconstruction iterative algorithms detectors maximum likelihood estimation optical collimators attenuation optical computing maximum likelihood detection;reconstruction image;calculo paralelo;reconstruction 2 dimensions;diagnostic techniques;reconstruccion imagen;exploration radioisotopique;massively parallel computer;computational complexity;image reconstruction;high resolution mode 3d maximum a posteriori estimation 2d slice reconstructions nuclear medicine medical diagnostic imaging single photon emission computed tomography massively parallel computers spect iterative em algorithm maspar decmpp sx machine planar measurements siemens orbiter rotating camera;three dimensional calculations;test maximalisation;computerized tomography;single photon emission computed tomography;computerised tomography;modele statistique;tecnica;radionuclide study;expectation;tridimensional image;algorithms;modelo estadistico;logic programs;exploracion radioisotopica;em algorithm;calcul parallele;programming;massively parallel processor;technique;parallel processing;tomoscintigraphie;expectacion;imagen tridimensional;tomography 550601 medicine unsealed radionuclides in diagnostics;algoritmo	A fully three-dimensional (3-D) implementation of the maximum a posteriori (MAP) method for single photon emission computed tomography (SPECT) is demonstrated. The 3-D reconstruction exhibits a major increase in resolution when compared to the generation of the series of separate 2-D slice reconstructions. As has been noted, the iterative EM algorithm for 2-D reconstruction is highly computational; the 3-D algorithm is far worse. To accommodate the computational complexity, previous work in the 2-D arena is extended, and an implementation on the class of massively parallel processors of the 3-D algorithm is demonstrated. Using a 16000- (4000-) processor MasPar/DECmpp-Sx machine, the algorithm is demonstrated to execute at 2.5 (7.8) s/EM-iteration for the entire 64x64x64 cube of 96 planar measurements obtained from the Siemens Orbiter rotating camera operating in the high-resolution mode.		Michael I. Miller;Christopher S. Butler	1993	IEEE transactions on medical imaging	10.1109/42.241884	iterative reconstruction;statistical model;three-dimensional space;parallel processing;programming;mathematical logic;resolution;image resolution;expectation–maximization algorithm;computer science;photon;mathematics;nuclear medicine;computational complexity theory;implementation;algorithm;expected value;statistics;medical physics;computer graphics (images)	Vision	52.75304523440706	-79.05153911400375	24288
4d2f2e17be1b232ba4e0a2a6aae7154030f07932	wavelet-driven knowledge-based mri calf muscle segmentation	landmark shape model;topology;image segmentation;myopathy segmentation diffusion wavelet muscle;biodiffusion;search paradigm;learning stage wavelet driven knowledge based mri muscle segmentation search paradigm geometric constraint landmark shape model diffusion map canonical correlation analysis;feature modeling;training;segmentation;correlation methods;wavelet transforms;magnetic resonance imaging muscles topology training data active shape model biomedical imaging medical diagnostic imaging anatomical structure diseases biopsy;computational modeling;shape;geometric constraint;local features;learning stage;canonical correlation analysis;medical image processing;magnetic resonance imaging;diffusion wavelet;shape modeling;learning artificial intelligence;wavelet transforms biodiffusion biomedical mri correlation methods image segmentation knowledge based systems learning artificial intelligence medical image processing muscle;myopathy;geometric constraints;wavelet driven knowledge based mri;knowledge based systems;muscle;data models;biomedical mri;muscle segmentation;muscles;knowledge base;diffusion map	We propose a novel representation of shape variation using diffusion wavelets, and a search paradigm based on local features. The representation can reflect arbitrary and continuous interdependencies in the training data. In contrast to state-of-the-art methods our approach during the learning stage optimizes the coefficients as well as the number and the position of landmarks using geometric constraints. During the learning stage the approach obtains a landmark shape model, based on diffusion maps. For the model search we apply an approach related to active feature models; the location of landmarks is updated iteratively, using local features, and the canonical correlation analysis. The resulting search is independent from the topology of the anatomical structure, and can represent complex geometric and photometric dependencies of the structure of interest. We report promising results on challenging medical data sets of T1 MRI full calf muscles.	coefficient;diffusion map;diffusion wavelets;interdependence;programming paradigm;wavelet	Salma Essafi;Georg Langs;Jean-François Deux;Alain Rahmouni;Guillaume Bassez;Nikos Paragios	2009	2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2009.5193024	diffusion map;data modeling;computer vision;knowledge base;canonical correlation;muscle;shape;computer science;magnetic resonance imaging;machine learning;pattern recognition;image segmentation;computational model;segmentation;wavelet transform	Vision	44.06851824065206	-76.61119818367033	24314
4f84d52f6272acbcd0f4d9433c03e3e498818276	transformation invariant control of voxel-wise false discovery rate	mri transformation invariant control voxel wise false discovery rate multiple testing statistical maps brain mapping neuroimaging community detection power enhancement fundamental geometrical property voxel wise fdr spatial transformation testing spaces normalized residuals linear models gaussian noises unit high dimensional sphere t statistics f statistics hyperspherical space mapping normalized residuals euclidean space image diffeomorphic transformation intrinsic volume of randomness semisynthetic images fdr inconsistency testing spaces;linear regression;testing;genetics;signal detection statistical analysis;statistical analysis biomedical mri brain gaussian noise medical image processing neurophysiology;neuroimaging;aerospace electronics;diseases;aerospace electronics testing volume measurement neuroimaging linear regression genetics diseases;volume measurement	"""Multiple testing for statistical maps remains a critical and challenging problem in brain mapping. Since the false discovery rate (FDR) criterion was introduced to the neuroimaging community a decade ago, many variations have been proposed, mainly to enhance detection power. However, a fundamental geometrical property known as transformation invariance has not been adequately addressed, especially for the voxel-wise FDR. Correction of multiple testing applied after spatial transformation is not necessarily equivalent to transformation applied after correction in the original space. Without the invariance property, assigning different testing spaces will yield different results. We find that normalized residuals of linear models with Gaussian noises are uniformly distributed on a unit high-dimensional sphere, independent of t-statistics and F-statistics. By defining volumetric measure in the hyperspherical space mapped by normalized residuals, instead of the image's Euclidean space, we can achieve invariant control of the FDR under diffeomorphic transformation. This hyperspherical measure also reflects intrinsic """"volume of randomness"""" in signals. Experiments with synthetic, semi-synthetic and real images demonstrate that our method significantly reduces FDR inconsistency introduced by the choice of testing spaces."""	brain mapping;chamaecyparis lawsoniana;experiment;false discovery rate;linear models;linear model;map;neuroimaging;normal statistical distribution;randomness;semiconductor industry;synthetic intelligence;voxel	Junning Li;Yonggang Shi;Arthur W. Toga	2016	IEEE transactions on medical imaging	10.1109/TMI.2016.2554554	econometrics;computer science;linear regression;machine learning;mathematics;software testing;statistics;neuroimaging	Vision	44.66398196813276	-78.09690513425095	24337
5ba55ae0597bcfc890abc914f11554f7c0a1f075	iterative transductive learning for automatic image segmentation and matting with rgb-d data	irregular neighboring patches;transductive learning;image segmentation;rgb d data;adaptive laranger;kinect;image matting;depth holes;iterative optimization	In this paper, we propose a fully automatic image segmentation and matting approach with RGB-Depth (RGB-D) data based on iterative transductive learning. The algorithm consists of two key elements: robust hard segmentation for trimap generation, and iterative transductive learning based image matting. The hard segmentation step is formulated as a Maximum A Posterior (MAP) estimation problem, where we iteratively perform depth refinement and bi-layer classification to achieve optimal results. For image matting, we propose a transductive learning algorithm that iteratively adjusts the weights between the objective function and the constraints, overcoming common issues such as over-smoothness in existing methods. In addition, we present a new way to form the Laplacian matrix in transductive learning by ranking similarities of neighboring pixels, which is essential to efficient and accurate matting. Extensive experimental results are reported to demonstrate the state-of-the-art performance of our method both subjectively and quantitatively. 2014 Elsevier Inc. All rights reserved.	algorithm;estimation theory;image segmentation;iteration;iterative method;laplacian matrix;loss function;optimization problem;pixel;refinement (computing);transduction (machine learning)	Bei He;Guijin Wang;Cha Zhang	2014	J. Visual Communication and Image Representation	10.1016/j.jvcir.2014.03.002	computer vision;transduction;computer science;machine learning;pattern recognition;mathematics;image segmentation	AI	47.20225046371906	-69.91304978408749	24357
2cd4728cac15986fdc26715676e2625cc9c1b560	direct content access and extraction from jpeg compressed images	image indexing;indexation;image browsing;jpeg and visual information systems;pattern recognition;image indexing and retrieval in compressed domain;visual information system	In this paper, we propose a novel design of content access and extraction algorithm for compressed image browsing and indexing, which is critical for all visual information systems. By analyzing the relationship between DCT coe3cients of one block of 8 × 8 pixels and its four sub-blocks of 4 × 4 pixels, the proposed algorithm extract an approximated image with smaller size for indexing and content browsing without incurring full decompression. While the computing cost is signi9cantly lower than full decompression, the approximated image also reserves the content features, which are su3cient for indexing and browsing as evidenced by our extensive experiments. ? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	approximation algorithm;brute-force search;computer science;computer vision;data compression;digital revolution;discrete cosine transform;experiment;feature extraction;image processing;image quality;image retrieval;image viewer;information management;information system;jpeg;line integral convolution;pattern recognition;pixel;random access	Jianmin Jiang;Andrew James Armstrong;Guo-Can Feng	2002	Pattern Recognition	10.1016/S0031-3203(01)00217-5	computer vision;computer science;pattern recognition;multimedia;information retrieval	Vision	42.31556385511758	-61.58634085230508	24394
7dbf2c28f8289982e6150ba265f650afe27fb4dc	fingerprint image enhancement using stft analysis	analisis imagen;mascara;traitement signal;belief;image processing;accentuation image;analyse fourier;image databank;biometrie;biometrics;biometria;procesamiento imagen;analyse temporelle;probabilistic approach;data mining;analisis temporal;traitement image;short time fourier transform;time analysis;image enhancement;empreinte digitale;croyance;fouille donnee;fingerprint recognition;signal processing;dactyloscopie;banco imagen;banque image;non stationary condition;pattern recognition;fingerprint;fourier analysis;image analysis;analisis fourier;condition non stationnaire;huella digital;masque;reconnaissance forme;condicion no estacionaria;reconocimiento patron;creencia;procesamiento senal;analyse image;busca dato;mask;fingerprint identification	Contrary to popular belief, despite decades of research in fingerprints, reliable fingerprint recognition is still an open problem. Extracting features out of poor quality prints is the most challenging problem faced in this area. This paper introduces a new approach for fingerprint enhancement based on Short Time Fourier Transform(STFT) Analysis. STFT is a well known technique in signal processing to analyze non-stationary signals. Here we extend its application to 2D fingerprint images.The algorithm simultaneously estimates all the intrinsic properties of the fingerprints such as the foreground region mask, local ridge orientation and local frequency orientation. We have evaluated the algorithm over a set of 800 images from FVC2002 DB3 database and obtained a 17% relative improvement in the recognition rate.	algorithm;download;feature extraction;fingerprint recognition;image editing;instantaneous phase;matlab;short-time fourier transform;signal processing;stationary process	Sharat Chikkerur;Venu Govindaraju;Alexander N. Cartwright	2005		10.1007/11552499_3	fingerprint;computer vision;image analysis;speech recognition;image processing;computer science;signal processing	Vision	45.34330158986197	-60.38269498253792	24397
2431eeb2df8877d78901fa37a091a23dc207c2b2	rotation-invariant hog descriptors using fourier analysis in polar and spherical coordinates	spherical harmonics;volumetric data;feature design;rotation invariance;histogram of oriented gradients;fourier analysis;image descriptor	The histogram of oriented gradients (HOG) is widely used for image description and proves to be very effective. In many vision problems, rotation-invariant analysis is necessary or preferred. Popular solutions are mainly based on pose normalization or learning, neglecting some intrinsic properties of rotations. This paper presents a method to build rotation-invariant HOG descriptors using Fourier analysis in polar/spherical coordinates, which are closely related to the irreducible representation of the 2D/3D rotation groups. This is achieved by considering a gradient histogram as a continuous angular signal which can be well represented by the Fourier basis (2D) or spherical harmonics (3D). As rotation-invariance is established in an analytical way, we can avoid discretization artifacts and create a continuous mapping from the image to the feature space. In the experiments, we first show that our method outperforms the state-of-the-art in a public dataset for a car detection task in aerial images. We further use the Princeton Shape Benchmark and the SHREC 2009 Generic Shape Benchmark to demonstrate the high performance of our method for similarity measures of 3D shapes. Finally, we show an application on microscopic volumetric data.	aerial photography;angularjs;artifact (software development);basis function;benchmark (computing);coefficient;computation;continuous signal;convolution;discretization;experiment;feature vector;fourier analysis;gradient;histogram of oriented gradients;irreducibility;selectivity (electronic);steerable filter	Kun Liu;Henrik Skibbe;Thorsten L Schmidt;Thomas Blein;Klaus Palme;Thomas Brox;Olaf Ronneberger	2013	International Journal of Computer Vision	10.1007/s11263-013-0634-z	computer vision;mathematical optimization;histogram of oriented gradients;computer science;mathematics;geometry;fourier analysis;spherical harmonics	Vision	39.50961868634555	-56.64559807273552	24414
19924f72de0b56b2116dd78bb4712d2df0ce2f2a	a method for binarization of document images from a live camera stream	image processing;document image binarization	This paper describes a method for binarization of document images from a live camera stream. The method is based on histogram matching over partial images referred to as tiles. A method developed previously has been applied successfully to images with artificially added noise. Here, an improved method is presented, in which the user has more direct control over the specification of the binarizer. The resulting system is then taken a step further, by considering the more difficult case of binarization of live camera images. It is demonstrated that the improved method works well for this case, even when the image stream is obtained using a slightly modified low-cost web camera with low resolution. For typical images obtained this way, a standard OCR reader is capable of reading the binarized images, detecting around 87.5i¾?% of all words without any error, and with mostly minor, correctable errors for the remaining words.		Mattias Wahde	2014		10.1007/978-3-319-25210-0_9	computer vision;computer science;multimedia;computer graphics (images)	Vision	37.719987640263994	-66.3516287566221	24441
13f32ae01479781e0a1a854ac0c81a081991f20b	spatially-variant directional mathematical morphology operators based on a diffused average squared gradient field	mathematical morphology;binary image;local adaptation	This paper proposes an approach for mathematical morphology operators whose structuring element can locally adapt its orientation across the pixels of the image. The orientation at each pixel is extracted by means of a diffusion process of the average squared gradient field. The resulting vector field, the average squared gradient vector flow, extends the orientation information from the edges of the objects to the homogeneous areas of the image. The provided orientation field is then used to perform a spatially variant filtering with a linear structuring element. Results of erosion, dilation, opening and closing spatially-variant on binary images prove the validity of this theoretical sound and novel approach.	algorithm;binary image;biometrics;closing (morphology);dilation (morphology);erosion (morphology);gradient;grayscale;image processing;knowledge acquisition and documentation structuring;mathematical morphology;opening (morphology);pixel;structuring element	Rafael Verdú;Jesús Angulo	2008		10.1007/978-3-540-88458-3_49	computer vision;mathematical optimization;mathematical morphology;binary image;computer science;morphological gradient;mathematics;geometry;structuring element	Vision	47.97904763661874	-68.21576375101802	24468
63b290eeac6358b7c1ce10edf5ea9d742302ef7d	multi-net system configuration for visual object segmentation by error backpropagation		This work proposes a new error backpropagation approach as a systematic way to configure and train the Multi-net System MNOD, a recently proposed algorithm able to segment a class of visual objects from real images. First, a single node of the MNOD is configured in order to best resolve the visual object segmentation problem using the best combination of parameters and features. The problem is then how to add new nodes in order to improve accuracy and avoid overfitting situations. In this scenario, the proposed approach employs backpropagation of error maps to add new nodes with the aim of increasing the overall segmentation performance. Experiments conducted on a standard dataset of real images show that our configuration method, using only simple edges and colors descriptors, leads to configurations that produced comparable results in visual objects segmentation.	adaboost;algorithm;backpropagation;color;experiment;map;memory segmentation;overfitting;simple features;system configuration;visual objects	Ignazio Gallo;Marco Vanetti;Simone Albertini;Angelo Nodari	2013		10.1007/978-3-642-38628-2_55	computer vision;machine learning;segmentation-based object categorization;pattern recognition;scale-space segmentation	Vision	30.23668975068137	-52.89062636781154	24530
37729a7bcfa57bb79e76d248bdd4537d32253293	robust anatomical correspondence detection by hierarchical sparse graph matching	hand;computer vision hierarchical sparse graph matching anatomical correspondence detection image registration motion correction graph nodes graph edges sparsity constraint pairwise agreement fuzziness hand x ray images;graph theory;sensitivity and specificity;multi models;image matching;radiographic image enhancement;graph matching;anatomic landmarks;fuzzy set theory;computer vision;sparsity;hierarchical correspondence detection;medical image processing;reproducibility of results;sparsity graph matching hierarchical correspondence detection line patch multi models;line patch;algorithms anatomic landmarks hand humans pattern recognition automated radiographic image enhancement radiographic image interpretation computer assisted reproducibility of results sensitivity and specificity subtraction technique;algorithms;pattern recognition automated;humans;medical image processing computer vision diagnostic radiography fuzzy set theory graph theory image matching;subtraction technique;radiographic image interpretation computer assisted;diagnostic radiography;x ray imaging robustness optimization vectors feature extraction biomedical imaging deformable models	Robust anatomical correspondence detection is a key step in many medical image applications such as image registration and motion correction. In the computer vision field, graph matching techniques have emerged as a powerful approach for correspondence detection. By considering potential correspondences as graph nodes, graph edges can be used to measure the pairwise agreement between possible correspondences. In this paper, we present a novel, hierarchical graph matching method with sparsity constraint to further augment the power of conventional graph matching methods in establishing anatomical correspondences, especially for the cases of large inter-subject variations in medical applications. Specifically, we first propose to measure the pairwise agreement between potential correspondences along a sequence of intensity profiles which reduces the ambiguity in correspondence matching. We next introduce the concept of sparsity on the fuzziness of correspondences to suppress the distraction from misleading matches, which is very important for achieving the accurate, one-to-one correspondences. Finally, we integrate our graph matching method into a hierarchical correspondence matching framework, where we use multiple models to deal with the large inter-subject anatomical variations and gradually refine the correspondence matching results between the tentatively deformed model images and the underlying subject image. Evaluations on both synthetic data and public hand X-ray images indicate that the proposed hierarchical sparse graph matching method yields the best correspondence matching performance in terms of both accuracy and robustness when compared with several conventional graph matching methods.	computer vision;diagnostic radiologic examination;distraction - pain management method;evaluation;graph - visual representation;graph theory;image registration;matching (graph theory);medical image;motion estimation;numerous;one-to-one (data model);radiography;sid meier's alpha centauri;sparse matrix;structure of parenchyma of lung;synthetic data;registration - actclass	Yanrong Guo;Guorong Wu;Jianguo Jiang;Dinggang Shen	2013	IEEE Transactions on Medical Imaging	10.1109/TMI.2012.2223710	computer vision;computer science;graph theory;3-dimensional matching;machine learning;pattern recognition;mathematics;fuzzy set;sparsity-of-effects principle;matching	Vision	42.64555671927953	-77.03004559722537	24536
1e89ca2554bc3e03c4566f6e38a13d1e5f090401	feature extraction of volume data based on multi-scale representation	feature detection;volume rendering;multi scale;scientific visualization;scale space;medical image;feature extraction;medical imaging;volume processing;applications;volume data	In this paper, we present a novel algorithm that can detect and extract salient points as features in 3-D volume datasets. This algorithm extracts not only the locations of feature points, but also finds out the scales at which the features are most significant. It applies the scale-space theory by adaptively processing the input volume in a few discrete scales. The features points, as well as their scales, detected can be used for subsequent processing, such as content-based volume data authentication and content-based volume rendering.We have implemented the algorithm and tested its effectiveness on several volume datasets. Some optimization has also been done on time-consuming intermediate steps to speed up the feature detection process.	algorithm;feature detection (computer vision);feature detection (web development);feature extraction;mathematical optimization;message authentication;scale space;speedup;volume rendering	Yinghui Wu;Ee-Chien Chang;Zhiyong Huang;Mohan S. Kankanhalli	2003		10.1145/604471.604506	medical imaging;computer vision;scientific visualization;scale space;feature extraction;computer science;pattern recognition;feature detection;data mining;volume rendering;feature	Visualization	40.77939555722623	-70.69677171240214	24546
952acbdce4764d4e3b035a28d8218c2506ceb00f	efficient use of cerebral cortical thickness to correct brain mr segmentation	brain;longitudinal study;image segmentation;laplace equations image segmentation thickness measurement biomedical measurements anisotropic magnetoresistance surface morphology surface fitting magnetic resonance magnetic field measurement deformable models;finite difference;indexing terms;magnetic resonance image;neurodegenerative disorder;expectation maximization;medical image processing;neurophysiology biomedical mri brain expectation maximisation algorithm finite difference methods image segmentation medical image processing;segmentation probability map cerebral cortical thickness brain mr segmentation expectation maximization approach laplace equation finite difference equation;neurophysiology;finite difference methods;cortical thickness;biomedical mri;expectation maximisation algorithm	Efficient, automatic and robust tools for measurement of cerebral cortical thickness would aid diagnosis and longitudinal studies of neurodegenerative disorders. In this work, we segment a 3D magnetic resonance image of the brain using an expectation-maximization approach. The definition of thickness used is based on the solution of Laplace's equation in the cortex. Unlike other works, finite difference equations for calculation of cortical thickness are generalized for anisotropic images in order to avoid resampling the input images. We also developed a method which combines information from the thickness estimation with the segmentation probability maps, in order to detect missegmented sulci and correct the segmentation accordingly.	expectation–maximization algorithm;finite difference;map;recurrence relation;resonance;thickness (graph theory)	Thanh-Mai Diep;Pierrick Bourgeat;Sébastien Ourselin	2007	2007 4th IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2007.356921	computer vision;mathematical optimization;finite difference;index term;expectation–maximization algorithm;computer science;finite difference method;magnetic resonance imaging;machine learning;mathematics;image segmentation;neurophysiology	Vision	43.507805948248105	-76.81883808852315	24600
6144adfca74da9948890b9112d468d71b253b921	medical image retrieval based on bidimensional empirical mode decomposition	hilbert transforms;cluster algorithm;fractals;medical image retrieval;biomedical imaging image retrieval feature extraction data mining image databases matrix decomposition clustering algorithms fractals information retrieval spatial databases;medical image decomposition;medical image processing fractals hilbert transforms;clustering algorithm;texture feature extraction;boundary processing;standard deviation;instantaneous frequency;texture features;intrinsic mode functions;boundary processing content based medical image retrieval texture analysis bidimensional empirical mode decomposition;fractal dimension;hilbert transform;texture analysis;medical image;phase matrix;intrinsic mode function;multiscale fractal dimension feature medical image retrieval bidimensional empirical mode decomposition medical image decomposition texture feature extraction intrinsic mode functions phase matrix instantaneous frequency matrix amplitude matrix hilbert transformations boundary processing method clustering algorithm;feature extraction;medical image processing;amplitude matrix;content based medical image retrieval;hilbert transformations;bidimensional empirical mode decomposition;spatial relationships;boundary processing method;instantaneous frequency matrix;multiscale fractal dimension feature;empirical mode decomposition	An approach of medical image decomposition and texture feature extraction based on the bidimensional empirical mode decomposition(BEMD), which can decompose the image into a set of functions denoted intrinsic mode functions (IMF) and a residue, was presented. Features extracted were the mean and standard deviation of the amplitude matrix, phase matrix and instantaneous frequency matrix of the IMFs and their Hilbert transformations. The extracted features were used for medical image retrieval. Moreover, according to the spatial relationship between local extrema points, a new boundary processing method based on clustering algorithm was proposed. In order to evaluate the proposed BEMD-based feature, we also presented a new multiscale fractal dimension feature. Preliminary comparison experimental results showed that the retrieval results of the BEMD-based feature were encouraged.	algorithm;cluster analysis;feature extraction;fractal dimension;hilbert space;hilbert–huang transform;image retrieval;instantaneous phase;maxima and minima	Wei Liu;Weidong Xu;Lihua Li	2007	2007 IEEE 7th International Symposium on BioInformatics and BioEngineering	10.1109/BIBE.2007.4375628	spatial relation;instantaneous phase;computer vision;hilbert transform;fractal;feature extraction;hilbert–huang transform;machine learning;pattern recognition;mathematics;cluster analysis;fractal dimension;standard deviation	Vision	38.34985580677992	-61.62892606254234	24712
fe1e5c1326cf16dee15165c2d258484e4fce7bf1	measuring hepatocytes reaction to dimethylnitrosamine using computerized microscope	biology computing;biological techniques and instruments;boundary formation computerised picture processing biology computing hepatocytes reaction dimethylnitrosamine computerized microscope image analysis hamster livers local search algorithm boundary search cytoplasm edges inner nucleus granularities;liver;image processing;local search algorithm;microscopy biomedical imaging liver pathology biomedical measurements image analysis animals microcomputers convolution kernel;microscopes biological techniques and instruments biology computing computerised picture processing liver;microscopes;software development;computerised picture processing;image analysis	The authors present a computer image analysis system which yields a quantitative description of hepatocyte reaction to dimethylnitrosamine, a potent carcinogen to the liver. A computer equipped with image processing hardware and software developed inhouse was used to measure hepatocyte nuclei in pathological section from hamster livers exposed to the poison. The critical step which determined measurement accuracy was boundary finding. A local search algorithm with limited depth was utilized. This algorithm overcame failures of the boundary search in cases where strong cytoplasm edges or inner-nucleus granularities caused imprecise boundary formation. The results show the progression of damage to the nuclei sampled from hamsters in the continuous exposure group, and regression back to normal in the two withdrawal groups. >		Eyal Bartfeld;Gershom Zajicek;G. Kenet;Devorah Schwartz-Arad	1988		10.1109/ICPR.1988.28268	computer vision;microscope;image analysis;image processing;computer science;local search;software development	Robotics	35.707223411517774	-79.79485667221704	24721
70ffedec6058b04159501170bb1c4e30e1769075	detection and classification of masses in mammographic images in a multi-kernel approach	extreme learning machines;support vector machines;mammography;breast cancer;multi resolution wavelets	BACKGROUND AND OBJECTIVE According to the World Health Organization, breast cancer is the main cause of cancer death among adult women in the world. Although breast cancer occurs indiscriminately in countries with several degrees of social and economic development, among developing and underdevelopment countries mortality rates are still high due to low availability of early detection technologies. From the clinical point of view, mammography is still the most effective diagnostic technology, given the wide diffusion of the use and interpretation of these images.   METHODS Herein this work we propose a method to detect and classify mammographic lesions using the regions of interest of images. Our proposal consists in decomposing each image using multi-resolution wavelets. Zernike moments are extracted from each wavelet component. Using this approach, we can combine both texture and shape features, which can be applied both to the detection and classification of mammary lesions. We used 355 images of fatty breast tissue of IRMA database, with 233 normal instances (no lesion), 72 benign, and 83 malignant cases.   RESULTS Classification was performed by using SVM and ELM networks with modified kernels in order to optimize accuracy rates, reaching 94.11%. Considering both accuracy rates and training times, we defined the ration between average percentage accuracy and average training time in a reverse order. Our proposal was 50 times higher than the ratio obtained using state-of-the-art approaches.   CONCLUSIONS As our proposed model can combine high accuracy rate with low learning time, whenever a new data is received, our work will be able to save a lot of time, hours, in learning process in relation to the best method of the state-of-the-art.	algorithm;artificial neural network;bi-rads;binary image;body tissue;breast fibroglandular tissue;breast imaging reporting and data system;class;computer vision;data (computing);early diagnosis;economic development;experiment;feature extraction;image analysis;immunoradiometric assays;irma board;kernel;linux;mammary gland parenchyma;mammary neoplasms;mammography;mathematical morphology;multilayer perceptron;neural network simulation;noninfiltrating intraductal carcinoma;numerous;paget's disease, mammary;point of view (computer hardware company);polynomial;radial basis function;record of retained body fluids or tissue sample;region of interest;resonance;support vector machine;symlet;wavelet;anatomical layer	Sidney M. L. Lima;Abel G. da Silva Filho;Wellington Pinheiro dos Santos	2016	Computer methods and programs in biomedicine	10.1016/j.cmpb.2016.04.029	support vector machine;computer vision;pathology;computer science;breast cancer;machine learning;data mining;statistics	ML	32.97288530574362	-76.01959893274754	24753
4d8435f7e6a0c1d58f413648bc8e04938b7dfa50	hierarchical estimation of optical flow using spectral energy method	gradient methods;image matching;image resolution;image sequences;coarsest resolution image sequences;dynamic image analysis;frequency analysis;gradient method;hierarchical estimation;image matching method;optical flow;spectral energy method;optical imaging;computer vision;optical filters;adaptive optics	The estimation of optical flow is an important problem in the dynamic image analysis. There are various methods of estimating the optical flow. The gradient method and matching method are based on the operation in the space-time domain. While spectral energy method is based on the frequency analysis and has robustness against noise. In this paper, we propose a hierarchical estimation of the optical flow using spectral energy method. In the proposed method, we make a set of hierarchical images for each frame. A global motion which is estimated at the coarsest resolution image sequences is corrected by using finer resolution image sequences. Consequently we can estimate both global and local motion accurately with robustness to noise.	frequency analysis;gradient method;image analysis;optical flow	Takashi Koike;Katsuya Kondo;Nozomu Hamada	1998	9th European Signal Processing Conference (EUSIPCO 1998)		image restoration;computer vision;mathematical optimization;feature detection;image processing;digital image correlation;mathematics;optics	Vision	52.3797620804105	-59.531375450355974	24791
ee75772cb5b3163686b32c0e84bd111be50a5833	superresolution with second generation wavelets	transformation ondelette;filtering;filtrage;high resolution reconstruction;second generation wavelet;high resolution;image processing;filtrado;low resolution;procesamiento imagen;traitement image;reduccion ruido;algorithme;algorithm;reconstruction image;haute resolution;reconstruccion imagen;image reconstruction;noise reduction;image sequence superresolution;image sequence;alta resolucion;reduction bruit;secuencia imagen;transformacion ondita;superresolution;superresolucion;second generation wavelets;wavelet transformation;sequence image;algoritmo	Over the last 3 years or so, first-generation wavelets have been used to realize superresolution from a captured sequence of low-resolution (LR) degraded frames. Here, it is pointed out that second-generation wavelets (SGWs) are inherently more suited for image superresolution. From preliminary results that exploit subpixel displacements between LR frames to attain superresolution, it is concluded that SGWs show promise and potential to be extremely fast, efficient and versatile for superresolution.	second generation multiplex plus;super-resolution imaging;wavelet	Nirmal K. Bose;Surapong Lertrattanapanich;Mahesh B. Chappalli	2004	Sig. Proc.: Image Comm.	10.1016/j.image.2004.02.001	computer vision;image resolution;image processing;computer science;computer graphics (images)	ML	53.01587003566185	-60.912624462849436	24816
ceaf24a1c756938125ef5865ec2183730385d7ea	discussions on some problems in face recognition	reconnaissance visage;interfase usuario;non invasive method;algorithm performance;illumination;facies;user interface;biometrie;localization;authentication;extraction forme;biometrics;biometria;face verification;localizacion;imagen nivel gris;classification;methode non invasive;authentification;autenticacion;face recognition;localisation;extraccion forma;resultado algoritmo;feature extraction;image niveau gris;performance algorithme;pattern recognition;interface utilisateur;reconnaissance forme;extraction caracteristique;reconocimiento patron;face detection;eclairement;grey level image;pattern extraction;clasificacion;alumbrado;metodo no invasivo	Face identification and verification have received more attention in biometric person authentication as their non-invasive, broad useful, and user-friendly. In the Face Authentication Test (FAT2004) held in conjunction with the 17th International Conference on Pattern Recognition, Tsinghua University won the Awards of Best Overall Performance Face Verification Algorithm. In this paper, we will discuss about some problems about improving the face recognition performance. Imitating human face identification through discriminating the face observation is very important for face recognition. Key technologies for distinguishing persons based on face appearances of different position, size, illumination, pose and age: face detection, feature location, size and grey level of face appearance normalization. Also, feature extraction and classification should be the focuses of face recognition research. Dealing with 3D pose variation and aging is the most difficult problem and needs more attention to obtain better face recognition performance.	3d single-object recognition;algorithm;authentication;biometrics;computer vision;face detection;facial recognition system;feature extraction;grayscale;illumination (image);image analysis;outline of object recognition;pattern recognition;usability	Xiaoqing Ding;Chi Fang	2004		10.1007/978-3-540-30548-4_7	facial recognition system;computer vision;face detection;speech recognition;computer science;artificial intelligence;three-dimensional face recognition;authentication;face recognition grand challenge;computer security	Vision	45.178131002955375	-59.91119107004019	24837
623ecc3a82acaabe27f759043015c0c3c2687979	fuzzy energy based active contours model for hr-pqct cortical bone segmentation	protocols;image segmentation;bones image segmentation active contours three dimensional displays nonhomogeneous media protocols;active contours;bones;nonhomogeneous media;three dimensional displays;bone 3d segmentation active contours fuzzy energy hr pqct	High Resolution peripheral Quantitative Computed Tomography (HR-pQCT) imaging for studying bone disease has become increasingly common. However, due to the bone inhomogeneity and the noise characteristics, segmentation of HR-pQCT data remains a challenging task. In this work we propose a novel segmentation technique of the cortical bone based on fuzzy energy active contours model. A novel approach as well as a new formulation of the fuzzy membership function are proposed to deal with the HR-pQCT inhomogeneity and separate the cortical bone from the trabecular one. Results show the efficiency and the high accuracy of the proposed approach compared to different existing techniques in terms of Dice similarity coefficient (DSC). Proposed method provides high result (DSC: 90.14±1.64%) compared to Burghardt (DSC: 85.86±3,16%) and FEBAC (DSC: 85.5±4.52%).	ct scan;coefficient;quantitative computed tomography	Mohamed Hafri;Hechmi Toumi;Stephanie Boutroy;Roland D. Chapurlat;Eric Lespessailles;Rachid Jennane	2016	2016 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2016.7533178	communications protocol;computer vision;computer science;image segmentation;scale-space segmentation	Robotics	40.573879198934115	-77.38542780252439	24847
25e0646e8c794859470c2cd583c58823ada6925b	aggregating binary local descriptors for image retrieval	binary local feature;fisher vector;vlad;bag of words;convolutional neural network;content-based image retrieval	Content-Based Image Retrieval based on local features is computationally expensive because of the complexity of both extraction and matching of local feature. On one hand, the cost for extracting, representing, and comparing local visual descriptors has been dramatically reduced by recently proposed binary local features. On the other hand, aggregation techniques provide a meaningful summarization of all the extracted feature of an image into a single descriptor, allowing us to speed up and scale up the image search. Only a few works have recently mixed together these two research directions, defining aggregation methods for binary local features, in order to leverage on the advantage of both approaches.In this paper, we report an extensive comparison among state-of-the-art aggregation methods applied to binary features. Then, we mathematically formalize the application of Fisher Kernels to Bernoulli Mixture Models. Finally, we investigate the combination of the aggregated binary features with the emerging Convolutional Neural Network (CNN) features. Our results show that aggregation methods on binary features are effective and represent a worthwhile alternative to the direct matching. Moreover, the combination of the CNN with the Fisher Vector (FV) built upon binary features allowed us to obtain a relative improvement over the CNN results that is in line with that recently obtained using the combination of the CNN with the FV built upon SIFTs. The advantage of using the FV built upon binary features is that the extraction process of binary features is about two order of magnitude faster than SIFTs.	analysis of algorithms;bernoulli polynomials;content-based image retrieval;convolutional neural network;farmville;fisher information;mixture model;visual descriptor	Giuseppe Amato;Fabrizio Falchi;Lucia Vadicamo	2017	Multimedia Tools and Applications	10.1007/s11042-017-4450-2	artificial intelligence;pattern recognition;convolutional neural network;automatic summarization;mixture model;computer science;content-based image retrieval;speedup;bag-of-words model;machine learning;binary number;image retrieval	Vision	30.928335016059325	-54.82343041671914	24856
1891fb2dfaa6b248d6c50f11315f81462eec17f0	learning to rank atlases for multiple-atlas segmentation	health research;atlas selection;uk clinical guidelines;biological patents;medical image processing image segmentation learning artificial intelligence;europe pubmed central;support vector machine svm rank;citation search;multi atlas based segmentation;uk phd theses thesis;life sciences;support vector machine svm rank atlas selection feature selection multi atlas based segmentation;feature selection;uk research reports;medical journals;image similarity based atlas selection methods multiple atlas segmentation medical imaging area target image labeling single atlas image similarity heuristic criterion final segmentation performance critical problem pairwise appearance observed instances final labeling performance expected labeling accuracy adni dataset sata dataset ixi dataset loni lpba40 dataset mas method learning based atlas selection methods;europe pmc;biomedical research;image segmentation training labeling feature extraction vectors accuracy mutual information;bioinformatics	Recently, multiple-atlas segmentation (MAS) has achieved a great success in the medical imaging area. The key assumption is that multiple atlases have greater chances of correctly labeling a target image than a single atlas. However, the problem of atlas selection still remains unexplored. Traditionally, image similarity is used to select a set of atlases. Unfortunately, this heuristic criterion is not necessarily related to the final segmentation performance. To solve this seemingly simple but critical problem, we propose a learning-based atlas selection method to pick up the best atlases that would lead to a more accurate segmentation. Our main idea is to learn the relationship between the pairwise appearance of observed instances (i.e., a pair of atlas and target images) and their final labeling performance (e.g., using the Dice ratio). In this way, we select the best atlases based on their expected labeling accuracy. Our atlas selection method is general enough to be integrated with any existing MAS method. We show the advantages of our atlas selection method in an extensive experimental evaluation in the ADNI, SATA, IXI, and LONI LPBA40 datasets. As shown in the experiments, our method can boost the performance of three widely used MAS methods, outperforming other learning-based and image-similarity-based atlas selection methods.	algorithmic efficiency;atlases;best practice;computation;experiment;heuristic;image registration;learning to rank;medical imaging;mutual information;relevance;selection (genetic algorithm);serial ata;silo (dataset);similarity measure;sparse matrix;biologic segmentation;registration - actclass	Gerard Sanroma;Guorong Wu;Yaozong Gao;Dinggang Shen	2014	IEEE Transactions on Medical Imaging	10.1109/TMI.2014.2327516	medical research;computer science;data science;machine learning;pattern recognition;data mining;feature selection	Vision	42.28954810920286	-78.1388102366628	24881
9ec29e8538027b64b9243024c033ca6bf5adc733	comparing face images using the modified hausdorff distance	base donnee;algorithm performance;image processing;point to point;edge detection;digital library;database;procesamiento imagen;base dato;correspondence problem;traitement image;gray scale;similitude;deteccion contorno;algorithme;algorithm;detection contour;face recognition;computational complexity;resultado algoritmo;mappage;distance hausdroff;similarity;performance algorithme;pattern recognition;hausdorff distance;face;mapping;reconnaissance forme;similitud;reconocimiento patron;hausdroff distance;echelle gris;retinal imaging;similarity measure;cognitive function;high speed;visual processing;escala gris;algoritmo;cara	We introduce a novel methodology applicable to face matching and fast screening of large facial databases. The proposed shape comparison method operates on edge maps and derives holistic similarity measures, yet, it does not require solving the point correspondence problem. While the use of edge images is important to introduce robustness to changes in illumination, the lack of point-to-point matching delivers speed and tolerance to local non-rigid distortions. In particular, we propose a face similarity measure derived as a variant of the Hausdorff distance by introducing the notion of a neighborhood function (N) and associated penalties (P). Experimental results on a large set of face images demonstrate that our approach produces excellent recognition results even when less than 3% of the original grey-scale face image information is stored in the face database (gallery). These results implicate that the process of face recognition may start at a much earlier stage of visual processing than it was earlier suggested. We argue, that edge-like retinal images of faces are initially screened ‘‘at a glance’’ without the involvement of high-level cognitive functions thus delivering high speed and reducing computational complexity. ( 1998 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved. Digital libraries Face recognition Modified Hausdorff distance	categorization;cognition;computational complexity theory;correspondence problem;data point;database;digital library;distortion;facial recognition system;grayscale;hausdorff dimension;high- and low-level;holism;image resolution;library (computing);map;pattern recognition;point-to-point protocol;projection screen;similarity measure	Barnabás Takács	1998	Pattern Recognition	10.1016/S0031-3203(98)00076-4	face;hausdorff distance;computer vision;digital library;cognition;edge detection;similarity;image processing;point-to-point;computer science;artificial intelligence;similitude;mathematics;geometry;correspondence problem;computational complexity theory;algorithm;grayscale	Vision	46.667795902608646	-60.204256607778234	24888
41eba1642dc8d1ff364fe9686a8f8db40c867e9a	university of glasgow at imageclef 2009 robot vision task: a rule based approach	interest points;rule based;robot vision;decision rule	For the submission from the University of Glasgow for the Image-CLEF 2009 Robot Vision Task a large set of interesting points were extracted using an edge corner detector, these points were used to represent each image. The RANSAC method [1] was then applied to estimate the similarity between test and training images based on the number of matched pairs of points. The location of robot was then annotated based on the training image which contains the highest number of matched point pairs with the test image. A set of decision rules with the respect to the trajectory behaviour of robot's motion were defined to refine the final results. An illumination filter was also applied for two of the runs in order to reduce the illumination effect.		Yue Feng;Martin Halvey;Joemon M. Jose	2009		10.1007/978-3-642-15751-6_38	rule-based system;computer vision;simulation;computer science;artificial intelligence;decision rule	Robotics	42.36485050142423	-54.12491553847089	24901
d0d895330876613816db177f3b23fb780a386ab9	an edge preserving regularization model for image restoration based on hopfield neural network	modelizacion;processus gauss;hopfield model;metodo adaptativo;modele hopfield;image numerique;restauration image;image processing;modelo hopfield;laplacian;procesamiento imagen;hopfield neural nets;image restoration;methode adaptative;traitement image;hopfield neural network;modelisation;restauracion imagen;laplacien;laplaciano;reseau neuronal hopfield;adaptive method;imagen numerica;total variation;digital image;gaussian process;reseau neuronal;proceso gauss;modeling;red neuronal;variacion total;variation totale;neural network	This paper designs an edge preserving regularization model for image restoration. First, we propose a generalized form of Digitized Total Variation (DTV), and then introduce it into restoration model as the regularization term. To minimize the proposed model, we map digital image onto network, and then develop energy descending schemes based on Hopfield neural network. Experiments show that our model can significantly better preserve the edges of image compared with the commonly used Laplacian regularization (with constant and adaptive coefficient). We also study the effects of neighborhood and gaussian parameter on the proposed model through experiments.	circuit restoration;hopfield network;image restoration;matrix regularization	Jian Sun;Zongben Xu	2006		10.1007/11760023_83	image restoration;computer vision;laplace operator;systems modeling;image processing;computer science;artificial intelligence;machine learning;gaussian process;mathematics;total variation;digital image;artificial neural network	Vision	52.54118385112764	-68.43999034239957	25025
a52e699b0705da8d8cfd8ad096ad837901b497f5	multi-scale neural texture classification using the gpu as a stream processing engine	nvidia geforce 8800 gtx;paper;texture detection;neural processing;gpu;nvidia;opengl;computer science;stream processing;visual system;cg	A neural architecture for texture classification running on the Graphics Processing Unit (GPU) under a stream processing model is presented in this paper. Textural features extraction is done in three different scales, it is based on the computations that take place on the mammalian primary visual pathway and incorporates both structural and color information. Feature vectors classification is done using a fuzzy neural network which introduces pattern analysis for orientation invariant texture recognition. Performance tests are done over a varying number of textures and the entire VisTex database. The intrinsic parallelism of the neural system led us to implement the whole architecture to run on GPUs, providing a speed-up between × 16 and × 25 for classifying textures of sizes 128 × 128 and 512 × 512 px with respect to an implementation on the CPU. A comparison of classification rates obtained with other methods is included and shows the great performance of the architecture. An average classification rate of 85.2% is obtained for 167 textures of size 512 × 512 px.	artificial neural network;central processing unit;computation;computer vision;experiment;feature extraction;feature vector;gene regulatory network;graphics processing unit;maxima and minima;mind;neuro-fuzzy;parallel computing;pattern recognition;run time (program lifecycle phase);stream processing;synchronization (computer science);texture mapping	Mario Martínez-Zarzuela;Francisco Javier Díaz Pernas;Miriam Antón-Rodríguez;José Fernando Díez Higuera;David González Ortega;Daniel Boto-Giralda;F. López-González;Isabel de la Torre Díez	2010	Machine Vision and Applications	10.1007/s00138-010-0254-3	computer vision;stream processing;visual system;computer hardware;computer science;machine learning;computer graphics (images)	ML	31.66273635290467	-60.87717826681782	25099
85e4e754970e590ddd21a0f83e3bf4616a4ff587	a multichannel convolutional neural network for hand posture recognition		Natural communication between humans involves hand gestures, which has an impact on research in human-robot interaction. In a real-world scenario, understanding human gestures by a robot is hard due to several challenges like hand segmentation. To recognize hand postures this paper proposes a novel convolutional implementation. The model is able to recognize hand postures recorded by a robot camera in real-time, in a real-world application scenario. The proposed model was also evaluated with a benchmark database and showed better results than the ones reported in the benchmark paper.	benchmark (computing);convolutional neural network;cubic function;database;deep learning;experiment;human–robot interaction;linux;modal logic;nao (robot);poor posture;real-time locating system;robot;sobel operator	Pablo V. A. Barros;Sven Magg;Cornelius Weber;Stefan Wermter	2014		10.1007/978-3-319-11179-7_51	speech recognition;machine learning;time delay neural network;convolutional neural network	AI	24.668835552294656	-60.281198286125466	25122
57c84a85af62e8f775d444f9ac2c3f19c61fdb09	a data dependent triangulation for vector fields	topology;critical point;piecewise linear techniques;computational geometry;topological skeletons data dependent triangulation vector fields piecewise linear vector field domain triangulation simple topology critical points poincare index;topology computational geometry piecewise linear techniques;data dependence;indexation;scattering computer graphics computer science ear data mining electrical capacitance tomography intrusion detection cost function switches topology;vector field	This article deals with dependencies of a piecewise linear vector field and the triangulation of the domain. It shows that the topology of the field may depend on the triangulation and gives a suitable choice to obtain a simple topology by changes of the triangulation. The main point is the appearance of pairs of critical points with positive and negative Poincaré index. Many of these occurences can be avoided by changing the grid. This is proved in the article. An algorithm is presented which uses these results to extract simpler topological skeletons than usual methods. Finally there are several examples comparing these algorithms to demonstrate the effects of the data-dependent triangulation.	algorithm;data dependency;piecewise linear continuation;topological skeleton	Gerik Scheuermann;Hans Hagen	1998		10.1109/CGI.1998.694255	triangulation;mathematical optimization;minimum-weight triangulation;vector field;computational topology;topology;delaunay triangulation;computational geometry;point set triangulation;mathematics;geometry;weak topology;extension topology;critical point;bowyer–watson algorithm;general topology;piecewise linear manifold;digital topology	Graphics	48.9307624785117	-65.05449298898513	25158
3ef7cb6045c243fd5472c22679f6b555d2352090	bilateral spatial filtering: refining methods for localizing brain activation in the presence of parenchymal abnormalities	bilateral filtering;functional mri;gaussian;low grade glioma;spatial filtering;spatial filter;bilateral filter;brain activation;signal to noise ratio	"""Functional MRI (fMRI) is an important tool for pre-surgical localization of eloquent cortex prior to resection of brain lesions. To increase the inherently low activation signal to noise ratio, fMRI pre-processing steps often include spatial smoothing. However, the effects of smoothing in the presence of brain lesions have not been studied. We have adapted the widely used method of Gaussian spatial filtering to include an """"edge stopping"""" function. This method, termed bilateral filtering, minimizes blurring of apparent brain activity across anatomic boundaries and into regions of non-activation. fMRI data were acquired in a patient with a known low grade glioma during a blocked finger-tapping paradigm. Simulated activity was superimposed on baseline images of non-activated brain using the same paradigm, with additive signal equal to 1, 3, and 5% of the mean physiologic background. Comparison of Gaussian and bilateral filtering suggests that the modified technique more accurately locates brain activation and increases the significance of activation bordering sharp transitions. Thus, spatial pre-processing with a bilateral filter may be particularly useful in the pre-operative assessment of brain lesions."""	baseline (configuration management);bilateral filter;blurred vision;class;congenital abnormality;electroencephalography;excision;gaussian blur;glioma;neoplasms;normal statistical distribution;p-value;patients;pineal gland neoplasm;preprocessor;programming paradigm;signal-to-noise ratio;smoothing (statistical technique);utility functions on indivisible goods;fmri	Scott A. Walker;David Miller;Jody Tanabe	2006	NeuroImage	10.1016/j.neuroimage.2006.06.051	computer vision;speech recognition;computer science;bilateral filter;communication;spatial filter	ML	43.98643346754894	-79.1086979652136	25184
7466a3208b474e1f924719376a7c690650aa43d9	a very deep sequences learning approach for human action recognition	会议论文	Human action recognition is a popular study in computer vision. The most difficult challenge is capturing the movement features of image sequences or videos. In recent years, deep convolutional networks have achieved great success in many image classification and recognition tasks. But in videos interpretation tasks, the deep-learning has not done well. There were [18, 19] earlier models which were built on convolutional networks for human action recognition tasks. We propose an approach based on CNNs and RNN-like models which have abilities to extract spatial and temporal features both, a CNN model can get static scores, a LSTM or GRU layer which gets dynamic class scores of human action. In another side, compared to a two-stream ConvNet [18, 24], we do not need an optical-flow CNN stream that saves us considerable time, RNN-like models just need a few hours to get convergence. And, we have achieved a quite remarkable performance. © Springer International Publishing Switzerland 2016.		Zhihui Lin;Chun Yuan	2016		10.1007/978-3-319-27674-8_23	computer vision;computer science;machine learning	Vision	28.317994809963054	-52.55397067415699	25229
c47d51607658773eb20ba77b93f2f5d38cad0c62	detecting unattended packages through human activity recognition and object association	moving object;on line systems;object recognition;deteccion blanco;systeme aide decision;hidden markov model;modele markov variable cachee;maquina vector soporte;hmm;reconnaissance objet;sistema ayuda decision;probabilistic approach;blanco movil;detection cible;detection objet;machine vecteur support;multiple objectives;decision support system;hidden markov models;enfoque probabilista;systeme en ligne;approche probabiliste;signal classification;pattern recognition;eigen features;classification signal;cible mobile;svm;reconnaissance forme;support vector machine;reconocimiento patron;human activity recognition;target detection;human activity;unattended package;moving target;object detection	This paper provides a novel approach to detect unattended packages in public venues. Different from previous works on this topic which are mostly limited to detecting static objects where no human is nearby, we provide a solution which can detect an unattended package with people in its close proximity but not its owners. Mimicking the human logic in detecting such an event, our decision-making is based on understanding human activity and the relationships between humans and packages. There are three main contributions from this paper. First, an efficient method is provided to online categorize moving objects into the predefined classes using the eigen-features and the support vector machines (SVM). Second, utilizing the classification results, a method is developed to recognize human activities with hidden Markov models (HMM) and decide the package ownership. Finally the unattended package detection is achieved by analyzing multiple object relationships: package ownership, spatial and temporal distance relationships.	activity recognition;object composition;sensor	Sijun Lu;Jian Zhang;David Dagan Feng	2007	Pattern Recognition	10.1016/j.patcog.2006.12.013	support vector machine;computer vision;computer science;artificial intelligence;machine learning;hidden markov model	Vision	45.41242162754304	-57.570155003744006	25231
e1c9b81ef224be844581e9fce8d00fcb4221d4e6	on 3d contour matching based on geometry features	3d contour;contour matching;contour similarity;eigenvector;geometry feature	In 3D objects recovering, geometry features of 3D contour curves were analyzed, method of 3D contour curves matching based geometry features was presented. Contour curves of 3D objects were extracted and represented by B-spline. According to geometry features of 3D contour, curvatures and torsions of point on curves were calculated after filtering and smoothing contour curves. Eigenvectors of 3D contours were constructed by curvatures and torsions. Features of corresponding points on two contour curves were compared to judge similarity of contour. Matching relation of contour was determined between tow contour curves based on similarity between two contours. Fragments mosaicing were realized for recovering broken objects based on contour curves matching. Experimental results show that that this method has high speed, accuracy and validity. © 2011 Springer-Verlag.	contour line	Caiying Luo;Shucheng Zhou	2011		10.1007/978-3-642-23220-6_79	filter (signal processing);smoothing;eigenvalues and eigenvectors;geometry;mathematics	Vision	41.86340110416838	-59.15240368472358	25242
f8a1d67bdd84a17f90df0d6e7184f3d09507ef4d	tumor ce image classification using svm-based feature selection	discrete wavelet transforms;support vector machine image classification svm feature selection gastrointestinal tumor capsule endoscopy sequential forward floating selection;support vector machines;gastrointestinal tumor capsule endoscopy;tumours;image classification;medical computing;feature extraction tumors image color analysis support vector machines accuracy endoscopes discrete wavelet transforms;accuracy;tumours endoscopes image classification medical computing support vector machines;image color analysis;feature extraction;endoscopes;tumors;capsule endoscopy;svm;feature selection;support vector machine;sequential forward floating selection	In this paper, we propose a new scheme aimed for gastrointestinal (GI) tumor capsule endoscopy (CE) images classification, which utilizes sequential forward floating selection (SFFS) together with support vector machine (SVM). To achieve this goal, candidate features related to texture characteristics of CE images are extracted. With these candidate features, SFFS based on SVM is applied to select the most discriminative features that can separate normal CE images from tumor CE images. Comprehensive experiments on our present CE image data verify that it is promising to employ the proposed scheme to recognize tumor CE images.	airport time capsule;binary pattern (image generation);computer vision;experiment;feature selection;sensitivity and specificity;support vector machine;tract (literature);wavelet	Baopu Li;Max Q.-H. Meng	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5649638	support vector machine;computer vision;computer science;engineering;machine learning;pattern recognition;feature selection	Robotics	34.58045784959472	-74.76239067624302	25265
c81ac30f7dea7a295517a9e4ba06abb244cd190a	probabilistic model for 3d interactive segmentation		"""Interactive 3D medical image segmentation based on a Bayesian inference is suggested.User-machine """"dialogue"""" is allowed by a few mouse clicks in regions of disagreement.User input is formulated as a probabilistic spatial term in a level-set functional.A generic method which accommodates different modalities, e.g. CT and multimodal MRI.GUI for clinical uses allows real-time, high performance with minimal user feedback. Display Omitted Fully-automated segmentation algorithms offer fast, objective, and reproducible results for large data collections. However, these techniques cannot handle tasks that require contextual knowledge not readily available in the images alone. Thus, the supervision of an expert is necessary.We present a generative model for image segmentation, based on a Bayesian inference. Not only does our approach support an intuitive and convenient user interaction subject to the bottom-up constraints introduced by the image intensities, it also circumvents the main limitations of a human observer-3D visualization and modality fusion. The user """"dialogue"""" with the segmentation algorithm via several mouse clicks in regions of disagreement, is formulated as a continuous probability map, that represents the user's certainty to whether the current segmentation should be modified. Considering this probability map as the voxel-vise Bernoulli priors on the image labels allows spatial encoding of the user-provided input. The method is exemplified for the segmentation of cerebral hemorrhages (CH) in human brain CT scans; ventricles in degenerative mice brain MRIs, and tumors in multi-modal human brain MRIs and is shown to outperform three interactive, state-of-the-art segmentation methods in terms of accuracy, efficiency and user-workload."""	statistical model	Tsachi Hershkovich;Tamar Shalmon;Ohad Shitrit;Nir Halay;Bjoern H. Menze;Irit Dolgopyat;Itamar Kahn;Ilan Shelef;Tammy Riklin-Raviv	2016	Computer Vision and Image Understanding	10.1016/j.cviu.2016.03.007	computer vision;computer science;artificial intelligence;machine learning;segmentation-based object categorization;image segmentation;scale-space segmentation	Vision	44.87445482773421	-78.36607352002753	25284
06c19f5ce159875900a513ec2303625248e75577	generation of realistic scene using illuminant estimation and mixed chromatic adaptation	spectre puissance;surface reflection;analisis componente principal;modele geometrique;methode moindre carre moyen;image processing;least mean squares methods;reflectivity;facteur reflexion;reflexion superficielle;procesamiento imagen;spectral power distribution;qualite image;traitement image;power distribution;power spectrum;eigenvector;distribution puissance;espectro potencia;sintesis imagen;algorithme;vector propio;image synthesis;algorithm;reflectance;imagen virtual;system synthesis;synthese systeme;principal component analysis;reflection model;image quality;reflexion superficial;image virtuelle;analyse composante principale;sintesis sistema;synthese image;calidad imagen;virtual image;reflection;vecteur propre;high light;eigenvectors;geometrical model;algoritmo;coeficiente reflexion;modelo geometrico	The algorithm of combining a real image with a virtual model was proposed to increase the reality of synthesized images. Currently, synthesizing a real image with a virtual model facilitated the surface reflection model and various geometric techniques. In the current methods, the characteristics of various illuminants in the real image are not sufficiently considered. In addition, despite the chromatic adaptation plays a vital role for accommodating different illuminants in two media viewing conditions, it is not taken into account in the existing methods. Thus, it is hardly to get high-quality synthesized images. In this paper, the authors proposed the two-phase image synthesis algorithm. First, the surface reflectance of the maximum highlight region (MHR) was estimated using the three eigenvectors obtained from the principal component analysis (PCA) applied to the surface reflectances of 1269 Munsell samples. The combined spectral value, i.e., the product of surface reflectance and the spectral power distributions (SPDs) of an illuminant, of MHR was then estimated using the three eigenvectors obtained from PCA applied to the products of reflectances of Munsell 1269 samples and the SPDs of four CIE Standard Illuminants (A, C, D65, D50, Green, and Yellow). By dividing the average combined spectral values of MHR by the average reflectances of MHR, we could estimate the illuminant of a real image. Second, the mixed chromatic adaptation (S-LMS) using an estimated and an external illuminants was applied to the virtual model image. For evaluating the proposed algorithm, experiments with synthetic and real scenes were performed. It was shown that the proposed method was effective in synthesizing the real and the virtual scenes under various illuminants.	motion estimation	Jae-Chul Kim;Sang Gi Hong;Dong-Ho Kim;Jong-Hyun Park	2004		10.1117/12.524639	computer vision;image processing;eigenvalues and eigenvectors;computer science;reflectivity;optics	Vision	51.62634199630128	-57.104800154729126	25304
3aa26c5cd2cfdb27412d54539c0415e08664973e	3d image analysis for evaluating internal deformation/fracture characteristics of materials	nanoorder 3d ct image 3d image analysis internal deformation fracture characteristic load deformation relationship;ultrasonic imaging;internal structure;3d image analysis;nanostructured materials;fracture;deformation;image analysis springs electronics packaging conducting materials materials science and technology geometry image resolution surface cracks deformable models frequency;ultrasonic imaging deformation fracture nanostructured materials	In the past, D/F characteristics, load-deformation relationships until the materials are fractured, have been analyzed on the surface. The D/F characteristics are affected by more than ten thousand micro-scale internal structures like air bubbles (pores), cracks and particles; therefore, it is required to analyze nano-scale D/F characteristics inside materials. In this paper, we propose a method that automatically obtains the corresponding relations of the particles from nano-order 3DCT images at each deformation stage. The particles are deformation-proof and may have different geometries. First of all, some big particles are considered as landmarks and matched between pre- and post-deformation. The results of landmark matching make it easy to match many remaining particles and pores.	adobe air;gnu nano;image analysis;template matching	Mitsuru Nakazawa;Yoshimitsu Aoki;Masakazu Kobayashi;Hiroyuki Toda	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761648	fracture;deformation	Vision	41.197504625224184	-69.62533148249366	25305
795636ad2280190e48d5f14133e70db54d6db96c	segmentation of images with insufficient dynamical range		In this paper a method is presented to automatically detect objects from images with insufficient contrast. Using the edge map by the Canny edge detector as a reference, the corresponding edge structures in the edge map by the zero-crossing edge detector are firstly determined. Then meaningful structures are differentiated with respect to those randomly distributed edge segments and are recovered from the zero-crossing edge map. The method is validated in a realistic vision system and compared favorably with existing methods. 1. General Instructions As a fundamental issue in computer vision and image processing, object detection aims to find semantic objects in digital images or videos. The detection can be supervised with an object model built upon a set of training data, like the Viola-Jones object detector. What is of interest here is the unsupervised object detection, which usually starts from a basic assumption: pixels associated with the same object will share similar properties (like intensity or standard deviation in a neighborhood) and pixels associated with different objects will exhibit different properties. There are two ways to apply this assumption to object detection by emphasizing the first part or the second part of the statement. An object can be detected through detecting all pixels with similar properties. In this way, object and background can be differentiated, and a partition of the image can be derived, which is named region-based image segmentation. Alternatively, one can detect the object through locating the boundaries since image properties will change at object boundary pixels. This approach is called edge detection. There have been a large number of techniques that had been proposed since 1960s to address the issue. Earlier developments treat the pixels separately, but efforts after 1980s tend to jointly consider the spatial relationship in order to yield a smooth segmentation map. For a literature review on early works, interested readers can refer to [1]. Among the recent developments, level set segmentation and graph-based segmentation are the two popular methods that have been received a number of attentions. The level set method is basically a reformulation of the active contour model [2] in the framework of level set. In spite of the increase in dimension, this formulation does not require a parameterized representation of the tracking object in the course of curve evolution. More importantly, topology change is very easy to adapt the contour towards the boundary of objects with varying shapes. These salient features make the method particularly useful in tracking interfaces and shapes [3]. Different from most active contour models that relate the object boundaries to image gradients, Chan and Vese [4] proposed a model where the stopping term is related to a particular segmentation of the image. Another advantage of this formulation is that the initial curve can be anywhere in the image. In most of traditional level set methods, it is usually require a step to periodically re-initialize the level set function to a signed distance function throughout the process of evolution in order to maintain the evolution stable. In [5], a new variational formulation was presented to force the level set function to be close to a signed distance function without the step of re-initialization. Another type of segmentation methods that has been of intensive interest in recent years is the graph-based method, in particular due to the efficient algorithm by Boykov and Kolmogorov [6] for computing the max-flow for computer vision related graph. The method takes image pixels as graph nodes and lines linking pairs of pixels as graph edges, thus the segmentation problem can be represented in terms of a graph. Wu and Leahy introduced a minimum graph cut method for image segmentation, but the method tends to bias towards finding small components. Shi and Malik [7] proposed a normalized cuts method to address this bias issue. In spite of the good performance as reported, the method yields an NP-hard computational problem and is pretty time consuming for real-time applications. A method running in ( ) m m log Ο for m graph edges was presented in [8], where the segmentation is based on pairwise region comparison with decision following the global properties of being not too coarse and not too find according to a particular region comparison function. Despite the tremendous efforts in object detection, it remains a challenging issue for reliably detecting objects under a wide range of variation in scene view, in particular for those computer vision systems running in outdoor and uncontrolled environment. A typical difficulty is the insufficient dynamical range for some observed objects, which would make the object appear with low contrast and barely visible even with human observation. The insufficient dynamical range could be due to several reasons. Very often it results from imperfect lighting condition, such as directional strong lighting, non-uniform weak lighting. Poor weather (like fog) or the medium (like turbulent water or some solvent) where the object is immersed could lead to the rapid decrease on the lighting transmission from objects to image plane on the one hand, and more importantly the effect of strong lighting interference due to particle reflection on the other hand. As a result, objects with different depth could exhibit remarkably different contrasts. For these images, normally it would require a good enhancement before proceeding to the step of object detection, which is another nontrivial issue. Here we present a simple yet MVA2011 IAPR Conference on Machine Vision Applications, June 13-15, 2011, Nara, JAPAN 4-10	active contour model;algorithm;calculus of variations;canny edge detector;computation;computational problem;digital image;dynamical system;edge detection;graph cuts in computer vision;image gradient;image plane;image processing;image segmentation;interference (communication);international association for pattern recognition;jones calculus;machine vision;maximum flow problem;np-hardness;object detection;pixel;randomness;real-time clock;segmentation-based object categorization;sensor;turbulence;uncontrolled format string;unsupervised learning;zero crossing	Zujun Hou;How-Lung Eng;Yue Wang;Ruijiang Luo	2011			computer vision;simulation;mathematics;canny edge detector;computer graphics (images)	Vision	47.63237429402433	-52.97697655484116	25325
8cbd9f2b85caa1721ea5b606911ca49f982991c0	the scene classification method based on difference vector in dct domain		Scene classification is one of the hot research topics in the field of computer vision, it is the basis of the organization and access for a variety of image database, so it has important practical significance. In our previous work, we put forward a novel fast scene classification method via DCT based on the energy concentration and multi-resolution characteristics of DCT coefficients. This paper improved our previous work proposed a scene classification method based on DCT domain using difference vectors. First of all, divided the whole image into the regular grid without repetition, in each grid, do DCT transform with the size of 8 * 8 get the DCT coefficients matrix, extract the AC coefficients in the matrix get the original vectors; Then, selected N images from each category in the database randomly, calculate the average vector of their original vectors, using the original vectors of all images corresponding category subtract the average vector get the difference vectors as the feature vectors; Finally, based on these feature vectors defined above, train classifiers with one-vs.-all support vector machine (SVM). In order to verify the robustness of the proposed algorithm, this paper has built an image database contains eight scene categories according to the OT database, this paper conducted cross validation experiment for the proposed method in the two databases. Experimental results show that the proposed method has higher accuracy and speed in image classification, and has good robustness.	algorithm;coefficient;computer vision;cross-validation (statistics);database;discrete cosine transform;jpeg;randomness;regular grid;scene graph;support vector machine;the matrix	Ce Li;Ming Li;Limei Xiao;Beijie Ren	2016		10.1007/978-3-319-42294-7_39	robustness (computer science);support vector machine;pattern recognition;cross-validation;artificial intelligence;grid;computer science;machine learning;regular grid;discrete cosine transform;feature vector;contextual image classification	Vision	36.48648880387498	-59.61195649329291	25330
a4c67f4b80d54d7a987ca7a03a7d60b2f7bef37e	visualizing shape deformations with variation of geometric spectrum	eigenvalues and eigenfunctions;measurement;manifolds;biomedical visualization;geometry;biomedical visualization geometry based technique spectral analysis;shape;geometry based technique;three dimensional displays;shape eigenvalues and eigenfunctions manifolds three dimensional displays measurement geometry iterative closest point algorithm;iterative closest point algorithm;spectral analysis	This paper presents a novel approach based on spectral geometry to quantify and visualize non-isometric deformations of 3D surfaces by mapping two manifolds. The proposed method can determine multi-scale, non-isometric deformations through the variation of Laplace-Beltrami spectrum of two shapes. Given two triangle meshes, the spectra can be varied from one to another with a scale function defined on each vertex. The variation is expressed as a linear interpolation of eigenvalues of the two shapes. In each iteration step, a quadratic programming problem is constructed, based on our derived spectrum variation theorem and smoothness energy constraint, to compute the spectrum variation. The derivation of the scale function is the solution of such a problem. Therefore, the final scale function can be solved by integral of the derivation from each step, which, in turn, quantitatively describes non-isometric deformations between two shapes. To evaluate the method, we conduct extensive experiments on synthetic and real data. We employ real epilepsy patient imaging data to quantify the shape variation between the left and right hippocampi in epileptic brains. In addition, we use longitudinal Alzheimer data to compare the shape deformation of diseased and healthy hippocampus. In order to show the accuracy and effectiveness of the proposed method, we also compare it with spatial registration-based methods, e.g., non-rigid Iterative Closest Point (ICP) and voxel-based method. These experiments demonstrate the advantages of our method.	brain;epilepsy;experiment;interpolation imputation technique;isometric projection;iteration;iterative closest point;iterative method;linear interpolation;muscle rigidity;numerous;patients;quadratic programming;synthetic data;triangle mesh;vertex;voxel	Jiaxi Hu;Hajar Hamidian;Zichun Zhong;Jing Hua	2017	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2016.2598790	mathematical optimization;combinatorics;manifold;shape;mathematics;geometry;measurement	Visualization	46.31079785402471	-77.65712981831362	25348
549ccabda72e3c0e3a0945326681116401b781ba	fast computation of geometric moments using a symmetric kernel	fast computation;algorithme rapide;cartesian coordinate;polynome zernike;metodo momento;zernike moments;zernike polynomial;image processing;moment method;analisis coordenada principal;complexite calcul;methode noyau;geometric moments with symmetric kernel sgm;invariant properties;procesamiento imagen;modele ordre reduit;separability;traitement image;temps calcul;polinomio zernike;complejidad computacion;efficient representation;separabilidad;computational complexity;methode moment;fast algorithm;modelo orden reducido;metodo nucleo;coordenadas cartesianas;zernike moment;reduced order model;kernel method;separabilite;transformation of coordinates;coordonnee cartesienne;principal coordinate analysis;tiempo computacion;computation time;analyse coordonnee principale;numerical instability;algoritmo rapido;changement coordonnee;symmetrical property;moment invariant;computation;cambio coordenadas	This paper presents a novel set of geometric moments with symmetric kernel (SGM) obtained using an appropriate transformation of image coordinates. By using this image transformation, the computational complexity of geometric moments (GM) is reduced significantly through the embedded symmetry and separability properties. In addition, it minimizes the numerical instability problem that occurs in high order GM computation. The novelty of the method proposed in this paper lies in the transformation of GM kernel from interval [0, ∞] to interval [−1, 1]. The transformed GM monomials are symmetry at the origin of principal Cartesian coordinate axes and hence possess symmetrical property. The computational complexity of SGM is reduced significantly from order O(N4) using the original form of computation to order O(N3) for the proposed symmetry-separable approach. Experimental results show that the percentage of reduction in computation time of the proposed SGM over the original GM is very significant at about 75.0% and 50.0% for square and non-square images, respectively. Furthermore, the invariant properties of translation, scaling and rotation in Hu’s moment invariants are maintained. The advantages of applying SGM over GM in Zernike moments computation in terms of efficient representation and computation have been shown through experimental results. 2008 Elsevier Ltd. All rights reserved.	cartesian closed category;computation;computational complexity theory;embedded system;holographic principle;image moment;instability;kernel (operating system);linear separability;monomial;numerical stability;second generation multiplex;time complexity	Chong-Yaw Wee;Raveendran Paramesran;Ramakrishnan Mukundan	2008	Pattern Recognition	10.1016/j.patcog.2007.12.012	cartesian coordinate system;kernel method;multidimensional scaling;image processing;computer science;machine learning;zernike polynomials;calculus;computation;mathematics;geometry;computational complexity theory;numerical stability;algorithm	Robotics	49.58147054476907	-61.131001029766935	25361
6c4351c4463b3632ee39ea645882a6a7d1b567a9	morse homology descriptor for shape characterization	level set;critical point;morse theory;computer vision;morse function;image recognition	We propose a new topological method for shape description that is suitable for any multi-dimensional data set that can be modelled as a manifold. The description is obtained for all pairs (M, f), where M is a closed smooth manifold and f a Morse function defined on M. More precisely, we characterize the topology of all pairs of lower level sets (M/sub y/, M/sub x/) of f, where M/sub a/ = f/sup -1/((-/spl infin/,a]), for all a /spl isin/ R. Classical Morse theory is used to establish a link between the topology of a pair of lower level sets of f and its critical points lying between the two levels.	homology (biology)	Madjid Allili;David Corriveau;Djemel Ziou	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1333697	computer vision;discrete mathematics;topology;discrete morse theory;morse homology;mathematics;geometry;morse theory	Vision	49.70774634885696	-63.216027179079965	25414
43a25280e1271f0b24725c37211fc14553f4709a	application of morphological segmentation to leaking defect detection in sewer pipelines	leaking;health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer vision;morphology;uk phd theses thesis;life sciences;sewer pipeline;uk research reports;medical journals;europe pmc;biomedical research;defect detection;bioinformatics	As one of major underground pipelines, sewerage is an important infrastructure in any modern city. The most common problem occurring in sewerage is leaking, whose position and failure level is typically identified through closed circuit television (CCTV) inspection in order to facilitate rehabilitation process. This paper proposes a novel method of computer vision, morphological segmentation based on edge detection (MSED), to assist inspectors in detecting pipeline defects in CCTV inspection images. In addition to MSED, other mathematical morphology-based image segmentation methods, including opening top-hat operation (OTHO) and closing bottom-hat operation (CBHO), were also applied to the defect detection in vitrified clay sewer pipelines. The CCTV inspection images of the sewer system in the 9th district, Taichung City, Taiwan were selected as the experimental materials. The segmentation results demonstrate that MSED and OTHO are useful for the detection of cracks and open joints, respectively, which are the typical leakage defects found in sewer pipelines.	acclimatization;aleurites (plant);algorithm;articular system;black hat;clay animation;closed-circuit television;closing (morphology);computer vision;conflict (psychology);correctness (computer science);edge detection;extravasation;fitness function;graphics pipeline;image segmentation;joints;manuscripts;mathematical morphology;mathematics;memory segmentation;muscle rigidity;named pipe;pipeline (computing);point cloud;research activities;segmentation action;sensor;software bug;spectral leakage;vertical talus;yang deficiency;biologic segmentation;hemoglobin f xin-su	Tung-Ching Su;Ming-Der Yang	2014		10.3390/s140508686	medical research;morphology;telecommunications;computer science;bioinformatics;engineering;electrical engineering;civil engineering;forensic engineering	Vision	43.608245265225605	-70.18790025858014	25444
96d6359813996af6864b0a296d8dde38609b88bd	computer aided detection in ct colonography, via spin images	unsupervised learning;ct colonography;computed tomographic;fiber optic;detection rate;true positive;computer aided detection;false positive;leave one out	  A technique for Computer Aided Detection (CAD) of colonic polyps, in Computed Tomographic (CT) Colonography is presented.  Following the segmentation of the colonic wall, normal wall is identified using a fast geometric scheme able to approximate  local curvature. The remaining structures are modeled using spin images and then compared to a set of existing polypoid models.  Locations with the highest probability of being colonic polyps are labeled as final candidates. Models are computed by an  unsupervised learning technique, using a leave one out technique on a study group of 50 datasets. True positive and false  positive findings were determined, employing fiber optic colonoscopy as standard of reference. The detection rate for polyps  larger than 6mm was above 85%, with an average false positive detection rate of 2.75 per case. The overall computation time  for the method is approximately 6 minutes. Initial results show that Computer Aided Detection is feasible and that our method  holds potential for screening purposes.    	ct scan;virtual colonoscopy	Gabriel Kiss;Johan Van Cleynenbreugel;Guy Marchal;Paul Suetens	2004		10.1007/978-3-540-30136-3_98	unsupervised learning;computer vision;speech recognition;type i and type ii errors;computer science;optical fiber;machine learning;computer graphics (images)	Vision	36.96207955578592	-77.39399409927822	25505
74d18c7a2b0a3e20b370dbc897529510d0d557d0	applying fuzzy clustering method to color image segmentation	macierze;image segmentation;measurement;color;algorytmy;segmentation;image color analysis;clustering algorithms;algorithms;matrix;clustering methods;segmentacja	The goal of this paper was to apply fuzzy clustering algorithm known as Fuzzy C-Means to color image segmentation, which is an important problem in pattern recognition and computer vision. For computational experiments, serial and parallel versions were implemented. Both were tested using various parameters and random number generator seeds. Various distance measures were used: Euclidean, Manhattan metrics and two versions of Gower coefficient similarity measure. The F and Q segmentation evaluation measures and output images were used to assess the result of color segmentation. Serial and parallel run times were compared.	algorithm;cluster analysis;coefficient;color image;computation;computer vision;experiment;fuzzy clustering;fuzzy cognitive map;image segmentation;input/output;kernel method;online and offline;openmp;pattern recognition;random number generation;seeds (cellular automaton);similarity measure	Omer Sakarya	2015	2015 Federated Conference on Computer Science and Information Systems (FedCSIS)	10.15439/2015F222	image texture;computer vision;fuzzy clustering;computer science;machine learning;segmentation-based object categorization;pattern recognition;mathematics;region growing;image segmentation;cluster analysis;scale-space segmentation;segmentation;matrix;measurement;statistics	Vision	42.358894984725694	-68.5012718223867	25512
73f965d9b521117d35ff3ea7e71250ac5d8388a9	dependence structure of gabor wavelets for face recognition		Up to today, face recognition is an open research subject in biometrie identification. In this paper we propose a method for face recognition based on the dependence structure of Gabor wavelet. As a useful tool, Gabor wavelets are widely used in image processing field. The strong dependencies exist in the domain of Gabor wavelets due to Gabor filters are not nonorthogonal. We have found that the dependence structure of Gabor wavelets can be used as the feature of face image, and hence it can be used to face recognition. In the proposed method, Gaussian copula is employed to describe the dependence structure of Gabor wavelets. Experiments of face recognition show the proposed method obviously improves the representation performance of Gabor wavelets, and is robust to low resolution face images.	belief propagation;database;experiment;feret (facial recognition technology);facial recognition system;gabor atom;gabor filter;gabor wavelet;illumination (image);image processing;image resolution;open research	Chaorong Li;Yuanyuan Huang	2017	2017 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2017.8280789	image processing;gabor wavelet;copula (probability theory);feature extraction;facial recognition system;mathematics;artificial intelligence;pattern recognition	Vision	33.41811673112877	-57.903689559959275	25533
59aeef054eb6657415643df4471ac01d17ba5b44	effective multiple feature fusion using topic model for social image visualization	visualization;nonhomogeneous media;vectors;feature extraction;conferences	This paper presents a multiple feature fusion method using topic model for social image visualization. Images in social media are represented from several aspects such as their visual information and tags. The proposed method extracts low-level features from social images and their tags and calculates their integrated high-level features. Specifically, the proposed method applies multilayer multimodal probabilistic Latent Semantic Analysis (mm-pLSA) to the low-level visual and tag features to obtain the high-level features. Then, by applying dimensionality reduction techniques to the obtained features, successful visualization becomes feasible.	dimensionality reduction;high- and low-level;multimodal interaction;probabilistic latent semantic analysis;social media;topic model	Kouhei Tateno;Takahiro Ogawa;Miki Haseyama	2014	2014 IEEE 3rd Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2014.7031202	computer vision;computer science;pattern recognition;data mining	Visualization	26.235975311158622	-55.3534884670368	25540
bd24edc5259ec6887302e6c10de4a6ee7e74c48e	three-dimensional motion determination from real scene images using straight line correspondences	vision ordenador;analisis escena;analyse scene;movimiento;algorithm analysis;three dimensional displacement;edge detection;sistema informatico;extraction forme;computer system;motion;deplacement tridimensionnel;three dimensional;computer vision;deteccion contorno;detection contour;extraccion forma;mouvement;desplazamiento tridimensional;vision ordinateur;analyse algorithme;systeme informatique;pattern extraction;analisis algoritmo;scene analysis	Abstract   An experiment in determining (3D) vehicle motion in an outdoor scene using line correspondences over an image sequence is presented. The motivation of this experiment is to test how well algorithms of motion estimation work on real life outdoor scenes. Using images taken by a well calibrated camera, the experiment includes straight line extraction from intensity images, straight line matching and motion estimation using line correspondences. Many corrections and adjustments are performed on the raw image data before they are used for motion estimation, which include film distortion correction, lens distortion correction and camera alignment. The results of this experiment indicate that for the type of vehicle motion under consideration, our algorithm can obtain reasonably accurate estimates for rotation. The experiment also reveals that there is a big gap between simulation tests and real scene tests for algorithms of motion estimation.		Yuncai Liu;Thomas S. Huang	1992	Pattern Recognition	10.1016/0031-3203(92)90079-X	three-dimensional space;computer vision;edge detection;computer science;motion;motion estimation;motion field;computer graphics (images)	Vision	49.66566718692407	-57.23954756084685	25554
1bddb755688511b9da66466811ea4bd6559445f6	design of statistical measures for the assessment of image segmentation schemes	benchmarking;analisis imagen;contenu image;image content;image segmentation;analisis estadistico;image processing;transition probability;analisis forma;procesamiento imagen;segmentation;probabilistic approach;traitement image;statistical analysis;realite terrain;enfoque probabilista;approche probabiliste;analyse statistique;segmentation image;probabilidad transicion;controle qualite;realidad terreno;image analysis;ground truth;pattern analysis;quality control;contenido imagen;analyse image;probabilite transition;analyse forme;control calidad	Image segmentation is discussed for years in numerous papers, but assessing its quality is mainly dealt with in recent works. Quality assessment is a primary concern for anyone working towards better segmentation tools. It both helps to objectively improve segmentation techniques and to compare performances with respect to other similar algorithms. In this paper we use a statistical framework to propose statistical measures capable to describe the performances of a segmentation scheme. All the measures rely on a ground-truth segmentation map that is supposed to be known and that serves as a reference when qualifying the results of any segmentation tool. We derive the analytical expression of several transition probabilities and show how to calculate them. An important conclusion from our study, often overlooked, is that performances can be content dependent, which means that one should adapt a measure to the content of an image.	algorithm;ground truth;heart rate variability;image segmentation;markov chain;performance;relevance	Marc Van Droogenbroeck;Olivier Barnich	2005		10.1007/11556121_35	computer vision;markov chain;quality control;image analysis;image processing;ground truth;computer science;artificial intelligence;segmentation-based object categorization;image segmentation;segmentation;benchmarking	Vision	45.09797114327862	-62.46192422415093	25618
deaab0f4378fa27634a274e9707562553d0986c9	an improved method based on cv and snake model for ultrasound image segmentation	active contour;image segmentation;regional information;edge detection;ultrasonic imaging;active contours;boundary information;cv model;computational modeling;shape;image edge detection;gvf snake ultrasound image segmentation active contour models boundary information regional information;active contour models;mathematical model;gvf snake;ultrasonic imaging edge detection image segmentation;gvf snake image segmentation active contour cv model;ultrasound image segmentation;image segmentation image edge detection active contours ultrasonic imaging mathematical model shape computational modeling	In recent years, active contour models have become one of hotspots in the field of image segmentation. However, for ultrasound images, it is difficult to achieve ideal segmentation results with those methods that only based on boundary information or regional information. In this paper, we combined GVF-Snake with CV model. First, preliminary segmentation is implemented with CV model. Then, the local information in each object area is optimized with GVF-Snake. The experimental results demonstrate the proposed method can effectively deal with image blur and edge break in ultrasound images. The resulting contours are relatively intact and close to the manual results.	image segmentation	Qianqian Li;Qingyi Liu;Lei Li;Yingxia Fu;Peirui Bai	2013		10.1109/ICIG.2013.38	computer vision;edge detection;shape;computer science;segmentation-based object categorization;pattern recognition;mathematical model;active contour model;image segmentation;scale-space segmentation;computational model;computer graphics (images)	Vision	45.09014123074904	-73.31284588437586	25657
807e5658a552404e68b9bc0591856756f60a0f5a	a multi cue discriminative approach to semantic place classification		This paper describes the participation of Idiap-MULTI to the Robot Vision Task at imageCLEF 2010. Our approach was based on a discriminative classification algorithm using multiple cues. Specifically, we used an SVM and combined up to four different histogram-based features with the kernel averaging method. We considered as output of the classifier, for each frame, the label and its associated margin, which we took as a measure of the confidence of the decision. If the margin value is below a threshold, determined via cross-validation during training, the classifier abstains from assigning a label to the incoming frame. This method was submitted to the obligatory task, obtaining a maximum score of up to 662, which ranked second in the overall competition. We then extended this algorithm for the optional task, where it is possible to exploit the temporal continuity of the sequence. We implemented a door detector so to infer when the robot has entered a new room. Then, we designed a stability estimation algorithm for determining the label of the room where the robot has entered, and we used this knowledge as a prior for the upcoming frames. Our approach obtained a score of up to 2052 in the obligatory task, ranking first.	algorithm;cross-validation (statistics);robot;scott continuity;support vector machine	Marco Fornoni;Jesus Martínez-Gómez;Barbara Caputo	2010			computer science;machine learning;pattern recognition;data mining	AI	25.43791815798016	-57.06450335730517	25662
3bad38ba8b32c248ac6519158525791d657daadc	a new method for characterization of shape	metodologia;image processing;procesamiento de imagen;convexite;processus diffusion;traitement image;methodologie;region;characterization;pattern recognition;pattern analysis;diffusion process;caracterisation;convexity;methodology;shape characterization;caracterizacion;analyse forme	Shape description is an essential component of any image-understanding system. Many approaches to description of shape have been proposed and used in the fields of image processing and computer vision. Pavlidis (1978) suggested a taxonomy of shape descriptors based on: (I) whether just the boundary, or the entire interior of the object was examined (the techniques were called external and internal, respectively); (2) whether the characterization was made on the basis of a scalar transform (in which a picture is transformed into an array of scalar features), or a space transform (a picture is transformed into another picture); and (3) whether the procedure is or is not informationpreserving in the sense that the original image can be reconstructed from the shape descriptors. Existing methods include the tu s curve, in which ~u is computed as the angle made between a fixed line and a tangent to the boundary of the region; it is plotted against s, the arc length of the boundary traversed. For a closed boundary, the function is periodic, and may be associated with segmentation of the boundary in terms of straight	computer vision;image processing;landline	O. Skliar;Murray H. Loew	1985	Pattern Recognition Letters	10.1016/0167-8655(85)90065-0	region;convexity;image processing;computer science;diffusion process;calculus;pattern recognition;methodology;mathematics;geometry	Vision	49.23871613522849	-61.521322838042536	25687
d60dabad00ab89cafb70f985e344eb0a1d42ed90	improved similarity-based online feature selection in region-based image retrieval	mutual information theory online feature selection region based image retrieval rbir high level semantic concept content based image retrieval cbir adaptive mixture model;cbir;rbir;image segmentation;supervised learning;iterative algorithms;bridges;region based image retrieval;feedback;high level semantic concept;mixture model;feature extraction;image retrieval content based retrieval;visual features;adaptive mixture model;mutual information;feature selection;image retrieval mutual information feedback image segmentation content based retrieval bridges feature extraction automation supervised learning iterative algorithms;mutual information theory;content based image retrieval;content based retrieval;online feature selection;image retrieval;automation	To bridge the gap between high level semantic concepts and low level visual features in content-based image retrieval (CBIR), online feature selection is really required. An effective similarity-based online feature selection algorithm in region-based image retrieval (RBIR) systems was proposed by W. Jiang etc., but some parts of the algorithm need to be improved. In this paper, the above algorithm is modified in two aspects: (1) Adaptive mixture models based on mutual information theory are adopted to determine the codebook size. (2) A new method is proposed, which can select not only feature axes parallel to the original ones, but also combined feature axes. Experimental results on 10000 images show that the proposed method can improve the retrieval performance, and save the computational time	codebook;computation;content-based image retrieval;feature selection;high-level programming language;information theory;mixture model;mutual information;selection algorithm;time complexity	Fei Li;Qionghai Dai;Wenli Xu	2006	2006 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2006.262508	computer vision;visual word;feature extraction;image retrieval;computer science;automation;machine learning;pattern recognition;mixture model;feedback;image segmentation;supervised learning;mutual information;feature selection;feature;information retrieval	Vision	34.49963275168174	-54.884877783075474	25690
f635349abee8bfafd5cb0d83e16be8c175d1b4c5	epithelium segmentation using deep learning in h&e-stained prostate specimens with immunohistochemistry as reference standard		Prostate cancer (PCa) is graded by pathologists by examining the architectural pattern of cancerous epithelial tissue on hematoxylin and eosin (H&E) stained slides. Given the importance of gland morphology, automatically differentiating between glandular epithelial tissue and other tissues is an important prerequisite for the development of automated methods for detecting PCa. We propose a new method, using deep learning, for automatically segmenting epithelial tissue in digitized prostatectomy slides. We employed immunohistochemistry (IHC) to render the ground truth less subjective and more precise compared to manual outlining on H&E slides, especially in areas with high-grade and poorly differentiated PCa. Our dataset consisted of 102 tissue blocks, including both low and high grade PCa. From each block a single new section was cut, stained with H&E, scanned, restained using P63 and CK8/18 to highlight the epithelial structure, and scanned again. The H&E slides were co-registered to the IHC slides. On a subset of the IHC slides we applied color deconvolution, corrected stain errors manually, and trained a U-Net to perform segmentation of epithelial structures. Whole-slide segmentation masks generated by the IHC U-Net were used to train a second U-Net on H&E. Our system makes precise cell-level segmentations and segments both intact glands as well as individual (tumor) epithelial cells. We achieved an F1-score of 0.895 on a hold-out test set and 0.827 on an external reference set from a different center. We envision this segmentation as being the first part of a fully automated prostate cancer detection and grading pipeline.		Wouter Bulten;Péter Bándi;Jeffrey Hoven;Rob van de Loo;Johannes Lotz;Nick Weiss;Jeroen van der Laak;Bram van Ginneken;Christina A. Hulsbergen van de Kaa;Geert J. S. Litjens	2018	CoRR		h&e stain;prostate;pathology;immunohistochemistry;prostate cancer;epithelium;prostatectomy;epithelial tissue;segmentation;biology	NLP	35.62876583383382	-76.838772234547	25731
0bfc4ea9c4a69b24b8acbe333bf155eeab99f8ac	supergraph models: a novel approach for structure learning, classification and recognition				Johannes Hartz	2013				Vision	28.44598567236192	-57.17774220188997	25798
69d753b799012afc9390ae2ad7dfbdd4baebaaee	fine-structured object segmentation via local and nonlocal neighborhood propagation	会议论文	In this paper, we present a novel method for the challenging task of fine-structured (FS) object segmentation. This task is formulated as a label propagation problem on an affinity graph. To enhance the completeness and connectivity of the FS objects, we introduce a novel neighborhood system combining both local and nonlocal connections, together with a robust scheme for edge weight calculation. Additionally, region cost is incorporated into the energy function to further maintain the connectivity of fine parts where the propagation is hard to reach. An appealing advantage of the proposed method is that the energy minimization has a closed-form solution and global optimum is guaranteed. Comparative experimental results on three datasets demonstrate the effectiveness of the proposed method.	energy minimization;global optimization;mathematical optimization;processor affinity;quantum nonlocality;software propagation	Yongchao Gong;Shiming Xiang;Zhiqiang Wang;Chunhong Pan	2015	2015 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2015.7351682	computer science	Robotics	47.34364660165625	-69.95469000637284	25826
5a3e3b22c30b53c03f46805b3f20980b6376a2ef	recognising planes in a single image	histograms;image recognition;image segmentation;learning planar structure single images recognition;learning;training;recognition;single images;three dimensional displays;image color analysis;planar structure;three dimensional displays histograms image recognition image segmentation image color analysis training cameras;cameras	We present a novel method to recognise planar structures in a single image and estimate their 3D orientation. This is done by exploiting the relationship between image appearance and 3D structure, using machine learning methods with supervised training data. As such, the method does not require specific features or use geometric cues, such as vanishing points. We employ general feature representations based on spatiograms of gradients and colour, coupled with relevance vector machines for classification and regression. We first show that using hand-labelled training data, we are able to classify pre-segmented regions as being planar or not, and estimate their 3D orientation. We then incorporate the method into a segmentation algorithm to detect multiple planar structures from a previously unseen image.	algorithm;autostereogram;gradient;machine learning;relevance	Osian Haines;Andrew Calway	2015	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2014.2382097	image texture;computer vision;feature detection;color image;binary image;image processing;computer science;machine learning;pattern recognition;histogram;mathematics;image segmentation;scale-space segmentation;automatic image annotation	Vision	35.7688158054528	-53.52961258184524	25851
e82aac7a4d69f8b137a6b79b9c3eef9f2e36161d	hebbr2-taffic: a novel application of neuro-fuzzy network for visual based traffic monitoring system	image processing;neuro fuzzy network;traffic flow;neuro fuzzy;image processing techniques;traffic monitoring;traffic monitoring system;rbf network	This paper presents a robust methodology that automatically counts moving vehicles along an expressway. The domain of interest for this paper is using both neuro-fuzzy network and simple image processing techniques to implement traffic flow monitoring and analysis. As this system is dedicated for outdoor applications, efficient and robust processing methods are introduced to handle both day and night analysis. In our study, a neuro-fuzzy network based on the Hebbian-Mamdani rule reduction architecture is used to classify and count the number of vehicles that passed through a three- or four-lanes expressway. As the quality of the video captured is corrupted under noisy outdoor environment, a series of preprocessing is required before the features are fed into the network. A vector of nine feature values is extracted to represent whether a vehicle is passing through a lane and this vector serves as input patterns would be used to train the neuro-fuzzy network. The vehicle counting and classification would then be performed by the well-trained network. The novel approach is benchmarked against the MLP and RBF networks. The results of using our proposed neuro-fuzzy network are very encouraging with a high degree of accuracy.	neuro-fuzzy	Siu-Yeung Cho;Hiok Chai Quek;Shao-Xiong Seah;Chin-Hui Chong	2009	Expert Syst. Appl.	10.1016/j.eswa.2008.08.043	traffic generation model;embedded system;computer vision;simulation;image processing;computer science;neuro-fuzzy;machine learning;traffic flow;network simulation;network traffic simulation	ML	28.836868559200425	-55.457359592586094	25865
e4d30b53bb4fe05261279a6439b84375bbed03b5	multiresolution map despeckling of sar images based on locally adaptive generalized gaussian pdf modeling	transformation ondelette;modelizacion;traitement signal;metodo estadistico;speckle;wavelet transforms filtering theory image denoising maximum likelihood estimation radar imaging synthetic aperture radar;restauration image;image processing;algorithms computer simulation image enhancement image interpretation computer assisted information storage and retrieval likelihood functions models statistical normal distribution numerical analysis computer assisted radar reproducibility of results sensitivity and specificity signal processing computer assisted;adaptive filtering;wavelet frame;funcion densidad probabilidad;filtrado adaptable;probability density function;ondelette;signal analysis;radar abertura sintetica;procesamiento imagen;analisis de senal;statistical method;estimation a posteriori;image restoration;wavelet decomposition;analyse multiresolution;undecimated wavelet decomposition;maximum likelihood estimation;traitement image;a posteriori estimation;local adaptation;modelisation;wavelet transforms;fonction densite probabilite;restauracion imagen;funcion logaritmica;logarithmic function;estimacion a posteriori;maximum a posteriori map estimation;methode statistique;signal processing;radar imaging;sar image;fonction logarithmique;map estimation;generalized gaussian;image resolution wavelet coefficients equations noise shaping spatial resolution signal resolution probability density function shape statistics speckle;undecimated wavelet decomposition adaptive filtering generalized gaussian gg modeling maximum a posteriori map estimation speckle synthetic aperture radar sar images;imagerie radar;filtrage adaptatif;image denoising;transformacion ondita	In this paper, a new despeckling method based on undecimated wavelet decomposition and maximum a posteriori (MAP) estimation is proposed. Such a method relies on the assumption that the probability density function (pdf) of each wavelet coefficient is generalized Gaussian (GG). The major novelty of the proposed approach is that the parameters of the GG pdf are taken to be space-varying within each wavelet frame. Thus, they may be adjusted to spatial image context, not only to scale and orientation. Since the MAP equation to be solved is a function of the parameters of the assumed pdf model, the variance and shape factor of the GG function are derived from the theoretical moments, which depend on the moments and joint moments of the observed noisy signal and on the statistics of speckle. The solution of the MAP equation yields the MAP estimate of the wavelet coefficients of the noise-free image. The restored SAR image is synthesized from such coefficients. Experimental results, carried out on both synthetic speckled images and true SAR images, demonstrate that MAP filtering can be successfully applied to SAR images represented in the shift-invariant wavelet domain, without resorting to a logarithmic transformation	assumed;coefficient;epilepsy, generalized;gadu-gadu;noise reduction;normal statistical distribution;portable document format;sample variance;shape factor (image analysis and microscopy);synthetic intelligence;wavelet transform	Fabrizio Argenti;Tiziano Bianchi;Luciano Alparone	2006	IEEE Transactions on Image Processing	10.1109/TIP.2006.881970	adaptive filter;computer vision;computer science;signal processing;pattern recognition;mathematics;statistics	Vision	53.44104532803158	-67.43222064523694	25866
04517c81870d460360b575154e04184f55889b8b	learning of structural descriptions of graphic symbols using deformable template matching	graphic symbols;structure methods;probability learning by example feature extraction image matching;structural descriptions learning;probability;features extraction;cost function;uncertainty;computer graphics;image matching;computer vision;probabilistic model;multi stage noise shaping;learning by example;shape;deformable template matching;pattern matching;feature extraction;learning from examples;graphic documents;statistical pattern recognition;pattern recognition;shape variability structural descriptions learning graphic symbols deformable template matching symbol recognition graphic documents features extraction learning from examples probabilistic model line parameters;shape pattern recognition cost function computer graphics pattern matching computer vision computer science feature extraction multi stage noise shaping uncertainty;computer science;deformable template;shape variability;line parameters;approaches to learning;symbol recognition	Accurate symbol recognition in graphic documents needs an accurate representation of the symbols to be recognized. If structural approaches are used for recognition, symbols have to be described in ternu of their shape, using structural relationships among extracted features. Unlike statistical pattern recognition, in structutul methods, slwbols are usually manually deJined from expertise knowledge, and not automatically infered from sample images. In this work we explain one approach to learn from examples a representative structural description of a symbol, thus providing better it formation about shape variabilit)! The description of U Symbol is based on a probabilistic model. It consists of a set of lines described by the mean and the variance of line parameters, respectively providing information about the model of the symbol, and its shape variabiliv. The representation of each image in the sample set as a set of lines is achieved using deformable template matching.	pattern recognition;statistical model;template matching	Ernest Valveny;Enric Martí	2001		10.1109/ICDAR.2001.953831	statistical model;computer vision;uncertainty;feature extraction;shape;computer science;machine learning;pattern matching;pattern recognition;probability;computer graphics;statistics	Vision	42.47725703306817	-53.88353853027049	25885
5180a52ababc4303a68dabd7d8bf04a6ddc1af69	an iterative thresholding algorithm for image segmentation	histograms;interpolation;aerospace engineering;probability;image segmentation;iterative algorithms;reflectivity;probability density function;real time;taylor expansion;testing;segmentation;vision adaptive computer vision machine vision real time segmentation taylor series thresholding;data mining;computer vision;object segmentation;adaptive;machine vision;pixel;image analysis;thresholding;lighting;digital image;vision;iterative algorithms image segmentation lighting histograms interpolation probability automation aerospace engineering testing image analysis;taylor series;automation	A thresholding technique is developed for segmenting digital images with bimodal reflectance distributions under nonuniform illumination. The algorithm works in a raster format, thus making it an attractive segmentation tool in situations requiring fast data throughput. The theoretical base of the algorithm is a recursive Taylor expansion of a continuously varying threshold tracking function.	algorithm;digital image;gradient;image segmentation;iterative method;raster graphics;recursion;thresholding (image processing);throughput;biologic segmentation	Arnulfo Perez;Rafael C. González	1987	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1987.4767981	computer vision;image analysis;machine vision;computer science;taylor series;machine learning;mathematics;thresholding;image segmentation;statistics;computer graphics (images)	Vision	49.3012479947201	-67.15775801702806	25934
12ef2ba0acd7f866178aeeed246687edcb0846c2	a new framework for automated segmentation of left ventricle wall from contrast enhanced cardiac magnetic resonance images	graph theory;cavity resonators;partial differential equation;contrast enhanced;optimisation;heart;shape recognition biomedical mri cardiology functions graph theory image segmentation maximum likelihood estimation medical image processing optimisation partial differential equations;in vivo ce cmr images left ventricle wall contrast enhanced cardiac magnetic resonance image automated segmentation maximum a posteriori estimation energy function graph cut based optimization algorithm first order visual appearance descriptor ce cmri 2d spatially rotation variant second order homogeneity descriptor lv inner cavity shape descriptor orthogonal wave eikonal partial differential equation speed function visual appearance model;image segmentation;cardiac magnetic resonance imaging;shape descriptor;cardiology;shape recognition;segmentation;joints;maximum likelihood estimation;left ventricle;energy function;markov gibbs random field left ventricle segmentation contrast enhanced cardiac magnetic resonance images;markov gibbs random field;visualization;image segmentation shape cavity resonators joints heart conferences visualization;shape;partial differential equations;graph cut;medical image processing;map estimation;optimal algorithm;functions;contrast enhanced cardiac magnetic resonance images;conferences;biomedical mri;random field	A novel automated framework for the segmentation of the left ventricle (LV) wall from contrast enhanced cardiac magnetic resonance images (CE-CMRI) is proposed. The framework consists of two main steps. First, the inner cavity of the LV is segmented from the surrounding tissues based on finding the Maximum A Posteriori (MAP) estimation of a new energy function using a graph-cuts-based optimization algorithm. The proposed energy function consists of three descriptors: 1st-order visual appearance descriptors of the CE-CMRI, a 2D spatially rotation-variant 2nd-order homogeneity descriptor, and a LV inner cavity shape descriptor. Second, the outer contour of the LV is segmented by generating an orthogonal wave, starting from the LV inner contour, by solving an Eikonal partial differential equation with a new speed function that combines the prior shape and current visual appearance models of the LV wall. The proposed framework was tested on in-vivo CE-CMR images and validated with manual expert delineations of left ventricle borders. Experiments and comparison results on real CE-CMR images confirm the robustness and accuracy of the proposed framework over the existing ones.	algorithm;computer model railroad interface;cut (graph theory);logical volume management;mathematical optimization;resonance;video-in video-out	Ahmed Elnakib;Garth M. Beache;Georgy L. Gimel'farb;Ayman El-Baz	2011	2011 18th IEEE International Conference on Image Processing	10.1109/ICIP.2011.6116096	computer vision;mathematical optimization;graph theory;mathematics;geometry;partial differential equation;statistics	Vision	44.28973392743104	-75.83182409072032	25955
91ecc43a01f112dd3d64df41d873af765226009e	abdominal organs segmentation based on multi-path fully convolutional network and random forests		Fully convolutional network has predicted multiple class dense outputs in CT image labels and obtained significant improvements in segmentation tasks. In this paper, we present a joint multi-path fully convolutional network (MFCN) with random forests (RF) architecture for abdominal organs segmentation automatically. First, in coarse segmentation step, three FCNs are trained respectively with three orthogonal directions which consider contextual and spatial information of fusion layers adequately. In classification step, using features extracted from different layers of network and normalizing them to mean value as supervoxel representation to train RF. This allows the computation of supervoxel at each orientation achieve high efficiency. Finally, we aggregate the results of MFCN and RF on voxel-wise and perform conditional random fields (CRF) focuses on smoothing borders of fine segmentation regions. We exceeds the state-of-the-art methods and get achievable DSC values for our work is 90.1%, 88.4%, 88.0%, 88.6% represent liver, right and left kidney, spleen respectively.		Yangzi Yang;Huiyan Jiang;Yen-Wei Chen	2018		10.1007/978-3-319-92231-7_21	smoothing;architecture;spatial analysis;segmentation;conditional random field;random forest;pattern recognition;mathematics;artificial intelligence	Vision	30.85031419145808	-75.52620494470379	25957
06695d3da2c8a4265d4933266b9da4d6ef019184	inexact graph matching for model-based recognition: evaluation and comparison of optimization algorithms	inexact graph matching;supervised classification;model based structure recognition;tree search;objective function;estimation of distribution algorithm;graph homomorphism;attributed relational graph;pattern recognition;facial features;genetic algorithm;optimal algorithm;estimation of distribution algorithms	A method for segmentation and recognition of image structures based on graph homomorphisms is presented in this paper. It is a model-based recognition method where the input image is over-segmented and the obtained regions are represented by an attributed relational graph (ARG). This graph is then matched against a model graph thus accomplishing the model-based recognition task. This type of problem calls for inexact graph matching through a homomorphism between the graphs since no bijective correspondence can be expected, because of the over-segmentation of the image with respect to the model. The search for the best homomorphism is carried out by optimizing an objective function based on similarities between object and relational attributes defined on the graphs. The following optimization procedures are compared and discussed: deterministic tree search, for which new algorithms are detailed, genetic algorithms and estimation of distribution algorithms. In order to assess the performance of these algorithms using real data, experimental results on supervised classification of facial features using face images from public databases are presented. 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	database;estimation of distribution algorithm;genetic algorithm;graph homomorphism;loss function;machine learning;matching (graph theory);mathematical optimization;optimization problem;pattern recognition;supervised learning	Roberto Marcondes Cesar Junior;Endika Bengoetxea;Isabelle Bloch;Pedro Larrañaga	2005	Pattern Recognition	10.1016/j.patcog.2005.05.007	spqr tree;combinatorics;graph bandwidth;null graph;estimation of distribution algorithm;computer science;clique-width;machine learning;pattern recognition;mathematics;graph;moral graph	Vision	42.831268938388014	-60.35296602786351	25960
6c2b392b32b2fd0fe364b20c496fcf869eac0a98	fully automatic face recognition framework based on local and global features	journal article;drntu engineering electrical and electronic engineering	Face recognition algorithms can be divided into two categories: holistic and local feature-based approaches. Holistic methods are very popular in recent years due to their good performance and high efficiency. However, they depend on careful positioning of the face images into the same canonical pose, which is not an easy task. On the contrary, some local feature-based approaches can achieve good recognition performances without additional alignment. But their computational burden is much heavier than holistic approaches. To solve these problems in holistic and local feature-based approaches, we propose a fully automatic face recognition framework based on both the local and global features. In this work, we propose to align the input face images using multi-scale local features for the holistic approach, which serves as a filter to narrow down the database for further fine matching. The computationally heavy local feature-based approach is then applied on the narrowed database. This fully automatic framework not only speeds up the local feature-based approach, but also improves the recognition accuracy comparing with the holistic and local approaches as shown in the experiments.	algorithm;align (company);computation;experiment;facial recognition system;holism;image noise;pattern recognition;performance;test set	Cong Geng;Xudong Jiang	2012	Machine Vision and Applications	10.1007/s00138-012-0423-7	computer vision;computer science;machine learning;data mining	Vision	40.03790751375672	-55.497370574929555	25969
567e5ab9d0eea2331614b5b191785ea0aaf836f1	numerical inversion of srnf maps for elastic shape analysis of genus-zero surfaces		"""Recent developments in elastic shape analysis (ESA) are motivated by the fact that it provides a comprehensive framework for simultaneous registration, deformation, and comparison of shapes. These methods achieve computational efficiency using certain square-root representations that transform invariant elastic metrics into euclidean metrics, allowing for the application of standard algorithms and statistical tools. For analyzing shapes of embeddings of <inline-formula><tex-math notation=""""LaTeX"""">$\mathbf {S}^2$</tex-math><alternatives> <inline-graphic xlink:href=""""laga-ieq1-2647596.gif""""/></alternatives></inline-formula> in <inline-formula> <tex-math notation=""""LaTeX"""">$\mathbb {R}^3$</tex-math><alternatives><inline-graphic xlink:href=""""laga-ieq2-2647596.gif""""/> </alternatives></inline-formula>, Jermyn et al. <xref ref-type=""""bibr"""" rid=""""ref1"""">[1]</xref> introduced square-root normal fields (SRNFs), which transform an elastic metric, with desirable invariant properties, into the <inline-formula><tex-math notation=""""LaTeX"""">$\mathbb {L}^2$</tex-math><alternatives> <inline-graphic xlink:href=""""laga-ieq3-2647596.gif""""/></alternatives></inline-formula> metric. These SRNFs are essentially surface normals scaled by square-roots of infinitesimal area elements. A critical need in shape analysis is a method for inverting solutions (deformations, averages, modes of variations, etc.) computed in SRNF space, back to the original surface space for visualizations and inferences. Due to the lack of theory for understanding SRNF maps and their inverses, we take a numerical approach, and derive an efficient multiresolution algorithm, based on solving an optimization problem in the surface space, that estimates surfaces corresponding to given SRNFs. This solution is found to be effective even for complex shapes that undergo significant deformations including bending and stretching, e.g., human bodies and animals. We use this inversion for computing elastic shape deformations, transferring deformations, summarizing shapes, and for finding modes of variability in a given collection, while simultaneously registering the surfaces. We demonstrate the proposed algorithms using a statistical analysis of human body shapes, classification of generic surfaces, and analysis of brain structures."""	algorithmic efficiency;attention deficit hyperactivity disorder;code for the japanese graphic character set for information interchange (jis x 0208-1990),;computation (action);cross-reference;decompression sickness;esa;estimated;generic drugs;genus;human body;map;mathematical optimization;musculoskeletal diseases;normal (geometry);numerical analysis;numerical method;optimization problem;plant roots;reference lab test reference range:finding:time reported elsewhere:reference lab test:nominal;sampling (signal processing);sampling - surgical action;shape analysis (digital geometry);solutions;spatial variability;statistical shape analysis;xlink;algorithm;registration - actclass	Hamid Laga;Qian Xie;Ian H. Jermyn;Anuj Srivastava	2017	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2016.2647596	mathematical optimization;topology;shape analysis;mathematics;geometry	Vision	48.23002258344841	-78.61999362684995	25979
01411bdba4bb0e83359789a9e64301638a10b365	graph-based multiplayer detection and tracking in broadcast soccer videos	directed graphs;dynamic programming;programacion dinamica;nonplayer regions;pistage;multimedia;digraph;edge links;image processing;illumination;video signal processing;tv broadcasting;soccer;deporte;luminance;rastreo;procesamiento imagen;digrafo;gunshot detection systems;dynamic program;graph based multiplayer tracking;layout;international soccer matches;soccer analysis;traitement image;player detection;graph based multiplayer detection;graphe pondere;trajectory;grafo pondero;football;directed graph;image sequence;multimedia communication;graphe oriente;poursuite cible;directed weighted graph;target tracking cameras layout tv broadcasting video recording gunshot detection systems face detection dynamic programming multimedia communication lighting;edge graph;video recording;programmation dynamique;arete graphe;grafo orientado;secuencia imagen;lighting;weighted graph;sport;target tracking;face detection;video signal processing directed graphs dynamic programming object detection sport tracking;region growing;broadcast soccer videos;eclairement;international soccer matches graph based multiplayer detection graph based multiplayer tracking broadcast soccer videos nonplayer regions region growing algorithm directed weighted graph edge links dynamic programming;region growing algorithm;cameras;tracking;arista grafico;sequence image;object detection;trajectory dynamic programming player detection soccer analysis tracking;alumbrado;futbol;digraphe;luminancia	In this paper, we propose a graph-based approach for detecting and tracking multiple players in broadcast soccer videos. In the first stage, the position of the players in each frame is determined by removing the non player regions. The remaining pixels are then grouped using a region growing algorithm to identify probable player candidates. A directed weighted graph is constructed, where probable player candidates correspond to the nodes of the graph while each edge links candidates in a frame with the candidates in next two consecutive frames. Finally, dynamic programming is applied to find the trajectory of each player. Experiments with several sequences from broadcasted videos of international soccer matches indicate that the proposed approach is able to track the players reasonably well even under varied illumination and ground conditions.	algorithm;backtracking;dynamic programming;heuristic (computer science);pixel;region growing;sensor;video content analysis	V. Pallavi;Jayanta Mukherjee;Arun K. Majumdar;Shamik Sural	2008	IEEE Transactions on Multimedia	10.1109/TMM.2008.922869	computer vision;simulation;directed graph;image processing;computer science;multimedia	Vision	40.179538451387444	-52.33571553633066	25995
be6879866794152e67c16c362d1fcc2299e57875	csdd features: center-surround distribution distance for feature extraction and matching	light dark;image matching;proof of concept;scale space;feature extraction;image registration;call center	Motivation A new interest region operator and feature descriptor called Center-Surround Distribution Distance (CSDD) is based on comparing feature distributions between a central foreground region and a surrounding ring of background pixels. In addition to finding light(dark) blobs surrounded by a dark(light) background, CSDD also detects blobs with arbitrary color distribution that “stand out” perceptually because they look different from the background. CSDD detection repeatability is evaluated and compared with other state-of-the-art approaches using a standard dataset, while use of CSDD features for image registration is demonstrated using a RANSAC procedure for affine image matching. We compared repeatability scores between the circular cCSDD detector, an elliptical eCSDD detector, and five other state-ofthe-art detectors (Harrisand Hessian-affine, MSER, edge-based (EBR), and intensity extrema-based (IBR)) for the eight image sequences from the standard affine covariant region detector evaluation dataset, available at http://www.robots.ox.ac.uk/~vgg/research/affine/	extended boot record;feature extraction;hessian affine region detector;image registration;image-based modeling and rendering;maximally stable extremal regions;pixel;random sample consensus;repeatability;sensor;visual descriptor	Robert T. Collins;Weina Ge	2008		10.1007/978-3-540-88690-7_11	computer vision;scale space;topology;feature extraction;computer science;image registration;pattern recognition;mathematics;proof of concept	Vision	40.71957368663001	-55.40245748663863	26068
58de0cbbfd960f7cfa1b2da937635640c2595886	implementation and performance evaluation of a progressive image retrieval system	quantization;image storage;base donnee;cuantificacion;performance evaluation;image databank;teneur;information retrieval;ondelette;interrogation base donnee;database;interrogacion base datos;base dato;image;quantification;aproximacion sucesiva;indexing;imagen;recherche information;content;banco imagen;indexation;successive approximation;compresion;banque image;indizacion;recuperacion informacion;compression;wavelets;database query;proporcion;approximation successive;wavelet;spatial information;image retrieval	An integrated wavelet-based image storage and indexing system is proposed in this research. Indexing features of consideration contains the texture, color and spatial information of images. These features can be naturally extracted during the successive approximation quantization (SAQ) stage of the wavelet compression process. Extensive experimental results are performed to demonstrate the retrieval performance of the new approach.© (1997) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Kai-Chieh Liang;C.-C. Jay Kuo	1997		10.1117/12.298465	wavelet;computer vision;image retrieval;computer science;data mining;information retrieval	Vision	42.95145291874239	-61.57406203037573	26069
61538004993895979d170e64a2a8e5f6a6e53c32	practical approach to the stereo matching of urban imagery	discontinuity;zona urbana;discontinuite;urban imagery;ombre;occlusion;solucion;shadows;solution;zone urbaine;algorithme;algorithm;sombra;stereo matching;shadow;urban area;correspondance stereo;discontinuidad;occlusions;algoritmo	Abstract   The problems encountered when stereo matching urban imagery, and other forms of imagery in which disparity discontinuities, shadows and occlusions occur, is discussed. The unsuitability of existing stereo matchers for this task is described in the light of recent work within UCL-PS, and a number of possible solutions are outlined.	computer stereo vision	Mark A. O'Neill;Mia Denos	1992	Image Vision Comput.	10.1016/0262-8856(92)90003-L	computer vision;shadow;computer science	Vision	49.16696429359126	-57.62272677793069	26122
8a7225176c0158063beddb4ee73a19da43fb3f49	isles (siss) challenge 2015: segmentation of stroke lesions using spatial normalization, random forest classification and contextual clustering		Automated methods for segmentation of ischemic stroke lesions could significantly reduce the workload of radiologists and speed up the beginning of patient treatment. In this paper, we present a method for subacute ischemic stroke lesion segmentation from multispectral magnetic resonance images (MRI). The method involves classification of voxels with a Random Forest algorithm and subsequent classification refinement with contextual clustering. In addition, we utilize the training data to build statistical group-specific templates and use them for calculation of individual voxel-wise differences from the global mean. Our method achieved a Dice coefficient of 0.61 for the leave-one-out cross-validated training data and 0.47 for the testing data of the ISLES challenge 2015.	random forest	Hanna-Leena Halme;Antti Korvenoja;Eero Salli	2015		10.1007/978-3-319-30858-6_18	machine learning;pattern recognition;data mining	Vision	32.007742071642916	-78.02428364513912	26136
ad046509fe4fd463c1017b2afdcb0802558812c0	robust image segmentation using resampling and shape constraints	image sampling;bayes estimation;modelizacion;image resampling;robust parameter estimation;integrated approach;sensitivity and specificity;bayesian statistics robust image segmentation shape constraints generative clustering model coarse shape information robust parameter estimation image resampling ambiguous color groupings texture features semantic likelihood map;texture;object recognition;analyse amas;shape constraints;sample size;semantic likelihood map;raisonnement base sur cas;razonamiento fundado sobre caso;image segmentation;analisis estadistico;image processing;bayesian statistics;grouping;cost function;learning;image databank;morfoscopia;bayes methods;analisis forma;coarse shape information;level set;shape analysis;procesamiento imagen;image segmentation bayes methods image colour analysis image sampling;semantics;bayesian methods;intelligence artificielle;robustness image segmentation shape humans pixel bayesian methods layout object recognition level set data mining;segmentation;layout;probabilistic approach;forma geometrica;texture features;data mining;semantica;semantique;classification;traitement image;robust image segmentation;identificacion sistema;signal processing computer assisted;modelisation;estimacion bayes;image enhancement;computational modeling;cluster analysis;shape;statistical analysis;analisis morfologico;image interpretation computer assisted;system identification;analyse tâche;mixture model;image colour analysis;enfoque probabilista;approche probabiliste;morphoscopie;task analysis;banco imagen;pixel;geometrical shape;banque image;analyse statistique;segmentation image;textura;inferencia;morphological analysis;reproducibility of results;estimacion parametro;mathematical model;analyse morphologique;models statistical;generalization segmentation mixture models shape analysis learning resampling;artificial intelligence;algorithms;robustness;analisis cluster;pattern recognition automated;teoria mezcla;forme geometrique;pattern analysis	Automated segmentation of images has been considered an important intermediate processing task to extract semantic meaning from pixels. We propose an integrated approach for image segmentation based on a generative clustering model combined with coarse shape information and robust parameter estimation. The sensitivity of segmentation solutions to image variations is measured by image resampling. Shape information is included in the inference process to guide ambiguous groupings of color and texture features. Shape and similarity-based grouping information is combined into a semantic likelihood map in the framework of Bayesian statistics. Experimental evidence shows that semantically meaningful segments are inferred even when image data alone gives rise to ambiguous segmentations.	bottom-up parsing;chamfer;cluster analysis;clutter;estimated;estimation theory;generalization (psychology);image scaling;image segmentation;inference;mixture model;pixel;population parameter;programme delivery control;resampling (statistics);solutions;testbed;top-down and bottom-up design;biologic segmentation;statistical cluster	Thomas Zöller;Joachim M. Buhmann	2007	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2007.1150	image texture;computer vision;range segmentation;image processing;computer science;machine learning;segmentation-based object categorization;pattern recognition;mixture model;mathematics;semantics;image segmentation;scale-space segmentation;statistics	Vision	49.41743919977943	-69.57571797272965	26186
2e3f26cded06d372c96d9a09aa384e94213bf334	novel fourier descriptor based on complex coordinates shape signature	scale normalization content based image retrieval fourier descriptors shape signature complex coordinates;retrieval performance complex coordinate shape signature content based image retrieval shape based image retrieval problems shape scale normalization fourier descriptor based methods;shape harmonic analysis image retrieval pattern recognition mpeg 7 standard frequency measurement;shape recognition content based retrieval fourier transforms image colour analysis image retrieval image texture	Shape, color and texture are the most important discriminative elements for content based image retrieval. Fourier descriptors are widely used in shape based image retrieval problems. This paper presents a novel method of extracting Fourier descriptors from the simplest shape signature - complex coordinates. Instead of the commonly used scale normalization with the magnitude of the first harmonic, normalization with the sum of magnitudes of all harmonics is used. This leads to an improved shape scale normalization. All the experimental results indicate that the proposed method outperforms many other state-of-the-art Fourier descriptors based methods, both in terms of retrieval performance and computational time.	computation;content-based image retrieval;database normalization;fast fourier transform;neural correlates of consciousness;time complexity	Emir Sokic;Samim Konjicija	2014	2014 12th International Workshop on Content-Based Multimedia Indexing (CBMI)	10.1109/CBMI.2014.6849843	image texture;computer vision;visual word;heat kernel signature;pattern recognition;information retrieval	Vision	39.64882575997321	-58.71334532353083	26196
daff7301ffc545a8756d4ea79f320c4816ae43e1	automatic 3d seed location and orientation detection in ct image for prostate brachytherapy	manual image segmentation;computerised tomography;modified k-means method;3d orientation estimation;automatic image processing;brachytherapy;image segmentation;prostate brachytherapy;automatic 3d seed location;seed orientation detection;object detection;pca;prostate seeds;principal components analysis;principal component analysis;phantoms;ct image;phantom	In prostate brachytherapy, the analysis of the 3D pose information of each individual implanted seed is one of the critical issues for dose calculation and procedure quality assessment. This paper addresses the development of an automatic image processing solution for the separation, localization and 3D orientation estimation of prostate seeds. This solution combines an initial detection of a set of seed candidates in CT images (using a thresholding and connected component method) with an orientation estimation using principal components analysis (PCA). The main originality of the work is the ability to classify the detected objects based on a priori intensity and volume information and to separate groups of seeds using a modified k-means method. Experiments were carried out on CT images of a phantom and a patient aiming to compare the proposed solution with manual segmentation or other previous work in terms of detection performance and calculation time.	ct scan;connected component (graph theory);image processing;imaging phantom;k-means clustering;principal component analysis;seed;thresholding (image processing)	Huu-Giao Nguyen;Céline Fouard;Francois Meneu;Jean-Yves Giraud;Jocelyne Troccaz	2014	2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2014.6868120	radiology;nuclear medicine;medical physics	Vision	39.306444783600526	-78.08942875377453	26336
6f822a234800bb3841851804e4b32e5209350b45	unsupervised surface defect detection using deep autoencoders and data augmentation		Surface level defect detection, such as detecting missing components, misalignments and physical damages, is an important step in any manufacturing process. In this paper, similarity matching techniques for manufacturing defect detection are discussed. We are proposing an algorithm which detects surface level defects without relying on the availability of defect samples for training. Furthermore, we are also proposing a method which works when only one or a few reference images are available. It implements a deep autoencoder network and trains input reference image(s) along with various copies automatically generated by data augmentation. The trained network is then able to generate a descriptor—a unique signature of the reference image. After training, a test image of the same product is sent to the trained network to generate a test image descriptor. By matching the reference and test descriptors, a similarity score is generated which indicates if a defect is found. Our experiments show that this approach is more generic than traditional hand-engineered feature extraction methods and it can be applied to detect multiple type of defects.		Abdul Mujeeb;Wenting Dai;Marius Erdt;Alexei Sourin	2018	2018 International Conference on Cyberworlds (CW)	10.1109/CW.2018.00076	computer vision;autoencoder;deep learning;feature extraction;unsupervised learning;computer science;standard test image;artificial intelligence	SE	28.334993181265467	-55.310336798057605	26385
731a2d303d650acdbab346d1ec671ad74ecd7d11	beard tolerant face recognition based on 3d geometry and color texture	face recognition		facial recognition system	Andrea F. Abate;Stefano Ricciardi;Gabriele Sabatino;Maurizio Tucci	2005			computer science;facial recognition system;three-dimensional face recognition;artificial intelligence;computer vision	Vision	30.747610927784216	-57.626096766588454	26416
4e46100c5eae681e2e382afc5e42a56d72ea58c0	plausible 3d colour surface completion using non-parametric techniques	surface structure;concepcion asistida;computer aided design;range data;geometrie algorithmique;surface parametrique;texture synthesis;estructura superficie;superficie parametrica;computational geometry;pattern synthesis;synthese forme;conception assistee;completitud;structure surface;geometria computacional;completeness;parametric surface;completude;sintesis forma	We consider the combined completion of 3D surface relief and colour for the hidden and missing portions of objects captured with 2 1 2 D (or 3D) capture techniques. Through an extension of nonparametric texture synthesis to facilitate the completion of localised 3D surface structure (relief) over an underlying geometric surface completion we achieve realistic, plausible completion and extension of 2 1 2 D partially visible surfaces. Additionally we show how this technique can be extended to the completion of increasingly available colour 2 1 2 D / 3D range data.	texture synthesis	Toby P. Breckon;Robert B. Fisher	2005		10.1007/11537908_7	computational geometry;completeness;parametric surface;mathematics;geometry;transformational grammar;texture synthesis;algorithm	Vision	51.50233291277998	-57.40271072432555	26417
39555f29b8e7be41bfe1c18a572f53eb03dd1072	resampling for face detection by self-adaptive genetic algorithm	cmu frontal face test;data collection;face detection;basic idea;adaboost-based face detector;face database;expanded database;self-adaptive genetic algorithm;state-of-the-art statistical method;existing face;computer vision;image classification;genetic algorithms;face recognition;sampling methods;statistical analysis	Over the past ten years, face detection has been thoroughly studied in computer vision research for its interesting applications. However, all of the state-of-the-art statistical methods suffer from the data collection for training a classifier. This paper presents a self-adaptive genetic algorithm (GA)-based method to swell face database through re-sampling from the existing faces. The basic idea is that a face is composed of a limited components set, and the GA can simulate the procedure of heredity. This simulation can also cover the variations of faces in different lighting conditions, poses, accessories, and quality conditions. To verify the generalization capability of the proposed method, we also use the expanded database to train an Adaboost-based face detector and test it on the MIT+CMU frontal face test set. The experimental results show that the data collection can be efficiently speeded up by the proposed methods.	adaboost;computer vision;crossover (genetic algorithm);face detection;genetic algorithm;mutation (genetic algorithm);performance;sampling (signal processing);simulation;software release life cycle;statistical classification;test set	Jie Chen;Xilin Chen;Wen Gao	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1334655	facial recognition system;sampling;computer vision;contextual image classification;face detection;genetic algorithm;computer science;machine learning;pattern recognition;statistics;data collection	Vision	26.14448496006973	-58.68911479162031	26458
a81bb4d4176a86ed0c91f32e74dd1bba793440ec	polynomial self-similarity for object classification	polynomials prototypes lighting correlation standards support vector machines shape;image matching;image classification;polynomials;nonuniform illumination conditions polynomial self similarity approach object classification internal self similarity recurring pattern global self similarity framework detail matching ambient illumination;polynomials image classification image matching;self similarity object classification ssd fft	Objects in an image may be semantically similar not because they share common photometric properties, but because they share common recurring patterns of internal self-similarities. In this paper, a polynomial self-similarity approach for object classification is proposed. Extending the global self-similarity framework, polynomial self-similarity enables greater flexibility in matching details with similar structure but intensity differences, and details under different ambient illumination. Experiments show that the proposed approach provides classification accuracy that is competitive with standard global self-similarity, even under challenging non-uniform illumination conditions.	ambient occlusion;polynomial;self-similarity	Frederick Tung;Alexander Wong	2013	2013 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)	10.1109/ICMEW.2013.6618291	computer vision;contextual image classification;discrete mathematics;computer science;pattern recognition;mathematics;polynomial	Vision	37.88998450084682	-57.853756323751156	26481
d357c3deb4899a0479778bc9087d5b064a32421a	automated detection of solar loops by the oriented connectivity method	segment solar coronal loop;automated detection;solar magnetic field;solar loops;automated technique;physical characteristic;magnetic field;noisy image;real coronal image;robust extraction;constructive curve detection approach;intensity image;oriented connectivity method;feature extraction;image segmentation;sun;automatic control;solar corona;coronal loops;algorithms	An automated technique to segment solar coronal loops from intensity images of the sun's corona is introduced. It exploits physical characteristics of the solar magnetic field to enable robust extraction from noisy images. The technique is a constructive curve detection approach, constrained by collections of estimates of the magnetic field's orientation. Its effectiveness is evaluated through experiments on synthetic and real coronal images.	cycle detection;edge detection;experiment;image processing;sensor;synthetic intelligence	Jong Kwan Lee;Timothy S. Newman;G. Allen Gary	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1333766	computer vision;coronal loop;corona;feature extraction;computer science;machine learning;automatic control;image segmentation	Robotics	48.01071437611956	-67.94757088581504	26510
9b8239a224faddf996b679dbc6ad251ed7744fca	using geometric processing in the visualization of ring features in tomographic images of wood	extracted curve;morphological distance transform;wood;fourier texture analyser;fft geometric processing ring feature visualization tomographic images wood texture based ring tracing algorithm region of interest growth ring geometry interactive visualization 3d log data fourier texture analyser vector field extracted curve morphological distance transform standard volume renderer wood defects identification noise immunity nonring features discrimination edge detection methods;image segmentation;computed tomography;edge detection;volume rendering;information technology;interactive visualization;filters;fft;data mining;glass;information geometry;image texture;wood defects identification;data visualisation;tomographic images;noise immunity;standard volume renderer;image edge detection;texture based ring tracing algorithm;feature extraction;region of interest;growth ring geometry;nonring features discrimination;ring feature visualization;data visualization;image edge detection data visualization filters data mining glass computed tomography information technology australia information geometry image analysis;computerised tomography;edge detection methods;wood processing;fast fourier transforms;image analysis;geometric processing;distance transform;vector field;3d log data;fast fourier transforms wood processing computerised tomography image segmentation data visualisation image texture feature extraction edge detection;australia	We have developed a texture-based ring tracing algorithm to allow region-of-interest to be selected in terms of growth ring geometry during interactive visualization of 3D log data, as opposed to traditional way of selecting by voxel values alone. To pick out a single ring structure, we use a Fourier texture analyser to convert an image into a vector field so that a curve can be traced from any starting point easily. The extracted curve is thickened with the morphological distance transform. The thickened curve is used as a mask to filter the log data spatially and the result sent to a standard volume renderer to visualize. This allows a small region around a growth ring to be visualized, which is crucial to identifying certain defects in wood. The texture-based approach is more immune to noise, is better at discriminating non-ring features, and is more suitable for single curve tracing than traditional edge detection methods.	algorithm;distance transform;edge detection;interactive visualization;tomography;volume rendering;voxel	Kenneth K. Tsui	1996		10.1109/ICIP.1996.560553	computer vision;fast fourier transform;computer science;theoretical computer science;mathematics;data visualization;computer graphics (images)	Visualization	43.00759361154098	-69.96583328316504	26514
add67b398b06306e2e24de3883b39d9eb1187e28	deep fusion pipeline for mild cognitive impairment diagnosis		Deep learning has allowed scientists to make significant improvements in tasks that were once considered difficult in disparate domains. Medical imaging is one of those domains where traditional analysis entailed multiple preprocessing steps and feature extraction or handcrafting of individual features for specific applications. Deep learning allows one to simplify this analysis pipeline into an end-to-end framework as it can handle the feature extraction phase without having to handcraft features. We leverage this characteristic of deep learning and present an architecture where multiple information modalities of different complexities can be fused together seamlessly and co-optimized to create a robust classifier. The performance of this fusion pipeline is demonstrated on Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset where discrimination between Alzheimer's Disease, Mild Cognitive Impairment and cognitively normal individuals using 3D magnetic resonance imaging and neuropsychological measures is presented.	alzheimer's disease neuroimaging initiative;deep learning;end-to-end principle;feature extraction;medical imaging;preprocessor;resonance;statistical classification	Upul Senanayake;Arcot Sowmya;Laughlin Dawes	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363832	artificial intelligence;convolutional neural network;pattern recognition;feature extraction;architecture;computer science;deep learning;fusion;cognition;neuropsychology;medical imaging	Vision	30.4066971498813	-75.98422998214214	26529
158ed17f934e4ea7aa974d8e412c7aa56e58df61	two-channel spatial interpolation of images	two channel interpolation;conversion image;interpolation;high resolution;image processing;image formation;high pass filter;interpolacion;simulation;image interpolation;procesamiento imagen;image conversion;simulacion;image format conversion;filtro multicanal;traitement image;algorithme;algorithm;haute resolution;filtre multicanal;multichannel filter;alta resolucion;conversion imagen;spatial interpolation;algoritmo	"""Proposed is a new method for the spatial image interpolation. The proposed method interpolates the lowand high-pass """"ltered images in separate channels so that it can not only recreate the stationary region naturally but also preserve the edges clearly. It can be used for the image format conversion. ( 2000 Elsevier Science B.V. All rights reserved."""	image file formats;multivariate interpolation;stationary process	Dong Wook Kang	2000	Sig. Proc.: Image Comm.	10.1016/S0923-5965(00)00004-7	computer vision;mathematical optimization;image processing;interpolation;computer science;stairstep interpolation;mathematics;nearest-neighbor interpolation;computer graphics (images)	Vision	52.36682411225914	-62.13541905524155	26537
8e7df5e64ee2cfd634415772284fedd7678c2f1e	2d human tracking by efficient model fitting using a path relinking particle filter	motion analysis;filtre particule;estimation mouvement;path relinking particle filter;algorithm performance;legged locomotion;estimacion movimiento;locomotion avec jambes;analyse mouvement;motion estimation;cuerpo humano;corps humain;analyse visuelle;human tracking;human body model;resultado algoritmo;modelo 2 dimensiones;particle filter;path relinking;human motion;human body;performance algorithme;modele 2 dimensions;adaptive computing;weight function;model fitting;analisis movimiento;two dimensional model;pose estimation	INTRODUCTION: Automatic visual analysis of human motion is an active research topic in Computer Vision and its interest has been growing in the last decade. Visual analysis of human movement is used in the fields of Medical, Occupational and Sports Biomechanics. The main purpose of this staudy is to present a 2D model-based Path Relinking Particle Filter (PRPF) algorithm for human motion tracking and analysis applications.	algorithm;computer vision;curve fitting;kinesiology;particle filter	Juan José Pantrigo;Ángel Sánchez;Kostas Gianikellis;Antonio S. Montemayor	2004		10.1007/978-3-540-30074-8_20	computer vision;human body;simulation;weight function;pose;particle filter;computer science;artificial intelligence;motion estimation;statistics	Vision	49.22619228499846	-55.87978916800688	26545
26a02d4dc3ad3263a3f1b9284468f473011a4339	4d hyperspherical harmonic (hyperspharm) representation of surface anatomy: a holistic treatment of multiple disconnected anatomical structures	hyperspherical harmonics;shape analysis;classification;endnotes;pubications;hippocampus amygdala;spharm	Image-based parcellation of the brain often leads to multiple disconnected anatomical structures, which pose significant challenges for analyses of morphological shapes. Existing shape models, such as the widely used spherical harmonic (SPHARM) representation, assume topological invariance, so are unable to simultaneously parameterize multiple disjoint structures. In such a situation, SPHARM has to be applied separately to each individual structure. We present a novel surface parameterization technique using 4D hyperspherical harmonics in representing multiple disjoint objects as a single analytic function, terming it HyperSPHARM. The underlying idea behind HyperSPHARM is to stereographically project an entire collection of disjoint 3D objects onto the 4D hypersphere and subsequently simultaneously parameterize them with the 4D hyperspherical harmonics. Hence, HyperSPHARM allows for a holistic treatment of multiple disjoint objects, unlike SPHARM. In an imaging dataset of healthy adult human brains, we apply HyperSPHARM to the hippocampi and amygdalae. The HyperSPHARM representations are employed as a data smoothing technique, while the HyperSPHARM coefficients are utilized in a support vector machine setting for object classification. HyperSPHARM yields nearly identical results as SPHARM, as will be shown in the paper. Its key advantage over SPHARM lies computationally; HyperSPHARM possess greater computational efficiency than SPHARM because it can parameterize multiple disjoint structures using much fewer basis functions and stereographic projection obviates SPHARM's burdensome surface flattening. In addition, HyperSPHARM can handle any type of topology, unlike SPHARM, whose analysis is confined to topologically invariant structures.	affine shape adaptation;align (company);anatomic structures;anatomy, regional;basis function;brain;cancer grant supplements (p30);classification;clinical use template;coefficient;geo warping;grey goo;holism;hypomagnesemia 1, intestinal;image registration;inference;physical object;population;program research project grants;quantum harmonic oscillator;silo (dataset);smoothing (statistical technique);sparse matrix;spherical power:invlen:pt:eye.left:qn;stereoscopy;support vector machine;vertex;voxel;wavelet;registration - actclass;research grants	Ameer Pasha Hosseinbor;Moo K. Chung;Cheng Guan Koay;Stacey M. Schaefer;Carien M. van Reekum;Lara Peschke-Schmitz;Mattew J. Sutterer;Andrew L. Alexander;Richard J. Davidson	2015	Medical image analysis	10.1016/j.media.2015.02.004	computer vision;mathematical optimization;combinatorics;biological classification;computer science;machine learning;shape analysis;mathematics;geometry;algorithm	ML	47.129806790224926	-77.38547749737928	26668
09ec2d5cba5b15894b1fea71489c5204a338fd95	multiple class segmentation using a unified framework over mean-shift patches	biological patents;object based segmentation;biomedical journals;image segmentation;text mining;europe pubmed central;citation search;mean shift;citation networks;fourier descriptors;research articles;abstracts;open access;model integration;life sciences;multiple class segmentation;clinical guidelines;fourier analysis;elliptical fourier descriptor;elliptical fourier descriptor multiple class segmentation object based segmentation mean shift patches;spatial relationships;full text;mean shift patches;rest apis;orcids;europe pmc;object detection;biomedical research;image segmentation shape biomedical imaging testing object recognition bayesian methods histograms biomedical informatics cancer clustering algorithms;object detection fourier analysis image segmentation;bioinformatics;literature search	Object-based segmentation is a challenging topic. Most of the previous algorithms focused on segmenting a single or a small set of objects. In this paper, the multiple class object-based segmentation is achieved using the appearance and bag of keypoints models integrated over mean-shift patches. We also propose a novel affine invariant descriptor to model the spatial relationship of keypoints and apply the elliptical Fourier descriptor to describe the global shapes. The algorithm is computationally efficient and has been tested for three real datasets using less training samples. Our algorithm provides better results than other studies reported in the literature.	algorithm;algorithmic efficiency;bottom-up parsing;class;gain;image histogram;instance (computer science);mean shift;object-based language;physical object;segmentation action;solid-state drive;time complexity;benefit;biologic segmentation	Lin Yang;Peter Meer;David J. Foran	2007	2007 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2007.383229	spatial relation;computer vision;text mining;mean-shift;computer science;machine learning;pattern recognition;data mining;image segmentation;fourier analysis;scale-space segmentation	Vision	41.44676342587077	-74.64042629329256	26677
c125a0c5d101cf5b3fcf770198a9de6709beccde	image retrieval by pattern categorization using wavelet domain perceptual features with lvq neural network	supervised learning;directionality;retrieval;regularity;local binary pattern;symmetry;feature vector;wavelet transform;lvq network;design pattern;cost effectiveness;vector quantizer;textile industry;neural network;image retrieval	For the efficient and cost effective management of large volume of images in textile industry, an effective retrieval system is expected. Textile (e.g., curtain) images of raw clothes have wide varieties of design patterns. Despite many research works in this area, only a few emphasize on complex pattern characteristics. Such patterns are horizontal, vertical, cross-stripes, leaves and flowers in curtain database. In this study, we propose a system that retrieves images based on wavelet domain perceptual features which mainly depend on edge and correlation characteristics of the wavelet subbands in the major directions (horizontal and vertical). In order to reduce searching time, we first catagorize various patterns using supervised learning vector quantization (LVQ) technique. Then for each category or group, a prototype vector is formed by averaging all classified feature vectors in it. For a typical query, the query key is first compared with a few prototype vectors to determine the expected category. Then the query key performs similarity comparisons with the population of that particular group and retrieves relevant images. Users have also the provision to select subsequent similar groups if any query fails to capture the correct group at first attempt. An experiment with a set of curtain images shows the effectiveness of the proposed features compared to conventional Gabor, pyramidal wavelet transform (PWT) or local binary pattern (LBP) features. 2005 Elsevier B.V. All rights reserved.	artificial neural network;binary pattern (image generation);categorization;design pattern;image retrieval;learning vector quantization;local binary patterns;prototype;stripes;supervised learning;wavelet transform	Md. Khayrul Bashar;Noboru Ohnishi;Tetsuya Matsumoto;Yoshinori Takeuchi;Hiroaki Kudo;Kiyoshi Agusa	2005	Pattern Recognition Letters	10.1016/j.patrec.2005.04.009	computer vision;local binary patterns;cost-effectiveness analysis;feature vector;textile industry;image retrieval;computer science;machine learning;directionality;pattern recognition;mathematics;design pattern;symmetry;supervised learning;wavelet transform	AI	36.729525314147395	-59.779009710031495	26705
8ebb243428d5b67b72a911cabfed39e4174e5c71	intensity non-standardness affects computer recognition of anatomical structures	tissue specificity;object recognition;image segmentation;tissues;multiple objectives;scanners;mr imaging;medical image;image display;magnetic resonance imaging;medical imaging;computing systems;affective computing	Since MR image intensities do not possess a tissue specific numeric meaning, even in images acquired for the same subject, on the same scanner, for the same body region, by using the same pulse sequence, it is important to transform the image scale into a standard intensity scale so that, for the same body region, intensities are similar. The lack of a standard image intensity scale in MRI leads to many difficulties in tissue characterizability, image display, and analysis, including image segmentation and registration. The influence of standardization on these tasks has been documented well; however, how intensity non-standardness may affect the automatic recognition of anatomical structures for image segmentation has not been studied. Motivated from the study that we previously presented in SPIE Medical Imaging Conference 2010, 2 in this study, we analyze the effects of intensity standardization on anatomical object recognition. A set of 31 scenarios of multiple objects from the ankle complex included in the model, plus seven different realistic levels of non-standardness introduced are considered for evaluation. The experimental results imply that, intensity variation among scenes in an ensemble a particular characteristic of the behavior of non-standardness degrades object recognition performance.	cross-validation (statistics);filter (signal processing);horseland;image quality;image scanner;image segmentation;medical imaging;meltwater entrepreneurial school of technology;outline of object recognition	Ulas Bagci;Jayaram K. Udupa;Xinjian Chen	2011		10.1117/12.877779	medical imaging;computer vision;computer science;cognitive neuroscience of visual object recognition;magnetic resonance imaging;affective computing;image segmentation;computer graphics (images)	Vision	36.44564069283001	-73.09508045979629	26710
b6136f3ef591ab6c7517a38c452772a5f3e7951b	similarity based retrieval from a 3d human database	body and head shape;retrieval;shape representation;human database;similarity	In this paper, we describe a framework for similarity based retrieval from a 3D human database. Our technique is based on both body and head shape representation and retrieval based on similarity of both of them. The 3D human database used in our study is the CAESAR [CAESAR] anthropometric database and in it are around 5000 bodies. Furthermore, we have developed a web based interface for specifying the queries and to interact with the retrieval system. We have seen that our approach performs the similarity based retrieval in a reasonable amount of time and seems to be a practical approach.	anthropometry	Afzal Godil;Sandy Ressler	2005		10.1145/1186954.1187044	computer vision;visual word;similarity;computer science;data mining;geometry;information retrieval	Web+IR	40.5034245546216	-59.76593067840388	26720
e88d046183fb41f62a658a25ecb75fce9fd1c492	automatic quantification of filopodia-based cell migration	biology computing;cell motility;geodesic distance filopodium segmentation fluorescence microscopy steerable filtering;fluorescence;image segmentation;bio optics;steerablefiltering;differential geometry;lung adenocarcinoma cells automatic quantification cell migration filopodia fluorescent cells 3d time lapse series steerable filter coarse segmentation cell shape morphological filters coarse binary mask geodesic distance transform;biomechanics;time series;computer architecture microprocessors shape biomedical imaging transforms microscopy;geodesic distance;filopodium segmentation;transforms biological techniques biology computing biomechanics bio optics cell motility differential geometry fluorescence image segmentation microorganisms time series;fluorescence microscopy;transforms;biological techniques;microorganisms	We present a fully automatic approach to quantitatively analyze filopodia-based migration of fluorescent cells in 3D time-lapse series. The proposed method involves three steps. First, each frame of the time-lapse series is preprocessed using a steerable filter and binarized to obtain a coarse segmentation of the cell shape. Second, a sequence of morphological filters is applied on the coarse binary mask to separate the cell body from individual filopodia. Finally, their length is estimated using a geodesic distance transform. The proposed approach is validated on 3D time-lapse series of lung adenocarcinoma cells. We show that the number of filopodia and their average length can be used as a descriptor to discriminate between different phenotypes of migrating cells.	distance (graph theory);distance transform;steerable filter	Martin Maska;Xabier Morales;Arrate Muñoz-Barrutia;Ana Rouzaut;Carlos Ortiz-de-Solorzano	2013	2013 IEEE 10th International Symposium on Biomedical Imaging	10.1109/ISBI.2013.6556563	fluorescence microscope;computer vision;geodesic;fluorescence;biomechanics;time series;mathematics;image segmentation;microorganism;optics;motility;statistics	Vision	39.878674017231084	-74.66112021932348	26783
2b6cb77255bc694022b0a5a20a7d3c177271d0fc	development of an accelerated gvf semi-automatic contouring algorithm for radiotherapy treatment planning	right ventricle;treatment planning;image guided radiation therapy;gradient vector flow;active contour;image segmentation;computed tomography;adaptive radiation;adaptive radiation therapy	Fast contouring is important in image-guided radiation therapy (IGRT) and adaptive radiation therapy (ART) where large computed tomography (CT) volumes have to be segmented. In this study, a modified active contour (also called snake) segmentation method based on a faster gradient-vector-flow (GVF) calculation algorithm is proposed. The accelerated method was tested on multiple organs, including lung, right ventricle, kidney and prostate. Compared to the original algorithm, the improved one reduced GVF calculation times to one-half or less without compromising contour accuracy.	active contour model;arabic numeral 100;ct scan;experiment;flow cytometry;gradient;heart ventricle;non-small cell lung carcinoma;organ;radiotherapy, image-guided;renal tissue;right lung;right ventricular structure;semiconductor industry;structure of parenchyma of lung;therapeutic radiology procedure;x-ray computed tomography;algorithm;biologic segmentation	Xingen Wu;Sharon A. Spencer;Sui Shen;John B. Fiveash;Jun Duan;Ivan A. Brezovich	2009	Computers in biology and medicine	10.1016/j.compbiomed.2009.05.001	computer vision;radiology;medicine;image-guided radiation therapy;computer science;active contour model;adaptive radiation;image segmentation;computed tomography;nuclear medicine;medical physics	Vision	39.649832599024656	-79.57076399876313	26817
0a3b29c96cc1786971bdc701a7b77dd41067998f	rgb-d image segmentation based on multiple random walkers	rgb d image segmentation;image segmentation;segmentation;synthetic aperture sonar;image edge detection;image color analysis;random walk;probability distribution;multiple random walkers;clustering algorithms;telecommunications	A novel RGB-D image segmentation algorithm is proposed in this work. This is the first attempt to achieve image segmentation based on the theory of multiple random walkers (MRW). We construct a multi-layer graph, whose nodes are superpixels divided with various parameters. Also, we set an edge weight to be proportional to the similarity of color and depth features between two adjacent nodes. Then, we segment an input RGB-D image by employing MRW simulation. Specifically, we decide the initial probability distribution of agents so that they are far from each other. We then execute the MRW process with the repulsive restarting rule, which makes the agents repel one another and occupy their own exclusive regions. Experimental results show that the proposed MRW image segmentation algorithm provides competitive segmentation performances, as compared with the conventional state-of-the-art algorithms.	algorithm;image segmentation;layer (electronics);mount rainier (packet writing);performance;raw image format;simulation	Se-Ho Lee;Won-Dong Jang;Byung Kwan Park;Chang-Su Kim	2016	2016 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2016.7532819	probability distribution;image texture;computer vision;synthetic aperture sonar;range segmentation;computer science;machine learning;segmentation-based object categorization;pattern recognition;mathematics;region growing;image segmentation;cluster analysis;minimum spanning tree-based segmentation;scale-space segmentation;segmentation;random walk;statistics	Robotics	44.3364862244822	-67.85259465892177	26844
4c648fe9b7bfd25236164333beb51ed364a73253	presentation attack detection methods for face recognition systems: a comprehensive survey	countermeasure;biometrics;face recognition;attacks;antispoofing;security	The vulnerability of face recognition systems to presentation attacks (also known as direct attacks or spoof attacks) has received a great deal of interest from the biometric community. The rapid evolution of face recognition systems into real-time applications has raised new concerns about their ability to resist presentation attacks, particularly in unattended application scenarios such as automated border control. The goal of a presentation attack is to subvert the face recognition system by presenting a facial biometric artifact. Popular face biometric artifacts include a printed photo, the electronic display of a facial photo, replaying video using an electronic display, and 3D face masks. These have demonstrated a high security risk for state-of-the-art face recognition systems. However, several presentation attack detection (PAD) algorithms (also known as countermeasures or antispoofing methods) have been proposed that can automatically detect and mitigate such targeted attacks. The goal of this survey is to present a systematic overview of the existing work on face presentation attack detection that has been carried out. This paper describes the various aspects of face presentation attacks, including different types of face artifacts, state-of-the-art PAD algorithms and an overview of the respective research labs working in this domain, vulnerability assessments and performance evaluation metrics, the outcomes of competitions, the availability of public databases for benchmarking new PAD algorithms in a reproducible manner, and finally a summary of the relevant international standardization in this field. Furthermore, we discuss the open challenges and future work that need to be addressed in this evolving field of biometrics.	algorithm;biometrics;database;electronic visual display;facial recognition system;performance evaluation;printing;real-time locating system;spoofing attack	Ramachandra Raghavendra;Christoph Busch	2017	ACM Comput. Surv.	10.1145/3038924	facial recognition system;face detection;simulation;computer science;information security;countermeasure;face recognition grand challenge;internet privacy;computer security;biometrics	Security	28.005508198928723	-62.704768513399515	26845
48efc76ad15276cdac263bd217f2f7e1f7cfe27a	how good are local features for classes of geometric objects	object recognition;geometric layout;shape statistics object recognition image segmentation performance evaluation computer science object detection statistical analysis focusing motorcycles;data collection;object categorization;object recognition feature extraction;geometric objects recognition local features geometric objects object categorization geometric layout shape based features appearance based descriptors feature statistics;geometric objects;geometric objects recognition;local features;feature extraction;feature statistics;appearance based descriptors;shape based features	Recent work in object categorization often uses local image descriptors such as SIFT to learn and detect object categories. Such descriptors explicitly code local appearance and have shown impressive results on objects with sufficient local appearance statistics. However, many important object classes such as tools, cups and other man-made artifacts seem to require features that capture the respective shape and geometric layout of those object classes. Therefore this paper compares, on a novel data collection of 10 geometric object classes, various shape-based features with appearance-based descriptors such as SIFT. The analysis includes a direct comparison of feature statistics as well as results within standard recognition frameworks, which are partly intuitive, but sometimes surprising.	berg connector;cups;categorization;cluster analysis;cosy (computer conferencing system);feature vector;gloh;gaussian blur;hessian;scale-invariant feature transform;visual descriptor	Michael Stark;Bernt Schiele	2007	2007 IEEE 11th International Conference on Computer Vision	10.1109/ICCV.2007.4408878	computer vision;feature extraction;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;mathematics;3d single-object recognition;statistics;data collection	Vision	34.86945257303688	-53.17850592006026	26896
0e0f7a48206590607d38a2f4ffe367e1d2a0b540	gray intensity images processing for pd pattern recognition based on genetic programming	image recognition;genetic program;image processing;storage requirement;image processing pattern recognition genetic programming partial discharges image recognition frequency pulse power systems image storage signal processing data mining;gray intensity image identification;search algorithm;surface discharges;spectrum;genetic programming;data mining;2d gray intensity image processing;three dimensional;power engineering computing;prpd mode;feature extraction;phase resolved partial discharge pattern recognition;partial discharge;pattern recognition;partial discharges;software flow chart;genetic algorithms;transformer insulation 2d gray intensity image processing phase resolved partial discharge pattern recognition genetic programming feature extraction 3d spectrum software flow chart search algorithm gray intensity image identification storage requirement;search problems;transformer insulation;3d spectrum;template matching;discharges;transformer insulation feature extraction genetic algorithms image recognition partial discharges power engineering computing search problems;template matching prpd mode image processing genetic programming image recognition	Partial discharge(PD) gray intensity image is regarded as the research object in this paper, a new principle and method based on genetic programming is proposed to extract PD features aiming at PRPD mode, This article firstly introduces the PRPD mode and the method to get the three-dimensional spectrum and two-dimensional gray intensity image, then gray intensity images identification technology based on genetic programming is introduced, Furthermore, the paper presents software flow chart of search algorithm of gray intensity image recognition. Finally, the results of experiment are given. Compared with the original image recognition technology, this method provides an effective pathway for the better recognition in image information, Using this method, the storage requirement and the calculation involved may be reduced, the results show that it is effective.	computation;computer vision;discharger;flowchart;gene regulatory network;genetic programming;pattern recognition;search algorithm;template matching	Xuesong Suo;Yuhong Zhou	2009	2009 International Joint Conference on Artificial Intelligence	10.1109/JCAI.2009.74	genetic programming;three-dimensional space;spectrum;computer vision;partial discharge;genetic algorithm;template matching;image processing;feature extraction;computer science;machine learning;pattern recognition;search algorithm	Robotics	38.70680176379947	-68.8806097443701	26940
ad7830895fcba6de7bd9ef79ddabc1dff20c8322	do multispectral palmprint images be reliable for person identification?	g400 computer science;discrete wavelet transform;biometrics;data fusion;discrete cosine transform;multispectral palmprint images;1d log gabor filter;feature extraction;multiresolution analysis	This paper is concerned with an investigation of multispectral palmprint images for improving person identification by replying to the question: can multispectral palmprint images be reliable for such purpose? Two biometric systems are then proposed. In the first system, each spectral image is aligned and then used for feature extraction using 1D Log-Gabor filter. The features are encoded and Hamming distance is used for matching. The fusion at matching score level is used before the decision making. The second system is based on multiresolution analysis for feature extraction. The spectral images are decomposed into frequency sub-images with different levels of decomposition. The extracted coefficients are used as features. The MGPDF is used for modeling the features and Log-Likelihood scores are used for matching. Fusion at the matching score level is used before decision making. A comparative study between the two systems is then developed. The experimental results are demonstrated using the PolyU multispectral database and the results show that the two proposed systems are more effective when using multispectral images than their monospectral counterpart images.	biometrics;coefficient;feature extraction;fingerprint;gabor filter;hamming distance;multiresolution analysis;multispectral image	Abdallah Meraoumia;Salim Chitroub;Ahmed Bouridane	2013	Multimedia Tools and Applications	10.1007/s11042-013-1706-3	multiresolution analysis;computer vision;speech recognition;feature extraction;computer science;discrete cosine transform;pattern recognition;multispectral pattern recognition;sensor fusion;discrete wavelet transform;algorithm;biometrics	Robotics	34.093584954977715	-61.1783417821631	26945
18e74bbfbb6276b32b5bef6083a9b6b2ad0bf7b3	stereo matching with adaptive support-weight correlation and graph cuts	computers;graph theory;adaptive supported window;minimization;computer graphics;adaptive supported window stereo graph cuts;image matching;pixel classification;image classification;correlation methods;computers minimization;energy use;middlebury homepage stereo matching graph cuts occlusion handling energy model based stereo method 2 step adaptive support weight correlation pixel classification disparity map middlebury data set;stereo matching;graph cut;stereo image processing;stereo;stereo image processing computer graphics correlation methods graph theory image classification image matching;graph cuts	Constructing a reliable data term and occlusion handling are two important issues for energy model based stereo method. In this paper, we at first use a 2-step adaptive support-weight correlation approach to get a reliable correlation volume. Then a pixel classification is proposed which classifies pixels into three classes: occluded, unstable and stable. For each pixel, according its class, a confidence weight is assigned. After that a new energy model is then constructed by integrating the correlation volume and the confidence weight. Finally, through minimizing this energy using Graph cuts, a better disparity map is obtained. Experimental results on the Middlebury data set show that our proposed method has the similar good performance with the top rank Graph Cuts based algorithms listed on the Middlebury homepage.	algorithm;binocular disparity;computer stereo vision;control theory;cut (graph theory);global optimization;mathematical optimization;pixel	Limin Shi;Fusheng Guo;Wei Gao;Zhanyi Hu	2010	2010 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2010.5642342	computer vision;cut;computer science;graph theory;machine learning;pattern recognition;mathematics	Vision	46.11010971090676	-69.87139379545958	26954
fd44cf265ed0b0d072c3ae2652f97215fda3aa29	embedding gestalt laws in markov random fields	model verification;gibbs distribution;mcmc algorithm;shape synthesis;maximum entropy methods;active contour;image segmentation;minimum entropy methods;perceptual grouping;markov random field;minimax techniques;markov random fields shape mathematical model image segmentation minimax techniques entropy stochastic processes monte carlo methods statistics psychology;markov chain monte carlo;local features;monte carlo methods image segmentation markov processes maximum entropy methods minimum entropy methods minimax techniques free energy;information theory gestalt laws markov random fields mrf 2d object shape modeling 2d object shape learning middle level vision problems image segmentation perceptual organization minimax entropy learning theory gibbs distributions colinearity cocircularity proximity parallelism symmetry contour based features region based features stochastic markov chain monte carlo algorithms mcmc algorithms model verification nonaccidental statistics;shape modeling;markov processes;learning theory;free energy;maximum entropy;monte carlo methods;gestalt laws;information theory;perceptual organization	The goal of this paper is to study a mathematical framework of 2D object shape modeling and learning for middle level vision problems, such as image segmentation and perceptual organization. For this purpose, we pursue generic shape models which characterize the most common features of 2D object shapes. In this paper, shape models are learned from observed natural shapes based on a minimax entropy learning theory. The learned shape models are Gibbs distributions defined on Markov random fields (MRFs). The neighborhood structures of these MRFs correspond to Gestalt laws-colinearity, cocircularity, proximity, parallelism, and symmetry. Thus, both contour-based and region-based features are accounted for. Stochastic Markov chain Monte Carlo (MCMC) algorithms are proposed for learning and model verification. Furthermore, this paper provides a quantitative measure for the so-called nonaccidental statistics and, thus, justifies some empirical observations of Gestalt psychology by information theory. Our experiments also demonstrate that global shape properties can arise from interactions of local features.	gestalt psychology;markov chain;markov random field	Song-Chun Zhu	1999	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.809110	markov chain monte carlo;information theory;boltzmann distribution;principle of maximum entropy;machine learning;learning theory;pattern recognition;active contour model;mathematics;image segmentation;markov process;statistics;monte carlo method	Vision	49.99668260025385	-69.77986825167325	27001
32b660918d8c26333ad515ad981fa544f0cf0763	high-throughput-derived biologically-inspired features for unconstrained face recognition	biologically inspired;face recognition	Many modern computer vision algorithms are built atop of a set of low-level feature operators (such as SIFT [23,24]; HOG [8,3]; or LBP [1,2]) that transform raw pixel values into a representation better suited to subsequent processing and classification. While the choice of feature representation is often not central to the logic of a given algorithm, the quality of the feature representation can have critically important implications for performance. Here, we demonstrate a large-scale feature search approach to generating new, more powerful feature representations in which a multitude of complex, nonlinear, multilayer neuromorphic feature representations are randomly generated and screened to find those best suited for the task at hand. In particular, we show that a brute-force search can generate representations that, in combination with standard machine learning blending techniques, achieve state-of-the-art performance on the Labeled Faces in the Wild (LFW) [19] unconstrained face recognition challenge set. These representations outperform previous state-of-the-art approaches, in spite of requiring less training data and using a conceptually simpler machine learning backend. We argue that such large-scale-search-derived feature sets can play a synergistic role with other computer vision approaches by providing a richer base of features with which to work.	facial recognition system;throughput	Nicolas Pinto;David D. Cox	2012	Image Vision Comput.	10.1016/j.imavis.2011.12.009	facial recognition system;feature learning;computer vision;feature vector;feature;feature extraction;computer science;machine learning;pattern recognition;feature	Vision	25.33060199578591	-53.169308687937956	27040
ed587a4a5dab5739c2477ee8921ffd13cca7d5e7	group sparsity model for stain unmixing in brightfield multiplex immunohistochemistry images	color deconvolution;rgb image unmixing;group sparsity;multiplex immunohistochemistry image	Multiplex immunohistochemistry (IHC) staining is a new, emerging technique for the detection of multiple biomarkers within a single tissue section. The initial key step in multiplex IHC image analysis in digital pathology is of tremendous clinical importance due to its ability to accurately unmix the IHC image and differentiate each of the stains. The technique has become popular due to its significant efficiency and the rich diagnostic information it contains. The intriguing task of unmixing a three-channel CCD color camera acquired RGB image into more than three colors is very challenging, and to the best of our knowledge, hardly studied in academic literature. This paper presents a novel stain unmixing algorithm for brightfield multiplex IHC images based on a group sparsity model. The proposed framework achieves robust unmixing for more than three chromogenic dyes while preserving the biological constraints of the biomarkers. Typically, a number of biomarkers co-localize in the same cell parts named priori. With this biological information in mind, the number of stains at one pixel therefore has a fixed up-bound, i.e. equivalent to the number of co-localized biomarkers. By leveraging the group sparsity model, the fractions of stain contributions from the co-localized biomarkers are explicitly modeled into one group to yield the least square solution within the group. A sparse solution is obtained among the groups since ideally only one group of biomarkers is present at each pixel. The algorithm is evaluated on both synthetic and clinical data sets, and demonstrates better unmixing results than the existing strategies.	algorithm;biological markers;cardinal cell part;charge-coupled device;color;greater than;image analysis;immunohistochemistry;least-squares analysis;multiplexing;name;pixel;sparse matrix;staining method;stains;synthetic data	Ting Chen;Chukka Srinivas	2015	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2015.04.001	computer vision;pathology	Vision	28.509027532341076	-74.97241822190803	27125
1ccf826661011097e84ccb8a080de4674f23335a	edge detection by selection of pieces of level lines	canny edge detection;detectors;filtering;computational gestalt;info eu repo semantics conferenceobject;edge detection;indexing terms;canny;statistical analysis;general methods;image edge detection;pixel;statistics;desolneux moisan morel;digital images;level line piece selection;algorithm design and analysis;elementary reasoning;general method;noise	We propose an edge detector based on the selection of well contrasted pieces of level lines, following the proposal of Desolneux-Moisan-Morel (DMM) [1]. The DMM edge detector has the problem of over-representation, that is, every edge is detected several times in slightly different positions. In this paper we propose two modifications of the original DMM edge detector in order to solve this problem. The first modification is a post-processing of the output using a general method to select the best representative of a bundle of curves. The second modification is the use of Canny's edge detector instead of the norm of the gradient to build the statistics. The two modifications are independent and can be applied separately. Elementary reasoning and some experiments show that the best results are obtained when both modifications are applied together.	edge detection	Enric Meinhardt	2008		10.1109/ICIP.2008.4711829	filter;algorithm design;computer vision;detector;edge detection;index term;computer science;noise;artificial intelligence;machine learning;mathematics;canny edge detector;digital image;algorithm;pixel;statistics	Vision	44.32637663603462	-67.22789641560895	27130
17e60e9c6537b195d1c42f88b42a14fd2f6c97b4	a new dynamic approach for finding the contour of bi-level images	formation image tridimensionnelle;algorithm complexity;image processing;3d imaging;edge detection;complejidad algoritmo;procesamiento imagen;chino;traitement image;deteccion contorno;detection contour;reconnaissance caractere;complexite algorithme;formacion imagen tridimensional;chinois;chinese;character recognition;reconocimiento caracter	Abstract   A new method to obtain the contour of a bi-level image is proposed. The method hinges on the clustering property of an image. The order of the search sequence for each boundary pixel is determined dynamically according to the occurring probabilities of its adjacent neighbors. The complexity of the proposed method is then analyzed, and some images and Chinese characters are processed. The results indicate that the proposed algorithm increases computation speed significantly over other established algorithms.	contour line	Louis R. Chow;H. C. Liu;S. Y. Hsu;D. W. Wu	1994	CVGIP: Graphical Model and Image Processing	10.1006/cgip.1994.1045	computer vision;edge detection;image processing;computer science;mathematics;chinese;algorithm	Robotics	46.08692985295636	-64.14382147403089	27172
ae2af55409e4cc8571e149fa4f9b739cad894f70	texture analysis based on the markov random	texture analysis	Abstract#R##N##R##N#A recent tendency in the study of texture is the analysis based on mathematical models rather than the analysis of intuitively clear geometrical features. This type of study is advantageous in that a systematic and theoretical viewpoint can be provided to various kinds of related texture image processings. This paper considers the Gaussian-Markov random field as a mathematical model for the texture image, and applications of the theory are discussed for texture classification and boundary extraction of texture regions. The determination of parameters for the Markov model is discussed first. Then the distance between textures is defined using the model parameters and a method of texture classification is proposed. The extraction of the boundary between texture regions is formulated as a testing of the parameters of the Markov model, and a method of texture region partition is proposed using the statistical testing variable as the discrimination function for the texture boundary. A classification experiment was performed for texture images with 13 categories, each containing 23 patterns. A 100% rate of classification was obtained, indicating the effectiveness of the proposed classification method. The region partition experiment was performed for the patched texture image. The result of partition was satisfactory, indicating the effectiveness of the proposed boundary extraction method.	markov chain	Field Model;Hiroshi Kaneko;Eiji Yodogawa	1985	Systems and Computers in Japan	10.1002/scj.4690160209	image texture;computer vision;computer science;machine learning;pattern recognition;mathematics;texture filtering	Logic	42.099733508004974	-64.1445146160426	27197
33ff69a34aa0c3be23e6762b1cc85985d58a0a98	contour shape description based on an arch height function	edge boundary;contour;deteccion;arche;courbure;detection;methode calcul;algorithme;metodo calculo;calculating method;algorithm;chord;pattern recognition;curvatura;curvature;angulo;contorno;reconnaissance forme;shape description;reconocimiento patron;height function;angle;arco;arch;algoritmo	Abstract   A new method to extract contour features is proposed. For any contour  C , a function, which we call Arch Height Function (AHF), is defined for each point and its value on  C  is computed. The set of AHF values is then used as a description of the shape of  C . In particular, its local maxima, if they exist, correspond precisely to the cornerpoints of  C . Besides, the method is computationally efficient as compared with the existing techniques of the contour feature extraction. The new method provides an effective and reliable tool for contour description, especially for angle detection. Some experimental results that demonstrate the adaptability and reliability of the AHF method are presented.	contour line	Yijia Lin;Jiqing Dou;Hongmei Wang	1992	Pattern Recognition	10.1016/0031-3203(92)90003-2	calculus;mathematics;geometry;curvature;chord;angle;arch	Vision	48.834764526019526	-60.83551697613147	27229
b19c675ea0e347cd8630c3bc5aff790fb58d2611	image orientation detection with integrated human perception cues (or which way is up)	bayesian framework;visual databases face recognition image texture object detection content based retrieval;photo acquiring model image orientation detection integrated human perception cues face orientation sky position brighter regions textured objects bayesian framework;prior knowledge;image texture;face recognition;image orientation;automatic detection;humans bayesian methods clustering algorithms digital cameras object detection face computer science detectors content management image retrieval;human perception;content based retrieval;object detection;visual databases	In this paper, we propose a set of human perceptual cues used jointly to automatically detect image orientation. The cues used are: orientation of faces, position of the sky, brighter regions, and textured objects, and symmetry. We combine these cues in a Bayesian framework, and the photo acquiring model has been considered carefully as the prior knowledge of the image orientation. Results on more than a thousand different images provide a compelling argument that our approach is a viable one.	bayesian network	Lei Wang;Xu Liu;Lirong Xia;Guangyou Xu;Alfred M. Bruckstein	2003		10.1109/ICIP.2003.1246736	facial recognition system;image texture;computer vision;object-class detection;orientation;computer science;pattern recognition;multimedia;perception	Vision	37.26212613050205	-53.9207099328144	27235
e971ad95c48db53f9001f7f122036cfcd0016d2a	relative scale method to locate an object in cluttered environment	generalized hough transform;three dimensional;relative scale;object localization;spatial relation;local features;multidimensional hashing;knowledge base	This paper proposes an efficient method to locate a three-dimensional object in cluttered environment. Model of the object is represented in a reference scale by the local features extracted from several reference images. A PCA-based hashing technique is introduced for accessing the database of reference features efficiently. Localization is performed in an estimated relative scale. Firstly, a pair of stereo images is captured simultaneously by calibrated cameras. Then the object is identified in both images by extracting features and matching them with reference features, clustering the matched features with generalized Hough transformation, and verifying clusters with spatial relations between the features. After the identification process, knowledge-based correspondences of features belonging to the object present in the stereo images are used for the estimation of the 3D position. The localization method is robust to different kinds of geometric and photometric transformations in addition to cluttering, partial occlusions and background changes. As both the model representation and localization are single-scale processes, the method is efficient in memory usage and computing time. The proposed relative scale method has been implemented and experiments have been carried out on a set of objects. The method results very good accuracy and takes only a few seconds for object localization by our primary implementation. An application of the relative scale method for exploration of an object in cluttered environment is demonstrated. The proposed method could be useful for many other practical applications.		Md. Saiful Islam;Andrzej Stefan Sluzek	2008	Image Vision Comput.	10.1016/j.imavis.2007.06.001	spatial relation;three-dimensional space;computer vision;knowledge base;computer science;machine learning;pattern recognition;mathematics	Robotics	43.04195767623109	-54.92031156558152	27241
6371273263a822316d7f493bc5e178be198f98d9	curve parametrization by moments	irregularity;conic location;high frequency noise;metodo momento;texture;ellipse detection;vision ordenador;kernel;feature detection;mathematics;image coding;image processing;moment method;multiplication operator;application software;edge detection;analisis forma;image moments curve parametrization parametric description conic section hough transform type methods high frequency noise ellipse detection;localization;kernel function;parameterization;intelligence artificielle;localizacion;algorithms artificial intelligence computer simulation image interpretation computer assisted models theoretical pattern recognition automated;transformacion hough;parametrizacion;conico;image texture;computer vision;irregularite;haute frequence;moments;parametric description;localisation;image moments;shape;complexity class;edge and feature detection;feature extraction;conic parameterization;methode moment;funcion nucleo;irregularidad;fonction noyau;textura;immune system;higher dimensions;conic section;artificial intelligence;conic detection;vision ordinateur;hough transformation;hough transform;pattern analysis;transformation hough;kernel image coding immune system equations mathematics image processing computer vision shape application software feature extraction;image texture edge detection;curve parametrization;inteligencia artificial;alta frecuencia;circle detection;conics;conique;high frequency;parametrisation;hough transform type methods;analyse forme;moments edge and feature detection	We present a method for deriving a parametric description of a conic section (quadratic curve) in an image from the moments of the image with respect to several specially-constructed kernel functions. In contrast to Hough-transform-type methods, the moment approach requires no large accumulator array. Judicious implementation allows the parameters to be determined using five multiplication operations and six addition operations per pixel. The use of moments renders the calculation robust in the presence of high-frequency noise or texture and resistant to small-scale irregularities in the edge. Our method is generalizable to more complex classes of curves with more parameters as well as to surfaces in higher dimensions.	accumulator (computing);accumulator device component;class;dimensions;eye enucleation procedure;hl7publishingsubsection <operations>;hough transform;incidence matrix;kernel;multiplication;pixel;quadratic function;recurrence relation;rendering (computer graphics)	Irina Popovici;William Douglas Withers	2009	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2008.54	hough transform;velocity moments;computer vision;image processing;computer science;machine learning;mathematics;geometry;conic section	Vision	50.456045569002065	-61.118760291488044	27250
1dd56cd5faef1d012da44ae15255f45c77f14648	recovering epipolar geometry from images of smooth surfaces	smooth surfaces;exact results;artificial intelligent;epipolar geometry;camera motion;isophoto curves;homography;pattern recognition;level curves;occluding contour	We present four methods for recovering the epipolar geometry from images of smooth surfaces. In the existing methods for recovering epipolar geometry corresponding feature points are used that cannot be found in such images. The first method is based on finding corresponding characteristic points created by illumination (ICPM—illumination characteristic points method). The second method is based on correspondent tangency points created by tangents from epipoles to outline of smooth bodies (OTPM—outline tangent points method). These two methods are exact and give correct results for real images, because positions of the corresponding illumination characteristic points and corresponding outline are known with small errors. But the second method is limited either to special type of scenes or to restricted camera motion. We also consider two more methods which are termed CCPM (curve characteristic points method, curves, denoted by word “green”, are used for this method on Figures) and CTPM (curve tangent points method, curves, denoted by word “red” are used for this method on Figures), for searching epipolar geometry for images of smooth bodies based on a set of level curves (isophoto curves) with a constant illumination intensity. The CCPM method is based on searching correspondent points on isophoto curves with the help of correlation of curvatures between these lines. The CTPM method is based on property of the tangential to isophoto curve epipolar line to map into the tangential to correspondent isophoto curves epipolar line. The standard method termed SM (standard method, curves, denoted by word “blue” are used for this method on Figures) and based on knowledge of pairs of the almost exact correspondent points, has been used for testing of these two methods. The main technical contributions of our CCPM method are following. The first of them consists of bounding the search space for epipole locations. On the face of it, this space is infinite and unbounded. We suggest a method to partition the infinite plane into a finite number of regions. This partition is based on the desired accuracy and maintains properties that yield an efficient search over the infinite plane. The second is an efficient method for finding correspondence between points of two closed isophoto curves and finding homography, mapping between these two isophoto curves. Then this homography is corrected for all possible epipole positions with the help of evaluation function. A finite subset of solution is chosen from the full set given by all possible epipole positions. This subset includes fundamental matrices giving local minimums of evaluating function close to global minimum. Epipoles of this subset lie almost on straight line directed parallel to parallax shift. CTPM method was used to find the best solution from this subset. Our method is applicable to any pair of images of smooth objects taken under perspective projection models, as long as assumption of the constant brightness is taken for granted. The methods have been implemented and tested on pairs of real images. Unfortunately, the last two methods give us only a finite subset of solution that usually includes good solution, but does not allow us to find this good solution among this subset. Exception is the case of epipoles in infinity. The main reason for such result is inaccuracy of assumption of constant brightness for smooth bodies. But outline and illumination characteristic points are not influenced by this inaccuracy. So, the first pair of methods gives exact results.	3d projection;epipolar geometry;evaluation function;fundamental matrix (computer vision);homography (computer vision);illumination (image);maxima and minima;parallax	Oleg Kupervasser	2013	Pattern Recognition and Image Analysis	10.1134/S1054661813020107	computer vision;mathematical optimization;topology;homography;computer science;level set;pattern recognition;mathematics;geometry;fundamental matrix;epipolar geometry	Vision	52.58099247621721	-55.07315043009367	27268
b493a1f2f83fc0b7b2ba44614d4bb664fb104ba4	human recognition by gait analysis using neural networks	fiabilidad;reliability;self organizing maps;viability;extraction forme;viabilite;carte autoorganisatrice;viabilidad;network analysis;extraccion forma;feature extraction;fiabilite;gait analysis;pattern recognition;autoorganizacion;self organization;reconnaissance forme;extraction caracteristique;reseau neuronal;reconocimiento patron;analyse circuit;pattern extraction;red neuronal;autoorganisation;analisis circuito;neural network	This paper presents a new method to recognize people by their gait, which forms part of a major project to detect and recognize automatically different human behaviours. The project is comprised of several stages, but this paper is focused on the last one, i.e. recognition. This stage is based on the Self-Organizing Map, assuming that the previous stage of feature extraction has already been solved. Although this previous stage is solved with manual extraction of human model points, the obtained results demonstrate the viability of the neural approach to the recognition of these kind of temporal sequences.	artificial neural network;gait analysis;neural network software	José Elías Herrero Jaraba;Carlos Orrite-Uruñuela;J. David Buldain Pérez;Armando Roy-Yarza	2002		10.1007/3-540-46084-5_59	computer vision;self-organization;gait analysis;self-organizing map;network analysis;feature extraction;computer science;artificial intelligence;machine learning;reliability;artificial neural network	Robotics	45.284377537409	-58.33606265237485	27303
088ed662140367dd95fb1734670c74b6f09a7976	page frame detection for double page document images	border removal;user needs;page splitting;image enhancement;document image enhancement;noise removal	Scanning two book pages at the same time helps to accelerate the scanning process but on the other hand introduces several difficulties if the user needs to have one page per image. A major difficulty is the appearance of noisy black borders around text areas as well as of noisy black stripes between the two pages. In this paper, we propose a novel algorithm for detecting the page frames on double page document images. Our aim is to split the image into the two pages as well as to remove noisy borders. First we apply a pre-processing which includes binarization, noise removal and image smoothing. Then, we detect the vertical zones of the two pages. In this stage, we introduce the vertical white run projections which have been proved efficient for detecting vertical zones of text areas. Finally, the horizontal zones of the two pages are detected based on horizontal white run projections. The experimental results on several double page document images from fifteen different books demonstrate the effectiveness of the proposed technique.	algorithm;binary image;book;colors of noise;image editing;image scanner;preprocessor;sensor;smoothing;stripes;web page	Nikolaos Stamatopoulos;Basilios Gatos;Theodore Georgiou	2010		10.1145/1815330.1815382	computer science;multimedia;world wide web;computer graphics (images)	Vision	38.71415582485804	-66.45652001319829	27307
8738a1150751495c8b65e443ce16dde04905fa7b	learning-based deformable registration of mr brain images	deformable registration;optimisation;consistent features;brain;saliency measurement;best scale selection;hammer registration algorithm learning based deformable image registration mr brain images magnetic resonance imaging best scale geometric features correspondence detection energy function optimization salient features consistent features;image registration biomedical measurements learning systems biomedical imaging magnetic resonance brain modeling medical simulation image color analysis anatomical structure computer science;optimisation biomedical mri brain image registration learning artificial intelligence medical image processing;algorithms artificial intelligence brain humans image enhancement image interpretation computer assisted information storage and retrieval magnetic resonance imaging pattern recognition automated phantoms imaging reproducibility of results sensitivity and specificity subtraction technique;indexing terms;mr brain images;geometric feature;energy function;learning systems;hammer registration algorithm;learning based method;best scale geometric features;magnetic resonance;saliency measurement best features best scale selection consistency measurement deformable registration feature based registration hierarchical registration learning based method;medical image processing;magnetic resonance imaging;image registration;salient features;correspondence detection;brain imaging;best features;biomedical image processing;hierarchical registration;learning artificial intelligence;energy function optimization;learning based deformable image registration;feature based registration;biomedical mri;consistency measurement;optimization methods	This paper presents a learning-based method for deformable registration of magnetic resonance (MR) brain images. There are two novelties in the proposed registration method. First, a set of best-scale geometric features are selected for each point in the brain, in order to facilitate correspondence detection during the registration procedure. This is achieved by optimizing an energy function that requires each point to have its best-scale geometric features consistent over the corresponding points in the training samples, and at the same time distinctive from those of nearby points in the neighborhood. Second, the active points used to drive the brain registration are hierarchically selected during the registration procedure, based on their saliency and consistency measures. That is, the image points with salient and consistent features (across different individuals) are considered for the initial registration of two images, while other less salient and consistent points join the registration procedure later. By incorporating these two novel strategies into the framework of the HAMMER registration algorithm, the registration accuracy has been improved according to the results on simulated brain data, and also visible improvement is observed particularly in the cortical regions of real brain data	algorithm;brain simulation;hammer;image registration;matching;mathematical optimization;requirement;resonance;wavelet;registration - actclass	Guorong Wu;Feihu Qi;Dinggang Shen	2006	IEEE Transactions on Medical Imaging	10.1109/TMI.2006.879320	computer vision;index term;radiology;medicine;computer science;image registration;magnetic resonance imaging;machine learning;pattern recognition	Vision	42.3162596213071	-77.10391957854272	27361
b5f0049de591a233cbf9acfd6ca4cc34726174ad	graph matching using a direct classification of node attendance	objet;acoplamiento grafo;object recognition;direct classification;subgrafo;selected works;object;classification;image bruitee;graph matching;isomorphism;isomorfismo;graph isomorphism;imagen sonora;couplage graphe;sous graphe;noisy image;pattern recognition;bepress;isomorphisme;reconnaissance forme;subgraph;reconocimiento patron;objeto;clasificacion	An algorithm has been developed that nds isomorphisms between both graphs and subgraphs The development is introduced in the object recognition problem domain The method isolates matching subgraphs nds a node to node mapping and reorders nodes thus permitting a direct comparison to be made between the resultant graphs The algorithm is of polynomial order It yields approximate results maintaining a performance level for subgraph isomorphisms at or above under a wide variety of conditions and with varying levels of noise The performance on the full size comparisons associated with graph isomorphisms has been found to be also under a variety of conditions Performance metrics methods of testing and results are presented	approximation algorithm;matching (graph theory);outline of object recognition;polynomial;problem domain;resultant;software performance testing	Fred W. DePiero;Mohan Manubhai Trivedi;Steven M. Serbin	1996	Pattern Recognition	10.1016/0031-3203(95)00140-9	combinatorics;discrete mathematics;biological classification;computer science;object;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;mathematics;graph isomorphism;isomorphism;algorithm;matching	Vision	46.16204626213902	-61.126126752611924	27366
c8270ed00305574aaa988d49425b9072b9aec386	fine-grained visual classification based on image foreground and sub-category similarity		We propose a fine-grained visual classification algorithm based on image foreground and sub-category similarity. In the processing of feature extracting, our model calculates the gradient of image pixels in a classification network to obtain the foreground of the image. Then input the foreground image and the original image into the bilinear convolution network to obtain the feature of the image. At the classification stage, we propose an improved SD-SVM algorithm, which takes the advantages of the similarities among sub-categories and the differences among the similarities of sub-category. Experimental results manifest that our algorithm can achieve 85.12% accuracy on the CUB-2011 dataset and 85.21% accuracy on the FGVC-aircrafts dataset even with only the category labels, which outperforms state-of-the-art fine-grained categorization methods.		Xianjin Jiang;Xin Lin;Yi Ji;Jianyu Yang;Chunping Liu	2017		10.1007/978-981-10-7305-2_13	pixel;categorization;bilinear interpolation;convolution;mathematics;pattern recognition;artificial intelligence	Vision	35.67386459342605	-58.16130766337524	27421
344a4d6887263db3bc7d1ed19f151ec8e9144af8	cross validation and segment support for stereo belief propagati	image segmentation;stereo disparity maps;endnotes;image region;belief propagation;image colour analysis;stereo image processing belief maintenance image colour analysis image segmentation;stereo image processing;stereo belief propagation;belief propagation optimisation;pubications;segment constraint;belief maintenance;cross validation;homogeneous colour;image segmentation pixel belief propagation costs markov random fields computer vision power engineering and energy systems engineering and theory equations optimization methods;image region image segmentation stereo belief propagation stereo disparity maps belief propagation optimisation cross validation homogeneous colour segment constraint	"""Typically, algorithms for generating stereo disparity maps have been developed to minimise the energy equation of a single image. This paper proposes a method for implementing cross validation in a belief propagation optimisation. When tested using the Middlebury online stereo evaluation, the cross validation improves upon the results of standard belief propagation. Furthermore, it has been shown that regions of homogeneous colour within the images can be used for enforcing the so-called """"segment constraint"""". Developing from this, segment support is introduced to boost belief between pixels of the same image region and improve propagation into textureless regions"""	algorithm;autostereogram;belief propagation;binocular disparity;computation;cross-validation (statistics);map;mathematical optimization;pattern recognition;pixel;quality of results;software propagation	Murray Evans;James M. Ferryman	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.422	computer vision;computer science;machine learning;pattern recognition;mathematics;image segmentation;cross-validation;belief propagation	Robotics	46.732975088524256	-52.560676264028494	27478
f4a3fc86f34ad3d22cb247f41d7ec81791506ced	multiview machine learning using an atlas of cardiac cycle motion		A cardiac motion atlas provides a space of reference in which the cardiac motion fields of a cohort of subjects can be directly compared. From such atlases, descriptors can be learned for subsequent diagnosis and characterization of disease. Traditionally, such atlases have been formed from imaging data acquired using a single modality. In this work we propose a framework for building a multimodal cardiac motion atlas from MR and ultrasound data and incorporate a multiview classifier to exploit the complementary information provided by the two modalities. We demonstrate that our novel framework is able to detect non ischemic dilated cardiomyopathy patients from ultrasound data alone, whilst still exploiting the MR based information from the multimodal atlas. We evaluate two different approaches based on multiview learning to implement the classifier and achieve an improvement in classification performance from 77.5% to 83.50% compared to the use of US data without the multimodal atlas.	machine learning	Esther Puyol-Antón;Matthew Sinclair;Bernhard Gerber;Mihaela Silvia Amzulescu;Hélène Langet;Mathieu De Craene;Paul Aljabar;Julia A. Schnabel;Paolo Piro;Andrew P. King	2017		10.1007/978-3-319-75541-0_1	cardiac cycle;computer vision;atlas (anatomy);computer science;artificial intelligence	AI	30.213510534661715	-78.91306521470612	27509
8bee18eb1f8fa24e0ff1beecf5b0b3a0a62af24b	contextual possibilistic modeling of pixellic knowledge for tumor segmentation in mammographic images		In this paper a novel possibilistic knowledge modeling at the pixel level, is proposed. This model consists on the use of the spatial contextual information at the level of each pixel, in order to evaluate a local based possibility distribution, resuming the pixel information. The proposed possibilistic modeling approach performance is evaluated through a pixel classification of both synthetic image and 5 mammographic images. Its performance is compared with three relevant reference methods: classic Bayesian approach and Markov Random fields approach with two optimization technics: Iterated Conditional Modes (ICM) and simulated annealing (RS). Our approach outperforms the other methods, in terms of recognition rate, by 94.84%, against, respectively, 93.88%, 85.10% and 84.67%. In addition, the proposed possibilistic modeling approach showed an interesting behavior of stability and allowed a better visually classification quality compared to other methods.	iterated conditional modes;iterated function;knowledge modeling;markov chain;markov random field;mathematical optimization;pixel;simulated annealing;synthetic intelligence	Imene Khanfir Kallel;Bassel Solaiman	2017	2017 International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)	10.1109/ATSIP.2017.8075563	pixel;random field;simulated annealing;probabilistic logic;machine learning;knowledge modeling;image segmentation;iterated conditional modes;markov chain;artificial intelligence;pattern recognition;mathematics	Vision	50.439282734138935	-69.35586972275595	27558
8adbcdda26052dd90eeedcc3da102d7899177520	human face detection using new high speed modular neural networks	reconnaissance visage;concepcion modular;learning process;clutter;image databank;base donnee tres grande;reseau vitesse elevee;detecteur phase;fouillis echo;face recognition;image simulation;reseau neuronal modulaire;computational complexity;confusion eco;banco imagen;banque image;modular design;phase detector;very large databases;reseau neuronal;face detection;detector fase;high speed;modular neural network;red neuronal;neural network;conception modulaire	In this paper, a new approach to reduce the computation time taken by neural networks for the searching process is introduced. Both fast and cooperative modular neural networks are combined to enhance the performance of the detection process. Such approach is applied to identify human faces automatically in cluttered scenes. In the detection phase, neural networks are used to test whether a window of 20 × 20 pixels contains a face or not. The major difficulty in the learning process comes from the large database required for face / nonface images. A simple design for cooperative modular neural networks is presented to solve this problem by dividing these data into three groups. Such division results in reduction of computational complexity and thus decreasing the time and memory needed during the test of an image. Simulation results for the proposed algorithm on Bio database show a good performance.	face detection;modular neural network;neural networks	Hazem M. El-Bakry	2005		10.1007/11550822_85	facial recognition system;phase detector;computer vision;face detection;simulation;computer science;artificial intelligence;machine learning;clutter;computational complexity theory;modular design;artificial neural network;algorithm	Vision	44.23099395748895	-58.88999529518745	27582
828fabdad5346dcb5b43b607b889712a70688e96	efficient video clip retrieval using index structure	database indexing;k nearest neighbor query video clip retrieval high dimensional index structure va file similarity measure;video databases;high dimensional index structure;query algorithm;video clip retrieval;high dimensionality;video representation video clip retrieval algorithm high dimensional index structure video database query algorithm vector approximation file va file;index structure;video retrieval;approximation theory;information retrieval algorithm design and analysis indexes computational complexity histograms information analysis deductive databases information processing computer science data engineering;image representation;video representation;k nearest neighbor;va file;video database;similarity measure;k nearest neighbor query;video clip retrieval algorithm;sliding window;vector approximation file;video retrieval approximation theory database indexing image representation video databases	Retrieving similar video clips from large video database requires high query efficiency, precision and recall, which remains a challenging problem since the traditional query algorithms are inefficient and time-consuming. In this paper, we adopt the high-dimensional index structure vector-approximation file (VA-file) to organize the video database, and propose a new similarity measure which takes the temporal order among the video representations into account to improve the accuracy of query. Based on the VA-file and similarity measure, a new video clip retrieval algorithm is proposed in our method to achieve high query efficiency by using restricted sliding window to construct candidate video clips. Experimental results show that the proposed video retrieval method is efficient and effective	algorithm;approximation;database index;precision and recall;similarity measure;video clip	Jing Zhang;Linjun Yang;Hong Lu;Xiangyang Xue;Yap-Peng Tan	2005	2005 IEEE 7th Workshop on Multimedia Signal Processing	10.1109/MMSP.2005.248688	sliding window protocol;database index;query optimization;query expansion;computer science;machine learning;video tracking;data mining;database;video post-processing;k-nearest neighbors algorithm;information retrieval;approximation theory	DB	39.79216670461257	-59.98813377628949	27630
f1be746cc31240c85fa122306de884d820ecfc7e	license plate detection using haar-like features and histogram of oriented gradients	licenses feature extraction accuracy training histograms computer vision classification algorithms;haar like cascaded classifier;histograms;classification algorithm;training;hog features license plate detection haar like features histogram of oriented gradients haar like cascaded classifier detection rate high false positives;image classification;histograms of oriented gradients;high false positives;computer vision;object detection computer vision feature extraction haar transforms image classification;accuracy;histogram of oriented gradients;feature extraction;licenses;classification algorithms;license plate detection;haar like features;detection rate;hog features;false positive;haar transforms;object detection	The Haar-like cascaded classifier has been used in license plate detection and yields a high detection rate, but it often has high false positives. We introduced a classifier which was trained through histogram of oriented gradients (HOG) features to judge the likelihood of candidate plates detected by Haar classifier, and selected the candidate with highest likelihood as the final plate, in order to reduce the false positives. This method was tested on 3000 images to obtain a recall rate of 95.2%, and accuracy of 94.0% as opposed to 66.4% without using HOG features. It was shown that the proposed method is able to eliminate most of the false candidate plates, such as barriers and incomplete plates.	gradient;haar wavelet;histogram of oriented gradients;sensitivity and specificity	Kuan Zheng;Yuanxing Zhao;Jing Gu;Qingmao Hu	2012	2012 IEEE International Symposium on Industrial Electronics	10.1109/ISIE.2012.6237313	computer vision;speech recognition;computer science;pattern recognition	Robotics	32.713643218861996	-56.722412514159686	27654
a44a3c1369159fb9b1d66d2772a0c4f24fe3b80f	decision tree based recognition of bangla text from outdoor scene images		This article proposes a scheme for automatic recognition of Bangla text extracted from outdoor scene images. For extraction, we obtain the headline, then apply certain conditions to distinguish between text and non-text. By removing the headline we partition the text into two zones. We further observe an association among the text symbols in these two different zones. For recognition purpose, we design a decision tree classifier with Multilayer Perceptron (MLP) at leaf nodes. The root node takes into account all possible text symbols. Further nodes highlight distinguishable features and act as two-class classifiers. Finally, at leaf nodes, a few text symbols remain, that are recognized using MLP classifiers. The association between the two zones makes recognition simpler and efficient. The classifiers are trained using about 7100 samples of 52 classes. Experiments are performed on 250 images (200 scene images and 50 scanned images).	decision tree	Ranjit Ghoshal;Anandarup Roy;Tapan Kumar Bhowmik;Swapan K. Parui	2011		10.1007/978-3-642-24965-5_61	natural language processing;computer vision;pattern recognition	Vision	35.13752180510498	-65.82170570860657	27669
d9cbdff63dd970c846fa19cf4169685815629f6d	deepmovie: using optical flow and deep neural networks to stylize movies.		A recent paper by Gatys et al. [1] describes a method for rendering an image in the style of another image. First, they use convolutional neural network features to build a statistical model for the style of an image. Then they create a new image with the content of one image but the style statistics of another image. Here, we extend this method to render a movie in a given artistic style. The naive solution that independently renders each frame produces poor results because the features of the style move substantially from one frame to the next. The other naive method that initializes the optimization for the next frame using the rendered version of the previous frame also produces poor results because the features of the texture stay fixed relative to the frame of the movie instead of moving with objects in the scene. The main contribution of this paper is to use optical flow to initialize the style transfer optimization so that the texture features move with the objects in the video. Finally, we suggest a method to incorporate optical flow explicitly into the cost function.	artificial neural network;brute-force search;convolutional neural network;deep learning;loss function;mathematical optimization;neural networks;optical flow;rendering (computer graphics);statistical model	Alexander G. Anderson;Cory P. Berg;Daniel P. Mossing;Bruno A. Olshausen	2016	CoRR		computer science;rendering (computer graphics);artificial neural network;machine learning;convolutional neural network;statistical model;artificial intelligence;computer vision;optical flow	Vision	25.336952468016342	-53.57193723099765	27762
8f52d8642b9226449af93bbbba6c5456a8d55303	sobt-rfw: rough-fuzzy computing and wavelet analysis based automatic brain tumor detection method from mr images	fuzzy set;segmentation;clustering;rough sets;brain tumor detection;wavelets	One of the important problems in medical diagnosis is the seg mentation and detection of brain tumor in MR images. The accurate estimation of brain tumor size is important for treatment planning and therapy evaluation. In this regard, this p aper presents a new method, termed as SoBT-RFW, for segmentation of brain tumor from MR images. It integrates judiciously the merits of rough-fuzzy computing and multiresolution image analysis technique. The proposed method starts with a simple skull stripping algorithm to remove non-cereb ral tissues such as skull, scalp, and dura from brain MR images. To extract the scale-space feature vec tor for each pixel of brain region, the dyadic wavelet analysis is used, while an unsupervised feat ur selection method, based on maximum relevance-maximum significance criterion, is used to se lect relevant and significant textural features for brain tumor segmentation. To address the uncer tainty problem of brain MR image segmentation, the proposed SoBT-RFW method uses the robust rou gh-fuzzyc-means algorithm. After the segmentation process, asymmetricity is analyzed by usi ng the Zernike moments of each of the tissues segmented in the brain to identify the tumor. Finall y, the location of the tumor is searched by a region growing algorithm based on the concept of rough se ts. The performance of the proposed SoBT-RFW method, along with a comparison with related appro aches, is demonstrated on a set of synthetic and real brain MR images using standard validity i ndices.	cluster analysis;dyadic transformation;embedded system;energy (psychological);feature selection;fuzzy clustering;fuzzy logic;image analysis;image segmentation;mathematical morphology;pixel;region growing;relevance;rough set;scale space;selection algorithm;set theory;synthetic intelligence;tor messenger;video post-processing;wavelet	Pradipta Maji;Shaswati Roy	2015	Fundam. Inform.	10.3233/FI-2015-1293	wavelet;computer vision;rough set;computer science;machine learning;pattern recognition;data mining;fuzzy set;cluster analysis;segmentation	Vision	41.84964566071655	-73.09707677810864	27765
10c9baf32cfec7db9f1ad1638f1f0b269acd7004	hierarchical retinal blood vessel segmentation based on feature and ensemble learning	ensemble learning;random forest;feature learning;convolutional neural network;retinal blood vessel segmentation	Segmentation of retinal blood vessels is of substantial clinical importance for diagnoses of many diseases, such as diabetic retinopathy, hypertension and cardiovascular diseases. In this paper, the supervised method is presented to tackle the problem of retinal blood vessel segmentation, which combines two superior classifiers: Convolutional Neural Network (CNN) and Random Forest (RF). In this method, CNN performs as a trainable hierarchical feature extractor and ensemble RFs work as a trainable classifier. By integrating the merits of feature learning and traditional classifier, the proposed method is able to automatically learn features from the raw images and predict the patterns. Extensive experiments have been conducted on two public retinal images databases (DRIVE and STARE), and comparisons with other major studies on the same database demonstrate the promising performance and effectiveness of the proposed method. & 2014 Elsevier B.V. All rights reserved.	convolutional neural network;database;ensemble learning;experiment;feature learning;radio frequency;random forest;randomness extractor;statistical classification	Shuangling Wang;Yilong Yin;Guibao Cao;Benzheng Wei;Yuanjie Zheng;Gongping Yang	2015	Neurocomputing	10.1016/j.neucom.2014.07.059	random forest;feature learning;computer vision;computer science;machine learning;pattern recognition;ensemble learning;convolutional neural network	AI	31.87778104616476	-75.37753040910138	27781
d256a89ebeb056dc11110d1e2f0ddb09a71a71e3	appearance indexing	database indexing;unsupervised learning;image texture;approximation theory;statistical analysis;image representation;content based retrieval;image retrieval	Although it is very hard to quantify the visual impression of an image, we conjecture that the overall visual appearance of an image may be the combined effect of the appearances of image patches of various shapes and sizes. We can imagine that all possible appearances of image patches of all possible shapes and sizes form a conceptual appearance space. Each point in the appearance space therefore corresponds to a certain combination of the object parameters (shape, size, surface texture, pose, orientation, etc) and the imaging conditions (illuminating source, viewing angle, sensor response etc.). Using real sensor data and unsupervised learning, statistically most representative appearance prototypes can be found to approximate the appearance space. Statistics of these appearance prototypes present in an image therefore characterize the image content, which in turn can be used to perform tasks such as content-based image retrieval.	approximation algorithm;content-based image retrieval;unsupervised learning;viewing angle	Guoping Qiu	2003		10.1109/ICASSP.2003.1199545	unsupervised learning;image texture;database index;computer vision;feature detection;active appearance model;visual word;image processing;image retrieval;computer science;machine learning;pattern recognition;mathematics;automatic image annotation;statistics;approximation theory	Vision	39.15600781279872	-57.50576275129955	27823
513e3a8b0440a02ef7272a8f15535291e682ed0c	vehicle detection and counting for complex weather conditions		There are many techniques used in moving objects detection. Post processing steps including setting an appropriate threshold to differentiate between the foreground and background have a big effect in increasing the detection rate accuracy of these techniques. However, up till now finding an appropriate threshold that is able to adapt itself particularly in scenes with poor visibility has not been very successful. In this paper, a new adaptive threshold algorithm based on the triangle threshold method is proposed. Together with the background modeling based on the approximate median filter, the triangle threshold is applied over the difference histogram between the current frame and the background model. Finally, morphological operations and counting are applied. We show that the triangle threshold can efficiently differentiate between foreground and background in urban roads under different weather conditions (i.e. fog and snowfall). Comparisons between the proposed method and adaptive local threshold (ALT) show the potential of our approach. The experimental results show that the proposed method has better detection rate compared to ALT while maintaining similar processing time.	approximation algorithm;background subtraction;mathematical morphology;median filter;negative base;thresholding (image processing)	Mohamed A. El-Khoreby;Syed Abd. Rahman Abu-Bakar	2017	2017 IEEE International Conference on Signal and Image Processing Applications (ICSIPA)	10.1109/ICSIPA.2017.8120648	computer vision;visibility;artificial intelligence;pattern recognition;computer science;median filter;brightness;thresholding;histogram;background subtraction	Vision	40.18209961818374	-65.7237528756764	27830
f8cd5359c74da8e735c95ca82800ac7a948ac433	design of a statistical model of brain shape	nuclear magnetic resonance imaging;variabilidad;medical imagery;systeme nerveux central;concepcion sistema;analisis estructural;statistical shape model;analisis forma;estudio comparativo;morfometria;deformability;encefalo;statistical model;morphometry;imageria rmn;etude comparative;sistema nervioso central;encephale;system design;deformabilite;deformabilidad;comparative study;modele statistique;imagerie medicale;modelo estadistico;imagerie rmn;pattern analysis;imageneria medical;analyse structurale;variability;structural analysis;variabilite;conception systeme;central nervous system;morphometrie;analyse forme;brain vertebrata	This paper describes a statistical shape model of the brain extending through the whole organ. The variability in a normal population is described by global deformation modes. The model is based on the analysis of homologous deformations mapping similar structures in brain images.	homology (biology);spatial variability;statistical model;statistical shape analysis	Lionel Le Briquer;James C. Gee	1997		10.1007/3-540-63046-5_46	active shape model;statistical model;central nervous system;morphometrics;comparative research;mathematics;structural analysis;statistics;systems design	Vision	45.61522254098135	-79.20709065732787	27842
0d638189056021ce3e9934fdd6f0499daf8be57c	connected segmentation tree — a joint representation of region layout and hierarchy	object representation;unsupervised learning;connected segmentation tree;image recognition;spatial adjacency;learning algorithm;image segmentation;unsupervised learning computational geometry image matching image representation image segmentation trees mathematics;object segmentation tree;image matching;training;cst graph representations connected segmentation tree joint representation region layout object representation spatial adjacency containment properties object segmentation tree inter region neighbor links recursive embedding structure region adjacency graphs voronoi diagram point patterns unsupervised learning;computational geometry;layout;trees mathematics;graph matching;region adjacency graph;cst graph representations;computational modeling;image edge detection;image representation;containment properties;pixel;graph representation;point patterns;inter region neighbor links;region layout;region adjacency graphs;joint representation;voronoi diagram;image segmentation tree graphs photometry image recognition sociotechnical systems encoding object segmentation unsupervised learning image edge detection solid modeling;recursive embedding structure	This paper proposes a new object representation, called connected segmentation tree (CST), which captures canonical characteristics of the object in terms of the photometric, geometric, and spatial adjacency and containment properties of its constituent image regions. CST is obtained by augmenting the objectpsilas segmentation tree (ST) with inter-region neighbor links, in addition to their recursive embedding structure already present in ST. This makes CST a hierarchy of region adjacency graphs. A regionpsilas neighbors are computed using an extension to regions of the Voronoi diagram for point patterns. Unsupervised learning of the CST model of a category is formulated as matching the CST graph representations of unlabeled training images, and fusing their maximally matching subgraphs. A new learning algorithm is proposed that optimizes the model structure by simultaneously searching for both the most salient nodes (regions) and the most salient edges (containment and neighbor relationships of regions) across the image graphs. Matching of the category model to the CST of a new image results in simultaneous detection, segmentation and recognition of all occurrences of the category, and a semantic explanation of these results.	algorithm;parse tree;recursion;unsupervised learning;voronoi diagram	Narendra Ahuja;Sinisa Todorovic	2008	2008 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2008.4587626	unsupervised learning;layout;computer vision;voronoi diagram;computational geometry;computer science;machine learning;pattern recognition;mathematics;geometry;graph;image segmentation;computational model;pixel;matching	Vision	43.873567289526854	-56.12251458287419	27847
6b165ee1a807e435b9e31f7e225b0eee96c31f7e	recognition of leaf image set based on manifold-manifold distance	plant leaves classification;phog descriptor;manifold manifold distance;leaf image set	Recognizing plant leaves has been a difficult and important work. In this paper, we formulate the problems by classifying leaf image sets rather than single-shot image, each of set contains leaf images pertaining to the same class. We extract leaf image feature and compute the distance between two manifolds modeled by leaf images. Specifically, we apply a clustering procedure in order to express a manifold by a collection of local linear models. Then the distance is measured between local models which come from different manifolds that constructed above. Finally, the problem is transformed to integrate the distance between pairs of subspace. Experiment based on the leaves (ICL) from intelligent computing laboratory of Chinese academy of sciences, which shows that the method has a great performance.		Ji-Xiang Du;Mei-Wen Shao;Chuan-Min Zhai;Jing Wang;Yuan Yan Tang;C. L. Philip Chen	2016	Neurocomputing	10.1016/j.neucom.2014.10.113	topology;machine learning;mathematics;geometry	Vision	34.666495860756605	-53.1209790016324	27871
b3cbc531eb09599736d9b8bef9930dfc26472386	image-asssited system for the diagnosis of bladder tumor recurrence	bladder image segmentation tumors biomedical imaging cancer retina bifurcation;bladder tumour recurrence characterization image asssited system bladder tumor recurrence diagnosis mor phometric property detection bladder mucosa images cystoscope tumour recurrence probability illumination problems vessel segmentation algorithm bifurcation number vascular tree vessel bladder area ration specific objective;tumours bifurcation biomedical optical imaging blood vessels endoscopes image segmentation medical image processing	This paper presents a system for detecting mor-phometric properties of bladder mucosa images obtained with a cystoscope. These properties are calculated for obtaining information about the probability of tumour recurrence. For this purpose, illumination problems of these images have been corrected to apply a vessels segmentation algorithm. Finally, the number of bifurcations of the vascular tree and a ratio Vessels/Bladder area are calculated to validate the hypothesis mentioned above. This validation is carried out with 20 images of bladder mucosa obtaining very promising results, in particular the presented algorithm achieves a sensibility of 0.8571 and a specificity of 1. Consequently, the system proposed in this paper shows valuable properties for the specific objective pointed, i.e, the characterization of the bladder tumour recurrence.	algorithm;bifurcation theory;recurrence relation;sensitivity and specificity;sensor	Nuria Urena;Fernando López-Mir;Sandra Morales;Valery Naranjo;Jose Luis Ruiz-Cerda	2014	IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)	10.1109/BHI.2014.6864324	pathology;mathematics;anatomy;surgery	Robotics	37.56666001430829	-77.10410981017989	27883
335db1b5f5b6e5605bb605a1d1981751d1e64ef9	data processing and pattern recognition in high-throughput capillary electrophoresis		A specific method for massive Capillary Electrophoresis data analysis based on pattern recognition techniques in the wavelet domain is presented. Low-resolution, denoised electropherograms are obtained by applying several pre-processing algorithms including discrete wavelet transform, denoising, detection of region of interest and baseline correction. The resultant signal is mapped into multi-character sequences exploiting the first derivative information and multi-level peak height quantization. Next, local alignment algorithms are applied on the coded sequence for peak pattern recognition. Finally, Gaussian approximation is performed to assure precise peak-height measurements.	approximation;baseline (configuration management);discrete wavelet transform;electropherogram;gaussian elimination;high-throughput computing;instrumentation amplifier;noise reduction;pattern recognition;preprocessor;region of interest;resultant;run time (program lifecycle phase);sensor;smith–waterman algorithm;throughput	Gerardo A. Ceballos;Jose L. Paredes;Luis Hernández	2009	2009 17th European Signal Processing Conference		mathematical optimization;pattern recognition;mathematics;statistics	Vision	38.557546122306455	-72.84069462062006	27895
8d70425c1c1c593f93ed660227e35ee5087de3a9	automated detection of lung nodules in chest radiographs using a false-positive reduction scheme based on template matching	image segmentation;cancer;image matching;lung;visual databases cancer diagnostic radiography image matching image segmentation lung medical image processing;medical image processing;frequency 3 3 ghz lung nodule automated detection false positive reduction scheme lung cancer diagnosis chest radiography automated nodule detection technique initial nodule candidate detection false positive reduction template matching technique jsrt database public database nodule candidate detection scheme sensitivity value lung segmentation data sets intel pc time 5 1 s;template matching computer aided diagnosis chest radiographs nodule detection false positive reduction;diagnostic radiography;visual databases	Automated detection of lung nodules in chest radiographs is important to reduce false negatives in the diagnoses of lung cancers using chest radiography. The automated nodule detection techniques consist of two steps of initial nodule candidate detection and false positive reduction. In this paper we propose an improved scheme for each of these steps. The proposed false-positive reduction scheme uses template matching technique. As the result of experiments using 125 images with nodules in the JSRT database which is a public database, the proposed nodule-candidate detection scheme gave sensitivity of 96% with 136.5 false positives per image. For evaluation of the total performance of the proposed nodule detection scheme, we created 40 date sets by 40 randomized selection of 80 training images and 45 test images from the 125 images with nodules in the JSRT database. As the result of experiments using these 40 data sets, the proposed nodule detection scheme gave 9.5, 12.5, and 13.8 false positives per image for sensitivity values of 60.2, 69.8, and 74.5% on the average of 40 data sets. The time needed by the proposed nodule detection scheme, excluding the time needed by lung segmentation, was 5.1 seconds per image on the average of 40 data sets using a 3.3GHz Intel PC.	database;experiment;performance evaluation;radiography;randomized algorithm;silicon controlled rectifier;template matching	Ryo-ichi Nagata;Tsuyoshi Kawaguchi;Hidetoshi Miyake	2012	2012 5th International Conference on BioMedical Engineering and Informatics	10.1109/BMEI.2012.6512916	computer vision;radiology;medicine;pathology;computer science;image segmentation;cancer	Vision	36.86107489550281	-77.0200799867117	27913
a29dd97c9990e3b0fe329193132c7f510c840e64	textline detection in degraded historical document images	historical documents;handwritten documents;document image binarization;textline detection	This paper presents a textline detection method for degraded historical documents. Our method follows a conventional two-step procedure that the binarization is first performed and then the textlines are extracted from the binary image. In order to address the challenges in historical documents such as document degradation, structure noise, and skews, we develop new methods for the binarization and textline extraction. First, we improve the performance of binarization by detecting the non-text regions and processing only text regions. We also improve the textline detection method by extracting main textblock and compensating the skew angle and writing style. Experimental results show that the proposed method yields the state-of-the-art performance for several datasets.	binary image;elegant degradation;historical document;sensor	Byeongyong Ahn;Jewoong Ryu;Hyung Il Koo;Nam Ik Cho	2017	EURASIP J. Image and Video Processing	10.1186/s13640-017-0229-7	artificial intelligence;pattern recognition;writing style;computer vision;skew;computer science;historical document;biometrics;binary image	Web+IR	37.26737957819754	-65.87960782326034	27936
ad4e86642dc05fe2a1e1ddf5c5b72d1c53306be8	segmenting endoscopic images using adaptive progressive thresholding: a hardware perspective	processing element;metodo adaptativo;endoscopia;image segmentation;image processing;threshold detection;linear antenna;adaptive progressive tresholding;adaptive progressive thresholding;real time;endoscopy;linear array;procesamiento imagen;antenne lineaire;methode adaptative;segmentation;antena lineal;traitement image;detection seuil;vecino mas cercano;deteccion umbral;endoscopic images;adaptive method;segmentation image;plus proche voisin;nearest neighbour;endoscopie;computer hardware;high performance;materiel informatique;material informatica	Hardware realization of a novel technique based on adaptive progressive thresholding (APT) for the real-time segmentation of endoscopic images is presented. The APT algorithm is mapped onto a linear array of processing elements with each element of a particular segment communicating with its nearest neighbours. The efficiency and hardware portability of this technique justifies its use in applications that require high performance in realtime. 2002 Elsevier Science B.V. All rights reserved.	algorithm;charge-coupled device;real-time clock;real-time computing;thresholding (image processing)	Vijayan K. Asari;Thambipillai Srikanthan	2002	Journal of Systems Architecture	10.1016/S1383-7621(01)00027-3	computer vision;speech recognition;image processing;computer science;image segmentation;segmentation;computer graphics (images)	Graphics	47.224234564904364	-63.6857493594151	27954
3103cf5b85129dc32a25f606557b9863f2943fe6	efficient retrieval of similar time sequences under time warping	time warp;sequence data;synthetic datasets similar time sequence retrieval time warping fast similarity searching large time sequence databases euclidean distance dissimilarity metric local accelerations decelerations field tested dissimilarity metric indexing viewpoint sequence length fastmap fast linear test sequential scanning;time warping;database;field test;euclidean distance;feature space;intelligent signal processing;indexing;feature extraction;indexation;communications systems;databases indexing pattern matching speech recognition discrete fourier transforms computer science educational institutions application software acceleration testing;temporal databases;technical report;similarity matching;spatial access method;similarity search	"""Fast similarity searching in large time-sequence databases has attracted a lot of research interest 1, 5, 2, 6, 3, 10]. All of them use the Euclidean distance (L 2), or some variation of L p metrics. L p metrics lead to eecient indexing, thanks to feature extraction (e.g., by keeping the rst few DFT coeecients) and subsequent use of fast spatial access methods for the points in feature space. In this work we examine a popular, eld-tested dissimilarity function, the \time warping"""" distance function which permits local accelerations and decelerations in the rate of the signals or sequences. This function is natural and suitable for several applications, like matching of voice, audio and medical signals (e.g., electrocardiograms) However, from the indexing viewpoint it presents two major challenges: (a) it does not lead to any natural \features"""", precluding the use of spatial access methods (b) it is quadratic (O(len 1 len 2)) on the length of the sequences involved. Here we show how to overcome both problems: for the former, we propose using a modiication of the so-called \FastMap"""", to map sequences into points, trading oo a tiny amount of \recall"""" (typically zero) for large gains in speed. For the latter, we provide a fast, linear test, to help us discard quickly many of the false alarms that FastMap will typically introduce. Using both ideas in cascade, our proposed method consistently outperformed the straightforward sequential scanning on both real and synthetic datasets and achieved up to 7.8-time speed-up (780%)."""	algorithm;database;dhrystone;emoticon;euclidean distance;feature extraction;feature vector;random indexing	Byoung-Kee Yi;H. V. Jagadish;Christos Faloutsos	1998		10.1109/ICDE.1998.655778	search engine indexing;feature vector;feature extraction;computer science;technical report;machine learning;dynamic time warping;pattern recognition;data mining;euclidean distance;database;temporal database;communications system	DB	40.792733208479035	-58.92113133793083	27997
0b0bfec24a27f2e8c8d5a5e94afc23da90097b06	a generalized logarithmic image processing model based on the gigavision sensor model	linear systems;tone mapping;histograms;image processing;sensor model;computer graphics;edge detection;image tone mapping;model generation;image dehazing logarithmic image processing gigavision sensor model statistical model generalized lip model glip model image representation gvs scalar multiplication tone mapping energy preserving algorithm;logarithmic image processing lip model;gigavision sensor gvs model;linear system;statistical model;computer vision;linear operator;statistical analysis;numerical model;image edge detection;image edge detection mathematical model linear systems transforms histograms numerical models;image representation;logarithmic image processing lip model generalized linear system gls gigavision sensor gvs model image tone mapping;transforms;mathematical model;generalized linear system gls;matrix multiplication;statistical analysis computer graphics computer vision image representation matrix multiplication;numerical models;scalar multiplication	The logarithmic image processing (LIP) model is a mathematical theory providing generalized linear operations for image processing. The gigavision sensor (GVS) is a new imaging device that can be described by a statistical model. In this paper, by studying these two seemingly unrelated models, we develop a generalized LIP (GLIP) model. With the LIP model being its special case, the GLIP model not only provides new insights into the LIP model but also defines new image representations and operations for solving general image processing problems that are not necessarily related to the GVS. A new parametric LIP model is also developed. To illustrate the application of the new scalar multiplication operation, we propose an energy-preserving algorithm for tone mapping, which is a necessary step in image dehazing. By comparing with results using two state-of-the-art algorithms, we show that the new scalar multiplication operation is an effective tool for tone mapping.	body dysmorphic disorders;choose (action);color space;data domain;default;generalized least squares;hl7publishingsubsection <operations>;image processing;imaging device;license;matlab;mathematics;multiplication;population parameter;sensor;statistical model;temperature:temp:pt:transcutaneous monitor sensor:qn;tone mapping;algorithm	Guang Deng	2012	IEEE Transactions on Image Processing	10.1109/TIP.2011.2166970	computer vision;speech recognition;image processing;computer science;theoretical computer science;machine learning;mathematics;linear system;statistics	Vision	52.14030676659611	-73.50189369288454	28009
bf9ede62dd3f8f4db4112750f64dfedca4504183	enhanced auto coloring with hierarchical region matching	hierarchy;auto coloring;2d animation;region matching	Abstract#R##N##R##N#This paper proposes a Hierarchical Region Matching (HRM) approach for computer-assisted auto coloring. The region-level analysis in traditional 2D animation is expanded into several component levels with a novel hierarchization method. With the hierarchy, various region matching algorithms can be applied from the first/highest to the last/lowest component level. HRM improves the matching accuracy and may deal with matching errors caused by occlusion, thus making the matching more robust, as verified by the results. Copyright © 2005 John Wiley & Sons, Ltd.	graph coloring	Jie Qiu;Seah Hock Soon;Feng Tian;Quan Chen;Zhongke Wu	2005	Journal of Visualization and Computer Animation	10.1002/cav.86	anime;computer science;artificial intelligence;algorithm;hierarchy	Visualization	37.54857938886472	-57.151635784315	28023
7bc3783d38b9b5070f658af85bba8470eebb1b8c	fraud detection in water meters using pattern recognition techniques		Water supply utilities have been increasingly looking for solutions to reduce water wastage. Many efforts have been made aiming to promote a better management of this resource. Fraud detection is one of these actions, as the irregular violations are usually held precariously, thus, causing leaks. In this context, the use of technology in order to automate the identification of potential frauds can be an important support tool to avoid water waste. Thus, this research aims to apply pattern recognition techniques in the implementation of an automated detection of suspected irregularities cases in water meters, through image analysis. The proposed computer vision system is composed of three steps: the detection of the water meter location, obtained by OPF classifier and HOG descriptor, detecting the seals through morphological image processing and segmentation methods; and the classification of frauds, in which the condition of the water meter seals is assessed. We validated the proposed framework using a dataset containing images of water meter inspections. At the last step, the proposed framework reached an average accuracy up to 81.29%. We concluded that a computer vision system is a promising strategy and has potential to benefit the analysis of fraud detection.	computer vision;image analysis;image processing;mathematical morphology;pattern recognition;sensor;software inspection	Juliana Patrícia Detroz;André Tavares da Silva	2017		10.1145/3019612.3019634	image processing;data mining;object detection;metre (music);water supply;computer science;artificial intelligence;pattern recognition	Vision	36.44247674000289	-70.37568491191205	28038
995bdec423a3cf86fbb0ef40efd9e4df6b0cab9e	enhancing cbir through feature optimization, combination and selection	image sampling;image features;optimisation;image resolution;statistical optimization;support vector machines;image databases;information retrieval;corel image collection content based image retrieval method image features statistical optimization similarity distance support vector machines;qa75 electronic computers computer science;feedback;statistical analysis;similarity distance;spatial databases;corel image collection;support vector machine;content based image retrieval;content based retrieval;z665 library science information science;support vector machines content based retrieval image retrieval optimisation statistical analysis;content based image retrieval method;image databases optimization methods image retrieval content based retrieval support vector machines spatial databases information retrieval image resolution feedback image sampling;optimization methods;image retrieval	We present a content-based image retrieval (CBIR) method based on the combination and selection of several image features. The novelty of our approach over existing methods is threefold: we provide a statistical optimization of the similarity distance for each feature; we replace certain features by a selection in a non-linear expansion of them; and we perform a linear combination of the features. We demonstrate superior capabilities of our method in certain cases over support vector machines (SVM) on a COREL image collection.	content-based image retrieval;mathematical optimization;nonlinear system;semantic similarity;support vector machine	Xavier Hilaire;Joemon M. Jose	2007	2007 International Workshop on Content-Based Multimedia Indexing	10.1109/CBMI.2007.385421	support vector machine;computer vision;image retrieval;computer science;machine learning;pattern recognition;information retrieval	Vision	39.16814651805559	-61.81898692209941	28061
60c187899d814956f51b1b52657897d0eeafa12d	a single tooth segmentation using pca-stacked gabor filter and active contour			active contour model;contour line;gabor filter	Pramual Choorat;Werapon Chiracharit;Kosin Chamnongthai;Takao Onoye	2013	IEICE Transactions		computer vision;pattern recognition	Vision	41.58128897194149	-71.70678394068659	28082
64e58f62c4c700802c91ba8bfc7fc7b2071275be	image warping using few anchor points and radial functions	mimica;facial expressions;image processing;gauchissement;mimique;procesamiento imagen;traitement image;radial basis function;transformation lineaire;torcimiento;normalization;linear transformation;facial expression;local support;warping;transformacion lineal;image warping;radial basis functions	Transformations based on radial basis functions have proven to be a powerful tool in image warping. In the present work we decompose these transformations into linear and radial terms, and show examples where such a decomposition is advantageous. Locally supported basis functions are introduced. Several applications are demonstrated, and a comparison with other warping techniques is carried out. Finally, some ne points of image warping are discussed.	image warping;ne (complexity);radial (radio);radial basis function	Nur Arad;Daniel Reisfeld	1995	Comput. Graph. Forum	10.1111/1467-8659.1410035	image warping;computer vision;radial basis function;topology;image processing;computer science;machine learning;mathematics;geometry;facial expression	EDA	50.934747207022816	-62.30698394397663	28097
584a0cb0d7d70673067daef9e473cca381e10ef2	off-line arabic character recognition – a review	electronic media;modelo markov oculto;preprocessing segmentation;image segmentation;neural networks;fourier transform;arabic ocr;modele markov cache;hidden markov model;optical character recognition;extraction forme;off line;vertical projection;forma geometrica;temporal information;reconnaissance caractere;hidden markov models;arabic;extraccion forma;fourier transformation;reconocimiento grafico;feature extraction;geometrical shape;segmentation image;horizontal projection;transformation fourier;reconocimento optico de caracteres;pattern recognition;forme geometrique;hough transform;arabe;reconnaissance graphique;reconnaissance forme;information system;off line recognition;reseau neuronal;reconocimiento patron;fuera linea;character recognition;pattern extraction;red neuronal;systeme information;reconocimiento caracter;graphical recognition;reconnaissance optique caractere;neural network;transformacion fourier;hors ligne;sistema informacion	Off-line recognition requires transferring the text under consideration into an image file. This represents the only available solution to bring the printed materials to the electronic media. However, the transferring process causes the system to lose the temporal information of that text. Other complexities that an off-line recognition system has to deal with are the lower resolution of the document and the poor binarisation, which can contribute to readability when essential features of the characters are deleted or obscured. Recognising Arabic script presents two additional challenges: orthography is cursive and letter shape is context sensitive. Certain character combinations form new ligature shapes, which are often font-dependent. Some ligatures involve vertical stacking of characters. Since not all letters connect, word boundary location becomes an interesting problem, as spacing may separate not only words, but also certain characters within a word. Various techniques have been implemented to achieve high recognition rates. These techniques have tackled different aspects of the recognition system. This review is organised into five major sections, covering a general overview, Arabic writing characteristics, Arabic text recognition system, Arabic OCR software and conclusions.	comparison of optical character recognition software;context-sensitive grammar;feature extraction;image file formats;image segmentation;online and offline;preprocessor;printing;stacking;statistical classification;vertical market software	Mohammad S. Khorsheed	2002	Pattern Analysis & Applications	10.1007/s100440200004	fourier transform;computer vision;speech recognition;computer science;machine learning;artificial neural network;hidden markov model	HCI	34.32476330406605	-67.18912534349627	28159
4afe1ecd065ee2d6922c3c0e60d41a90aaf07a4c	retinal image classification using a histogram based approach	saturation histograms;histograms;histogram based representation;eye;green histograms;retinal blood vessels;case base reasoning;biometrics access control;optic disc retinal image classification histogram based representation case based reasoning age related macular degeneration time series analysis dynamic time warping green histograms saturation histograms retinal blood vessels;image classification;time series;blood vessel;evaluation metric;optical imaging;time series analysis;age related macular degeneration;image color analysis;image colour analysis;image representation;pixel;retinal image classification;diseases;histograms image color analysis time series analysis pixel optical imaging retinal vessels;case based reasoning;time series biometrics access control case based reasoning diseases eye image classification image colour analysis image representation;retinal vessels;dynamic time warping;retinal imaging;optic disc	An approach to classifying retinal images using a histogram based representation is described. More specifically, a two stage Case Based Reasoning (CBR) approach is proposed, to be applied to histogram represented retina images to identify Age-related Macular Degeneration (AMD). To measure the similarity between histograms, a time series analysis technique, Dynamic Time Warping (DTW), is employed. The advocated approach utilises two “case bases” for the classification process. The first case base consists of green and saturation histograms with retinal blood vessels removed. The second case base comprises the same histograms, but with the Optic Disc (OD) removed as well. The reported experiments demonstrate that the proposed two stage classification process outperforms the single stage classification process with respect to a number of evaluation metrics: specificity, sensitivity and accuracy.	case-based reasoning;computer vision;dynamic time warping;evaluation function;experiment;image segmentation;matched filter;preprocessor;saturation arithmetic;sensitivity and specificity;time series	Mohd. Hanafi Ahmad Hijazi;Frans Coenen;Yalin Zheng	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596320	computer vision;computer science;histogram matching;time series;mathematics;statistics;computer graphics (images)	Vision	34.83312848040495	-74.44147927296112	28204
96fe009d7e400eaba6a18bcb5d33ca7a597d4f7b	automated ground-based cloud recognition	analisis coocurrencia;analisis imagen;autocorrelation function;object recognition;vision ordenador;air traffic control;analyse cooccurrence;texture image;extraction forme;classifier system;natural images;condicion meteorologica;reconnaissance objet;neural network classifier;texture features;cooccurrence analysis;atmospheric condition;condition meteorologique;image texture;funcion autocorrelacion;computer vision;extraccion forma;fonction autocorrelation;feature extraction;regulation trafic aerien;pattern recognition;image analysis;vision ordinateur;k nearest neighbour;reconnaissance forme;extraction caracteristique;reseau neuronal;reconocimiento patron;analyse image;pattern extraction;red neuronal;reconnaissace nuage;neural network	Recognition of naturally occurring objects is a challenging task. In particular, the recognition of clouds is particularly challenging as the texture of such objects is extremely variable under different atmospheric conditions. There are several benefits of a practical system that can detect and recognise clouds in natural images especially for applications such as air traffic control. In this paper, we test well-known texture feature extraction approaches for automatically training a classifier system to recognise cumulus, towering cumulus, cumulo-nimbus clouds, sky and other clouds. For cloud recognition, we use a total of five different feature extraction methods, namely autocorrelation, co-occurrence matrices, edge frequency, Law’s features and primitive length. We use the k-nearest neighbour and neural network classifiers for identifying cloud types in test images. This exhaustive testing gives us a better understanding of the strengths and limitations of different feature extraction methods and classification techniques on the given problem. In particular, we find that no single feature extraction method is best suited for recognising all classes. Each method has its own merits. We discuss these merits individually and suggest further improvements in this difficult area.	artificial neural network;autocorrelation;co-occurrence matrix;cumulus;feature extraction;k-nearest neighbors algorithm;learning classifier system;statistical classification	Maneesha Singh;Matt Glennen	2005	Pattern Analysis and Applications	10.1007/s10044-005-0007-5	image texture;computer vision;image analysis;autocorrelation;feature extraction;computer science;artificial intelligence;air traffic control;cognitive neuroscience of visual object recognition;machine learning	ML	42.39286449599436	-62.90570316804785	28219
d1663a30ecf3516f82520fe5dba3d138180325f5	a linear discriminant analysis framework based on random subspace for face recognition	reconnaissance visage;evaluation performance;base donnee;procesamiento informacion;high dimensionality;performance evaluation;image processing;small sample size;integration information;biometrie;random sampling;evaluacion prestacion;biometrics;database;biometria;procesamiento imagen;base dato;useful information;informacion util;metodo subespacio;data fusion;linear discriminate analysis;traitement image;methode sous espace;discriminant analysis;analyse discriminante;analisis discriminante;information integration;automatic recognition;lda;face recognition;random subspace;fusion donnee;muestreo aleatorio;information processing;integracion informacion;pattern recognition;subspace method;information fusion;reconnaissance forme;reconocimiento patron;traitement information;fusion datos;echantillonnage aleatoire;principal subspace;information utile;reconocimiento automatico;reconnaissance automatique	Linear Discriminant Analysis (LDA) often suffers from the small sample size problem when dealing with high dimensional face data. Random subspace can effectively solve this problem by random sampling on face features. However, it remains a problem how to construct an optimal random subspace for discriminant analysis and perform the most efficient discriminant analysis on the constructed random subspace. In this paper, we propose a novel framework, Random Discriminant Analysis (RDA), to handle this problem. Under the most suitable situation of the principal subspace, the optimal reduced dimension of the face sample is discovered to construct a random subspace where all the discriminative information in the face space is distributed in the two principal subspaces of the within-class and between-class matrices. Then we apply Fisherface and Direct LDA respectively to the two principal subspaces for simultaneous discriminant analysis. The two sets of discriminant analysis features from dual principal subspaces are first combined at the feature level, and then all the random subspaces are further integrated at the decision level. With the discriminating information fusion at the two levels, our method can take full advantage of useful discriminant information in the face space. Extensive experiments on different face databases demonstrate its performance. Key Word: LDA, Random Subspace, Principal Subspace	effi;experiment;face space;facial recognition system;linear discriminant analysis;monte carlo method;random-access memory;remote database access;sampling (signal processing)	Xiaoxun Zhang;Yunde Jia	2007	Pattern Recognition	10.1016/j.patcog.2006.12.002	random subspace method;sampling;computer vision;kernel fisher discriminant analysis;speech recognition;information processing;image processing;computer science;information integration;machine learning;pattern recognition;optimal discriminant analysis;mathematics;sensor fusion;linear discriminant analysis;multiple discriminant analysis;biometrics	Vision	44.30988020633379	-60.081142085656616	28233
10e960c916971d1530676e183cb76a408ac2c682	medical image segmentation using improved fcm	image segmentation;fcm histogram image segmentation medical image processing;journal;histogram;medical image processing;fcm	Image segmentation is one of the most important problems in medical image processing, and the existence of partial volume effect and other phenomena makes the problem much more complex. Fuzzy C-means, as an effective tool to deal with PVE, however, is faced with great challenges in efficiency. Aiming at this, this paper proposes one improved FCM algorithm based on the histogram of the given image, which will be denoted as HisFCM and divided into two phases. The first phase will retrieve several intervals on which to compute cluster centroids, and the second one will perform image segmentation based on improved FCM algorithm. Compared with FCM and other improved algorithms, HisFCM is of much higher efficiency with satisfying results. Experiments on medical images show that HisFCM can achieve good segmentation results in less than 0.1 second, and can satisfy real-time requirements of medical image processing.	algorithm;experiment;fuzzy cognitive map;image processing;image segmentation;medical imaging;real-time locating system;requirement	Xiaofeng Zhang;Caiming Zhang;Wenjing Tang;ZhenWen Wei	2012	Science China Information Sciences	10.1007/s11432-012-4556-0	image texture;computer vision;feature detection;computer science;segmentation-based object categorization;pattern recognition;data mining;histogram;mathematics;region growing;image segmentation;scale-space segmentation;statistics;image histogram	Vision	42.52985900774574	-72.81986014514877	28258
94cca377829c60a8ad78ca29c6282f1bc01df4a8	an information theoretic framework for image segmentation	imatges segmentacio;bottom up;telecommunication channels image segmentation greedy algorithms image colour analysis;image segmentation;image processing;top down;imaging segmentation;greedy algorithms;info eu repo semantics article;imatges processament;image colour analysis;mutual information;computer algorithms;algorismes computacionals;telecommunication channels;image segmentation partitioning algorithms clustering algorithms histograms image processing entropy random variables chaos quantization merging;information theoretic;image colour analysis image segmentation information channel image intensity histogram image partitioning mutual information greedy top down algorithm histogram quantization algorithm	In this paper, an information theoretic framework for image segmentation is presented. This approach is based on the information channel that goes from the image intensity histogram to the regions of the partitioned image. It allows us to define a new family of segmentation methods which maximize the mutual information of the channel. Firstly, a greedy top-down algorithm which partitions an image into homogeneous regions is introduced. Secondly, a histogram quantization algorithm which clusters color bins in a greedy bottom-up way is defined. Finally, the resulting regions in the partitioning algorithm can optionally be merged using the quantized histogram.	bottom-up parsing;color quantization;greedy algorithm;image segmentation;information theory;mutual information;top-down and bottom-up design	Jaume Rigau;Miquel Feixas;Mateu Sbert	2004	2004 International Conference on Image Processing, 2004. ICIP '04.	10.1109/ICIP.2004.1419518	image texture;computer vision;range segmentation;image processing;computer science;histogram matching;machine learning;segmentation-based object categorization;pattern recognition;top-down and bottom-up design;mathematics;region growing;image segmentation;scale-space segmentation;statistics;image histogram	Robotics	44.37822497513837	-67.8170667813775	28283
a9a8bac92be9a48d505ff907dfdb582f42b1b470	image segmentation based on situational dct descriptors	image segmentation;k means;discrete cosine transform;scalar quantization;clustering;principal component analysis;k means algorithm;human vision system;dct	It is of utmost importance in multimedia processing to achieve still image segmentation, i.e., to partition images into regions of coherent color and texture. In this paper we propose a novel image segmentation method using a special visual descriptor. For each pixel p, the discrete cosine transform (DCT) of the block centered on p together with its location in the image is employed as its content descriptor thus resulting in a long vector vp??, referred to as situational DCT descriptors (SDDs). A scalar quantization step is then carried out on the DCT component of SDDs to reflect the fact that the human vision system is not of uniform discriminative sensitivity to details of different frequencies. Next the principal component analysis is conducted to drastically reduce the dimensionality of SDDs. The adaptive K-means algorithm is then performed to arrive at the region assignment for each pixel. The final partitioning results are obtained after performing the post-processing step. Encouraging empirical performance has been demonstrated.	discrete cosine transform;image segmentation	Jie Wei	2002	Pattern Recognition Letters	10.1016/S0167-8655(01)00124-6	computer vision;speech recognition;computer science;machine learning;discrete cosine transform;pattern recognition;mathematics;scale-space segmentation;k-means clustering	Vision	39.90469242731827	-64.0503380105288	28313
fdc10218fdb95594499808010cc9a460f324587f	inherent bias and noise in the hough transform	background noise;histograms;quantization;shape detection histograms hough transform noise suppression pattern recognition;image processing;fluctuations;voting noise shaping noise cancellation shape background noise quantization retina vocabulary pattern recognition discrete transforms;vocabulary;noise suppression;shape detection;arrays;shape;discrete transforms;voting;retina;imaging;noise cancellation;transforms;parameter space;pattern recognition;noise shaping;hough transform;noise	Considering the Hough transformation as a linear imaging process recasts certain well-known problems, provides a useful vocab-ulary, and possibly indicates a source of applicable literature on the behavior of the Hough transformation in various forms of noise. A consideration of the analytic form of peaks in parameter space sets the stage for the idea of using complementary (negative) votes to cancel off-peak positive votes in parameter space, thus sharpening peaks and reducing bias.	hough transform;population parameter;vocabulary	Christopher M. Brown	1983	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1983.4767428	hough transform;computer vision;speech recognition;noise shaping;voting;quantization;image processing;shape;computer science;noise;active noise control;histogram;mathematics;background noise;parameter space	Vision	52.40833155865853	-61.555526100063375	28320
858284ff730c3cc3b2586d8adf19ab49ff38ab60	classification of alzheimer's disease using whole brain hierarchical network	magnetic resonance imaging brain correlation databases dementia;classification alzheimer s disease regions of interest hierarchical network	Regions of interest (ROIs) based classification has been widely investigated for analysis of brain magnetic resonance imaging (MRI) images to assist the diagnosis of Alzheimeru0027s disease (AD) including its early warning and developing stages, e.g., mild cognitive impairment (MCI) including MCI converted to AD (MCIc) and MCI not converted to AD (MCInc). Since an ROI representation of brain structures is obtained either by pre-definition or by adaptive parcellation, the corresponding ROI in different brains can be measured. However, due to noise and small sample size of MRI images, representations generated from single or multiple ROIs may not be sufficient to reveal the underlying anatomical differences between the groups of disease-affected patients and health controls (HC). In this paper, we employ a whole brain hierarchical network (WBHN) to represent each subject. The whole brain of each subject is divided into 90, 54, 14, and 1 regions based on Automated Anatomical Labeling (AAL) atlas. The connectivity between each pair of regions is computed in terms of Pearsonu0027s correlation coefficient and used as classification feature. Then, to reduce the dimensionality of features, we select the features with higher $F-$ scores. Finally, we use multiple kernel boosting (MKBoost) algorithm to perform the classification. Our proposed method is evaluated on MRI images of 710 subjects (200 AD, 120 MCIc, 160 MCInc, and 230 HC) from the Alzheimeru0027s Disease Neuroimaging Initiative (ADNI) database. The experimental results show that our proposed method achieves an accuracy of 94.65 percent and an area under the receiver operating characteristic (ROC) curve (AUC) of 0.954 for AD/HC classification, an accuracy of 89.63 percent and an AUC of 0.907 for AD/MCI classification, an accuracy of 85.79 percent and an AUC of 0.826 for MCI/HC classification, and an accuracy of 72.08 percent and an AUC of 0.716 for MCIc/MCInc classification, respectively. Our results demonstrate that our proposed method is efficient and promising for clinical applications for the diagnosis of AD via MRI images.	atm adaptation layer;adaptive grammar;alzheimer's disease neuroimaging initiative;area under curve;cervical atlas;coefficient;cognition disorders;kernel (operating system);magnetic resonance imaging;mild cognitive disorder;multiple congenital anomalies;network topology;patients;percent (qualifier value);receiver operating characteristic;receiver operator characteristics;region of interest;tree network;algorithm;recurrent childhood brain stem glioma	Jin Liu;Min Li;Wei Lan;Fang-Xiang Wu;Yi Pan;Jianxing Wang	2018	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2016.2635144	receiver operating characteristic;boosting (machine learning);machine learning;sample size determination;artificial intelligence;computer science	ML	30.25462254935174	-78.1030350796229	28374
28b294170130f832fafc08bff955461809c72737	research of flame detection on visual saliency method	kmeans segment;saliency;fft;dbip;flame detection;selective attention;spectral residual	In order to improve the fire detection efficiency of large-scale and complex environment, the paper built a model of flame detection on visual selective attention method. In this model, saliency regions are obtained by Fourier spatial and temporal spectral residual, saliency objects are generated by using a object detection method based on the weight of the color space clustering, and saliency points are found by difference block inverse probability .According to the rules of flame’s color we can judge the risk of fire. The experimental results show that the flame detecting method can find different flames in wild scenes ,and it is very accurate, effective and robust.	cluster analysis;color space;experiment;object detection;sensor	Junling Liu;Hongwei Zhao;Tianjiao Zhao	2013	JCP	10.4304/jcp.8.12.3264-3271	computer vision;fast fourier transform;simulation;attention;salience;computer graphics (images)	Vision	37.52648072316708	-62.835901581007256	28409
a1fc2acab59a4f345ffb6298582f61aae7489e7b	content-based retrieval of medical images by combining global features	content management;busqueda informacion;analisis imagen;radiation dose;utilisation information;anotacion;analisis contenido;filtering;texture;ajustamiento modelo;contenu image;filtrage;medical imagery;uso informacion;categorisation;image content;linguistique;donnee textuelle;distance measure;information use;recherche image;dato textual;information retrieval;filtrado;interrogation base donnee;query refinement;interrogacion base datos;annotation;gestion contenido;classification;ajustement modele;refinement method;histogram;content analysis;categorizacion;linguistica;histogramme;medical image;recherche information;busqueda por contenido;dose rayonnement;model matching;textura;textual data;imagineria medica;imagerie medicale;gestion contenu;image analysis;information system;analyse contenu;methode raffinement;multilinguisme;contenido imagen;histograma;analyse image;metodo afinamiento;deformable model;content based retrieval;database query;clasificacion;systeme information;recherche par contenu;multilingualism;spatial information;dosis irradiacion;multilinguismo;categorization;sistema informacion;image retrieval;linguistics	A combination of several classifiers using global features for the content description of medical images is proposed. Beside well known texture histogram features, downscaled representations of the original images are used, which preserve spatial information and utilize distance measures which are robust with regard to common variations in radiation dose, translation, and local deformation. These features were evaluated for the annotation task and the retrieval task in ImageCLEF 2005 without using additional textual information or query refinement mechanisms. For the annotation task, a categorization rate of 86.7% was obtained, which ranks second among all submissions. When applied in the retrieval task, the image content descriptors yielded a mean average precision (MAP) of 0.0751, which is rank 14 of 28 submitted runs. As the image deformation model is not fit for interactive retrieval tasks, two mechanisms are evaluated with regard to the trade-off between loss of accuracy and speed increase: hierarchical filtering and prototype selection.	categorization;information retrieval;medical imaging;prototype;refinement (computing)	Mark Oliver Güld;Christian Thies;Benedikt Fischer;Thomas Martin Deserno	2005		10.1007/11878773_77	filter;computer vision;visual word;image analysis;content analysis;biological classification;content management;image retrieval;computer science;artificial intelligence;absorbed dose;histogram;spatial analysis;linguistics;texture;information system;statistics;categorization	Vision	43.14710081330361	-61.847322351172345	28418
88706a34e890f1ec1e194e3538b320bc23a52a53	fast unsupervised segmentation of 3d magnetic resonance angiography	turbulent blood flow;image segmentation;laminar blood flow expectation maximization magnetic resonance angiography blood vessels turbulent blood flow;cerebrovascular system unsupervised segmentation 3d magnetic resonance angiography mra images adaptive probabilistic model blood vessel laminar blood flow turbulent blood flow;haemodynamics;unsupervised segmentation;indexing terms;magnetic resonance angiography image segmentation blood flow principal component analysis blood vessels biomedical imaging data mining deformable models probability;blood vessel;laminar blood flow;image segmentation biomedical mri blood vessels haemodynamics haemorheology;expectation maximization;fast algorithm;magnetic resonance angiography;blood flow;magnetic res onance;blood vessels;haemorheology;biomedical mri	A new physically justified adaptive probabilistic model of blood vessels on magnetic resonance angiography (MRA) images is proposed. The model accounts for both laminar (for normal subjects) and turbulent blood flow (in abnormal cases like anemia or stenosis) and results in a fast algorithm for extracting a 3D cerebrovascular system from the MRA data. Experiments with real data sets confirm the high accuracy of the proposed approach.	algorithm;emoticon;radiology;resonance;statistical model;turbulence;xfig	Ayman El-Baz;Aly A. Farag;Georgy L. Gimel'farb;Mohamed Abou El-Ghar;Tarek Eldiasty	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312370	computer vision;index term;expectation–maximization algorithm;computer science;blood flow;machine learning;hemodynamics;image segmentation	Robotics	43.369017483299615	-76.56513468371983	28420
931a5a431eced9c5c410b9bd70cf0b10e0ae5973	constructing the histogram representation for automatic gridding of cdna microarray images	signal intensity;cdna microarray	This paper proposes an novel approach for automatic gridding of cDNA microarray images based on histogram representation. The approach constructs histogram representation to characterize microarray images and use it, instead of raw signal intensities used in previous gridding methods, to identify spots. The histogram representation can efficiently reduce noise and the influence from low raw signal intensities and local contaminations. The proposed approach is successfully tested on different types of microarray images and is compared with several previous algorithms.	dna microarray	Hong-Qiang Wang;Hau-San Wong;Hailong Zhu	2008		10.1007/978-3-540-77413-6_32	computer science;bioinformatics;pattern recognition;data mining	Vision	38.717340398019516	-72.7704027589601	28424
28312c3a47c1be3a67365700744d3d6665b86f22	face recognition: a literature survey	system evaluation;face recognition;law enforcement;general terms algorithms additional face recognition;person identification;image analysis;literature survey;human perception	As one of the most successful applications of image analysis and understanding, face recognition has recently received significant attention, especially during the past several years. At least two reasons account for this trend: the first is the wide range of commercial and law enforcement applications, and the second is the availability of feasible technologies after 30 years of research. Even though current machine recognition systems have reached a certain level of maturity, their success is limited by the conditions imposed by many real applications. For example, recognition of face images acquired in an outdoor environment with changes in illumination and/or pose remains a largely unsolved problem. In other words, current systems are still far away from the capability of the human perception system.This paper provides an up-to-date critical survey of still- and video-based face recognition research. There are two underlying motivations for us to write this survey paper: the first is to provide an up-to-date review of the existing literature, and the second is to offer some insights into the studies of machine recognition of faces. To provide a comprehensive survey, we not only categorize existing recognition techniques but also present detailed descriptions of representative methods within each category. In addition, relevant topics such as psychophysical studies, system evaluation, and issues of illumination and pose variation are covered.	capability maturity model;categorization;facial recognition system;illumination (image);image analysis	Wenyi Zhao;Rama Chellappa;P. Jonathon Phillips;Azriel Rosenfeld	2003	ACM Comput. Surv.	10.1145/954339.954342	computer vision;image analysis;computer science;perception	AI	28.925402563022388	-61.28188926558164	28427
e707281248e2097e250d64118459b862257459ce	hierarchical image segmentation based on iterative contraction and merging	image segmentation;image resolution;image colour analysis image resolution image segmentation iterative methods optimisation;image color analysis;merging;clustering algorithms;optimization;image segmentation algorithm design and analysis merging image resolution clustering algorithms optimization image color analysis;hierarchical image segmentation iterative contraction iterative merging optimization problem contraction and merging process image resolution pixel based contraction image pixel intraregion color difference region based contraction;algorithm design and analysis;affinity matrix contraction process hierarchical image segmentation	In this paper, we propose a new framework for hierarchical image segmentation based on iterative contraction and merging. In the proposed framework, we treat the hierarchical image segmentation problem as a sequel of optimization problems, with each optimization process being realized by a contraction-and-merging process to identify and merge the most similar data pairs at the current resolution. At the beginning, we perform pixel-based contraction and merging to quickly combine image pixels into initial region-elements with visually indistinguishable intra-region color difference. After that, we iteratively perform region-based contraction and merging to group adjacent regions into larger ones to progressively form a segmentation dendrogram for hierarchical segmentation. Comparing with the state-of-the-art techniques, the proposed algorithm can not only produce high-quality segmentation results in a more efficient way, but also keep a lot of boundary details in the segmentation results.	algorithm;computation;dendrogram;entity name part qualifier - adopted;high- and low-level;image segmentation;information;iterative method;large;mathematical optimization;merge;optimization problem;pixel;processor affinity;real-time computing;simulation;texture mapping;biologic segmentation	Jia-Hao Syu;Sheng-Jyh Wang;Li-Chun Wang	2017	IEEE Transactions on Image Processing	10.1109/TIP.2017.2651395	image texture;algorithm design;computer vision;feature detection;range segmentation;image resolution;binary image;computer science;morphological gradient;machine learning;segmentation-based object categorization;pattern recognition;mathematics;region growing;image segmentation;cluster analysis;minimum spanning tree-based segmentation;scale-space segmentation	Vision	45.70540260645339	-68.63960668061263	28447
94f5c6601b79e7f62d1272038510564bc869078d	automatic gender detection using on-line and off-line information	handwriting analysis;classifier combination;gaussian mixture;gaussian mixture model;gaussian mixture models;detection rate;multiple classifier combination	In this paper, the problem of classifying handwritten data with respect to gender is addressed. A classification method based on Gaussian Mixture Models is applied to distinguish between male and female handwriting. Two sets of features using on-line and off-line information have been used for the classification. Furthermore, we combined both feature sets and investigated several combination strategies. In our experiments, the on-line features produced a higher classification rate than the off-line features. However, the best results were obtained with the combination. The final gender detection rate on the test set is 67.57%, which is significantly higher than the performance of the on-line and off-line system with about 64.25 and 55.39%, respectively. The combined system also shows an improved performance over human-based classification. To the best of the authors’ knowledge, the system presented in this paper is the first completely automatic gender detection system which works on on-line data. Furthermore, the combination of on-line and off-line features for gender detection is investigated for the first time in the literature.	apache axis;experiment;google map maker;mixture model;online and offline;optimizing compiler;test set;user interface;on-line system	Marcus Liwicki;Andreas Schlapbach;Horst Bunke	2010	Pattern Analysis and Applications	10.1007/s10044-010-0178-6	speech recognition;computer science;machine learning;pattern recognition;mixture model	ML	31.946937554848645	-63.60969214637618	28478
2b74fba404886b1a3fe5ea651bf6e991fe369390	the color retrieval system using statistics and the pca			principal component analysis	Young Kwan Choi;Chul Choi;Chang-Chun Park	2004			statistics;computer science	Vision	27.253694027208063	-65.0670410904821	28491
544413d75891597b661d6dbaceed5fc031a2e01a	structural analysis and matching of shape by logical property	teoria cognitiva;metodo adaptativo;analisis estadistico;complexite calcul;analisis estructural;morfoscopia;fundamental unit;shape analysis;cognitive theory;methode adaptative;forma geometrica;similarity retrieval;theorie cognitive;complejidad computacion;statistical analysis;analisis morfologico;computational complexity;pattern matching;morphoscopie;adaptive method;geometrical shape;analyse statistique;morphological analysis;pattern recognition;analyse morphologique;forme geometrique;concordance forme;reconnaissance forme;analyse structurale;reconocimiento patron;structural analysis;structural properties;structure analysis	The shape is one of most important feature for characterising an object. However, most shapes that are expressed with primitive uniform features have difficulty reflecting their logical and structural properties. In this paper, we propose a structural analysis scheme for the shape feature structured by logical properties, as well as a similar retrieval method. A shape is represented as a set of curve segments with a specific pattern. As a fundamental unit, a curve segment has adaptive features based on the logical property of its pattern. The relationship information of curve segments is expressed as a structural feature. We also use it as a feature for coarse-fine matching because our shape features have global characteristics as a structural feature and local characteristics as an adaptive feature of shape. Our experiments show that structural-adaptive features through logical analysis result in effectively classifying shapes according to their cognitive characteristics. Various experiments show that our approach reduces computational complexity and retrieval cost.	structural analysis	Nanhyo Bang;Kyhyun Um	2004		10.1007/978-3-540-27868-9_56	feature recognition;computer vision;computer science;shape analysis;mathematics;geometry;structural analysis;programming language;feature;algorithm	Logic	43.58867666975091	-61.305701302414484	28517
951e0c58a5c35c8d2afeac61787583e6ea20f9d4	embedding 3d geometric features for rigid object part segmentation		Object part segmentation is a challenging and fundamental problem in computer vision. Its difficulties may be caused by the varying viewpoints, poses, and topological structures, which can be attributed to an essential reason, i.e., a specific object is a 3D model rather than a 2D figure. Therefore, we conjecture that not only 2D appearance features but also 3D geometric features could be helpful. With this in mind, we propose a 2-stream FCN. One stream, named AppNet, is to extract 2D appearance features from the input image. The other stream, named GeoNet, is to extract 3D geometric features. However, the problem is that the input is just an image. To this end, we design a 2Dconvolution based CNN structure to extract 3D geometric features from 3D volume, which is named VolNet. Then a teacher-student strategy is adopted and VolNet teaches GeoNet how to extract 3D geometric features from an image. To perform this teaching process, we synthesize training data using 3D models. Each training sample consists of an image and its corresponding volume. A perspective voxelization algorithm is further proposed to align them. Experimental results verify our conjecture and the effectiveness of both the proposed 2-stream CNN and VolNet.	2d computer graphics;3d modeling;algorithm;align (company);computer vision;convolution	Yafei Song;Xiaowu Chen;Jia Li;Qinping Zhao	2017	2017 IEEE International Conference on Computer Vision (ICCV)	10.1109/ICCV.2017.70	artificial intelligence;computer vision;conjecture;computer science;feature extraction;semantics;pattern recognition;image segmentation;embedding;training set;solid modeling;segmentation	Vision	29.98923035363323	-52.585476391114305	28535
b11571d3391bda61945f17b329c01dc8e5f79749	a minutia-based partial fingerprint recognition system	fingerprint matching;minimum cost flow;similarity score;chip;partial fingerprint;fingerprint recognition;minutia;fingerprint identification;matching method;neural network	Matching incomplete or partial fingerprints continues to be an important challenge today, despite the advances made in fingerprint identification techniques. While the introduction of compact silicon chip-based sensors that capture only part of the fingerprint has made this problem important from a commercial perspective, there is also considerable interest in processing partial and latent fingerprints obtained at crime scenes. When the partial print does not include structures such as core and delta, common matching methods based on alignment of singular structures fail. We present an approach that uses localized secondary features derived from relative minutiae information. A flow network-based matching technique is introduced to obtain one-to-one correspondence of secondary features. Our method balances the tradeoffs between maximizing the number of matches and minimizing total feature distance between query and reference fingerprints. A two-hidden-layer fully connected neural network is trained to generate the final similarity score based on minutiae matched in the overlapping areas. Since the minutia-based fingerprint representation is an ANSI-NIST standard [American National Standards Institute, New York, 1993], our approach has the advantage of being directly applicable to existing databases. We present results of testing on FVC2002’s DB1 and DB2 databases. 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	acoustic fingerprint;algorithm;artificial neural network;convex hull;database;distortion;experiment;fingerprint verification competition;fingerprint recognition;flow network;integrated circuit;minimum-cost flow problem;minutiae;one-to-one (data model);pattern recognition;sensor	Tsai-Yang Jea;Venu Govindaraju	2005	Pattern Recognition	10.1016/j.patcog.2005.03.016	chip;minutiae;fingerprint;computer vision;speech recognition;minimum-cost flow problem;computer science;machine learning;pattern recognition;data mining;fingerprint recognition;artificial neural network	AI	32.258065139438706	-62.180280968919334	28561
09ef57f6d3d66315a9a75494eaeec989f22fe8de	preprocessing and feature selection for improved sensor interoperability in online biometric signature verification	biosecure device interoperability on line signature time functions based system global features based system fusion dtw;online services;feature recognition;sensors;fusion;signature verification;biometrics;feature recognition biometrics signature verification device interoperabillity fusion online services sensors;device interoperabillity;feature selection improved sensor interoperability online biometric signature verification smartphones biometric approach device interoperability interoperability device compensation biometric trait commercial sector banking sector global feature based system time function based system wacom device biosecure ds3 dynamic signature dataset biosecure ds2 dynamic signature dataset personal digital assistant mobile device equal error rate eer random forgeries;article;smart phones feature extraction feature selection handwriting recognition open systems	Due to the technological evolution and the increasing popularity of smartphones, people can access an application using authentication based on biometric approaches from many different devices. Device interoperability is a very challenging problem for biometrics, which needs to be further studied. In this paper, we focus on interoperability device compensation for online signature verification since this biometric trait is gaining a significant interest in banking and commercial sector in the last years. The proposed approach is based on two main stages. The first one is a preprocessing stage where data acquired from different devices are processed in order to normalize the signals in similar ranges. The second one is based on feature selection taking into account the device interoperability case, in order to select to select features which are robust in these conditions. This proposed approach has been successfully applied in a similar way to two common system approaches in online signature verification, i.e., a global features-based system and a time functions-based system. Experiments are carried out using Biosecure DS2 (Wacom device) and DS3 (Personal Digital Assistant mobile device) dynamic signature data sets which take into account multisession and two different scenarios emulating real operation conditions. The performance of the proposed global features-based and time functions-based systems applying the two main stages considered in this paper have provided an average relative improvement of performance of 60.3% and 26.5% Equal Error Rate (EER), respectively, for random forgeries cases, compared with baseline systems. Finally, a fusion of the proposed systems has achieved a further significant improvement for the device interoperability problem, especially for skilled forgeries. In this case, the proposed fusion system has achieved an average relative improvement of 27.7% EER compared with the best performance of time functions-based system. These results prove the robustness of the proposed approach and open the door for future works using devices as smartphones or tablets, commonly used nowadays.	authentication;baseline (configuration management);biometrics;database normalization;emulator;enhanced entity–relationship model;feature selection;interoperability;mobile device;optical disc authoring;personal digital assistant;preprocessor;shiren the wanderer gb2;smartphone;tablet computer	Rubén Tolosana;Rubén Vera-Rodríguez;Javier Ortega-Garcia;Julian Fiérrez	2015	IEEE Access	10.1109/ACCESS.2015.2431493	feature recognition;fusion;sensor;data mining;world wide web;computer security;biometrics;signature recognition	Mobile	29.17096539863965	-62.66698539757175	28568
7754fe12d26b4fc8ee12454ff13709b452992f7e	measuring similarity between pixel signatures	computer-aided mammography;scale-orientation pixel signature;similarity measure;euclidean distance;statistical analysis;earth mover s distance	We address the problem of finding specific types of structure in medical images, such as mammograms. We use scale-orientation signatures to provide a rich description of local structure but observe that, when they are treated as vectors for statistical analysis, obvious measures of similarity such as Euclidean distance are not robust to small changes in structure. We describe three robust methods for measuring similarity, based on the transportation (earth mover's) distance. The most sophisticated of these—the best partial matching (BPM) distance—detects common structure between signatures, even when potentially confounding structure is also present. We compare the three new similarity measures and Euclidean distance experimentally. BPM distance is shown to give the best results for both synthetic and real mammogram data.	pixel;type signature	Anthony S. Holmes;C. J. Rose;Christopher J. Taylor	2002	Image Vision Comput.	10.1016/S0262-8856(02)90005-3	earth mover's distance;computer vision;pattern recognition;normalized compression distance;data mining;euclidean distance;mathematics;jaro–winkler distance;statistics	Vision	40.70506575828785	-58.559687974140175	28571
6fccb0d8175c7661e0dabca18ffa52124559adef	the study of randomized visual saliency detection algorithm	software;animals;models theoretical;computer graphics;attention;image processing computer assisted;artificial intelligence;algorithms;pattern recognition automated;humans;random allocation;computer simulation	Image segmentation process for high quality visual saliency map is very dependent on the existing visual saliency metrics. It is mostly only get sketchy effect of saliency map, and roughly based visual saliency map will affect the image segmentation results. The paper had presented the randomized visual saliency detection algorithm. The randomized visual saliency detection method can quickly generate the same size as the original input image and detailed results of the saliency map. The randomized saliency detection method can be applied to real-time requirements for image content-based scaling saliency results map. The randomization method for fast randomized video saliency area detection, the algorithm only requires a small amount of memory space can be detected detailed oriented visual saliency map, the presented results are shown that the method of visual saliency map used in image after the segmentation process can be an ideal segmentation results.	dspace;display resolution;image scaling;image segmentation;randomized algorithm;real-time clock;requirement;stage level 2;stage level 3;test scaling;visual basic[.net];biologic segmentation	Yuantao Chen;Weihong Xu;Fangjun Kuang;Shangbing Gao	2013		10.1155/2013/380245	computer simulation;computer vision;attention;computer science;kadir–brady saliency detector;machine learning;pattern recognition;computer graphics;algorithm	Vision	53.45389331465578	-63.89779417102664	28601
faca730a75b0ae605dbc4e287388b6fcd657f6b9	neural network based denoised methods for retinal fundus images and mri brain images	radial basis function networks biomedical mri brain eye image colour analysis image denoising image enhancement medical image processing;magnetic resonance imaging biological neural networks neurons mathematical model retina biomedical imaging;disease progress diagnosis neural network based denoised method medical image processing medical imaging technique human body medical diagnosis retinal colour fundus image mri brain image noise level fundus fluorescein angiography ffa high contrast retinal image contrast injection magnetic resonance imaging biomedical image image details image enhancement technique high resolution fundus database hrf database oasis mri brain image database radial basis function neural network rbf neural network psnr improvement contrast normalisation technique	Image processing is an active research area in which medical image processing is a highly challenging field. Medical imaging techniques are used to image the inner portion of human body for medical diagnosis. In this research work, retinal colour fundus images and MRI brain images noise level has been improved. Fundus Fluorescein Angiography (FFA) is the invasive based technique used to give high contrast retinal images but it used contrast injection and other side Magnetic Resonance Imaging (MRI) is a medical used to produce the high contrast image. The biomedical images are mostly suffered from the varied contrast and due to varied contrast, the details of images are not observed properly even after the image enhancement techniques because the presence of noise. In this research, The High-Resolution Fundus (HRF) database is used and it contained 36 images of two pairs (18 good quality images and 18 bad quality images). Oasis MRI brain image database is also used and it contained 30 images. Radial Basis Function (RBF) neural network gave highest PSNR improvement of 53% and 56% in HRF retinal images database and Oasis MRI Brain images database as compared to wavelet technique (18%,35%) and sub space method( 29%,9%). The optimal denoised method is one important step to get better result of contrast normalisation techniques and give accurate results to diagnose the disease progress.	artificial neural network;computed tomography angiography;image editing;image processing;medical imaging;noise (electronics);peak signal-to-noise ratio;radial basis function;resonance;wavelet	Toufique Ahmed Soomro;Junbin Gao	2016	2016 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2016.7727327	computer vision	Vision	34.26071879116888	-76.76142477351863	28626
3a5f8d0fd6e6cf7fa3630f25dff44613aca5406d	3d-connected components analysis for traffic monitoring in image sequences acquired from a helicopter	artefacto;subtraction;moving object;metodo adaptativo;homograph;zona urbana;urban environment;helicoptero;image processing;surveillance;homografo;road traffic;gestion trafic;corps mobile;sustraccion;zone urbaine;procesamiento imagen;soustraction;methode adaptative;traffic management;fotografia aerea;traitement image;milieu urbain;artefact;homographe;aerial image;helicoptere;vigilancia;trafic routier;photographie aerienne;monitoring;cuerpo movil;adaptive method;image sequence;background subtraction;poursuite cible;gestion trafico;urban area;spatial data structures;trafico carretera;secuencia imagen;helicopter;moving body;monitorage;vehicle tracking;traffic monitoring;target tracking;monitoreo;connected component;medio urbano;sequence image;aerial photography;structure donnee spatiale	The aim of the study was to develop methods for moving vehicle tracking in aerial image sequences taken over urban areas. The first image of the sequence was manually registered to a map. Corner points were extracted semi-automatically, then tracked along the sequence, to enable video stabilisation by homography estimation. Moving objects were detected by means of adaptive background subtraction. The vehicles were identified among many stabilisation artifacts and tracked, with a simple tracker based on spatiotemporal connected components analysis. While the techniques used were basic, the results turned out to be encouraging, and several improvements are under scrutiny.	aerial photography;background subtraction;connected component (graph theory);geographic information system;ground truth;homography (computer vision);image processing;image resolution;pixel;semiconductor industry;vehicle tracking system	Matthieu Molinier;Tuomas Häme;Heikki Ahola	2005		10.1007/11499145_16	computer vision;active traffic management;simulation;connected component;background subtraction;subtraction;image processing;computer science;mathematics;aerial photography	Vision	48.723341391496156	-56.99169477827537	28655
d49aff426b25e31be178d3230d6a2d021e04848f	towards direct reconstruction from a gamma camera based on compton scattering	energy resolution;simulation ordinateur;camara gamma;radioisotope scanning and imaging;source distribution direct image reconstruction gamma camera compton scattering electronically collimated camera photon counting statistics energy resolution spect imaging nuclear medicine medical diagnostic imaging single photon emission computerized tomography infinitely extending plane computer simulations measurement uncertainties cone surface projections algorithms fully 3d reconstruction;processing;emission computed tomography;modele mathematique;image processing;etude theorique;radiology and nuclear medicine;genie biomedical;camera gamma;etude experimentale;photon;photon counting;performance;compton effect;tomocentelleografia;coincidence detection;computerised tomography compton effect image reconstruction medical image processing radioisotope scanning and imaging;modelo matematico;measurement uncertainty;positron emission tomography;foton;process tomography;algorithme;algorithm;gamma camera;cameras image reconstruction single photon emission computed tomography measurement uncertainty electromagnetic scattering particle scattering event detection optical collimators statistics energy resolution;reconstruction image;accuracy;compton scattering;biomedical engineering;diagnostic techniques;mathematical models;reconstruccion imagen;exploration radioisotopique;diffusion compton;image reconstruction;medical image processing;computerized tomography;single photon emission computed tomography;estudio teorico;computerised tomography;tecnica;mathematical model;radionuclide study;three dimensional reconstruction;gamma cameras;ingenieria biomedica;simulacion computadora;theoretical study;exploracion radioisotopica;difusion compton;computer simulation;estudio experimental;technique;cameras;tomoscintigraphie;tomography 550601 medicine unsealed radionuclides in diagnostics;algoritmo	The Compton scattering camera (sometimes called the electronically collimated camera) has been shown by others to have the potential to better the photon counting statistics and the energy resolution of the Anger camera for imaging in SPECT. By using coincident detection of Compton scattering events on two detecting planes, a photon can be localized to having been sourced on the surface of a cone. New algorithms are needed to achieve fully three-dimensional reconstruction of the source distribution from such a camera. If a complete set of cone-surface projections are collected over an infinitely extending plane, it is shown that the reconstruction problem is not only analytically solvable, but also overspecified in the absence of measurement uncertainties. Two approaches to direct reconstruction are proposed, both based on the photons which travel perpendicularly between the detector planes. Results of computer simulations are presented which demonstrate the ability of the algorithms to achieve useful reconstructions in the absence of measurement uncertainties (other than those caused by quantization). The modifications likely to be required in the presence of realistic measurement uncertainties are discussed.	algorithm;computer simulation;decision problem;detectors;gamma camera;photons;projections and predictions;reconstruction conjecture;sensor;subsurface scattering	Michael J. Cree;Philip J. Bones	1994	IEEE transactions on medical imaging	10.1109/42.293932	computer simulation;image processing;computer science;compton scattering;mathematical model;mathematics;optics;nuclear medicine;physics;statistics;medical physics	Vision	52.8181900100942	-79.24397663209199	28735
27cc1a6ec745e2cb1d39a95e6cf37e4cc05b7ba3	efficient symmetry detection using local affine frames	time complexity;perspective projection;computer and information science;hough transform;maximally stable extremal region;near real time;data och informationsvetenskap	We present an efficient method for detecting planar bilateral symmetries under perspective projection. The method uses local affine frames (LAFs) constructed on maximally stable extremal regions or any other affine covariant regions detected in the image to dramatically improve the process of detecting symmetric objects under perspective distortion. In contrast to the previous work no Hough transform, is used. Instead, each symmetric pair of LAFs votes just once for a single axis of symmetry. The time complexity of the method is n log(n), where n is the number of LAFs, allowing a near real-time performance. The proposed method is robust to background clutter and partial occlusion and is capable of detecting an arbitrary number of symmetries in the image.	3d projection;algorithm;apache axis;bilateral filter;clutter;distortion;hough transform;maximally stable extremal regions;real-time clock;real-time computing;real-time web;sensor;time complexity	Hugo Cornelius;Michal Perdoch;Jiri Matas;Gareth Loy	2007		10.1007/978-3-540-73040-8_16	hough transform;time complexity;computer vision;combinatorics;discrete mathematics;perspective;computer science;mathematics;geometry	Vision	45.07688379885669	-54.901566230898965	28758
5ce6d5ee17cd33cab8b405711d05397dceb502c4	local shape from specularity	vision ordenador;computer graphics;superficie rugosa;surface roughness;coefficient reflexion;intelligence artificielle;experimental result;computer vision;physics;specular reflection;reflexion especular;shape;reflectance;resultado experimental;reflexion speculaire;pattern recognition;rough surface;artificial intelligence;vision ordinateur;surfaces;inteligencia artificial;reconnaissance forme;reconocimiento patron;resultat experimental;grafico computadora;infographie;models;images;surface rugueuse;coeficiente reflexion	We show that highlights in images of objects with specularly reflecting surfaces provide significant information about the surfaces which generate them. A brief survey is given of specular reflectance models which have been used in computer vision and graphics. For our work, we adopt the Torrance-Sparrow specular model which, unlike most previous models, considers the underlying physics of specular reflection from rough surfaces. From this model we derive powerful relationships between the properties of a specular feature in an image and local properties of the corresponding surface. We show how this analysis can be used for both prediction and interpretation in a vision system. A shape from specularity system has been implemented to test our approach. The performance of the system is demonstrated by careful experiments with specularly reflecting objects.	computer vision;diffuse reflection;experiment;graphics;ibm notes;interpretation (logic);rough set;specularity;top-down and bottom-up design	Glenn Healey;Thomas O. Binford	1988	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(88)90143-0	computer vision;specular reflection;surface roughness;shape;computer science;mathematics;geometry;reflectivity;specular highlight;computer graphics;surface;computer graphics (images)	Vision	51.442819747751415	-57.559531578093484	28764
c9c0044723b88ac864e5340d343a356676be97dd	braille document parameters estimation for optical character recognition	line spacing;radon transform;optical character recognition;visual impairment;braille image;parameter estimation;skewness;character recognition	There is a significant need for a system to recognize Braille documents in order to preserve them and make them available to a larger group of visually impaired people. We introduce a high-adaptive Braille documents parameters estimation method to automatically determine the skewness, indentations, and spacing in both vertical and horizontal directions. The key element in determining the skewness of the images is based on Radon transform, which is generated from the integral of a function over straight lines, and is nicely applied in this case since Braille documents are highly directional. We demonstrate the effectiveness of skewness correction as well as the accuracy of indentation and spacing in both orientations. The proposed algorithm is an essential component of character recognition of Braille document discussed in this paper.	estimation theory;optical character recognition	Zhenfei Tai;Samuel Cheng;Pramode K. Verma	2008		10.1007/978-3-540-89646-3_90	arithmetic;computer vision;skewness;radon transform;speech recognition;computer science;estimation theory;optical character recognition;statistics	Vision	36.43166404619471	-66.56686703767012	28854
8ee12b9ba9b2f223f10a34bd8ad71ab955dd6032	precise segmentation of the lateral ventricles and caudate nucleus in mr brain images using anatomically driven histograms	noyau caude;nuclear magnetic resonance imaging;analisis imagen;lateral cerebral ventricle;medical imagery;brain;image segmentation;image processing;systeme nerveux central;caudate nucleus;ventricule cerebral lateral;analisis cuantitativo;morfometria;biomedical nmr;procesamiento imagen;segmentation;encefalo;indexing terms;analisis automatico;traitement image;magnetic resonance image;automatic generation;morphometry;imageria rmn;adult algorithms caudate nucleus cerebral ventricles child corpus callosum female humans image enhancement image processing computer assisted magnetic resonance imaging male reproducibility of results time factors;sistema nervioso central;histogram;image segmentation brain biomedical nmr medical image processing;automatic analysis;histogramme;encephale;analyse quantitative;magnetic resonance;medical image processing;neuromorphometry lateral ventricles caudate nucleus mr brain images anatomically driven histograms precise segmentation time saving automated method t1 weighted coronal magnetic resonance brain images normal control subjects automatically generated intensity thresholds medical diagnostic imaging mri;imagerie medicale;brain imaging;analyse automatique;quantitative analysis;image analysis;normal control;imagerie rmn;nucleo caudado;imageneria medical;histograma;analyse image;segmentacion;central nervous system;morphometrie;image segmentation brain histograms magnetic resonance automation neuroscience hospitals noise robustness automatic control magnetic resonance imaging;ventriculo cerebral lateral;brain vertebrata	This paper demonstrates a time-saving, automated method that helps to segment the lateral ventricles and caudate nucleus in T1-weighted coronal magnetic resonance (MR) brain images of normal control subjects. The method involves choosing intensity thresholds by using anatomical information and by locating peaks in histograms. To validate the method, the lateral ventricles and caudate nucleus were segmented in three brain scans by four experts, first using an established method involving isointensity contours and manual editing, and second using automatically generated intensity thresholds as an aid to the established method. The results demonstrate both time savings and increased reliability.		Andrew J. Worth;Nikos Makris;Mark R. Patti;Julie M. Goodman;Elizabeth A. Hoge;Verne S. Caviness;David N. Kennedy	1998	IEEE Transactions on Medical Imaging	10.1109/42.700743	computer vision;index term;radiology;computer science;quantitative analysis;central nervous system;magnetic resonance imaging;morphometrics;histogram;image segmentation;nuclear medicine;segmentation	Vision	38.711439023058205	-80.12744975219826	28917
10f021658d58b0035af3b252146bd4a1dc84c3a2	a fast and fully automated approach to segment optic nerves on mri and its application to radiosurgery	radiosurgery optic nerves segmentation machine learning support vector machines mri;brain;image segmentation;support vector machines;radiosurgery;image segmentation support vector machines optical imaging biomedical optical imaging brain three dimensional displays;support vector machines biomedical mri brain cancer eye image segmentation medical image processing neurophysiology planning radiation therapy;optical imaging;machine learning;three dimensional displays;mri;biomedical optical imaging;fast optic nerve segmentation processing time optic nerve segmentation robustness optic nerve segmentation accuracy svm support vector machine cerebellum segmentation brainstem segmentation atlas based segmentation clinical outcome radiotherapy cost effectiveness radiotherapy efficiency radiation oncology treatment planning automatic segmentation computer module brain structure functionality impairment proposed treatment dose advanced radiotherapy technology critical brain structure delineation radiosurgery application mri fully automated optic nerve segmentation;optic nerves segmentation	Delineating critical structures of the brain is required for advanced radiotherapy technologies to determine whether the dose from the proposed treatment will impair the functionality of those structures. Employing an automatic segmentation computer module in the radiation oncology treatment planning process has the potential to significantly increase the efficiency, cost-effectiveness, and, ultimately, clinical outcome of patients undergoing radiation therapy. Atlas-based segmentation has shown to be a suitable tool for the segmentation of large structures such as the brainstem or the cerebellum. However, smaller structures such as the optic nerves are more difficult to segment. In this work, we present a novel approach to automatically segment the optic nerves, which is based on Support Vector Machines (SVM). Compared to state of the art methods, the presented method obtained a better performance in regards to accuracy, robustness and processing time, being a suitable trade-off between these three factors.	computer module;robustness (computer science);support vector machine	Jose Dolz;Henri-Arthur Leroy;Nicolas Reyns;Laurent Massoptier;Maximilien Vermandel	2015	2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2015.7164064	support vector machine;computer vision;computer science;magnetic resonance imaging;machine learning;optical imaging;image segmentation;medical physics	Vision	36.39279996239561	-78.8078404472747	28951
963ff1fb2e77843efebacae386b994d2cfe27d4f	salient object detection: a discriminative regional feature integration approach	image segmentation;master saliency map salient object detection discriminative regional feature integration heuristic computational model saliency map computation regression problem multilevel image segmentation supervised learning regional feature vector saliency score regional contrast regional property regional backgroundness descriptor;regression analysis;image segmentation vectors image color analysis feature extraction object detection histograms training;learning artificial intelligence;object detection;regression analysis image segmentation learning artificial intelligence object detection	Salient object detection has been attracting a lot of interest, and recently various heuristic computational models have been designed. In this paper, we regard saliency map computation as a regression problem. Our method, which is based on multi-level image segmentation, uses the supervised learning approach to map the regional feature vector to a saliency score, and finally fuses the saliency scores across multiple levels, yielding the saliency map. The contributions lie in two-fold. One is that we show our approach, which integrates the regional contrast, regional property and regional background ness descriptors together to form the master saliency map, is able to produce superior saliency maps to existing algorithms most of which combine saliency maps heuristically computed from different types of features. The other is that we introduce a new regional feature vector, background ness, to characterize the background, which can be regarded as a counterpart of the objectness descriptor [2]. The performance evaluation on several popular benchmark data sets validates that our approach outperforms existing state-of-the-arts.	feature integration theory;object detection	Huaizu Jiang;Jingdong Wang;Zejian Yuan;Yang Wu;Nanning Zheng;Shipeng Li	2013		10.1109/CVPR.2013.271	computer vision;computer science;kadir–brady saliency detector;machine learning;pattern recognition;image segmentation;regression analysis	Vision	33.29419250307973	-54.25321900671035	28960
2ee1522670f1c8b3bb52aefa9d3c1899fbd2f11f	shadow identification and classification using invariant color models	shadow detection;layout light sources geometry shape lighting image segmentation color signal processing laboratories digital images;image classification;low complexity;color model;image colour analysis;feature extraction;feature extraction image colour analysis image classification;scene layout shadow identification shadow classification invariant color models shadow detection digital images shadow candidate regions extraction self shadow points cast shadow points illumination conditions;digital image;lts1	A novel approachto shadow detectionis presentedin this paper. The methodis basedon the useof invariant color models to identify andto classifyshadows in digital images.The procedureis dividedinto two levels: first, shadow candidateregionsare extracted;then,by usingtheinvariantcolor features,shadow candidatepixelsareclassifiedasself shadow pointsor ascastshadow points. Theuseof invariantcolor featuresallows a low complexity of the classificationstage.Experimentalresultsshow that the methodsucceedsin detectingandclassifyingshadows within the environmentalconstrainsassumedashypotheses, which are less restrictive thanstate-of-the-art methodswith respectto illumination conditionsandscene’ s layout.	digital image;global illumination	Elena Salvador;Andrea Cavallaro;Touradj Ebrahimi	2001		10.1109/ICASSP.2001.941227	computer vision;contextual image classification;color model;feature extraction;shadow and highlight enhancement;computer science;machine learning;shadow mapping;digital image;computer graphics (images)	Vision	44.64042399245129	-54.139572576672734	28965
104ca1b9e156ededc5b0228f2cbefd88b9e7b5b4	multiscale methods for the segmentation and reconstruction of signals and images	scientific application;generalization error;brain;reconstruccion senal;image segmentation image reconstruction smoothing methods error analysis noise reduction biomedical engineering noise robustness biomedical imaging algorithm design and analysis recursive estimation;brain error statistics image segmentation image reconstruction signal reconstruction interference suppression variational techniques markov processes gaussian processes medical image processing biomedical mri;image segmentation;image processing;gaussian processes;methode echelle multiple;two dimensions;etude experimentale;efficient algorithm;variational techniques;procesamiento imagen;statistical method;metodo escala multiple;lutte bruit;gaussian markov random field;segmentation;traitement image;noise control;interference suppression;reconstruction image;variational approach;medical image;reconstruccion imagen;image reconstruction;medical image processing;error statistics;signal reconstruction;multiscale method;markov processes;reconstruction signal;estudio experimental;inhomogeneous gaussian markov random fields multiscale methods segmentation reconstruction signals images noisy signal noisy image scientific applications medical imaging denoising boundary locations variational approach statistical interpretation error statistics recursive procedures;control ruido;segmentacion;biomedical mri	This paper addresses the problem of both segmenting and reconstructing a noisy signal or image. The work is motivated by large problems arising in certain scientific applications, such as medical imaging. Two objectives for a segmentation and denoising algorithm are laid out: it should be computationally efficient and capable of generating statistics for the errors in the reconstruction and estimates of the boundary locations. The starting point for the development of a suitable algorithm is a variational approach to segmentation (Shah 1992). This paper then develops a precise statistical interpretation of a one dimensional (1-D) version of this variational approach to segmentation. The 1-D algorithm that arises as a result of this analysis is computationally efficient and capable of generating error statistics. A straightforward extension of this algorithm to two dimensions would incorporate recursive procedures for computing estimates of inhomogeneous Gaussian Markov random fields. Such procedures require an unacceptably large number of operations. To meet the objective of developing a computationally efficient algorithm, the use of previously developed multiscale statistical methods is investigated. This results in the development of an algorithm for segmenting and denoising which is not only computationally efficient but also capable of generating error statistics, as desired.	addresses (publication format);algorithm;algorithmic efficiency;calculus of variations;computation (action);dimensions;ensemble interpretation;estimated;hl7publishingsubsection <operations>;markov chain;markov random field;medical imaging;noise reduction;normal statistical distribution;recursion;signal processing;variational principle;biologic segmentation	Michael K. Schneider;Paul W. Fieguth;W. Clem Karl;Alan S. Willsky	2000	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.826782	iterative reconstruction;signal reconstruction;computer vision;two-dimensional space;image processing;computer science;machine learning;gaussian process;mathematics;image segmentation;markov process;noise control;segmentation;statistics;generalization error	Vision	53.24038871509643	-74.54716136013448	29036
538cdaf903bc63bc575bdf42996bcb4bef61d4e9	feature extraction based on fuzzy set theory for handwriting recognition	hidden markov models handwriting recognition fuzzy set theory feature extraction word processing;fuzzy set;handwriting recognition;feature extraction fuzzy set theory handwriting recognition image segmentation fuzzy sets hidden markov models databases system testing vocabulary image recognition;hidden markov model;fuzzy set theory;word segmentation;hidden markov models;feature extraction;word processing;straight lines feature extraction fuzzy set theory handwriting recognition handwritten words word segmentation process ordered sequence line segments membership values curved lines fuzzy hidden markov models brazilian bank checks	This puper presents U method bused on fuzzy set theory for extructing features from handwriting words. After the feature extruction and the word segmentation process a handwriting word is represented by an ordered sequence of line segments. For each of these segments are calculated memberships values to fuzzy sets representing different types of curve lines und struight lines. The position of the line segments in a letter or piece of letter resulting from the word segmentation is also evaluated by mecm of fuzzy sets. Fuzzy Hidden Markov Models are employed to classify the handwriting words. A database compounded by handwriting words extrcicted from Bruzilian bankchecks is used to test the proposed system.	feature extraction;fuzzy set;handwriting recognition;hidden markov model;markov chain;microsoft word for mac;set theory;text segmentation	Natanael Rodrigues Gomes;Lee Luan Ling	2001		10.1109/ICDAR.2001.953871	speech recognition;fuzzy classification;computer science;machine learning;pattern recognition;fuzzy set;hidden markov model	AI	33.556262153409705	-66.13072462373279	29039
2e6882fa319ab3df2d5eef171a39d800ac091398	gaussian ringlet intensity distribution (grid) features for rotation-invariant object detection in wide area motion imagery	local intensity distribution based object tracking gaussian ringlet intensity distribution features rotation invariant object detection wide area motion imagery ring partitioned histograms low resolution environments rotation invariance;histograms databases accuracy equations standards feature extraction measurement;object tracking gaussian distribution image motion analysis image resolution object detection	Most detection algorithms are established by using well defined features. Since wide area imagery is low resolution and has features that are not well defined, a local intensity distribution based methodology seems a likely candidate. We propose a new methodology, Gaussian Ringlet Intensity Distribution (GRID), which is a derivative of the ring-partitioned histograms for local intensity distribution based object tracking in low-resolution environments, which deals with the issue of rotation invariance. We observed that the proposed algorithm produces the highest accuracy among other state of the art methodologies and provides robust features for rotationally invariant detection and tracking in wide area motion imagery.	algorithm;image resolution;object detection	Theus H. Aspiras;Vijayan K. Asari;Juan R. Vasquez	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7025468	computer vision;pattern recognition	Robotics	40.3274668856486	-55.217622489596664	29105
0606bc00b07956098669f2fc292c3fa4799c57ae	how salient is scene text?	image features;visual attention models;saliency map character localization visual attention models;saliency map;computer model;nontext region suppression scene text detection algorithms computational models visual attention model image features salient location identification object detection tasks saliency maps;visualization image color analysis bayesian methods humans feature extraction computational modeling shape;feature extraction;character localization;text detection;text detection feature extraction object detection;visual attention;object detection	Computational models of visual attention use image features to identify salient locations in an image that are likely to attract human attention. Attention models have been quite effectively used for various object detection tasks. However, their use for scene text detection is under-investigated. As a general observation, scene text often conveys important information and is usually prominent or salient in the scene itself. In this paper, we evaluate four state-of-the-art attention models for their response to scene text. Initial results indicate that saliency maps produced by these attention models can be used for aiding scene text detection algorithms by suppressing non-text regions.	algorithm;computation;computational model;map;object detection	Asif Shahab;Faisal Shafait;Andreas Dengel;Seiichi Uchida	2012	2012 10th IAPR International Workshop on Document Analysis Systems	10.1109/DAS.2012.42	computer simulation;computer vision;feature extraction;computer science;machine learning;pattern recognition;feature	Vision	37.812976941308044	-53.71150042711533	29138
73b7488dc0d6547d2fb18cc33f4a8869e0fa796e	robust non-local tv- $l^{1}$ optical flow estimation with occlusion detection		"""In this paper, we propose a robust non-local TV-<inline-formula> <tex-math notation=""""LaTeX"""">$L^{1}$ </tex-math></inline-formula> optical flow method with occlusion detection to address the problem of weak robustness of optical flow estimation with motion occlusion. First, a TV-<inline-formula> <tex-math notation=""""LaTeX"""">$L^{1}$ </tex-math></inline-formula> form for flow estimation is defined using a combination of the brightness constancy and gradient constancy assumptions in the data term and by varying the weight under the Charbonnier function in the smoothing term. Second, to handle the potential risk of the outlier in the flow field, a general non-local term is added in the TV-<inline-formula> <tex-math notation=""""LaTeX"""">$L^{1}$ </tex-math></inline-formula> optical flow model to engender the typical non-local TV-<inline-formula> <tex-math notation=""""LaTeX"""">$L^{1}$ </tex-math></inline-formula> form. Third, an occlusion detection method based on triangulation is presented to detect the occlusion regions of the sequence. The proposed non-local TV-<inline-formula> <tex-math notation=""""LaTeX"""">$L^{1}$ </tex-math></inline-formula> optical flow model is performed in a linearizing iterative scheme using improved median filtering and a coarse-to-fine computing strategy. The results of the complex experiment indicate that the proposed method can overcome the significant influence of non-rigid motion, motion occlusion, and large displacement motion. Results of experiments comparing the proposed method and existing state-of-the-art methods by, respectively, using Middlebury and MPI Sintel database test sequences show that the proposed method has higher accuracy and better robustness."""	blurred vision;computation (action);database;displacement mapping;experiment;gradient;iterative method;jean;leigh syndrome , french canadian type;manuscripts;mathematical optimization;median filter;muscle rigidity;optical flow;psychologic displacement;review [publication type];sensor;smoothing (statistical technique);total variation denoising;brightness;triangulation	Congxuan Zhang;Zhen Chen;Mingrun Wang;Ming Li;Shaofeng Jiang	2017	IEEE Transactions on Image Processing	10.1109/TIP.2017.2712279	artificial intelligence;robustness (computer science);computer vision;outlier;median filter;smoothing;optical filter;brightness;mathematics;triangulation (social science);optical flow	Vision	51.02356530643794	-73.86961247846938	29160
f9ca921e103e3889a74596f60319a96a011ce89d	point pair features based object detection and pose estimation revisited	rgbd;three dimensional displays solid modeling computational modeling feature extraction accuracy pipelines;segmentation;accuracy;computational modeling;pipeline object detection segmentation 3d matching point pair features rgbd point cloud;three dimensional displays;feature extraction;pipelines;solid modeling;3d matching;point cloud;pipeline;object detection;point pair features	We present a revised pipe-line of the existing 3D object detection and pose estimation framework based on point pair feature matching. This framework proposed to represent 3D target object using self-similar point pairs, and then matching such model to 3D scene using efficient Hough-like voting scheme operating on the reduced pose parameter space. Even though this work produces great results and motivated a large number of extensions, it had some general shortcoming like relatively high dimensionality of the search space, sensitivity in establishing 3D correspondences, having performance drops in presence of many outliers and low density surfaces. In this paper, we explain and address these drawbacks and propose new solutions within the existing framework. In particular, we propose to couple the object detection with a coarse-to-fine segmentation, where each segment is subject to disjoint pose estimation. During matching, we apply a weighted Hough voting and an interpolated recovery of pose parameters. Finally, all the generated hypothesis are tested via an occlusion-aware ranking and sorted. We argue that such a combined pipeline simultaneously boosts the detection rate and reduces the complexity, while improving the accuracy of the resulting pose. Thanks to such enhanced pose retrieval, our verification doesn't necessitate ICP and thus achieves better compromise of speed vs. accuracy. We demonstrate our method on existing datasets as well as on our scenes. We conclude that via the new pipe-line, point pair features can now be used in more challenging scenarios.	3d pose estimation;hidden surface determination;hough transform;interpolation;object detection;self-similarity	Tolga Birdal;Slobodan Ilic	2015	2015 International Conference on 3D Vision	10.1109/3DV.2015.65	computer vision;pose;3d pose estimation;computer science;machine learning;pattern recognition	Vision	43.953557959442286	-53.14353596041835	29179
555b96636a718ab0e75e110a36d8ef27d4278e79	optical flow on moving manifolds	spatio temporal regularization;65m30;68u10;58j90;optical flow;variational methods;evolving surfaces	Optical flow is a powerful tool for the study and analysis of motion in a sequence of images. In this paper we study a Horn–Schunck-type spatio-temporal regularization functional for image sequences that have a non-Euclidean, time varying image domain. To that end we construct a Riemannian metric that describes the deformation and structure of this evolving surface. The resulting functional can be seen as a natural geometric generalization of previous work by Weickert and Schnörr in 2001 and Lefèvre and Baillet in 2008 for static image domains. In this paper we show the existence and well-posedness of the corresponding optical flow problem and derive necessary and sufficient optimality conditions. We demonstrate the functionality of our approach in two experiments using both synthetic and real data.	experiment;flow network;horn clause;optical flow;synthetic intelligence;well-posed problem	Martin Bauer;Markus Grasmair;Clemens Kirisits	2015	SIAM J. Imaging Sciences	10.1137/140965235	computer vision;mathematical optimization;mathematical analysis;topology;computer science;machine learning;optical flow;mathematics	Vision	53.29060973065756	-70.48992542358798	29189
3f5323631001a390a8431ae8936752adb139e2b2	glioma segmentation with cascaded unet		MRI analysis takes central position in brain tumor diagnosis and treatment, thus it’s precise evaluation is crucially important. However, it’s 3D nature imposes several challenges, so the analysis is often performed on 2D projections that reduces the complexity, but increases bias. On the other hand, time consuming 3D evaluation, like, segmentation, is able to provide precise estimation of a number of valuable spatial characteristics, giving us understanding about the course of the disease. Recent studies, focusing on the segmentation task, report superior performance of Deep Learning methods compared to classical computer vision algorithms. But still, it remains a challenging problem. In this paper we present deep cascaded approach for automatic brain tumor segmentation. Similar to recent methods for object detection, our implementation is based on neural networks; we propose modifications to the 3D UNet architecture and augmentation strategy to efficiently handle multimodal MRI input, besides this we introduce approach to enhance segmentation quality with context obtained from models of the same topology operating on downscaled data. We evaluate presented approach on BraTS 2018 dataset and discuss results.	algorithm;artificial neural network;computer vision;deep learning;multimodal interaction;object detection	Ittai Eden;Thi-To-Quyen Tran;V. E. Turlapov	2018	CoRR		glioma;machine learning;pattern recognition;artificial intelligence;computer science;brain tumor;segmentation	Vision	31.235164526108758	-75.21090585891362	29198
9dfa0372c0ddb186369081e3df4609090b34fb62	separate chinese character and english character by cascade classifier and feature selection	image sampling;histograms;classifier combination;optical character recognition feature extraction image classification image sampling natural languages;support vector machines;optical character recognition;prototypes;training;cascade classifier;chinese character;image classification;text analysis;confidence bias;natural languages;diversity reception;optical character recognition software;ocr technique;accuracy;ocr language identification cascade classifier feature selection;research and development;feature extraction;image sample;pixel;optical character recognition software natural languages prototypes diversity reception text analysis character recognition research and development laboratories support vector machines support vector machine classification;classification algorithms;english character;ocr;language identification;support vector machine classification;multilevel cascade classifier;feature selection;character recognition;confidence bias chinese character english character ocr technique multilevel cascade classifier feature selection image sample	The separation of Chinese character and English character is helpful for OCR technique. In this paper, a multi-level cascade classifier combined with feature selection is constructed to identify Chinese character and English character based on individual character. Most of samples are identified by the first node classifier, the remained low classification confidence samples are fed to the next node classifiers to get the final result. For the motivation of utilizing feature complementarity, each node classifier is trained on low classification confidence samples of its previous node classifier with independent feature selection. Furthermore, a confidence bias is utilized to improve the classifier generalization. The experiment results validate the effectiveness of this classifier.	cascading classifiers;complementarity theory;feature selection;optical character recognition;statistical classification	Yuanping Zhu;Jun Sun;Akihiro Minagawa;Yoshinobu Hotta;Satoshi Naoi	2009	2009 10th International Conference on Document Analysis and Recognition	10.1109/ICDAR.2009.164	language identification;margin classifier;support vector machine;bayes classifier;contextual image classification;speech recognition;cascading classifiers;quadratic classifier;feature extraction;computer science;machine learning;pattern recognition;histogram;accuracy and precision;prototype;natural language;optical character recognition;feature selection;pixel	AI	32.74588946402219	-65.36533554315795	29261
b5b21cd20ddeffbb483c33b7d73f3a0012e35709	the viability of advantg deterministic method for synthetic radiography generation		Abstract Fast simulation techniques to generate synthetic radiographic images of high resolution are helpful when new radiation imaging systems are designed. However, the standard stochastic approach requires lengthy run time with poorer statistics at higher resolution. The investigation of the viability of a deterministic approach to synthetic radiography image generation was explored. The aim was to analyze a computational time decrease over the stochastic method. ADVANTG was compared to MCNP in multiple scenarios including a small radiography system prototype, to simulate high resolution radiography images. By using ADVANTG deterministic code to simulate radiography images the computational time was found to decrease 10 to 13 times compared to the MCNP stochastic approach while retaining image quality.	radiography;synthetic data	Andrew Bingham;Hyoung K. Lee	2018	Computer Physics Communications	10.1016/j.cpc.2018.02.009	medical physics;mathematics;mathematical optimization;computer vision;radiation;radiography;image quality;deterministic system (philosophy);digital radiography;artificial intelligence	Theory	50.595127608525644	-78.50671027947497	29263
bd42534cb09922e52dc8b32152cda96c8a17e13a	a meta-learning approach for recommendation of image segmentation algorithms	histograms;machine learning algorithms;image segmentation;standards;prediction algorithms;wounds;image color analysis	There are many algorithms for image segmentation, but there is no optimal algorithm for all kind of image applications. To recommend an adequate algorithm for segmentation is a challenging task that requires knowledge about the problem and algorithms. Meta-learning has recently emerged from machine learning research field to solve the algorithm selection problem. This paper applies meta-learning to recommend segmentation algorithms based on meta-knowledge. We performed experiments in four different meta-databases representing various real world problems, recommending when three different segmentation techniques are adequate or not. A set of 44 features based on color, frequency domain, histogram, texture, contrast and image quality were extracted from images, obtaining enough discriminative power for the recommending task in different segmentation scenarios. Results show that Random Forest meta-models were able to recommend segmentation algorithms with high predictive performance.	algorithm selection;computer vision;database tuning;experiment;f1 score;feature selection;image processing;image quality;image segmentation;machine learning;meta learning (computer science);radio frequency;random forest;selection algorithm;texture mapping;unsupervised learning	Gabriel F. C. Campos;Sylvio Barbon Junior;Rafael Gomes Mantovani	2016	2016 29th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)	10.1109/SIBGRAPI.2016.058	image texture;computer vision;computer science;machine learning;segmentation-based object categorization;pattern recognition;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation	Vision	33.55211833535019	-71.22581758852478	29295
545014b2b4b5157c205dbff08308bf16ee710670	a novel computerized method based on support vector machine for tongue diagnosis	bayesian network;image processing;traditional chinese medicine;support vector machines;bayes methods;image classification;biomedical imaging;inspection;image texture;support vector machines tongue image color analysis feature extraction diseases medical diagnostic imaging biomedical imaging;support vector machines bayes methods feature extraction image classification image texture inspection medical image processing;computerized tongue diagnosis;image color analysis;feature extraction;medical image processing;tongue diagnosis;tongue;diseases;image processing techniques;chromatic measure;image classification support vector machine tongue diagnosis traditional chinese medicine computerized tongue inspection chromatic measure textural measure image processing bayesian network;computerized tongue inspection;support vector machine;traditional chinese medicine bayesian networks computerized tongue diagnosis support vector machine;textural measure;medical diagnostic imaging;bayesian networks;diagnostic method	The tongue diagnosis is an important diagnostic method in traditional chinese medicine (TCM). In this paper, we present a novel computerized tongue inspection method based on support vector machine (SVM). First, two kinds of quantitative features, chromatic and textural measures, are extracted from tongue images by using popular image processing techniques. Then, support vector machine and Bayesian network are employed to build the mapping relationships between these features and diseases, respectively. Finally, we present a comparison between SVM and BN classification. The experiment results show that we can use SVM to classify the tongue images more excellently and get a relative reliable prediction of diseases based on these features.	bayesian network;support vector machine;toolkit for conceptual modeling	Zhong Gao;Lai-Man Po;Wu Jiang;Xin Zhao;Hao Dong	2007	2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System	10.1109/SITIS.2007.115	traditional chinese medicine;support vector machine;computer vision;speech recognition;image processing;computer science;machine learning;pattern recognition;bayesian network	Robotics	35.196524896561215	-73.62246318956231	29312
ac54c7a5ebf1259f0e6c79d8bb987b7249592a09	color filtering-based efficient face detection	image colour analysis face recognition filtering theory image classification;face detection detectors computational efficiency probability distribution filters face recognition filtering bayesian methods;image classification;face recognition;image colour analysis;membership function;face detection;cascade face detector facial color filtering efficient face detection subwindow scanning method face classifier nonface classifier scanning method facial color membership function;filtering theory	In this paper we propose a sub-window scanning method and a face/non-face classifier using a facial color filter. The scanning method skips over sub-windows that do not contain possible faces based on a facial color membership function. The face/non-face classifier using facial color has low computational cost and can reject non-face sub-windows in an early stage of the cascade face detector. The proposed model reduces the overall computation time of face detection and eliminates false alarms.	algorithmic efficiency;computation;face detection;microsoft windows;statistical classification;time complexity	Yeong Nam Chae;Jinyun Chung;Hyun Seung Yang	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761492	facial recognition system;computer vision;contextual image classification;face detection;object-class detection;membership function;computer science;machine learning;pattern recognition;three-dimensional face recognition;mathematics;face hallucination	Vision	34.43565514509619	-60.62787680897992	29323
0268d47142c579264a11787e1c74e6c3a06ef11d	self-invertible 2d log-gabor wavelets	transformation ondelette;analisis imagen;gaussian noise;image features;log gabor ﬁlters;simple cell;translation invariant;fonction orthogonale;optimisation;naming;log gabor filters;restauration image;analisis estadistico;image processing;optimizacion;biorthogonal wavelets;high pass filter;degree of freedom;articulo;subband decomposition;ruido gaussiano;procesamiento imagen;invarianza;natural images;image restoration;probabilistic approach;analyse multiresolution;filtro gabor;primary visual cortex;traitement image;corteza visual;invariance;wavelet transforms;restauracion imagen;oriented high pass filters;gabor filter;wavelet transform;statistical analysis;subbanda;descomposicion subbanda;bande frequence;frequency band;enfoque probabilista;approche probabiliste;subband;bruit gaussien;analyse statistique;denomination;filtre gabor;recouvrement ensemble;denominacion;orthogonal function;image analysis;optimization;receptive field;image denoising;transformacion ondita;set covering;decomposition sous bande;cubierta conjunto;funcion ortogonal;oriented high pass ﬁlters;multiresolution analysis;analyse image;visual system;gabor wavelets;banda frecuencia;sous bande;cortex visuel;visual cortex;wavelet transformation;analisis multiresolucion	Orthogonal and biorthogonal wavelets became very popular image processing tools but exhibit major drawbacks, namely a poor resolution in orientation and the lack of translation invariance due to aliasing between subbands. Alternative multiresolution transforms which specifically solve these drawbacks have been proposed. These transforms are generally overcomplete and consequently offer large degrees of freedom in their design. At the same time their optimization gets a challenging task. We propose here the construction of log-Gabor wavelet transforms which allow exact reconstruction and strengthen the excellent mathematical properties of the Gabor filters. Two major improvements on the previous Gabor wavelet schemes are proposed: first the highest frequency bands are covered by narrowly localized oriented filters. Secondly, the set of filters cover uniformly the Fourier domain including the highest and lowest frequencies and thus exact reconstruction is achieved using the same filters in both the direct and the inverse transforms (which means that the transform is self-invertible). The present transform not only achieves important mathematical properties, it also follows as much as possible the knowledge on the receptive field properties of the simple cells of the Primary Visual Cortex (V1) and on the statistics of natural images. Compared to the state of the art, the log-Gabor wavelets show excellent ability to segregate the image information (e.g. the contrast edges) from spatially incoherent Gaussian noise by hard thresholding, and then to represent image features through a reduced set of large magnitude coefficients. Such characteristics make the transform a promising tool for processing natural images.	aliasing;coefficient;frequency band;gabor wavelet;image processing;mathematical optimization;multiresolution analysis;thresholding (image processing);wavelet transform	Sylvain Fischer;Filip Sroubek;Laurent U. Perrinet;Rafael Redondo;Gabriel Cristóbal	2006	International Journal of Computer Vision	10.1007/s11263-006-0026-8	wavelet;computer vision;image analysis;speech recognition;image processing;computer science;mathematics;geometry;gabor wavelet;wavelet transform	Vision	46.598880252946934	-62.4784999517845	29342
2cb99aa4e906cf7aaf6f5a7c323d4d74cddb2e3a	addressing cbir efficiency, effectiveness, and retrieval subjectivity simultaneously	content based image retrieval cbir;index structure;indexing method;hierarchical elimination based a retrieval hear;fuzzy logic;fast and semantics tailored retrieval fast;theoretical analysis;indexation;region based features;fast imaging;indexing tree pruning itp;experimental evaluation;content based image retrieval;relevance feedback;adaptive region weight updating arwu;semantic retrieval	This work is about Content Based Image Retrieval (CBIR), focusing on developing a Fast And Semantics-Tailored (FAST) image retrieval methodology. Specifically, the contributions of FAST methodology to the CBIR literature include: (1) development of a new indexing method based on fuzzy logic to incorporate color, texture, and shape information into a region based approach to improving the retrieval effectiveness and robustness (2) development of a new hierarchical indexing structure and the corresponding Hierarchical, Elimination-based A* Retrieval algorithm (HEAR) to significantly improve the retrieval efficiency without sacrificing the retrieval effectiveness; it is shown that HEAR is guaranteed to deliver a logarithm search in the average case (3) employment of user relevance feedbacks to tailor the semantic retrieval to each user's individualized query preference through the novel Indexing Tree Pruning (ITP) and Adaptive Region Weight Updating (ARWU) algorithms. Theoretical analysis and experimental evaluations show that FAST methodology holds a great promise in delivering fast and semantics-tailored image retrieval in CBIR.	a* search algorithm;best, worst and average case;bottom-up parsing;content-based image retrieval;decision tree;fast fourier transform;fuzzy logic;heap feng shui;image processing;information retrieval;interaction;iteration;jing;lu decomposition;linear search;machine learning;online search;relevance feedback;spatial database	Ruofei Zhang;Zhongfei Zhang	2003		10.1145/973264.973276	fuzzy logic;computer vision;visual word;computer science;data mining;information retrieval;human–computer information retrieval	Web+IR	39.82852474893193	-61.12218995589724	29384
86787c5a70cbe252537cb81d831cb547b28d975e	ms-capsnet: a novel multi-scale capsule network		Capsule network is a novel architecture to encode the properties and spatial relationships of the feature in an image, which shows encouraging results on image classification. However, the original capsule network is not suitable for some classification tasks, where the target objects are complex internal representations. Hence, we propose a multi-scale capsule network that is more robust and efficient for feature representation in image classification. The proposed multi-scale capsule network consists of two stages. In the first stage, structural and semantic information are obtained by multi-scale feature extraction. In the second stage, the hierarchy of features is encoded to multi-dimensional primary capsules. Moreover, we propose an improved dropout to enhance the robustness of the capsule network. Experimental results show that our method has a competitive performance on FashionMNIST and CIFAR10 datasets.	computer vision;dropout (neural networks);encode;feature extraction;ms-dos	Canqun Xiang;Lu Zhang;Yi Tang;Wenbin Zou;Chen Xu	2018	IEEE Signal Processing Letters	10.1109/LSP.2018.2873892	convolutional code;pattern recognition;mathematics;artificial intelligence;encoding (memory);feature extraction;architecture;robustness (computer science);capsule;hierarchy;contextual image classification	ML	25.994053890079396	-52.474734173698536	29481
49792bb2910e821ea6a9a5647b98f553e82124e1	vehicle license plate recognition using visual attention model and deep learning	networks;image segmentation;neural networks;convolution;machine learning;contamination;computer science;video	A vehicle’s license plate is the unique feature by which to identify each individual vehicle. As an important research area of an intelligent transportation system, the recognition of vehicle license plates has been investigated for some decades. An approach based on a visual attention model and deep learning is proposed to handle the problem of Chinese car license plate recognition for traffic videos. We first use a modified visual attention model to locate the license plate, and then the license plate is segmented into seven blocks using a projection method. Two classifiers, which combine the advantages of convolutional neural network-based feature learning and support vector machine for multichannel processing, are designed to recognize Chinese characters, numbers, and alphabet letters, respectively. Experimental results demonstrate that the presented method can achieve high recognition accuracy and works robustly even under the conditions of illumination change and noise contamination. © The Authors. Published by SPIE under a Creative Commons Attribution 3.0 Unported License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI. [DOI: 10.1117/1.JEI.24.3.033001]	artificial neural network;automatic number plate recognition;channel (digital image);convolutional neural network;deep learning;feature learning;feature model;precision and recall;region of interest;support vector machine	Di Zang;Zhenliang Chai;Junqi Zhang;Dongdong Zhang;Jiujun Cheng	2015	J. Electronic Imaging	10.1117/1.JEI.24.3.033001	computer vision;speech recognition;video;computer science;machine learning;contamination;image segmentation;convolution;artificial neural network	AI	34.92944061302476	-64.0794129484427	29488
a144b9d24e1c0980e32546a4116b3d09b485bb9f	model based pose estimator using linear-programming	image tridimensionnelle;estimation mouvement;robust estimator;vision estereoscopica;random sampling;weighted least square;representation image;estimacion movimiento;vision stereoscopique;motion estimation;reconstruction image;maximum likelihood estimate;programacion lineal;reconstruccion imagen;image representation;phase estimation;image reconstruction;linear programming;programmation lineaire;linear program;tridimensional image;stereopsis;imagen tridimensional;pose estimation	Given a3D object and some measurements for points in this object, it is desired to find the 3D location of the object. A new model based pose estimator from stereo pairs based on linear programming ( LP) is presented. In the presence of outliers, the new LP estimator provides better results than maximum likelihood estimators such as weighted least squares, and is usually almost as good as robust estimators such asLMEDS. In the presence of noise the new LP estimator provides better results than robust estimators such as LMEDS, and is slightly inferior to maximum likelihood estimators such as weighted least squares. In the presence of noise and outliers especially for wide angle stereo the new estimator provides the best results. TheLP estimator is based on correspondence of a points to convex polyhedrons. Each points corresponds to a unique polyhedron, which represents its uncertainty in 3D as computed from the stereo pair. Polyhedron can also be computed for 2D data point by using a-priori depth boundaries. TheLP estimator is a single phase (no separate outlier rejection phase) estimator solved by single iteration (no re-weighting), and always converges to the global minimum of its error function. The estimator can be extended to include random sampling and re-weighting within the standard frame work of a linear program.	a3d;data point;image noise;iteration;least squares;linear programming;maxima and minima;monte carlo method;polyhedron;rejection sampling;sampling (signal processing)	Moshe Ben-Ezra;Shmuel Peleg;Michael Werman	2000		10.1007/3-540-45054-8_18	iterative reconstruction;efficient estimator;minimum mean square error;minimax estimator;robust statistics;sampling;computer vision;econometrics;mathematical optimization;minimum-variance unbiased estimator;estimator;pose;stein's unbiased risk estimate;computer science;trimmed estimator;linear programming;stereopsis;efficiency;motion estimation;mathematics;mean squared error;maximum likelihood;bias of an estimator;consistent estimator;invariant estimator;statistics	Vision	51.7756287575408	-52.1823261872282	29652
fc1c728faded5d4dbdece980352fa544e4aac4dc	processing 2d gel electrophoresis images for efficient gaussian mixture modeling		In modern molecular biology the most commonly used method to distinct proteins present in complex sample is two-dimensional gel electrophoresis. Unfortunately, the quality of the gel image is reduced by the presence of non-linear background signal, spikes, streaks and other artefacts. The main components of gel image are protein spots. To properly distinguish spots, mostly in overlapping regions, mixture modeling can be performed. Due to many signal impurities the estimation of model parameters is inadequate. In this study, by using two fragments of real gel image and a set of synthetic data, three background correction methods with four image filtering methods were collated and the quality of spot detection based on mixture modeling was checked. The presented results prove that efficient modeling of 2D gel electrophoresis images must be preceded by proper background correction and noise filtering. A two-step Otsu algorithm was the best method for removing background signal. There was no single favorite from filtering methods, but using 2D matched filtering leads to good results despite the background correction method used.		Michal Marczyk	2017		10.1007/978-3-319-60816-7_5	filter (signal processing);background correction method;background correction;synthetic data;biological system;gaussian;two-dimensional gel electrophoresis;gel electrophoresis;materials science;chromatography	ML	39.7257288990507	-72.44133681834386	29686
02b626b8cd99ca0aee7da0a6578c4d85fff81927	level set evolution with locally linear classification for image segmentation	image segmentation;locally linear classification;level set methods;active contour model	This paper presents a novel local region-based level set model for image segmentation. In each local region, we define a locally weighted least squares energy to fit a linear classification function. The local energy is then integrated over the entire image domain to form an energy functional in terms of level set function. The energy minimization is achieved by level set evolution and estimation of parameters of the locally linear function in an iterative process. By introducing the locally linear functions to separate background and foreground in local regions, our model not only ensures the accuracy of the segmentation results, but also be very robust to initialization. Experiments are reported to demonstrate the effectiveness and efficiency of our model.	energy minimization;experiment;image segmentation;iteration;least squares;linear classifier;linear function	Ying Wang;Shiming Xiang;Chunhong Pan;Lingfeng Wang;Gaofeng Meng	2011	2011 18th IEEE International Conference on Image Processing	10.1016/j.patcog.2012.12.006	computer vision;range segmentation;computer science;machine learning;segmentation-based object categorization;pattern recognition;active contour model;mathematics;region growing;image segmentation;scale-space segmentation	Vision	50.41254765454709	-71.1535983731122	29763
ea572991a75acfc8a8791955f670d2c48db49023	arbitrary-shape object localization using adaptive image grids	drntu engineering electrical and electronic engineering;conference paper	Sliding-window based search is a widely used technique for object localization. However, for objects of non-rectangle shapes, noises in windows may mislead the localization, causing unsatisfactory results. In this paper, we propose an efficient bottom-up approach for detecting arbitrary-shape objects using image grids as basic components. First, a test image is partitioned into n × n grids and the object is localized by finding a set of connected grids which maximize the classifier’s response. Then, graph cut segmentation is used to improve the object boundary by utilizing local image context. Instead of using bounding boxes, the proposed approach searches connected regions of any shapes. With the graph cut refinement, our approach can start with coarse image grids and is robust to noises. To make image grids better cover the object of arbitrary shape, we also propose a fast adaptive grid partition method which takes image content into account and can be efficiently implemented by dynamic programming. The use of adaptive partition further improves the localization accuracy of our approach. Experiments on PASCAL VOC 2007 and VOC 2008 datasets demonstrate the effectiveness of our approach.	adaptive mesh refinement;algorithm;bottom-up parsing;cut (graph theory);dynamic programming;graph cuts in computer vision;internationalization and localization;microsoft windows;refinement (computing);sensor;standard test image;top-down and bottom-up design	Chunluan Zhou;Junsong Yuan	2012		10.1007/978-3-642-37331-2_6	computer vision;mathematical optimization;computer science;theoretical computer science;machine learning;mathematics	Vision	46.31898928088501	-69.79243421509706	29856
f20b73f68c6cafe880f13309264dc7bf728db3a2	heuristic rules for improving the quality of simulation based on the sequential non-overlapping batch mean	video signal processing;edge detection;microscopy;communication networks thumb stochastic processes discrete event simulation communication system control error correction protection finishing data analysis steady state;data mining;blood vessel;steady state simulation heuristic rules simulation quality sequential nonoverlapping batch mean sequential procedures stochastic discrete event simulation communication networks statistical error sequential output data analysis;automatic adherent leukocyte recognition;leukocyte movement tracking;inflammatory tissue;medical image processing;automatic intravital video mining system;leukocytes migration detection;telecommunication networks discrete event simulation statistical analysis stochastic processes;vivo microscopy video;blood vessels;tracking	It is generally accepted that sequential procedures for stochastic discrete-event simulation of communication networks are the only practical approach for controlling statistical errors of the final simulation results. A commonly used stopping rule is based on the relative statistical error, since the magnitudes of the point estimates do not need to be known beforehand. The relative statistical error is defined as the ratio of the half-width of the confidence interval to the point estimate of the performance measure. The simulation is stopped when this ratio reaches a satisfactorily low value. One of the problems of this approach is that the inhe ently random nature of the output data can cause an accidental, temporary satisfaction of the stopping rule, resulting in acceptance of a result based on too-small samples of output data. We propose rules of thumb for protecting the quality of the final results from fully automated sequential procedures. The goal is to reduce the probability of finishing too early. The effectiveness of these rules of thumb is quantitatively assessed on the basis of the results of coverage analysis of a method of sequential output data analysis in steady-state simulation of communication networks: non-overlapping batch means.	error-tolerant design;experiment;heuristic;queueing theory;simulation;steady state;telecommunications network	Jong-Suk Ruth Lee;Hae-Duck Joshua Jeong	2007	The 2007 International Conference on Intelligent Pervasive Computing (IPC 2007)	10.1109/IPC.2007.52	computer vision;simulation;computer science;communication	Robotics	38.21351941714708	-77.07790183157297	29900
512117b01cb336bdbe203ba42a8d2370eb92ef48	very low bit rate video coding using morphological segmentation and contour/texture motion compensation	video signals low bit rate video coding feature extraction contour texture motion compensation time recursive morphological segmentation region based motion estimation image sequence;motion estimation;motion compensated;computer vision;bit rate video coding motion compensation image coding motion estimation signal processing algorithms layout image segmentation signal processing video signal processing;video coding;lts1	This paper describes a segmentation-based coding algorithm for very low bit rate. The algorithm involves a segmentation relying on a time recursive morphological segmentation technique. It extracts both large and contrasted regions. Then, a simple region-based motion estimation is performed. Finally, the sequence is coded by contour-texture motion compensation. The proposed method leads to very low bit rates while being able to represent the meaningful regions of the scene. Moreover, it makes no assumption about the scene content and can be used for any sequence.	data compression;motion compensation	Philippe Salembier;Chuang Gu;Montse Pardàs;Murat Kunt	1994		10.1109/ICPR.1994.577115	computer vision;quarter-pixel motion;computer science;coding tree unit;pattern recognition;motion estimation;block-matching algorithm;scale-space segmentation;motion compensation;computer graphics (images)	Vision	47.96219422786599	-54.221895862275204	29973
16a796a41d4be75c5aec64822edf858aa41cd67d	thresholding-based segmentation revisited using mixtures of generalized gaussian distributions	image segmentation;multimodal histogram image thresholding based segmentation multimodal class conditional distribution nongaussian distribution modeling otsu method kittler and illingworth minimum error thresholding mixture of generalized gaussian distribution mogg modeling;image segmentation gaussian distribution;image segmentation gaussian distribution histograms laplace equations pattern recognition dispersion biomedical imaging;gaussian distribution	This paper presents a new approach to image-thresholding-based segmentation. It considerably improves existing methods by efficiently modeling non-Gaussian and multi-modal class-conditional distributions. The proposed approach seamlessly: 1) extends the Otsu's method to arbitrary numbers of thresholds and 2) extends the Kittler and Illingworth minimum error thresholding to non-Gaussian and multi-modal class-conditional data. We use the recently-proposed mixture of generalized Gaussian distributions (MoGG) modeling, which enables to efficiently represent heavy-tailed data, as well as multi-modal histograms with flat and sharply-shaped peaks. Experiments performed on synthetic data and real-world image segmentation show the performance of the proposed approach with comparison to recent state-of-the-art techniques.	experiment;friedrich kittler;image segmentation;mixture model;modal logic;multi-core processor;otsu's method;procedural generation;synthetic data;thresholding (image processing);world file	Aissa Boulmerka;Mohand Saïd Allili	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		normal distribution;computer vision;computer science;segmentation-based object categorization;pattern recognition;balanced histogram thresholding;mathematics;region growing;thresholding;image segmentation;scale-space segmentation;statistics	Robotics	51.133648324134086	-69.16436958310346	29976
8fffbbb47a5af5577e3e2ddaeede152d5e619164	wavelet-based circular hough transform and its application in embryo development analysis	biological cells;machine vision;circular hough transform	Detecting object shapes from images remains a challenging problem in computer vision, especially in cases where some a priori knowledge of the shape of the objects of interest exists (such as circle-like shapes) and/or multiple object shapes overlap. This problem is important in the field of biology, particularly in the area of early-embryo development, where the dynamics is given by a set of cells (nearly-circular shapes) that overlap and eventually divide. We propose an approach to this problem that relies mainly on a variation of the circular Hough Transform where votes are weighted by wavelet kernels, and a fine-tuning stage based on dynamic programming. The wavelet-based circular Hough transform can be seen as a geometric-driven pulling mechanism in a set of convolved images, thus having important connections with well-stablished machine learning methods such as convolution networks.	accumulator (computing);algorithm;cell (microprocessor);computer vision;convolution;dynamic programming;hoare logic;hough transform;machine learning;onset (audio);the circle (file system);wavelet	Marcelo Cicconet;Davi Geiger;Kristin C. Gunsalus	2013			hough transform;computer vision;speech recognition;machine vision;computer science;computer graphics (images)	Vision	31.82683165435463	-60.87483477246458	29999
17b8ea08738ee6df8b338848fc39ba3c5cdefc76	spatial wavelets for temporally correlated fmri	temporal correlation;image resolution;image resolution wavelet transforms biomedical mri spatial filters;wavelet thresholding;magnetic resonance imaging blood fluctuations signal design hemodynamics white noise australia brain modeling context modeling magnetic noise;spatial filters;wavelet transforms;functional magnetic resonance images;spatio temporal models;spatially homogeneous filter spatial wavelet temporally correlated fmri spatio temporal model functional magnetic resonance imaging functional mri wavelet based activation estimation brain noise image resolution level wavelet thresholding visual mri;biomedical mri	Within the context of a properly formulated spatio-temporal model for functional magnetic resonance imaging (tMRI), we develop a procedure for wavelet-based activation estimation that explicitly accounts for the temporally correlated 'brain' noise. This leads to a kind of resolution level ~ dependent wavelet thresholdmg, a novelty in the spatial setting. The method is illustrated on a visual A-B fMRl experiment and is seen to give significantly better results compared with those obtainable via a more conventional smoothing step involving preprocessing with a spatially homogeneous filter.	preprocessor;resonance;smoothing;wavelet	Victor Solo;Emery N. Brown;Christopher J. Long	2003		10.1109/ICIP.2003.1246812	computer vision;speech recognition;image resolution;computer science;mathematics;wavelet transform	ML	50.76580970116526	-77.23886649079303	30137
6243f78ce5d64c97f7fe4a12b8611618582aa46a	atlas encoding by randomized forests for efficient label propagation		We propose a method for multi-atlas label propagation based on encoding the individual atlases by randomized classification forests. Most current approaches perform a non-linear registration between all atlases and the target image, followed by a sophisticated fusion scheme. While these approaches can achieve high accuracy, in general they do so at high computational cost. This negatively affects the scalability to large databases and experimentation. To tackle this issue, we propose to use a small and deep classification forest to encode each atlas individually in reference to an aligned probabilistic atlas, resulting in an Atlas Forest (AF). At test time, each AF yields a probabilistic label estimate, and fusion is done by averaging. Our scheme performs only one registration per target image, achieves good results with a simple fusion scheme, and allows for efficient experimentation. In contrast to standard forest schemes, incorporation of new scans is possible without retraining, and target-specific selection of atlases remains possible. The evaluation on three different databases shows accuracy at the level of the state of the art, at a significantly lower runtime.	algorithmic efficiency;alignment;anisotropic filtering;atlases;database;encode;forests;nonlinear system;numerous;random forest;randomized algorithm;scalability;software propagation;registration - actclass	Darko Zikic;Ben Glocker;Antonio Criminisi	2013	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-40760-4_9	computer science;bioinformatics;data science;data mining	Vision	29.2145348627337	-73.49979956445267	30155
6cde2105d32547dea63e5f58f6532f45cf82d6bb	descriptive local feature groups for image classification	image features;spatial context;visualization conferences feature extraction vocabulary computer vision pattern recognition entropy;object categorization;vocabulary;image classification;contextual information;local feature groups;computer vision;visualization;object categorization descriptive local feature groups image classification bag of visual words bow image representation spatial contextual information image features discriminative power spatial contexts;bag of features;local features;image representation;feature extraction;pattern recognition;entropy;image representation image classification;bag of visual words;image classification local feature groups bag of features bag of visual words object categorization;conferences	In the conventional bag of visual words (BoW) based image representation, single visual word is not discriminative enough and the spatial contextual information among local image features is ignored. In this paper, descriptive local feature groups are proposed to address these two problems. First, local image features are refined by slightly transforming the original image. Then they are clustered and represented by visual words. Second, the candidate local feature groups are generated by searching the neighbors of every local image features. This kind of grouping shows more discriminative power than a single feature and the local spatial contexts can be catched. Third, we obtain the groups more descriptive to the object category by defining a significance score and the groups with high score are selected. Finally, the high order descriptive local feature groups are integrated to the vector based object categorization framework by a feature reweighting strategy. Experimental results on Scene-15 and Caltech 101 demonstrate the superior performance of our method.	bag-of-words model in computer vision;caltech 101;categorization;regular expression;score bug;visual word	Lei Yu;Changsheng Xu	2011	2011 18th IEEE International Conference on Image Processing	10.1109/ICIP.2011.6116170	computer vision;entropy;contextual image classification;visualization;feature extraction;computer science;spatial contextual awareness;machine learning;pattern recognition;bag-of-words model in computer vision;feature	Vision	34.78094306387691	-54.66079775507609	30199
964f6b9d1bc925afcd307f128305831e1b34f49b	rivulet: 3d neuron morphology tracing with iterative back-tracking	3d neuron reconstruction;neuron morphology	The digital reconstruction of single neurons from 3D confocal microscopic images is an important tool for understanding the neuron morphology and function. However the accurate automatic neuron reconstruction remains a challenging task due to the varying image quality and the complexity in the neuronal arborisation. Targeting the common challenges of neuron tracing, we propose a novel automatic 3D neuron reconstruction algorithm, named Rivulet, which is based on the multi-stencils fast-marching and iterative back-tracking. The proposed Rivulet algorithm is capable of tracing discontinuous areas without being interrupted by densely distributed noises. By evaluating the proposed pipeline with the data provided by the Diadem challenge and the recent BigNeuron project, Rivulet is shown to be robust to challenging microscopic imagestacks. We discussed the algorithm design in technical details regarding the relationships between the proposed algorithm and the other state-of-the-art neuron tracing algorithms.	algorithm design;artificial neuron;image quality;interrupt;iterative method;mathematical morphology;name;numerous	Siqi Liu;Donghao Zhang;Sidong Liu;David Dagan Feng;Hanchuan Peng;Tom Weidong Cai	2016	Neuroinformatics	10.1007/s12021-016-9302-0	computer vision;simulation;computer science;artificial intelligence	Vision	39.95849259225431	-73.07657252505055	30240
9ee93e54a113c9ad9246088d626647210e1ade14	digital mammography	computers;technology;comparative studies;breast neoplasms;breast radiography;receiver operating characteristic curve (roc);diagnosis;calcification;diagnostic aid	This article considers the spatial scan statistic presented in [1] and discusses its applicability to digital mammography. The statistic utilizes stochastic scan partitions, and the availability of the sampling distribution for the statistic yields an exact test for the homogeneity of a point process. The test has the potential for improved power over conventional alternatives when the point process is embedded in an underlying continuous random field such as a gray-scale image, and is recommended in situations for which a cluster in the point process will correspond to a region in the underlying field which can be segmented as distinct from its surroundings. Theoretical, simulation, and experimental results from [1] indicating the validity and utility of the test for the detection of clustered microcalcifications in digital mammography are summarized.	embedded system;grayscale;point process;sampling (signal processing);simulation	Robert S. Cahn;BJORN CEDERSTROMl;MATS DANIELSSONl;Bruce H. Hasegawa;MATS LUNDQVISTl;David Nygren	1998		10.1007/978-94-011-5318-8		ML	40.01938165757023	-70.15450579685543	30247
bb04d42c73997786e15b76de6bfe6587f31d5dfa	facial expression recognition using facial expression intensity characteristics of thermal image	area of mouth and jaw;facial expression recognition;thermal image;and utterance judgment	To develop a robot that understands human feeling, we propose a method for recognizing facial expressions. A video was analyzed by thermal image processing and the feature parameter of facial expression, which was extracted in the area of the mouth and jaw by a two-dimensional discrete cosine transform. The facial expression intensity, defined as the norm of the difference vector between the feature vector of the neutral facial expression and that of the observed one, was measured. The feature vector made by facial expression intensity and time at utterance was used for recognizing facial expression.	discrete cosine transform;feature vector;image processing	Yasunari Yoshitomi;Taro Asada;Ryota Kato;Masayoshi Tabuse	2015	JRNAL	10.2991/jrnal.2015.2.1.2	psychology;computer vision;speech recognition;communication	Vision	29.544529611714566	-59.518731156280744	30275
7a74456e2cdd45d0aba3300275d8b719ad166921	feature-based detection of facial landmarks from neutral and expressive facial images	reconnaissance visage;mimica;vision ordenador;feature detection;detection forme;image segmentation;image processing;facies;edge detection;computer vision face detection image edge detection facial features face recognition image segmentation testing image databases nose mouth;analisis forma;mimique;procesamiento imagen;segmentation;indexing terms;shape detection;traitement image;computer vision;deteccion contorno;detection contour;deteccion forma;face recognition;edge and feature detection;feature extraction;segmentation image;algorithms artificial intelligence biometry face facial expression humans image interpretation computer assisted pattern recognition automated photography reproducibility of results sensitivity and specificity subtraction technique;image processing and computer vision;vision ordinateur;pattern analysis;facial expression;edge and feature detection index terms computing methodologies image processing and computer vision segmentation;characteristic edge pattern formed landmark candidates expressive facial images neutral facial images facial landmarks feature based detection edge map construction edge detection;computing methodologies;edge detection feature extraction face recognition;analyse forme;index terms computing methodologies	Feature-based method for detecting landmarks from facial images was designed. The method was based on extracting oriented edges and constructing edge maps at two resolution levels. Edge regions with characteristic edge pattern formed landmark candidates. The method ensured invariance to expressions while detecting eyes. Nose and mouth detection was deteriorated by happiness and disgust.	eye;face;map;sensor	Yulia Gizatdinova;Veikko Surakka	2006	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2006.10	computer vision;speech recognition;edge detection;index term;facies;image processing;feature extraction;computer science;pattern recognition;feature detection;image segmentation;segmentation;facial expression	Vision	42.7443058123935	-58.98610098028289	30278
88b72264f2d06f445f5bc10a45314a25e46aae32	image-based fire detection using neural networks	fire flame detection;color masking;burning degree estimation;neural network	An image-based fire detection method using neural networks is proposed in this paper. First, flame color features, based on the HSI color model, are trained by a backpropagation neural network for flame recognition. Then, based on the learned flame color features, regions with fire-like colors are roughly separated from an image. Besides segmenting flame regions, background objects with similar fire colors or resulted from the reflection of fire flames are also separated from the image. In order to get rid of these spurious fire-like regions, the image difference method and the invented color masking technique are applied. Finally, a compact method is devised to estimate the burning degree of fire flames so that users could be informed with a proper warning alarm. The proposed system can achieve 96.47% fire detection rate on average.	artificial neural network;backpropagation;color;horizontal situation indicator;neural network software	Wen-Bing Horng;Jian-Wen Peng	2006		10.2991/jcis.2006.301	color model;artificial neural network;spurious relationship;computer vision;fire detection;backpropagation;artificial intelligence;masking (art);computer science	Robotics	35.359995384348	-63.42881786528117	30281
6485a87ecd337ced597bb2cc92463545db8e1d4e	classification-driven stochastic watershed. application to multispectral segmentation		The aim of this paper is to present a general methodology based on multispectral mathematical morphology in order to segment multispectral images. The methods consists in computing a probability density function pdf of contours conditioned by a spectral classification. The pdf is conditioned through regionalized random balls markers thanks to a new algorithm. Therefore the pdf contains spatial and spectral information. Finally, the pdf is segmented by a watershed with seeds (i.e. markers) coming from the classification. Consequently, a complete method, based on a classificationdriven stochastic watershed is introduced. This approach requires a unique and robust parameter: the number of classes which is the same for similar images. Moreover, an efficient way to select factor axes, of Factor Correspondence Analysis (FCA), based on signal to noise ratio on factor pixels is presented.	algorithm;correspondence analysis;formal concept analysis;mathematical morphology;multispectral image;pixel;portable document format;seeds (cellular automaton);signal-to-noise ratio;stellar classification;watershed (image processing)	Guillaume Noyel;Jesús Angulo;Dominique Jeulin	2008				Vision	42.25682145160924	-66.94530467391242	30305
d5797ed8793f82a226ab054bccf97d92d7df077d	frequency divergence image: a novel method for action recognition		Action recognition systems have the potential to support clinicians, coaches and physical therapists in identifying important adopted movement patterns which could aid injury detection potential or inform rehabilitation strategies. Currently, motion capture systems, structured light pattern and time-of-flight sensors have utilization limitations that place constraints on their use outside of the laboratory setting. For this reason, we propose a system for human action recognition from video. The method presented in this work has utility with patient populations, such as Parkinson's disease, Alzheimer's disease, multiple sclerosis and dementia, outside of laboratory setting to detect the degree of which, and progression of, gait pathology. We developed a novel vision algorithm for template matching—the characterization of the motion in a video sequence. The method, titled Frequency Divergence Image, is a paradigm shift in template matching methods. Template matching methods measure macro-motion, whereas the proposed method detects micro-motion that differs from the flow of the action. We show that micro-cues improve prediction performance of human action on a real-world data set. We demonstrate a 9.15% improvement in classification accuracy over the original Motion History Image formulation when used with a convolutional neural network. Future work will focus on the deployment of the system to identify gait pathology from various patient populations.	algorithm;artificial neural network;color gradient;convolutional neural network;motion capture;population;programming paradigm;sensor;software deployment;structured light;template matching	Albert C. Cruz;Brian Street	2017	2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)	10.1109/ISBI.2017.7950722	convolutional neural network;computer vision;structured light;computer science;software deployment;pattern recognition;support vector machine;machine learning;motion capture;artificial neural network;gait;template matching;artificial intelligence	Vision	26.805453122601538	-75.86348536114005	30359
c06ca26b33ab2e9ce118ca02018be5834e8164a6	robust ear recognition using gradient ordinal relationship pattern		A reliable personal recognition based on ear biometrics is highly in demand due to its vast application in automated surveillance, law enforcement etc. In this paper a robust ear recognition system is proposed using gradient ordinal relationship pattern. A reference point based normalization is proposed along with a novel ear transformation over normalized ear, to obtain robust ear representations. Ear samples are enhanced using a local enhancement technique. Later a dissimilarity measure is proposed that can be used for matching ear samples. Two publicly available ear databases IITD and UND-E are used for the performance analysis. The proposed system has shown very promising results and significant improvement over the existing state of the art ear systems. The proposed system has shown robustness against small amount of illumination variations and affine transformations due to the virtue of ear transformation and tracking based matching respectively.	authentication;biometrics;database;feature extraction;gradient;journal of automata, languages and combinatorics;line code;ordinal data;pattern recognition;profiling (computer programming);region of interest;scheme;speech enhancement;viz: the computer game	Aditya Nigam;Phalguni Gupta	2014		10.1007/978-3-319-16634-6_45	speech recognition;machine learning;pattern recognition	Vision	33.74067046388451	-60.57746328880485	30449
408fbfc38f380e54888c763579884091866a7353	an effective combination of mpp contour-based features for off-line text-independent arabic writer identification	handwriting recognition;writer identification;feature vector;distance metric;ranking algorithm;probability distribution function	  This paper proposes an off-line, text-independent, Arabic writer identification approach, using a combination of probability  distribution function (PDF) features. In writer identification, the success of PDFs in terms of homogeneity, classification  and identification rates encouraged researchers to study them with different types of structural features. Intensive experiments  achieved on 82 writers from the IFN/ENIT database show, in particular, that 6 simple feature vectors based on the length,  direction, angle and curvature measurements, which are extracted from the minimum-perimeter polygon (MPP) contours of the  pieces of Arabic words, can be used to reach promising Arabic writer identification rates. The results are obtained using  a set of distance metrics and the Borda ranking algorithm for classification, and the best identification rates are 90.2%  for top1, and 97.5% for top10, which confirm the consistency of the proposed approach.    	contour line;goodyear mpp	Mohamed Nidhal Abdi;Maher Khemakhem;Hanêne Ben-Abdallah	2009		10.1007/978-3-642-10546-3_26	speech recognition;computer science;machine learning;pattern recognition	NLP	34.046195668220435	-64.30026453042666	30456
7764db7ae4aca2e80d84a620b0c3aade026f6d9c	hippocampal shape modeling based on a progressive template surface deformation and its verification	surface roughness;shape analysis brain hippocampus magnetic resonance imaging mri progressive model deformation;deformable models;subtle shape changes hippocampal shape modeling progressive template surface deformation rough segmentations noisy segmentations anatomical correspondence mesh to volume registration progressive model deformation flexible weighting scheme model rigidity multilevel neighborhood vertex connectivity large to small scale deformation pairwise correspondence geometric distortion individual shape characteristics smooth surface reconstruction mild cognitive impairment alzheimer s disease individual shape models cognitive abilities spharm pdm shapeworks lddmm volume registration template injection shape similarity surface roughness shape deformity statistical analyses clinical variables;rough surfaces;laplace equations;shape;diseases;robustness;shape deformable models diseases laplace equations rough surfaces surface roughness robustness;surface roughness biomedical mri brain cognition deformation diseases image registration image segmentation medical image processing physiological models shear modulus statistical analysis	Accurately recovering the hippocampal shapes against rough and noisy segmentations is as challenging as achieving good anatomical correspondence between the individual shapes. To address these issues, we propose a mesh-to-volume registration approach, characterized by a progressive model deformation. Our model implements flexible weighting scheme for model rigidity under a multi-level neighborhood for vertex connectivity. This method induces a large-to-small scale deformation of a template surface to build the pairwise correspondence by minimizing geometric distortion while robustly restoring the individuals' shape characteristics. We evaluated the proposed method's 1) accuracy and robustness in smooth surface reconstruction, 2) sensitivity in detecting significant shape differences between healthy control and disease groups (mild cognitive impairment and Alzheimer's disease), 3) robustness in constructing the anatomical correspondence between individual shape models, and 4) applicability in identifying subtle shape changes in relation to cognitive abilities in a healthy population. We compared the performance of the proposed method with other well-known methods-SPHARM-PDM, ShapeWorks and LDDMM volume registration with template injection-using various metrics of shape similarity, surface roughness, volume, and shape deformity. The experimental results showed that the proposed method generated smooth surfaces with less volume differences and better shape similarity to input volumes than others. The statistical analyses with clinical variables also showed that it was sensitive in detecting subtle shape changes of hippocampus.	alzheimer's disease;anatomical point;clinical use template;cognition disorders;congenital abnormality;distortion;k-vertex-connected graph;large deformation diffeomorphic metric mapping;muscle rigidity;numerous;point-to-point protocol;spharm-pdm;self-similarity;sensor;verification of theories;vertex;registration - actclass	Jae-il Kim;Maria del C. Valdés Hernández;Natalie A. Royle;Jinah Park	2015	IEEE Transactions on Medical Imaging	10.1109/TMI.2014.2382581	active shape model;computer vision;surface roughness;shape;computer science;shape analysis;mathematics;geometry;robustness	Vision	42.459637090970496	-79.38130971207855	30466
54c1a01159a983ff0c6a09ea91169b8e62f79925	improving airway segmentation in computed tomography using leak detection with convolutional networks	airway segmentation;chest computed tomography;convolutional networks	We propose a novel method to improve airway segmentation in thoracic computed tomography (CT) by detecting and removing leaks. Leak detection is formulated as a classification problem, in which a convolutional network (ConvNet) is trained in a supervised fashion to perform the classification task. In order to increase the segmented airway tree length, we take advantage of the fact that multiple segmentations can be extracted from a given airway segmentation algorithm by varying the parameters that influence the tree length and the amount of leaks. We propose a strategy in which the combination of these segmentations after removing leaks can increase the airway tree length while limiting the amount of leaks. This strategy therefore largely circumvents the need for parameter fine-tuning of a given airway segmentation algorithm. The ConvNet was trained and evaluated using a subset of inspiratory thoracic CT scans taken from the COPDGene study. Our method was validated on a separate independent set of the EXACT'09 challenge. We show that our method significantly improves the quality of a given leaky airway segmentation, achieving a higher sensitivity at a low false-positive rate compared to all the state-of-the-art methods that entered in EXACT09, and approaching the performance of the combination of all of them.	ct scan;chest;convolutional neural network;extraction;independent set (graph theory);inspiration function;neural network simulation;population parameter;sensor;subgroup;supervised learning;algorithm;biologic segmentation	Jean-Paul Charbonnier;Eva M. van Rikxoort;Arnaud A. A. Setio;Cornelia Schaefer-Prokop;Bram van Ginneken;Francesco Ciompi	2017	Medical image analysis	10.1016/j.media.2016.11.001	computer vision;simulation	Vision	30.96117085970522	-75.44819937689167	30481
2953afc34c4b6182e3daba1e07a592a7457ce17c	review on feature extraction technique for handwritten marathi compound character recognition	end points;optical character recognition;loops;junctions;devanagari script feature extraction technique unconstrained handwritten marathi compound character recognition handwriting text recognition system design marathi script;zoning;feature extraction;optical character recognition feature extraction handwritten character recognition;junctions zoning statistical end points loops;statistical;feature extraction character recognition compounds accuracy handwriting recognition histograms market research;handwritten character recognition	This paper give a short review on feature extraction technique for Handwritten Marathi Compound Character recognition. The ultimate goal of designing a handwriting recognition system with an accuracy rate of 100% is quite illusionary, because even human beings are not able to recognize every handwritten text without any doubt. Compound characters which are one of the features of Marathi script, derived from Devanagari, occur frequently in the script. Recognition of these characters faces challenges to the researchers due to their complex structure. This paper presents a different feature extraction techniques for recognition of unconstrained handwritten Marathi compound characters.	feature extraction;handwriting recognition;optical character recognition	Snehal S. Golait;Latesh G. Malik	2013	2013 6th International Conference on Emerging Trends in Engineering and Technology	10.1109/ICETET.2013.33	natural language processing;speech recognition;document processing;feature;feature extraction;intelligent character recognition;computer science;intelligent word recognition;pattern recognition	Robotics	32.717730961624596	-67.19735558092286	30556
678c6fa7df31680da9d88a09803504281d4cacd6	cross entropy: a new solver for markov random field modeling and applications to medical image segmentation	cross entropy;stochastic method;optimal method;rare event simulation;simulated annealing;markov random field;objective function;belief propagation;graph cut;medical image segmentation	This paper introduces a novel solver, namely cross entropy (CE), into the MRF theory for medical image segmentation. The solver, which is based on the theory of rare event simulation, is general and stochastic. Unlike some popular optimization methods such as belief propagation and graph cuts, CE makes no assumption on the form of objective functions and thus can be applied to any type of MRF models. Furthermore, it achieves higher performance of finding more global optima because of its stochastic property. In addition, it is more efficient than other stochastic methods like simulated annealing. We tested the new solver in 4 series of segmentation experiments on synthetic and clinical, vascular and cerebral images. The experiments show that CE can give more accurate segmentation results.	belief propagation;cross entropy;cut (graph theory);experiment;extreme value theory;global optimization;graph - visual representation;image segmentation;incised wound;markov chain;markov random field;mathematical optimization;medical image;medical records systems, computerized;segmentation action;simulated annealing;simulation;software propagation;solver;synthetic intelligence;biologic segmentation	Jue Wu;Albert C. S. Chung	2005	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/11566465_29	mathematical optimization;cut;simulated annealing;computer science;machine learning;segmentation-based object categorization;pattern recognition;mathematics;image segmentation;scale-space segmentation;cross entropy;belief propagation	Vision	44.219466879841	-75.03328357020268	30608
4acb7cb1fa31011e569947759c28b3e79d35f2b9	toward 3-d gesture recognition	mouvement main;orientation doigt;estimation mouvement;methode gant libre;modelo 3 dimensiones;modele 3 dimensions;gesture;estimacion movimiento;reconocimiento;three dimensional model;motion estimation;tracking hand movement;recognition;hand tracking;estimacion parametro;mouvement tridimensionnel;parameter estimation;estimation parametre;reconnaissance;geste;gesture recognition;gesto	This paper presents a glove-free method for tracking hand movements using a set of 3-D models. In this approach, the hand is represented by ve cylindrical models which are t to the third phalangeal segments of the ngers. Six 3-D motion parameters for each model are calculated that correspond to the movement of the ngertips in the image plane. Trajectories of the moving models are then established to show the 3-D nature of the hand motion.	gesture recognition;image plane	James W. Davis;Mubarak Shah	1999	IJPRAI	10.1142/S0218001499000227	computer vision;computer science;motion estimation;gesture recognition;estimation theory;gesture	Vision	49.23289836225361	-56.973384657209564	30655
da2e3c451f8bbd27cfca14a8d0b5c8aadfcc0a7e	learning to segment in images and videos with different forms of supervision				Anna Khoreva	2017				Vision	29.296997855227488	-57.51361234175816	30723
3578090aa0257284e9978bd7fda4d4f7bfd7c59f	region-based image retrieval using color-size features of watershed regions	user interface;region based image retrieval;visual feature;region filtering;region of interest;visual features;earth mover s distance;content based image retrieval;similarity measure;color size feature;image retrieval	This paper presents a region-based image retrieval system that provides a user interface for helping to specify the watershed regions of interest within a query image. We first propose a new type of visual features, called color-size feature, which includes color-size histogram and moments, to integrate color and region-size information of watershed regions. Next, we design a scheme of region filtering that is based on color-size histogram to fast screen out some of most irrelevant regions and images for the preprocessing of the image retrieval. Our region-based image retrieval system applies the Earth Mover’s Distance in the design of the similarity measure for image ranking and matching. Finally, we present some experiments for the color-size feature, region filtering, and retrieval results that demonstrate the efficiency of our proposed system. 2009 Elsevier Inc. All rights reserved.	color;experiment;image retrieval;image scaling;interactivity;matching (graph theory);preprocessor;region of interest;relevance feedback;similarity measure;user interface;watershed (image processing)	Cheng-Chieh Chiang;Yi-Ping Hung;Hsuan Yang;Greg C. Lee	2009	J. Visual Communication and Image Representation	10.1016/j.jvcir.2009.01.001	earth mover's distance;image texture;computer vision;feature detection;visual word;image retrieval;computer science;pattern recognition;user interface;automatic image annotation;feature;information retrieval;region of interest	Vision	39.00864968199874	-60.80960647291989	30750
12a005a33c822184a3e25bc0d1193a5b69cfd51b	hodor: histogram of differential orientations for rigid landmark tracking in medical images		Feature extraction plays a pivotal role in pattern recognition and matching. An ideal feature should be invariant to image transformations such as translation, rotation, scaling, etc. In this work, we present a novel rotation-invariant feature, which is based on Histogram of Oriented Gradients (HOG). We compare performance of the proposed approach with the HOG feature on 2D phantom data, as well as 3D medical imaging data. We have used traditional histogram comparison measures such as Bhattacharyya distance and Normalized Correlation Coefficient (NCC) to assess efficacy of the proposed approach under effects of image rotation. In our experiments, the proposed feature performs 40%, 20%, and 28% better than the HOG feature on phantom (2D), Computed Tomography (CT-3D), and Ultrasound (US-3D) data for image matching, and landmark tracking tasks respectively.		Abhishek Tiwari;Kedar Anil Patwardhan	2018		10.1117/12.2293083	histogram of oriented gradients;imaging phantom;feature extraction;computer vision;invariant (mathematics);medical imaging;scaling;histogram;mathematics;artificial intelligence;bhattacharyya distance	Vision	40.42656550528099	-56.86051095325714	30756
7b8a7885fb108a622c2c8cbad083d0dc7b3c9371	variational networks for joint image reconstruction and classification of tumor immune cell interactions in melanoma tissue sections		Immunotherapy is currently revolutionizing the treatment of cancer. Detailed analyses of tumor immune cell interaction in the tumor microenvironment will facilitate an accurate prediction of a patient’s clinical response. The automatic and reliable pre-screening of histological tissue sections for tumor infiltrating immune cells (TILs) will support the development of TIL-based predictive biomarkers for checkpoint immunotherapy. In this paper, a learning approach for image classification is presented, which allows various pattern inquires for different types of tissue section images. The underlying trainable reaction diffusion model combines classification and denoising. The model is trained using a stochastic generation of training data. The effectiveness of this approach is demonstrated for immunofluorescent and for Hematoxylin and Eosin (H&E) stained melanoma section images. A particular focus is on the classification of TILs in the proximity to melanoma cells in an experimental melanoma mouse model and in human melanoma. This new learning approach for images of melanoma tissue sections will refine the strategy for the practical clinical application of biomarker research.	computer vision;habitat;interaction;iterative reconstruction;noise reduction;transaction processing system;variational principle	Alexander Effland;Michael Hölzel;Teresa Klatzer;Erich Kobler;Jennifer Landsberg;Leonie Neuhäuser;Thomas Pock;Martin Rumpf	2018		10.1007/978-3-662-56537-7_86	cancer;h&e stain;immunotherapy;tumor microenvironment;immune system;biomarker (medicine);melanoma;contextual image classification;cancer research;computer science	ML	30.55020786946482	-76.87238036085357	30852
35e92b5e1186059fe82df0bf17bdc3679e300238	regional appearance modeling based on the clustering of intensity profiles	unsupervised clustering;appearance modeling;medical imaging;model based image segmentation	Model-based image segmentation is a popular approach for the segmentation of anatomical structures from medical images because it includes prior knowledge about the shape and appearance of structures of interest. This paper focuses on the formulation of a novel appearance prior that can cope with large variability between subjects, for instance due to the presence of pathologies. Instead of relying on Principal Component Analysis such as in Statistical Appearance Models, our approach relies on a multimodal intensity profile atlas from which a point may be assigned to several profile modes consisting of a mean profile and its covariance matrix. These profile modes are first estimated without any intra-subject registration through a boosted EM classification based on spectral clustering. Then, they are projected on a reference mesh whose role is to store the appearance information in a common geometric representation. We show that this prior leads to better performance than the classical monomodal Principal Component Analysis approach while relying on fewer profile modes.	cluster analysis;heart rate variability;image segmentation;medical imaging;multimodal interaction;principal component analysis;spectral clustering;statistical machine translation	François Chung;Hervé Delingette	2013	Computer Vision and Image Understanding	10.1016/j.cviu.2013.01.011	medical imaging;computer vision;active appearance model;machine learning;pattern recognition	Vision	43.97911428705902	-77.7361342658765	30868
c44a9d030a040029bbf343670606750a2c5d83ff	an automated vehicle license plate recognition system	object recognition;localization;licenses computer vision intelligent vehicles object recognition;computer vision;car models automated vehicle license plate recognition system computer vision method vehicle identification plate localization process image capture process license plate number recognition;recognition;intelligent vehicles;licenses;wavelet license plate localization recognition;wavelet;traffic engineering computing computer vision image recognition;license plate	License plate recognition is a computer vision method that identifies vehicles from their license plates. The most crucial step of such a system is accurate localization of the plate. The authors propose a system for automatic recognition that has three phases: image capture, plate localization, and license plate number recognition. They tested their methodology on 40 different car models with different types of license plates.	automatic number plate recognition;computer vision	Hitesh Rajput;Tanmoy Som;Soumitra Kar	2015	Computer	10.1109/MC.2015.244	wavelet;computer vision;simulation;speech recognition;internationalization and localization;computer science;cognitive neuroscience of visual object recognition;statistics	Vision	32.485925396493116	-57.66786087664176	30881
a1e2e5d3cd10c7a39842a487131cc8049f0a0275	fractional discrimination for texture image segmentation	filtering;image segmentation;edge detection;institute for integrated and intelligent systems;texture classification;conference output;information technology;local scales;image classification;texture features;discriminant function;fractional discrimination functions;global scale;feature identification texture image segmentation fractional discrimination functions image texture analysis texture classification texture edge points enhancement image decomposition contextual filtering global scale local scales;image texture;texture analysis;image edge detection;feature identification;feature extraction;image segmentation feature extraction image edge detection image texture analysis image decomposition filtering information technology microelectronics australia image analysis;image analysis;texture edge points enhancement;image texture analysis;texture image segmentation;microelectronics;contextual filtering;image decomposition;edge detection image texture image segmentation image classification feature extraction filtering theory;filtering theory;australia	Texture image segmentation plays an important role in texture analysis. This paper presents an approach to image segmentation by texture classification based on fractional discrimination functions. The idea behind this method is to enhance the texture edge points b y means of image decomposition and contextual filtering in terms of the proposed fractional function. In addition, such function is described in a unified form with three-parameters. The parameters determine the global scale in conjunction with local scales for feature identification. Our experimental results show that texture features can be effectively extracted on the basis of the selective fractional discrimination function.	image segmentation	Jane You;Suresh Hungenahally;Abdul Sattar	1997		10.1109/ICIP.1997.647743	filter;image texture;computer vision;contextual image classification;image analysis;edge detection;feature extraction;computer science;machine learning;pattern recognition;discriminant function analysis;mathematics;image segmentation;scale-space segmentation;texture compression;information technology;texture filtering;microelectronics	Vision	40.095803410817844	-63.26169080405276	30889
6b7833a6541d093c5cc9ae50d81757eaa0f280d0	embarrassingly simple model for early action proposal		Early action proposal consists in generating high quality candidate temporal segments that are likely to contain an action in a video stream, as soon as they happen. Many sophisticated approaches have been proposed for the action proposal problem but from the off-line perspective. On the contrary, we focus on the on-line version of the problem, proposing a simple classifier-based model, using standard 3D CNNs, that performs significantly better than the state of the art.	display resolution;online and offline;streaming media	Marcos Baptista-Ríos;Roberto Javier López-Sastre;Francisco Javier Acevedo-Rodríguez;Saturnino Maldonado-Bascón	2018	CoRR		machine learning;pattern recognition;artificial intelligence;classifier (linguistics);computer science	Vision	27.74860377142246	-52.46728200125914	30893
34e3f9417f0d223cda4ecca3cd2e3cd38fc98ade	methodology for the design of nn-based month-word recognizers written on brazilian bank checks	neural networks;rejection;real world application;handwritten word recognition;feature selection;modular architecture;artificial neural network;neural network	The study of handwritten words is tied to the development of recognition methods to be used in real-world applications involving handwritten words, such as bank checks, postal envelopes, and handwritten texts, among others. In this work, the focus is handwritten words in the context of Brazilian bank checks, specifically the months of the year, and no restrictions are placed on the types or styles of writing or the number of writers. A global feature set and two architectures of artificial neural networks (ANN) are evaluated for classification of the words. The objectives are to evaluate the performance of conventional and class-modular MLP (multiplelayer perceptron) architectures, to develop a rejection mechanism based on multiple thresholds, and to analyze the behavior of the feature set proposed in the two architectures. The experimental results demonstrate the superiority of the class-modular architecture over the conventional MLP architecture. A rejection mechanism with multiple thresholds demonstrates favorable performance in both architectures. The feature set analysis shows the importance of the structural primitives such as concavities and convexities, and perceptual primitives such as ascenders and descenders. The experimental results reveal a recognition rate of 81.75% without the rejection mechanism, and a reliability rate 91.52% with a rejection rate of 25.33%.	artificial neural network;black box;computation;feature selection;finite-state machine;lexicon;local search (optimization);memory-level parallelism;perceptron;postal;programming paradigm;rejection sampling;semantic network	Marcelo N. Kapp;Cinthia Obladen de Almendra Freitas;Robert Sabourin	2007	Image Vision Comput.	10.1016/j.imavis.2006.01.005	speech recognition;computer science;artificial intelligence;machine learning;artificial neural network	ML	24.982692813226397	-62.1401984195194	30914
7ba03f48d0ebc26b134db3c13b233d31f2b1661f	random subspace for an improved biohashing for face authentication	reconnaissance visage;image processing;biometrie;authentication;biometrics;biometria;procesamiento imagen;face verification;metodo subespacio;feature space;traitement image;random number;biohashing;methode sous espace;authentification;automatic recognition;autenticacion;face recognition;random subspace;pattern recognition;subspace method;nombre aleatoire;reconnaissance forme;reconocimiento patron;random numbers;numero aleatorio;dimensional reduction;reconocimiento automatico;reconnaissance automatique	Verification based on tokenised pseudo-random numbers and user specific biometric feature has received much attention. In this paper, we propose a BioHashing system for automatic face recognition based on Fisher-based Feature Transform, a supervised transform for dimensionality reduction that has been proved to be very effective for the face recognition task. Since the dimension of the Fisher-based transformed space is bounded by the number of classes – 1, we use random subspace to create K feature spaces to be concatenated in a new higher dimensional space, in order to obtain a big and reliable ‘‘BioHash code’’. 2007 Elsevier B.V. All rights reserved.	authentication;best, worst and average case;biometrics;concatenation;dimensionality reduction;enhanced entity–relationship model;feret (facial recognition technology);feret database;facial recognition system;hash function;pseudorandomness	Loris Nanni;Alessandra Lumini	2008	Pattern Recognition Letters	10.1016/j.patrec.2007.10.005	computer vision;speech recognition;image processing;computer science;artificial intelligence;authentication;mathematics	AI	44.410917301286844	-59.99491391717649	30918
12e8843f2a1753c37493b7e906641737b8414e26	integation methods of model-free features for 3d tracking	metodo cuadrado menor;modelizacion;model based reasoning;methode moindre carre;optimisation;raisonnement base sur modele;pistage;filtro kalman;image processing;least squares method;optimizacion;occlusion;wireframe;integration information;real time;occultation;filtre kalman;rastreo;procesamiento imagen;oclusion;kalman filter;outlier;traitement image;modelisation;observacion aberrante;posture;information integration;robustesse;temps reel;least square;integracion informacion;postura;tiempo real;observation aberrante;robustness;optimization;ocultacion;modeling;tracking;grafico de tipo alambre;dessin au trait;robustez	A number of approaches for 3D pose tracking have been recently introduced, most of them utilizing an edge (wireframe) model of the target. However, the use of an edge model has significant problems in complex scenes due to background, occlusions, and multiple responses. Integration of model-free information has been recently proposed to decrease these problems.#R##N##R##N#In this paper, we propose two integration methods for model-free point features to enhance the robustness and to increase the performance of real-time model-based tracking. The relative pose change between frames is estimated using an optimization approach. This allows the pose change to be integrated very efficiently in a Kalman filter. Our first approach estimates the pose change in a least squares sense while the second one uses M-estimators to decrease the effect of outliers. Experiments are presented which demonstrate that the approaches are superior in performance to earlier approaches.		Ville Kyrki;Kerstin Schmock	2005		10.1007/11499145_57	computer vision;simulation;image processing;computer science;least squares;statistics	Vision	47.8492109661201	-57.15882194394953	30958
64364da7171e502d75e9be3c629fc3b2d07002b2	performance analysis of various local and global shape descriptors for image retrieval	angular radial transform;zernike moments;fourier descriptor;hough transform;image retrieval	In this paper, various prominent local and global descriptors are evaluated against each other for analyzing their performance on shape-based image retrieval. Local descriptors include Fourier descriptors, Weber’s local descriptor, local binary patterns, and local ternary patterns. The prominent global descriptors include moment invariants, generic Fourier descriptor (GFD), angular radial transform (ART), wavelet moments (WM), and Zernike moment descriptor (ZMD). In addition, a novel local descriptor is proposed based on the histograms of circular arcs and linear edges, which are detected by means of Hough transform. The proposed local descriptor provides features, which are invariant to geometric transformations and are robust to noise as compared to some existing prominent local descriptors. We also propose an improvement in the performance of global descriptors GFD, ART, WM, and ZMD by taking advantage of the phase information in the comparison process along with their magnitude. Subsequently, the local and global descriptors with the best image-retrieval performances are combined to design an effective retrieval system, which further enhances the retrieval performance substantially. All descriptors are analyzed in terms of six principles set by MPEG-7. Detailed experiments are performed on standard benchmark image databases along with their rotation-invariance and noise test. The results of experiments reveal that the proposed fusion of local and global descriptors outperforms other major descriptors.	angularjs;benchmark (computing);database;experiment;fast fourier transform;global optimization;hough transform;image retrieval;local binary patterns;local ternary patterns;mpeg-7;performance;poisson wavelet;profiling (computer programming);radial (radio);zmdi	Chandan Singh;Pooja Sharma	2012	Multimedia Systems	10.1007/s00530-012-0288-7	hough transform;computer vision;image retrieval;computer science;machine learning;pattern recognition	Vision	37.87421725028406	-59.357517652944196	30971
f612a87930847cb92363544a19234060d8f82340	probabilistic diffeomorphic registration: representing uncertainty		This paper presents a novel mathematical framework for representing uncertainty in large deformation diffeomorphic image registration. The Bayesian posterior distribution over the deformations aligning a moving and a fixed image is approximated via a variational formulation. A stochastic differential equation (SDE) modeling the deformations as the evolution of a time-varying velocity field leads to a prior density over deformations in the form of a Gaussian process. This permits estimating the full posterior distribution in order to represent uncertainty, in contrast to methods in which the posterior is approximated via Monte Carlo sampling or maximized in maximum a-posteriori (MAP) estimation. The framework is demonstrated in the case of landmark-based image registration, including simulated data and annotated pre and intra-operative 3D images.	approximation algorithm;calculus of variations;gaussian process;image registration;monte carlo method;sampling (signal processing);velocity (software development)	Demian Wassermann;Matthew Toews;Marc Niethammer;William M. Wells	2014		10.1007/978-3-319-08554-8_8	computer vision;mathematical optimization;mathematics;geometry	Vision	47.361855913322984	-76.86359362724872	30994
b96d19553be5230afa3a67e9fa2f7feed9a358d0	robust automatic human identification using face, mouth, and acoustic information	reconnaissance visage;gaussian noise;vision ordenador;fiabilidad;reliability;base donnee;sistema experto;image processing;data compression;multimodal fusion;facies;signal visuel;biometrie;acoustics;biometrics;ruido gaussiano;database;biometria;procesamiento imagen;base dato;senal visual;personal identity;traitement image;computer vision;identificacion sistema;face recognition;system identification;fiabilite;robustesse;bruit gaussien;visual signal;pattern recognition;visual control;human identification;controle visuel;robustness;vision ordinateur;compresion dato;reconnaissance forme;information system;systeme expert;reconocimiento patron;acoustique;systeme information;identification systeme;control visual;compression donnee;acustica;robustez;sistema informacion;expert system	Discriminatory information about person identity is multimodal. Yet, most person recognition systems are unimodal, e.g. the use of facial appearance. With a view to exploiting the complementary nature of different modes of information and increasing pattern recognition robustness to test signal degradation, we developed a multiple expert biometric person identification system that combines information from three experts: face, visual speech, and audio. The system uses multimodal fusion in an automatic unsupervised manner, adapting to the local performance and output reliability of each of the experts. The expert weightings are chosen automatically such that the reliability measure of the combined scores is maximized. To test system robustness to train/test mismatch, we used a broad range of Gaussian noise and JPEG compression to degrade the audio and visual signals, respectively. Experiments were carried out on the XM2VTS database. The multimodal expert system out performed each of the single experts in all comparisons. At severe audio and visual mismatch levels tested, the audio, mouth, face, and tri-expert fusion accuracies were 37.1%, 48%, 75%, and 92.7% respectively, representing a relative improvement of 23.6% over the best performing expert.	acoustic cryptanalysis;authentication;biometrics;elegant degradation;expert system;image noise;informatics;jpeg;multimodal interaction;oracle fusion architecture;pattern recognition;software deployment;triangular function;uncontrolled format string;unsupervised learning;user-centered design;videotelephony	Niall A. Fox;Ralph Gross;Jeffrey F. Cohn;Richard B. Reilly	2005		10.1007/11564386_21	data compression;personal identity;facial recognition system;gaussian noise;computer vision;speech recognition;facies;system identification;image processing;computer science;artificial intelligence;reliability;expert system;information system;biometrics;robustness	Vision	45.300006597742076	-60.36906093685679	31019
1cca9d668a82f7a5ac184ed2c4d4c5506b2d93aa	performance analysis of a fast distance transform algorithm in the euclidean metric	performance analysis;distance transform		algorithm;distance transform;euclidean distance;profiling (computer programming)	Marina L. Gavrilova;Muhammad H. Alsuwaiyel;Juraj Pivovarov	2002			mathematical optimization;minkowski distance;s transform;distance matrix;computer science;chebyshev distance;euclidean distance;euclidean distance matrix;distance transform	Vision	45.128154096951	-64.53324793087451	31032
497f354bd3838f32130f317a6c9b27882141dcb5	an algorithm on sign words extraction and recognition of continuous persian sign language based on motion and shape features of hands		Sign language is the most important means of communication for deaf people. Given the lack of familiarity of non-deaf people with the language of deaf people, designing a translator system which facilitates the communication of deaf people with the surrounding environment seems to be necessary. The system of translating the sign language into spoken languages should be able to identify the gestures in sign language videos. Consequently, this study provides a system based on machine vision to recognize the signs in continuous Persian sign language video. This system generally consists of two main phases of sign words extraction and their classification. Several stages, including tracking and separating the sign words, are conducted in the sign word extraction phase. The most challenging part of this process is separation of sign words from video sequences. To do this, a new algorithm is presented which is capable of detecting accurate boundaries of words in the Persian sign language video. This algorithm decomposes sign language video into the sign words using motion and hand shape features, leading to more favorable results compared to the other methods presented in the literature. In the classification phase, separated words are classified and recognized using hidden Markov model and hybrid KNN-DTW algorithm, respectively. Due to the lack of proper database on Persian sign language, the authors prepared a database including several sentences and words performed by three signers. Simulation of proposed words boundary detection and classification algorithms on the above database led to the promising results. The results indicated an average rate of 93.73 % for accurate words boundary detection algorithm and the average rate of 92.4 and 92.3 % for words recognition using hands motion and shape features, respectively.	hidden markov model;k-nearest neighbors algorithm;machine vision;markov chain;sensor;simulation	Masoud Zadghorban;Manoochehr Nahvi	2016	Pattern Analysis and Applications	10.1007/s10044-016-0579-2	natural language processing;cued speech;speech recognition;computer science;stop words	Vision	30.64876002622596	-60.67313482977507	31075
00ce935e1de2b1ec2e10deed56a61abdc51f0bac	a new approach for fingerprint minutia extraction algorithm.			algorithm;fingerprint	Maha Tolba;Tigran Andreasyan;Vahan Markarov	2010			computer network;computer vision;computer science;minutiae;fingerprint;artificial intelligence	NLP	35.02144636980959	-62.323348564812086	31104
6579130da4fab69a7365a7cab958ef3768ee3640	diabetic retinopathy detection using feedforward neural network		Diabetic Retinopathy is an eye disorder which causes vision blurriness and blindness in diabetic patients. Currently, detection of Diabetic Retinopathy involves manual methods in which physical examination is done by a trained eye physician. This consumes a lot of time of the physician which could have been devoted to other patients. This paper tries to tackle this issue by using computer vision to not only detect this disease, but also automating this procedure using neural network to give results of many patients within a short time frame.	artificial neural network;computer vision;feedforward neural network	Jayant Yadav;Manish Sharma;Vikas Saxena	2017	2017 Tenth International Conference on Contemporary Computing (IC3)	10.1109/IC3.2017.8284350	artificial intelligence;computer vision;artificial neural network;physical examination;eye disorder;feedforward neural network;optometry;diabetic retinopathy;blindness;computer science	Vision	33.20869210686924	-76.22617884425375	31161
e76dc361db36bcb69b3c7ea20d6f513ac6c10cd2	fine-grained classification of identity document types with only one example	histograms;neural networks;training;layout;optical character recognition software;accuracy;visualization;histograms training accuracy optical character recognition software visualization layout neural networks;training image fine grained classification identity document types state of the art visual recognition scanned document feature representations convolutional neural networks;neural nets document image processing image classification image representation	In this paper, we tackle the task of recognizing types of partly very similar identity documents using state-of-the-art visual recognition approaches. Given a scanned document, the goal is to identify the country of issue, the type of document, and its version. Whereas recognizing the individual parts of a document with known standardized layout can be done reliably, identifying the type of a document and therefore also its layout is a challenging problem due to the large variety of documents. In our paper, we develop and evaluate different techniques for this application including feature representations based on recent achievements with convolutional neural networks. On a dataset with 74 different classes and using only one training image per class, our best approach achieves a mean class-wise accuracy of 97.7%.	artificial neural network;categorization;convolutional neural network;document classification;general-purpose modeling;logistic regression;preprocessor;receiver operating characteristic	Marcel Simon;Erik Rodner;Joachim Denzler	2015	2015 14th IAPR International Conference on Machine Vision Applications (MVA)	10.1109/MVA.2015.7153149	layout;computer vision;visualization;document processing;computer science;machine learning;document layout analysis;pattern recognition;histogram;accuracy and precision;artificial neural network;statistics	Vision	31.255730957940376	-66.08978564699515	31179
905e85346c375fdf1c02e2f230a49025224665a5	classifying pump-probe images of melanocytic lesions using the weyl transform		Diagnosis of melanoma is fraught with uncertainty, and discordance rates among physicians remain high because of the lack of a definitive criterion. Motivated by this challenge, this paper first introduces the Patch Weyl transform (PWT), a 2-dimensional variant of the Weyl transform. It then presents a method for classifying pump-probe images of melanocytic lesions based on the PWT coefficients. Performance of the PWT coefficients is shown to be superior to classification based on baseline intensity, on standard descriptors such as the Histogram of Oriented Gradients (HOG) and Local Binary Patterns (LBP), and on coefficients derived from PCA and Fourier representations of the data.	baseline (configuration management);coefficient;histogram of oriented gradients;image gradient;local binary patterns;principal component analysis;wigner–weyl transform	Hyun Keun Ahn;Qiang Qiu;Elisabeth Bosch;Andrew Thompson;Francisco E. Robles;Guillermo Sapiro;Warren S. Warren;A. Robert Calderbank	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8461298	local binary patterns;fourier transform;histogram of oriented gradients;artificial intelligence;principal component analysis;symmetric matrix;pattern recognition;computer science	Robotics	33.84072744925969	-74.79560555882193	31207
162e78010143b6e986225aaf1c4c55c722ee34ea	a similarity-based object recognition algorithm		Model-based object recognition is a challenging task especially if the objects of interest have a great natural variance. Such applications cannot be solved by only one general case, a case base is necessary to detect all objects with a sufficiently high accuracy. A flexible matching strategy is required that selects the most similar case out of the case base and fits it to an unseen object in a restricted distance transformation. In this paper we present our matching algorithm that establish point correspondences between a shape case and the found edges extracted from new images. A positive match will be found if the similarity measure holds	algorithm;computer simulation;conformity;correspondence problem;euclidean distance;fits;outline of object recognition;pixel;similarity measure	Petra Perner;Silke Jänichen	2013	Trans. Mass-Data Analysis of Images and Signals		computer vision;artificial intelligence;machine learning;mathematics	Vision	42.95774098524743	-54.60246585664585	31236
5c3561df3f8aaa6c7bfd5f02a7cb8796fc23ef53	automated tracking of the carotid artery in ultrasound image sequences using a self organizing neural network	image segmentation;strain rate;ultrasound;2d ultrasound image sequences;ultrasonic imaging;growing neural gas;topology preserving algorithm;wiwa;carotid arteries;ultrasound imaging;wave intensity wall analysis;ultrasonic examination;medicinsk bildbehandling;ultrasonic imaging strain image sequences carotid arteries image segmentation tracking algorithm design and analysis;self organising feature maps;carotid artery;automated tracking;medical image processing;ultrasonic imaging biomedical ultrasonics blood vessels image segmentation image sequences medical image processing self organising feature maps tracking;vascular disease;self organization;efficiency analysis;topology preservation;strain;self organizing neural network automated tracking carotid artery ultrasound;algorithm design and analysis;biomedical ultrasonics;ultrasonic examination automated tracking carotid artery self organizing neural network 2d ultrasound image sequences growing neural gas topology preserving algorithm wave intensity wall analysis wiwa vascular disease;blood vessels;self organizing neural network;tracking;neural network;image sequences	An automated method for the segmentation and tracking of moving vessel walls in 2D ultrasound image sequences is introduced. The method was tested on simulated and real ultrasound image sequences of the carotid artery. Tracking was achieved via a self organizing neural network known as Growing Neural Gas. This topology-preserving algorithm assigns a net of nodes connected by edges that distributes itself within the vessel walls and adapts to changes in topology with time. The movement of the nodes was analyzed to uncover the dynamics of the vessel wall. By this way, radial and longitudinal strain and strain rates have been estimated. Finally, wave intensity signals were computed from these measurements. The method proposed improves upon wave intensity wall analysis, WIWA, and opens up a possibility for easy and efficient analysis and diagnosis of vascular disease through noninvasive ultrasonic examination.	algorithm;artificial neural network;neural gas;organizing (structure);radial (radio);self-organization	Jimmy C. Azar;Hamed Hamid Muhammed	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.623	strain rate;algorithm design;computer vision;self-organization;computer science;machine learning;ultrasound;tracking;strain;image segmentation;artificial neural network	Vision	40.97897366387425	-76.53778304279344	31262
9457208e6196e3c75b8f065534a0a994ce0b8fe1	analysis of time-varying psoriasis lesion image patterns	biomedical imaging;diseases;statistical analysis;color band;multi-variate alteration detection transform;time varying registered psoriasis lesion image patterns;pattern analysis;image analysis	The multi-variate alteration detection transform is applied to pairs of within and between time varying registered psoriasis image patterns. Color band contribution to the variates explaining maximal change is analyzed.	maximal set	Bjarne K. Ersbøll;Allan Aasbjerg Nielsen;Gabriela Maletti;David Delgado-Gómez	2004	2004 2nd IEEE International Symposium on Biomedical Imaging: Nano to Macro (IEEE Cat No. 04EX821)		computer vision;image analysis;radiology;medicine;pathology;computer science;optics	Embedded	37.511856127021304	-74.47732605069767	31320
1b6c92d43c747755275c2c75ec94e9e4cb8abdea	an open source implementation of colon cad in 3d slicer	software;ct colonography;computer aided diagnosis;predictive value;cad;colon;visualization;virtual colonoscopy;colonoscopy;computer aided detection;3d slicer;computing systems;false positive;open source	Most colon CAD (computer aided detection) software products, especially commercial products, are designed for use by radiologists in a clinical environment. Therefore, those features that effectively assist radiologists in finding polyps are emphasized in those tools. However, colon CAD researchers, many of whom are engineers or computer scientists, are working with CT studies in which polyps have already been identified using CT Colonography (CTC) and/or optical colonoscopy (OC). Their goal is to utilize that data to design a computer system that will identify all true polyps with no false positive detections. Therefore, they are more concerned with how to reduce false positives and to understand the behavior of the system than how to find polyps. Thus, colon CAD researchers have different requirements for tools not found in current CAD software. We have implemented a module in 3D Slicer to assist these researchers. As with clinical colon CAD implementations, the ability to promptly locate a polyp candidate in a 2D slice image and on a 3D colon surface is essential for researchers. Our software provides this capability, and uniquely, for each polyp candidate, the prediction value from a classifier is shown next to the 3D view of the polyp candidate, as well as its CTC/OC finding. This capability makes it easier to study each false positive detection and identify its causes. We describe features in our colon CAD system that meets researchers’ specific requirements. Our system uses an open source implementation of a 3D Slicer module, and the software is available to the pubic for use and for extension (http://www2.wfubmc.edu/ctc/download/).	3dslicer;ct scan;colon classification;computer scientist;computer-aided design;http 404;open-source software;radiology;requirement;sensor;virtual colonoscopy	Haiyong Xu;H. Donald Gage;Peter Santago	2010		10.1117/12.844370	embedded system;simulation;visualization;type i and type ii errors;computer science;cad	SE	33.91980005462198	-78.59025483733171	31325
df87ed17dce2e7eef0ad820a85bd214921b56d94	a comparison of shape matching methods for contour based pose estimation	analisis imagen;calculo de variaciones;object recognition;vision ordenador;silhouette;image segmentation;image processing;flux optique;level set;procesamiento imagen;optical flow estimation;reconnaissance objet;traitement image;computer vision;registro imagen;posture;calcul variationnel;numerical scheme;recalage image;flujo optico;shape matching;pattern matching;image registration;segmentation image;postura;courbe niveau;iterative closest point;analyse combinatoire;image analysis;vision ordinateur;optical flow;concordance forme;curva nivel;analyse image;silueta;variational calculus;analisis combinatorio;contour line;combinatorial analysis;pose estimation	In this paper, we analyze two conceptionally different approaches for shape matching: the well-known iterated closest point (ICP) algorithm and variational shape registration via level sets. For the latter, we suggest to use a numerical scheme which was introduced in the context of optic flow estimation. For the comparison, we focus on the application of shape matching in the context of pose estimation of 3-D objects by means of their silhouettes in stereo camera views. It turns out that both methods have their specific shortcomings. With the possibility of the pose estimation framework to combine correspondences from two different methods, we show that such a combination improves the stability and convergence behavior of the pose estimation algorithm. In Combinatorial Image Analysis, Springer LNCS 4040, R. Reulke et al. (Eds.), pp. 263-276, Berlin, Germany, June 2006 c © Springer-Verlag Berlin Heidelberg 2006	3d pose estimation;algorithm;commodore 4040;conception;contour line;image analysis;iteration;lecture notes in computer science;numerical analysis;optical flow;springer (tank);stereo camera;variational principle;whole earth 'lectronic link	Bodo Rosenhahn;Thomas Brox;Daniel Cremers;Hans-Peter Seidel	2006		10.1007/11774938_21	computer vision;image analysis;pose;3d pose estimation;image processing;computer science;image registration;level set;cognitive neuroscience of visual object recognition;pattern matching;optical flow;mathematics;geometry;image segmentation;silhouette;iterative closest point;contour line;calculus of variations	Vision	49.99014788437908	-57.772344198010366	31340
7411449cbc2242dd690e64aa00e6de6c15829fa4	cloud-based object recognition: a system proposal		In this chapter, we will present a proposal for the cloud – based object recognition system. The system will extract the local features from the image and classify the object on the image using Membership Function ARTMAP (MF ARTMAP) or Gaussian Markov Random Field model. The feature extraction will be based on SIFT, SURF and ORB methods. Whole system will be built on the cloud architecture, to be readily available for the needs of the new emerging technological field of cloud robotics. Besides the system proposal, we specified research and technical goals for the following research.	artificial intelligence;artificial neural network;cloud computing;cloud robotics;feature extraction;markov chain;markov random field;membership function (mathematics);outline of object recognition;requirement;roboearth;robot;scalability;scale-invariant feature transform;speeded up robust features	Daniel Lorencik;Martina Tarhanicova;Peter Sincak	2013		10.1007/978-3-319-05582-4_61	deep-sky object;3d single-object recognition	Robotics	30.487189140628075	-57.315580351462245	31354
0679b381c241b2cb3c16c5884d7192787169deed	geometry-based image retrieval in binary image databases	busqueda informacion;modelizacion;dynamic programming;topology;geometry based image retrieval system;object recognition;medical imagery;binary image databases;programacion dinamica;medical image retrieval;correspondent node;hierarchical;size and shape;image processing;computed tomography;medical images;image databases;recherche image;binary image;information retrieval;analisis forma;dynamic programming algorithm;algoritmo recursivo;topologie;database;geometry based image retrieval;procesamiento imagen;base dato;metric;courbure;reconnaissance objet;intelligence artificielle;shape measurement;psychology;image objects shape;traitement image;isomorphism;similitude;hierarchical shape size and shape;topologia;isomorfismo;modelisation;maximum similarity subtree isomorphism;compression image;algorithme recursif;shape;medical image;image compression;recherche information;shape matching;pattern matching;heuristic algorithms;information retrieval image retrieval image databases computed tomography topology shape measurement dynamic programming heuristic algorithms psychology humans;medical images geometry based image retrieval system binary image databases curvature tree image objects shape triangle area representation maximum similarity subtree isomorphism recursive algorithm dynamic programming algorithm;similarity;image binaire;programmation dynamique;base de donnees;imagineria medica;imagerie medicale;curvature tree;algorithms artificial intelligence computer systems database management systems databases factual documentation image enhancement image interpretation computer assisted information storage and retrieval pattern recognition automated;imagen binaria;curvatura;attributed tree matching;artificial intelligence;visual databases image retrieval;metrico;curvature;triangle area representation;psychologie;recursive algorithm;pattern analysis;humans;isomorphisme;inteligencia artificial;concordance forme;similitud;modeling;human perception;metrique;analyse forme	In this paper, a geometry-based image retrieval system is developed for multiobject images. We model both shape and topology of image objects using a structured representation called curvature tree (CT). The hierarchy of the CT reflects the inclusion relationships between the image objects. To facilitate shape-based matching, triangle-area representation (TAR) of each object is stored at the corresponding node in the CT. The similarity between two multiobject images is measured based on the maximum similarity subtree isomorphism (MSSI) between their CTs. For this purpose, we adopt a recursive algorithm to solve the MSSI problem and a very effective dynamic programming algorithm to measure the similarity between the attributed nodes. Our matching scheme agrees with many recent findings in psychology about the human perception of multiobject images. Experiments on a database of 13,500 real and synthesized medical images and the MPEG-7 CE-1 database of 1,400 shape images have shown the effectiveness of the proposed method.	algorithm;anatomic node;anatomy, regional;binary image;ces1 protein, human;dynamic programming;image retrieval;matching;mpeg-7;nut hypersensitivity;physical object;published database;recursion (computer science);tree (data structure)	Naif Alajlan;Mohamed S. Kamel;George H. Freeman	2008	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2008.37	computer vision;image processing;image retrieval;computer science;theoretical computer science;machine learning;dynamic programming;mathematics;geometry	Vision	48.484265575151525	-61.130246487960676	31370
206a1ea181be2bafe8e527482d478bcadb96a6c1	a modular framework for the automatic classification of chromosomes in q-band images	automatic karyotyping;chromosome polarization;alternating decision trees;image classification;artificial neural networks;chromosome classification	The manual analysis of the karyogram is a complex and time-consuming operation, as it requires meticulous attention to details and well-trained personnel. Routine Q-band laboratory images show chromosomes that are randomly rotated, blurred or corrupted by overlapping and dye stains. We address here the problem of robust automatic classification, which is still an open issue. The proposed method starts with an improved estimation of the chromosome medial axis, along which an established set of features is then extracted. The following novel polarization stage estimates the chromosome orientation and makes this feature set independent on the reading direction along the axis. Feature rescaling and normalizing techniques take full advantage of the results of the polarization step, reducing the intra-class and increasing the inter-class variances. After a standard neural network based classification, a novel class reassignment algorithm is employed to maximize the probability of correct classification, by exploiting the constrained composition of the human karyotype. An average 94% of correct classification was achieved by the proposed method on 5474 chromosomes, whose images were acquired during laboratory routine and comprise karyotypes belonging to slightly different prometaphase stages. In order to provide the scientific community with a public dataset, all the data we used are publicly available for download.		Enea Poletti;Alfredo Ruggeri	2012	Computer methods and programs in biomedicine	10.1016/j.cmpb.2011.07.013	computer vision;contextual image classification;computer science;bioinformatics;machine learning;artificial neural network	Vision	38.26049619899219	-72.14115589906712	31422
a87a12942e91a29fe11c6d22519883ead1bc2eef	a local approach for 3d object recognition through a set of size functions	object recognition;object categorization;shape classification;3d model description	In this paper, a local approach for 3D object recognition is presented. It is based on the topological invariants provided by the critical points of the 3D object. The critical points and the links between them are represented by a set of size functions obtained after splitting the 3D object into portions. A suitable similarity measure is used to compare the sets of size functions associated with the 3D objects. In order to validate our approach's recognition performance, we used different collections of 3D objects. The obtained scores are favourably comparable to the related work. The 3D object is split into 18 portions according to its principal axes.Each portion is represented by a size function.A well suited similarity measure is used to compare between the 3D objects.	3d single-object recognition;automated planning and scheduling;computation;computer science;concave function;database normalization;graphics processing unit;outline of object recognition;time complexity	Mohammed Ayoub Alaoui Mhamdi;Djemel Ziou	2014	Image Vision Comput.	10.1016/j.imavis.2014.08.015	computer vision;method;object model;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;mathematics;3d single-object recognition	Vision	39.26017714651754	-57.66584263028991	31490
9607d8ed98302f6f46c9fb49bba103b4e041a7db	video-based handwritten chinese character recognition	complex chinese character;handwritten chinese character;online ocr system;recognition system;video-based handwritten chinese character;recognition experiment;video-based stroke-tracing;error correction technique;large set;noise problem;video-based handwritten chinese character	In this work, we propose a video-based handwritten Chinese character recognition system. By using several error correction techniques, the algorithm works effectively against various shadow and noise problems for video-based stroke-tracing of complex Chinese characters. The stroke temporal information similar to an online OCR system is accurately extracted. Recognition experiments on a large set of handwritten Chinese characters clearly demonstrates the efficacy of the system.	algorithm;error detection and correction;experiment;online and offline;optical character recognition;regular expression	Xiaoou Tang;Feng Lin;Jianzhuang Liu	2005	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2004.839975(410)1	computer vision;speech recognition;feature extraction;computer science;intelligent word recognition;pattern recognition;optical character recognition;chinese	Vision	32.594063995964454	-66.24505193762285	31565
e9d89ff7c1bcd610fa8eb44d86598ab5a14bb353	mplboost-based mixture model for effective human detection with deformable part model	detectors;training detectors image color analysis vectors deformable models visualization support vector machines;support vector machines;mplboost;training;deformable models;root classifier mplboost based mixture model human detection deformable part model automated selection discriminative root models intra class variations visual feature clustering;visualization;vectors;mixture model;image color analysis;human detection;feature combination;human detection mplboost mixture model deformable part model feature combination;object detection;deformable part model	The Deformable Part Model has shown high accuracy in tackling certain occlusion or deformations of objects such as cars and bikes. However, as for human category characterized by a larger number of articulated parts and more significant appearance variations, its performance gain is not so remarkable. To address this issue, we propose an MPLBoost-based mixture model which splits data into coherent groups and trains one root classifier for each, resulting in automated selection of discriminative root models and better representation of intra-class variations through visual feature clustering. Based on this boosting framework, multiple complementary features are combined to capture shape, texture and color information. Experimental results demonstrate that the proposed model can achieve an impressive performance improvement, especially in handling larger variations of human poses and viewpoints.	cluster analysis;coherence (physics);mixture model	Chaoran Gu;Luntian Mou;Yonghong Tian;Tiejun Huang	2013	2013 IEEE International Conference on Multimedia and Expo (ICME)	10.1109/ICME.2013.6607599	support vector machine;computer vision;detector;visualization;computer science;machine learning;pattern recognition;mixture model	Vision	34.002496686681795	-53.38402043219454	31612
da64c9ce7be30f2a8ab7ed0fe2efe3ff191b1793	a markov chain monte carlo based rigid image registration method		We propose a Monte Carlo Markov Chain (MCMC) based method for image registration. We formulate the image registration problem within a Bayesian framework and generate samples from the resulting posterior density of the registration parameters using MCMC. Thus, posterior density is characterized through the samples that are drawn with the MCMC principle. When the posterior density is multimodal, samples from different modes of the posterior lead to different and meaningful solutions for the image registration problem. We perform experiments on pairs of test images which may admit multiple registration solutions. Preliminary results demonstrate the potential of the proposed approach.	experiment;image registration;markov chain monte carlo;monte carlo method;multimodal interaction	Navdar Karabulut;Ertunc Erdil;Müjdat Çetin	2017	2017 25th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2017.7960520	artificial intelligence;computer science;pattern recognition;computer vision;monte carlo method;image registration;markov chain monte carlo;hybrid monte carlo;markov process;bayesian probability	Vision	51.18410609839087	-73.32829227809798	31648
af16cbd37e1c531619691353da2e9717e765c295	intensity normalization in the analysis of functional datscan spect images: the α-stable distribution-based normalization method vs other approaches	pet;intensity normalization;spect;computer aided diagnosis system;parkinson s disease;alpha stable distributions	This work is focused on the study of the different intensity normalization procedures available for the proper normalization of 3D functional brain images devoted to the early diagnosis of Parkinson's disease. This normalization step is essential, as it corresponds to the initial step in any subsequent computerbased analysis. There are particular features of the Parkinson's disease patterns in the functional brain images. Although there are a variety of normalization methods available, these particular features provoke that, for Parkinson's disease brain image study, not all of the available normalization procedures present the same proper performance when they are applied. In this work, conventional intensity normalization approaches are considered, along with a novel normalization approach based on the α-stable distribution. All these normalization procedures are referred and their performance is compared. The experimentation and the evaluation results are both based on single-photon emission computed tomography (SPECT) brain images from real cases already diagnosed by expert clinicians. For the performance evaluation, two methods are considered: one based on nearest neighbors and the other related to exceeding a particular striatum activation threshold. In addition, the obtained results are validated by means of statistical analysis, applying the Kullback–Leibler divergence, the Euclidean distance and the Hellinger distance. & 2014 Elsevier B.V. All rights reserved.	ct scan;discrepancy function;euclidean distance;experiment;kullback–leibler divergence;performance evaluation;tomography	Pablo Padilla;Juan Manuel Górriz;Javier Ramírez;Diego Salas-Gonzalez;Ignacio Álvarez	2015	Neurocomputing	10.1016/j.neucom.2014.01.080	spatial normalization;pet	ML	31.998741307502556	-78.69020104955054	31656
e9571993cba53074df0e0ab8af17e0c98a9fb053	design and implementation of log-gabor filter in fingerprint image enhancement	filtering;evaluation performance;image recognition;reconocimiento imagen;filtrage;enhancement;log gabor filter;performance evaluation;image processing;accentuation image;automatic system;implementation;biometrie;evaluacion prestacion;filtrado;biometrics;database;biometria;procesamiento imagen;base dato;filtro gabor;qualite image;traitement image;traditional gabor filter;gabor filter;image enhancement;automatic recognition;design method;sistema automatico;design and implementation;automatic fingerprint identification system;robustesse;identification;image quality;dactyloscopie;reconnaissance image;filtre gabor;base de donnees;systeme automatique;pattern recognition;fingerprint;robustness;calidad imagen;reconnaissance forme;reconocimiento patron;implementacion;fingerprint identification;reconocimiento automatico;reconnaissance automatique;robustez	The performance of automatic fingerprint identification system relies heavily on the quality of fingerprint images. Fingerprint enhancement is essential to ensure the robustness of fingerprint identification with respect to the image quality. Gabor filtering is the most popular method in fingerprint enhancement. To overcome the limitations of traditional Gabor filter and promote fingerprint enhancement performance, the Log-Gabor filter is introduced in this paper. The design method and implementation scheme of Log-Gabor filter in fingerprint enhancement are described in detail. The enhancement performance is assessed on standard fingerprint databases. Experimental results show that the proposed Log-Gabor filtering method can effectively improve the fingerprint image quality and promote the reliability of fingerprint identification.	fingerprint;gabor filter;image editing	Wei Wang;Jianwei Li;Feifei Huang;Hailiang Feng	2008	Pattern Recognition Letters	10.1016/j.patrec.2007.10.004	fingerprint;computer vision;speech recognition;image processing;computer science;fingerprint recognition	Vision	45.23407942940053	-60.692570061252184	31670
9b7748f34d0b2f3a2248c3908888b94fc512ce47	atherosclerotic plaque tissue characterization in 2d ultrasound longitudinal carotid scans for automated classification: a paradigm for stroke risk assessment		In the case of carotid atherosclerosis, to avoid unnecessary surgeries in asymptomatic patients, it is necessary to develop a technique to effectively differentiate symptomatic and asymptomatic plaques. In this paper, we have presented a data mining framework that characterizes the textural differences in these two classes using several grayscale features based on a novel combination of trace transform and fuzzy texture. The features extracted from the delineated plaque regions in B-mode ultrasound images were used to train several classifiers in order to prepare them for classification of new test plaques. Our CAD system was evaluated using two different databases consisting of 146 (44 symptomatic to 102 asymptomatic) and 346 (196 symptomatic and 150 asymptomatic) images. Both these databases differ in the way the ground truth was determined. We obtained classification accuracies of 93.1 and 85.3 %, respectively. The techniques are low cost, easily implementable, objective, and non-invasive. For more objective analysis, we have also developed novel integrated indices using a combination of significant features.	carotid atherosclerosis;cerebrovascular accident;class;computer-aided design;data mining;database;dental plaque;extraction;grayscale color map;ground truth;patients;programming paradigm;risk assessment;senile plaques;stratified sampling;test set	U. Rajendra Acharya;Muthu Rama Krishnan Mookiah;Subbhuraam Vinitha Sree;David M. Afonso;João M. Sanches;Shoaib Shafique;Andrew Nicolaides;Luís Mendes Pedro;José Fernandes e Fernandes;Jasjit S. Suri	2012	Medical & Biological Engineering & Computing	10.1007/s11517-012-1019-0	radiology;medicine;pathology;surgery	ML	35.54836222441489	-77.49453212481575	31713
7b087ef0d3a177d243ccd47f262062d6f44cf7a8	extraction and selection of dynamic features of the human iris	dynamic features extraction;real time;fiber optics;personal identification;iris recognition;texture features;data mining;iris texture analysis;dynamic features selection;image texture;texture analysis;humans iris biometrics lighting image texture analysis feature extraction infrared imaging eyes software measurement measurement standards;optical imaging;image acquisition;feature extraction;data mining dynamic features selection dynamic features extraction human iris personal identification iris texture analysis biometric identification pupil contraction pupil dilation near infra red illumination consensual reflex;consensual reflex;dynamic iris real time;human iris;near infra red illumination;humans;iris recognition data mining feature extraction image texture;lighting;pupil contraction;biometric identification;iris;dynamic;pupil dilation	The personal identification through iris texture analysis is a highly efficient biometric identification method. Some algorithms and techniques were developed, taking into consideration the texture features of the iris image in the human eye. Nonetheless, such features, due to the fact that they are static, they are also susceptible to fraud. That is, a picture can replace the iris in an analysis. For that reason, this paper proposes a method for extracting the texture features of the iris during the pupil contraction and dilation, in addition to the dynamic contraction and dilation features themselves. Therefore, it was developed a new image acquisition system through NIR (Near Infra-Red) illumination, considering the Consensual Reflex of the eyes. The features are measured according to a dynamic illumination standard controlled by the software and are afterwards selected by means of data mining. Then it is possible to increase the safety in the biometric recognition devices of people through their iris, for only living irises can be utilized. The results show a significant precision index in determining such features, despite being inferior to the ones obtained by means of static methodology.	algorithm;biometrics;data mining;digital single-lens reflex camera;dilation (morphology)	Adilson Gonzaga;Ronaldo Martins da Costa	2009	2009 XXII Brazilian Symposium on Computer Graphics and Image Processing	10.1109/SIBGRAPI.2009.16	computer vision;geography;iris recognition;optics;computer graphics (images)	Graphics	36.187000490565694	-72.3527542705081	31718
57d08195547328bcc3981e91cd85860be70d4aa8	a two-stage visual turkish sign language recognition system based on global and local features	modelo markov oculto;image recognition;lenguaje por signos;reconocimiento imagen;vision ordenador;sign language recognition;reconnaissance geste;modele markov cache;hidden markov model;sign language;approximation plus proche voisin;intelligence artificielle;computer vision;langage gestuel;visual languages;local features;langage visuel;reconnaissance image;artificial intelligence;k nearest neighbor;audition;vision ordinateur;audicion;inteligencia artificial;gesture recognition;hearing;nearest neighbor approximation	In order to provide communication between the deaf-dumb people and the hearing people, a two-stage system translating Turkish Sign Language into Turkish is developed by using vision based approach. Hidden Markov models are utilized to determine the global feature group in the dynamic gesture recognition stage, and k nearest neighbor algorithm is used to compare the local features in the static gesture recognition stage. The system can perform person dependent recognition of 172 isolated signs.		Hakan Haberdar;Songül Albayrak	2006		10.1007/11875604_5	speech recognition;sign language;computer science;artificial intelligence;machine learning;gesture recognition;k-nearest neighbors algorithm;hidden markov model	Vision	45.594303900029374	-58.444804291258706	31733
e245a9009f378685a10703214d4640aa74740452	blind image steganalysis based on wavelet coefficient correlation	steganalysis;joint probability density matrix;wavelet decomposition;journal;期刊论文;blind steganalysis;coefficient correlation;co occurrence matrix	To detect the presence of information in a stego image more reliably, a blind JPEG steganalysis method based on interand intra-wavelet subband correlations in the wavelet domain is proposed. First, after two-level wavelet decomposition, the joint probability density of each subband’s difference from neighboring coefficients in the horizontal, vertical, and diagonal directions is calculated, and the entropy and energy are extracted from the joint probability density matrix as features. Then the image is decomposed into three subbands, and the PDF (probability density function) is extracted from each subband’s wavelet coefficient. Finally, the three kinds of features described above are combined to detect the image. In experiments, the proposed method is compared with various other blind steganalysis methods, and the impacts of different feature combinations on detection accuracy are discussed. Experimental results from typical JPEG image stego algorithms such as F5, Jsteg, Outguess, and Jphide show that the proposed method significantly outperforms typical blind steganalysis methods. The proposed method also has some detection capabilities for double-compressed images. a 2012 Elsevier Ltd. All rights reserved.	algorithm;co-occurrence matrix;coefficient;density matrix;document-term matrix;experiment;feature extraction;jpeg;portable document format;steganalysis;steganography;wavelet transform	Han Zong;Fenlin Liu;Xiangyang Luo	2012	Digital Investigation	10.1016/j.diin.2012.02.003	speech recognition;steganalysis;computer science;pattern recognition;co-occurrence matrix	Vision	35.632336152251675	-60.190608112620616	31736
c33bf10abfcb19a2fc4aa8de55632626326047b6	determining the asymmetries of skin lesions with fuzzy borders	fuzzy borders;patient diagnosis;skin lesion;clinical feature;rgb colour image camera;clinical features;image segmentation;backpropagation skin image segmentation measurement errors symmetry biomedical optical imaging medical image processing cancer neural nets;cancer;neural nets;disease;skin;symmetric distance enhancement;image segmentation accuracy;backpropagation;asymmetric measurement;malignant tumors;symmetry;electrostatic discharge;artificial neural networks;image enhancement;shape;lesions;circularity;medical image processing;diseases;lesion shape;patient diagnosis skin lesion asymmetry fuzzy borders malignant melanoma cancer youth disease lesion shape asymmetric measurement circularity image segmentation accuracy artificial neural network model symmetric distance enhancement image enhancement digitized images neural network model rgb colour image camera clinical features;digital image;biomedical optical imaging;neural network model;fuzzy neural networks;malignant melanoma;skin lesions cancer malignant tumors diseases shape image segmentation artificial neural networks fuzzy neural networks electrostatic discharge;skin lesion asymmetry;artificial neural network model;digitized images;measurement errors;youth;artificial neural network	Malignant melanoma is a popular cancer among youth; it is desirable to have a fast and convenience way to determine this disease in its early stage. One of the clinical features in diagnosis is related to the shape of lesions. In previous studies, circularity is commonly used as the asymmetric measurement of skin lesions. However, this measurement depends very much on the accuracy of the segmentation result. In this paper, we present an artificial neural network model to improve the measurements of the asymmetries of lesions that may have fuzzy borders. The main idea is enhancing the symmetric distant (eSD) with a number of variations. Results from experiments, which use the digitized images from the Lesion Clinic in Vancouver, Canada have shown the good discriminating power of the neural network model.	artificial neural network;experiment;network model	Vincent T. Y. Ng;Tim K. Lee;Benny Y. M. Fung	2003		10.1109/BIBE.2003.1188955	computer vision;electrostatic discharge;shape;computer science;backpropagation;machine learning;skin;image segmentation;symmetry;digital image;artificial neural network;cancer;observational error	Web+IR	36.00831606209261	-75.89541354739082	31749
c5400fdae5b9237ca262237de0273794ffdcf538	an end to end deep neural network for iris segmentation in unconstrained scenarios	data augmentation;deep neural networks;iris segmentation	With the increasing imaging and processing capabilities of today's mobile devices, user authentication using iris biometrics has become feasible. However, as the acquisition conditions become more unconstrained and as image quality is typically lower than dedicated iris acquisition systems, the accurate segmentation of iris regions is crucial for these devices. In this work, an end to end Fully Convolutional Deep Neural Network (FCDNN) design is proposed to perform the iris segmentation task for lower-quality iris images. The network design process is explained in detail, and the resulting network is trained and tuned using several large public iris datasets. A set of methods to generate and augment suitable lower quality iris images from the high-quality public databases are provided. The network is trained on Near InfraRed (NIR) images initially and later tuned on additional datasets derived from visible images. Comprehensive inter-database comparisons are provided together with results from a selection of experiments detailing the effects of different tunings of the network. Finally, the proposed model is compared with SegNet-basic, and a near-optimal tuning of the network is compared to a selection of other state-of-art iris segmentation algorithms. The results show very promising performance from the optimized Deep Neural Networks design when compared with state-of-art techniques applied to the same lower quality datasets.	algorithm;artificial neural network;authentication;biometrics;database;deep learning;experiment;image quality;mobile device;network planning and design;neural tube defects;biologic segmentation	Shabab Bazrafkan;Shejin Thavalengal;Peter Corcoran	2018	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2018.06.011	artificial intelligence;artificial neural network;machine learning;mathematics;image quality;network planning and design;biometrics;end-to-end principle;mobile device;segmentation	AI	29.810118892916073	-74.58011916970163	31779
ba8c34f9ce3a77d20894ac591977c924514e447c	statistical change detection with moments under time-varying illumination	lighting layout samarium robustness detection algorithms algorithm design and analysis testing machine vision image segmentation change detection algorithms;test hypothese;statistical moment;metodo estadistico;time varying;change detection;image segmentation;image processing;time varying illumination;detection algorithms;test hipotesis;machine vision applications;moment statistique;time varying systems;procesamiento imagen;statistical method;testing;layout;traitement image;structural change;circular shift moments;experimental result;regle decision;momento estadistico;detection mouvement;time varying imagery;statistical decision rule;statistical analysis;methode statistique;machine vision;statistical change detection;hypothesis testing;resultado experimental;samarium;robustness;lighting;regla decision;resultat experimental;critical value;machine vision applications statistical change detection noise free case time varying illumination circular shift moments statistical decision rule hypothesis testing time varying imagery;motion detection;algorithm design and analysis;decision rule;change detection algorithms;noise;time varying systems noise image processing statistical analysis;hypothesis test;noise free case	In this paper, an illumination-independent statistical change detection method is proposed. The proposed method consists of two parts. First, based on our defined circular shift moments, structural changes can be distinguished from those due to time-varying illumination in the noise-free case. Moreover, the amount of computation is less than that of the shading model method. Second, in the light of the characteristics of the defined moments, a statistical decision rule is also proposed to cope with the effects of noise. The change detection problem can be treated as one of hypothesis testing. Critical values can be chosen according to the desired level of significance. Experimental results indicate that the proposed method detects changes accurately in the time-varying illumination case.	circular shift;computation (action);illumination (image);less than;list of common shading algorithms	Sze-Chu Liu;Chang-Wu Fu;Shyang Chang	1998	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.709658	computer vision;statistical hypothesis testing;simulation;machine vision;image processing;computer science;machine learning;mathematics;statistics	Visualization	47.35266219031315	-62.64074186165462	31815
71de1efa1878819439fc164b357647433209848b	score normalization for keystroke dynamics biometrics	databases;biometrics access control authentication databases standards protocols feature extraction;protocols;image segmentation authorisation biometrics access control feature extraction handwritten character recognition;standards;biometrics access control;authentication;conferenceobject;feature extraction;score normalization analysis target dependent score normalization techniques keystroke dynamics recognition systems thresholding techniques behavioral biometric recognition systems keystroke dynamics authentication systems keystroke dynamics biometrics;forensics ink identification pen verifier hyperspectral analysis handwritten document analysis	This paper analyzes score normalization for keystroke dynamics authentication systems. Previous studies have shown that the performance of behavioral biometric recognition systems (e.g. voice and signature) can be largely improved with score normalization and target-dependent techniques. The main objective of this work is twofold: i) to analyze the effects of different thresholding techniques in 4 different keystroke dynamics recognition systems for real operational scenarios; and ii) to improve the performance of keystroke dynamics on the basis of target-dependent score normalization techniques. The experiments included in this work are worked out over the keystroke pattern of 114 users from two different publicly available databases. The experiments show that there is large room for improvements in keystroke dynamic systems. The results suggest that score normalization techniques can be used to improve the performance of keystroke dynamics systems in more than 20%. These results encourage researchers to explore this research line to further improve the performance of these systems in real operational environments.	algorithm;authentication;biometrics;database normalization;dynamical system;event (computing);experiment;keystroke dynamics;machine learning;supervised learning;thresholding (image processing)	Aythami Morales;Elena Luna-Garcia;Julian Fiérrez;Javier Ortega-Garcia	2015	2015 International Carnahan Conference on Security Technology (ICCST)	10.1109/CCST.2015.7389686	speech recognition;computer science;pattern recognition;data mining	Mobile	29.19687849560304	-63.32887869190047	31912
1565f1b4c5fad9ce4816a055f033f04db58d1b13	agglomerated feature extractionin medical images for breast cancer and its characteristic pattern generation	breast cancer detection;pattern generation;minimum gradient;medical image;self rotated correlation pattern;feature extraction;breast cancer screening;hexagonal mask;breast cancer	About 1 in 8 women in the United States is expected to develop breast cancer over the course of herentire lifetime but a few medical imaging techniques have been applied for breast cancer screening. In addition, the feature extraction and comparison in medical images for breast cancer detection haverarely been reported in literature. We propose a new framework toextract agglomerated features in medical imagesand comparethem by relating original characteristic patterns thereof. Our method concentrates on three key aspects and they are: a comparison between intensity distributions of pixels collected by the hexagonal mask, detecting minimum gradient points in a radial intensity series, and generatinga characteristic pattern of the feature. The main contribution of ourproposed approach is improving a method of identifying features which is lesssensitive to noise in medical images for breast cancerdetectionand presenting an original design of relating features which is consistent to the orientation and size of the feature. Experimental results demonstrate that our proposed approach is more tolerant of image noise than prior research and generates an invariant characteristic pattern of various orientations and sizes.	feature extraction;gradient;image noise;medical imaging;pixel;radial (radio);sensor	Jucheol Moon;Sung Y. Shin;Donghoon Kang;Soon-Ik Jeon;Hyung Do Choi;Jung Y. Kim	2011		10.1145/2103380.2103424	computer vision;engineering;pattern recognition;biological engineering	Vision	36.87874793681225	-75.98939769642442	31989
16f0ccb610cf860f7952f097a2de2a664358c9fb	appearance-based keypoint clustering	texture;color;object tracking;image texture;clustering;pixel;histograms;image segmentation;segmentation;feature extraction;clustering algorithms	We present an algorithm for clustering sets of detected interest points into groups that correspond to visually distinct structure. Through the use of a suitable colour and texture representation, our clustering method is able to identify keypoints that belong to separate objects or background regions. These clusters are then used to constrain the matching of keypoints over pairs of images, resulting in greatly improved matching under difficult conditions. We present a thorough evaluation of each component of the algorithm, and show its usefulness on difficult matching problems.	algorithm;analysis of algorithms;cluster analysis;computer cluster;filter bank;matching (graph theory);mean shift;processor affinity	Francisco J. Estrada;Pascal Fua;Vincent Lepetit;Sabine Süsstrunk	2009	2009 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPRW.2009.5206514	correlation clustering;computer vision;fuzzy clustering;computer science;machine learning;pattern recognition;cluster analysis	Vision	37.33808247714869	-57.29729415594932	32010
6db9babf4e8f87722c587aca30338885bca025f8	globally optimal algorithms for stratified autocalibration	estensibilidad;metodo cuadrado menor;homograph;methode moindre carre;optimisation;transformation affine;image processing;least squares method;optimizacion;homografo;search space;branching;projection method;procesamiento imagen;metric;optimum global;autocalibration;global optimum;convex relaxations;computer imaging vision pattern recognition and graphics;traitement image;fonction objectif;conico;homographe;preparacion serie fabricacion;multiple view;objective function;reconstruction image;branch and bound method;methode projection;dimension independiente;reconstruccion imagen;metodo branch and bound;independent dimension;convex function;ramificacion;image reconstruction;affine transformation;metodo proyeccion;least square;artificial intelligence incl robotics;pattern recognition;analyse non convexe;image processing and computer vision;dimension independante;vue multiple;ramification;multiple view geometry;funcion objetivo;metrico;global optimization;optimization;extensibilite;scalability;computer science;process planning;methode separation et evaluation;non convex analysis;convex relaxation;projective reconstruction;algoritmo optimo;algorithme optimal;optimal algorithm;branch and bound;preparation gamme fabrication;fonction convexe;conics;optimo global;conique;metrique;transformacion afin;vista multiple;funcion convexa;analisis no convexo	We present practical algorithms for stratified autocalibration with theoretical guarantees of global optimality. Given a projective reconstruction, we first upgrade it to affine by estimating the position of the plane at infinity. The plane at infinity is computed by globally minimizing a least squares formulation of the modulus constraints. In the second stage, this affine reconstruction is upgraded to a metric one by globally minimizing the infinite homography relation to compute the dual image of the absolute conic (DIAC). The positive semidefiniteness of the DIAC is explicitly enforced as part of the optimization process, rather than as a post-processing step. For each stage, we construct and minimize tight convex relaxations of the highly non-convex objective functions in a branch and bound optimization framework. We exploit the inherent problem structure to restrict the search space for the DIAC and the plane at infinity to a small, fixed number of branching dimensions, independent of the number of views. Chirality constraints are incorporated into our convex relaxations to automatically select an initial region which is guaranteed to contain the global minimum. Experimental evidence of the accuracy, speed and scalability of our algorithm is presented on synthetic and real data.	algorithm;branch and bound;camera resectioning;least squares;mathematical optimization;maxima and minima;modulus of continuity;scalability;stratified sampling;synthetic intelligence;video post-processing	Manmohan Krishna Chandraker;Sameer Agarwal;David J. Kriegman;Serge J. Belongie	2009	International Journal of Computer Vision	10.1007/s11263-009-0305-2	mathematical optimization;combinatorics;image processing;computer science;mathematics;geometry;least squares;global optimization	Vision	51.20300320609338	-55.92613003899526	32024
3139afbf8a560119f9347b562543ef497a8b73dc	offline extraction of indic regional language from natural scene image using text segmentation and deep convolutional sequence		Regional language extraction from a natural scene image is always a challenging proposition due to its dependence on the text information extracted from Image. Text Extraction on the other hand varies on different lighting condition, arbitrary orientation, inadequate text information, heavy background influence over text and change of text appearance. This paper presents a novel unified method for tackling the above challenges. The proposed work uses an image correction and segmentation technique on the existing Text Detection Pipeline an Efficient and Accurate Scene Text Detector (EAST). EAST uses standard PVAnet architecture to select features and non maximal suppression to detect text from image. Text recognition is done using combined architecture of MaxOut convolution neural network (CNN) and Bidirectional long short term memory (LSTM) network. After recognizing text using the Deep Learning based approach, the native Languages are translated to English and tokenized using standard Text Tokenizers. The tokens that very likely represent a location is used to find the Global Positioning System (GPS) coordinates of the location and subsequently the regional languages spoken in that location is extracted. The proposed method is tested on a self generated dataset collected from Government of India dataset and experimented on Standard Dataset to evaluate the performance of the proposed technique. Comparative study with a few state-of-the-art methods on text detection, recognition and extraction of regional language from images shows that the proposed method outperforms the existing methods.	artificial neural network;computer forensics;convolution;deep learning;emoticon;gaussian blur;global positioning system;ground truth;image resolution;lexical analysis;long short-term memory;maximal set;online and offline;optical character recognition;text segmentation;xfig;zero suppression	Sauradip Nag;Pallab Kumar Ganguly;Sumit Roy;Sourab Jha;Krishna Bose;Abhishek Jha;Koushik Dasgupta	2018	CoRR		pattern recognition;convolutional neural network;tokenization (data security);architecture;deep learning;artificial neural network;regional language;government;text segmentation;computer science;artificial intelligence	NLP	30.203761106004567	-55.026512985563116	32042
147eeefbd0b48d4d9a0720f93c04848b2810fb3d	detecting vorticity in optical flow of fluids	eigenvalues and eigenfunctions;eigenvalues extraction;estimation theory;vortices;vorticity detection;navier stokes equations;optical vortices;optical flow estimation;matrix algebra;integrated optics;correlation methods;local correlation efficiency;eigenvalues;dense optical flow estimation;computational fluid dynamics;feature confidence factor;optical imaging;fluids optical flow;feature extraction;mathematical model;gradient methods;robustness;optical flow;vortices computational fluid dynamics correlation methods eigenvalues and eigenfunctions estimation theory feature extraction gradient methods image sequences matrix algebra navier stokes equations;mathematical model optical imaging optical vortices navier stokes equations integrated optics robustness;local correlation efficiency vorticity detection fluids optical flow dense optical flow estimation local image information gradients matrices eigenvectors eigenvalues extraction feature confidence factor;local image information;eigenvectors;image sequences;gradients matrices	In this paper we apply the diffusion framework to dense optical flow estimation. Local image information is represented by matrices of gradients between paired locations. Diffusion distances are modelled as sums of eigenvectors weighted by their eigenvalues extracted following the eigen decomposion of these matrices. Local optical flow is estimated by correlating diffusion distances characterizing features from different frames. A feature confidence factor is defined based on the local correlation efficiency when compared to that of its neighbourhood. High confidence optical flow estimates are propagated to areas of lower confidence.	eigen (c++ library);gradient;hessian;navier–stokes equations;optical flow;sensor;solver;velocity (software development)	Ashish Doshi;Adrian G. Bors	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.519	computer vision;mathematical optimization;mathematical analysis;eigenvalues and eigenvectors;computer science;mathematics;geometry;statistics	Vision	52.9546293032104	-72.20566427809518	32054
513de6c5ae2eccd4875d3fe22e9a3b6206b9c052	an extended center-symmetric local ternary patterns for image retrieval		A new texture spectrum descriptor was proposed for region description in the paper, which is an extension of center-symmetric local ternary pattern (CS-LTP). Different from CS-LTP, the central piexl of the region are considered together in the definition of the extended center- symmetric local ternary pattern (eCS-LTP). Without adding the dimension of CS-LTP, the proposed operator contains more information of the region. The two methods, CS-LTP and eCS-LTP were tested on two commonly used texture image databases in the context of image retrieval and the experimental results show that eCS-LTP gives better performance than CS-LTP.	image retrieval;local ternary patterns	Xiaosheng Wu;Junding Sun	2011		10.1007/978-3-642-23321-0_56	computer vision;theoretical computer science;mathematics;information retrieval	Vision	37.70224867529198	-59.58738233105346	32064
293316f4640321fd47210fe832de4ec2895acf2c	multiscale histogram of oriented gradient descriptors for robust character recognition	engineering;histograms;image recognition;text analysis character recognition computer graphics document image processing feature extraction gradient methods image recognition;electrical electronic;computer graphics;technology;training;oriented gradient columns histograms oriented gradients hog character recognition;image character multiscale histogram oriented gradient descriptor robust character recognition technique image extraction graphics pose semantic information image recognition data sets hog descriptor;text analysis;hog;testing;science technology;shape;oriented gradients;feature extraction;document image processing;gradient methods;artificial intelligence;computer science;oriented gradient columns;text recognition;character recognition;histograms character recognition training image recognition shape text recognition testing	Characters extracted from images or graphics pose a challenge for traditional character recognition techniques. The high degree of intraclass variation along with the presence of clutter makes accurate recognition difficult, yet the semantic information conveyed by sections of text within images or graphics makes their recognition an important problem. Previous work has shown that, on the two most commonly used datasets of such characters, Histogram of Oriented Gradient (HOG) descriptors have outperformed other methods. In this work we consider two extensions of the HOG descriptor to include features at multiple scales, and evaluate their performance using characters taken from images and graphics. We demonstrate that, by combining pairs of oriented gradients at different scales, it's possible to achieve an increase in performance of 12.4% and 5.6% on the two datasets.	clutter;data descriptor;gradient;graphics;image;optical character recognition	Andrew J. Newell;Lewis D. Griffin	2011	2011 International Conference on Document Analysis and Recognition	10.1109/ICDAR.2011.219	computer vision;text mining;speech recognition;feature extraction;shape;computer science;machine learning;pattern recognition;computer graphics;technology	Vision	35.984373805713986	-56.038125459224226	32101
2b2c3618cc45d11daa1475787e96135cdcf52012	ventilatory impairment detection based on distribution of respiratory-induced changes in pixel values in dynamic chest radiography: a feasibility study	chest radiograph;functional imaging;feasibility study;ventilation;flat panel detector;normal control;pattern analysis;computer analysis;chest radiography;x rays	Decreased ventilation is observed on chest radiographs as small changes in X-ray translucency, and ventilatory impairments can therefore be detected by analyzing the distribution of respiratory-induced changes in pixel value. This study was performed to develop a ventilatory impairment detection method based on the distribution of respiratory-induced changes in pixel values. Sequential chest radiographs during respiration were obtained using a dynamic flat panel detector system. Respiratory-induced changes in pixel value were measured in each local area and then compared for symmetrical positions in both lungs, which were located at the same distance from the axis of the thorax at the same level. The right–left symmetry was assessed in 20 clinical cases (Abnormal, 14; Normal, 6). In normal controls, the distribution was symmetrical, and there were good correlations of the pixel value changes in both lungs at symmetrical positions (r = 0.66±0.05). In contrast, abnormal cases did not show a symmetrical distribution of pixel value changes (r = 0.40±0.23) due to ventilation abnormalities observed as reductions in pixel value changes. Ventilatory impairment could be detected as deviation from the right–left symmetry of respiratory-induced changes in pixel value. In particular, the present method could be useful for detecting unilateral abnormalities. However, to detect bilateral abnormalities, further studies are required to develop multilevel detection methods combined with several methods of pattern analysis.	apache axis;articulation disorders;axis vertebra;bilateral filter;bilateral sound;cognition disorders;congenital abnormality;detectors;flat panel detector;flat panel display;left lung;mason's invariant;patients;pattern recognition;pixel;plain chest x-ray;radiography;respiration;sensor;structure of parenchyma of lung	Rie Tanaka;Shigeru Sanada;Masaki Fujimura;Masahide Yasui;Shiro Tsuji;Norio Hayashi;Hiroyuki Okamoto;Yuko Nanbu;Osamu Matsui	2010	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-010-0491-y	ventilation;feasibility study;flat panel detector;radiology;medicine;functional imaging;nuclear medicine;medical physics	Vision	38.533844818520755	-79.64721150004469	32143
70b37db55364a31dff9392e5546de1bfe5f17e8f	weighted graph classification by self-aligned graph convolutional networks using self-generated structural features				Xuefei Zheng;Min Zhang;Jiawei Hu;Weifu Chen;Guo-Can Feng	2018		10.1007/978-3-030-03335-4_44		Vision	28.47517118735199	-57.14101524300569	32201
235b397aa6b6e28a3f8a41987f9b4fe6f01fe5a1	analysis of parameters for the automatic computation of the tear film break-up time test based on cclru standards	dry eye syndrome;tear film;image processing;but test;video analysis	Dry eye syndrome is affecting a remarkable percentage of population. The prevalence is 10-15% of normal population, and 18-30% of contact lenses users. The break-up time (BUT) is a clinical test used for the diagnosis of this disease. In this work, we perform an analysis of parameters for a global and a local automatic computation of the BUT measure, based on criteria of specificity and sensitivity. We have tested our methodology on a dataset composed of 18 videos annotated by 4 different experts. The local analysis preserves the results of the global approach providing useful additional information about the break-up tear zone.		Lucía Ramos;Noelia Barreira;Antonio Mosquera González;Manuel G. Penedo;Eva Yebra-Pimentel;Carlos García-Resúa	2014	Computer methods and programs in biomedicine	10.1016/j.cmpb.2013.12.003	computer vision;simulation;image processing;computer science	Graphics	35.38126455319728	-76.34715525744603	32320
109ffbcc4005bc19935b8e68103013d7e01fffb8	learning to identify facial expression during detection using markov decision process	dynamic programming;detectors;decision tree facial expression identification markov decision process face detection dynamic programming face recognition image classification;classifying space;decision tree;technological innovation;image resolution;image databases;image classification;dynamic program;optimal policy;facial expression identification;eyes;face recognition;object detection decision trees dynamic programming face recognition image classification markov processes;classification tree analysis;markov processes;markov decision process;facial expression;face detection classification tree analysis decision trees face recognition dynamic programming eyes technological innovation detectors image databases image resolution;face detection;decision trees;object detection	"""While there has been a great deal of research in face detection and recognition, there has been very limited work on identifying the expression on a face. Many current face detection methods use a Viola-Jones style """"cascade"""" of Adaboost-based classifiers to detect faces. We demonstrate that faces with similar expression form """"clusters"""" in a """"classifier space"""" defined by the real-valued outcomes of these classifiers on the images and address the task of using these classifiers to classify a new image into the appropriate cluster (expression). We formulate this as a Markov decision process and use dynamic programming to find an optimal policy - here a decision tree whose internal nodes each correspond to some classifier, whose arcs correspond to ranges of classifier values, and whose leaf nodes each correspond to a specific facial expression, augmented with a sequence of additional classifiers. We present empirical results that demonstrate that our system accurately determines the expression on a face during detection"""	adaboost;algorithm;decision tree;dynamic programming;face detection;jones calculus;markov chain;markov decision process;tree (data structure)	Ramana Isukapalli;Ahmed M. Elgammal;Russell Greiner	2006	7th International Conference on Automatic Face and Gesture Recognition (FGR06)	10.1109/FGR.2006.71	random subspace method;computer vision;computer science;machine learning;pattern recognition	Vision	35.763009130292716	-53.18591969198356	32346
a2dbd266eeedc0b351ca01534b59901b5afec0aa	detecting texture periodicity from the cooccurrence matrix	analisis imagen;analisis estadistico;image processing;analisis textura;deteccion;tabla contingencia;procesamiento imagen;imagen nivel gris;detection;periodicite;traitement image;periodicity;texture analysis;periodicidad;statistical analysis;image niveau gris;analyse statistique;image analysis;contingency table;table contingence;grey level image;analyse image;analyse texture	Abstract   Cooccurrence histograms have been widely used in texture and signal analysis. There have been suggestions on how to find structure and periodicity of the texture from cooccurrence histograms. A statistical property called agreement is here recommended as an indication of periodic structure. It is measured by a κ statistic.	quasiperiodicity;sensor	Jussi Parkkinen;K. Selkäinaho;Erkki Oja	1990	Pattern Recognition Letters	10.1016/0167-8655(90)90054-6	computer vision;image analysis;image processing;contingency table;computer science;artificial intelligence;algorithm;statistics	Vision	44.86364293963425	-62.439823972540744	32355
69ab94d05d3da8f07b5b023e8a69f0078f1dbd52	automatic mass detection in mammography images using particle swarm optimization and functional diversity indexes		This paper proposes a computational method to assist in detection of masses in dense and non-dense breasts on mammography images. The proposed methodology is divided into six steps. In summary, the first step consist of the images acquisition that was obtained from the Digital Database for Screening Mammography (DDSM). In the second step, a preprocessing is performed in order to remove noises and enhance the images. In the third step, the segmentation is performed to find the regions of interest (ROIs) that are candidates for masses using Particle Swarm Optimization (PSO). The fourth step consists in the first false positives reduction based on reduction by distance and Graph Clustering. The fifth step is the second false positive reduction based on texture features using functional diversity indexes. Finally, in the sixth step, the support vector machine (SVM) is used to classify ROIs in whether mass or non-mass. The best results were found in case of dense breast tissue, resulting in a sensitivity of 97.52%, specificity of 92.28%, accuracy of 94.82%, false positives rate per image of 0.38 and free-curve receiver operating characteristic of 0.98.	mathematical optimization;particle swarm optimization;preprocessor;receiver operating characteristic;region of interest;sensitivity and specificity;support vector machine	Otilio Paulo S. Neto;Aristófanes Corrêa Silva;Anselmo Cardoso de Paiva;Marcelo Gattass	2017	Multimedia Tools and Applications	10.1007/s11042-017-4710-1	computer vision;artificial intelligence;computer science;support vector machine;pattern recognition;receiver operating characteristic;mammography;preprocessor;clustering coefficient;false positive paradox;particle swarm optimization;segmentation	Vision	35.36002279276659	-74.586388549958	32357
2277df262c9ed5fa831008149e78bbb3fd905250	local boosted features for pedestrian detection	comunicacion de congreso;histograms of oriented gradients;local features;pedestrian detection;part of book or chapter of book	The present paper addresses pedestrian detection using local boosted features that are learned from a small set of training images. Our contribution is to use two boosting steps. The first one learns discriminant local features corresponding to pedestrian parts and the second one selects and combines these boosted features into a robust class classifier. In contrast of other works, our features are based on local differences over Histograms of Oriented Gradients (HoGs). Experiments carried out to a public dataset of pedestrian images show good performance with high classification rates. 1	boosting (machine learning);categorization;discriminant;image gradient;pedestrian detection	Michael Villamizar;Alberto Sanfeliu;Juan Andrade-Cetto	2009		10.1007/978-3-642-02172-5_18	computer vision;speech recognition;artificial intelligence	ML	32.4336259443748	-54.4548182300669	32429
b935c8787ce8e14cd9544a952b8e38f6cd94a361	mathematical morphology and weighted least squares to correct handwriting baseline skew	weighted least squares;filtering;mathematical morphology;least squares approximations;pseudo convex hull;mathematics;handwriting recognition;bank data processing handwritten character recognition handwriting recognition mathematical morphology computational geometry least squares approximations;weighted least square;computational geometry;handwriting baseline skew correction;morphology least squares methods handwriting recognition character generation read only memory mathematics humans error correction writing filtering;bank data processing;morphology;error correction;character generation;bank check date images;writing;humans;convex hull;read only memory;empirical thresholds;least squares methods;handwritten character recognition;pseudo convex hull mathematical morphology weighted least squares handwriting baseline skew correction bank check date images empirical thresholds	An approach to correct the baseline handwritten word skew in the image of bank check dates is presented in this article. The main goal of such approach is to reduce the use of empirical thresholds. The weighted least squares approach is used on the pseudo-convex hull obtained from the mathematical morphology.	baseline (configuration management);convex hull;fragmentation (computing);heuristic (computer science);least squares;mathematical morphology;maxima and minima	Marisa E. Morita;Jacques Facon;Flávio Bortolozzi;Silvio J. A. Garnés;Robert Sabourin	1999		10.1109/ICDAR.1999.791816	filter;generalized least squares;error detection and correction;speech recognition;mathematical morphology;morphology;computational geometry;computer science;convex hull;machine learning;pattern recognition;handwriting recognition;writing;least squares;read-only memory	Vision	48.53990635717744	-72.9075630932474	32462
dda9591eba1736c9edfcb050bf4b85646d83758f	readjusting unstable regions to improve the quality of high accuracy optical flow	moving object;traitement signal;unstable region;optical control;vision ordenador;image motion analysis;estimation mouvement;motion control;image sequences filtering theory;application software;flux optique;optical filters;compact design;estimacion movimiento;concepcion compacta;diffusion anisotrope;optical flow estimation;high accuracy optical flow;motion estimation;blanco movil;high precision;anisotropic diffusion;power method;unstable region context based anisotropic diffusion filter optical flow;computer applications;application informatique;computer vision;algorithme;context based anisotropic diffusion filter high accuracy optical flow unstable regions readjustment optical flow estimation;algorithm;motion blur;imagen borrosa;flujo optico;conception compacte;difusion anisotropica;three dimensional displays;blurred image;signal processing;precision elevee;poursuite cible;context based anisotropic diffusion filter;precision elevada;cible mobile;vision ordinateur;optical flow;image floue;anisotropic scattering;target tracking;procesamiento senal;filtering theory;moving target;tracking;image motion analysis optical filters computer vision application software motion estimation motion control optical control tracking three dimensional displays geometrical optics;unstable regions readjustment;geometrical optics;image sequences;algoritmo	Optical flow is an important problem in computer vision since applications of accurate optical flow estimation enable us to control and manipulate tracking, 3-D reconstruction, motion blurring, and dirt removal. Many powerful methods have been proposed to solve the optical flow problem; however, instabilities at the boundaries of moving objects are still challenges. A difficult part of the optical flow problem is how to accurately and quickly detect and readjust unstable regions at the boundaries. This paper aims to enhance optical flow estimation by detecting and readjusting the unstable regions. In this paper, a new algorithm to detect and quickly readjust unstable regions at the boundaries of moving objects is presented in a more general and compact manner. In addition, a new context-based anisotropic diffusion filter, which is significant in processing intermediate data, is discussed in detail. Our approach has demonstrated more accurate results than previous approaches.	algorithm;anisotropic diffusion;box blur;computation;computer vision;control theory;flow network;optical flow;pixel;sensor	Synh Viet Uyen Ha;Jae Wook Jeon	2010	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2010.2041818	motion control;geometrical optics;computer vision;application software;simulation;power iteration;computer science;signal processing;motion estimation;optical flow;optical filter;tracking;computer applications;anisotropic diffusion	Vision	51.594216428319406	-58.72060286012839	32524
b729c1ce19f9cc15945dcb72a8aba947af30fc43	from gigabytes to bytes: automated denoising and feature identification in electron tomograms of intact bacterial cells	noise reduction electrons microorganisms tomography data acquisition explosions spatial resolution information analysis noise robustness signal to noise ratio;image segmentation;large dataset;bacterial cells;segmentation;feature extraction denoising electron tomograms bacterial cells automated data acquisition segmentation;automated feature extraction;electron microscopy;automated data acquisition;feature extraction;medical image processing;electron tomography;statistical inference;denoising;signal to noise ratio;electron tomograms;template matching;data acquisition;tomography;microorganisms;tomography feature extraction image segmentation medical image processing microorganisms	"""Advances in automated data acquisition in electron tomography have led to an explosion in the amount of data that can be obtained about the spatial architecture of a variety of biologically and medically relevant objects with resolutions in the """"nano"""" range of 10-1000 nm. The development of methods to automatically analyze the vast amounts of information contained in these tomograms is a major challenge since the electron tomograms are intrinsically very noisy. A fundamental step in the automatic analysis of large amounts of data for statistical inference is to segment relevant 3D features in cellular tomograms. Procedures for segmentation must work robustly and rapidly in spite of the low signal to noise ratios inherent to biological electron microscopy. This work first evaluates various non-linear denoising techniques on tomograms recorded at cryogenic temperatures. Using datasets of bacterial tomograms as an example, we demonstrate that non-linear diffusion techniques significantly improve the fidelity of automated feature extraction. Our approach represents an important step in automating the efficient extraction of useful information from large datasets in biological tomography, and facilitates the overall goal of speeding up the process of reducing gigabyte-sized tomograms to relevant byte-sized data."""	algorithm;byte;data acquisition;electron tomography;feature extraction;gnu nano;gigabyte;high-throughput computing;network access device;noise reduction;nonlinear system;semiconductor industry;signal-to-noise ratio;throughput	Rajesh Narasimha;Iman Aganj;Mario Borgnia;Guillermo Sapiro;Steven W. McLaughlin;Jacqueline Milne;Sriram Subramaniam	2007	2007 4th IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2007.356849	computer vision;statistical inference;template matching;electron tomography;feature extraction;computer science;pattern recognition;noise reduction;tomography;image segmentation;microorganism;data acquisition;signal-to-noise ratio;segmentation;electron microscope	Visualization	40.315777898306074	-74.04459129043121	32569
d443e374fcb4a084859bd3e99f327b6120f3cd5f	detecting hippocampal shape changes in alzheimer's disease using statistical shape models	mini mental state examination;m ri;brain;magnetism;statistical shape model;hippocampus;shape analysis;mr imaging;statistical discrimination;magnetic resonance;principal component analysis;alzheimer s disease;normal control;support vector machine;diseases and disorders	The hippocampus is affected at an early stage in the development of Alzheimer's disease (AD). Using brain Magnetic Resonance (MR) images, we can investigate the effect of AD on the morphology of the hippocampus. Statistical shape models (SSM) are usually used to describe and model the hippocampal shape variations among the population. We use the shape variation from SSM as features to classify AD from normal control cases (NC). Conventional SSM uses principal component analysis (PCA) to compute the modes of variations among the population. Although these modes are representative of variations within the training data, they are not necessarily discriminant on labelled data. In this study, a Hotelling's T test is used to qualify the landmarks which can be used for PCA. The resulting variation modes are used as predictors of AD from NC. The discrimination ability of these predictors is evaluated in terms of their classification performances using support vector machines (SVM). Using only landmarks statistically discriminant between AD and NC in SSM showed a better separation between AD and NC. 1. Description of purpose Early detection and diagnosis of Alzheimer's disease (AD) is a challenging task. Since the hippocampus is affected by atrophy in the earliest stage of disease, which may result in the reduction of volume and the change in the shape of hippocampus. Hippocampal volume has been previously used to classify AD from normal control (NC) subjects, as well as cases with mild cognitive impairment (MCI) [1]. Shape information in the form of spherical harmonics (SH) has been used as features in the support vector machine (SVM) classification [2,3]. Statistical Shape Models (SSMs) have been used to model the variability in the hippocampal shapes among the population (e.g. [4]). They usually rely on principal component analysis (PCA) to determine a lower dimensional subspace that accounts for the most variations. However, these modes of variations are not necessarily discriminant. In this study, we aim to improve the discrimination between AD and NC using shape information characterized by SSM. We use SSM to search for variations on the surface regions that are significantly discriminant between the two groups. The discriminant regions may be due to both volume and shape changes. We propose to use the morphological variation on these surface regions as variables to distinguish AD from NC cases. These variations are also correlated with the cognitive decline in AD.	alzheimer's disease neuroimaging initiative;landmark point;linear discriminant analysis;mathematical morphology;performance;principal component analysis;resonance;sensor;spatial variability;statistical model;support vector machine	Kai-Kai Shen;Pierrick Bourgeat;Jurgen Fripp;Fabrice Mériaudeau;Olivier Salvado	2011		10.1117/12.877869	support vector machine;magnetism;speech recognition;artificial intelligence;magnetic resonance imaging;machine learning;shape analysis;hippocampus;principal component analysis	Vision	31.582847513218447	-78.71147174768639	32699
ec9ff0ffd98222b1fe7c8b47a663d670efbbf8c1	soft-linked quadtree: a cascaded ring structure using flexible linkage concept	probability;picture processing;trees mathematics;trees mathematics pattern recognition picture processing probability;pattern recognition;couplings image segmentation labeling control systems machine vision robot vision systems uncertainty layout joining processes path planning;probabilities image segment picture processing labelling pattern recognition cascaded ring structure flexible linkage concept maximal block representation soft linked quadtree nodes	Quadtree is a variant of the niaxinlal block representation scheme. The image is recursively subdivided until each tree node is simple. accordirlg to some criterion. This paper presents a new look at this representation b y introducing the concept of f lexible linkage and a modular ring structure. A so f tl inked quadtree can be put together by various admissible permutations o f 3 rings. Each ring consists o f two nodes with uniform a n d / o r mixed label. Each node, in contrasl to a conventional quadtree. has only a probabilistic aff i l iation t o various segments of an image. Moreover, the links between father and son nodes are so f t and characterized b y a branch strength. All nodes hare children: the degree o f mutual attachment is the variable. The presence of soft links gives rise to an up projection e f f e c t whereby the classification o f children impacts the ancestor's original label. This impact is modeled as a recursive relationship between all iiodal state probabilities. branch strengths arid tree depth. The implication of this viewpoint on some of the existing quadtree-based algorithms is discussed mid n need for re-evaluation is pointed out.	algorithm;attachments;linkage (software);quadtree;recursion	Bijan G. Mobasseri	1988		10.1109/CVPR.1988.196301	computer vision;combinatorics;discrete mathematics;computer science;machine learning;quadtree;probability;mathematics;geometry;algorithm;statistics	Robotics	44.08191451107693	-56.155293004684005	32728
27578f29f082f44702c3f63b14c8d18e32c5146f	dense rgb-d semantic mapping with pixel-voxel neural network	rgb-d slam;semantic mapping;visual mapping	In this paper, a novel Pixel-Voxel network is proposed for dense 3D semantic mapping, which can perform dense 3D mapping while simultaneously recognizing and labelling the semantic category each point in the 3D map. In our approach, we fully leverage the advantages of different modalities. That is, the PixelNet can learn the high-level contextual information from 2D RGB images, and the VoxelNet can learn 3D geometrical shapes from the 3D point cloud. Unlike the existing architecture that fuses score maps from different modalities with equal weights, we propose a softmax weighted fusion stack that adaptively learns the varying contributions of PixelNet and VoxelNet and fuses the score maps according to their respective confidence levels. Our approach achieved competitive results on both the SUN RGB-D and NYU V2 benchmarks, while the runtime of the proposed system is boosted to around 13 Hz, enabling near-real-time performance using an i7 eight-cores PC with a single Titan X GPU.	adaptive filter;artificial neural network;benchmark (computing);deploy;domestic robot;end-to-end principle;enlargement procedure;european union;experiment;fuse device component;graphics processing unit;hertz (hz);high- and low-level;inference;map;nonlinear system;physical object;pixel;point cloud;real-time clock;real-time computing;real-time web;revision procedure;robotic mapping;robotics;scientific publication;semantic mapper;semantic mapping (statistics);simultaneous localization and mapping;softmax function;software deployment;source code;time complexity;titan (supercomputer);tmax;voxel;weight;biologic segmentation;irex iliad	Cheng Zhao;Li Sun;Pulak Purkait;Rustam Stolkin	2018		10.3390/s18093099	point cloud;electronic engineering;fuse (electrical);voxel;semantic mapping;engineering;pixel;artificial neural network;artificial intelligence;rgb color model;pattern recognition;softmax function	AI	26.99408559349223	-53.37007445856611	32756
4af842f2266bd04074c95af0d6649d8648f65307	template-based eye and mouth detection for 3d video conferencing	reconnaissance visage;pupil;feature detection;pistage;medicion automatica;modelo 3 dimensiones;facies;imagen fija;teleconference;edge detection;modele 3 dimensions;pupille;lip;video conference;rastreo;three dimensional model;inicializacion;automatic measurement;mesure automatique;high precision;deteccion contorno;teleconferencia;detection contour;face recognition;senal video;levre;fixed image;signal video;automatic detection;face animation;precision elevee;precision elevada;video signal;labio;facial features;image fixe;deformable template;3d video;pupila;initialization;initialisation;tracking	The usage of 3D face animation techniques within video conference applications enables new features like viewpoint adaptation, stereo display, or virtual conferencing in shared synthetic rooms. Most of these systems require an automatic detection of facial feature points for tracking or initialization purposes. We have developed an automatic method for face feature detection using synthetic deformable templates. The algorithm does not require a training procedure or parameter set. It can be applied to images with different sizes of the face area. Iris-pupil centers, mouth corners and mouth inner lip line are robustly found with high accuracy from one still image. This automatic process allows to set up an advanced video conference system that uses 3D head models of the participants to synthesize new views.	algorithm;autostereogram;crystallographic information file;feature detection (computer vision);feature detection (web development);feature model;hausdorff dimension;mobile device;pixel;stereo display;synthetic intelligence	Jürgen Rurainsky;Peter Eisert	2003		10.1007/978-3-540-39798-4_6	facial recognition system;computer vision;initialization;simulation;teleconference;edge detection;facies;computer science;feature detection;tracking;videoconferencing;computer graphics (images)	Vision	47.50749133925878	-57.41168072701079	32767
872f803445cddc39f63d451eaa56164c533a6a8d	cervical cell classification using features related to morphometry and texture of nuclei		The Papanicolaou test is used for early prediction of cervical cancer. Computer vision techniques for automating the microscopy analysis of cervical cells in this test have received great attention. Cell segmentation is needed here in order to obtain appropriate features for classification of abnormal cells. However, accurate segmentation of the cell cytoplasm is difficult, due to cell overlapping and variability of color and intensity. This has determined a growing interest in classifying cells using only features from the nuclei, which are easier to segment. In this work, we classified cells in the pap-smear test using a combination of morphometric and Haralick texture features, obtained from the nucleus gray-level co-occurrence matrix. A comparison was made among various classifiers using these features and data dimensionality reduction through PCA. The results obtained showed that this combination can be a promising alternative in order to automate the analysis of cervical cells.	cell signaling;co-occurrence matrix;color;computer vision;dimensionality reduction;document-term matrix;morphometrics;principal component analysis;robert haralick;smear campaign;spatial variability	Juan V. Lorenzo-Ginori;Wendelin Curbelo-Jardines;José Daniel López-Cabrera;Sergio B. Huergo-Suárez	2013		10.1007/978-3-642-41827-3_28	pattern recognition;artificial intelligence;papanicolaou test;computer science;cervical cells;abnormal cells;dimensionality reduction;cervical cancer;cytoplasm;cell;segmentation	ML	36.01099054897879	-74.8389046781368	32778
2f0bcca9fe25b44def5fb0259fbd5cb9b52cd9c4	an agent-based approach for range image segmentation	image segmentation;multi agent systems;range image;artificial potential field	In this paper an agent-based segmentation approach is presented and evaluated. The approach consists in using a high number of autonomous agents for the segmentation of a range image in its different planar regions. The moving agents perform cooperative and competitive actions on the image pixels allowing a robust extraction of regions and an accurate edge detection. An artificial potential field, created around pixels of interest, allows the agents to be gathered around edges and noise regions. The results obtained with real images are compared to those of some typical methods for range image segmentation. The comparison results show the potential of the proposed approach for scene understanding in range images regarding both segmentation efficiency, and detection accuracy.	abandonware;agent-based model;algorithm;autonomous agent;autonomous robot;edge detection;emergence;image segmentation;pixel;range imaging;range segmentation;region growing	Smaine Mazouzi;Zahia Guessoum;Fabien Michel;Mohamed Batouche	2006		10.1007/978-3-540-85449-4_11	image texture;computer vision;range segmentation;computer science;artificial intelligence;machine learning;segmentation-based object categorization;multi-agent system;pattern recognition;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation	Robotics	44.76091677036408	-68.78367287901048	32781
7f3e0bd21ead365af8dd302ab7d5b1ab53e7d437	affine-invariant recognition of gray-scale characters using global affine transformation correlation	gaussian noise;successive iteration method;correlation methods gaussian noise iterative methods image matching optical character recognition;image matching;optical character recognition;global affine transformation;correlation methods;random gaussian noise affine invariant recognition gray scale characters global affine transformation correlation noise tolerance normalized cross correlation global affine transformation affine invariant correlation successive iteration method topographic features matching constraints;iterative methods;gray scale character recognition;affine transformation;iteration method;noise tolerant and affine invariant image matching;character recognition;normalized cross correlation;character recognition gray scale degradation gaussian noise image matching image segmentation image recognition surface morphology surface topography shape	ÐThis paper describes a new, promising technique of gray-scale character recognition that offers both noise tolerance and affine-invariance. The key ideas are twofold. First is the use of normalized cross-correlation as a matching measure to realize noise tolerance. Second is the application of global affine transformation (GAT) to the input image so as to achieve affine-invariant correlation with the target image. In particular, optimal GAT is efficiently determined by the successive iteration method using topographic features of gray-scale images as matching constraints. We demonstrate the high matching ability of the proposed GAT correlation method using gray-scale images of numerals subjected to random Gaussian noise and a wide range of affine transformation. Moreover, extensive recognition experiments show that the achieved recognition rate of 94.3 percent against rotation within 30 degrees, scale change within 30 percent, and translation within 20 percent of the character width along with random Gaussian noise is sufficiently high compared to the 42.8 percent offered by simple correlation. Index TermsÐGray-scale character recognition, normalized cross-correlation, global affine transformation, noise-tolerant and affineinvariant image matching, successive iteration method.	binary image;computation;computational model;cross-correlation;distortion;elegant degradation;experiment;gradient;grayscale;image registration;iteration;landweber iteration;optical character recognition;real life;topography;www	Toru Wakahara;Yoshimasa Kimura;Akira Tomono	2001	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.917573	computer vision;discrete mathematics;pattern recognition;mathematics;geometry;iterative method;statistics	Vision	43.343258227314266	-57.77721174585232	32836
ef9c92ecb4df0e8b31b6aa61fd8b0ab1023a8c79	a performance evaluation study of four wavelet algorithms for the pitch period estimation of speech signals	wavelet analysis;performance evaluation;image processing;edge detection;speech processing;multiscale analysis;wavelet transform;automatic speaker recognition;pitch estimation	Abstract   Pitch period is considered an important parameter in designing an automatic speaker recognition/identification system. Recently, inspired by application of multiscale analysis to edge detection in image processing, a new technique for pitch detection and estimation, based on the dyadic wavelet transform, was developed. In this paper we provide a more general setting for the wavelet based pitch estimation methodology: we show that certain restrictions on the window function, inherent in wavelet analysis, are unnecessary, and that discretization of the dilation parameter on a finer than the dyadic scale can be used advantageously in the multiscale pitch detection scheme.	algorithm;performance evaluation;wavelet	Mohammad S. Obaidat;Andy Brodzik;Balqies Sadoun	1998	Inf. Sci.	10.1016/S0020-0255(98)10032-4	wavelet;computer vision;speech recognition;edge detection;second-generation wavelet transform;continuous wavelet transform;image processing;computer science;pattern recognition;speech processing;cascade algorithm;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;wavelet transform	DB	52.34414662953601	-66.07021265224492	32901
086d3e1791349a6aded486a1db18c79408f9a31d	a generalized graph reduction framework for interactive segmentation of large images	user study;graph reduction;random walker;graph based segmentation;graph cuts;interactive segmentation	The speed of graph-based segmentation approaches, such as random walker (RW) and graph cut (GC), depends strongly on image size. For high-resolution images, the time required to compute a segmentation based on user input renders interaction tedious. We propose a novel method, using an approximate contour sketched by the user, to reduce the graph before passing it on to a segmentation algorithm such as RW or GC. This enables a significantly faster feedback loop. The user first draws a rough contour of the object to segment. Then, the pixels of the image are partitioned into “layers” (corresponding to different scales) based on their distance from the contour. The thickness of these layers increases with distance to the contour according to a Fibonacci sequence. An initial segmentation result is rapidly obtained after automatically generating foreground and background labels according to a specifically selected layer; all vertices beyond this layer are eliminated, restricting the segmentation to regions near the drawn contour. Further foreground/background labels can then be added by the user to refine the segmentation. All iterations of the graph-based segmentation benefit from a reduced input graph, while maintaining full resolution near the object boundary. A user study with 16 participants was carried out for RW segmentation of a multi-modal dataset of 22 medical images, using either a standard mouse or a stylus pen to draw the contour. Results reveal that our approach significantly reduces the overall segmentation time compared with the status quo approach ( p < 0.01). The study also shows that our approach works well with both input devices. Compared to super-pixel graph reduction, our approach provides full resolution accuracy at similar speed on a high-resolution benchmark image with both RW and GC segmentation methods. However, graph reduction based on super-pixels does not allow interactive correction of clustering errors. Finally, our approach can be combined with super-pixel clustering methods for further graph reduction, resulting in even faster segmentation. © 2016 Published by Elsevier Inc.	amiga walker;approximation algorithm;benchmark (computing);cluster analysis;cut (graph theory);feedback;graph cuts in computer vision;graph reduction;image resolution;input device;iteration;modal logic;pixel;random walker algorithm;read-write memory;rendering (computer graphics);rough set;stylus (computing);thickness (graph theory);usability testing	Houssem Eddine Gueziri;Michael J. McGuffin;Catherine Laporte	2016	Computer Vision and Image Understanding	10.1016/j.cviu.2016.05.009	computer vision;cut;computer science;theoretical computer science;machine learning;segmentation-based object categorization;image segmentation;graph reduction;random walker algorithm;minimum spanning tree-based segmentation;scale-space segmentation;connected-component labeling	Vision	46.390362645399144	-70.33415352872186	32924
7eba3871280009a2eb00bc400d3601f9409d7aa8	novelty detection in wildlife scenes through semantic context modelling	semantic context;novelty detection;co occurrence matrices;multiple one class models	Novelty detection is an important functionality that has found many applications in information retrieval and processing. In this paper we propose a novel framework that deals with novelty detection in multiple-scene image sets. Working with wildlife image data, the framework starts with image segmentation, followed by feature extraction and classification of the image blocks extracted from image segments. The labelled image blocks are then scanned through to generate a co-occurrence matrix of object labels, representing the semantic context within the scene. The semantic co-occurrence matrices then undergo binarization and principal component analysis for dimension reduction, forming the basis for constructing one-class models on scene categories. An algorithm for outliers detection that employs multiple one-class models is proposed. An advantage of our approach is that it can be used for novelty detection and scene classification at the same time. Our experiments show that the proposed approach algorithm gives favourable performance for the task of detecting novel wildlife scenes, and binarization of the semantic co-occurrence matrices helps increase the robustness to variations of scene	approximation algorithm;bag-of-words model in computer vision;co-occurrence matrix;computation;dimensionality reduction;document-term matrix;dynamic problem (algorithms);experiment;feature extraction;high- and low-level;image segmentation;information retrieval;key frame;novelty detection;one-class classification;principal component analysis;sensor;statistical classification;statistical model;user experience	Suet-Peng Yong;Jeremiah D. Deng;Martin K. Purvis	2012	Pattern Recognition	10.1016/j.patcog.2012.02.036	computer vision;computer science;machine learning;pattern recognition	Vision	38.31883514201961	-52.45717028374091	32967
976aebd2438187837f10c4cb1d6b7afbad61cee5	automatic detection of helmet uses for construction safety	histograms;image segmentation;surveillance;discrete cosine transforms;feature extraction;safety	The U.S. construction industry suffers from the highest number of fatalities among all industries, i.e., one in five worker deaths in private industry were in construction. Tremendous loss has occurred to the workers' families, the industry, and the nation. Considering the large and increasing number of construction projects that are being conducted in the U.S., there is a growing necessity of developing innovative methods to automatically monitor the safety for the workers at construction sites. Since the head is the most critical area of a human body and is the most vulnerable to an impact that could cause serious injury or death, the use of a protective helmet in construction work is needed. In this paper, we aim to automatically detect the uses of construction helmets (e.g., whether the construction worker wears the helmet or not) by analyzing the construction surveillance images. Based on the collected images, we first detect the object of interest (i.e., construction worker) and further analyze whether the worker wears the helmet or not, by using computer vision and machine learning techniques. In the first step, we incorporate frequency domain information of the image with a popular human detection algorithm Histogram of Oriented Gradient (HOG) for construction worker detection; in the second step, the combination of color-based and Circle Hough Transform (CHT) feature extraction techniques is applied to detect helmet uses for the construction worker.	algorithm;circle hough transform;color;computer vision;deep learning;feature extraction;gradient;machine learning;scalability;search algorithm;sensor	Abu Hasnat Mohammad Rubaiyat;Tanjin T. Toma;Masoumeh Kalantari Khandani;Syed A. Rahman;Lingwei Chen;Yanfang Ye;Christopher S. Pan	2016	2016 IEEE/WIC/ACM International Conference on Web Intelligence Workshops (WIW)	10.1109/WIW.2016.045	simulation;feature extraction;computer science;machine learning;data mining;histogram;image segmentation;computer security	DB	38.468987011425305	-68.24515466744907	33099
a047ea8f6dcafae5ce077952ee2b554580ed072a	on-road vehicle and pedestrian detection using improved codebook model	bin boundaries on road vehicle detection on road pedestrian detection implicit shape model object detection object categorization ism training local feature descriptor codebook generation interest point detector evaluation harris detector shape context local feature descriptor fuzzy function soft distribution k means algorithm mean shift;fuzzy set theory;pedestrians;shape vehicles context detectors clustering algorithms feature extraction object detection;feature extraction;road vehicles feature extraction fuzzy set theory object detection pedestrians;object detection;road vehicles	In this paper, an improved implicit shape model is presented for on-road vehicle and pedestrian detection. Implicit shape model (ISM) is widely used for object detection and categorization. The training of ISM usually consists of three components: interest point detector, local feature descriptor, codebook generation. We evaluate six common interest point detectors to determine the best detector for vehicles and pedestrians, and the experiments show that Harris Detector is more efficient than the others. The original shape context local feature descriptor is sensitive to shape with points near boundaries of bins, as each point gives hard distribution to the bin. Therefore, a fuzzy function is employed to make each point gives soft distribution to all around bins to make it robust to shapes with small difference on boundaries of bins. Finally, k-means algorithm is replaced by Mean shift to generate codebook, as it produces more accurate codebook on datasets without small bandwidth.	algorithm;categorization;codebook;data descriptor;experiment;harris affine region detector;implicit shape model;k-means clustering;list of code lyoko episodes;mean shift;object detection;pedestrian detection;sfiaplus;sensor;shape context;visual descriptor	Xiangyang Li;Xiangzhong Fang;Qingchun Lu	2013	Proceedings of 2013 IEEE International Conference on Vehicular Electronics and Safety	10.1109/ICVES.2013.6619592	computer vision;machine learning;pattern recognition;mathematics	Vision	32.8332585186098	-55.86984482606946	33188
0bf05cec6848f96b09424e84414bf6884dd75ccc	accurate optical flow estimation in noisy sequences by robust tensor-driven anisotropic diffusion	eigenvalues and eigenfunctions;motion field classification optical flow estimation noisy sequences tensor driven anisotropic diffusion filtering method noisy image sequences thresholding criterion normalization function eigenvectors eigenvalues;geometrical optics image motion analysis optical noise robustness anisotropic magnetoresistance optical filters tensile stress image sequences eigenvalues and eigenfunctions filtering;optical flow estimation;anisotropic diffusion;eigenvalues;image sequence;eigenvalues and eigenfunctions image sequences filtering theory;3d structure;filtering theory;eigenvectors;diffusion tensor;image sequences	In this paper, a new tensor-driven anisotropic diffusion filtering method is proposed for achieving accurate optical flow estimation in noisy image sequences. The novelties of our approach are: (1) robust tensor-driven anisotropic diffusion computation, (2) new thresholding criterion for normalization function. By utilizing the decomposed eigenvectors and eigenvalues of the 3D structure tensor, the robust diffusion tensor is computed to steer the anisotropic filtering over the input image sequence. The moving orientations of the local spatio-temporal structures are precisely captured during the denoising process. For achieving more accurate diffusion tensor computation, a new thresholding criterion is developed in the normalization function to threshold the decomposed eigenvalues. As compared with that of existing methods, our experimental results demonstrate much improved accuracy on both motion field classification and optical flow estimation.	anisotropic diffusion;anisotropic filtering;computation;motion field;noise reduction;optical flow;structure tensor;thresholding (image processing)	Hai-Yun Wang;Kai-Kuang Ma	2005	IEEE International Conference on Image Processing 2005	10.1109/ICIP.2005.1530636	computer vision;mathematical optimization;mathematical analysis;eigenvalues and eigenvectors;computer science;mathematics;geometry;anisotropic diffusion	Vision	52.21749074810841	-70.85669000568525	33238
c624d7860ba69535c5fa140a1f1db26d336044b5	improved medical image modality classification using a combination of visual and textual features	image modality classification;feature fusion;visual image descriptors	In this paper, we present the approach that we applied to the medical modality classification tasks at the ImageCLEF evaluation forum. More specifically, we used the modality classification databases from the ImageCLEF competitions in 2011, 2012 and 2013, described by four visual and one textual types of features, and combinations thereof. We used local binary patterns, color and edge directivity descriptors, fuzzy color and texture histogram and scale-invariant feature transform (and its variant opponentSIFT) as visual features and the standard bag-of-words textual representation coupled with TF-IDF weighting. The results from the extensive experimental evaluation identify the SIFT and opponentSIFT features as the best performing features for modality classification. Next, the low-level fusion of the visual features improves the predictive performance of the classifiers. This is because the different features are able to capture different aspects of an image, their combination offering a more complete representation of the visual content in an image. Moreover, adding textual features further increases the predictive performance. Finally, the results obtained with our approach are the best results reported on these databases so far.	bag-of-words model;database;high- and low-level;histogram;local binary patterns;medical image;modality (human–computer interaction);scale-invariant feature transform;tf–idf	Ivica Dimitrovski;Dragi Kocev;Ivan Kitanovski;Suzana Loskovska;Saso Dzeroski	2015	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2014.06.005	computer vision;speech recognition;computer science;pattern recognition	Vision	25.6007068508901	-57.23176454730471	33256
b5eb615660ca12bb8fd67956bc79b42494a18a89	enhanced pseudo zernike moments in face recognition	pseudo zernike moments;kernel;fisher s linear discriminant;face recognition;zernike moment;ta engineering general civil engineering general	This paper presents an approach to boost the performance of pseudo Zernike moments in face recognition. This approach is a hybrid of a kernel trick, discriminant function and pseudo Zernike moments (PZM), namely as Kernel-based Fisher Pseudo Zernike Moments (KFPZM). KFPZM maps the moment-based features into a high dimensional feature space via kernel function for disclosing the underlying variables which carry significant information about the image. Then, it performs discriminant analysis onto the mapped features to enhance the discrimination power via Fisher’s Linear Discriminant (FLD). Experimental results show that the proposed method outperforms the sole PZM and the integrated FLD with PZM methods, achieving recognition rate of 98.11% and 93.03% in the face databases with facial expression variations and illumination variations, respectively.	database;facial recognition system;feature vector;illumination (image);kernel method;linear discriminant analysis;map	Ying-Han Pang;Andrew Beng-Jin Teoh;David Chek Ling Ngo	2005	IEICE Electronic Express	10.1587/elex.2.70	facial recognition system;computer vision;kernel fisher discriminant analysis;kernel;computer science;machine learning;pattern recognition;mathematics	Vision	33.770801135271256	-58.963168607088775	33277
ea15dca1b7e9bb0ced86f8e1f3c3de3dcc3bfe50	curved planar reformation and optimal path tracing (crop) method for false positive reduction in computer-aided detection of pulmonary embolism in ctpa	pulmonary arteries;networks;computer aided diagnosis;photoemission spectroscopy;receivers;feature extraction;computer aided detection;curved planar reformation;vessel segmentation;optimal path finding;diseases and disorders;false positive reduction	The curved planar reformation (CPR) method re-samples the vascular structures along the vessel centerline to generate longitudinal cross-section views. The CPR technique has been commonly used in coronary CTA workstation to facilitate radiologists’ visual assessment of coronary diseases, but has not yet been used for pulmonary vessel analysis in CTPA due to the complicated tree structures and the vast network of pulmonary vasculature. In this study, a new curved planar reformation and optimal path tracing (CROP) method was developed to facilitate feature extraction and false positive (FP) reduction and improve our PE detection system. PE candidates are first identified in the segmented pulmonary vessels at prescreening. Based on Dijkstra’s algorithm, the optimal path (OP) is traced from the pulmonary trunk bifurcation point to each PE candidate. The traced vessel is then straightened and a reformatted volume is generated using CPR. Eleven new features that characterize the intensity, gradient, and topology are extracted from the PE candidate in the CPR volume and combined with the previously developed 9 features to form a new feature space for FP classification. With IRB approval, CTPA of 59 PE cases were retrospectively collected from our patient files (UM set) and 69 PE cases from the PIOPED II data set with access permission. 595 and 800 PEs were manually marked by experienced radiologists as reference standard for the UM and PIOPED set, respectively. At a test sensitivity of 80%, the average FP rate was improved from 18.9 to 11.9 FPs/case with the new method for the PIOPED set when the UM set was used for training. The FP rate was improved from 22.6 to 14.2 FPs/case for the UM set when the PIOPED set was used for training. The improvement in the free response receiver operating characteristic (FROC) curves was statistically significant (p<0.05) by JAFROC analysis, indicating that the new features extracted from the CROP method are useful for FP reduction.	asea irb;bifurcation theory;ct pulmonary angiogram;dijkstra's algorithm;feature extraction;feature vector;gradient;path tracing;radiology;receiver operating characteristic;sensitivity and specificity;workstation	Chuan Zhou;Heang-Ping Chan;Yanhui Guo;Jun Wei;Aamer Chughtai;Lubomir M. Hadjiiski;Baskaran Sundaram;Smita Patel;Jean W. Kuriakose;Ella A. Kazerooni	2013		10.1117/12.2008048	photoemission spectroscopy;computer vision;simulation;feature extraction;physics		35.917164601304606	-77.94642786267106	33295
3e408150363e16fe0032268b0c2489cc96b4c0d5	performance assessment of a face verification based access control system	facial biometric;access control face recognition cameras image databases latches biomedical imaging biomedical engineering system testing machine vision roads;performance evaluation;biometrics access control;authentication;face verification system;model based approach;peer reviewed conference;face verification;intra person dependencies performance assessment face verification face recognition systems door access control system model based approach internal failure modes inter person dependencies;face recognition;face recognition biometrics access control;access control;performance assessment	In recent years there has been much progress in the development of facial recognition systems. The FERET series of tests reported the black box performance of several such systems working on stored face images. Much less effort has been spent in studying the behaviour of systems under realistic conditions of use. We describe and analyse the result of a trial of a door access control system based on a model-based approach. The trial consisted of 10 registered users making over 200 accesses during a 2 week period. We describe the internal failure modes and the performance characteristics of the system, identify inter- and intra-person dependencies and make recommendations for future work.	control system	Gavin V. Wheeler;Patrick Courtney;Timothy F. Cootes;Christopher J. Taylor	2000		10.1109/AFGR.2000.840638	facial recognition system;computer vision;simulation;computer science;access control;machine learning;authentication;face recognition grand challenge;computer security	Security	27.516908900572354	-62.84037158446506	33360
8b03536df5f47b345120c4d20937d80751f595a4	improved multi-scale line detection method for retinal blood vessel segmentation			edge detection	Kejuan Yue;Beiji Zou;Zailiang Chen;Qing Liu	2018	IET Image Processing	10.1049/iet-ipr.2017.1071	artificial intelligence;computer vision;segmentation;blood vessel;retinal;mathematics;pattern recognition	EDA	41.53667892640575	-71.7420580803036	33406
c9a48b0a8ae519a0e3c72756bf1b8b581aec29e3	post-processed lda for face and palmprint recognition: what is the rationale	euclidean distance;linear discriminate analysis;face recognition;dimensionality reduction;feature extraction;palmprint recognition;dimensional reduction;linear discriminant analysis lda	Linear discriminant analysis (LDA)-based methods have been very successful in face and palmprint recognition. Recently, a class of post-processing approaches has been proposed to improve the recognition performance of LDA in face recognition. In-depth analysis, however, has not been presented to reveal the effectiveness of the post-processing approach. In this paper, we first investigate the rationale of the post-processing approach using a Gaussian function, and demonstrate the mutual relationship between the post-processing approach and the image Euclidean distance (IMED) method. We further extend the post-processing approach to palmprint recognition and use the FERET face and the PolyU palmprint databases to evaluate the post-processed LDA method. Experimental results indicate that the post-processing approach is effective in improving the recognition rate for LDA-based face and palmprint recognition.	design rationale;fingerprint	Wangmeng Zuo;Hongzhi Zhang;David Zhang;Kuanquan Wang	2010	Signal Processing	10.1016/j.sigpro.2009.06.004	facial recognition system;speech recognition;feature extraction;computer science;machine learning;pattern recognition;euclidean distance;three-dimensional face recognition;mathematics;dimensionality reduction	Vision	33.69515273184306	-58.89211731364586	33438
c3019d8b944d50d0013c88132b4b6c506a02865c	an alternating split bregman algorithm for multi-region segmentation	concave programming;image segmentation;image database;iterative methods computer vision concave programming image segmentation;computer vision;region segmentation;optimization problem;iterative methods;fluorescence microscopy;image segmentation computer vision vectors labeling optimization approximation methods image color analysis;convex relaxation;live cell fluorescence microscopy alternating split bregman algorithm multiregion image segmentation nonconvex optimization problem computer vision convex relaxations continuous potts segmentation model primal dual approach berkeley image database;large classes	Multi-region image segmentation aims at partitioning an image into several “meaningful” regions. The associated optimization problem is non-convex and generally difficult to solve. Finding the global optimum, or good approximations of it, hence is a problem of first interest in computer vision. We propose an alternating split Bregman algorithm for a large class of convex relaxations of the continuous Potts segmentation model. We compare the algorithm to the primal-dual approach and show examples from the Berkeley image database and from live-cell fluorescence microscopy.	algorithm;approximation;bregman divergence;computer vision;convex function;global optimization;image segmentation;mathematical optimization;optimization problem;potts model	Grégory Paul;Janick Cardinale;Ivo F. Sbalzarini	2011	2011 Conference Record of the Forty Fifth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)	10.1109/ACSSC.2011.6190034	computer vision;mathematical optimization;feature detection;machine learning;segmentation-based object categorization;mathematics;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation	Vision	50.09088632287493	-71.76435580372305	33441
fa7a965d054cd70e560f0fd0810773b97ab66d9b	segmenting ct prostate images using population and patient-specific statistics for radiotherapy	clinical radiotherapy;health research;uk clinical guidelines;image features;biological patents;image segmentation;computed tomography;local descriptor;intra patient variation;clinical application;europe pubmed central;inter patient variation ct prostate image segmentation patient specific statistics population specific statistics clinical radiotherapy deformable model scale invariant feature transform local descriptor image features online training approach shape statistics intra patient variation;training;citation search;biological organs;prostate ct images deformable model shape statistics segmentation sift;deformable models;segmentation;ct prostate image segmentation;prostate ct images;statistical analysis biological organs computerised tomography feature extraction image segmentation medical image processing radiation therapy;surface treatment;shape;statistical analysis;sift;uk phd theses thesis;scale invariant feature transform;variable speed drives;inter patient variation;feature extraction;medical image processing;patient specific statistics;image segmentation computed tomography statistics deformable models medical treatment biomedical imaging robustness pixel active shape model principal component analysis;life sciences;computerised tomography;radiation therapy;shape statistics;uk research reports;medical journals;deformable model;population specific statistics;online training approach;europe pmc;biomedical research;bioinformatics	PURPOSE In the segmentation of sequential treatment-time CT prostate images acquired in image-guided radiotherapy, accurately capturing the intrapatient variation of the patient under therapy is more important than capturing interpatient variation. However, using the traditional deformable-model-based segmentation methods, it is difficult to capture intrapatient variation when the number of samples from the same patient is limited. This article presents a new deformable model, designed specifically for segmenting sequential CT images of the prostate, which leverages both population and patient-specific statistics to accurately capture the intrapatient variation of the patient under therapy.   METHODS The novelty of the proposed method is twofold: First, a weighted combination of gradient and probability distribution function (PDF) features is used to build the appearance model to guide model deformation. The strengths of each feature type are emphasized by dynamically adjusting the weight between the profile-based gradient features and the local-region-based PDF features during the optimization process. An additional novel aspect of the gradient-based features is that, to alleviate the effect of feature inconsistency in the regions of gas and bone adjacent to the prostate, the optimal profile length at each landmark is calculated by statistically investigating the intensity profile in the training set. The resulting gradient-PDF combined feature produces more accurate and robust segmentations than general gradient features. Second, an online learning mechanism is used to build shape and appearance statistics for accurately capturing intrapatient variation.   RESULTS The performance of the proposed method was evaluated on 306 images of the 24 patients. Compared to traditional gradient features, the proposed gradient-PDF combination features brought 5.2% increment in the success ratio of segmentation (from 94.1% to 99.3%). To evaluate the effectiveness of online learning mechanism, the authors carried out a comparison between partial online update strategy and full online update strategy. Using the full online update strategy, the mean DSC was improved from 86.6% to 89.3% with 2.8% gain. On the basis of full online update strategy, the manual modification before online update strategy was introduced and tested, the best performance was obtained; here, the mean DSC and the mean ASD achieved 92.4% and 1.47 mm, respectively.   CONCLUSIONS The proposed prostate segmentation method provided accurate and robust segmentation results for CT images even under the situation where the samples of patient under radiotherapy were limited. A conclusion that the proposed method is suitable for clinical application can be drawn.	atrial septal defects;body dysmorphic disorders;bone tissue;ct scan;gradient;image segmentation;increment;mathematical optimization;online machine learning;patients;population;portable document format;test set;biologic segmentation	Qianjin Feng;Mark Foskey;Songyuan Tang;Wufan Chen	2009	Medical physics	10.1109/ISBI.2009.5193039	computer vision;medicine;pathology;computer science;scale-invariant feature transform;computed tomography;medical physics	Vision	41.678853008874746	-78.79064747004422	33457
d76ce7b0b838e01c487d7fc64850d579e72c4d8f	a survey on breaking technique of text-based captcha		The CAPTCHA has become an important issue in multimedia security. Aimed at a commonly used text-based CAPTCHA, this paper outlines some typical methods and summarizes the technological progress in text-based CAPTCHA breaking. First, the paper presents a comprehensive review of recent developments in the text-based CAPTCHA breaking field. Second, a framework of text-based CAPTCHA breaking technique is proposed. And the framework mainly consists of preprocessing, segmentation, combination, recognition, postprocessing, and other modules. Third, the research progress of the technique involved in each module is introduced, and some typical methods of segmentation and recognition are compared and analyzed. Lastly, the paper discusses some problems worth further research.	captcha;text-based (computing)	Jun Chen;Xiangyang Luo;Yanqing Guo;Yi Zhang;Daofu Gong	2017	Security and Communication Networks	10.1155/2017/6898617	computer science;theoretical computer science;computer security;technological change;preprocessor;captcha	Vision	30.656202755382157	-67.8920086806891	33489
18f0f7ff2603df02b548359c9fb37d89eec29ec3	medical image segmentation using level sets and dictionary learning		In recent years, medical image analysis technology has grown rapidly. Several algorithms have been developed to segment and classify anatomical organs, using different medical image modalities such as computed tomography (CT), and magnetic resonance imaging (MRI). Medical image segmentation is a key problem in many applications, such as detection of brain tumors and disorders, or volumetric analysis of the normal brain. In this dissertation, I address the segmentation and classification problem of normal and abnormal structures in the human body. The segmentation objectives are to develop fully automatic methods for anatomical organ segmentation using prior knowledge. Prior knowledge is incorporated in terms of local and global image features using level set, and dictionary learning methods. The first part of this dissertation presents an efficient way to include global features to improve organ segmentation. I address the problem of the Mumford-Shah model in segmenting brain structures due to their boundary ambiguity by proposing a topological prior. It provides prior knowledge about the brain topology that helps to accurately segment brain structures. The classical level set energy functional is extended by adding the topological prior. Further, the topological graph is used as a feature to classify normal and abnormal brains. In the second part of this dissertation, I present an efficient strategy to couple the local features of grayscale, and label image data using both the level set formulation and the dictionary learning method. I show that the embedding of the sparse representation of local features in the level set formulation leads to a potential boost in segmentation accuracy compared to using only the voxel-wise dictionary learning method. This algorithm is applied to solve singleand multi-region segmentation problems. The third part of this dissertation focuses on a new method that combines the local, and global image information in a level set formulation using the dictionary learning approach. I show that such a combination leads to a significant improvement in the segmentation accuracy. Overall, I show that the embedding of prior knowledge in the level set formulation using the dictionary learning approach obtains more accurate segmentation results (92.7%). For all the proposed methods, I present extensive validation using real clinical data.	algorithm;ct scan;dictionary;grayscale;image analysis;image segmentation;machine learning;medical image computing;medical imaging;resonance;sparse approximation;sparse matrix;tomography;topological graph;voxel	Saif Dawood Salman Al-Shaikhli	2016				Vision	31.46203917021473	-75.18438300539329	33515
3566e5bb320722b55dc4b4f526c6d722fa5dd09e	3d point cloud segmentation using topological persistence	three dimensional displays face image segmentation clustering algorithms sensors robots topology;sampling methods image segmentation;fixed distance metric 3d point cloud segmentation topological persistence 3d point cloud data persistent homology theory zeroth homology group sampling conditions	In this paper, we present an approach to segment 3D point cloud data using ideas from persistent homology theory. The proposed algorithms first generate a simplicial complex representation of the point cloud dataset. Next, we compute the zeroth homology group of the complex which corresponds to the number of connected components. Finally, we extract the clusters of each connected component in the dataset. We show that this technique has several advantages over state of the art methods such as the ability to provide a stable segmentation of point cloud data under noisy or poor sampling conditions and its independence of a fixed distance metric.	algorithm;connected component (graph theory);homology (biology);persistence (computer science);persistent homology;point cloud;sampling (signal processing);simplicial complex	William J. Beksi;Nikolaos Papanikolopoulos	2016	2016 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2016.7487710	combinatorics;discrete mathematics;topology;mathematics;scale-space segmentation	Robotics	45.966016771398394	-54.207218126532034	33542
b2a406c2af37f32be4ad86a6c9833af8d4d1b7c9	wavelet-based reconstruction for rapid mri	compressed sensing;image resolution;gaussian processes;wavelet transforms;image reconstruction;medical image processing;image reconstruction wavelet transforms tv magnetic resonance imaging gsm wavelet domain;wavelet transforms biomedical mri compressed sensing data acquisition gaussian processes image reconstruction image resolution medical image processing;data acquisition;tv constraint wavelet based reconstruction mri magnetic resonance imaging data acquisition times image resolution compressed sensing techniques cs techniques k space data under sampling image reconstruction l1 regularization sparsifying transforms wavelet regularization gaussian scale mixture model gsm model total variation constraint;biomedical mri	In magnetic resonance imaging (MRI), slow data acquisition times often introduce artefacts due to motion and also limit the resolution of the images captured. To address this issue, compressed sensing (CS) techniques have recently been applied to allow under-sampling of the k-space data providing faster acquisition times. To reconstruct the image from the under-sampled measurements, a number of image reconstruction methods have been used. These techniques typically make use of l1-regularization and sparsifying transforms such as the wavelet transform. In this paper, we present a wavelet domain reconstruction method that utilises wavelet regularization with a Gaussian scale mixture (GSM) model prior combined with a Total Variation (TV) constraint in the complex wavelet domain. Our results show that, when compared to the results of previous approaches, the volume reconstructed using our proposed method has superior quality both visually and quantitatively.	algorithm;compressed sensing;data acquisition;iterative reconstruction;real-time clock;resonance;sampling (signal processing);synthetic data;wavelet transform	Rafiqul Islam;Andrew J. Lambert;Mark R. Pickering	2012	2012 International Conference on Digital Image Computing Techniques and Applications (DICTA)	10.1109/DICTA.2012.6411693	iterative reconstruction;wavelet;computer vision;image resolution;second-generation wavelet transform;computer science;machine learning;pattern recognition;gaussian process;mathematics;wavelet packet decomposition;data acquisition;discrete wavelet transform;compressed sensing;statistics;wavelet transform	Robotics	51.118501459907954	-76.85027008290704	33549
1e4abe37529468db30fcd28e6e26f7ff2c37961a	elastic registration of medical images using radial basis functions with compact support	tumor resection;medical images;biomedical imaging equations surgery image registration neoplasms graphics image analysis anatomy energy measurement shape;biomedical imaging;positive definite;radial basis function networks;tomographic images;radial basis function;shape;medical image;energy measurement;medical image processing;image registration;computerised tomography;surgery;compact support;image analysis;neoplasms;elastic registration;system of equations;anatomy;landmark;graphics;computerised tomography radial basis function networks medical image processing;radial basis functions;tomographic images elastic registration medical images radial basis functions compact support landmark tumor resection	We introduce radial basis functions with compact support for elastic registration of medical images. With these basis functions the influence of a landmark on the registration result is limited to a circle in 2D and, respectively, to a sphere in 3D. Therefore, the registration can be locally constrained which especially allows to deal with rather local changes in medical images due to, e.g., tumor resection. An important property of the used RBFs is that they are positive definite. Thus, the solvability of the resultin g system of equations is always guaranteed. We demonstrate our approach for synthetic as well as for 2D and 3D tomographic images.	3d computer graphics;dr-dos;elastic matching;experiment;imagine (3d modeling software);medical imaging;radial (radio);radial basis function;synthetic intelligence;thin plate spline;tomography;xfig	Mike Fornefett;Karl Rohr;H. Siegfried Stiehl	1999		10.1109/CVPR.1999.786970	computer vision;radial basis function;image analysis;computer science;machine learning;mathematics	Vision	46.210400381387025	-76.92597396379772	33569
4eb0a0d7335cb17cc7bee9692f89f9c90929aa89	multi-class protein subcellular localization classification using support vector machines			support vector machine	Peng Wai Meng;Jagath C. Rajapakse	2005				ML	29.355623663917697	-58.12813601859367	33596
b35886521605587dc82a28adefd422fdc4ff12cc	learning a shared transform model for skull to digital face image matching.		Human skull identification is an arduous task, traditionally requiring the expertise of forensic artists and anthropologists. This paper is an effort to automate the process of matching skull images to digital face images, thereby establishing an identity of the skeletal remains. In order to achieve this, a novel Shared Transform Model is proposed for learning discriminative representations. The model learns robust features while reducing the intra-class variations between skulls and digital face images. Such a model can assist law enforcement agencies by speeding up the process of skull identification, and reducing the manual load. Experimental evaluation performed on two pre-defined protocols of the publicly available IdentifyMe dataset demonstrates the efficacy of the proposed model.	algorithm;digital image;image registration	Maneet Singh;Shruti Nagpal;Richa Singh;Mayank Vatsa;Afzel Noore	2018	CoRR		artificial intelligence;discriminative model;human skull;computer science;law enforcement;pattern recognition;skull	Vision	30.792209703604524	-53.73249758859036	33602
ad1679295a5e5ebe7ad05ea1502bce961ec68057	framework for combination aware au intensity recognition	databases;combination aware au intensity recognition support vector machines elm extreme learning machines semi markov model au combination knowledge face alignment small head movements feature extraction;vdhmm facs elm au combination aware hierarchical classification;electronic mail;support vector machines;training;au combination aware hierarchical classification;gold;hidden markov models;gold hidden markov models training support vector machines face databases electronic mail;facs;vdhmm;support vector machines face recognition feature extraction learning artificial intelligence markov processes;face;elm	We present a framework for combination aware AU intensity recognition. It includes a feature extraction approach that can handle small head movements which does not require face alignment. A three layered structure is used for the AU classification. The first layer is dedicated to independent AU recognition, and the second layer incorporates AU combination knowledge. At a third layer, AU dynamics are handled based on variable duration semi-Markov model. The first two layers are modeled using extreme learning machines (ELMs). ELMs have equal performance to support vector machines but are computationally more efficient, and can handle multi-class classification directly. Moreover, they include feature selection via manifold regularization. We show that the proposed layered classification scheme can improve results by considering AU combinations as well as intensity recognition.	cellular automaton;computation;computational model;f1 score;facial recognition system;feature extraction;feature selection;manifold regularization;markov chain;markov model;matrix regularization;multiclass classification;regular expression;semiconductor industry;spontaneous order;support vector machine	Isabel Gonzalez;Werner Verhelst;Meshia C&#x00E9;dric Oveneke;Hichem Sahli;Dongmei Jiang	2015	2015 International Conference on Affective Computing and Intelligent Interaction (ACII)	10.1109/ACII.2015.7344631	gold;face;support vector machine;computer science;machine learning;pattern recognition;data mining;hidden markov model	Vision	30.79310705898575	-53.952765891902516	33604
2ba74dbeaec578c1e33ef6b510ab874fca2d86d1	body contours aam: automatic landmarking for people recognition			active appearance model	Karla Trejo;Cecilio Angulo;Juan Carlos Aguado	2015		10.3233/978-1-61499-578-4-279	computer vision;speech recognition;artificial intelligence;computer science	Vision	30.527668862357427	-58.87415012269196	33669
08ab03249449e90b552f51ac9ac2c5f4d568b427	cerebral aneurysm occurrence prediction by morphometric analysis of the willis ring	support vector machines;bifurcation;arteries;shape;feature extraction;joining processes;aneurysm	It is known that lifestyle habit and genetic factor are main reasons that occur cerebral aneurysms. In addition, some studies suggest that cerebral artery shape might be correlated with a risk of occurring aneurysms. For the purpose of preemptive medical care of the cerebral aneurysm, this study proposes a method to estimate a risk of occurring cerebral aneurysms based on the cerebral artery structure. The method extracts morphometric features of the Wills ring such as 3-D artery shape and bifurcation angle in 3-D magnetic resonance angiography (MRA) images. It then estimates the risk of occurring cerebral aneurysms from the extracted features using support vector machines (SVM). To validate the proposed method, we employed 40 subjects with cerebral aneurysms, and 40 subjects without cerebral aneurysms. Leave-one-out cross validation test was performed, and the method using 3-D artery shape achieved a sensitivity of 75% and a specificity of 75%; one using bifurcation angle did a sensitivity of 33% and a specificity of 71%; one using all features did a sensitivity of 68% and a specificity of 89%. The results showed that 3-D shape is effective for cerebral aneurysm occurrence risk prediction.	acceptance testing;bifurcation theory;care-of address;cross-validation (statistics);morphometrics;resonance;sensitivity and specificity;support vector machine	Marin Yasugi;Md Belayat Hossain;Hironobu Shibutani;Tamotsu Nomura;Manabu Nii;Masakazu Morimoto;Syoji Kobashi	2016	2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2016.7844495	support vector machine;feature extraction;shape;computer science;machine learning;mathematics	Robotics	34.27973694162437	-79.20193689929577	33672
c6f0796f6c516785c3af2aa431b9b18ec8262b92	modeling of echocardiogram video based on views and states	transition state;modelizacion;hierarchical system;vision ordenador;image processing;diagramme etat;long axis;systeme hierarchise;procesamiento imagen;echocardiographie;region interes;classification;traitement image;computer vision;modelisation;sistema jerarquizado;histogram;diagrama estado;senal video;histogramme;signal video;estado transitorio;echocardiography;state diagram;video signal;short axis;vision ordinateur;ecocardiografia;region interet;reseau neuronal;histograma;state transition diagram;modeling;clasificacion;red neuronal;etat transition;artificial neural network;interest region;neural network;dynamic behavior	In this work we propose a hierarchical state-based model for representing an echocardiogram video using objects present and their dynamic behavior. The modeling is done on the basis of the different types of views like short axis view, long axis view, apical view, etc. For view classification, an artificial neural network is trained with the histogram of a ‘region of interest’ of each video frame. A state transition diagram is used to represent the states of objects in different views and corresponding transition from one state to another. States are detected with the help of synthetic M-mode images. In contrast to traditional single M-mode approach, we propose a new approach named as ‘Sweep M-mode’ for the detection of states.	apache axis;artificial neural network;state diagram;synthetic intelligence	Aditi Roy;Shamik Sural;Jayanta Mukherjee;Arun K. Majumdar	2006		10.1007/11949619_36	computer vision;geography;artificial intelligence;cartography	AI	46.316408759283746	-57.75252184301847	33717
2e5b1a9076ea274af40cbbb3501c6d8eab119ed6	empirical bayesian em-based motion segmentation	iterations empirical bayesian expectation maximisation based motion segmentation statistical procedures nongreedy soft decisions pixel assignment spatial coherence empirical bayesian data analysis algorithm prior parameter estimation prior beliefs quantitative parameter specification trial and error strategies;image segmentation;bayesian methods motion segmentation computer vision image segmentation image motion analysis optical computing motion estimation clustering algorithms spatial coherence data analysis;image sequence analysis;image sequences image segmentation motion estimation statistical analysis data analysis;motion estimation;segmentation;data analysis;motion segmentation;statistical analysis;expectation maximization;bayesian learning;bayesian data analysis;learning in vision;image sequences	A recent trend in motion-based segmentation has been to rely on statistical procedures derived from ExpectationMaximization (EM) principles. EM-based approaches have various attractives for segmentation, such as proceeding by taking non-greedy soft decisions with regards to the assignment of pixels to regions, or allowing the use of sophisticated priors capable of imposing spatial coherence on the segmentation. A practical difficulty with such priors is, however, the determination of appropriate values for their parameters. In this work, we exploit the fact that the EM framework is itself suited for empirical Bayesian data analysis to develop an algorithm that finds the estimates of the prior parameters which best explain the observed data. Such an approach maintains the Bayesian appeal of incorporating prior beliefs, but requires only a qualitative description of the prior, avoiding the requirement of a quantitative specification of its parameters. This eliminates the need for trialand-error strategies for parameter determination and leads to better segmentations in less iterations.	coherence (physics);greedy algorithm;iteration;pixel;specification language	Nuno Vasconcelos;Andrew Lippman	1997		10.1109/CVPR.1997.609376	computer vision;expectation–maximization algorithm;computer science;machine learning;segmentation-based object categorization;pattern recognition;motion estimation;image segmentation;data analysis;scale-space segmentation;bayesian inference;segmentation;statistics	Vision	48.47378775726492	-52.081853391434784	33747
1fc5dad90c459d25a53d73125ea50094e28d6525	individualised model of facial age synthesis based on constrained regression	age progression;facial ageing;regression analysis face recognition feature extraction image colour analysis image representation;training;constrained regression;aging;active appearance model;active appearance model aging shape image color analysis mathematical model computational modeling training;constrained regression facial ageing age estimation age progression age synthesis;conference paper;computational modeling;face recognition;shape;image color analysis;image colour analysis;image representation;feature extraction;constrained regressor facial age synthesis constrained regression automatic facial ageing afa facial ageing system color based active appearance model facial feature extraction age estimator aam representation;age estimation;mathematical model;regression analysis;age synthesis	Faces convey much information. Interestingly we humans have a remarkable ability of identifying, extracting, and interpreting this information. Recently automatic facial ageing (AFA) has gained popularity due to its numerous applications which include search for missing people, biometrics, and multimedia. The problem of AFA is faced with various challenges, including incomplete training datasets, unrestrained environments, ethnic and gender variations to mention but a few. This work presents a new approach to automatic facial ageing which involves the development of a person specific facial ageing system. A color based Active Appearance Model (AAM) is used to extract facial features. Then, regression is used to model an age estimator. Age synthesis is achieved by computing a solution that minimises the distance from the original face with the use of constrained regression. The model is tested on a challenging database of single image per person. Initial results suggest that plausible images can be rerendered at different ages, automatically using the AAM representation. Using the constrained regressor we are guaranteed to get estimated ages that are exact for an individual at a given age.	active appearance model;alternating finite automaton;autostereogram;biometrics;database;facial recognition system;linear least squares (mathematics)	Ali Maina Bukar;Hassan Ugail;David Connah	2015	2015 International Conference on Image Processing Theory, Tools and Applications (IPTA)	10.1109/IPTA.2015.7367147	facial recognition system;computer vision;active appearance model;feature extraction;shape;computer science;artificial intelligence;pattern recognition;mathematical model;computational model;regression analysis	Vision	42.01427731178522	-53.37639322856297	33838
058d082701c8badf4ed7fddcc258dedf4012073f	keypoints from symmetries by wave propagation	wave equation detector keypoints symmetry;image structures;detectors;feature based recognition pipelines wave propagation salient symmetries wave equation heat equation gaussian scale space theory image structures;image processing;gaussian processes;boundary conditions;wave equations;detector;wave propagation feature extraction gaussian processes image processing wave equations;heating;symmetry;feature based recognition pipelines;wave equation;heat equation;gaussian scale space theory;feature extraction;mathematical model;keypoints;propagation equations mathematical model detectors heating feature extraction boundary conditions;wave propagation;propagation;salient symmetries	The paper conjectures and demonstrates that repeatable key points based on salient symmetries at different scales can be detected by a novel analysis grounded on the wave equation rather than the heat equation underlying traditional Gaussian scale-space theory. While the image structures found by most state-of-the-art detectors, such as blobs and corners, occur typically on planar highly textured surfaces, salient symmetries are widespread in diverse kinds of images, including those related to untextured objects, which are hardly dealt with by current feature-based recognition pipelines. We provide experimental results on standard datasets and also contribute with a new dataset focused on untextured objects. Based on the positive experimental results, we hope to foster further research on the promising topic of scale invariant analysis through the wave equation.	pipeline (computing);scale space;sensor;software propagation	Samuele Salti;Alessandro Lanza;Luigi di Stefano	2013	2013 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2013.373	computer vision;mathematical optimization;detector;wave equation;image processing;computer science;mathematics;geometry	Vision	40.05737094570483	-55.655588850972634	33865
5ca556fcc2fae88ebbaa9d1792db3bd804b6a9e3	an effective driver fatigue monitoring system	image recognition;fatigue;road accidents;lattices;fatigue monitoring;perclos fatigue monitoring adaboost lattice degree of nearness;perclos;monitoring system;fourier descriptors;condition monitoring;discrete fourier transform driver fatigue monitoring system adaboost classifier haar like based cascaded classifier eye region localization fourier descriptor contour feature edge feature feature extraction;machine vision;feature extraction;adaboost;pattern classification;driver circuits;robustness;fatigue face detection lattices condition monitoring feature extraction robustness flowcharts road accidents driver circuits machine vision;learning artificial intelligence;face detection;lattice degree of nearness;discrete fourier transforms;flowcharts;driver information systems;pattern classification discrete fourier transforms driver information systems feature extraction image recognition learning artificial intelligence	This paper proposes an effective driver fatigue monitoring system. A Haar-like based cascaded AdaBoost classifier is trained for eye region localization from the input drive face video; and then lattice degree of nearness based on Fourier descriptor is utilized for eye states identification; finally, PERCLOS is calculated for fatigue detection. The most prominent contribution of this paper is: instead of localizing each eye accurately, some useful contour and edge features are extracted by DFT, and lattice degree of nearness is introduced to determine eye states without difficult threshold problems in many traditional eye states algorithms. The algorithms presented in this paper are proved to be both robust and fast for driver monitoring system by a large amount of experiments.	adaboost;algorithm;experiment;haar wavelet	Shanshan Zhang;Fuqiang Liu;Zhipeng Li	2010	2010 International Conference on Machine Vision and Human-machine Interface	10.1109/MVHI.2010.153	adaboost;computer vision;face detection;flowchart;machine vision;feature extraction;computer science;machine learning;pattern recognition;lattice;robustness	Robotics	33.84547115791555	-60.57953288790686	33947
873f978d1672c433bd42b9c00abe7355512c6230	relationship between weight correlation of the convolution kernels and the optimal architecture of cnn			convolution	Qi Wang;Yonggang Lu	2018		10.3233/978-1-61499-927-0-653		AI	28.835584795777322	-57.00882406152546	33969
8f54ae9f4dd1a82c933d086661df03ab78f9b3f1	combination of multiple samples utilizing identification model in biometric systems	likelihood ratio;image matching;multilayer perceptrons;scattering;multilayer perceptron;multilayer perceptrons face recognition fingerprint identification image matching;conference paper;multilayer perceptron combination method identification model biometric system authentication matching scores biometric modalities nist bssr1 face datasets fvc2002 fingerprint datasets likelihood ratio;face recognition;fingerprint identification	In some cases, the test person might be asked to provide another authentication attempt besides the first one so that combination of the two input templates might give the system more confidence if the person is genuine or impostor. Instead of simply combining the matching scores which are associated with a single person compared to the two input templates, we investigate the use of matching scores corresponding to all enrolled persons. The dependencies between scores generated by the same input templates are accounted for the proposed combination algorithm. Such combination methods can be extended to large number of classes and input templates. Since matching scores are used, the proposed methods can also be applied on arbitrary biometric modalities. The experiments are conducted on NIST BSSR1 face and FVC2002 fingerprint datasets by using both likelihood ratio and multilayer perceptron combination methods.	algorithm;authentication;biometric device;biometrics;ct scan;experiment;fingerprint;multilayer perceptron	Xi Cheng;Sergey Tulyakov;Venu Govindaraju	2011	2011 International Joint Conference on Biometrics (IJCB)	10.1109/IJCB.2011.6117512	facial recognition system;fingerprint;speech recognition;likelihood-ratio test;computer science;machine learning;pattern recognition;scattering;multilayer perceptron	Vision	29.971886316586254	-64.01411634267275	34044
56fcecfb3a594664d30db45ae8c4b0c37c44fc5b	towards an automated framework for coronary lesions detection and quantification in cardiac ct angiography. (vers un système automatisé pour la détection et la quantification des lésions coronaires dans des angiographies ct cardiaques)		Towards an automated framework for coronary lesions detection and quantification in cardiac CT angiography Coronary heart diseases (CVDs) are the group of disorders that affect the coronary artery vessels. They are the world’s leading cause of mortality (7.3 million deaths worldwide). Therefore, early detection of these diseases using less invasive techniques provides better therapeutic outcome, as well as reduces costs and risks, compared to an interventionist approach. Recent studies showed that X-ray computed tomography (CT) may be used as an alternative to accurately locate and grade heart lesions in a non invasive way. However, analysis of cardiac CT exam for coronaries lesions inspection remains a tedious and time consuming task, as it is based on the manual analysis of the vessel cross sections. High accuracy is required, and thus only highly experienced clinicians are able to analyze and interpret the data for diagnosis. Computerized tools are critical to reduce processing time and ensure quality of diagnostics. The goal of this thesis is to provide automated coronaries analysis tools to help in non-invasive CT angiography examination. Such tools allow pathologists to efficiently diagnose and evaluate risks associated with CVDs, and to raise the quality of the assessment from a purely qualitative level to a quantitative level. The first objective of our work is to design, analyze and validate a set of automated algorithms for coronary arteries analysis with the final purpose of automated stenoses detection and quantification. We propose different algorithms covering different processing steps towards a fully automated analysis of the coronary arteries. Our contribution covers the three major blocks of the whole processing chain and deals with different image processing fields. First, we present an algorithm dedicated to heart volume extraction. The approach extracts the heart as one single object that can be used as an input masque for automated coronary arteries segmentation. This work eliminates the tedious and time consuming step of manual removing obscuring structures around the heart (lungs, ribs, sternum, liver...) and quickly provides a clear and well defined view of the coronaries. This approach uses a		Imen Melki	2015				SE	37.9650158508593	-79.99488912379954	34073
14f140c814cd95e733d0a5d65cd9533384ffee77	computer aided detection of colonic polyps via geometric feature classification				Gabriel Kiss;Johan Van Cleynenbreugel;Maarten Thomeer;Paul Suetens;Guy Marchal	2002				Vision	41.47687186089605	-71.71648687396375	34112
15079020cd1f61a6ba3ad918c97a98dba709ab30	edge detection with automatic scale selection approach to improve coherent visual attention model	edge detection;biological vision;scale selection;visual attention	An automatic scale selection approach is developed to improve the coherent visual attention model (Le Meur, O., Le Callet, P., Barba, D., Thoreau, D., 2006. A coherent computational approach to model bottom-up visual attention. IEEE Trans. Pattern Anal. Machine Intell. 28 (5), 802-817). The new approach uses linear summation to combine the automatic scale selection attention model with the coherent visual attention model. It is biologically more plausible because two important properties of human vision (i.e. edge detection and scale selection) are used. Its performance is evaluated by a large human fixation dataset. The t-test indicates that the improved model outperforms the original one highly significantly (p<0.01), and thus the new approach furnishes a more accurate model for visual attention prediction.	coherent;computation;comstock–needham system;edge detection	Jiayu Liang;Shiu Yin Yuen	2013		10.1016/j.patrec.2013.06.004	computer vision;edge detection;computer science;machine learning;pattern recognition;human visual system model	Vision	40.15989980475786	-68.04841015831079	34123
d2ab4efb39c500498f33fa61aac84a40dceb325a	outlier-resistant dissimilarity measure for feature-based image matching	voltage control;intersection matching distance image matching descriptor vector dissimilarity measure feature extraction;object recognition;descriptor vectors;dissimilarity measure;image matching;intersection matching distance;outlier resistant dissimilarity measure;feature based image matching;computational complexity;image representation;feature extraction;image registration;object recognition content based retrieval image matching image registration image representation image retrieval;voltage control image matching feature extraction image retrieval computational complexity robustness object recognition;robustness;content based image retrieval;descriptor vector;content based retrieval;descriptor vectors outlier resistant dissimilarity measure feature based image matching object recognition image registration content based image retrieval image representation;image retrieval	A novel dissimilarity measure is proposed to perform correspondence image matching for object recognition, image registration and content-based image retrieval. This is a feature-based matching, which supposes image representation (object description) in the form of a set of multi-location descriptor vectors. The proposed measure called intersection matching distance eliminates outlies (false or missing feature points) while transformation-invariantly matching two sets of descriptor vectors. A block-subdivision algorithm for time-efficient image matching is also described.	algorithm;content-based image retrieval;experiment;image registration;matching (graph theory);outline of object recognition;subdivision surface;usc interactive media & games division	Roman M. Palenichka;Ahmed Lakhssassi;Marek B. Zaremba	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.213	computer vision;feature detection;template matching;feature extraction;image retrieval;computer science;image registration;cognitive neuroscience of visual object recognition;machine learning;optimal matching;pattern recognition;mathematics;computational complexity theory;feature;robustness	Vision	40.443639477612464	-58.493675113174454	34150
4d54f4e4525e3e288f5763e984a2cbc2c1a7f362	active contours for cell tracking	minimisation;motion analysis;calculus of variations;contour updating;rolling leukocytes;animals;weak cell edges;video sequence;partial differential equation;dirichlet type boundary condition;gradient vector flow;image motion analysis;active contour;leukocyte motion analysis;snake based method;video signal processing;edge detection;video microscopy;dirichlet type boundary condition active contours cell tracking snake based method video sequence rolling leukocytes video microscopy leukocyte motion analysis inflammatory disease geometric primitive energy functional minimization calculus of variations euler equations contour updating partial differential equation pde generalized gradient vector flow gvf contrast changes weak cell edges;microscopy;geometric primitive;video sequences;active contours;pde;energy function;gradient methods diseases medical image processing tracking edge detection image sequences video signal processing microscopy image motion analysis minimisation partial differential equations;cell tracking;shape;boundary condition;partial differential equations;contrast changes;medical image processing;solid modeling;generalized gradient vector flow;euler equations;diseases;gradient methods;inflammatory disease;calculus of variation;gvf;active contours white blood cells in vivo animals shape video sequences microscopy motion analysis diseases solid modeling;energy functional minimization;in vivo;tracking;white blood cells;image sequences;euler equation	This paper introduces an active contour or snakebased method for tracking cells within a video sequence. Specifically, we apply our cell tracking techniques to rolling leukocytes observed in vivo (in living animal) from video microscopy. The analysis of leukocyte motion reveals cues about the mechanism of inflammatory disease. To attack the problem of tracking leukocytes in vivo, the proposed snake tracker utilizes shape and size information specific to the leukocytes. The principal contribution of this work lies in introducing the shape and size constraint as a geometric primitive in the parametric snake energy model. The energy functional is then minimized through the basic principles of the calculus of variations to obtain the Euler equations used in contour updating. We have developed a partial differential equation (PDE) based generalized gradient vector flow (GVF) that accommodates for contrast changes and weak cell edges. Whereas previous GVF models are sensitive to initial contour placement, the modified GVF construction with Dirichlet type boundary condition (BC) allows a snake tracker to be robust for a wide range of initial positions. Another contribution in this work is to incorporate an energy term in the snake model that eliminates the need for explicitly resampling the snake contour intermittently as performed in traditional snake evolution. Using animal experiments, we compare the accuracy of the proposed snake tracker with the correlation and centroid based tracker and show that the proposed tracker is superior in terms of increased number of frames tracked and reduced localization error.	active contour model;calculus of variations;euler;experiment;geometric primitive;gradient;resampling (statistics);video-in video-out	Nilanjan Ray;Scott T. Acton	2002		10.1109/IAI.2002.999932	computer vision;mathematical optimization;computer science;microscopy;mathematics;geometry;euler equations;partial differential equation;calculus of variations	Vision	48.03068593923078	-71.8288696373118	34156
8194da6ef956705c69c267cdeeda63154e789899	optimizing statistical character recognition using evolutionary strategies to recognize aircraft tail numbers	signal image and speech processing;tracking system;image processing;optical character recognition;quantum information technology spintronics;classification system;evolutionary strategy;guidance and control;character recognition;evolutionary computing	The design of statistical classification systems for optical character recognition (OCR) is a cumbersome task. This paper proposes a method using evolutionary strategies (ES) to evolve and upgrade the set of parameters in an OCR system. This OCR is applied to identify the tail number of aircrafts moving on the airport. The proposed approach is discussed and some results are obtained using a benchmark data set. This research demonstrates the successful application of ES to a difficult, noisy, and real-world problem.	benchmark (computing);optical character recognition;optimizing compiler;statistical classification	Antonio Berlanga;Juan A. Besada;Jesús García Herrero;José M. Molina López;Javier I. Portillo;José R. Casar	2004	EURASIP J. Adv. Sig. Proc.	10.1155/S1110865704312084	computer vision;speech recognition;tracking system;image processing;intelligent character recognition;computer science;artificial intelligence;machine learning;evolution strategy;optical character recognition;algorithm	Robotics	28.74632309174626	-66.41340689365241	34224
7f4b474a782ca0301f91dd88d6aa71d1a2a8729f	unsupervised segmentation of retinal blood vessels using a single parameter vesselness measure	vessel centerlines detection;eigenvalues and eigenfunctions;histograms;eye;image segmentation;retinal blood vessels;medical image processing biomedical measurement blood blood vessels eigenvalues and eigenfunctions eye hessian matrices image colour analysis;hessian matrix;vessel extraction;biomedical imaging;unsupervised segmentation;eigenvalues;blood vessel;eigenvalue;retinal images;scale space;retina blood vessels biomedical imaging image segmentation matched filters pixel eigenvalues and eigenfunctions image analysis retinopathy diabetes;hessian matrix biomedical image processing retinal images vessel extraction scale space;colour fundus images unsupervised segmentation retinal blood vessels single parameter vesselness measurement hessian matrix eigenvalue vessel centerlines detection eigenvectors;image colour analysis;retina;colour fundus images;medical image processing;blood;pixel;biomedical image processing;single parameter vesselness measurement;retinal imaging;biomedical measurement;blood vessels;eigenvectors;hessian matrices	In this paper, a novel vesselness measure based on analysis of the Hessian matrix is presented. The larger eigenvalue of the Hessian matrix is used for vessel centerlines detection, while vessel orientations are estimated from the eigenvectors corresponding to the smaller eigenvalue. The vesselness measure combines information from vessel centerlines and orientations over scales to segment retinal blood vessels from colour fundus images. A publicly available dataset is used to evaluate the performance of our proposed method which has the advantage of being unsupervised and of using only one parameter.	film-type patterned retarder;hessian;unsupervised learning;vii	Nancy M. Salem;Asoke K. Nandi	2008	2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing	10.1109/ICVGIP.2008.34	computer vision;mathematics;optics;computer graphics (images)	Vision	40.19041084944641	-75.56794893675412	34268
04d8f9184c1473cfd2757896d1eff93c303bb4b0	sugar: a framework to support mammogram diagnosis	patient diagnosis;stress;itemsets;patient diagnosis feature extraction mammography medical image processing;discretization;automatic extraction;biomedical imaging;association rules;data mining;association rules data mining biomedical imaging medical diagnostic imaging itemsets feature extraction decision making image analysis computer science stress;mammogram abnormalities;association rule;feature extraction;medical image processing;image analysis;feature selection;computer science;sugar;mammography;mining complexity sugar association rules mammogram abnormalities automatic extraction discretization;high sensitivity;mining complexity;medical diagnostic imaging	In this paper we present a framework based on association-rules to help diagnosis of mammogram abnormalities. Our framework - SuGAR - combines low-level features automatically extracted from images with high-level knowledge gotten from specialists to mine association rules, suggesting possible diagnoses. Our framework is optimized, in the sense that it combines, in a single step, feature selection and discretization, reducing the mining complexity. The framework was applied to real datasets and the results show high sensitivity (up to 95%) and accuracy (up to 92%), allowing us to claim that association rules can effectively aid in the diagnosing task.	algorithm;association rule learning;discretization;feature extraction;feature selection;high- and low-level;standard test image;sugar	Marcela Xavier Ribeiro;Agma J. M. Traina;André G. R. Balan;Caetano Traina;Paulo Mazzoncini de Azevedo Marques	2007	Twentieth IEEE International Symposium on Computer-Based Medical Systems (CBMS'07)	10.1109/CBMS.2007.101	medical imaging;image analysis;association rule learning;computer science;machine learning;pattern recognition;data mining;feature selection	Robotics	34.872635047563264	-73.72511079743785	34276
c6c755388cad6104424b979ca618e40977da69f3	nonlinear fusion of multispectral citrus fruit image data with information contents	multiscale decomposition;image fusion;wavelet transform;clustering;entropy filter	The main issue of vison-based automatic harvesting manipulators is the difficulty in the correct fruit identification in the images under natural lighting conditions. Mostly, the solution has been based on a linear combination of color components in the multispectral images. However, the results have not reached a satisfactory level. To overcome this issue, this paper proposes a robust nonlinear fusion method to augment the original color image with the synchronized near infrared image. The two images are fused with Daubechies wavelet transform (DWT) in a multiscale decomposition approach. With DWT, the background noises are reduced and the necessary image features are enhanced by fusing the color contrast of the color components and the homogeneity of the near infrared (NIR) component. The resulting fused color image is classified with a C-means algorithm for reconstruction. The performance of the proposed approach is evaluated with the statistical F measure in comparison to some existing methods using linear combinations of color components. The results show that the fusion of information in different spectral components has the advantage of enhancing the image quality, therefore improving the classification accuracy in citrus fruit identification in natural lighting conditions.	algorithm;citrus plant;classification;coefficient;color image;daubechies wavelet;discrete wavelet transform;f1 score;image quality;machine vision;multispectral image;nonlinear system;spectroscopy, near-infrared;contents - htmllinktype	Peilin Li;Sang-Heon Lee;Hung-Yao Hsu;Jae-Sam Park	2017		10.3390/s17010142	computer vision;speech recognition;computer science;engineering;pattern recognition;cluster analysis;image fusion;wavelet transform	Vision	41.02173821284646	-66.49577836565427	34277
79ba7123120e0a46244a592a9d5b596a398df0e8	holographic image representations: the fourier transform method	analisis imagen;image processing;fourier transform;holografia optica;image communication;procesamiento imagen;optical holography;traitement image;reconstruction image;reconstruccion imagen;fourier transformation;image representation;image reconstruction;transformation fourier;image analysis;holographie optique;analyse image;transformacion fourier	We discuss holographic image representations. Arbitrary portions of a holographic representation enable reconstruction of the whole image, with distortions that decrease gradually with the increase of the size of the portions available. Holographic representations enable progressive refinement in image communication or retrieval tasks, with no restrictions on the order in which the data fragments (sections of the representation) are accessed or become available.		Alfred M. Bruckstein;Robert J. Holt;Arun N. Netravali	1997		10.1007/3-540-63508-4_102	fourier transform;computer vision;image analysis;image processing;computer science;mathematics;geometry;computer graphics (images)	Vision	51.58707736843188	-62.21760191511946	34302
148ee82e72b82341bc6b6c13ea05c36646d4d01b	real-time non-local means image denoising algorithm based on local binary descriptor	non local means;local binary descriptor;image denoising;real time image processing	In this paper, a speed-up technique for the non-local means (NLM) image denoising method based on local binary descriptor (LBD) is proposed. In the NLM, most of the computation time is spent on searching for non-local similar patches in the search window. The local binary descriptor which represents the structure of patch as binary strings is employed to speed up the search process in the NLM. The descriptor allows for a fast and accurate preselection of non-local similar patches by bitwise operations. Using this approach, a tradeoff between time-saving and noise removal can be obtained. Simulations exhibit that despite being principally constructed for speed, the proposed algorithm outperforms in terms of denoising quality as well. Furthermore, a parallel implementation on GPU brings NLM-LBD to real-time image denoising.	algorithm;noise reduction;non-local means;real-time clock	Hancheng Yu;Aiting Li	2016	TIIS	10.3837/tiis.2016.02.021	computer vision;mathematical optimization;local binary patterns;machine learning;non-local means	Vision	52.9464895346499	-64.95070431184423	34315
03f955d81a5b25fd361909928bc35719e2bd5ed1	a shock grammar for recognition	databases;detectors;object recognition;two dimensional shape;computer vision object recognition;electric shock;occlusion;reaction diffusion space;shocks;reaction diffusion;occlusion shock grammar recognition two dimensional shape shocks singularities subpixel local detectors geometric constraints global consistency reaction diffusion space scale changes;low resolution;shock grammar;satisfiability;skeleton;computer vision;stability;engine cylinders;recognition;birds;shape;subpixel local detectors;singularities;scale changes;humans;global consistency;electric shock shape detectors stability databases humans birds proposals engine cylinders skeleton;geometric constraints;proposals	We confront the theoretical and practical difficulties of computing a representation for two-dimensional shape, based on shocks or singularities that arise as the shape’s boundary is deformed. First, we develop subpixel local detectors for finding and classifying shocks. Second, we show that shock patterns are not arbitrary but obey the rules of a grammar, and in addition satisfy specific topological and geometric constraints. Shock hypotheses that violate the grammar or are topologically or geometrically invalid are pruned to enforce global consistency. Survivors are organized into a hierarchical graph of shock groups computed in the reaction-diffusion space, where diffusion plays a role of regularization to determine the significance of each shock group. The shock groups can be functionally related to the object’s parts, protrusions and bends, and the representation is suited to recognition: several examples illustrate its stability with rotations, scale changes, occlusion and movement of parts, even at very low resolutions.	pixel;sensor;yahoo! groups	Kaleem Siddiqi;Benjamin B. Kimia	1996		10.1109/CVPR.1996.517119	gravitational singularity;computer vision;detector;image resolution;stability;shape;computer science;cognitive neuroscience of visual object recognition;machine learning;mathematics;geometry;skeleton;reaction–diffusion system;satisfiability	Vision	46.633823996136584	-52.89819483319043	34337
792ff721af56bbfc7beddb2e7c1ceffc4a11d69a	landmark and intensity-based, consistent thin-plate spline image registration	intensidad;marking;spline;medical imagery;image numerique;systeme nerveux central;esplin;estudio comparativo;shape analysis;hombre;encefalo;anatomia;algorithme;etude comparative;algorithm;sistema nervioso central;medical image;encephale;marcacion;image registration;enregistrement donnee;registro datos;imagen numerica;human;comparative study;tecnica;imagineria medica;imagerie medicale;reperage;transformation inverse;evaluation;digital image;evaluacion;data logging;inverse transformation;anatomie;anatomy;thin plate spline;technique;central nervous system;intensity;intensite;homme;transformacion inversa;algoritmo;brain vertebrata	Landmark-based thin-plate spline image registration is one of the most commonly used methods for non-rigid medical image registration and anatomical shape analysis. It is well known that this method does not produce a unique correspondence between two images away from the landmark locations because interchanging the role of source and target landmarks does not produce forward and reverse transformations that are inverses of each other. In this paper, we present two new image registration algorithms that minimize the thin-plate spline bending energy and the inverse consistency error—the error between the forward and the inverse of the reverse transformation. The landmarkbased consistent thin-plate spline algorithm registers images given a set of corresponding landmarks while the intensity-based consistent thinplate spline algorithm uses both corresponding landmarks and image intensities. Results are presented that demonstrate that using landmark and intensity information to jointly estimate the forward and reverse transformations provides better correspondence than using landmarks or intensity alone.	algorithm;fiducial marker;image registration;jacobian matrix and determinant;mean squared error;medical imaging;thin plate spline	Hans J. Johnson;Gary E. Christensen	2001		10.1007/3-540-45729-1_33	spline;computer vision;computer science;image registration;central nervous system;evaluation;comparative research;data logger;shape analysis;intensity;thin plate spline;digital image	Vision	45.82147394009671	-79.56841759343828	34367
6c61a4dbd1359063ba009731fd19c43c75bb89ab	automatic segmentation of prostate zones		Convolutional networks have become state-of-the-art techniques for automatic medical image analysis, with the U-net architecture [1] being the most popular at this moment. In this article we report the application of a 3D version of U-net [2] to the automatic segmentation of prostate peripheral and transition zones in 3D MRI images. Our results are slightly better than recent studies that used 2D U-net [3] and handcrafted feature [4] approaches. In addition, we test ideas for improving the 3D U-net setup, by 1) letting the network segment surrounding tissues, making use of the fixed anatomy, and 2) adjusting the network architecture to reflect the anisotropy in the dimensions of the MRI image volumes. While the latter adjustment gave a marginal improvement, the former adjustment showed a significant deterioration of the network performance. We were able to explain this deterioration by inspecting feature map activations in all layers of the network. We show that to segment more tissues the network replaces feature maps that were dedicated to detecting prostate peripheral zones, by feature maps detecting the surrounding tissues.	image analysis;map;marginal model;medical image computing;medical imaging;network architecture;network performance;network segment;peripheral;sensor	Germonda Mooij;Ines Bagulho;Henkjan Huisman	2018	CoRR		peripheral;architecture;pattern recognition;network architecture;network segment;artificial intelligence;segmentation;network performance;computer science	ML	30.422789763763276	-75.70096163052544	34426
b7c976aaea191a5ead61c9ccd1b615a95324e062	binocular robot vision system with autonomous movement of viewpoint	systeme intelligent;vision robot;sistema activo;vision estereoscopica;autonomous system;edge detection;profil raie;sistema inteligente;vision stereoscopique;line detection;transformacion hough;systeme actif;sistema autonomo;active system;deteccion contorno;detection contour;robot vision;binocular vision;line shape;retina;systeme autonome;intelligent system;pattern recognition;hough transforms;hough transformation;hough transform;transformation hough;vision binocular;reconnaissance forme;reconocimiento patron;stereopsis;perfil raya espectral;vision binoculaire	A binocular robot vision system having an autonomously moving active viewpoint is proposed. By using this active viewpoint, the system constructs a correspondence between the images of a feature points on the right and left retinas easily and calculates the spatial coordinates of the feature points. The system incorporates two intelligent functions for enlarging the measuring region and increasing the accuracy of measurement. The first intelligent function is an autonomous movement of the viewpoint and the second is weighting process for measured points. These functions work when the system can recognize the solid body. As the first steps of the development of the recognition of a solid body, we incorporate these functions into the system to detect straight lines in an image. To detect lines we use Hough transform. The system searches a region surrounded by 4 straight lines. Then the system recognizes the region as a quadrangle. The system constructs a correspondence between the quadrangles in the right and left images. By the use of the result of the constructed correspondence, the system calculates the spatial coordinates of an object. An experiment shows the effect of the line detection using Hough transform, the recognition of the surface of the object and the calculation of the spatial coordinates of the object.	autonomous robot;binocular vision	Yoshito Yabuta;Hiroshi Mizumoto;Shiro Arii	2004		10.1117/12.526598	computer vision;geography;cartography;computer graphics (images)	Robotics	48.59024719046419	-58.673843488449236	34444
95f3d9bec2d4bf857d2acd7ea2927683ecc6b363	data augmentation and directional feature maps extraction for in-air handwritten chinese character recognition based on convolutional neural network		Abstract Recently convolutional neural networks (CNN) have demonstrated remarkable performance in various classification problems. In this paper, we also introduce CNN into in-air handwritten Chinese character recognition (IAHCCR) and propose new directional feature maps, named bend directional feature maps. Then we integrate the combination of various types of directional feature maps with the CNN and obtain better recognition performance compared with other methods reported for IAHCCR. For further improving recognition rate, we propose a new data augmentation method dedicated to in-air handwritten Chinese characters. The proposed data augmentation method combines global transformation with local distortion and effectively enlarges the training dataset. Experimental results demonstrate that our proposed methods can greatly improve the recognition rate for IAHCCR.	artificial neural network;convolutional neural network;map;optical character recognition	Xiwen Qu;Weiqiang Wang;Ke Lu;Jianshe Zhou	2018	Pattern Recognition Letters	10.1016/j.patrec.2018.04.001	artificial intelligence;convolutional neural network;pattern recognition;mathematics;distortion	Vision	29.42648297100436	-55.64777388555603	34470
8546885e83f7901340c7893fdfc017cef86d910a	convolutional long short-term memory networks for recognizing first person interactions		In this paper, we present a novel deep learning based approach for addressing the problem of interaction recognition from a first person perspective. The proposed approach uses a pair of convolutional neural networks, whose parameters are shared, for extracting frame level features from successive frames of the video. The frame level features are then aggregated using a convolutional long shortterm memory. The hidden state of the convolutional long short-term memory, after all the input video frames are processed, is used for classification in to the respective categories. The two branches of the convolutional neural network perform feature encoding on a short time interval whereas the convolutional long short term memory encodes the changes on a longer temporal duration. In our network the spatio-temporal structure of the input is preserved till the very final processing stage. Experimental results show that our method outperforms the state of the art on most recent first person interactions datasets that involve complex ego-motion. In particular, on UTKinect-FirstPerson it competes with methods that use depth image and skeletal joints information along with RGB images, while it surpasses all previous methods that use only RGB images by more than 20% in recognition accuracy.	artificial neural network;channel (digital image);convolutional neural network;deep learning;first-person (video games);image processing;interaction;long short-term memory;network architecture;neuroepistemology;raw image format	Swathikiran Sudhakaran;Oswald Lanz	2017	2017 IEEE International Conference on Computer Vision Workshops (ICCVW)	10.1109/ICCVW.2017.276	artificial intelligence;machine learning;long short term memory;convolutional neural network;pattern recognition;computer science;encoding (memory);feature extraction;deep learning;rgb color model;logic gate;convolution	Vision	27.70805435467887	-52.304942784570144	34526
9e56e56778b9cd01a873e84f5481945d1a61ffe1	modeling white-matter fiber-orientation uncertainty for improved probabilistic tractography		Tractography uses fiber-orientation estimates to trace the likely paths of white-matter tracts through the brain, in order to map brain connectivity non-invasively. In this paper, we propose a novel probabilistic framework for modeling fiber-orientation uncertainty and improve probabilistic tractography. The main innovation in the present formulation consists in coupling a particle filtering process with a clustered-mixture model approach to model directional data. Mixtures of von Mises-Fisher (vMF) distributions are used to support the probabilistic estimation of intravoxel fiber directions. The fitted parameters of the clustered vMF mixture at each voxel are then used to estimate white-matter pathways using particle filtering techniques. The technique is validated on simulated as well as on real human brain data experiments.	adobe streamline;algorithm;coupling (computer programming);directional statistics;emoticon;experiment;fiber to the x;gfa basic;mixture model;particle filter;video-in video-out;voxel	Adelino R. Ferreira da Silva	2014		10.5220/0005069300710078	computer science;artificial intelligence;machine learning;statistics	Vision	48.286076898373906	-79.61168279992961	34646
b3b7f9da71d42d3652503c4469c189e390a15cdb	degraded document image enhancement using hybrid thresholding and mathematical morphology	stopping criteria;histograms;mathematical morphology;image enhancement document image processing;image segmentation;hybrid thresholding;degraded document image enhancement;gray level histogram degraded document image enhancement hybrid thresholding mathematical morphology digitized degraded documents iterative global thresholding;image enhancement;smoothing methods;filtering algorithms;pixel;gray level histogram;document image processing;ink;digitized degraded documents;character recognition;iterative global thresholding;degradation image enhancement morphology iterative algorithms paper technology histograms pixel computer science character recognition ink;noise	The paper presents a hybrid thresholding approach for binarization and enhancement of degraded documents. Historical documents contain information of great cultural and scientific value. But such documents are frequently degraded over time. Digitized degraded documents require specialized processing to remove different kinds of noise and to improve readability. The approach for enhancing degraded documents uses a combination of two thresholding algorithms. First, iterative global thresholding is applied to the smoothed degraded image until the stopping criteria is reached. Then a threshold selection method from gray level histogram is used to binarize the image. The next step is detecting areas where noise still remains and applying iterative thresholding locally. A method to improve the quality of textual information in the document is also done as a post processing stage, thus making the approach efficient and better suited for character recognition applications.	algorithm;grayscale;historical document;image editing;iterative method;mathematical morphology;optical character recognition;selection (genetic algorithm);sensor;smoothing;thresholding (image processing)	Nija Babu;N. G. Preethi;S. S. Shylaja	2008	2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing	10.1109/ICVGIP.2008.55	computer vision;speech recognition;computer science;pattern recognition;balanced histogram thresholding	Vision	38.50785088470122	-66.68774040457106	34694
256781c6ef6141858ad02a91cd6fd98dca4936eb	inferring region salience from binary and gray-level images	perceptual grouping;region of interest;pattern recognition	We introduce a method that uses contour fragments to highlight regions of interest. Our method obtains as input either a binary image or the gradient map of a gray-level image. It produces a saliency map that re0ects for every point in the image our belief that it belongs to a salient region. Saliency is determined by criteria such as closure, convexity, and size. In addition, gaps in the boundaries of regions diminish their saliency. Explicit scale parameter determines the size of interest. The method is implemented by a convolution of the input edge image with a linear 6lter that speci6es the region of in0uence of a contour point over the image. Experiments demonstrate the utility of the method for saliency and segmentation. ? 2003 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	binary image;bitwise operation;convex function;convolution;exptime;emoticon;experiment;grayscale;image gradient;image segmentation;pattern recognition;region of interest;xslt/muenchian grouping	Yossi Cohen;Ronen Basri	2003	Pattern Recognition	10.1016/S0031-3203(03)00120-1	computer vision;computer science;machine learning;pattern recognition;mathematics;region of interest	Vision	45.657234093061106	-67.49729417190467	34700
ac676a90d68ab78574cf91b356035dd822457974	"""fingerprint singular points detection and direction estimation with a """"t"""" shape model"""	modelizacion;alignement;metodo adaptativo;model based reasoning;raisonnement base sur modele;base donnee;point estimation;image processing;biometrie;biometrics;database;biometria;procesamiento imagen;base dato;methode adaptative;classification;traitement image;modelisation;empreinte digitale;estimation ponctuelle;dactyloscopie;adaptive method;alineamiento;punto singular;fingerprint;huella digital;shape modeling;estimacion puntual;modeling;clasificacion;point singulier;alignment;fingerprint identification;singular point	As a sort of evident landmark features of fingerprints, singular points (SPs) play important roles in fingerprint alignment, classification and recognition. We present an adaptive “T” shape model of SPs and develop a robust and generic approach to detect SPs and their directions simultaneously. The proposed approach utilizes homocentric sectors around candidate SPs to pick out lateral-axes and further main-axes based on the proposed model. The results of the experiment conducted on a public database, FVC 2002, demonstrate the effectiveness of the method in this paper.	fingerprint	Pengwei Hao;Chao Zhang	2005		10.1007/11527923_21	fingerprint;computer vision;image processing;computer science;artificial intelligence;database	Vision	45.618273652135535	-59.53516935698756	34705
3a4332870a04fcea80dfb7af0b75148e11719963	a learning based deformable template matching method for automatic rib centerline extraction and labeling in ct images	rib cage;computed tomography;mrf;image matching;bottom up learning based detection;acm;object detection computerised tomography image matching learning artificial intelligence markov processes medical image processing;global shape constraints;clinical applications;learning based deformable template matching method;markov random field based articulated rigid transformation method;chest ct scans;shape;feature extraction;medical image processing;computerised tomography;active contour model deformation;rib pairing;ribs;ct image labeling;robustness;rib seed point detection;markov processes;learning artificial intelligence;pathology;labeling;object detection;automatic rib centerline extraction;rib cage learning based deformable template matching method automatic rib centerline extraction ct image labeling clinical applications rib seed point detection chest ct scans bottom up learning based detection global shape constraints mrf markov random field based articulated rigid transformation method active contour model deformation acm rib pairing;ribs labeling robustness computed tomography shape pathology feature extraction	The automatic extraction and labeling of the rib centerlines is a useful yet challenging task in many clinical applications. In this paper, we propose a new approach integrating rib seed point detection and template matching to detect and identify each rib in chest CT scans. The bottom-up learning based detection exploits local image cues and top-down deformable template matching imposes global shape constraints. To adapt to the shape deformation of different rib cages whereas maintain high computational efficiency, we employ a Markov Random Field (MRF) based articulated rigid transformation method followed by Active Contour Model (ACM) deformation. Compared with traditional methods that each rib is individually detected, traced and labeled, the new approach is not only much more robust due to prior shape constraints of the whole rib cage, but removes tedious post-processing such as rib pairing and ordering steps because each rib is automatically labeled during the template matching. For experimental validation, we create an annotated database of 112 challenging volumes with ribs of various sizes, shapes, and pathologies such as metastases and fractures. The proposed approach shows orders of magnitude higher detection and labeling accuracy than state-of-the-art solutions and runs about 40 seconds for a complete rib cage on the average.	active contour model;algorithm;ct scan;contour line;householder transformation;image noise;markov chain;markov random field;speedup;supervised learning;template matching;top-down and bottom-up design;tracing (software);video post-processing	Dijia Wu;David Liu;Zoltan Puskas;Chao Lu;Andreas Wimmer;Christian Tietjen;Grzegorz Soza;Shaohua Kevin Zhou	2012	2012 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2012.6247774	computer vision;computer science;pattern recognition;computed tomography;rib cage	Vision	41.119275304032506	-76.86859821199094	34749
2a6b5b8afee8289e454db9447fdaebc1282c1fea	automatic face recognition and identification tools in the forensic science domain		This paper describes an experimental work executed by Carabinieri Forensic Investigation Department (Italy) to explore the performance of the auto‐ matic face recognition systems in forensic domain. The main goal of the research is to survey the recognition ability and identification performance of these tools. The experiments are carried out using three commercial automatic facial recog‐ nition platforms. In our work we compare the difference between the forensic experts’ way of manual facial comparison with the machine outcome in two different scenarios; the first is a training and certification environment, a facial image comparisons proficiency test to verify the recognition capabilities. The second is a daily forensic caseworks scenario, formed by 130 real cases success‐ fully investigated by forensic experts, to analyze the identification achievement.	experiment;facial recognition system	Angelo Salici;Claudio Ciampini	2017		10.1007/978-3-319-67639-5_2	forensic science;data mining;certification;facial recognition system;speech recognition;computer science	AI	28.805321190012858	-63.185887835968366	34767
1a7b39e41d1ceafa824928bcf65b63b0d7b93472	video summarization by video structure analysis and graph optimization	video signal processing;scene skimming concatenation;content entropy;video summarization;graph optimization;detected video scene classification;video structure analysis;scene skimming length;classification;dynamic programming;abstracting;entropy;spatial-temporal dissimilarity function;video scene boundary detection;layout;structure analysis;tree data structures;computer science	We propose a novel video summarization method that combines video structure analysis and graph optimization. First, we analyze the structure of the video, find the boundaries of video scenes, then we calculate each scene's skimming length based on its structure and content entropy. Second, we define a spatial-temporal dissimilarity function between video shots and model each video scene as a graph, then find each scene's optimal skimming in the graph with dynamic programming. Finally, the whole video's skimming is obtained by concatenating the skimmings of the scenes. Experimental results show that our approach preserves the scene level structure and ensures balanced coverage of the major contents of the original video.	concatenation;dynamic programming;level structure;mathematical optimization	Shi Lu;Irwin King;Michael R. Lyu	2004	2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)		video compression picture types;computer vision;entropy;image analysis;systems modeling;content analysis;image processing;biological classification;computer science;theoretical computer science;document structure description;dynamic programming;video tracking;block-matching algorithm;structural analysis;multimedia;video post-processing	Vision	38.86994689968394	-52.43064992889809	34785
1118ebd36ccfe3f5c1ac433eef64c3d09ad262df	mra image segmentation with capillary active contour	active contour;image segmentation;computer aided diagnosis;level set;blood vessel;three dimensional;magnetic res onance	Precise segmentation of three-dimensional (3D) magnetic resonance angiography (MRA) image can be a very useful computer aided diagnosis (CAD) tool in clinical routines. Our objective is to develop a specific segmentation scheme for accurately extracting vasculature from MRA images. Our proposed algorithm, called the capillary active contour (CAC), models capillary action where liquid can climb along the boundaries of thin tubes. The CAC, which is implemented based on level sets, is able to segment thin vessels and has been applied for verification on synthetic volumetric images and real 3D MRA images. Compared with other state-of-the-art MRA segmentation algorithms, our experiments show that the introduced capillary force can facilitate more accurate segmentation of blood vessels.	active contour model;anatomy, regional;blood vessel;blood capillaries;blood supply aspects;capillary action;common access card;computer-aided design;contour line;experiment;image segmentation;magnetic resonance angiography;segmentation action;specimen source codes - tube;synthetic intelligence;verification of theories;algorithm;angiogram;biologic segmentation	Pingkun Yan;Ashraf A. Kassim	2005	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/11566465_7	three-dimensional space;computer vision;radiology;computer science;level set;active contour model;mathematics;image segmentation;scale-space segmentation;computer graphics (images)	Vision	39.63581661195322	-79.99502463682691	34902
ae44846606b8c5a03f69819543e8ec86d40be53f	sparse patch-based label fusion for multi-atlas segmentation	conventional label fusion method;graph structure;appropriate graph;atlas image;input image;existing label fusion method;multi-atlas segmentation;graph adjacency structure;patch-based label fusion method;sparse patch-based label fusion;fixed image neighborhood	Patch-based label fusion methods have shown great potential in multi-atlas segmentation. It is crucial for patch-based labeling methods to determine appropriate graphs and corresponding weights to better link patches in the input image with those in atlas images. Currently, two independent steps are performed, i.e., first constructing graphs based on the fixed image neighborhood and then computing weights based on the heat kernel for all patches in the neighborhood. In this paper, we first show that many existing label fusion methods can be unified into a graph-based framework, and then propose a novel method for simultaneously deriving both graph adjacency structure and graph weights based on the sparse representation, to perform multi-atlas segmentation. Our motivation is that each patch in the input image can be reconstructed by the sparse linear superposition of patches in the atlas images, and the reconstruction coefficients can be used to deduce both graph structure and weights simultaneously. Experimental results on segmenting brain anatomical structures from magnetic resonance images (MRI) show that our proposed method achieves significant improvements over previous patch-based methods, as well as other conventional label fusion methods.	coefficient;experiment;graph (discrete mathematics);ieee 802.1aq;mathematical optimization;netpbm format;oracle fusion middleware;patch (computing);resonance;sparse approximation;sparse matrix;superposition principle	Daoqiang Zhang;Qimiao Guo;Guorong Wu;Dinggang Shen	2012		10.1007/978-3-642-33530-3_8	computer vision;machine learning;pattern recognition;mathematics	Vision	47.18759349113666	-70.62551514999788	34950
44f152d0465b27ef7a4c76abaab0986120b466d2	perception-based image segmentation using the bounded irregular pyramid	bottom up;image segmentation;natural images;ground truth;quantitative evaluation	This paper presents a bottom-up approach for fast segmentation of natural images. This approach has two main stages: firstly, it detects the homogeneous regions of the input image using a colour-based distance and then, it merges these regions using a more complex distance. Basically, this distance complements a contrast measure defined between regions with internal region descriptors and with attributes of the shared boundary. These two stages are performed over the same hierarchical framework: the Bounded Irregular Pyramid (BIP). The performance of the proposed algorithm has been quantitatively evaluated with respect to ground-truth segmentation data.	image segmentation	Rebeca Marfil;Antonio Bandera;Francisco Sandoval Hernández	2007		10.1007/978-3-540-74936-3_25	computer vision;range segmentation;machine learning;segmentation-based object categorization;pattern recognition;mathematics;image segmentation;scale-space segmentation	Vision	45.59664330136371	-68.60837062748095	34952
e23b6f5fcf3b569b5dd35a9b582c0e48b0da2f6a	adaptable ring for vision-based measurements and shape analysis	databases;drugs;shape shape measurement databases image color analysis drugs image resolution;image resolution;shape measurement vision based measurement shape detection pharmaceutical pill shapes superimposed adaptable ring automatic optical inspection;shape measurement;shape;image color analysis;vision based measurement vbm automatic optical inspection image shape analysis shape measurement;shape measurement automatic optical inspection	A vision-based measurement approach for pill shape detection is presented along with other applications. Rapid and accurate pill identification is needed by medical and law enforcement personnel during emergencies. But real-world pill identification is challenging due to varied lighting conditions, minor manufacturing defects, and subsequent pill wear. Surmounting these challenges is possible using multiple inputs: pill color, imprint, and shape. Of these different inputs, pill shape is the most important and difficult parameter due to its variations. In this paper, we describe a novel technique to accurately detect the complex pharmaceutical pill shapes using measurements derived from a superimposed adaptable ring centered automatically on either the shape’s centroid or its bounding box midpoint determined based on the measurements from two other rings, namely the inner ring and the outer ring. It is shown that the measurements from the overlays of the adaptable ring suffice to successfully classify the shapes of the pills currently in the Pillbox database (U.S. National Library of Medicine, 2014) with an accuracy of 98.7%. Our method demonstrated higher accuracy when compared with Hu-moments on the same data set. Using logistic regression techniques, Hu-moments provided an accuracy of 96.6%. Though developed for the domain of pharmaceutical pill shapes, we discuss how the measurements from the adaptable ring can also be used in other industrial applications to increase the level of accuracy with the help of this real-time less computationally complex method.	color;holographic principle;image moment;logistic regression;minimum bounding box;real-time clock;sensor;shape analysis (digital geometry)	Kanakam Teja Maddala;Randy H. Moss;William V. Stoecker;Jason R. Hagerty;Justin G. Cole;Nabin K. Mishra;R. Joe Stanley	2017	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2017.2650738	computer vision;image resolution;shape;computer science;engineering;mathematics;optics;engineering drawing	Visualization	36.56788918639199	-72.28129512451383	34975
16af0f145334cbec86e7e35a57943f4396c73b49	the development of a multi-stage learning scheme using new tissue descriptors for automatic grading of prostatic carcinoma	wavelet transforms biological organs biomedical optical imaging cancer image classification image colour analysis learning artificial intelligence medical image processing sensitivity tumours;quaternion features;automated gleason grading;quaternion features automated gleason grading multi classifier systems histopathology image analysis;multi classifier systems;sensitivity multistage learning scheme development tissue descriptors automatic grading prostatic carcinoma automated classification hypercomplex wavelet analysis quaternion color ratios modified local binary patterns multiclass classifiers binary classifiers hold out cross validation prostate cancer biopsy images dataset gleason grades image classification;quaternions image color analysis prostate cancer vectors fractals feature extraction support vector machines;histopathology image analysis	This paper introduces a new system for the automated classification of prostatic carcinomas from biopsy images. The important components of the proposed system are (1) the new features for tissue description based on hyper-complex wavelet analysis, quaternion color ratios, and modified local binary patterns; and (2) a new framework for multi-stage learning that integrates both multi-class and binary classifiers. The system performance is estimated by employing Hold-out cross-validation in a dataset of 71 prostate cancer biopsy images with different Gleason grades. Simulation results show that the presented technique is able to correctly classify images in 98.89% of the test cases. Furthermore, the system is robust in terms of sensitivity (0.9833) and specificity (0.9917). We have demonstrated the efficacy of our system in distinguishing between Gleason grades 3, 4 and 5.	cross-validation (statistics);gleason's theorem;local binary patterns;sensitivity and specificity;simulation;test case;wavelet	Clara Mosquera Lopez;Sos S. Agaian;Alejandro Velez-Hoyos	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6854269	computer vision;machine learning;pattern recognition;mathematics	Robotics	34.77125246346511	-75.38138122900197	34986
010d127b38a479156d65d23a9c112619f85857b3	level set-based ct liver image segmentation with watershed and artificial neural networks	decision support systems hybrid intelligent systems silicon manganese;liver;neural nets;image classification;matrix algebra;neural network classification level set based ct liver image segmentation artificial neural networks regions of interest rol watershed approach first order statistics grey level cooccurrence matrix infected region classification neural network training contrast enhancement noise removal;image enhancement;medical image processing;computerised tomography;statistics;segmentation level set watershed algorithm filtering;image denoising;learning artificial intelligence;statistics computerised tomography image classification image denoising image enhancement learning artificial intelligence liver matrix algebra medical image processing neural nets	The objective of this paper is to evaluate a new combined approach intended for reliable CT liver image segmentation, to separate the liver from other organs, and segment the liver into a set of regions of interest (ROIs). The approach combines the level set with watershed approach used as post segmentation step to produce a reliable segmentation result. Features of first order statistics and grey-level cooccurrence matrix, are calculated and passed to an artificial neural network, to be trained and to classify infected regions. Filtering is used before the segmentation approach to enhance contrast, remove noise and emphasize certain features, as well as connecting ribs around the liver. To evaluate the performance of presented approach, we performed many tests on different CT liver images. The experimental results obtained, show that the overall accuracy offered by the proposed approach is 92.1% in segmenting CT liver images into set of regions even with noise, and 88.9% average accuracy for neural network classification.	artificial neural network;image segmentation;region of interest;watershed (image processing)	Abdalla Zidan;Neveen I. Ghali;Aboul Ella Hassanien;Hesham A. Hefny	2012	2012 12th International Conference on Hybrid Intelligent Systems (HIS)	10.1109/HIS.2012.6421316	image texture;computer vision;computer science;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation	Robotics	38.12978163242461	-75.46017712543419	34993
c6dd3e0c25da0f244896ff54476d05c29697e15f	image thresholding using type ii fuzzy sets	fuzzy set;image processing;measures of fuzziness;fuzzy set theory;fuzzy sets;type ii fuzzy sets;image thresholding;ultrafuzziness	Image thresholding is a necessary task in some image processing applications. However, due to disturbing factors, e.g. non-uniform illumination, or inherent image vagueness, the result of image thresholding is not always satisfactory. In recent years, various researchers have introduced new thresholding techniques based on fuzzy set theory to overcome this problem. Regarding images as fuzzy sets (or subsets), different fuzzy thresholding techniques have been developed to remove the grayness ambiguity/vagueness during the task of threshold selection. In this paper, a new thresholding technique is introduced which processes thresholds as type II fuzzy sets. A new measure of ultrafuzziness is also introduced and experimental results using laser cladding images are provided. 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	cladding (fiber optics);fuzzy set;image processing;pattern recognition;set theory;thresholding (image processing);vagueness	Hamid R. Tizhoosh	2005	Pattern Recognition	10.1016/j.patcog.2005.02.014	computer vision;discrete mathematics;membership function;defuzzification;image processing;fuzzy classification;computer science;fuzzy number;pattern recognition;balanced histogram thresholding;mathematics;thresholding;fuzzy set;fuzzy set operations	AI	41.45701499883915	-67.35416301820231	35052
339a0d2028dd9aa6701708904d8ce8cd8d535dfc	content based image retrieval using local feature descriptors on hadoop for indoor navigation		This paper demonstrates Content Based Image Retrieval (CBIR) algorithms implementation on a huge image set. Such implementation will be used to match query images to previously stored geotagged image database for the purpose of vision based indoor navigation. Feature extraction and matching are demonstrated using the two famous key-point detection CBIR algorithms: Scale Invariant Feature Transformation (SIFT) and Speeded Up Robust Features (SURF). The key-points matching results using Brute Force and FLANN (Fast Library for Approximate Nearest Neighbors) on various levels for both SIFT and SURF algorithms are compared herein. The algorithms are implemented on Hadoop MapReduce framework integrated with Hadoop Image Processing Interface (HIPI) and Open Computer Vision Library (OpenCV). As a result, the experiments shown that using SIFT with KNN (4, 5, and 6) levels give the highest matching accuracy in comparison to the other methods.		Heba Gaber;Mohammed Marey;Safaa E. Amin;Howida A. Shedeed;Mohamed F. Tolba	2018		10.1007/978-3-319-99010-1_56	image processing;content-based image retrieval;big data;feature extraction;computer vision;artificial intelligence;scale-invariant feature transform;computer science	Vision	37.365329001298846	-58.130227719552934	35074
9682e3ecd06d9c3c60d81658ecb84faed9bf1271	semi-automatic rough classification of multichannel medical imaging data		Rough set theory is an approach to handle vagueness or uncertainty. We propose methods that apply rough set theory in the context of segmentation (or partitioning) of multichannel medical imaging data. We put this approach into a semi-automatic framework, where the user specifies the classes in the data by selecting respective regions in 2D slices. Rough set theory provides means to compute lower and upper approximations of the classes. The boundary region between the lower and the upper approximations represents the uncertainty of the classification.We present an approach to automatically compute segmentation rules from the rough set classification using a k-means approach. The rule generation removes redundancies, which allows us to enhance the original feature space attributes with a number of further feature and object space attributes. The rules can be transferred from one 2D slice to the entire 3D data set to produce a 3D segmentation result. The result can be refined by the user by interactively adding more samples (from the same or other 2D slices) to the respective classes. Our system allows for a visualization of both the segmentation result and the uncertainty of the individual class representations. The methods can be applied to single- as well as multichannel (or multimodal) imaging data. As a proof of concept, we applied it to medical imaging data with RGB color channels.	medical imaging;semiconductor industry	Ahmed Elmoasry;Mohamed Sadek Maswadah;Lars Linsen	2012		10.1007/978-3-642-21608-4_5	proof of concept;mathematics;visualization;rgb color model;feature vector;rough set;artificial intelligence;medical imaging;communication channel;pattern recognition	Vision	41.4694609295893	-72.32200413243096	35125
ff1405dd3b68a1edbae7b887417aa8c4fb0ccca4	evolving content-driven superpixels for accurate image representation	berkeley segmentation dataset;underlying image property;superpixel oversegmentation;simple image variation;comparable performance;new algorithm;image information;direct control;superpixel coverage;performance metrics;content-driven superpixels;accurate image representation	A novel approach to superpixel generation is presented that aims to reconcile image information with superpixel coverage. It is described as content-driven as the number of superpixels in any given area is dictated by the underlying image properties. By using a combination of well-established computer vision techniques, superpixels are grown and subsequently divided on detecting simple image variation. It is designed to have no direct control over the number of superpixels as this can lead to errors. The algorithm is subject to performance metrics on the Berkeley Segmentation Dataset including: explained variation; mode label analysis, as well as a measure of oversegmentation. The results show that this new algorithm can reduce the superpixel oversegmentation and retain comparable performance in all other metrics. The algorithm is shown to be stable with respect to initialisation, with little variation across performance metrics on a set of random initialisations.		Richard J. Lowe;Mark S. Nixon	2011		10.1007/978-3-642-24028-7_18	computer vision;machine learning;pattern recognition	Vision	45.8790563325576	-68.72471753913219	35134
7429998815794fbadce091f8c1223d1a1a53fc2d	multi-class alzheimer's disease classification using image and clinical features		Abstract Alzheimeru0027s disease (AD) is the most common form of dementia, which results in memory related issues in subjects. An accurate detection and classification of AD alongside its prodromal stage i.e., mild cognitive impairment (MCI) is of great clinical importance. In this paper, an Alzheimer detection and classification algorithm is presented. The bag of visual word approach is used to improve the effectiveness of texture based features, such as gray level co-occurrence matrix (GLCM), scale invariant feature transform, local binary pattern and histogram of gradient. The importance of clinical data provided alongside the imaging data is highlighted by incorporating clinical features with texture based features to generate a hybrid feature vector. The features are extracted from whole as well as segmented regions of magnetic resonance (MR) brain images representing grey matter, white matter and cerebrospinal fluid. The proposed algorithm is validated using the Alzheimeru0027s disease neuro-imaging initiative dataset (ADNI), where images are classified into one of the three classes namely, AD, normal, and MCI. The proposed algorithm outperforms state-of-the-art techniques in key evaluation parameters including accuracy, sensitivity, and specificity. An accuracy of 98.4% is achieved for binary classification of AD and normal class. For multi-class classification of AD, normal and MCI, an accuracy of 79.8% is achieved.		Tooba Altaf;Syed Muhammad Anwar;Nadia Gul;Muhammad Nadeem Majeed;Muhammad Majid	2018	Biomed. Signal Proc. and Control	10.1016/j.bspc.2018.02.019	white matter;local binary patterns;pattern recognition;mathematics;visual word;artificial intelligence;binary classification;feature vector;histogram;scale-invariant feature transform;dementia	ML	33.93095986770833	-75.22256805630202	35147
3aad50a93305b3256ec4e13c6f80ce27fd3a849e	comparison of thyroid segmentation techniques for 3d ultrasound	image segmentation;endocrine system;algorithms;ultrasonography	The segmentation of the thyroid in ultrasound images is a field of active research. The thyroid is a gland of the endocrine system and regulates several body functions. Measuring the volume of the thyroid is regular practice of diagnosing pathological changes. In this work, we compare three approaches for semi-automatic thyroid segmentation in freehand-tracked three-dimensional ultrasound images. The approaches are based on level set, graph cut and feature classification. For validation, sixteen 3D ultrasound records were created with ground truth segmentations, which we make publicly available. The properties analyzed are the Dice coefficient when compared against the ground truth reference and the effort of required interaction. Our results show that in terms of Dice coefficient, all algorithms perform similarly. For interaction, however, each algorithm has advantages over the other. The graph cut-based approach gives the practitioner direct influence on the final segmentation. Level set and feature classifier require less interaction, but offer less control over the result. All three compared methods show promising results for future work and provide several possible extensions.	adobe freehand;algorithm;coefficient of determination;cut (graph theory);feature vector;graph cuts in computer vision;ground truth;semiconductor industry;statistical classification;sørensen–dice coefficient;usability;video post-processing	Tom Wunderling;B. Golla;P. Poudel;Christoph Arens;Michael Friebe;Christian Hansen	2017		10.1117/12.2254234	computer vision;ultrasonography;image segmentation;endocrine system	Web+IR	39.26251800960708	-79.61319905981537	35176
f1a6232d8d0d0e4bc4d6041137e62884c610e6d2	aspect graphs for three-dimensional object recognition machine vision systems	aspect transition;object structure;aspect-graph-based 3-d object representation;red strip;reaction time;three-dimensional object recognition machine;certain aspect;aspect graph;vision system;object understanding;elementary task;efficient 3-d object recognition;machine vision;three dimensional;object recognition	The purpose of this research is to seek evidence for viewer-centered (especially aspect-graphbased) visual processing in the elementary task of object understanding. Two homologous, bilaterally symmetrical three-dimensional (3-D) objects have been employed that differ in that one is based on parts with flat surfaces and the other on parts with curved surfaces. The following procedure has been followed, separately for each object. In the training (saturated free inspection and manipulation) phase, a location (identical for both objects) of the object is marked with a red strip and the subjects’ task is to memorize the object structure as well as the position of the strip. In the test phase, two-dimensional views of the object without the strip are presented and the subjects’ task is to determine whether the previously marked location should be visible or invisible in the particular view. Findings have been found consistent with an aspect-graph-based 3-D object representation: (a) the reaction times and errors show characteristic dependencies on viewpoint; (b) a number of views (corresponding to certain aspects and aspect transitions of the aspect graph) consistently produce faster and more accurate recognition; (c) the differences in the aspect graphs of the two objects are reflected in differing patterns of reaction times and errors; furthermore; (d) the subjects impose a standard orientation on the objects, whereby a strong inversion effect is observed; and (e) performance varies in a similar way for both objects as a function of tilt. It is concluded that object understanding is viewpoint dependent, that is, based on a number of views. The characteristics of the views found to be most important for object understanding can be employed for creating efficient 3-D object recognition machine vision systems. © 2005 Wiley Periodicals, Inc.	emoticon;homology (biology);john d. wiley;machine vision;outline of object recognition	Tatiana Tambouratzis;Michael J. Wright	2005	Int. J. Intell. Syst.	10.1002/int.20053	three-dimensional space;computer vision;method;pose;object model;machine vision;image processing;form perception;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;3d single-object recognition;object-oriented programming	Robotics	45.8495639957492	-55.806229728586565	35183
22d6d9c1b7ac2738b51d93be45ac8f753f81867c	stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4d patient data	unsupervised learning;object recognition;probability;liver;pixel classification;training;biological organs;image classification;unsupervised learning biological organs biomedical mri feature extraction image classification medical image processing object detection probability;visualization;machine learning;magnetic resonance;edge and feature detection;patient datasets stacked autoencoders unsupervised feature learning 4d patient data medical image analysis ground truth labels supervised machine learning tissue types organ shapes abnormal dataset magnetic resonance medical images visual hierarchical features temporal hierarchical features object class categorization unlabeled multimodal dce mri dataset weakly supervised training probabilistic patch based method image classifiers multiple organ detection deep learning model intrinsic abnormalities;feature extraction;medical image processing;liver training machine learning medical diagnostic imaging visualization feature extraction;biomedical image processing;artificial intelligence databases factual humans image enhancement image processing computer assisted magnetic resonance imaging pattern recognition automated pilot projects;biomedical image processing edge and feature detection object recognition pixel classification machine learning;object detection;medical diagnostic imaging;biomedical mri	Medical image analysis remains a challenging application area for artificial intelligence. When applying machine learning, obtaining ground-truth labels for supervised learning is more difficult than in many more common applications of machine learning. This is especially so for datasets with abnormalities, as tissue types and the shapes of the organs in these datasets differ widely. However, organ detection in such an abnormal dataset may have many promising potential real-world applications, such as automatic diagnosis, automated radiotherapy planning, and medical image retrieval, where new multimodal medical images provide more information about the imaged tissues for diagnosis. Here, we test the application of deep learning methods to organ identification in magnetic resonance medical images, with visual and temporal hierarchical features learned to categorize object classes from an unlabeled multimodal DCE-MRI dataset so that only a weakly supervised training is required for a classifier. A probabilistic patch-based method was employed for multiple organ detection, with the features learned from the deep learning model. This shows the potential of the deep learning model for application to medical images, despite the difficulty of obtaining libraries of correctly labeled training datasets and despite the intrinsic abnormalities present in patient datasets.	artificial intelligence;autoencoder;body tissue;categorization;class;congenital abnormality;deep learning;feature learning;genetic heterogeneity;ground truth;histocompatibility testing;image analysis;image retrieval;libraries;machine learning;medical image;medical records systems, computerized;multimodal interaction;neoplasm metastasis;neoplasms;numerous;object detection;organ;outline of object recognition;patients;plant extracts;radiology;resonance;silo (dataset);supervised learning;tracer;algorithm	Hoo-Chang Shin;Matthew G Orton;David J. Collins;Simon J. Doran;Martin O. Leach	2013	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2012.277	semi-supervised learning;unsupervised learning;computer vision;contextual image classification;visualization;feature extraction;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;probability	ML	32.415804911134686	-75.44628511311923	35189
5800730d3319ed2f2ebdc053eeea654d8dc93ac6	a novel anchorperson detection algorithm based on spatio-temporal slice	pattern clustering;spatio temporal slice;video signal processing image segmentation object detection pattern clustering;image segmentation;video signal processing;news programs;news videos;large scale;anchorperson detection algorithm;detection algorithm;decision fusion;pattern analysis;object detection;decision fusion anchorperson detection algorithm spatio temporal slice news programs news videos pattern analysis pattern clustering;detection algorithms sociotechnical systems robustness gunshot detection systems clustering algorithms videoconference indexing pattern analysis computers navigation	For conveniently navigating and editing the news programs, it is very important to segment the video into meaningful units. The effective indexing of news videos can be fulfilled by the anchorperson shot because it is an indicator which denotes the occurrence of upcoming news stories. The paper presents a novel anchorperson detection algorithm based on spatio-temporal slice (STS). With STSpattern analysis, clustering and decision fusion, anchorperson shots can be detected for browsing news video. The large-scale experimental results demonstrate that the algorithm is accurate, robust and effective.	algorithm;cluster analysis	Anan Liu;Sheng Tang;Yongdong Zhang;Jintao Li;Zhaoxuan Yang	2007	14th International Conference on Image Analysis and Processing (ICIAP 2007)	10.1109/ICIAP.2007.15	computer vision;computer science;data mining;multimedia;image segmentation	Robotics	38.39572725395145	-52.933181845424514	35209
3273f9661d0a04b84e565d12130b1b69a7f005d5	denoising smooth signals using a bayesian approach: application to altimetry	bayes methods;computational modeling;logic gates;noise reduction;satellites;correlation;signal processing algorithms	This paper presents a novel Bayesian strategy for the estimation of smooth signals corrupted by Gaussian noise. The method assumes a smooth evolution of a succession of continuous signals that can have a numerical or an analytical expression with respect to some parameters. The proposed Bayesian model takes into account the Gaussian properties of the noise and the smooth evolution of the successive signals. In addition, a gamma Markov random field prior is assigned to the signal energies and to the noise variances to account for their known properties. The resulting posterior distribution is maximized using a fast coordinate descent algorithm whose parameters are updated by analytical expressions. The proposed algorithm is tested on satellite altimetric data demonstrating good denoising results on both synthetic and real signals. In comparison with state-of-the-art algorithms, the proposed strategy provides a good compromise between denoising quality and necessary reduced computational cost. The proposed algorithm is also shown to improve the quality of the altimetric parameters when combined with a parameter estimation or a classification strategy.	algorithm;algorithmic efficiency;bayesian network;computation;coordinate descent;energy, physics;estimation theory;gaussian blur;markov chain;markov random field;noise reduction;normal statistical distribution;numerical analysis;personnameuse - assigned;population parameter;succession;synthetic intelligence	Abderrahim Halimi;Gerald S. Buller;Stephen McLaughlin;Paul Honeine	2017	IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing	10.1109/JSTARS.2016.2629516	computer vision;econometrics;logic gate;computer science;machine learning;noise reduction;mathematics;computational model;correlation;physics;satellite;statistics	ML	52.91458144624688	-76.09688317892132	35260
9d056527781f9bb4a7def18b5cd3cb668f8c47fa	deblurring subject to nonnegativity constraints when known functions are present with application to object-constrained computerized tomography	artefacto;iterative method;computerized axial tomography;tomodensitometria;radiodiagnostic;optimisation;medical imagery;metallic material;aplicacion medical;image processing;optimizacion;foreign body;corps etranger;procesamiento imagen;hombre;medical diagnostic imaging brachytherapy treatment advanced cervical cancer x ray computed tomography imaging object constrained computerized tomography nonnegativity constraints deblurring tomographic images reconstruction;traitement image;artefact;metodo iterativo;algorithme;algorithm;reconstruction image;radiodiagnostico;produit metallique;tomodensitometrie;application software computed tomography image reconstruction optical imaging x ray imaging cervical cancer kernel brachytherapy deconvolution books;reconstruccion imagen;cuerpo extrano;methode iterative;image reconstruction;medical image processing;human;computerised tomography;imagineria medica;imagerie medicale;medical image processing image reconstruction computerised tomography;evaluation;optimization;medical application;artifacts brachytherapy female humans image processing computer assisted phantoms imaging tomography x ray computed uterine cervical neoplasms;evaluacion;radiodiagnosis;producto metalico;homme;application medicale;algoritmo	The reconstruction of tomographic images is often treated as a linear deblurring problem. When a high-density, man-made metal object is present somewhere in the image field, it is a deblurring problem in which the unknown function has a component that is known except for some location and orientation parameters. The authors first address general linear deblurring problems in which a known function having unknown parameters is present. They then show how the resulting iterative solution can be applied to tomographic imaging in the presence of man-made foreign objects, and they apply the result, in particular, to X-ray computed tomography imaging used in support of brachytherapy treatment of advanced cervical cancer.	brachytherapy;cervix carcinoma;deblurring;diagnostic radiologic examination;foreign bodies;iterative method;neck;x-ray computed tomography	Donald L. Snyder;Joseph A. O'Sullivan;Bruce R. Whiting;Ryan J. Murphy;Jasenka Benac;J. Adam Cataldo;Jeffrey F. Williamson	2001	IEEE Transactions on Medical Imaging	10.1109/42.959298	iterative reconstruction;computer vision;radiology;image processing;computer science;evaluation;mathematics;iterative method;nuclear medicine;medical physics	Vision	52.64450527015179	-78.91060305771144	35302
74cfbdae695b4c5e8f14a65580d97c405e1fadb2	conditional random field modelling of interactions between findings in mammography	networks;neural networks;computer aided diagnosis;mammography;modeling;vision	Recent breakthroughs in training deep neural network architectures, in particular deep Convolutional Neural Networks (CNNs), made a big impact on vision research and are increasingly responsible for advances in Computer Aided Diagnosis (CAD). Since many natural scenes and medical images vary in size and are too large to feed to the networks as a whole, two stage systems are typically employed, where in the first stage, small regions of interest in the image are located and presented to the network as training and test data. These systems allow us to harness accurate region based annotations, making the problem easier to learn. However, information is processed purely locally and context is not taken into account. In this paper, we present preliminary work on the employment of a Conditional Random Field (CRF) that is trained on top the CNN to model contextual interactions such as the presence of other suspicious regions, for mammography CAD. The model can easily be extended to incorporate other sources of information, such as symmetry, temporal change and various patient covariates and is general in the sense that it can have application in other CAD problems.	conditional random field;interaction	Thijs Kooi;J J Mordang;Nico Karssemeijer	2017		10.1117/12.2254133	vision;computer vision;simulation;systems modeling;computer science;machine learning;artificial neural network	HCI	30.375455529243307	-73.92305594837629	35323
86d19cebfd1b03db0ffe585c6da29528a7c73f29	disc: deep image saliency computing via progressive representation learning	histograms;saliency detection convolutional neural network cnn image labeling representation learning;image labeling;disc deep image saliency computing progressive representation learning salient object detection pattern recognition image processing feature engineering feature learning fine grained image saliency computing fine level observations coarse level observations deep convolutional neural network cnn superpixel based local context information coarse level saliency map;convolutional neural network cnn image labeling representation learning saliency detection;saliency detection;computer vision;convolutional neural network cnn;visualization;computational modeling;image color analysis;期刊论文;coarse level saliency map disc deep image saliency computing progressive representation learning salient object detection pattern recognition image processing feature engineering feature learning fine grained image saliency computing fine level observations coarse level observations deep convolutional neural network cnn superpixel based local context information;representation learning;context;object detection;computational modeling context image color analysis visualization object detection computer vision histograms;object detection feature extraction image representation image resolution learning artificial intelligence neural nets;feature extraction image representation image resolution learning artificial intelligence neural nets object detection	"""Salient object detection increasingly receives attention as an important component or step in several pattern recognition and image processing tasks. Although a variety of powerful saliency models have been intensively proposed, they usually involve heavy feature (or model) engineering based on priors (or assumptions) about the properties of objects and backgrounds. Inspired by the effectiveness of recently developed feature learning, we provide a novel deep image saliency computing (DISC) framework for fine-grained image saliency computing. In particular, we model the image saliency from both the coarse-and fine-level observations, and utilize the deep convolutional neural network (CNN) to learn the saliency representation in a progressive manner. In particular, our saliency model is built upon two stacked CNNs. The first CNN generates a coarse-level saliency map by taking the overall image as the input, roughly identifying saliency regions in the global context. Furthermore, we integrate superpixel-based local context information in the first CNN to refine the coarse-level saliency map. Guided by the coarse saliency map, the second CNN focuses on the local context to produce fine-grained and accurate saliency map while preserving object details. For a testing image, the two CNNs collaboratively conduct the saliency computing in one shot. Our DISC framework is capable of uniformly highlighting the objects of interest from complex background while preserving well object details. Extensive experiments on several standard benchmarks suggest that DISC outperforms other state-of-the-art methods and it also generalizes well across data sets without additional training. The executable version of DISC is available online: <;uri xlink:type=""""simple"""">http://vision.sysu.edu.cn/projects/DISC<;/uri>."""	artificial neural network;biological neural networks;body dysmorphic disorders;computation (action);convolutional neural network;executable;experiment;feature learning;image processing;machine learning;object detection;pattern recognition;physical object;uniform resource identifier;xlink	Tianshui Chen;Liang Lin;Lingbo Liu;Xiaonan Luo;Xuelong Li	2016	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2015.2506664	feature learning;computer vision;visualization;computer science;kadir–brady saliency detector;machine learning;pattern recognition;histogram;computational model	Vision	28.65460165094096	-52.863248124006	35331
e148407e173fecca02d46725b5e823ad8e847979	robust face recognition under different facial expressions, illumination variations and partial occlusions	delta discrete cosine transform coefficient;hidden markov model;embedded hidden markov model;local binary pattern;discrete cosine transform;face recognition;facial expression;robust face recognition	In this paper, a robust face recognition system is presented, which can perform precise face recognition under facial expression variations, illumination changes, and partial occlusions. The embedded hidden Markov model based face classifier is applied for identity recognition in which the proposed observation extraction is presented by performing local binary patterns prior to performing delta operation on the discrete cosine transform coefficients of consecutive blocks. Experimental results show that the proposed face recognition system achieves high recognition accuracy of 99%, 96.6% and 98% under neutral face, expression variations, and illumination changes respectively. Particularly, under partial occlusions, the system achieves recognition rate of 81.6% and 86.6% for wearing sunglasses and scarf respectively.	facial recognition system	Shih-Ming Huang;Jar-Ferr Yang	2011		10.1007/978-3-642-17829-0_31	computer vision;local binary patterns;speech recognition;computer science;machine learning;discrete cosine transform;pattern recognition;facial expression;hidden markov model	Vision	32.650218712491544	-59.12814099130195	35340
5719519d42a4886e6a30cf1b5d2a2b08428469cf	deep learning and hand-crafted feature based approaches for polyp detection in medical videos		Video analysis including classification, segmentation or tagging is one of the most challenging but also interesting topics multimedia research currently try to tackle. This is often related to videos from surveillance cameras or social media. In the last years, also medical institutions produce more and more video and image content. Some areas of medical image analysis, like radiology or brain scans, are well covered, but there is a much broader potential of medical multimedia content analysis. For example, in colonoscopy, 20% of polyps are missed or incompletely removed on average. Thus, automatic detection to support medical experts can be useful. In this paper, we present and evaluate several machine learning-based approaches for real-time polyp detection for live colonoscopy. We propose pixel-wise localization and frame-wise detection methods which include both handcrafted and deep learning based approaches. The experimental results demonstrate the capability of analyzing multimedia content in real clinical settings, the possible improvements in the work flow and the potential improved detection rates for medical experts.	closed-circuit television;deep learning;experiment;feature engineering;image analysis;long short-term memory;machine learning;medical image computing;medical imaging;pixel;radiology;real-time clock;sensitivity and specificity;social media;test set;time series	Konstantin Pogorelov;Olga Ostroukhova;Mattis Jeppsson;Håvard Espeland;Carsten Griwodz;Thomas de Lange;Dag Johansen;Michael Riegler;Pål Halvorsen	2018	2018 IEEE 31st International Symposium on Computer-Based Medical Systems (CBMS)	10.1109/CBMS.2018.00073	data mining;computer science;deep learning;feature extraction;image segmentation;medical imaging;content analysis;artificial intelligence	Vision	32.27524024219772	-74.74988917424997	35373
69a26a8d376f84ea965f858d181e878b82a47e6a	cct: a cross-concat and temporal neural network for multi-label action unit detection		Action Unit (AU) detection is essential for facial expression analysis. However, most existing AU detection algorithms only focus on physical features, e.g., temporal feature and AU correlations, without considering various distributions of AUs, i.e., some AUs are quite less than others. In this work, we propose a novel cross-concat and temporal (CCT) neural network, which simultaneously consider physical features and the distribution differences. First, we design a cross-concat block (CCB) to adapt to the various distributions of AUs. CCB is based on the idea of skip connections since skip connections can reuse features from different layers and capture abundant features of AUs even with relatively small-size training samples. Second, LSTM layers are utilized to capture the temporal dependencies and multi-label learning is utilized for capturing AU correlations. Experimental results on three popular AU detection datasets, BP4D, DISFA, and GFT, show that the proposed algorithm outperforms the state-of-the-art ones.	algorithm;artificial neural network;change control board;computational complexity theory;concatenation;long short-term memory;multi-label classification	Qiaoping Hu;Fei Jiang;Parravicini Umberto;Ruimin Shen	2018	2018 IEEE International Conference on Multimedia and Expo (ICME)	10.1109/ICME.2018.8486516	kernel (linear algebra);feature extraction;artificial neural network;artificial intelligence;computer science;pattern recognition;convolution	Vision	27.038956240613008	-52.44461054753834	35558
33b278e840921d4dd570900f3ec5dd9c78badc40	by example synthesis of three-dimensional porous materials	digital fabrication;texture synthesis;porous material;solid texture	Porous materials are ubiquitous in nature and are used for many applications. However, there is still a lack of computational methods for generating and modeling complex porous structures. While conventional texture synthesis methods succeed in synthesizing solid texture based on a 2D input, to generate a 3D structure that visually matches a given 3D exemplar remains an open question. We present the first framework that can synthesize porous material that is structurally consistent to input 3D exemplar. In our framework, the 2D texture optimization method is extended built upon 3D neighborhood. An adaptive weighted mechanism method is proposed to reduce blurring and accelerate the convergence speed. Moreover, a connectivity pruning algorithm is performed as post-processing to prune spurious branches. Experimental results demonstrate that our method can preserve both the structural continuity and material descriptors of input exemplar while maintain visual similarity with input structure.	3d printing;algorithm;computation;display resolution;experiment;mathematical optimization;microsoft research;printer (computing);scott continuity;texture synthesis;video post-processing	Hui Zhang;Weikai Chen;Bin Wang;Wenping Wang	2017	Computer Aided Geometric Design	10.1016/j.cagd.2017.03.015	theoretical computer science;texture synthesis	Graphics	53.63715497193256	-69.1990641864821	35582
ba8500256fc56208794072d988750dc24d309246	content-based image retrieval using color features of salient regions	dominant color;content based image retrieval cbir;saliency;spatial distribution	This paper presents a content-based color image retrieval system based on color features from the salient regions and their spatial relationship. The proposed method first extracts the salient regions by a color contrast method, and finds several dominant colors for each region. Then, the spatial distribution of each dominant color is described as a binary map. Specifically, the salient region is partitioned into small sub-blocks, and each sub-block is assigned as 1 or 0 according to the number of pixels corresponding to the dominant color. The set of binary maps define the spatial distribution of dominant colors within and across the salient regions, which approximately reflect the objects' shapes and the spatial relationship of the objects. A simple matching method for this description is also proposed, which needs very few computations for each image matching. According to the experiments with several widely used color image databases, the proposed method shows better retrieval performance than the state-of-the-art and previous color-based methods. The proposed algorithm is suitable for color image retrieval on the web and mobile systems, because it needs very few computations which are mostly binary logical operations.	algorithm;color image;computation;content-based image retrieval;database;experiment;image registration;logical connective;map;pixel	Jaehyun An;Sang Hwa Lee;Nam Ik Cho	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7025615	color histogram;computer vision;color quantization;hsl and hsv;color normalization;color depth;binary image;salience;high color;information retrieval;computer graphics (images)	Vision	39.35139200318018	-59.837413751821344	35649
2b229953d388f1ce8ecdf007a1b9884a7d0acf61	rd-based seeded region growing for extraction of breast tumor in an ultrasound volume	interferometrie optique;semilla;theorie vitesse distorsion;medida velocidad;rate distortion;speckle;ultrason;securite;taux erreur;ultrasound;semence;generation maille;mammary gland;profilometry;volume;speckle noise;mesure vitesse;intelligence artificielle;homogeneidad;rate distortion theory;glandula mamaria;speed measurement;seeded region growing;volumen;ultrasonido;tumor;pixel;metrologia superficie;safety;metrologie surface;profilometrie;error rate;tumeur;artificial intelligence;seed;glande mammaire;optical interferometry;homogeneite;inteligencia artificial;surface metrology;indice error;mesh generation;region growing;seguridad;diagrama mancha;perfilometria;interferometria optica;homogeneity	This paper proposes a rate-distortion (RD) based seeded region growing (SRG) for extracting an object such as breast tumors in ultrasound volumes which contain speckle noise and indistinct edges. In the proposed algorithm, region growing proceeds in such a way that the growing cost is minimized which is represented as the combination of rate measuring the roughness of a region contour and distortion measuring the inhomogeneity of pixels in a region. An input image is first segmented into an initial seed region and atomic homogeneous regions. The seed is next merged with one of adjacent regions which makes the RD cost minimum at each step. Such a merging is repeated until the RD cost averaged over the entire seed contour reaches the maximum. As a result, the final seed holds region homogeneity and has a smooth contour while maximizing inhomogeneity against its adjacent regions. Experiments of extracting breast tumors in four real ultrasound volumes show the proposed method yields the average 40% improvement in error rate with respect to the results extracted manually over some conventional methods.	region growing;ruby document format	Jong In Kwak;Sang Hyun Kim;Nam Chul Kim	2005		10.1007/11596448_118	speckle pattern;speckle noise;mesh generation;profilometer;homogeneity;rate–distortion theory;word error rate;computer science;interferometry;artificial intelligence;machine learning;ultrasound;region growing;volume;pixel;statistics	EDA	47.31564338636389	-74.41379848851267	35669
9ebdfb86d7aa1e7f96bd3fd5b134d987e0ffda2c	hypothesis validation of far-wall brightness in carotid-artery ultrasound for feature-based imt measurement using a combination of level-set segmentation and registration	databases;spline;far wall;image segmentation;image processing;morphological image processing hypothesis validation far wall brightness internal carotid artery ultrasound feature based imt measurement algorithms intima media thickness level set segmentation level set registration atherosclerosis indicator completely automated layer extraction calex system atheroedge systems from global biomedical technologies inc pixel intensities common carotid artery b mode longitudinal ultrasound images carotid wall patented methodology carotid image frames b spline based nonrigid registration affine registration carotid artery lumen;level set segmentation;ultrasound;edge detection;ultrasonic imaging;performance;level set;intima media thickness imt;ultrasound us;image segmentation carotid arteries image edge detection gray scale databases splines mathematics;gray scale;splines mathematics;carotid arteries;common carotid artery;intima media thickness;brightness;image edge detection;ultrasound us brightness carotid artery far wall intima media thickness imt level set segmentation nonrigid registration performance;carotid artery;feature extraction;medical image processing;internal carotid artery;image registration;nonrigid registration;biomedical ultrasonics;thickness measurement;blood vessels;ultrasonic imaging biomedical ultrasonics blood vessels feature extraction image registration image segmentation medical image processing splines mathematics thickness measurement	Intima-media thickness (IMT) is now being considered as an indicator of atherosclerosis. Our group has developed several feature-based IMT measurement algorithms such as the Completely Automated Layer EXtraction (CALEX) (which is a class of patented AtheroEdge Systems from Global Biomedical Technologies, Inc., CA, USA). These methods are based on the hypothesis that the highest pixel intensities are in the far wall of the common carotid artery (CCA) or the internal carotid artery (ICA). In this paper, we verify that this hypothesis holds true for B-mode longitudinal ultrasound (US) images of the carotid wall. This patented methodology consists of generating the composite image (the arithmetic sum of images) from the database by first registering the carotid image frames with respect to a nearly straight carotid-artery frame from the same database using: (1) B-spline-based nonrigid registration and (2) affine registration. Prior to registration, we segment the carotid-artery lumen using a level-set-based algorithm followed by morphological image processing. The binary lumen images are registered, and the transformations are applied to the original grayscale CCA images. We evaluated our technique using a database of 200 common carotid images of normal and pathologic carotids. The composite image presented the highest intensity distribution in the far wall of the CCA/ICA, validating our hypothesis. We have also demonstrated the accuracy and improvement in the IMT segmentation result with our CALEX 3.0 system. The CALEX system, when run on newly acquired US images, shows the IMT error of about 30 μm. Thus, we have shown that the CALEX algorithm is able to exploit the far-wall brightness for accurate IMT measurements.	algorithm;b-spline;grayscale;image processing;image registration;independent computing architecture;interactive machine translation;mathematical morphology;medical ultrasound;pixel;thickness (graph theory)	Filippo Molinari;Ganapathy Krishnamurthi;U. Rajendra Acharya;Subbhuraam Vinitha Sree;Guang Zeng;Luca Saba;Andrew Nicolaides;Jasjit S. Suri	2012	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2011.2174901	spline;computer vision;edge detection;performance;image processing;feature extraction;computer science;image registration;level set;ultrasound;image segmentation;engineering drawing;brightness;grayscale	Vision	39.29584506090268	-77.49561602060933	35679
409f0aa468b73a0c54473433d029e9fd1fe50d71	scaling theorems for zero crossings	linear differential equations;passage;nonlinear filters psychology laplace equations information analysis signal analysis image edge detection filtering signal processing artificial intelligence visual system;nonlinear filters;image filtering;filtering;zero crossing gaussian filters scale space;theorems;image processing;image intensification;echelle;signal analysis;laplacian;procesamiento de imagen;differential operators;image;heating;psychology;escala;data mining;scale;traitement image;linear filtering;filtre gaussien;laplacien;laplace equations;scale space;difference equations;image edge detection;imagen;signal processing;zero crossing;scaling factor;contours;maximum likelihood detection;mathematical model;two dimensional;artificial intelligence;filtre electrique;one dimensional;gaussian filters;visual system;crossings;operators mathematics;information analysis;filtering theory;electric filter;zero	We characterize some properties of the zero crossings of the Laplacian of signals¿in particular images¿filtered with linear filters, as a function of the scale of the filter (extending recent work by Witkin [16]). We prove that in any dimension the only filter that does not create generic zero crossings as the scale increases is the Gaussian. This result can be generalized to apply to level crossings of any linear differential operator: it applies in particular to ridges and ravines in the image intensity. In the case of the second derivative along the gradient, there is no filter that avoids creation of zero crossings, unless the filtering is performed after the derivative is applied.	arabic numeral 0;gradient;normal statistical distribution;test scaling	Alan L. Yuille;Tomaso A. Poggio	1986	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1986.4767748	scale factor;filter;differential operator;computer vision;scale;mathematical optimization;laplace operator;two-dimensional space;discrete mathematics;theorem;scale space;recurrence relation;visual system;computer science;machine learning;image;signal processing;linear differential equation;linear filter;mathematical model;mathematics;geometry;zero crossing;data analysis;dimension;statistics	Vision	50.90305117330158	-65.61358429482686	35757
b92dd7aafa42def3bce2a9d9321cf6909f6c310a	a novel approach of cryptanalysis using som	cybernetics;pattern clustering;machine learning technique;key clustering;self organising feature maps cryptography independent component analysis learning artificial intelligence pattern clustering;probability density function;independent component analysis;data mining;independent component analysis cryptanalysis machine learning technique self organizing map key clustering encrypted message;cybernetics sliding mode control;cryptanalysis;encrypted message;machine learning;self organising feature maps;cryptography;phase transformation;self organizing map;self organized map;learning artificial intelligence;conferences	Machine learning techniques like self organizing maps has been explored for the first time for efficient key clustering in cryptanalysis. In the first phase, transformations have been employed on the encrypted messages to find the dominance in the features and n, in the second phase, independent component analysis -ICA to find important features among the transformed features and finally SOM has been employed for clustering.	cluster analysis;cryptanalysis;encryption;independent component analysis;key clustering;machine learning;organizing (structure);self-organization;self-organizing map	Bala Chandra;P. Paul Varghese;Pramod K. Saxena;Shri Kant	2008	2008 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2008.4811611	independent component analysis;cryptanalysis;probability density function;cybernetics;computer science;cryptography;artificial intelligence;theoretical computer science;machine learning;data mining;statistics	EDA	26.054861468676666	-65.34926491949821	35769
78a35e06df95adeac38963c003b506f28ee98360	learning discriminative canonical correlations for object recognition with image sets	reconnaissance visage;metodo correlacion;image recognition;object recognition;reconocimiento imagen;vision ordenador;estimation mouvement;image processing;illumination;facies;methode non parametrique;correlation method;estimacion movimiento;luminance;vector space;procesamiento imagen;motion estimation;reconnaissance objet;linear discriminate analysis;fonction discriminante;discriminant function;traitement image;computer vision;discriminant analysis;analyse discriminante;motion capture;analisis discriminante;metodo no parametrico;face recognition;eclairage;discrimination learning;robustesse;reconnaissance image;funcion discriminante;pattern recognition;non parametric method;robustness;vision ordinateur;lighting;espace vectoriel;reconnaissance forme;reconocimiento patron;eclairement;correlation canonique;espacio vectorial;correlacion canonica;methode correlation;alumbrado;canonical correlation;robustez;luminancia	We address the problem of comparing sets of images for object recognition, where the sets may represent arbitrary variations in an object’s appearance due to changing camera pose and lighting conditions. The concept of Canonical Correlations (also known as principal angles) can be viewed as the angles between two subspaces. As a way of comparing sets of vectors or images, canonical correlations offer many benefits in accuracy, efficiency, and robustness compared to the classical parametric distribution-based and non-parametric sample-based methods. Here, this is demonstrated experimentally for reasonably sized data sets using existing methods exploiting canonical correlations. Motivated by their proven effectiveness, a novel discriminative learning over sets is proposed for object recognition. Specifically, inspired by classical Linear Discriminant Analysis (LDA), we develop a linear discriminant function that maximizes the canonical correlations of within-class sets and minimizes the canonical correlations of between-class sets. The proposed method significantly outperforms the state-of-the-art methods on two different object recognition problems using face image sets with arbitrary motion captured under different illuminations and image sets of five hundred general object categories taken at different views.	disk image;experiment;feature selection;linear discriminant analysis;markov switching multifractal;outline of object recognition;principal component analysis;robustness (computer science);video	Tae-Kyun Kim;Josef Kittler;Roberto Cipolla	2006		10.1007/11744078_20	computer vision;image processing;computer science;artificial intelligence;lighting;mathematics	Vision	46.227221237043416	-57.819843316442224	35778
204c6a6c56dab18d68566f0928fbb5f5d2c3f6ea	occam filters for stochastic sources with application to digital images	stochastic sources;gaussian noise;stochastic resonance;filtering;image coding;svd based occam filter;data compression;digital filters stochastic processes stochastic resonance data compression filtering image coding singular value decomposition digital images gaussian noise noise reduction;singular value decomposition;random noise;singular value decomposition data compression image coding gaussian noise digital filters stochastic processes;stochastic processes;noise reduction;digital filters;relative compressibility;lossy data compression;occam filters;svd based occam filter stochastic sources digital images occam filters lossy data compression relative compressibility singular value decomposition gaussian noise;digital image;digital images;discrete sampling	An Occam filter employs lossy data compression to separate signal from noise. Previously, it was shown that Occam filters can filter random noise from deterministic signals. Here, we show that Occam filters can also separate two stochastic sources, depending on their relative compressibility. We also compare the performance of Occam filters and wavelet-based denoising on digital images.	data compression;digital image;lossy compression;noise (electronics);noise reduction;wavelet;occam	Balas K. Natarajan;Konstantinos Konstantinides;Cormac Herley	1996		10.1109/ICIP.1996.559517	stochastic process;computer vision;mathematical optimization;computer science;theoretical computer science;machine learning;mathematics;digital image;statistics	ML	53.67883857804162	-67.4902708416544	35802
9874357a1cef5f3752d75101405bf8b2341d3adb	an estimation-theoric approach to terrain image segmentation	image segmentation		image segmentation	Charles W. Therrien	1982	Computer Graphics and Image Processing	10.1016/0146-664X(82)90025-9		Graphics	41.88266742802104	-70.85227413313558	35807
ef9bbeeab753ea81b9f2c8c0fbdcba77c15556e1	preliminary coarse image registration by using straight lines found on them for constructing super resolution mosaics and 3d scene recovery	fuzzy logic;image registration;3d scene reconstruction;super resolution	An algorithm of coarse image registration of a 3D scene taken from different camera perspectives is proposed. The algorithm uses information on geometrical parameters of straight lines found on the images and on distribution of color and/or brightness around these lines. Colors are taken into account by using the fuzzy logic technique. The result of the algorithm operation is a planar projective transformation (planar homography) matching approximately the images. In order to use the technique in algorithms of 3D scene reconstruction, an estimate of size of the window used for searching correspondent points after the coarse image registration is obtained.	algorithm;color;fuzzy logic;image registration;super-resolution imaging	Dmitriy B. Volegov;Dmitry V. Yurin	2008	Programming and Computer Software	10.1134/S0361768808050058	fuzzy logic;homography;computer vision;computer science;image registration;mathematics;geometry;superresolution;computer graphics (images)	Vision	52.709107571946625	-55.558917642469055	35857
156b18272362d8c371a67cfde1d913a02a54387d	morphological scale-space operators for images supported on point clouds		The aim of this paper is to develop the theory, and to propose an algorithm, for morphological processing of images painted on point clouds, viewed as a length metric measure space (X, d, μ). In order to extend morphological operators to process point cloud supported images, one needs to de ne dilation and erosion as semigroup operators on (X, d). That corresponds to a supremal convolution (and in mal convolution) using admissible structuring function on (X, d). From a more theoretical perspective, we introduce the notion of abstract structuring functions formulated on length metric Maslov idempotent measurable spaces, which is the appropriate setting for (X, d). In practice, computation of Maslov structuring function is approached by a random walks framework to estimate heat kernel on (X, d, μ), followed by the logarithmic trick.		Jesús Angulo	2015		10.1007/978-3-319-18461-6_7	computer vision;topology;geometry	Vision	51.107527755828826	-63.694399725624464	35903
b4c9494d76a87d47b3357e2b0fa0a77e055fc4a1	dorsal hand vein recognition across different devices		With the fast development of the information, the application of distributed recognition system becomes more widespread. But the difference of hardware condition of terminal acquisition and all kinds of environments in distributed recognition system made biometric feature images different, which were gathered by different hardware. Include contrast, lightness, shifting, angle of rotation, size and so on. These differences will inevitably reduce accuracy of recognition and will not satisfy the development needs of the times. This paper synthetically analyses the important factors of heterogeneous dorsal hand vein images which are resulted by different devices. After normalizing grayscale images, this paper uses a segmentation method based on gradient difference to segment the texture of veins and uses SIFT to extract and match features. Discrimination in this paper can improve to 90.17 %, which is higher than other algorithms. This method can effectively solve the problem about dorsal hand vein recognition across different devices.		YiDing Wang;Xuan Zheng;Congcong Wang	2016		10.1007/978-3-319-46654-5_34	dorsal hand;grayscale;normalization (statistics);computer vision;biometrics;artificial intelligence;scale-invariant feature transform;lightness;segmentation;computer science;angle of rotation	HCI	33.793057691831116	-61.71502770752931	36032
4be88a5ce6d54377026e421ce8fea3e9cab02135	deep learning hashing for mobile visual search	signal image and speech processing;biometrics;pattern recognition;image processing and computer vision	The proliferation of mobile devices is producing a new wave of mobile visual search applications that enable users to sense their surroundings with smart phones. As the particular challenges of mobile visual search, achieving high recognition bitrate becomes the consistent target of existed related works. In this paper, we explore to holistically exploit the deep learning-based hashing methods for more robust and instant mobile visual search. Firstly, we present a comprehensive survey of the existed deep learning based hashing methods, which showcases their remarkable power of automatic learning highly robust and compact binary code representation for visual search. Furthermore, in order to implement the deep learning hashing on computation and memory constrained mobile device, we investigate the deep learning optimization works to accelerate the computation and reduce the model size. Finally, we demonstrate a case study of deep learning hashing based mobile visual search system. The evaluations show that the proposed system can significantly improve 70% accuracy in MAP than traditional methods, and only needs less than one second computation time on the ordinary mobile phone. Finally, with the comprehensive study, we discuss the open issues and future research directions of deep learning hashing for mobile visual search.	binary code;computation;deep learning;hash function;holism;map;mathematical optimization;mobile device;mobile phone;smartphone;time complexity	Wu Liu;Huadong Ma;Heng Qi;Dong Zhao;Zhineng Chen	2017	EURASIP J. Image and Video Processing	10.1186/s13640-017-0167-4	computer vision;visual search;artificial intelligence;binary code;computation;mobile phone;hash function;deep learning;theoretical computer science;pattern recognition;computer science;exploit;machine learning;mobile device	HCI	27.47117333456444	-57.269197110669495	36134
2258b2cec3c21980671bd53182aad7d8b3b4273d	feature extraction		Feature extraction is the process of defining a set of features, or image characteristics, which will most efficiently, or meaningfully represent the information that is important for analysis and classification. Features are functions of the original measurement variables.	feature extraction	David S. Rosenberg	2009		10.1007/978-0-387-73003-5_2177		ML	36.54085810110906	-59.38661886129896	36137
2095e886de09eb436a1fb17278f3b3cde10ac3bd	edge detection and processing using shearlets	wavelet analysis;image edge detection wavelet transforms wavelet analysis image analysis filtering anisotropic magnetoresistance multidimensional systems digital filters image processing image recognition;directional filter edge detection edge processing multiscale directional representation shearlets transform image representation;multiscale directional representation;optimization technique;edge detection;indexing terms;digital filter;wavelet transforms;sensitivity;wavelet transforms multidimensional digital filters image edge analysis;wavelet transform;image edge detection;image representation;wavelet transforms digital filters edge detection image representation;digital filters;transforms;directional filter;shearlets transform;multidimensional digital filters;edge processing;noise;continuous wavelet transforms;image edge analysis	Mathematically wavelets are not very effective in representing images containing distributed discontinuities such as edges. This paper deals with a new multiscale directional representation called the shearlet transform that has been shown to represent specific classes of images with edges optimally. Techniques based on this transform for edge detection and analysis are presented. Unlike previously developed directional filter based techniques for edge detection, shearlets provide a theoretical basis for characterizing how edges will behave in such representations. Experiments demonstrate that this novel approach is very competitive for the purpose of edge detection and analysis.	edge detection;experiment;shearlet;wavelet	Sheng Yi;Demetrio Labate;Glenn R. Easley;Hamid Krim	2008	2008 15th IEEE International Conference on Image Processing	10.1109/ICIP.2008.4711963	computer vision;mathematical optimization;shearlet;digital filter;edge detection;computer science;pattern recognition;mathematics;wavelet transform	Vision	52.07459707201128	-65.72704441747136	36140
563490df824cafeb7366b0aeda18bb1cc9a9a511	semi-supervised learning for text-line detection	libre mercado;iterative method;traitement signal;europa;filtering;evaluation performance;filtrage;traitement image document;on line processing;detection forme;algorithm performance;document analysis;performance evaluation;image processing;supervised learning;evaluacion prestacion;echantillonnage;filtrado;language adaptiveness;database;procesamiento imagen;base dato;segmentation;line detection;shape detection;traitement image;semi supervised learning;marche concurrentiel;reduccion ruido;metodo iterativo;sampling;algorithme;tratamiento en linea;algorithm;deteccion forma;analyse documentaire;document segmentation;automatic detection;resultado algoritmo;text line detection;methode iterative;signal processing;noise reduction;reduction bruit;performance algorithme;detection rate;base de donnees;document image processing;analisis documental;group process;apprentissage supervise;open market;traitement en ligne;europe;muestreo;aprendizaje supervisado;procesamiento senal;noise removal;segmentacion;algoritmo	Automatically detecting text-lines from document images has been long studied. However, most researchers today are focusing on boosting the detection rate instead of noise removal. In this paper, we propose a semi-supervised learning framework that targets to segment Manhattan-layout documents with significant levels of noise. The algorithm consists of three steps: first, an initial segmentation process uses the seed filling algorithm; second, an iterative grouping process uses the projection profiles to estimate the vertical border of page contents; third, an inside page-content noise removal uses the online training and classification. We test our algorithm using two databases. The first is the University of Washington (UW)-III database with 1,600 images of different input qualities that has been widely used by the Document Analysis Research (DAR) communities to measure segmentation algorithm performance. The second is the NILE database created by sampling from 320 journals pages of east Asian, east European and middle Eastern languages. The result shows that our framework achieves competitive performance in terms of both page frame level segmentation and text-line level segmentation, and is particularly strong at filtering noise. It also shows that our algorithm is more adaptive to language variations.	edge detection;semi-supervised learning;semiconductor industry;supervised learning	Zongyi Liu;Hanning Zhou;Ning Yang	2010	Pattern Recognition Letters	10.1016/j.patrec.2010.03.015	filter;sampling;computer vision;speech recognition;open market operation;image processing;computer science;artificial intelligence;machine learning;signal processing;noise reduction;iterative method;supervised learning;scale-space segmentation;segmentation;group dynamics	Vision	46.44604294450815	-63.555711788694246	36162
699d48d8cd9fae48020ab00e819734dc3040ba8d	analysis of white blood cell differential counts using dual-tree complex wavelet transform and support vector machine classifier	poor quality;accurate segmentation;normal blood smear image;dual-tree complex wavelet;complete blood count;white blood cell;support vector machine;support vector machine classifier;white blood cell differential;thin blood smear;blood smear;complex wavelet transform;cell type identification	A widely used pathological screening test for blood smears is the complete blood count which classifies and counts peripheral particles into their various types. We particularly interested in the classification and counting of the five main types of white blood cells (leukocytes) in a clinical setting where the quality of microscopic imagery may be poor. A critical first step in the medical analysis of cytological images of thin blood smears is the segmentation of individual cells. The quality of the segmentation has a great influence on the cell type identification, but for poor quality, noisy, and/or low resolution images, segmentation is correspondingly less reliable. In this paper, we compensate for less accurate segmentation by extracting features based on wavelets using the Dual-Tree Complex Wavelet Transform (DT-CWT) which is based on multi-resolution characteristics of the image. These features then form the basis of classification of white blood cells into their five primary types with a Support Vector Machine (SVM) that performs classification by constructing hyper-planes in a high multi-dimensional space that separates cases of different classes. This approach was validated with experiments conducted on poor quality, normal blood smear images.	complex wavelet transform;support vector machine	Mehdi Habibzadeh;Adam Krzyzak;Thomas Fevens	2012		10.1007/978-3-642-33564-8_50	computer vision;pattern recognition	ML	35.46695414500972	-75.86262364558824	36187
34e074b02da6f9ddbaaebfd9b3c00eac508dba1e	plane-based content preserving warps for video stabilization	image segmentation;video signal processing;video signal processing deformation image segmentation image sequences markov processes random processes;deformation;random processes;three dimensional displays coplanar waveguides cameras image segmentation robustness image reconstruction motion segmentation;markov processes;tracked feature points plane based content preserving warps video stabilization framework image deformation technique cpw sparsely constructed 3d points building interiors textureless regions piecewise planar regions jittery video markov random fields nonplanar regions segmentation information video sequences;image sequences	Recently, a new image deformation technique called content-preserving warping (CPW) has been successfully employed to produce the state-of-the-art video stabilization results in many challenging cases. The key insight of CPW is that the true image deformation due to viewpoint change can be well approximated by a carefully constructed warp using a set of sparsely constructed 3D points only. However, since CPW solely relies on the tracked feature points to guide the warping, it works poorly in large texture less regions, such as ground and building interiors. To overcome this limitation, in this paper we present a hybrid approach for novel view synthesis, observing that the texture less regions often correspond to large planar surfaces in the scene. Particularly, given a jittery video, we first segment each frame into piecewise planar regions as well as regions labeled as non-planar using Markov random fields. Then, a new warp is computed by estimating a single homography for regions belong to the same plane, while inheriting results from CPW in the non-planar regions. We demonstrate how the segmentation information can be efficiently obtained and seamlessly integrated into the stabilization framework. Experimental results on a variety of real video sequences verify the effectiveness of our method.	3d reconstruction;acronis true image;approximation algorithm;gaussian blur;homography (computer vision);ibm notes;image warping;internet information services;linkage (software);markov chain;markov random field;microsoft customer care framework;on-premises wiring;planar graph;structure from motion;view synthesis	Zihan Zhou;Hailin Jin;Yi Ma	2013	2013 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2013.298	image texture;stochastic process;computer vision;simulation;computer science;mathematics;image segmentation;markov process;scale-space segmentation;deformation;statistics;computer graphics (images)	Vision	53.751987447728844	-53.204892193848245	36194
76cfa1e269be93f6d545e9eb8d2ebf550be3e968	a robust feature extraction framework for face recognition	feature extraction kernel fractional step nonlinear discriminant analysis kf nda method fractional step linear discriminant analysis f lda method kernel nonlinear discriminant analysis k nda gabor transformed face images face recognition augmented gabor feature vector agfv gabor wavelet representations;gabor transform;robustness feature extraction face recognition linear discriminant analysis kernel nails educational institutions computer science image analysis wavelet analysis;linear discriminate analysis;discriminant analysis;wavelet transforms;feature vector;face recognition;local features;image representation;feature extraction;orientation selectivity;spatial locality;gabor wavelets;image representation face recognition feature extraction wavelet transforms	The kernel fractional-stop nonlinear discriminant analysis (KF-NDA) method not only extends the fractional-step linear discriminant analysis (F-LDA) method to a nonlinear version, but also further improves the generalization ability of traditional kernel nonlinear discriminant analysis (K-NDA). On the other hand, the Gabor transformed face images exhibit strong characteristics of spatial locality, scale and orientation selectivity, similar to those displayed by Gabor wavelets. Such characteristics produce salient local features that are most suitable for face recognition (FR). Hence, the augmented Gabor feature vector (AGFV) derived from a set of downsampled Gabor wavelet representations of face images is robust to the various of face images and simultaneously exhibits the more discriminatory information. Based on the AGFV and the KF-NDA, a robust feature extraction framework, i.e., the Gabor KF-NDA (GKF-NDA), is proposed for FR. In this framework, the KF-NDA method is directly applied to extract the robust nonlinear feature from the AGFV. Experimental results tested on the popular databases show that the GKF-NDA is more effective than oilier existing FR approaches.	database;decimation (signal processing);emoticon;facial recognition system;feature extraction;feature vector;gabor wavelet;kalman filter;kernel (operating system);linear discriminant analysis;locality of reference;nonlinear system;principle of locality;selectivity (electronic)	Guang Dai;Yasutoshi Otani	2004	2004 International Conference on Image Processing, 2004. ICIP '04.	10.1109/ICIP.2004.1419762	facial recognition system;gabor transform;computer vision;kernel fisher discriminant analysis;feature vector;feature extraction;computer science;machine learning;pattern recognition;mathematics;linear discriminant analysis;gabor wavelet;wavelet transform	Vision	34.24866880833516	-58.07459974111044	36223
47159026a9da400de62ef9bd7d4fc4a11dd62938	a computational model for amodal completion	euler elastica;disocclusion;relatability;perception;visual completion;bayesian model	This paper presents a computational model to recover the most likely interpretation of the 3D scene structure from a planar image, where some objects may occlude others. The estimated scene interpretation is obtained by integrating some global and local cues and provides both the complete disoccluded objects that form the scene and their ordering according to depth. Our method first computes several distal scenes which are compatible with the proximal planar image. To compute these different hypothesized scenes, we propose a perceptually inspired object disocclusion method, which works by minimizing the Euler’s elastica as well as by incorporating the relatability of partially occluded contours and the convexity of the disoccluded objects. Then, to estimate the preferred scene, we rely on a Bayesian model and define probabilities taking into account the global complexity of the objects in the hypothesized scenes as well as the effort of bringing these objects in their relative position in the planar image, which is also measured by an Euler’s elastica-based quantity. The model is illustrated with numerical experiments on, both, synthetic and real images showing the ability of our model to reconstruct the occluded objects and the preferred perceptual order among them. We also present results on images of the Berkeley dataset with provided figure-ground ground-truth labeling.	bayesian network;computation;computational model;continuation;euler;experiment;ground truth;numerical analysis;probabilistic turing machine;synthetic intelligence	Maria Oliver;Gloria Haro;Mariella Dimiccoli;Baptiste Mazin;Coloma Ballester	2016	Journal of Mathematical Imaging and Vision	10.1007/s10851-016-0652-x	computer vision;artificial intelligence;mathematics;geometry;bayesian inference;perception	Vision	53.58059795419983	-52.71762364720302	36241
394ea0e7730b5386545c826041ddf0d9c1c0be9d	a contrario detection of good continuation of points	good continuation detection;curves;gestalt;points;floyd warshall algorithm contrario detection good point continuation smooth curve gestalt theory clustering points;statistical analysis edge detection pattern clustering;a contrario good continuation detection points curves gestalt;organizations noise measurement psychology robustness visualization tensile stress noise;a contrario	We will consider the problem of detecting configurations of points regularly spaced and lying on a smooth curve. This corresponds to the notion of good continuation introduced in the Gestalt theory. We present a robust algorithm for clustering points along such curves, whilst at the same time discarding noisy samples. Based on the a contrario methodology, the detector builds upon a simple, symmetric primitive for a triplet of points, and finds statistically meaningful chains of such triplets. An efficient implementation is proposed using the Floyd-Warshall algorithm. Experiments on synthetic and real data show that the method is able to identify the perceptually relevant configuration of points in good continuation.	cluster analysis;continuation;dhrystone;experiment;floyd–warshall algorithm;gestalt psychology;sensor;triplet state;while	José Lezama;Rafael Grompone von Gioi;Gregory Randall;Jean-Michel Morel	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7025964	computer vision;mathematical optimization;mathematics;point;algorithm;gestalt psychology	Robotics	42.82851103828554	-63.57639009371966	36355
90e874614a7a7926b5d346b64de43b82b73bf319	wearable heading estimation for motion tracking in health care by adaptive fusion of visual–inertial measurements		The increasing demand for health informatics has become a far-reaching trend in the aging society. The utilization of wearable sensors enables monitoring senior people daily activities in free-living environments, conveniently and effectively. Among the primary health-care sensing categories, the wearable visual–inertial modality for human motion tracking, gradually exerts promising potentials. In this paper, we present a novel wearable heading estimation strategy to track the movements of human limbs. It adaptively fuses inertial measurements with visual features following locality constraints. Body movements are classified into two types: general motion (which consists of both rotation and translation) or degenerate motion (which consists of only rotation). A specific number of feature correspondences between camera frames are adaptively chosen to satisfy both the feature descriptor similarity constraint and the locality constraint. The selected feature correspondences and inertial quaternions are employed to calculate the initial pose, followed by the coarse-to-fine procedure to iteratively remove visual outliers. Eventually, the ultimate heading is optimized using the correct feature matches. The proposed method has been thoroughly evaluated on the straight-line, rotatory, and ambulatory movement scenarios. As the system is lightweight and requires small computational resources, it enables effective and unobtrusive human motion monitoring, especially for the senior citizens in the long-term rehabilitation.	abnormal degeneration;body dysmorphic disorders;categories;classification;clinical informatics;computational resource;course (navigation);frame (physical object);informatics (discipline);kinesiology;limb structure;locality of reference;modality (human–computer interaction);movement;visual descriptor;wearable computer;physical hard work;sensor (device);zinc pyrithione 10 mg/ml medicated shampoo	Yinlong Zhang;Wei Liang;Hongsheng He;Jindong Tan	2018	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2018.2795006	computer vision;wearable computer;artificial intelligence;locality;inertial frame of reference;pattern recognition;computer science;match moving	Vision	26.345329479411944	-69.17080132706155	36371
0910f65b415b59e753579dcddf244b9ef5ca3199	morphological operations on polygons using straight skeletons for digital pathology		In the context Digital Pathology, this work presents an efficient implementation of vector-based mathematical morphological operators applied to simple polygons. We achieve this by performing wavefront propagation and computing polygon straight skeletons. We present several applications of this method on histo-pathological images.	mathematical morphology;software propagation;straight skeleton;unit propagation	Daniel Felipe Gonzalez Obando;Jean-Christophe Olivo-Marin;Vannary Meas-Yedid	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363826	computer vision;operator (computer programming);computer science;artificial intelligence;wavefront;polygon;digital pathology	Arch	45.48867781365379	-74.2029951035048	36418
7c622df16f06d9f1c1af7262e91c54906e1b7e0e	locating facial features and pose estimation using a 3d shape model	large scale;3d model;driver monitoring;facial features;face;shape modeling;quantitative evaluation;normalized cross correlation;pose estimation	We present an automatic method for locating facial features and estimating head pose in 2D images and video using a 3D shape model and local view-based texture patches. After automatic initialization, the 3D pose and shape are refined iteratively to optimize the match between the appearance predicted by the model, and the image. The local texture patches are generated using the current 3D pose and shape, and the locations of model points are refined by neighbourhood search, using normalized cross-correlation to provide some robustness to illumination. A key aspect is the presentation of a large-scale quantitative evaluation, comparing the method to a well-established 2D approach. We show that the accuracy of feature location for the 3D system is comparable to that of the 2D system for near-frontal faces, but significantly better for sequences which involve large rotations, obtaining estimates of pose to within 10o at headings of up to 70o.	3d pose estimation;cross-correlation	Angela Caunce;David Cristinacce;Christopher J. Taylor;Timothy F. Cootes	2009		10.1007/978-3-642-10331-5_70	face;computer vision;pose;3d pose estimation;cross-correlation;machine learning;pattern recognition	Vision	43.96543039431163	-53.337474902832966	36427
3506b6099eca244f5ec056c23b3d599ce84bc520	detector of image orientation based on borda count	image processing;support vector machines;image orientation detection;combination rule;low level features;image orientation;automatic detection;borda count;detection algorithm;support vector machine	Accurately and automatically detecting image orientation is a task of great importance in intelligent image processing. In this paper, we present an automatic image orientation detection algorithm based on low-level features: color moments; Harris corner; phase symmetry; edge direction histogram. Support vector machines, statistical classifiers, parzen window classifiers are used in our approach: we use Borda Count as combination rule for these classifiers. Large amounts of experiments have been conducted, on a database of more than 6000 images of real photos, to validate our approach. Discussions and future directions for this work are also addressed at the end of the paper.		Alessandra Lumini;Loris Nanni	2006	Pattern Recognition Letters	10.1016/j.patrec.2005.08.023	support vector machine;computer vision;feature detection;image processing;computer science;machine learning;pattern recognition	Vision	32.81717118526831	-56.42627224926913	36505
583b87cd63ca896ccd9aabb2bc1e31ac1e878792	semi-supervised learning of deep difference features for facial expression recognition		Facial expression recognition (FER) is an important means of detecting human emotions and is widely applied in many fields, such as affective computing and human-computer interaction. Currently, several methods for FER heavily rely on large amounts of manually labeled data, which are costly and not available in real-world applications. To address this problem, this paper proposes a semi-supervised method based on the deep difference features. First, a cascaded structure is introduced to the original safe semi-supervised SVM (S4VM) to solve the multi-classification task. Then, multiple deep different features are fed to the cascaded S4VM to train the six basic facial expressions using the information of the unlabeled data safely. Extensive experiments show that the proposed method achieved encouraging results on public databases even when using a small labeled sample set.	semi-supervised learning;semiconductor industry;supervised learning	Can Xu;Ruyi Xu;Jingying Chen;Leyuan Liu	2018		10.1007/978-3-030-03338-5_21	labeled data;semi-supervised learning;support vector machine;deep learning;affective computing;facial expression;computer science;artificial intelligence;pattern recognition	Vision	26.541098835526903	-54.51342251392492	36528
9fc2ea1c875eeb9bdc223ae9050c4e0a07f78d45	quantifying progression of multiple sclerosis via classification of depth videos	610 medicine health	This paper presents new learning-based techniques for measuring disease progression in Multiple Sclerosis (MS) patients. Our system aims to augment conventional neurological examinations by adding quantitative evidence of disease progression. An off-the-shelf depth camera is used to image the patient at the examination, during which he/she is asked to perform carefully selected movements. Our algorithms then automatically analyze the videos, assessing the quality of each movement and classifying them as healthy or non-healthy. Our contribution is three-fold: We i) introduce ensembles of randomized SVM classifiers and compare them with decision forests on the task of depth video classification; ii) demonstrate automatic selection of discriminative landmarks in the depth videos, showing their clinical relevance; iii) validate our classification algorithms quantitatively on a new dataset of 1041 videos of both MS patients and healthy volunteers. We achieve average Dice scores well in excess of the 80% mark, confirming the validity of our approach in practical applications. Our results suggest that this technique could be fruitful for depth-camera supported clinical assessments for a range of conditions.	classification;color gradient;decision trees;decision tree;eighty;evaluation procedure;forests;fuse device component;inference;movement;multiple sclerosis;offset binary;ordinal position;ordinal data;patients;preparation;progressive disease;randomized algorithm;relevance;silo (dataset);temporal lobe;trees (plant);video recording;nervous system disorder;videocassette	Peter Kontschieder;Jonas F. Dorn;Cecily Morrison;Robert Corish;Darko Zikic;Abigail Sellen;Marcus D'Souza;Christian Philipp Kamm;Jessica Burggraaff;Prejaas Tewarie;Thomas Vogel;Michela Azzarito;Ben Glocker;Peter Chin;Frank Dahlke;Chris Polman;Ludwig Kappos;Bernard M. J. Uitdehaag;Antonio Criminisi	2014	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-319-10470-6_54	computer vision;simulation;medicine;computer science;artificial intelligence;machine learning;data mining;mathematics;statistics	Vision	26.32279448560788	-78.89428044966768	36604
7bb5c3d3479fa2af3b83155d3a6cc860be2ae4ea	a new approach of 3d watermarking based on image segmentation	watermarking;topology;remeshing 3d watermarking image segmentation rst transformations smoothing additive random noise cropping;image segmentation;remeshing;watermarking image segmentation;geometry;additive noise;additive random noise;resists;noise robustness;smoothing methods;3d watermarking;three dimensional displays;smoothing;classification algorithms;cropping;robustness;floods;strips;signal to noise ratio;rst transformations;noise;watermarking three dimensional displays robustness image segmentation signal to noise ratio classification algorithms noise	In this paper, a robust 3D triangular mesh watermarking algorithm based on 3D segmentation is proposed. In this algorithm three classes of watermarking are combined. First, we segment the original image to many different regions. Then we mark every type of region with the corresponding algorithm based on their curvature value. The experiments show that our watermarking is robust against numerous attacks including RST transformations, smoothing, additive random noise, cropping, simplification and remeshing.	algorithm;digital watermarking;experiment;image segmentation;intel matrix raid;level of detail;noise (electronics);polygon mesh;smoothing;utility functions on indivisible goods	Saoussen Ben Jabra;Ezzeddine Zagrouba	2008	2008 IEEE Symposium on Computers and Communications	10.1109/ISCC.2008.4625612	statistical classification;computer vision;strips;digital watermarking;computer science;cropping;noise;theoretical computer science;pattern recognition;resist;image segmentation;signal-to-noise ratio;robustness;smoothing	Vision	51.19446082069235	-67.32560776260765	36637
532236afc4ce666c205307b34cc6ae88ac41eaae	semantic segmentation of polarimetric sar imagery using conditional random fields	image segmentation training semantics pixel labeling feature extraction computational modeling;image segmentation;learning experience;polarimetric sar image;training;polarimetric sar;semantics;conditional random fields polarimetric sar semantic segmentation;conditional random fields;polsar;computational modeling;polsar semantic segmentation polarimetric sar image conditional random field;radar polarimetry;feature extraction;pixel;conditional random field;synthetic aperture radar radar polarimetry;semantic segmentation;labeling;synthetic aperture radar	The paper proposes a fast and accurate semantic segmentation approach for a large Polarimetric SAR (PolSAR) image using Conditional Random Fields (CRFs). It efficiently incorporates the polarimetric signatures, texture and intensity features into a unite CRFs model, and employs a fast max-margin training method for parameters learning. Experiments on RadarSat-2 PolSAR data in Flevoland test site demonstrate that our approach achieves precise segmentation results with a few well-selected training samples.	conditional random field;electronic signature;polarimetry;successive approximation adc;teaching method	Wen Yang;Xun Zhang;Lijun Chen;Hong Sun	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5652378	computer vision;computer science;machine learning;pattern recognition;semantics;conditional random field;remote sensing	Vision	31.178799524401327	-70.70004805225736	36639
0c4cfbc1ecc23575e9ffa3e871a514d601c182df	theoretical foundations of spatially-variant mathematical morphology part ii: gray-level images	geometrical theory;analisis imagen;linear systems;traitement signal;translation invariant;filtering;mathematical morphology;vision ordenador;computer vision spatially variant mathematical morphology gray level images euclidean space geometrical concept signal processing gray level erosion gray level dilation gray level opening gray level closing gray level morphological systems large class gray level operator gray level vertical translations maragos kernel representation translation invariant function processing systems upper semicontinuous v systems spatially variant linear systems nonlinear systems mathematical framework image processing systems spatially variant order rank filters linear time varying systems gray level sv mathematical morphology image analysis;gray level erosion;spatially variant mathematical morphology;kernel;representacion sistema;morfologia matematica;traduccion automatica;order statistic;gray level opening;analisis estadistico;image processing;linear time varying system;morphology kernel signal processing image processing image analysis nonlinear systems signal analysis filtering theory filters computational modeling;linear filter;espace euclidien;behavioral analysis;gray level dilation;theorie geometrique;analisis forma;filtering morphological;signal analysis;spatially variant linear systems;temps lineaire;systems engineering;filters;time varying systems;procesamiento imagen;gray level vertical translations;espacio euclidiano;morphological operation;intelligence artificielle;imagen nivel gris;gray level images;probabilistic approach;tiempo lineal;indexing terms;gray level sv mathematical morphology;filtro lineal;traitement image;time varying system;structure function;computer vision;noyau systeme exploitation;morphology;mathematical framework;nonlinear systems;computational modeling;time varying systems image colour analysis linear systems mathematical morphology nonlinear systems;traduction automatique;statistical analysis;filtre lineaire	In this paper, we develop a spatially-variant (SV) mathematical morphology theory for gray-level signals and images in the Euclidean space. The proposed theory preserves the geometrical concept of the structuring function, which provides the foundation of classical morphology and is essential in signal and image processing applications. We define the basic SV gray-level morphological operators (that is, SV gray-level erosion, dilation, opening, and closing) and investigate their properties. We demonstrate the ubiquity of SV gray-level morphological systems by deriving a kernel representation for a large class of systems, called V-systems, in terms of the basic SV gray-level morphological operators. A V-system is defined to be a gray-level operator, which is invariant under gray-level (vertical) translations. Particular attention is focused on the class of SV flat gray-level operators. The kernel representation for increasing V-systems is a generalization of Maragos' kernel representation for increasing and translation-invariant function-processing systems. A representation of V-systems in terms of their kernel elements is established for increasing and upper semicontinuous V-systems. This representation unifies a large class of spatially-variant-linear and nonlinear systems under the same mathematical framework. The theory is used for analyzing special cases of signal and image processing systems such as SV order rank filters and ' linear-time-varying systems. Finally, simulation results show the potential power of the general theory of gray-level SV mathematical morphology in several image analysis and computer vision applications.	angina pectoris, variant;closing (morphology);computer vision;dilation (morphology);erosion (morphology);foundations;generalization (psychology);grayscale;image analysis;image processing;kernel (operating system);language translations;mathematical morphology;mathematics;nonlinear system;opening (morphology);pathological dilatation;semi-continuity;simulation;systemverilog;time complexity	Nidhal Bouaynaya;Dan Schonfeld	2008	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2007.70756	filter;adaptive filter;kolmogorov structure function;time complexity;computer vision;kernel;order statistic;mathematical morphology;index term;image processing;nonlinear system;computer science;artificial intelligence;euclidean space;invariant;signal processing;linear filter;mathematics;geometry;linear system;computational model;semi-continuity;algorithm	Vision	50.73608181877931	-64.864309710224	36734
ff49c6bb4fe44e2cb29771e82b6c6a8ae334bdfa	place recognition of 3d landmarks based on geometric relations		Place recognition based on landmarks or features is an important problem occurring in localization, mapping, computer vision and point cloud processing. In this paper, we present GLAROT-3D, a translation and rotation invariant 3D signature based on geometric relations. The proposed method encodes into a histogram the pairwise relative positions of keypoint features extracted from 3D sensor data. Since it relies only on geometric properties and not on specific feature descriptors, it does not require any prior training or vocabulary construction and enables lightweight comparisons between landmark maps. The similarity of two point maps is computed as the distance between the corresponding rotated histograms to achieve rotation invariance. Histogram rotation is enabled by efficient orientation histogram based on sphere cubical projection. The performance of GLAROT has been assessed through experiments with standard benchmark datasets.	algorithm;bag-of-words model in computer vision;benchmark (computing);cloud computing;computer vision;experiment;feature recognition;for loop;internationalization and localization;map;point cloud;reference frame (video);simultaneous localization and mapping;vocabulary	Dario Lodi Rizzini	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8202220	artificial intelligence;invariant (physics);computer science;point cloud;computer vision;histogram;invariant (mathematics);pairwise comparison;vocabulary	Robotics	41.80711834824594	-55.4211118937846	36794
d5337bf0c37d149e89cbcdb33a19dd8259af80a5	geometric and photometric analysis for interactively recognizing multicolor or partially occluded objects	vision system;analisis imagen;image recognition;interfase usuario;object recognition;reconocimiento imagen;vision ordenador;vision robot;markets;image segmentation;image processing;occlusion;mercado;user interface;relacion hombre maquina;occultation;procesamiento imagen;oclusion;man machine relation;reconnaissance objet;robotics;segmentation;human robot interaction;traitement image;computer vision;user assistance;robot vision;reconocimiento voz;assistance utilisateur;photometry;marche;asistencia usuario;reconnaissance image;service robot;pattern recognition;robotica;speech recognition;ambiguity;interface utilisateur;photometrie;image analysis;vision ordinateur;robotique;relation homme machine;reconnaissance forme;reconnaissance parole;information system;reconocimiento patron;ocultacion;ambiguedad;analyse image;fotometria;systeme information;segmentacion;ambiguite;sistema informacion	An effective human-robot interaction is essential for wide penetration of service robots into the market. Such robots need vision systems to recognize objects. It is, however, difficult to realize vision systems that can work in various conditions. More robust techniques of object recognition and image segmentation are essential. Thus, we have proposed to use the human user's assistance for objects recognition through speech. Our previous system assumes that it can segment images without failure. However, if there are occluded objects and/or objects composed of multicolor parts, segmentation failures cannot be avoided. This paper presents an extended system that can recognize objects in occlusion and/or multicolor cases using geometric and photometric analysis of images. If the robot is not sure about the segmentation results, it asks questions of the user by appropriate expressions depending on the certainty to remove the ambiguity.	assistive technology;geometric analysis;hidden surface determination;human–robot interaction;image segmentation;interactivity;outline of object recognition;robot	Md. Altab Hossain;Rahmadi Kurnia;Yoshinori Kuno	2005		10.1007/11595755_17	computer vision;image analysis;simulation;occultation;photometry;image processing;computer science;cognitive neuroscience of visual object recognition;image segmentation;robotics;user interface;segmentation;information system	Robotics	47.582446873913796	-58.492249118010434	36816
6637137f90298b6582ce64361393f989d5ba4b72	simulating alteration on fingerprint images	perlin noise fingerprints alteration mutilation synthetic database;fingerprint recognition skin image matching fingers databases noise receivers;simulated altered fingerprint generation method fingerprint images fingerprint alteration biometric identification fingerprint mutilation papillary ridge structure destruction offender identity real world altered fingerprint database altered fingerprint detection public database synthetically altered fingerprints;visual databases fingerprint identification;fingerprint identification;visual databases	Fingerprint alteration represents one of the newest challenges in biometric identification. The aim of fingerprint mutilation is to destroy the structure of the papillary ridges so that the identity of the offender cannot be recognized by the biometric system. The problem has received little attention and there is a lack of a real world altered fingerprints database that would allow researchers to develop new algorithms and techniques for altered fingerprints detection. The major contribution of this paper is that it provides a new public database of synthetically altered fingerprints. Starting from the cases described in the literature, three methods for generating simulated altered fingerprints are proposed.	algorithm;biometrics;database;elasticity (data store);fingerprint;perlin noise;scar (physics);simulation	Adina Petrovici	2012	2012 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS) Proceedings	10.1109/BIOMS.2012.6345772	computer vision;geography;data mining;internet privacy	Vision	31.588463100864693	-62.96390896871062	36847
505655313fa3b4f57a3f9ae7669031d0a9a88d7b	online handwritten mathematical expressions recognition by merging multiple 1d interpretations	grammar;handwriting recognition;two dimensional displays;layout;blstm;online handwriting;merging;label graph;handwritten mathematical expression;text recognition	In this work, we propose to recognize handwritten mathematical expressions by merging multiple 1D sequences of labels produced by a sequence labeler. The proposed solution aims at rebuilding a 2D expression from several 1D labeled paths. An online math expression is a sequence of strokes which is later used to build a graph considering both temporal and spatial orders among these strokes. In this graph, node corresponds to stroke and edge denotes the relationship between a pair of strokes. Next, we select 1D paths from the built graph with the expectation that these paths could catch all the strokes and the relationships between pairs of strokes. As an advanced and strong sequence classifier, BLSTM networks are adopted to label the selected 1D paths. We set different weights to these 1D labeled paths and then merge them to rebuild a label graph. After that, an additional post-process will be performed to complete the edges automatically. We test the proposed solution and compare the results to the state of art in online math expression recognition domain.	algorithm;graph (discrete mathematics);ground truth;label printer applicator	Shaobo Zhang;Harold Mouchère;Christian Viard-Gaudin	2016	2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR)	10.1109/ICFHR.2016.0045	layout;speech recognition;computer science;machine learning;pattern recognition;grammar;handwriting recognition	Vision	35.203316714706055	-68.0549762636884	36857
5fedb6d3e5b248e0411635bd18fb3c2f48092f21	reasoning about edges in scale space	vision ordenador;representacion conocimientos;multiscale reasoning algorithm;restauration image;image processing;dato que falta;methode echelle multiple;edge detection;zero crossing images;edge detector;knowledge representation computer vision inference mechanisms;sistema informatico;procesamiento imagen;inference mechanisms;computer system;image restoration;metodo escala multiple;raisonnement;traitement image;computer vision;deteccion contorno;donnee manquante;detection contour;restauracion imagen;scale space;noise elimination;edge recovery;zero crossing images computer vision knowledge representation inference mechanisms noise elimination edges scale space edge detector multiscale reasoning algorithm edge recovery edge behavior edge curves;edge curves;razonamiento;vision ordinateur;multiscale method;systeme informatique;missing data;image edge detection detectors computer vision machine vision filtering optical filters problem solving home appliances performance evaluation detection algorithms;reasoning;knowledge representation;edges;representation connaissances;edge behavior;espace echelle	Explores the role of reasoning in early vision processing. In particular, the problem of detecting edges is addressed. The authors do not try to develop another edge detector, but rather, they study an edge detector rigorously to understand its behavior well enough to formulate a reasoning process that allow appliance of the detector judiciously to recover useful information. They present a multiscale reasoning algorithm for edge recovery: reasoning about edges in scale space (RESS). The knowledge in RESS is acquired from the theory of edge behavior in scale space and represented by a number of procedures. RESS recovers desired edge curves through a number of reasoning processes on zero crossing images at various scales. The knowledge of edge behavior in scale space enables RESS to select proper scale parameters, recover missing edges, eliminate noise or false edges, and correct the locations of edges. A brief evaluation of RESS is performed by comparing it with two well-known multistage edge detection algorithms. >	scale space	Yi Lu;Ramesh Jain	1992	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.126806	image restoration;edge;computer vision;scale space;edge detection;missing data;image processing;computer science;artificial intelligence;machine learning;mathematics;reason	Vision	53.01364651750389	-62.20619796934359	36872
a1daf5e64c5e1f5467d9f5784bd25a8c96b01f24	a shape constrained parametric active contour model for breast contour detection	sensitivity and specificity;female;breast active contours shape image reconstruction surgery force cancer;autologous tissue reconstruction shape constrained parametric active contour model breast contour detection breast morphology breast cancer survivor reconstructive surgery catenary curve mathematical shape constraint nipple areola scars anterior posterior photograph;imaging three dimensional;cancer;shape recognition cancer medical image processing photography;shape recognition;photography;breast;image enhancement;image interpretation computer assisted;medical image processing;reproducibility of results;artificial intelligence;algorithms;pattern recognition automated;humans;algorithms artificial intelligence breast female humans image enhancement image interpretation computer assisted imaging three dimensional pattern recognition automated photography reproducibility of results sensitivity and specificity	Quantitative measures of breast morphology can help a breast cancer survivor to understand outcomes of reconstructive surgeries. One bottleneck of quantifying breast morphology is that there are only a few reliable automation algorithms for detecting the breast contour. This study proposes a novel approach for detecting the breast contour, which is based on a parametric active contour model. In addition to employing the traditional parametric active contour model, the proposed approach enforces a mathematical shape constraint based on the catenary curve, which has been previously shown to capture the overall shape of the breast contour reliably [1]. The mathematical shape constraint regulates the evolution of the active contour and helps the contour evolve towards the breast, while minimizing the undesired effects of other structures such as, the nipple/areola and scars. The efficacy of the proposed approach was evaluated on anterior posterior photographs of women who underwent or were scheduled for breast reconstruction surgery including autologous tissue reconstruction. The proposed algorithm shows promising results for detecting the breast contour.	active contour model;breast;cancer survivor;cicatrix;contour line;galaxy morphological classification;large;mammaplasty;mammary neoplasms;mathematics;nipples;operative surgical procedures;reconstructive surgical procedures;schedule (document type);sensor;silo (dataset);tissue expansion devices;algorithm;photograph	Juhun Lee;Gautam S. Muralidhar;Gregory P. Reece;Mia K. Markey	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6346954	computer vision;medicine;computer science;engineering;artificial intelligence;photography;engineering drawing;surgery;cancer	Vision	40.993022611296844	-79.13208773370005	36875
513a6f76a96926e1f0807dcfed1777478e849dfa	minimum average-cost path for real time 3d coronary artery segmentation of ct images	coronary artery;ct image;computational cost;coronary artery segmentation;minimal path technique;average edge cost;macp model;efficient optimization;real time;image voxels;minimum spanning tree method;minimum average-cost path	In this paper, we propose a Minimum Average-cost Path (MACP) model for segmenting 3D coronary arteries by minimizing the average edge cost along path in discrete 4D graph constructed by image voxels and associated radii. Prim's Minimum Spanning Tree method is used for efficient optimization of the MACP model. The centerline and the radii of the cross sections of the coronary artery are extracted simultaneously during the optimization. The method does not need any image preprocessing steps and has been intensively validated as an effective approach with the Rotterdam Coronary Artery Algorithm Evaluation Framework. The computational cost of the proposed method is particularly low (7.467 seconds per segment, 18.5mm/s on average), which makes real time segmentation of coronary artery possible. Shortcut problem, which is a classic issue of the minimal path techniques, can also be overcome by the proposed method.	algorithmic efficiency;arterial system;ct scan;computation;extraction;graph - visual representation;keyboard shortcut;mathematical optimization;minimum spanning tree;preprocessor;prim's algorithm;segmentation action;voxel;biologic segmentation	Ning Zhu;Albert C. S. Chung	2011	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-23626-6_54	mathematical optimization;combinatorics;mathematics	Robotics	40.81655295037171	-77.32823974967361	36889
182cb782f4ff971ac4308bec22cc58f32b07ec1f	multi-test cervical cancer diagnosis with missing data estimation	cancer;cervix;medical diagnostics;cervical cancer	Cervical cancer is a leading most common type of cancer for women worldwide. Existing screening programs for cervical cancer suffer from low sensitivity. Using images of the cervix (cervigrams) as an aid in detecting pre-cancerous changes to the cervix has good potential to improve sensitivity and help reduce the number of cervical cancer cases. In this paper, we present a method that utilizes multi-modality information extracted from multiple tests of a patient’s visit to classify the patient visit to be either low-risk or high-risk. Our algorithm integrates image features and text features to make a diagnosis. We also present two strategies to estimate the missing values in text features: Image Classifier Supervised Mean Imputation (ICSMI) and Image Classifier Supervised Linear Interpolation (ICSLI). We evaluate our method on a large medical dataset and compare it with several alternative approaches. The results show that the proposed method with ICSLI strategy achieves the best result of 83.03% specificity and 76.36% sensitivity. When higher specificity is desired, our method can achieve 90% specificity with 62.12% sensitivity. © (2015) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	missing data	Tao Xu;Xiaolei Huang;Edward Kim;L. Rodney Long;Sameer K. Antani	2015		10.1117/12.2080871	data mining;cancer	Vision	34.13140725624165	-77.29206136908122	36924
b6e3b41495b3c3a89ed73e7b9adeb13a9998260e	using the generalized radon transform for detection of curves in noisy images	gaussian noise;radon transforms;radon transform;discrete transforms noise level digital images application software image processing computer vision image converters noise robustness vectors stacking;edge detection;digital image;parameter estimation;curve parameters detection generalized radon transform discrete radon transform gaussian noise noisy images digital images parameter domain thresholding algorithm threshold level numerical example;parameter estimation radon transforms edge detection gaussian noise	In this paper the discrete generalized Radon transform will be investigated as a tool for detection of curves in noisy digital images. The discrete generalized Radon transform maps an image into a parameter domain, where curves following a specific parameterized curve form will correspond to a peak in the parameter domain. A major advantage of the generalized Radon transform is that the curves are allowed to intersect. This enables a thresholding algorithm in the parameter domain for simultaneous detection of curve parameters. A threshold level based on the noise level in the image is derived. A numerical example is presented to illustrate the theory.	algorithm;digital image;map;noise (electronics);numerical analysis;thresholding (image processing)	Peter Aundal Toft	1996		10.1109/ICASSP.1996.545862	gaussian noise;hough transform;computer vision;mathematical optimization;radon transform;edge detection;computer science;mathematics;estimation theory;digital image;statistics	Vision	51.416171545060664	-66.0809448793809	37011
eea2e9e607efbc448a9cb1b5e60a657405953fe2	an algorithm for fingerprint identification based on wavelet transform and gabor feature	gabor feature;discrete wavelet transforms;image matching;wavelet transform fingerprint identification gabor feature;gabor filters;image texture;wavelet transforms;feature vector;wavelet transform;vectors;fingerprint recognition;wavelet transforms feature extraction fingerprint identification gabor filters image texture vectors;feature extraction;recognition rates fingerprint identification wavelet transform gabor feature sub images feature vectors fvc2004 databases texture information;fingerprint recognition wavelet transforms image matching feature extraction data mining image processing pattern matching genetics conference management image databases;fingerprint identification	This paper presents an algorithm for fingerprint identification based on wavelet transform and Gabor features. Firstly, a center point area of the fingerprint is detected, then the image in this area is decomposed into different sub-images using wavelet transform, finally we extract Gabor features from these sub-images to generate feature vectors for matching. The experiment conducted over the four FVC2004 databases shows that the proposed approach can capture much texture information at different scales and orientations, achieve high recognition rates.	algorithm;database;fingerprint;wavelet transform	Cheng Xu;Xin-Ming Cheng	2009	2009 Third International Conference on Genetic and Evolutionary Computing	10.1109/WGEC.2009.74	wavelet;gabor transform;computer vision;speech recognition;s transform;second-generation wavelet transform;continuous wavelet transform;computer science;machine learning;pattern recognition;cascade algorithm;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;gabor wavelet;wavelet transform	Robotics	35.511695471381415	-61.14432759379092	37033
9ce03c97ffdb429697d4ee7dce39df2c4a639dcb	autoedes: a model-based bayesian framework for automatic end-diastolic and end-systolic frame selection in angiographic image sequence	bayesian framework;bass;clinical data;automatic;background modeling;probability density;robalo;charpente;end diastole;left ventricular;automatico;bar poisson;angiography;modelo;extremite;automatic detection;end;image sequence;extremidad;clinical practice;graphical model;automatique;secuencia imagen;modele;angiographie;modeling;angiografia;models;armadura;sequence image;framework;end systole;x rays	This paper presents a novel approach to automatically detect the end-diastolic (ED) and end-systolic (ES) frames from an X-ray left ventricular angiographical image sequence. ED and ES image detection is the first step for widely used left ventricular analysis in catheterization lab. However, due to the inherent difficulties of X-ray angiographical image, automatic ED and ES frame selection is a challenging task and still remains unsolved. The current clinical practice uses manual selection, which is not only time consuming but also sensitive to different persons at different time. In this paper, we propose to formulate the X-ray angiogram by a dynamical graphical model. Then the posterior density of the left ventricular state is estimated by using Bayesian probability density propagation and adaptive background modeling. Preliminary experimental results have demonstrated the superior performance of the proposed algorithm on clinical data.	algorithm;graphical model;signal processing;software propagation	Wei Qu;Sukhveer Singh;Mike Keller	2008		10.1117/12.769693	end;bass;probability density function;simulation;systems modeling;computer science;artificial intelligence;software framework;graphical model;automatic transmission	Vision	46.183060049670196	-78.66313394622522	37062
3c23bd9f458d922a6cb5cc493a9220af41688d28	fingerprint recognition using wavelet domain features	finterprint recognition;shannon entropy;image matching;standard deviation;wavelet transformation finterprint recognition feature extraction;reference point;wavelet transforms;feature vector;wavelet transform;fingerprint recognition;feature extraction;region of interest;fvc2002 database wavelet domain features minutiae based method image based fingerprint recognition method wavelet transformation features extraction region of interest roi reference point location rotation alignment location fingerprint matching euclidian distance feature vector extraction mean energy standard deviation shannon entropy;fingerprint recognition image matching feature extraction wavelet transforms gabor filters vectors databases;entropy;wavelet transforms entropy feature extraction fingerprint identification image matching;wavelet transformation;fingerprint identification	Image-based and minutiae-based are two major methods of fingerprint recognition. In this work, we presented an image-based fingerprint recognition method by using wavelet transformation and this method is efficient even for low quality fingerprint. The features extraction of the proposed method differing with previous wavelet methods is based on the blocks of enhanced region of interest (ROI). The alignment is required to build ROI including location the reference point and rotation alignment. Fingerprint matching was performed on simply Euclidian distance of feature vector extracted from wavelet domain. These features consist of mean energy, standard deviation and Shannon entropy for the purpose of making these features more discriminative. The good recognition accuracy was achieved on the FVC2002 database.	computational complexity theory;entropy (information theory);euclidean distance;feature vector;fingerprint recognition;hamming distance;minutiae;region of interest;shannon (unit);wavelet transform	Ting Tang	2012	2012 8th International Conference on Natural Computation	10.1109/ICNC.2012.6234738	computer vision;speech recognition;pattern recognition;mathematics	Vision	35.01353379569991	-61.30333059046865	37079
068424c07824c2f9fa942f1a3d2cb28c535e572d	optimization and interpolation for distorted contour estimation	array processing;optimisation;interpolation;interpolation method optimization interpolation distorted contour estimation image processing array processing wavefront distortions canceling distorted curves retrieval global optimization algorithm;image processing;optimal method;wavefront distortions canceling;optimisation image processing image retrieval interpolation;interpolation method;distorted curves retrieval;interpolation acoustic distortion optimization methods array signal processing phase distortion image retrieval image processing signal generators sensor arrays signal processing;fast algorithm;satellite image;global optimization algorithm;global optimization;optimization;distorted contour estimation;image retrieval	Distorted curves retrieval is faced for robotic way screening, particle trajectory characterization, aerial and satellite image analysis. This image processing problem has been transposed to an array processing problem by adopting specific conventions. Some solutions for wavefront distortions canceling have already been proposed. In this paper we aim at improving an existing method for distorted curves retrieval, making use of a global optimization algorithm. We show that it is possible to combine an optimization method to an interpolation method in order to obtain a reliable and fast algorithm	aerial photography;algorithm;array processing;contour line;distortion;global optimization;image analysis;image processing;interpolation;mathematical optimization;robot	Salah Bourennane;Julien Marot	2006	2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings	10.1109/ICASSP.2006.1660443	computer vision;mathematical optimization;image processing;image retrieval;interpolation;computer science;machine learning;mathematics;global optimization	Robotics	52.68807531986162	-60.05336888604463	37099
26cc49b2203ad3b572ebb348dc32bf38cf2b88c7	3-d object pose estimation by shading and edge data fusion - simulating virtual manipulation on mental images	3d object pose estimation shading edge data fusion virtual manipulation stimulation mental images model matching virtual manipulation human recognition scheme shading image nonlinear least squares method edge information robustness pose estimation model matching techniques geometrical features vertices edges;virtual manipulation;object recognition;motion estimation object recognition image matching image enhancement;image matching;linear least square;motion estimation;data fusion;geometric feature;object recognition image matching image enhancement motion estimation;image enhancement;image matching humans image recognition object recognition image segmentation solid modeling surface reconstruction shape cameras computer vision;edges 3d object pose estimation shading edge data fusion virtual manipulation stimulation mental images model matching virtual manipulation human recognition scheme shading image nonlinear least squares method edge information robustness pose estimation model matching techniques geometrical features vertices;3 d object;model matching;shading and edge data fusion;non linear least squares method;object model;pose estimation	Human beings seem to recognize objects based on a kind of model-matching, i.e., a virtual manipulation on mental images. This paper presents a 3 0 object pose estimation method simulating the human recognition scheme. Computer synthesizes not only an edge image but also a shading image from an object model. Then, it matches the two kinds of synthesized images with the inputted images individually by using a non-linear leastsquares method, and estimates the pose parameter values. Finally, it chooses the better of the individually estimated poses. Thus, the fusion of the shading and the edge information is achieved. Since the two pieces of information complement each other, this method has the advantage of much higher robustness and accuracy of pose estimation than ordinary model-matching techniques which rely only on geometrical features such as vertices or edges.	3d pose estimation;nonlinear system;shading;simulation	Yoshihiko Nomura;Dili Zhang;Yuko Sakaida;Seizo Fujii	1996		10.1109/CVPR.1996.517173	computer vision;pose;object model;3d pose estimation;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;motion estimation;articulated body pose estimation;mathematics;sensor fusion	Vision	47.966241296883695	-52.14333919503182	37103
1db81adcbf783eb865e3ff1e23f924379698f2f5	improved fuzzy snakes applied to biometric verification problems	pattern size;image recognition;snakes;fuzzy snakes;handwriting recognition;biometrics access control;palmprint lines;off line verification problem;input variables;pattern shape;fuzzy rules;signature verification;biometrics fuzzy sets shape control testing fuzzy control intelligent systems fuzzy systems veins handwriting recognition physics computing;variable length interconnected lines;biometrics;biological system modeling;biomedical imaging;image representation biometrics access control feature extraction fuzzy set theory image recognition;data mining;fuzzy set theory;energy function;shape memory;computational modeling;shape;image representation;feature extraction;pattern orientation;palmprints;palmprints snakes biometrics off line verification problem handwritten signatures;stroke point fuzzy snakes biometric verification problem biometric pattern representation variable length interconnected lines handwriting signature strokes palmprint lines infrared hand vein data pattern size pattern shape pattern orientation fuzzy shape memory snake model;infrared hand vein data;infrared;biometric verification problem;handwriting signature strokes;stroke point;handwritten signatures;fuzzy shape memory snake model;biometric pattern representation	Some types of biometric patterns can be represented as a collection of variable-length interconnected lines. This is the case of handwriting signature strokes, palmprint lines or infrared hand vein data. Typical variations in size, shape and orientation of these patterns for the same person make difficult to develop reliable biometric verification systems for them. Fuzzy snakes have been successfully applied to the off-line signature verification problem where the corresponding energy function is described by a set of fuzzy rules. In this paper, we extend the fuzzy shape-memory snake model by introducing a new external energy term: the difference between the angle of the tangent to the snake in a control point and the angle of the tangent to a specific stroke point (for all the strokes of the test pattern). Experimental results for both off-line signature and palmprint verifications have shown that the new fuzzy approach outperforms other snake models.	biometrics;control point (mathematics);fingerprint;fuzzy logic;mathematical optimization;online and offline;test card	J. Velez;Abraham Sánchez;F. Fernandez	2009	2009 Ninth International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2009.81	computer vision;infrared;feature extraction;shape;computer science;shape-memory alloy;machine learning;pattern recognition;handwriting recognition;fuzzy set;computational model;biometrics	Robotics	41.743348770728595	-57.881626811107544	37123
4d189d4f99f10a63f12636c0e67849fb59bf8b04	asymmetry computing for cholesteatoma detection based on 3-d ct images	numerical calculation	Cholesteatoma is a destructive and expanding sac in the middle ear and/or mastoid process. If untreated, cholesteatoma can result in nerve deterioration, deafness, imbalance and vertigo. Traditional diagnose methods rely on doctors' experience and often misdiagnosed. In this paper, we propose a novel asymmetry-computing algorithm for cholesteatoma detection based on 3-D CT images. By applying this algorithm, we provide a complete numerical calculation framework and its simulation. The proposed algorithm is tested on real 3-D eardrum CT images. The diagnose accuracy rate of cholesteatoma is 72.73%, and the misdiagnose rate is only 27.27%. The result demonstrates the applicability of the proposed asymmetry-computing algorithm for cholesteatoma detection. Therefore the proposed algorithm is beneficial for clinic diagnose.		Anping Song;Guangtai Ding;Wu Zhang	2007		10.1007/978-3-540-74769-7_83	medicine;pathology;audiology;surgery	Vision	37.29086930203037	-79.10379865260562	37133
7537f7c89c1cbe267cf047b991c72be3386c1e47	real-time rolled fingerprint construction based on key-column extraction	image mosaic;key-column extraction;rolled fingerprint	Fingerprint identification is an important biometric method for personal authentication. Rolled fingerprint can provide much more information than flat fingerprint, so the method is needed for construct a rolled fingerprint from a plain fingerprint sequence. Based on Key-column extraction, a real-time image mosaicking algorithm is proposed for rolled fingerprint construction. Compared to other construction methods, experimental results show that the proposed algorithm leads to a better performance, especially when the finger is rolling with a fast speed. © Springer International Publishing 2013.	fingerprint;real-time transcription	Yongliang Zhang;Shanshan Fang;Yingjie Bian;Yuanhong Li	2013		10.1007/978-3-319-02961-0_25	computer vision;fingerprint;artificial intelligence;biometrics;authentication;computer science	Crypto	34.31831601100178	-62.678018805342184	37142
744508cc612e28056b6079da074aae2ea788ac5d	tongue line extraction	detectors;kernel;uneven lighting conditions tongue line extraction traditional chinese tongue diagnosis wide line detector;surface roughness;rough surfaces;brightness;feature extraction;medical image processing;pixel;clinical practice;tongue;rough surface;tongue shape detectors rough surfaces surface roughness kernel nonlinear filters biometrics computer science noise shaping;medical image processing feature extraction	Tongue line refers to the surface of the tongue covered with fissures or lines in deep or shallow shape and is one type of important features in clinical practice of Traditional Chinese Tongue Diagnosis (TCTD). However, it is hard to extract tongue lines completely due to the large variation of the widths of tongue lines and the strong noise caused by the rough surface of tongue and uneven illumination. In this paper, an improved wide line detector (WLD) is presented for tongue line extraction. Based on the characteristics of tongue lines, the original WLD is improved to avoid the undesired separation of a wide line and the influence of uneven lighting conditions. The proposed method has been tested on a total of 286 tongue line images and our experimental results demonstrate that the improved WLD significantly outperforms the original WLD for tongue line extraction by improving the TPR 16.5%, FPR 44.6% and PM 33.4%, respectively.	film-type patterned retarder	Laura Li Liu;David Zhang;Ajay Kumar;Xiangqian Wu	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761651	computer vision;detector;kernel;speech recognition;surface roughness;feature extraction;computer science;machine learning;brightness;pixel	Vision	37.523759988875426	-69.2428342564283	37222
b1285ea68ff90c8a08e5614136f2a0d0057dfa83	commute time guided transformation for feature extraction	manifold learning;commute time;face recognition;random walk;feature extraction	1077-3142/$ see front matter Crown Copyright 2 doi:10.1016/j.cviu.2011.11.002 ⇑ Corresponding author. Address: Room 725, Cen University, Beijing 100084, China. Fax: +86 10 62788 E-mail address: qionghaidai@tsinghua.edu.cn (Q. D This paper presents a random-walk-based feature extraction method called commute time guided transformation (CTG) in the graph embedding framework. The paper contributes to the corresponding field in two aspects. First, it introduces the usage of a robust probability metric, i.e., the commute time (CT), to extract visual features for face recognition via a manifold way. Second, the paper designs the CTG optimization to find linear orthogonal projections that would implicitly preserve the commute time of high dimensional data in a low dimensional subspace. Compared with previous CT embedding algorithms, the proposed CTG is a graph-independent method. Existing CT embedding methods are graph-dependent that could only embed the data on the training graph in the subspace. Differently, CTG paradigm can be used to project the out-of-sample data into the same embedding space as the training graph. Moreover, CTG projections are robust to the graph topology that it can always achieve good recognition performance in spite of different initial graph structures. Owing to these positive properties, when applied to face recognition, the proposed CTG method outperforms other state-of-the-art algorithms on benchmark datasets. Specifically, it is much efficient and effective to recognize faces with noise. Crown Copyright 2011 Published by Elsevier Inc. All rights reserved.	algorithm;benchmark (computing);crown group;facial recognition system;fax;feature extraction;graph embedding;image noise;mail (macos);mathematical optimization;performance;programming paradigm;topological graph theory	Yue Deng;Qionghai Dai;Ruiping Wang;Zengke Zhang	2012	Computer Vision and Image Understanding	10.1016/j.cviu.2011.11.002	facial recognition system;computer vision;feature extraction;computer science;machine learning;pattern recognition;mathematics;nonlinear dimensionality reduction;random walk	AI	34.19051954542006	-57.275213891130086	37252
b41c63979782297a005721e0360ddd50acb43d54	particle pollution estimation from images using convolutional neural network and weather features		Airborne particulate matter with a diameter less than 2.5 micrometers $(\mathrm{PM}_{2.5})$ is one of the most harmful air pollutants, because $\mathrm{PM}_{2.5}$ can be inhaled into human body and cause serious health problems by transmitting hazardous chemicals deeply into lung and bloodstream. A reliable, easily accessible, and low-cost $\mathrm{PM}_{2.5}$ monitoring system can greatly help people raise public awareness of $\mathrm{PM}_{2.5}$ and reduce health hazards of air pollution. In this paper, we combine image and weather information to estimate $\mathrm{PM}_{2.5}$ indices of outdoor images using deep learning and support vector regression (SVR) techniques. The proposed method first uses a convolutional neural network (CNN) to predict the $\mathrm{PM}_{2.5}$ index based on image information, and then the $\mathrm{PM}_{2.5}$ predicted by CNN and two weather features, humidity and wind speed, are combined to yield final estimated $\mathrm{PM}_{2.5}$ index using a created SVR model. We assessed our method using two datasets collected from Shanghai City and Beijing City in China and experimental results demonstrated the effectiveness of the proposed method for $\mathrm{PM}_{2.5}$ estimation.		Qirong Bo;Wenwen Yang;Nabin Rijal;Yilin Xie;Jun Feng;Jing Zhang	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451306	convolutional neural network;mathematical analysis;pattern recognition;artificial intelligence;computer science	Robotics	34.12588314251212	-70.55876378993166	37283
2005d47d638559b1ea2cb7543006ddf4c0dd66ed	elastic registration based on matrix-valued spline functions and direct integration of landmarks and intensities	brain;matrices	We introduce a new approach for spline-based elastic registration using both point landmarks and intensity information. With this approach, both types of information and a regularization based on the Navier equation are directly integrated in a single energy minimizing functional. For this functional, we have derived an analytic solution, which is based on matrix-valued non-radial basis functions. Our approach can cope with monomodal and multimodal images. For the latter case, we have integrated a computationally efficient analytic similarity measure. We have successfully applied our approach to synthetic images, phantom images, and MR images of the human brain.		Stefan Wörz;Andreas Biesdorf;Karl Rohr	2012		10.1117/12.911414	computer vision;mathematical optimization;physics;matrix	Vision	47.515095619849866	-76.65997501340917	37295
d32f39a271759e15986ef9dc57f07b30f291c296	texture classification by multi-model feature integration using bayesian networks	bayesian network;bayesian network classifier;confidence measure;texture classification;gaussian markov random field;image texture;statistical properties;gabor filter;feature integration;bayesian networks	In this paper, a texture classification method based on multi-model feature integration by Bayesian networks is proposed. Considering that many image textures exhibit both structural and statistical properties, two feature sets based on two texture models––the Gabor model and the Gaussian Markov random field model are used to describe the image properties in both structure and statistics. A Bayesian network classifier is then used to combine these two sets of features along with their individual confidence measures for texture classification. Seventy eight Brodatz textures were used to evaluate the classification performance. The results show that the proposed method is better than that using a single set of features from either model for texture classification. 2002 Elsevier Science B.V. All rights reserved.	bayesian network;bayesian programming;feature integration theory;gabor filter;image texture;markov chain;markov random field;textures: a photographic album for artists and designers	Yong Huang;Kap Luk Chan;Zhihua Zhang	2003	Pattern Recognition Letters	10.1016/S0167-8655(02)00263-5	computer vision;variable-order bayesian network;computer science;machine learning;pattern recognition;bayesian network;mathematics	Vision	40.59851276553208	-62.69186589222404	37370
259fb03511c9ecb06b7865221166c1c930116ee5	fam-based fuzzy inference for detecting shot transitions	frames per second;image numerique;memoire associative;fuzzy set;logique floue;conjunto difuso;logica difusa;ensemble flou;fuzzy logic;senal video;signal video;fuzzy inference;imagen numerica;inferencia;associative memory;video signal;memoria asociativa;digital image;inference	We describe a fuzzy inference approach for detecting and classifying shot transitions in video sequences. Our approach basically extends FAM(Fuzzy Associative Memory) to detect and classify shot transitions, including cuts, fades and dissolves. We consider a set of feature values that characterize differences between two consecutive frames as input fuzzy sets, and the types of shot transitions as output fuzzy sets. An initial implementation runs at approximately 7 frames per second on PC and yields promising results.	fuzzy associative matrix;sensor	Seok-Woo Jang;Gye-Young Kim;Hyung-Il Choi	2001		10.1007/3-540-44596-X_5	fuzzy logic;computer vision;computer science;artificial intelligence;machine learning;mathematics;fuzzy set;frame rate;digital image;algorithm	NLP	45.60423873203122	-57.3672489629792	37373
56cbeeb67933677243e3a15ea2943d86110f94c6	hierarchical age estimation with dissimilarity-based classification	age progression;biometrics;active appearance model;age estimation;ensemble classifiers	This paper proposes a novel approach that models the process of aging using Active Appearance Models (AAMs) and Ensemble of Classifiers for Age Estimation. The approach treats the problem of age estimation as a combination of classification and regression problems. In this approach, face image is encoded using the statistically driven AAMs which uses both shape and appearance models to form a combined model to represent the face image as a feature vector. A global classifier is then used to obtain a rough idea about the age by distinguishing between child/teen-hood and adulthood, while final age estimation is made using regression functions. To reduce misclassification error, an ensemble containing various classifiers trained on multiple dissimilarities has been used. The images thus classified are passed on to different aging functions for further accurate age estimation.#R##N##R##N#Experiments have been performed on the publicly available FG-NET database and the Center for Vital Longevity Face Database to test the approach. It has been observed that the proposed approach has the lowest Mean Absolute Error (MAE) and the highest Cumulative Score when compared with other published results. It is further tested on IIT Kanpur database consisting of images of age group 18–34 acquired under semi-controlled environment.		Sharad Kohli;Surya Prakash;Phalguni Gupta	2013	Neurocomputing	10.1016/j.neucom.2012.08.069	active appearance model;computer science;machine learning;pattern recognition;data mining;biometrics;statistics	NLP	28.438881147355122	-58.8699838482624	37384
99d40039b043c7f18ee288dc08987b72d091f827	color clustering text extraction algorithm for mobile phone images			algorithm;mobile phone	Adrián Canedo-Rodriguez;Jung Hyoun Kim;John C. Kelly;Jung Hee Kim;Soo-Hyung Kim;Yolanda Blanco-Fernández;Pavan Banugondi	2010			mobile phone;cluster analysis;artificial intelligence;pattern recognition;computer science	ML	37.3675820131197	-65.25242681692785	37403
c6bef45ab9a3c1ce6d7f19ba028671b7448f28a0	a flexible similarity measure for 3d shapes recognition	shape measurement object recognition solid modeling topology spatial databases humans histograms noise robustness testing noise shaping;similarity metric;topology;object recognition;range data;shape recognition;partial information;indexing terms;index terms computer vision;3d object recognition;computer vision;computational geometry flexible similarity 3d shapes recognition 3d objects recognition modeling wave topology 3d objects modeling meshes cone curvature mesh model occlusion conditions pattern recognition;pattern recognition index terms computer vision feature measurement object recognition similarity measures;pattern recognition;similarity measures;image denoising object recognition computer vision topology mesh generation;image denoising;algorithms artificial intelligence cluster analysis computer graphics computer simulation image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval numerical analysis computer assisted pattern recognition automated reproducibility of results sensitivity and specificity signal processing computer assisted subtraction technique user computer interface;mesh generation;similarity measure;feature measurement;object model	This paper is devoted to presenting a new strategy for 3D objects recognition using a flexible similarity measure based on the recent modeling wave (MW) topology in spherical models. MW topology allows us to establish an n-connectivity relationship in 3D objects modeling meshes. Using the complete object model, a study on considering different partial information of the model has been carried out to recognize an object. For this, we have introduced a new feature called cone-curvature (CC), which originates from the MW concept. CC gives an extended geometrical surroundings knowledge for every node of the mesh model and allows us to define a robust and adaptable similarity measure between objects for a specific model database. The defined similarity metric has been successfully tested in our lab using range data of a wide variety of 3D shapes. Finally, we show the applicability of our method presenting experimentation for recognition on noise and occlusion conditions in complex scenes.	3d modeling;acclimatization;anatomic node;anatomy, regional;aspartate transaminase;cluster analysis;computer stereo vision;computer vision;cone-rod dystrophies;distance;hidden surface determination;matching;manuscripts;microwave;node - plant part;physical object;similarity measure;social inequality;statistical cluster	Antonio Adán;Miguel Adán	2004	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2004.94	mesh generation;computer vision;index term;object model;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition	Vision	46.69133296187107	-71.79372447057445	37407
486d140b431c43943f6ca2951bdc1a0389984962	detection of curves with unknown endpoints using minimal path techniques	minimal path technique;proceedings;crack detection;algorithms;curve detection	Minimal path techniques have been used to detect features in images that can be modeled as curves. The current minimal path theory works only with prior knowledge about both the endpoints or one end point plus the total length of the open curve. We propose a novel algorithm that relaxes the user input requirements of existing techniques and detects the complete curve (even with branches) assuming the knowledge of only one arbitrary point on the curve. This algorithm is applied to detect features that can be modeled as open curves: cracks in structures and narrow elongated objects in medical images. This procedure can also be extended to closed curves and more complex topologies consisting of both closed curves and open curves. Minimal path technique is based on the computation of the geodesic distance map U(x) that seeks to minimize weighted distance between two points p1 and x.	algorithm;computation;distance (graph theory);distance transform;requirement	Vivek Kaul;Yichang James Tsai;Anthony J. Yezzi	2010		10.5244/C.24.62	computer science;theoretical computer science;mathematics;distributed computing;algorithm	Vision	49.18219724485055	-64.5415576605411	37411
a087d5bb0495ac39adeb5a319545b97ec2132e5f	a multi-source image registration algorithm based on combined line and point features		A multi-source image registration algorithm based on combined line and point features is proposed for images containing typical line objects. Firstly, the image control line features are extracted for coarse registration by the use of visual saliency and Line Segment Detection (LSD). Visual saliency represents human visual characteristics. LSD has attributes including rotation invariance, illumination changes insensitivity and noise resistant ability. Secondly, Scale Invariant Feature Transform (SIFT) based on multi-resolution analysis is used to extract the point features with scale and rotation invariant characteristics. Then the feature points are used to realize the fine registration. Finally, the simulation results are analyzed, and the validity of the algorithm is verified from subjective effect and objective evaluation indices.	algorithm;image registration;multi-source;multiresolution analysis;simulation	Yi Yang;Yuanli Liu	2017	2017 20th International Conference on Information Fusion (Fusion)	10.23919/ICIF.2017.8009690	computer science;invariant (physics);control line;computer vision;salience (neuroscience);scale-invariant feature transform;artificial intelligence;invariant (mathematics);image registration;algorithm;line segment;pattern recognition;multi-source	Robotics	39.357261449965826	-56.5783809279446	37417
1af466b7626afe41a8a5fb0e0367380e9d5225cd	scan integration as a labelling problem	g740 computer vision;dk atira pure researchoutput researchoutputtypes contributiontojournal article;surface details;computer science all;integration;mrf labelling;multi view scans;tk electrical engineering electronics nuclear engineering	Integration is a crucial step in the reconstruction of complete 3D surface model from multiple scans. Ever-present registration errors and scanning noise make integration a nontrivial problem. In this paper, we propose a novel method for multi-view scan integration where we solve it as a labeling problem. Unlike previous methods, which have been based on various merging schemes, our labeling-based method is essentially a selection strategy. The overall surface model is composed of surface patches from selected input scans. We formulate the labeling via a higher-order Markov Random Field (MRF) which assigns a label representing an index of some input scan to every point in a base surface. Using a higher-order MRF allows us to more effectively capture spatial relations between 3D points. We employ belief propagation to infer this labeling and experimentally demonstrate that this integration approach provides significantly improved integration via both qualitative and quantitative comparisons.		Ran Song;Yonghuai Liu;Ralph R. Martin;Paul L. Rosin	2014	Pattern Recognition	10.1016/j.patcog.2014.02.008	computer vision;computer science;artificial intelligence	Vision	46.62531207078373	-53.60644815143775	37460
1f5e47ad5490a63c7bea79000999b711055fbf2a	aggregated channels network for real-time pedestrian detection		Convolutional neural networks (CNNs) have demonstrated their superiority in numerous computer vision tasks, yet their computational cost results prohibitive for many real-time applications such as pedestrian detection which is usually performed on low-consumption hardware. In order to alleviate this drawback, most strategies focus on using a two-stage cascade approach. Essentially, in the first stage a fast method generates a significant but reduced amount of high quality proposals that later, in the second stage, are evaluated by the CNN. In this work, we propose a novel detection pipeline that further benefits from the two-stage cascade strategy. More concretely, the enriched and subsequently compressed features used in the first stage are reused as the CNN input. As a consequence, a simpler network architecture, adapted for such small input sizes, allows to achieve real-time performance and obtain results close to the state-of-the-art while running significantly faster without the use of GPU. In particular, considering that the proposed pipeline runs in frame rate, the achieved performance is highly competitive. We furthermore demonstrate that the proposed pipeline on itself can serve as an effective proposal generator.	acf;algorithmic efficiency;artificial neural network;computation;computer vision;convolutional neural network;display resolution;embedded system;fastest;graphics processing unit;machine vision;network architecture;pedestrian detection;pixel;real-time clock;real-time transcription;sensor;server (computing)	Farzin Ghorban;Javier Marín;Yu Su;Alessandro Colombo;Anton Kummert	2018	CoRR		computer engineering;machine learning;drawback;network architecture;convolutional neural network;deep learning;frame rate;cascade;computer science;artificial intelligence;pedestrian detection;communication channel	Vision	27.679327187693758	-53.4627933125879	37470
c1405874b6ae198ba62a4c9bf626b7f4c9cf3428	intracranial deformation caused by brain tumors: assessment of 3-d surface by magnetic resonance imaging	nuclear magnetic resonance imaging;intracranial;systeme nerveux pathologie;intracraneal;brain;gaussian curvature;image processing;measurement;neoplasms magnetic resonance brain magnetic resonance imaging surface treatment volume measurement medical treatment size measurement shape cancer;etude theorique;cancer;hyperbolic surface;genie biomedical;shape analysis technique brain tumors 3d surface assessment magnetic resonance imaging intracranial deformation surface segmentation problems b splines method digital 3d image surfaces mean curvature gaussian curvature planar surface parabolic surface elliptic surface hyperbolic surface geometric changes invariance properties brain size variations patient treatment response monitoring medical diagnostic imaging;etude experimentale;brain size variations;morfoscopia;shape analysis technique;biomedical nmr;shape analysis;procesamiento imagen;encephale pathologie;hombre;exploracion;surface segmentation problems;size measurement;courbure;encefalo;traitement image;magnetic resonance image;brain tumor;imageria rmn;sistema nervosio central patologia;brain tumors;cerebral disorder;invariance properties;mr imaging;surface treatment;nervous system diseases;planar surface;biomedical engineering;shape;deformation;geometric changes;encephale;systeme nerveux central pathologie;medida;magnetic resonance;tumor;3d surface assessment;medical image processing;morphoscopie;brain size;magnetic resonance imaging;sistema nervioso patologia;human;patient treatment response monitoring;intracrânien;estudio teorico;tecnica;superficie;exploration;central nervous system disease;encefalo patologia;medical image processing biomedical nmr brain;curvatura;tumeur;curvature;surface;volume measurement;ingenieria biomedica;imagerie rmn;b spline;mesure;theoretical study;neoplasms;digital 3d image surfaces;medical treatment;mean curvature;intracranial deformation;estudio experimental;b splines method;technique;deformacion;b splin;elliptic surface	A shape analysis technique has been developed to quantify intracranial deformation as a means of objectively assessing treatment for brain tumor. Conventional measurements of tumor volume are prone to ambiguity and error, so instead the authors are investigating the secondary space occupying effects of tumor, namely the deformation of structures within the brain. In order to avoid surface segmentation problems in MR images and to facilitate computation, the B-splines method has been introduced to approximate digital 3-D image surfaces. Using the mean curvature and the Gaussian curvature the authors classify a surface into 4 basic types: planar, parabolic, elliptic, and hyperbolic. The deformation of a surface can be described by measuring the geometric changes in these basic types. The method is independent of size, domain (translation), and viewpoint (rotation). These invariance properties are important as they overcome problems caused by wide variations in brain size within the normal population as well as small differences in patient orientation during acquisition. Experimental results show the potential of the technique in objectively monitoring patient response to treatment.		Dong-yong Dai;Barrie Condon;Donald M. Hadley;Roy Rampling;Graham Teasdale	1993	IEEE transactions on medical imaging	10.1109/42.251120	b-spline;gaussian curvature;radiology;exploration;shape;magnetic resonance imaging;mean curvature;shape analysis;mathematics;geometry;curvature;optics;nuclear magnetic resonance;brain size;surface;deformation;measurement;cancer	Visualization	45.38593730195139	-79.52097574231213	37548
0ee0b881b1525c95352a61fb70baa2cc4c61f3f1	vineyard yield estimation based on the analysis of high resolution images obtained with artificial illumination at night	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;color features;yield estimation;segmentation techniques;uk phd theses thesis;life sciences;precision agriculture;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	This paper presents a method for vineyard yield estimation based on the analysis of high-resolution images obtained with artificial illumination at night. First, this paper assesses different pixel-based segmentation methods in order to detect reddish grapes: threshold based, Mahalanobis distance, Bayesian classifier, linear color model segmentation and histogram segmentation, in order to obtain the best estimation of the area of the clusters of grapes in this illumination conditions. The color spaces tested were the original RGB and the Hue-Saturation-Value (HSV). The best segmentation method in the case of a non-occluded reddish table-grape variety was the threshold segmentation applied to the H layer, with an estimation error in the area of 13.55%, improved up to 10.01% by morphological filtering. Secondly, after segmentation, two procedures for yield estimation based on a previous calibration procedure have been proposed: (1) the number of pixels corresponding to a cluster of grapes is computed and converted directly into a yield estimate; and (2) the area of a cluster of grapes is converted into a volume by means of a solid of revolution, and this volume is converted into a yield estimate; the yield errors obtained were 16% and -17%, respectively.	calibration;color space;grapes (dietary);high-resolution scheme;histogram;image resolution;image segmentation;mathematical morphology;memory segmentation;naive bayes classifier;obstruction;pixel;real-time clock;real-time computing;real-time transcription;sample variance;segmentation action;spatial variability;biologic segmentation;grape extract;ripening	Davinia Font;Marcel Tresanchez;Dani Martínez;Javier Moreno;Eduard Clotet;Jordi Palacín	2015		10.3390/s150408284	telecommunications;bioinformatics;data science;data mining;precision agriculture;optics;statistics	Vision	39.15246578438048	-72.46227274873485	37577
8d8d9ef81d29268727479e6cd0942d5e52142f3b	a patch-based spatiotemporal phase unwrapping method for phase contrast mri using graph cuts	wrapping;phase wrapping;phase unwrapping algorithms;neighboring frames;phase contrast;phase noise;phase contrast mri;pixel wrapping algorithm design and analysis blood partitioning algorithms magnetic resonance imaging error analysis;velocity encoding;phase unwrapping algorithms patch based spatiotemporal phase phase contrast mri graph cuts magnetic resonance imaging phase noise neighboring frames current frame energy function spatial temporal constraints phase wrapping;magnetic resonance imaging phase unwrapping velocity encoding graph cut phase contrast;magnetic resonance image;energy function;temporal information;error analysis;current frame;temporal constraints;patch based spatiotemporal phase;graph cut;medical image processing;wrapping biomedical mri medical image processing phase noise;blood;magnetic resonance imaging;pixel;graph cuts;algorithm design and analysis;spatial temporal constraints;spatial information;partitioning algorithms;biomedical mri;phase unwrapping	Phase unwrapping is an important and challenging problem in phase contrast magnetic resonance imaging (PC-MRI). In this paper, we propose a new algorithm for phase unwrapping based on graph cuts. Our algorithm takes a patch-based approach which has the advantages of simplicity and robustness to phase noise. To make use of temporal information from the neighboring frames as well as spatial information from the current frame, the energy function is designed to combine both spatial and temporal constraints. The proposed method has been tested with real PC-MRI data. Experimental results demonstrate that our algorithm is capable of unwrapping images with severe phase wrapping, and that it outperforms other existing popular phase unwrapping algorithms both qualitatively and quantitatively.	algorithm;cut (graph theory);ibm systems network architecture;in-phase and quadrature components;instantaneous phase;mathematical optimization;one-class classification;patch (computing);phase noise;resonance;smoothing;wrapping (graphics)	Wenyu Xie;Ying Sun;Sim Heng Ong	2010	2010 11th International Conference on Control Automation Robotics & Vision	10.1109/ICARCV.2010.5707369	computer vision;cut;computer science;magnetic resonance imaging;machine learning;mathematics	Vision	45.2770099183467	-73.88025854741178	37639
218e90d4893b9551cefe84c504dd5fad04ff6cd5	classifying textile designs using region graphs		Markov random field pixel labelling is often used to obtain image segmentations in which each segment or region is labelled according to its attributes such as colour or texture [4]. This paper explores the use of such a representation for image classification. In particular, the problem of classifying textile images according to design type is addressed. Figure 1(a) shows an example of an image segmented into groups of regions by assigning each pixel a label; the label image is shown in the centre. Given such a labelling, the image can be represented as a bag of shapes by computing shape descriptors for each connected component [3]. However, a bag of shapes model ignores relationships betw een the groups of regions. In order to retain information about these relation ships, we construct undirected weighted graphs as shown in Figure 1(b ). Each vertex is associated with a group of regions (bag of shapes). Edg es in the graph denote either the extent to which the groups’ regions are spatially adjacent or the dissimilarity of their respective bags of shapes.	computer vision;connected component (graph theory);graph (discrete mathematics);markov chain;markov random field;pixel	Wei Jia;Stephen J. Mckenna;Annette A. Ward;Keith Edwards	2010		10.5244/C.24.93	computer science;artificial intelligence;computer vision;markov random field;pattern recognition;pixel;vertex (geometry);labelling;connected component;contextual image classification;graph	Vision	43.898796276102516	-56.27083593824526	37652
77ee3046152fdb834e6120cb599029d4d2ffd767	carrying object detection using pose preserving dynamic shape models	modelo dinamico;mascara;modelizacion;iterative method;ajustamiento modelo;estimation mouvement;silhouette;image processing;generic model;cuerpo deformable;estimacion movimiento;remplissage;dynamic model;cinematica;procesamiento imagen;outlier;motion estimation;filling;forma geometrica;shape deformation;kinematics;traitement image;metodo iterativo;ajustement modele;modelisation;observacion aberrante;detection objet;detector proximidad;methode iterative;shape reconstruction;model matching;modele dynamique;deformable body;geometrical shape;cinematique;background subtraction;corps deformable;preservation;observation aberrante;forme geometrique;masque;shape modeling;modeling;preservacion;mask;silueta;proximity detector;object detection;relleno;detecteur proximite	In this paper, we introduce a framework for carrying object detection in different people from different views using pose preserving dynamic shape models. We model dynamic shape deformations in different people using kinematics manifold embedding and decomposable generative models by kernel map and multilinear analysis. The generative model supports pose-preserving shape reconstruction in different people, views and body poses. Iterative estimation of shape style and view with pose preserving generative model allows estimation of outlier in addition to accurate body pose. The model is also used for hole filling in the background-subtracted silhouettes using mask generated from the best fitting shape model. Experimental results show accurate estimation of carrying objects with hole filling in discrete and continuous view variations.	anomaly detection;display resolution;gait analysis;generative model;ibm notes;iteration;motherboard;object detection	Chan-Su Lee;Ahmed M. Elgammal	2006		10.1007/11789239_33	active shape model;computer vision;kinematics;outlier;systems modeling;background subtraction;3d pose estimation;image processing;computer science;motion estimation;geometry;iterative method;mask;silhouette;preservation	Vision	47.4452699476485	-56.66510959210803	37665
a9239f2134d18da85a60a43564547fbadcd8e83b	multiscale edge detection and gradient vector flow snakes for automated identification of the carotid artery wall in longitudinal b-mode ultrasound images	discrete wavelet transforms;gradient vector flow;discrete wavelet transform;active contour;image segmentation;edge detection;real arterial wall boundary estimation multiscale edge detection gradient vector flow snakes automated carotid artery wall identification longitudinal b mode ultrasound images automatic active contour based segmentation carotid artery wall detection initial snake contour gvf snake image wavelet transform local maxima image edge map gvf field;ultrasonic imaging;carotid arteries;wavelet transforms;ultrasound imaging;image edge detection image segmentation ultrasonic imaging carotid arteries discrete wavelet transforms vectors;gradient vector flow snake ultrasound imaging carotid artery multi scale edge detection wavelet transform;wavelet transform;vectors;image edge detection;carotid artery;gradient vector flow snake;medical image processing;multi scale edge detection;gradient methods;biomedical ultrasonics;blood vessels;wavelet transforms biomedical ultrasonics blood vessels edge detection gradient methods image segmentation medical image processing	This paper proposes a fully automatic active-contour-based segmentation method, for the detection of the carotid artery wall in longitudinal B-mode images. A multiscale edge detection methodology is used for the definition of an initial snake contour, followed by a gradient vector flow (GVF) snake. The multiscale edge detection method is based on finding the local maxima of the wavelet transform of the image, which is very close to the real contour. The GVF snake is based on the calculation of the image edge map and the calculation of the GVF field which guides the deformation for the estimation of the real arterial wall boundaries. In twenty cases of healthy carotid arteries the sensitivity, specificity and accuracy were higher than 0.97, 0.99 and 0.98 respectively, for both diastolic and systolic cases. In conclusion, the proposed methodology provides a new accurate procedure to detect the arterial wall in ultrasound images of the carotid artery.	active contour model;edge detection;gradient;maxima and minima;sensitivity and specificity;wavelet transform	Aikaterini I. Matsakou;Nikolaos N. Tsiaparas;Spyretta Golemati;Konstantina S. Nikita	2012	2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2012.6235881	computer vision;radiology;computer science;mathematics;wavelet transform;computer graphics (images)	Vision	40.61392252663523	-76.20193147073122	37687
53f8f1ddd83a9e0e0821aaa883fbf7c1f7f5426e	face recognition using principal component analysis and log-gabor filters	gabor filter;face recognition;principal component analysis;equal error rate;facial expression	In this article we propose a novel face recognition method based on Principal Component Analysis (PCA) and Log-Gabor filters. The main advantages of the proposed method are its simple implementation, training, and very high recognition accuracy. For recognition experiments we used 5151 face images of 1311 persons from different sets of the FERET and AR databases that allow to analyze how recognition accuracy is affected by the change of facial expressions, illumination, and aging. Recognition experiments with the FERET database (containing photographs of 1196 persons) showed that our method can achieve maximal 97-98% first one recognition rate and 0.3-0.4% Equal Error Rate. The experiments also showed that the accuracy of our method is less affected by eye location errors and used image normalization method than of traditional PCA -based recognition method.	algorithm;decorrelation;experiment;feret (facial recognition technology);feret database;facial recognition system;feature selection;feature vector;gabor filter;maximal set;principal component analysis	Vytautas Perlibakas	2006	CoRR		facial recognition system;computer vision;speech recognition;computer science;machine learning;pattern recognition;three-dimensional face recognition;eigenface;facial expression;principal component analysis	Vision	32.7543564964588	-59.408685143932125	37702
44b4ecdc5034cfc950113e7dd61771d77fed242b	bi-directional regional forces for level set propagation: an application to static and motion imagery	level set		software propagation	Jasjit S. Suri;Jianbo Gao	2001			level set;mathematics;computer vision;artificial intelligence	Vision	45.40912141035889	-74.71730477043242	37741
16cd417a098cdb54f52e076f11a08163af86c413	image representation using accurate orthogonal gegenbauer moments	algorithme rapide;metodo momento;evaluation performance;fonction orthogonale;gegenbauer polynomial;image numerique;polinomio gegenbauer;legendre moments;performance evaluation;moment method;approximation error;gegenbauer moments;fonction poids;methode noyau;numerical method;evaluacion prestacion;representation image;imagen nivel gris;polinomio legendre;gray level images;legendre polynomial;error aproximacion;recurrence;metodo numerico;polynome gegenbauer;representation signal;image representation;recurrencia;methode moment;fast algorithm;metodo nucleo;signal representation;image niveau gris;imagen numerica;funcion peso;gegenbauer polynomials;kernel method;orthogonal function;numerical approximation;digital image;weight function;polynome legendre;funcion ortogonal;chebyshev moments;grey level image;algoritmo rapido;symmetry property;methode numerique;erreur approximation	Image representation by using polynomial moments is an interesting theme. In this paper, image representation by using orthogonal Gegenbauer function is presented. A novel method for accurate and fast computation of orthogonal Gegenbauer moments is proposed. The accurate values of Gegenbauer moments are obtained by mathematically integrating Gegenbauer polynomials multiplied by their weight functions over the digital image pixels. A novel recurrence formula is derived for the kernel generation. The proposed method removes the numerical approximation errors involved in conventional method. A fast algorithm is proposed to accelerate the moment's computations. A comparison with the conventional method is performed. The obtained results explain the efficiency and the superiority of the proposed method.		Khalid M. Hosny	2011	Pattern Recognition Letters	10.1016/j.patrec.2011.01.006	gegenbauer polynomials;kernel method;approximation error;mathematical analysis;weight function;legendre polynomials;numerical analysis;computer science;machine learning;calculus;orthogonal functions;mathematics;geometry;digital image;statistics	Vision	50.212610107995324	-62.08082791029776	37817
864ef0175b96a094aaf8d8ec771b264eb76eea0d	system for the recognition of human faces	extraction information;image recognition;reconocimiento imagen;base donnee;information extraction;performance;database;base dato;identification;reconnaissance image;pattern recognition;identificacion;reconnaissance forme;rendimiento;reconocimiento patron;extraction informacion	This paper describes a system for content-based retrieval of facial images from an image database. The system includes feature extraction based on expert-assisted feature selection, spatial feature measurement, feature and shape representation, feature information compression and organization, search procedures, and pattern-matching techniques. The system uses novel data structures to represent the extracted information. These structures include attributed graphs for representing local features and their relationships, n-tuple of mixed mode data, and highly compressed feature codes. For the retrieval phase, a knowledge-directed search technique that uses a hypothesis refinement approach extracts specific features for candidate identification and retrieval. The overall system, the components, and the methodology are described. The system has been implemented on an IBM Personal System/2® running Operating System/2®. Examples demonstrating the performance of the system are included.		Mohamed S. Kamel;Helen C. Shen;Andrew K. C. Wong;Radu I. Campeanu	1993	IBM Systems Journal	10.1147/sj.322.0307	identification;computer vision;visual word;speech recognition;performance;computer science;kanade–lucas–tomasi feature tracker;pattern recognition;database;information extraction;feature;feature model	Robotics	43.39881820538611	-60.0934555639788	37822
337785724bf89f8dbff62f9b96ef73fbf79120d5	predicting sufficient annotation strength for interactive foreground segmentation	graph theory;segmentation quality sufficient annotation strength prediction interactive foreground segmentation manual annotation mode bounding boxes freehand outlines accuracy effort tradeoff prediction graph cut segmentation image visual separability foreground uncertainty image segmention;image segmentation;image segmentation graph theory;image segmentation image color analysis prediction algorithms uncertainty training accuracy shape	The mode of manual annotation used in an interactive segmentation algorithm affects both its accuracy and ease-of-use. For example, bounding boxes are fast to supply, yet may be too coarse to get good results on difficult images, freehand outlines are slower to supply and more specific, yet they may be overkill for simple images. Whereas existing methods assume a fixed form of input no matter the image, we propose to predict the tradeoff between accuracy and effort. Our approach learns whether a graph cuts segmentation will succeed if initialized with a given annotation mode, based on the image's visual separability and foreground uncertainty. Using these predictions, we optimize the mode of input requested on new images a user wants segmented. Whether given a single image that should be segmented as quickly as possible, or a batch of images that must be segmented within a specified time budget, we show how to select the easiest modality that will be sufficiently strong to yield high quality segmentations. Extensive results with real users and three datasets demonstrate the impact.	adobe freehand;algorithm;autostereogram;cut (graph theory);display resolution;linear separability;modality (human–computer interaction)	Suyog Dutt Jain;Kristen Grauman	2013	2013 IEEE International Conference on Computer Vision	10.1109/ICCV.2013.166	computer vision;computer science;graph theory;machine learning;segmentation-based object categorization;pattern recognition;mathematics;image segmentation;scale-space segmentation	Vision	29.671808926333686	-72.05703265379977	37827
075ed6f6b0a57dc887b4545b8e48120418caf9bb	a fingerprint segmentation method using a recurrent neural network	image segmentation;authorisation;rule based;fingerprint recognition recurrent neural networks image sensors fingers neurons image matching image segmentation histograms optical sensors sensor systems;segmentation faults fingerprint segmentation method recurrent neural network fingerprint image identification vertical length variation rnn group delay spectra horizontal pixel line state dependency histogram learning performance segmentation error segmentation rate;state dependence;statistical analysis;recurrent neural nets;recurrent neural network;learning artificial intelligence;fingerprint identification;learning artificial intelligence fingerprint identification authorisation image segmentation recurrent neural nets statistical analysis	In this paper, we propose a segmentation method for identifying a fingerprint image with the variation of vertical length using a recurrent neural network (RNN). Group delay spectra and histograms of horizontal pixel line are used as input features fed into the RNN and two target output patterns with and without consideration of state dependency are introduced for learning. The method composed of the histogram learning and the state-dependent target indicates the best performance. When the tolerable segmentation error is 60 pixels, a segmentation rate of 97.2% is obtained. In comparison with the rule-based method, this method has an advantage of about 10%. Furthermore, we show that this method has a characteristic different from the rule-based method in regard to segmentation faults, and the learning with the state-dependent target is more effective than that without the dependency.	artificial neural network;fingerprint recognition;group delay and phase delay;logic programming;newton's method;pixel;random neural network;recurrent neural network	Shinji Sato;T. Umezaki	2002		10.1109/NNSP.2002.1030046	computer vision;computer science;machine learning;segmentation-based object categorization;pattern recognition;region growing;image segmentation;scale-space segmentation	Vision	31.423437148712516	-64.99372846955181	37833
1ac35229a3fe4aba3bfcf7f28215bf136914ba1b	adult image classification by a local-context aware network		To build a healthy online environment, adult image recognition is a crucial and challenging task. Recent deep learning based methods have brought great advances to this task. However, the recognition accuracy and generalization ability need to be further improved. In this paper, a local-context aware network is proposed to improve the recognition accuracy and a corresponding curriculum learning strategy is proposed to guarantee a good generalization ability. The main idea is to integrate the global classification and the local sensitive region detection into one network and optimize them simulatenously. Such strategy helps the classification networks focus more on suspicious regions and thus provide better recognition performance. Two datasets containing over 150,000 images have been collected to evaluate the performance of the proposed approach. From the experiment results, it is observed that our approach can always achieve the best classification accuracy compared with several state-of-the-art approaches investigated.		Xizi Wang;Feng Cheng;Shilin Wang;Huanrong Sun;Gongshen Liu;Cheng Zhou	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451366	deep learning;pattern recognition;contextual image classification;context aware network;computer science;artificial intelligence	Vision	24.76088168032908	-57.536702089072286	37843
06b28d5b54974c71de3dea49ad47139edefa0a48	fast shape matching of height functions with heuristic search strategy	fast computation;dynamic programming;image matching;shape recognition;shape dynamic programming heuristic algorithms algorithm design and analysis transform coding computer vision conferences;shape recognition dynamic programming image matching image retrieval;heuristic search;competitive retrieval performance fast shape matching heuristic search strategy fast computational framework height functions descriptor dynamic programming algorithm dp public shape benchmarks;shape matching;fast computation shape matching heuristic search height functions;height functions;image retrieval	In this paper, we propose a fast computational framework based on height functions descriptor for handling shape matching. To improve the efficiency, we utilize the strategy of heuristic search to reduce the large search space of dynamic programming (DP) algorithm between sample points of every two shapes during shape matching. Experiments on several public shape benchmarks(such as, MPEG-7 dataset, Kimia's dataset and ETH-80 dataset) demonstrate superior efficiency and competitive retrieval performance over previous methods.	computation;davis–putnam algorithm;dynamic programming;fast fourier transform;graphics processing unit;heuristic;mpeg-7;machine learning;shape analysis (digital geometry);similarity measure	Yuefang Gao;Zhonghong Huang;Baichuan Yang	2013	2013 Seventh International Conference on Image and Graphics	10.1109/ICIG.2013.188	computer vision;mathematical optimization;image retrieval;computer science;machine learning;dynamic programming;mathematics	Vision	39.56684142073894	-55.753698018602805	37861
5dfa2bd3a9bacaf936a7462295ccf677f3e94792	the fractal pyramid with applications to image coding	eigenvalues and eigenfunctions;fractals;multiscale signal decomposition;image coding;iterative decoding;iterative algorithms;application software;color;signal representations;fractal pyramid;rgb color image;pyramid image representation;rgb color image fractal pyramid image coding iterated transformation theory fractal image coding algorithm pyramid image representation itt coded image second type functional equation functional equations multiscale signal decomposition itt coded signals eigen structure linear operators gray tone images;transform coding;gray tone images;iterated transformation theory;itt coded image;iterative methods;functional equation;image generation;linear operator;image colour analysis;image representation;signal representation;linear operators;transforms;itt coded signals;signal resolution;functional equations;eigenvalues and eigenfunctions image representation image coding functional equations image colour analysis fractals iterative methods transform coding transforms;fractals image coding equations image generation image representation signal resolution signal representations color;extraterrestrial measurements;fractal image coding algorithm;eigen structure;color image;second type functional equation	We extend the iterated transformation theory (ITT ) fractal image coding algorithm proposed by A. Jacquin [1] to generate a pyramid image representation. An ITT coded image is modeled as the solution of a second kind functional equation. This representation is iterated to form an ITT chain of functional equations which can serve as the framework for a multiscale signal decomposition. This formalism can be extended to accommodate hybrid ITT representations and, in the limit, ITT coded signals as a solution of a homogeneous functional equation. Existence of the ITT chain signal representation is shown to be connected to the eigen-structure of the linear operators of the associated functional equations. At each level of the ITT chain representation, the signal is decomposed into two parts which are not orthogonal. We use this decomposition to build an ITT pyramid representation for gray-tone images as well as for RGB color images.	algorithm;eigen (c++ library);fractal;iteration;pyramid (image processing);semantics (computer science);transformation theory	Alexandru Bogdan	1995		10.1109/ICASSP.1995.480092	functional equation;computer vision;pyramid;discrete mathematics;mathematics;geometry	Vision	51.996965831445735	-64.03589986434122	37862
95dffcc92bda88d9f4f5b112d100f43951745b8c	multiscale segmentation of unstructured document pages using soft decision integration	image segmentation;neural networks;context dependent classification;multiscale analysis;uncertainty handling;wavelet packet;fuzzy set theory;fuzzy set theory document image processing image segmentation feature extraction image texture wavelet transforms uncertainty handling feedforward neural nets;image texture;layout graphics image segmentation neural networks white spaces background noise fuzzy neural networks information analysis performance analysis context;wavelet transforms;feature extraction;soft decision integration;document image processing;feedforward neural nets;document processing;wavelet packets;wavelet packets multiscale segmentation unstructured document pages soft decision integration document texture multiscale feature vectors feedforward neural network fuzzy membership assignments document processing context dependent classification	We present an algorithm for layout-independent document page segmentation based on document texture using multiscale feature vectors and fuzzy local decision information. Multiscale feature vectors are classified locally using a neural network to allow softifuzzy multi-class membership assignments. Segmentation is performed by integrating soft local decision vectors to reduce their “ambiguities.”	algorithm;artificial neural network;feature vector	Kamran Etemad;David S. Doermann;Rama Chellappa	1997	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.566817	image texture;computer vision;document processing;feature extraction;computer science;machine learning;pattern recognition;wavelet packet decomposition;fuzzy set;image segmentation;artificial neural network;wavelet transform	Vision	34.082066130330944	-65.8276248809113	37865
4efd82122f99d05d3c6b1021855efd23de02573d	hybrid method combining superpixel, random walk and active contour model for fast and accurate liver segmentation	active contour;interactive segmentation;random walk;superpixel;volumetric medical image	Organ segmentation is an important pre-processing step in surgery planning and computer-aided diagnosis. In this paper, we propose a fast and accurate liver segmentation framework. Our proposed method combines a knowledge-based slice-by-slice Random Walk (RW) segmentation algorithm (proposed in our previous work) with a superpixel algorithm called the Contrast-enhanced Compact Watershed (CCWS) method to reduce computing time and memory costs. Compared to the commonly used Simple Linear Iterative Clustering (SLIC), we demonstrate that our CCWS is more appropriate for liver segmentation. To improve the methods accuracy, we use a modified narrow band active contour model as a refinement after the initial segmentation. The experiments showed that the superpixel-based slice-by-slice RW could segment the entire liver with improved speed, and the modified active contour model is more precise than the original Chan-Vese Model. As a result, the proposed framework is able to quickly and accurately segment the entire liver.		Ye Yuan;Yen-Wei Chen;Chunhua Dong;Hai Yu;Zhiliang Zhu	2018	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2018.08.012	entire liver;random walk;computer vision;cluster analysis;active contour model;artificial intelligence;medicine;segmentation	Vision	40.84015772504453	-77.48613057979327	37874
08dc4d7585fc5430a01c404267d279610990132b	skin lesion image segmentation based on adversarial networks			image segmentation	Ning Wang;Yanjun Peng;Yuanhong Wang;Meiling Wang	2018	TIIS	10.3837/tiis.2018.06.021	distributed computing;adversarial system;lesion;computer vision;image segmentation;computer science;artificial intelligence	Vision	31.733752329341673	-73.77323812380708	37893
6d884fa3056c1095b8e53d24a235d0afec90bf89	development of iris security system using adaptive quality-based template fusion		Recently, the interface of computer technologies and biology has an enormous impact on society. Human recognition research projects promise a new life to various security consulting. Iris recognition is considered to be one of the exceedingly reliable authentication systems. To account for iris data variations, nearly of all iris systems store multiple templates per each user. Approaching to overcome the storage space and computation overheads, this paper proposes an intelligent fusion technique, algorithms, and suggestions. The quality of the input image has been checked firstly to ensure that “qualified iris samples” will be only treated. The proposed system, with the aid of the image selection stage and template quality test, has the advantage of being adaptive and simple, but can come at the expense of reject extremely inadequate data for any user. Complete the eye shape using the convex hull is the main key for image selection module. Shape-based thresholding is integrated with morphological features to avoid the dark iris problems, elliptical pupil and iris shapes. For best recognition rate, the optimum values of the 1D log Gabor filter parameters and different sizes of the iris code are recorded. From experimental results, an HD value of 0.4 can be chosen as a suitable separation point, and the optimum code size was found to be 20 × 480. An experimental work reveals a reduction in database size by nearly a 78 % and an increase of verification speed of about 85.25 % is achieved while 14.75 % of computation time in the shifting process is only required. Comparing with existing algorithms, the proposed algorithm gives an accuracy of 96.52 and 99.72 % for TRR and TAR, respectively for closed loop tested dataset. In addition, with a number of experimentations, the proposed algorithm gives the lowest FAR and FRR of 0.0019 and 0.00287 % respectively and EER of 0.0024 %.		M. M. Eid;M. A. Mohamed;M. A. Abou-El-Soud	2015		10.1007/978-3-319-21206-7_23	convex hull;iris flower data set;log gabor filter;template;computation;thresholding;iris recognition;artificial intelligence;pattern recognition	Robotics	35.11301150032105	-71.09638899745498	37985
a9162f51a7a72ad306d8b6f81e0eb628669c07ea	entropy-based window selection for detecting dim and small infrared targets	local difference measure;window selection;infrared image;dim and small target detection	Dim and small target detection in complex background is considered a difficult and challenging problem. Conventional algorithms using the local difference/mutation possibly produce high missed or mistaken detection rates. In this paper, we propose an effective algorithm for detecting dim and small infrared targets. In order to synchronously enhance targets and suppress complex background clutters, we adopt an adaptive entropy-based window selection technique to construct a novel local difference measure (LDM) map of an input image, which measures the dissimilarity between the current region and its neighboring ones. In this way, the window size can be adaptively regulated according to local statistical properties. Compared with the original image, the LDM map has less background clutters and noise residual. This guarantees the lower false alarm rates under the same probability of detection. Subsequently, a simple threshold is used to segment the target. More than 600 dim and small infrared target images against different complex and noisy backgrounds were utilized to validate the detection performance of the proposed approach. Extensive experimental results demonstrate that the proposed method not only works more stably for different target movements and signal-to-clutter ratio values, but also has a better performance compared with classical baseline methods. The evaluation results suggest that the proposed method is simple and effective with regard to detection accuracy. & 2016 Elsevier Ltd. All rights reserved.	algorithm;baseline (configuration management);clutter;effective method;embedded system;experiment;latent class model;sensor;through-hole technology	He Deng;Xianping Sun;Maili Liu;Chaohui Ye;Xin Zhou	2017	Pattern Recognition	10.1016/j.patcog.2016.07.036	computer vision;mathematics;statistics	Vision	41.71346147899616	-54.55008268224693	37988
e162be399cb455a4d514def50fa696a6edccb02b	multiresolution analysis of digital images using the continuous extension of discrete group transforms	transformation ondelette;traitement signal;image numerique;interpolation;4230;resolution spatiale;transformation cosinus discrete;low pass filter;digital imaging;segmentation;analyse multiresolution;discrete cosine transform;linear filtering;algorithme;multiple scales;wavelet transforms;triangular lattice;wavelet transform;filtre passe bas;discrete cosine transforms;triangular lattices;signal processing;reseau carre;imagen numerica;algorithms;transform theory;image analysis;low pass filters;digital image;stationary wavelet transform;multiresolution analysis;analyse image;square lattices;reseau triangulaire;segmentacion;analisis multiresolucion;data grid;discrete group;spatial resolution	A new technique is presented for multiresolution analysis (MRA) of digital images. In 2D, it has four variants, two of which are applicable on square lattices; the Discrete Cosine Transform (DCT) is the simpler of the two. The remaining variants can be used in the same way on triangular lattices. The property of the Continuous Extension of the Discrete Group Transform (CEDGT) is used to analyse data for each level of decomposition. The MRA principle is obtained by increasing the data grid for each level of decomposition, and by using an adapted low filter to reduce some irregularities due to noise effect. Compared to some stationary wavelet transforms, the image analysis with a multiresolution CEDGT transform gives better results. In particular, a wavelet transform is capable of providing a local representation at multiple scales, but some local details disappear due to the use of the low pass filter and the reduction of the spatial resolution for a high level of decomposition. This problem is avoided with CEDGT. The smooth interpolation, used by the multiresolution CEDGT, gives interesting results for coarse-to-fine segmentation algorithm and others analysis processes.© (2006) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	digital image;multiresolution analysis	Mickaël Germain;Jiri Patera	2006		10.1117/12.650720	multiresolution analysis;wavelet;computer vision;image analysis;second-generation wavelet transform;low-pass filter;signal processing;stationary wavelet transform;wavelet transform	Vision	51.849097818498684	-62.92857024478278	38070
d16ba8683b193ee1f61dd79326a6830a316ccde8	cursive on-line handwriting word recognition using a bi-character model for large lexicon applications	databases;bi character model;handwriting recognition;image segmentation;support vector machines;on line handwriting recognition;lexicon;training;word processing handwriting recognition handwritten character recognition image segmentation linguistics;segmentation;combining of on line and off line feature;cursive online handwriting recognition;hybrid svm hmm model;analytical approach;character recognizer cursive online handwriting recognition word recognition bi character model lexicon segmentation analytical approach;hidden markov models;dictionaries;word recognition;character recognition hidden markov models handwriting recognition databases training dictionaries support vector machines;hybrid svm hmm model on line handwriting recognition combining of on line and off line feature bi character model;character recognition;handwritten character recognition;word processing;character recognizer;linguistics	This paper deals with on-line handwriting recognition in a closed-world environment with a large lexicon. Several applications using handwriting recognition have been developed, but most of them consider a lexicon of limited size. Many difficulties, in particular confusions during the segmentation stage, are linked to the use of a large lexicon, with large writing variations and an increased complexity of the connections between characters. In order to circumvent these problems, we introduce in this paper an original method based on a new analytical approach using two levels of recognition models: an isolated character recognizer and an original bi-character recognition model. The idea behind the bi-character model is to recognize jointly two neighboring characters. The objective is to reduce the confusions between characters occurring during the segmentation step. Experiments show an interesting improvement of the recognition rate when introducing the bi-character model, as the recognition rate is increased of 7.2% for a 1000 words lexicon, of 9.1% for a 2000 words lexicon, and up to 15% for a 10000 words lexicon.	concatenation;conditional random field;experiment;finite-state machine;ground truth;handwriting recognition;lexicon;online and offline;optical character recognition;performance	Sophea Prum;Muriel Visani;Jean-Marc Ogier	2010	2010 12th International Conference on Frontiers in Handwriting Recognition	10.1109/ICFHR.2010.38	natural language processing;support vector machine;speech recognition;word recognition;intelligent character recognition;computer science;machine learning;pattern recognition;handwriting recognition;image segmentation;segmentation	Vision	32.55900614980146	-66.46530562411925	38111
ea70c4fd7b3286357e007c51f7dc561cf26c8ebe	computer-aided detection of microcalcifications in digital mammograms to support early diagnosis of breast cancer		Early detection of microcalcifications in mammograms is considered one of the best tools to prevent breast cancer. Although traditionally this task have been performed with analog mammograms, digital mammograms are currently an alternative for examination of breast to detect microcalcifications and any other kind of breast abnormalities. Digital mammography presents some advantages in comparison to its analog counterpart, such as lower radiation dosage for acquisition and possibility to storage for telemedicine purposes. Nevertheless, digitalization entails loss of resolution and difficulties to detect microcalcifications. Therefore, several methods based on digital image processing have been proposed to perform detection of microcalcifications in digital mammograms, to support the early detection and prognosis of breast cancer. However, sometimes computer-aided methods fail due to the characteristics of certain microcalcifications that are hard to detect either by visual examination and by computerized analysis. For this reason, this work presents a method based on contrast enhancement and wavelet reconstruction oriented to increase the rate of computer-aided detected microcalcifications. The images correspond to the mini-MIAS database, which provides mammograms of healthy women and with breast microcalcifications, including the respective coordinates of their locations. The work includes also the application of the method in resolution-enhanced mammograms via sparse representation, with the aim to determine the role of resolution enhancement for a possible improvement in the performance of the method.		Nayid Triana;Alexander Cerquera	2013		10.1007/978-3-642-38637-4_30	computer science;digital image processing;computer-aided;artificial intelligence;computer vision;breast cancer;wavelet;digital mammography;sparse approximation;breast microcalcifications	HCI	34.42808879968419	-77.21334785805355	38123
26050b50c1048f9ffbba44a48ee71f731cec255f	edge detection for cement images based on interactive genetic algorithm		The cement is a type of cementious material which hydration is an extremely complex process. In order to research the evolution of particles during cement hydration, the particles should be differentiated from cement images. However, the existence of partial volume effect and similarity of intensity between different phases causes the boundaries of particles are not clear. Therefore, it is difficult for the traditional edge detection methods to differentiate the edges of the particles from cement microstructural images. In this paper, a method detecting edges for cement image based on interactive genetic algorithm (IGA) is proposed. The IGA utilizes human knowledge to evaluate the quality of evolved convolution templates to yield a better detector. Experimental results show that the method can accurately detect the edge for cement images.	edge detection;genetic algorithm	Guangyue Gao;Lin Wang;Bo Yang;Liangliang Zhang;Fengyang Sun;Ajith Abraham;Shuangrong Liu	2017		10.1007/978-3-319-76351-4_5	genetic algorithm;partial volume;computer vision;detector;convolution;cement;artificial intelligence;materials science;edge detection	Vision	40.1485035321828	-71.92672769120082	38172
145b94f3eb6dd5bffa080b87ff2ce6bef341c877	mesh-based active model initialization for multiple organ segmentation in mr images		Active models are widely used for segmentation of medical images. One of the key issues of active models is the initialization phase which affects significantly the segmentation performance. This paper presents a novel method for an automatic initialization of different types of active models by exploiting an adaptive mesh generation technique which is suitable for automatic detection of multiple organs. This method has been applied on MR images and results show the ability of the proposed method in simultaneously extracting initial approximate boundaries that are close to the exact boundaries of multiple organs. The effect of the proposed initialization algorithm on the segmentation has been tested on a series of arm and thoracic MR images and the results show an improvement in the convergence and speed of active model segmentation of multiple organs with respect to those obtained using manual initialization.		M. R. Mohebpour;François Guibault;Farida Cheriet	2017		10.1007/978-3-319-59876-5_47	computer vision;computer science;artificial intelligence;pattern recognition;initialization;scale-space segmentation;mesh generation;segmentation	Vision	41.31820944561401	-76.52260275832991	38176
ef3957f177050e6de98bdd092a34e2fa37338948	shape matching for rigid objects by aligning sequences based on boundary change points		This paper presents a new boundary (shape) matching algorithm for 2D rigid objects without voids. Our new algorithm presents a new shape representation that uses the outcome from an active contour (AC) model. An object’s shape is partitioned into a clockwise ordered sequence of edges, where every edge is a boundary segment enclosed by reference points. These points are convex hull vertices which lie on boundary corners. Further, the reference points are used to generate angles. Hence, a boundary shape maps to a sequence of angles, turning the shape matching problem to alignment of cyclic sequences of angles. The latter makes our method scaling and rotational invariant. Experiments validate the theoretical concept, and provide qualitative comparison with other methods in the field.	sequence alignment	Abdullah N. Arslan;Nikolay Metodiev Sirakov	2017		10.1007/978-3-319-59108-7_24	mathematical optimization;clockwise;convex hull;computer science;scaling;vertex (geometry);blossom algorithm;invariant (mathematics);active contour model;topology	Robotics	49.474830350647714	-54.200385835080205	38180
c7eb56dedec25f78e6d1d6fd00486b6e57f29f8e	epitomized summarization of wireless capsule endoscopic videos for efficient visualization	visual quality;semantic interpretation;semantic information;wireless capsule endoscopy;spatial distribution;semantic description;video recording;visual features;em algorithm	A video recording of an examination by Wireless Capsule Endoscopy (WCE) may typically contain more than 55,000 video frames, which makes the manual visual screening by an experienced gastroenterologist a highly time-consuming task. In this paper, we propose a novel method of epitomized summarization of WCE videos for efficient visualization to a gastroenterologist. For each short sequence of a WCE video, an epitomized frame is generated. New constraints are introduced into the epitome formulation to achieve the necessary visual quality for manual examination, and an EM algorithm for learning the epitome is derived. First, the local context weights are introduced to generate the epitomized frame. The epitomized frame preserves the appearance of all the input patches from the frames of the short sequence. Furthermore, by introducing spatial distributions for semantic interpretation of image patches in our epitome formulation, we show that it also provides a framework to facilitate the semantic description of visual features to generate organized visual summarization of WCE video, where the patches in different positions correspond to different semantic information. Our experiments on real WCE videos show that, using epitomized summarization, the number of frames have to be examined by the gastroenterologist can be reduced to less than one-tenth of the original frames in the video.	automatic summarization;biologic preservation;capsule endoscopy;chromosome condensation;electron microscopy;evaluation;expectation–maximization algorithm;experiment;frame (physical object);frame language;image registration;imagery;semantic interpretation;used quit cigarette smoking videos;video recording;registration - actclass;tenth;videocassette	Xinqi Chu;Chee Khun Poh;Liyuan Li;Kap Luk Chan;Shuicheng Yan;Weijia Shen;That Mon Htwe;Jiang Liu;Joo-Hwee Lim;Eng Hui Ong	2010	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-15745-5_64	computer vision;semantic interpretation;expectation–maximization algorithm;computer science;machine learning;multimedia	Vision	46.89753946501599	-74.2035461718908	38186
629b10bd454b87ea837d787bd871f5e710f47cc0	locating salient edges for cbir based on visual attention model	modelizacion;contenu image;image content;raisonnement base sur cas;razonamiento fundado sobre caso;image processing;saliency map;recherche image;edge detection;localization;procesamiento imagen;semantics;edge extraction;localizacion;semantica;semantique;atencion visual;traitement image;calcul analogique;similitude;deteccion contorno;modelisation;detection contour;histogram;localisation;histogramme;similarity;attention visuelle;similitud;case based reasoning;contenido imagen;histograma;visual attention;modeling;analog calculus;calculo analogico;image retrieval;image similarity	Visual attention model was usually used for salient region detection. However, little work has been employed to use the model for salient edge extraction. Since edge information is also important element to represent the semantic content of an image, in this paper, attention model is extended for salient edges detection. In our approach, an improved saliency map computing algorithm is employed first. Then, based on the saliency map, a novel and efficient salient edges detection method is introduced. Moreover, the concept of salient edge histogram descriptors (SEHDs) is proposed for image similarity comparison. Experiments show that the proposed algorithm works well.	content-based image retrieval	Feng Songhe;Xu De	2006		10.1007/11881070_38	case-based reasoning;computer vision;systems modeling;edge detection;similarity;internationalization and localization;image processing;image retrieval;computer science;artificial intelligence;similitude;histogram;mathematics;semantics	Vision	43.73195728637168	-61.530619917483726	38237
34556b35d101de319bbcac0c35f8d7fc7c02cd0e	reliability-based decision fusion in multimodal biometric verification systems	benchmarking;signal image and speech processing;on line systems;evaluation performance;base donnee;procesamiento informacion;performance evaluation;biometrie;evaluacion prestacion;biometrics;evaluacion comparativa;database;biometria;base dato;data fusion;etat actuel;automatic recognition;quantum information technology spintronics;systeme en ligne;fusion donnee;state of the art;information processing;decision fusion;pattern recognition;estado actual;reconnaissance forme;reconocimiento patron;traitement information;fusion datos;reconocimiento automatico;reconnaissance automatique	We present a methodology of reliability estimation in the multimodal biometric verification scenario. Reliability estimation has shown to be an efficient and accurate way of predicting and correcting erroneous classification decisions in both unimodal (speech, face, online signature) and multimodal (speech and face) systems. While the initial research results indicate the high potential of the proposed methodology, the performance of the reliability estimation in a multimodal setting has not been sufficiently studied or evaluated. In this paper, we demonstrate the advantages of using the unimodal reliability information in order to perform an efficient biometric fusion of two modalities. We further show the presented method to be superior to state-of-the-art multimodal decision-level fusion schemes. The experimental evaluation presented in this paper is based on the popular benchmarking bimodal BANCA database.	biometrics;graphical model;multimodal interaction;oracle fusion architecture	Krzysztof Kryszczuk;Jonas Richiardi;Plamen J. Prodanov;Andrzej Drygajlo	2007	EURASIP J. Adv. Sig. Proc.	10.1155/2007/86572	computer vision;speech recognition;information processing;computer science;artificial intelligence;sensor fusion;biometrics;benchmarking	Web+IR	45.49552404406466	-59.938727129974005	38273
c0e462bd42dcab97a7c3f6c405c12790b4771c7d	feature extraction and image matching of 3d lung cancer cell image	lung cancer;image features;cancer;3d cancer cell image local invariant features feature extraction image matching;optical scanners;image matching;scale invariant feature transform matching method feature extraction image matching 3d lung cancer cell image medical analysis biotechnology confocal laser scanning microscopy harris laplace method;lung;optical scanners cancer feature extraction image matching laplace transforms lung medical image processing;research paper;laplace transforms;feature extraction image matching lungs cancer biomedical imaging image analysis automation biotechnology data mining microscopy;feature extraction;medical image processing;3d cancer cell image;confocal laser scanning microscopy;local invariant features;3d structure;invariant feature;matching method;volume data	The demand for automation in medical analysis is continuously growing with large number of application in biotechnology and medical research. Feature extraction and image matching are important steps in analyzing medical cells. In this research paper, we are concentrating on extracting and matching features from a full 3D volume data of lung cancer cell that was recorded with a confocal laser scanning microscopy (LSM) at a voxel size of about (0.3μm)3. In order to apply feature extraction on 3D cell image, the image is slices into ten different viewpoints of 2D images with thickness of each slice are about 0.1μm. An experiment has been done based on local invariant features methods which are HarrisLaplace method to extract features of each slices and SIFT matching method to find and match same features in each slices. The experiment shows that these methods can extract the same features although in different viewpoints. This research paper application can be served as preliminary step for further research study in analyzing 3D structure of cancer cell image.	3d computer graphics;experiment;feature extraction;harris affine region detector;image registration;point of view (computer hardware company);scale-invariant feature transform;sensor;thickness (graph theory);voxel	Hizmawati Madzin;Roziati Zainuddin	2009	2009 International Conference of Soft Computing and Pattern Recognition	10.1109/SoCPaR.2009.103	computer vision;feature detection;feature extraction;computer science;confocal laser scanning microscopy;machine learning;pattern recognition;feature;laplace transform;cancer;computer graphics (images)	Robotics	37.59758023362935	-74.31911079970874	38295
5deea60e3fe5695247f8a7d1d6dab1f14e405f78	reconstruction of 3d human body pose from stereo image sequences based on top-down learning	modelizacion;image tridimensionnelle;linear combination;base donnee;algoritmo busqueda;image processing;learning;top down;image matching;algorithme recherche;search algorithm;database;procesamiento imagen;base dato;stereoscopy;cuerpo humano;traitement image;statistical model;corps humain;human body model;3d human modeling;aprendizaje;modelisation;reconstruction image;apprentissage;learning methods;reconstruction of 3d human body pose;reconstruccion imagen;combinacion lineal;image reconstruction;reconstruction volume;human body;volume reconstruction;spatio temporal features;image sequence;modele statistique;learning problems;stereoscopie;tridimensional image;depth information;modelo estadistico;secuencia imagen;estereoscopia;modeling;appariement image;combinaison lineaire;sequence image;imagen tridimensional	This paper presents a novel method for reconstructing a 3D human body pose from stereo image sequences based on a top-down learning method. However, it is inefficient to build a statistical model using all training data. Therefore, the training data is hierarchically divided into several clusters to reduce the complexity of the learning problem. In the learning stage, the human body model database is hierarchically constructed by classifying the training data into several sub-clusters with silhouette images. The data of each cluster in the bottom level is represented by a linear combination of examples. In the reconstruction stage, the proposed method hierarchically searches a cluster for the best matching silhouette image using a silhouette history image (SHI). Then, the 3D human body pose is reconstructed from a depth image using a linear combination of examples method. By using depth information to reconstruct 3D human body pose, the similar poses in silhouette images are estimated as different 3D human body poses. The experimental results demonstrate that the proposed method is efficient and effective for reconstructing 3D human body poses.	top-down and bottom-up design	Hee-Deok Yang;Seong-Whan Lee	2007	Pattern Recognition	10.1016/j.patcog.2007.01.033	iterative reconstruction;stereoscopy;statistical model;computer vision;human body;systems modeling;linear combination;image processing;computer science;artificial intelligence;top-down and bottom-up design;statistics;search algorithm	Vision	46.808008176572116	-57.25368224559488	38303
bfd32172b3b064f320916b196bbd93f5a04f1b90	computerized system for quantitative assessment of atherosclerotic plaques in the femoral and iliac arteries visualized by multislice computed tomography	atherosclerotic alteration course prediction computerized quantitative plaque assessment system quantitative atherosclerotic plaque assessment femoral artery plaque iliac artery plaque atherosclerotic plaque visualization multislice computed tomography image visible atherosclerotic plaque quantification advanced morphology method image series processing sorted pixel intensity method artery segmentation accuracy lumen plaque region segmentation gaussian mixture modeling numerical analysis statistical analysis atherosclerosis progression semiautomatic femoral artery tracking semiautomatic iliac artery tracking quantitative atherosclerotic alteration evaluation surgical treatment planning;mathematical morphology computed tomography ct iliac and femoral arteries artery tracking atherosclerosis image segmentation;statistical analysis blood vessels computerised tomography diseases feature extraction gaussian processes image segmentation image sequences mathematical morphology medical image processing mixture models object tracking;arteries atherosclerosis image segmentation computed tomography polynomials medical diagnostic imaging	Objective: The investigation is aimed at the development of a semiautomatic method of examining the femoral and iliac arteries, and quantifying atherosclerotic plaques visible in the multislice computed tomography images. Methods: We have utilized the advanced morphology and segmentation methods for processing of a series of the images. In particular, a novel sorted pixel intensity approach to segment the artery into the lumen/plaque regions has been used, and effectively combined with the Gaussian mixture modeling to increase the accuracy of the segmentation. Results: Our numerical results are compared with those obtained manually by two experts. Statistics relevant to the progression of atherosclerosis have also been suggested. Results of the semiautomatic tracking of the femoral and iliac arteries and of the quantitative evaluation of atherosclerotic alterations therein have been shown to correspond well with the expert's results. Conclusion: The developed system is likely to be valuable tool for supporting the quantitative evaluation of atherosclerotic changes in arteries. Significance: In its present form the system can be used for planning surgical treatment and/or predicting the course of the atherosclerotic alterations.	arterial system;atherosclerosis;bone structure of ilium;ct scan;color gradient;galaxy morphological classification;image segmentation;mixture model;multidetector computed tomography;normal statistical distribution;numerical analysis;pixel;senile plaques;structure of iliac artery;structure of lumen of body system;x-ray computed tomography;biologic segmentation	Tomasz Markiewicz;Miroslaw Dziekiewicz;Stanislaw Osowski;Romana Boguslawska-Walecka;Wojciech Kozlowski;Marek Maruszynski	2015	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2015.2392254	computer vision;radiology;pathology	Visualization	38.9997971983378	-79.27567982084871	38331
691ea522d998ccc887d7118aeec59a4e1fac29e4	automatic scale selection as a pre-processing stage to interpreting real-world data	feature detection;software performance evaluation computer vision image representation feature extraction;computer and information science;software performance evaluation;computer vision;computer vision writing laboratories numerical analysis buildings detectors image analysis pattern analysis performance analysis application software;scale space;image representation;feature extraction;data och informationsvetenskap;low level vision modules automatic scale selection real world data interpretation ranges of scale scale of observation unknown measurement data processing image representation scale space representation normalized derivatives image structures feature detection computer vision applications performance	We perceive objects in the world as meaningful entities only over certain ranges of scale. A simple example is the concept of a branch of a tree, which makes sense only at a scale from, say, a few centimeters to at most a few meters, It is meaningless to discuss the tree concept at the nanometer or kilometer level. At those scales, it is more relevant to talk about the molecules that form the leaves of the tree, and the forest in which the tree grows, respectively. This fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of “scale” is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by “representing” image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to “select” local appropriate scales for further analysis. After a brief review of the main ideas behind a scale-space representation, I will in this talk describe a recently developed systematic methodology for “generating hypotheses about interesting scale levels in image data” based on a general principle stating that local extrema over scales of different combinations of “normalized derivatives” are likely candidates to correspond to interesting image structures. Specifically, it will be shown how this idea can be used for formulating feature detectors which automatically adapt their local scales of processing to the local image structure. Support for the proposed methodology will be presented in terms of general study of the scale selection method under rescalings of the input data, as well as more detailed analysis of how the scale selection method performs when integrated with various types of feature detection modules and then applied to characteristic image patterns. Moreover, it will be illustrated by a rich set of experiments how this scale selection approach applies to various types of feature detection problems in early vision. In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottle-neck. It will be argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to analyze complex unknown environments. T. Lindeberg. “Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention.’’ IJCV, 11(3):283-318, 1993. T. Lindeberg. “On scale selection for differential operators.” In 8th SCIA, pages 857-866, 1993. T. Lindeberg. “Scale-Space Theory in Computer Vision.” Kluwer, Netherlands, 1994. T. Lindeberg. “Edge detection and ridge detection with automatic scale selection.” In Proc. IEEE Comp. Soc. Conf. on Computer Vision and Pattern Recognition, 1996, pages 465-470, San Francisco, California, 1996. T. Lindeberg. “Feature detection with automatic scale selection.” Technical Report ISRN KTHINAA?-{ }-96118-{ }-SE, KTH, 1996. T. Lindeberg. “A scale selection principle for estimating image deformations.” Technical Report Shortened version in 5th ICCV. ISRN KTWNAP-{ }-96116-{ }-SE, KTH, 1996. 490 0-8186-7686496 $05.00	computer vision;edge detection;entity;experiment;feature detection (computer vision);feature detection (web development);high- and low-level;iccv;maxima and minima;pattern recognition;ridge detection;scale space;scandinavian conference on image analysis;sensor;the forest	Tony Lindeberg	1996		10.1109/TAI.1996.560799	computer vision;feature detection;scale space;feature extraction;computer science;artificial intelligence;machine learning;kanade–lucas–tomasi feature tracker;feature detection;data mining;multi-scale approaches;n-jet;automatic image annotation;feature;scale-space axioms	Vision	39.903951335528575	-54.2776697981811	38344
d74bc67aaa686fd330b6f26a9ff3d33588c118f2	a fast algorithm for integrating connected-component labeling and euler number computation		This paper proposes a fast algorithm for integrating connected-component labeling and Euler number computation. Based on graph theory, the Euler number of a binary image in the proposed algorithm is calculated by counting the occurrences of four patterns of the mask for processing foreground pixels in the first scan of a connected-component labeling process, where these four patterns can be found directly without any additional calculation; thus, connected-component labeling and Euler number computation can be integrated more efficiently. Moreover, when computing the Euler number, unlike other conventional algorithms, the proposed algorithm does not need to process background pixels. Experimental results demonstrate that the proposed algorithm is much more efficient than conventional algorithms either for calculating the Euler number alone or simultaneously calculating the Euler number and labeling connected components.	algorithm;binary image;computation (action);connected component (graph theory);connected-component labeling;euler;graph - visual representation;graph theory;pixel	Lifeng He;Bin Yao;Xiao Zhao;Yun Yang;Zhenghao Shi;Hideto Kasuya;Yuyan Chao	2015	Journal of Real-Time Image Processing	10.1007/s11554-015-0499-1	mathematical optimization;euler tour technique	Graphics	45.77594718970156	-68.53783931573581	38388
bf83972ae84773a7ee7b1ca2b0d3e1bed909c493	multi-scale stacked sequential learning	modelizacion;stacked sequential learning;evaluation performance;methode essai;performance evaluation;image processing;long range interaction;learning;methode echelle multiple;probabilidad condicional;evaluacion prestacion;pixel classification;probabilite conditionnelle;procesamiento imagen;image classification;metodo escala multiple;analyse multiresolution;traitement image;aprendizaje;modelisation;etat actuel;apprentissage;campo aleatorio;machine learning;state of the art;classification image;conditional random field;multiresolution;estado actual;dependent data;multiscale method;interaction model;test method;multiscale;multiresolution analysis;modeling;conditional probability;analisis multiresolucion;champ aleatoire;contextual classification;random field;metodo ensayo	Sequential learning is the discipline of machine learning that deals with dependent data such that neighboring labels exhibit some kind of relationship. The paper main contribution is two-fold: first, we generalize the stacked sequential learning, highlighting the key role of neighboring interactions modeling. Second, we propose an effective and efficient way of capturing and exploiting sequential correlations that takes into account long-range interactions. We tested the method on two tasks: text lines classification and image pixel classification. Results on these tasks clearly show that our approach outperforms the standard stacked sequential learning as well as state-of-the-art conditional random fields. & 2011 Elsevier Ltd. All rights reserved.	adaboost;conditional random field;fastest;feature vector;interaction;machine learning;nonlinear system;pixel;sampling (signal processing)	Carlo Gatta;Eloi Puertas;Oriol Pujol	2011	Pattern Recognition	10.1016/j.patcog.2011.04.003	multiresolution analysis;contextual image classification;random field;systems modeling;conditional probability;image processing;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;test method;conditional random field;statistics	AI	45.04023546415505	-61.44633929280485	38400
8d95ef00e55d77331e1424bfc2a2fcff111f019c	accurate inversion of 3-d transformation fields	equation non lineaire;topology;ecuacion no lineal;spline;transformation field inversion;algorithm performance;image resolution;gauchissement;splines mathematics image registration nonlinear equations;interval analysis techniques;indexing terms;carta de datos;splines mathematics;algorithme;algorithm;accuracy;distance measurement;intersubject brain registration 3d transformation fields image warping problems b spline based representation topology preservation nonlinear equations interval analysis techniques topology preserving b spline based deformation fields;precision;estimation;transformation field inversion image warping interval analysis resolution of systems of nonlinear equations;resultado algoritmo;mappage;image registration;3d transformation fields;torcimiento;topology preserving b spline based deformation fields;performance algorithme;intersubject brain registration;resolution of systems of nonlinear equations;nonlinear equations;mapping;b spline based representation;b spline;topology nonlinear equations brain modeling interpolation stress yield estimation parameter estimation;image warping problems;topology preservation;algorithms brain image enhancement image interpretation computer assisted imaging three dimensional magnetic resonance imaging reproducibility of results sensitivity and specificity;non linear equation;systems of nonlinear equations;warping;b splin;interval analysis;image warping;algoritmo	This correspondence addresses the inversion of 3-D transformation fields, which is a problem that typically arises in image warping problems. A topology preserving parametric B-spline-based representation of the deformation field is considered. Topology preservation ensures that the transformation is a one-to-one mapping and consequently that it is invertible. Inverting such transformation fields amounts to solving a system of nonlinear equations. To tackle this problem, we rely on interval analysis techniques. The proposed algorithm yields a solution whose accuracy is user-controlled. This method may be extended to any dense transformation field and also to deformations defined on a grid of points, by considering a projection in the space of topology preserving B-spline-based deformation fields. The performance of the algorithm is illustrated on transformation fields coming from intersubject brain registration.	addresses (publication format);algorithm;anatomy, regional;b-spline;biologic preservation;image warping;interval arithmetic;musculoskeletal diseases;nonlinear system;one-to-one (data model)	Vincent Noblet;Christian Heinrich;Fabrice Heitz;Jean-Paul Armspach	2008	IEEE Transactions on Image Processing	10.1109/TIP.2008.2002310	image warping;computer vision;mathematical optimization;discrete mathematics;nonlinear system;computer science;mathematics;geometry;accuracy and precision;statistics	Visualization	47.6005017271148	-78.05941573271967	38478
0b841fb3e3e0e6eacc342631c4944249bdef8fe7	neurosphere fate prediction: an analysis-synthesis approach for feature extraction	optimisation;evolutionary computation;image segmentation;image texture;prediction theory;feature extraction;medical image processing;image registration;medicine;solid modeling biological system modeling image segmentation feature extraction data models stem cells;prediction theory evolutionary computation feature extraction image registration image segmentation image sequences image texture medical image processing medicine optimisation;registration algorithm neurosphere fate prediction analysis synthesis approach feature extraction biomedical research field regenerative medicine automated methods neural stem cell development neurosphere colony phase contrast microscopy structural features extraction textural features extraction cell division dynamism cell behavior patterns biological interpretation phase contrast imaging complex evolution image processing image analysis on line analysis method time lapse sequences fast level set curve detection cells segmentation prior biological knowledge optimal 3 dimensional configuration evolutionary optimisation algorithm;image sequences	The study of stem cells is one of the current most important biomedical research field. Understanding their development could allow multiple applications in regenerative medicine. For this purpose, we need automated methods for the segmentation and the modeling of neural stem cell development process into a neurosphere colony from phase contrast microscopy. We use such methods to extract relevant structural and textural features like cell division dynamism and cell behavior patterns for biological interpretation. The combination of phase contrast imaging, high fragility and complex evolution of neural stem cells pose many challenges in image processing and image analysis. This study introduces an on-line analysis method for the modeling of neurosphere evolution during the first three days of their development. From the corresponding time-lapse sequences, we extract information from the neurosphere using a combination of fast level set and curve detection for segmenting the cells. Then, based on prior biological knowledge, we generate possible and optimal 3-dimensional configuration using registration and evolutionary optimisation algorithm.	algorithm;bioinformatics;business interoperability interface;data mining;edge detection;feature extraction;image analysis;image processing;itk;library (computing);mathematical optimization;online and offline;vtk	Stephane Ulysse Rigaud;Nicolas Loménie;Shvetha Sankaran;Sohail Ahmed;Joo-Hwee Lim;Daniel Racoceanu	2012	The 2012 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2012.6252628	image texture;computer vision;feature extraction;computer science;image registration;machine learning;pattern recognition;image segmentation;evolutionary computation	Robotics	44.05979357525636	-76.56622259674684	38540
59c4f3f75f807c43171d25371a7c243544490487	automatic nuclei and cytoplasm segmentation of leukocytes with color and texture-based image enhancement	cell segmentation;image enhancement white blood cells cell segmentation peripheral blood smears;image segmentation image color analysis gray scale discrete wavelet transforms white blood cells color;image enhancement;peripheral blood smears;white blood cells	Designing a single automatic and accurate segmentation approach for different classes of white blood cells is a challenging task. This paper presents a fully automated segmentation framework to segment both nuclei and cytoplasm of five major classes of white blood cells in the peripheral blood smears based on color and texture enhancement. Particularly, a new gray-scale transform is generated based on three representative color channels to separate the nuclei from the cytoplasm and background by Poisson distribution based minimum error thresholding. For cytoplasm segmentation, discrete wavelet transform (DWT) and morphological filtering based enhancement procedure is utilized to highlight the cytoplasm and eliminate the small details inside the cells. Finally level set-based refinement and false candidates filtering are applied to obtain the accurate cell segmentation. The proposed approach is evaluated on two sets of peripheral blood smears, and it demonstrates improved segmentation performance when compared with existing methods.	channel (digital image);discrete wavelet transform;grayscale;image editing;mathematical morphology;peripheral;refinement (computing);thresholding (image processing)	Afaf Tareef;Yang Song;Tom Weidong Cai;Yue Wang;David Dagan Feng;Mei Chen	2016	2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2016.7493418	computer vision;pathology;anatomy	Vision	38.833177200456745	-74.94332531060665	38553
2a7ec1540b9bb5813c28f7fba98b7ec219d6db89	multi-scale rock detection on mars		In this paper, we propose a novel autonomous Martian rock detection framework via superpixel segmentation. Different from current state-of-the-art pixel-level rock segmenting methods, the proposed method deals with this issue in region level. Image is splitted into homogeneous regions based on intensity information and spatial layout. The heart of proposed framework is to enhance such region contrast. Then, rocks can be simply segmented from the resulting contrast-map by an adaptive threshold. Our method is efficient in dealing with large image and only few parameters need to set. Preliminary experimental results show that our algorithm outperforms edge-based methods in various grayscale rover images.		Guoqing Li;Yunhai Geng;Xueming Xiao	2018	SCIENCE CHINA Information Sciences	10.1007/s11432-017-9277-x	grayscale;mathematical optimization;computer vision;homogeneous;mars rover;mathematics;mars exploration program;artificial intelligence	Theory	46.51889567122969	-66.55266444135506	38554
483f00ebf3a1846b89ccacaf2bd4081a3da92b2d	a hybrid license plate extraction method for complex scenes	licenses layout image edge detection data mining vehicles intelligent transportation systems radiofrequency identification computer science monitoring control systems;license plate extraction;edge detection;image colour analysis edge detection feature extraction;refining selection;line detection;satisfiability;color constraints;hybrid method;image colour analysis;feature extraction;straight line detection;weight based edge density map;weight assignment;color constraints license plate extraction cluttered images straight line detection weight assignment weight based edge density map refining selection;extraction method;cluttered images	This paper presents a hybrid method for extracting license plates from cluttered images. The proposed algorithm consists of three major components. First, a line detection method is proposed to detect straight lines in the edge map. Second, a weight assignment scheme is applied to obtain a weight based edge density map. Regions with the densest edges are selected as candidates. Third, all candidate plates will pass to a refining selection procedure. One candidate that best satisfy the color constraints becomes the output	algorithm;color;edge detection	Wangchao Le;Shaofa Li	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.83	computer vision;edge detection;feature extraction;computer science;pattern recognition;satisfiability	Vision	44.85644094841359	-54.06193867308858	38557
316f036b6fc4a6fe4cd50620b23edcc89175d6e3	otitis media vocabulary and grammar	grammar;biological patents;otitis media with no effusion otitis media vocabulary otitis media grammar otitis media diagnostic category classification accuracy middle ear inflammation acute otitis media bacterial superinfection middle ear fluid sterile effusion children diagnosis antibiotics overprescription feature set visual cues vocabulary terms decision process otitis media with effusion;biomedical journals;text mining;europe pubmed central;set theory diseases ear image classification medical image processing microorganisms paediatrics;vocabulary;citation search;image classification;set theory;citation networks;classification;ear;research articles;paediatrics;abstracts;medical image processing;open access;life sciences;clinical guidelines;diseases;media vocabulary grammar gray scale feature extraction lighting image color analysis;full text;grammar otitis media classification vocabulary;microorganisms;rest apis;orcids;europe pmc;biomedical research;otitis media;bioinformatics;literature search	We propose an automated algorithm for classifying diagnostic categories of otitis media (middle ear inflammation); acute otitis media, otitis media with effusion and no effusion. Acute otitis media represents a bacterial superinfection of the middle ear fluid and otitis media with effusion a sterile effusion that tends to subside spontaneously. Diagnosing children with acute otitis media is hard, leading to overprescription of antibiotics that are beneficial only for children with acute otitis media, prompting a need for an accurate and automated algorithm. To that end, we design a feature set understood by both otoscopists and engineers based on the actual visual cues used by otoscopists; we term this otitis media vocabulary. We also design a process to combine the vocabulary terms based on the decision process used by otoscopists; we term this otitis media grammar. The algorithm achieves 84% classification accuracy, in the range or outperforming clinicians who did not receive special training, as well as state-of-the-art classifiers.	acute inflammatory demyelinating polyneuropathy;acute otitis media;categories;classification;ear inflammation;engineering;infectious otitis media;infertility;leukemia, myelocytic, acute;otitis media with effusion;superinfection;vocabulary;algorithm;grammar;middle ear	Anupama Kuruvilla;Pablo H. Hennings-Yeomans;Pedro Quelhas;Nader Shaikh;Alejandro Hoberman;Jelena Kovacevic	2012	2012 19th IEEE International Conference on Image Processing	10.1109/ICIP.2012.6467492	contextual image classification;text mining;speech recognition;biological classification;computer science;grammar;microorganism;set theory	Visualization	37.144364897009815	-75.52214469924347	38606
8ba801da3e5a7cdc58af118350621ccce71ef74b	breast tissue segmentation on mr images using kfcm with spatial constraints	breast tissue;manuals;kernel;image segmentation;linear programming;clustering algorithms	Accurate segmentation of breast on MR images is an essential and crucial step for computer-aided breast disease diagnosis and surgical planning. In this paper, an effective approach is proposed for segmenting the breast image into different regions, each corresponding to a different tissue. The segmentation work flow comprises two key steps. Firstly, we use the threshold-based method and morphological operations to determine the breast-air boundary and breast-chest wall so that the breast region can be extracted. Then a kernelled fuzzy C-means algorithm with spatial information (SKFCM) is used to separate the fibroglandular tissues from the fat. The proposed method is used to segment the clinical breast MR images. Experimental results have been shown visually and achieve reasonable consistency. The SKFCM method is appropriate for the problem of breast tissue segmentation.	algorithm;fuzzy cognitive map;mathematical morphology	Hong Song;Qian Zhang;Feifei Sun;Jiandong Wang;Quansheng Wang;Jingdan Qiu;Deqiang Kou	2014	2014 IEEE International Conference on Granular Computing (GrC)	10.1109/GRC.2014.6982845	computer vision;kernel;computer science;linear programming;machine learning;segmentation-based object categorization;image segmentation;cluster analysis;scale-space segmentation	Robotics	40.46621521314466	-77.17670581659905	38646
56a6e7bbfeb03485b0c9d5904052646b0f653d6a	a novel genetic programming based morphological image analysis algorithm	genetic program;binary image;morphological operation;genetic programming;image enhancement;region of interest;evolution strategy;image analysis;infrared;mathematics morphological	This paper gives an applicable genetic programming(GP) approach to solve the binary image analysis and gray scale image enhancement problems. By showing a section of binary image and the corresponding goal image, this algorithm automatically produces a mathematic morphological operation sequence to transform the target into the goal. While the operation sequence is applied to the whole image, the objective of image analysis is achieved. With well-defined chromosome structure and evolution strategy, the effectiveness of evolution is promoted and more complex morphological operations can be composed in a short sequence. In addition, this algorithm is also applied to infrared finger vein gray scale images to enhance the region of interest. Whose effect is examined by an application of identity authentication, and the accuracy of authentication is promoted.	algorithm;authentication;binary image;evolution strategy;genetic programming;grayscale;image analysis;image editing;mathematical morphology;region of interest	Jun Wang;Ying Tan	2010		10.1145/1830483.1830659	genetic programming;computer vision;feature detection;image analysis;infrared;binary image;computer science;artificial intelligence;machine learning;mathematics;evolution strategy;top-hat transform;region of interest	Vision	41.98295370369232	-66.20510584728109	38702
2fb67775feb9018933ca6d5e0364fd61687b2fd4	semi-supervised learning based on joint diffusion of graph functions and laplacians		In existing anisotropic diffusion-based semi-supervised learning approaches, anisotropic graph Laplacian is estimated based on (potentially noisy) function evaluations. We propose to regularize the graph Laplacian estimates. We develop a framework that regularizes the Laplace-Beltrami operators on Riemannian manifolds, and discretize it to a regularizer on diffusivity operators on graphs. Isotropic Laplace-Beltrami operator Δ on a Riemannian manifold (M, g) with a metric g is a second-order differential operator: Δf = ∇g∗∇gf, where ∇g and ∇g∗ are the gradient and divergence operators, respectively. Δ generates the diffusion process on M : ∂f ∂t = −Δgf. Anisotropic Laplace-Beltrami operator Δ is defined based on a symmetric positive definite diffusivity operator D: Δf = ∇g∗D∇gf. D controls the strength and direction of diffusion at each point x on M . Regularizing Δ by regularizing D as a surrogate: 1) Kernel-based Δ representation [HAL05]: A consistent kernel-based estimate Δghf : [Δghf ](x) = 1 h2 ( f(x)− [A g h(x)f ] dh(x) ) , where [Agh(x)f ] = ∫ M kh(x, y)f(y)dV (x), dh(x) = [A g h(x)1], dV (x) = √| det(g)|dx (g: g’s coordinate matrix), and kh(x, y) = { 1 hm k(‖i(x)− i(y)‖Rm , h) if ‖i(x)− i(y)‖Rm ≤ h 0 otherwise with k(a, b) = exp (−a/b) and i being the embedding of M into R. ⇒ The spatial variation of Δ is entirely determined by the metric g. 2) Equivalence of metric and diffusivity operator on manifolds: Proposition 1 (KTP15) The anisotropic Laplacian operator Δ on a compact Riemannian manifold (M, g) is equivalent to the Laplace-Beltrami operator Δ on (M, g) with a new metric g depending on D. When the diffusivity operator D is uniformly positive definite, g is explicitly obtained as c(x)g(x) = g(x)D−1(x), where g(x) and D(x) are the coordinate matrices of g and D at each point x, and c(x) = √ detg(x)/ √ detg(x). ⇒ Anisotropic diffusion on (M, g) is isotropic diffusion on M with a new metric g. Discretization: On a weighted graph (X,E,W ) with nodes X = {x1, . . . ,xu}, edges {Ei} = {eij} ⊂ X × X, non-negative similarities wij := w(eij) ∈ W , and the space of functions H(Ei) on Ei, the local graph diffusivity operator Di : H(Ei) → H(Ei) is defined as: Di := ∑ {j:(j,i)∈Ei} qijbij ⊗ bij ⇔ [DiS](eij) = qijbij 〈bij , S〉 , ∀S ∈ H(Ei), ⊗: the tensor product; basis function bij := 1ij ∈ H(E). The anisotropic graph Laplacian is defined as: [Lf ](xi) := [∇iDi∇if ](xi) = ⎛ ⎝ 1 di u ∑ j=1 wijqij ⎞ ⎠ f(xi)− 1 di u ∑	anisotropic diffusion;basis function;discretization;exptime;emoticon;gradient;laplacian matrix;semi-supervised learning;semiconductor industry;supervised learning;turing completeness;vergence	Kwang In Kim	2016		10.1007/978-3-319-46454-1_43	combinatorics;mathematical analysis;topology;mathematics	Vision	51.49283750876555	-73.55426617606652	38732
df37395faa21f4d28200b8c85a5f4e8cf6d8d451	split bregman's algorithm for three-dimensional mesh segmentation	image segmentation		algorithm;bregman divergence	Nabi Habiba;Ali Douik	2016	J. Electronic Imaging	10.1117/1.JEI.25.3.033011	computer vision;computer science;segmentation-based object categorization;pattern recognition;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation	Theory	45.93990633077944	-70.24652764805035	38737
11859d37c85c7bb07f7496a62530340e1fdf7887	aha-3d: a labelled dataset for senior fitness exercise recognition and segmentation from 3d skeletal data		Automated assessment of fitness exercises has important applications in computer and robot-based exercise coaches to deploy at home, gymnasiums or care centers. In this work, we introduce AHA-3D, a labeled dataset of sequences of 3D skeletal data depicting standard fitness tests on young and elderly subjects, for the purpose of automatic fitness exercises assessment. To the best of our knowledge, AHA-3D is the first publicly available dataset featuring multi-generational, male and female subjects, with frame-level labels, allowing for action segmentation as well as the estimation of metrics like risk of fall, and autonomy to perform daily tasks. We present two baseline methods for recognition and one for segmentation. For recognition, we trained models on the positions of the joints achieving 88.2%± 0.077 accuracy, and on joint positions and velocities, achieving 91%± 0.082 accuracy. Using the Kolmogorov-Smirnov test we determined the model trained on velocities was superior. The segmentation baseline achieved an accuracy of 88.29% in detecting actions at frame level. Our results show promising recognition and detection performance suggesting AHA3D’s potential use in practical applications like exercise performance and correction, elderly fitness level estimation and risk of falling for elders.	autonomy;baseline (configuration management);international symposium on fundamentals of computation theory;item unique identification;sensor	João Antunes;Alexandre Bernardino;Asim Smailagic;Daniel P. Siewiorek	2018			artificial intelligence;pattern recognition;computer vision;computer science;segmentation	Vision	26.774495751767997	-75.83586722370808	38770
52a1beeeda6ef57639f2b40d71eb4eed6d9930d2	analysis and recognition of facial expression based on point-wise motion energy	facial expression recognition;rule based;human machine interface;facial features;facial expression;energy value;real time systems	Automatic estimation of facial expression is an important step in en- hancing the capability of human-machine interfaces. In this research, we pres- ent a novel method that analyses and recognizes facial expression based on point-wise motion energy. The proposed method is simple because we exploit a few motion energy values, which is acquired by an intensity-based thresholding and counting algorithm. The method consists of two steps: analysis and recog- nition. At the analysis step, we compute the motion energies of facial features and compare them with each other to figure out the normative properties of each expression. We extract the dominant facial features related to each expres- sion among facial features. At the recognition step, we perform rule-based fa- cial expression recognition on arbitrary images using the results of analysis. We apply the proposed method to the JAFFE database and verify its feasibility. In addition, we implement a real-time system that recognizes facial expression very well under weakly-controlled environments.		Hanhoon Park;Jong-Il Park	2004		10.1007/978-3-540-30126-4_85	rule-based system;human–machine interface;computer vision;speech recognition;computer science;facial expression	Vision	30.381052692099228	-60.74736481049602	38773
5d9ab10d5e1c2ca70acc1c6aa4e735a3da276664	advances in texture-based segmentation of high resolution remote sensing imagery	remote sensing image;geophysical image processing;texture;texture fragmentation and reconstruction algorithm;high resolution;image segmentation;region adjacency graph texture based segmentation high resolution remote sensing imagery texture fragmentation and reconstruction algorithm nested segmentation maps watershed like transform;image resolution;high resolution remote sensing imagery;testing;segmentation;image segmentation image resolution remote sensing testing image reconstruction algorithm design and analysis large scale systems merging tin biomedical engineering;region adjacency graph;image texture;region adjacency graph remote sensing images segmentation texture;remote sensing imagery;texture based segmentation;biomedical engineering;image reconstruction;remote sensing;watershed like transform;merging;nested segmentation maps;remote sensing images;tin;remote sensing geophysical image processing geophysical techniques image reconstruction image segmentation image texture;algorithm design and analysis;geophysical techniques;large scale systems	The Texture Fragmentation and Reconstruction (TFR) algorithm, recently proposed for the segmentation of textured images, has been applied with promising results to high-resolution remote-sensing images. The algorithm provides a sequence of nested segmentation maps which allow the analysis at various scales of observation. Although for most test images TFR has proven able to recognize major semantic areas, some failures have also been observed due to the presence of large background regions that span the whole image and prevent the formation of distinct local textures. In this paper we introduce a new step in the TFR processing flow which detects background regions and divides them in multiple homogeneous fragments based on their geometric level properties. To this end, connected regions are first reduced to atomic components through a watershed-like transform, and then clustered again based on the features of the associated region-adjacency graph. Early experimental results prove the effectiveness of the new processing step, and its beneficial effect on the whole algorithm.	algorithm;fragmentation (computing);image resolution;map;watershed (image processing)	Raffaele Gaetano;Giuseppe Scarpa;Giovanni Poggi	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5417361	computer vision;image resolution;computer science;remote sensing;computer graphics (images)	Vision	47.358958200475094	-67.46791184005663	38801
7d7d21c8f26b4be4769a3134c2d72c4d508bcab0	stereo matching using reduced-graph cuts	minimisation;graph theory;image matching;disparity range stereo matching reduced graph cut global energy function minimisation;indexing terms;energy function;stereo matching;cameras cost function stereo vision taxonomy optimization methods calibration parameter estimation phase estimation solid modeling layout;graph cut;matching;stereo image processing;stereo vision;graph cut stereo vision matching;stereo image processing graph theory image matching minimisation	Some recent stereo matching algorithms are based on graph cuts. They transform the matching problem to a minimisation of a global energy function. The minimisation can be done by finding out an optimal cut in a special graph. Different methods were proposed to construct the graph. But all of them, consider for each pixel, all possible disparities between minimum and maximum values. In this article, a new method is proposed: only some potential values in the disparity range are selected for each pixel. These values can be found using a local analysis of stereo matching. This method allows us to make wider the disparity range, and at the same time to limit the volume of the graph, and therefore to reduce the computation time.	algorithm;binocular disparity;computation;computer stereo vision;cut (graph theory);matching (graph theory);mathematical optimization;pixel;time complexity	Ayman Zureiki;Michel Devy;Raja Chatila	2007	2007 IEEE International Conference on Image Processing	10.1109/ICIP.2007.4378935	computer stereo vision;matching;graph cuts in computer vision;computer vision;minimisation;mathematical optimization;template matching;index term;cut;stereopsis;graph theory;3-dimensional matching;pattern recognition;mathematics	Vision	49.81361866030901	-53.36475362563406	38838
37cd3ba9c66039b430a9536c77601fd5822338f8	undecimated discrete wavelet transform for touchless 2d fingerprint identification		Several recent research efforts in biometrics have focused on developing the touchless fingerprint identification system. Most of them are using imaging resulting from cameras and mobile devices. The acquired images are firstly subjected to robust preprocessing steps to localise region of interest in order to extract its features. In the literature, touchless fingerprint features are generally based on algorithms designed for minutiae analysis in touch-based images. Because of perspective distortions and deformations in the samples, minutiae-based techniques can obtain poor results. This paper investigates multi-resolution decomposition features to overcome the limitations of using traditional minutiae algorithms in term of accuracy and matching speed. These decompositions are implemented on Hong Kong Polytechnic University 2D touchless fingerprint database that contains 10,080 images. Experimental results illustrate successful use of undecimated discrete wavelet transform (UDWT) and discrete wavelet pack...	discrete wavelet transform;fingerprint	Salah Ahmed Saeed Othman;Tarik Boudghene Stambouli	2016	IJBM	10.1504/IJBM.2016.10003549	discrete wavelet transform	Vision	34.018934546645546	-61.0580133990721	38859
8cbce87c5e9a8fc411fbcb269928f6e1523e634f	multivariate discriminant analysis of multiparametric brain mri to differentiate high grade and low grade gliomas — a computer-aided diagnosis development study	tumors principal component analysis magnetic resonance imaging sensitivity and specificity sensitivity linear discriminant analysis;brain;biodiffusion;tumours;sensitivity analysis;medical image processing;principal component analysis;primary tumor multivariate discriminant analysis multiparametric brain mri low grade gliomas high grade gliomas computer aided diagnosis development study magnetic resonance imaging diffusion weighted mr imaging diffusion tensor imaging perfusion mr imaging mr spectroscopic imaging principal component analysis dimensional reduction quadratic discriminant analysis linear discriminant analysis specificity analysis sensitivity analysis computer aided diagnosis system glioma grading;tumours biodiffusion biomedical mri brain medical image processing principal component analysis sensitivity analysis;biomedical mri	The aim of this study is to investigate the predictive capacity of multiparametric magnetic resonance imaging (MRI) findings using multivariate discriminant analysis. Preoperative clinical findings and multiparametric MRI, including diffusion weighted MR imaging, diffusion tensor imaging, perfusion MR imaging and MR spectroscopic imaging, were used as predictors to distinguish high grade from low grade gliomas. Principal component analysis was performed prior to discriminant analysis for dimensional reduction. Linear and quadratic discriminant analysis were performed and compared based on sensitivity and specificity analysis. The sensitivities of linear and quadratic discriminant analysis were 76.5% and 83.5%, respectively. Their specificities were 68.5% and 46.5%, respectively. Quadratic discriminant analysis provided a better discrimination than linear discriminant analysis for this dataset. This study is a model for a computer aided diagnosis system for glioma grading.	linear discriminant analysis;principal component analysis;quadratic classifier;resonance;sensitivity and specificity	Fusun Citak Er;Zeynep Firat;Ilhami Kovanlikaya;Ugur Türe;Esin Ozturk-Isik	2013	13th IEEE International Conference on BioInformatics and BioEngineering	10.1109/BIBE.2013.6701649	computer science;machine learning;sensitivity analysis;statistics;principal component analysis	Vision	30.829469152498092	-78.58192202663275	38885
349cc9a5607f4b164537735677cf678eaaa26511	real-time surveillance system detecting persons in complex scenes	systeme temps reel;traitement signal;deteccion blanco;flux optique;surveillance;surveillance system;real time;intruso;space time;satisfiability;detection cible;detection objet;visual surveillance;vigilancia;senal video;signal video;flujo optico;feature extraction;signal processing;video signal;intrus;real time system;optical flow;sistema tiempo real;extraction caracteristique;procesamiento senal;target detection;intruder;object detection	To provide better customer service, NCJRS has made this Federally-funded grant final report available electronically in addition to traditional paper copies. Opinions or points of view expressed are those of the author(s) and do not necessarily reflect the official position or policies of the U.S.	national criminal justice reference service;real-time transcription;sensor	Akihiko Iketani;Atsushi Nagai;Yoshinori Kuno;Yoshiaki Shirai	2001	Real-Time Imaging	10.1006/rtim.2000.0211	computer vision;telecommunications;feature extraction;computer science;space time;signal processing;optical flow;satisfiability	Graphics	47.51902330405626	-56.815063309017305	38911
fe79140ba00b0dc3ee0bbbc23771d739c95434b8	color texture image retrieval based on gaussian copula models of gabor wavelets	copula model;image representation;gabor wavelets;color texture retrieval	Color texture retrieval is a hot research area in image analysis. In this paper, we propose an efficient color texture retrieval method by using copula model based on Gabor wavelets. When Gabor wavelets are used to decompose color image, three types of dependence exist in the decomposed subbands of Gabor wavelets: color dependence, scale dependence and direction dependence. We analyze these dependencies and then capture them by using Gaussian copula function. Four copula schemes are developed, and accordingly four KLDs (Kullback-Leibler distances) of the copula schemes are introduced for color texture image retrieval. The evaluations of the proposed method are performed on several color texture databases including two large texture databases ALOT and STex. Experimental results demonstrate the proposed method has better performance than the state-of-the-art retrieval methods. HighlightsWe propose a color texture retrieval method by using Gabor wavelet and Copula model.We use copula model to capture the dependencies of Gabor wavelet and color channels.Four copula models are implemented based on Gabor wavelet in color space.Our method shows better performance on large databases than other popular methods.	gabor filter;image retrieval;wavelet	Chaorong Li;Yuanyuan Huang;Lihong Zhu	2017	Pattern Recognition	10.1016/j.patcog.2016.10.030	image texture;computer vision;speech recognition;pattern recognition;mathematics;gabor wavelet	Vision	37.31567559068152	-60.359792802022454	39028
7d13e13350979cceed5f1eac9c6d14c135db3969	multiscale am-fm models and instantaneous amplitude evaluation for mammographic density classification		Breast cancer is the most common cancer in women and the number of incidences keeps rising. Mammographic breast density has been recognized as a very important breast cancer risk and can also mask abnormalities. Information regarding mammographic breast density may be used for planning individualized breast cancer screening and treatment. Thus, breast density is increasingly assessed as the limitations of a onefits-all method of screening and Computer Aided Detection become more apparent. The presented work investigates the use of Amplitude-Modulation Frequency-Modulation (AM-FM) models in the evaluation of multiscale Instantaneous Amplitude (IA) features for the characterization of breast density. AM-FMmodels provide a meaningful and concise method to model digital images. The IA evaluated at different frequency scales is used to capture the relative variations in the breast tissue characteristic to the different breast density classes. Normalized histograms of the IA across the different frequency scales estimated using multiscale Dominant Component Analysis are used to model the breast density classes. Classification of a new mammogram into one of the density categories is achieved using the k-nearest neighbor method and the Euclidean distance metric. The method is evaluated using the Breast Imaging Reporting and Data System on the Medical Image Analysis Society mammographic database and the results are presented and compared to other methods in the literature. The presented method allows breast density classification accuracy reaching over 80%.	am broadcasting;bi-rads;data system;database;digital image;euclidean distance;fm broadcasting;image analysis;k-nearest neighbors algorithm;medical image computing;modulation;nearest neighbor search	Ioannis Constantinou;Marios S. Pattichis;Chrysa Tziakouri;Constantinos S. Pattichis;Styliani Petroudi	2014			am/fm/gis;computer vision;amplitude;artificial intelligence;mammographic density;mathematics;pattern recognition	Vision	34.91514687953791	-77.07260159976637	39030
aefc40554cd2d336c8c809d664c755ba7be50274	weighted graph based description for finger-vein recognition		The randomness of vein networks determines the discrimination of finger veins patterns in recognition. Effectively describing the random patterns is therefore very important for finger-vein based biometrics. In this paper, a new graph-based method is proposed for finger-vein network feature representation. A block-wise action is first done for graph node generation from a finger-vein image. By applying Delaunay triangulation to these obtained nodes, the graph edges are then built for featuring the spatial relations between images blocks. For a given feature space, each of these edges can locally represent a relationship between two adjacent nodes. Considering local variations in image contents, the graph edges are further weighted node-wisely using the statistics of image blocks. Thus, a graph can globally represent a finger-vein network, and its weighted edges can locally describe the relations of image blocks. Experimental results on two image databases totally 1,200 image samples show that the proposed method performs well in finger-vein recognition.	finger vein recognition	Ziyun Ye;Jinfeng Yang;José Hernández Palancar	2017		10.1007/978-3-319-69923-3_40	adjacency matrix;finger vein recognition;graph (abstract data type);null graph;feature vector;clique-width;delaunay triangulation;voltage graph;computer science;artificial intelligence;pattern recognition	Vision	37.39482191341764	-56.80137392877406	39108
e89d60eb9fe8339e7698d65ef17b8a530d0a746b	on the comparison of nn-based architectures for diabetic damage detection in retinal images	ebp mlp;damage detection;diabetic damage detection;sparsely connected neural networks;retinal imaging	The automatic screening of retinal images for an early detection of diabetic symptoms and an early prevention of diabetic retinopathies has been a prime focus in recent times. In this paper a contribution to improve diabetic damage detection in retinal images via neural networks is proposed by comparing two neural strategies. By considering the first architecture, fundus oculi symptomatic pale regions are firstly highlighted by enhancing image contrast with a neurofuzzy subnet, which is synthesized using a Sparsely-Connected Neural Network. Then, obtained contrast-enhanced images with bimodal histograms are globally segmented, after an optimal thresholding performed by a neural subsystem. In output binary images, suspect diabetic areas are finally isolated. By considering the second architecture, an EBP MLP neural net is synthesized, where a suitable training set of suspect patterns is developed by (5 × 5) windows centered on damaged pixels in gold standard images provided by clinicians. Performances are evaluated by percentage measures of exactness in the detection of suspect damaged areas via a comparison with gold standard images provided by clinicians. Results of both strategies are discussed and compared with other researchers' ones.		Vitoantonio Bevilacqua;Leonarda Carnimeo;Giuseppe Mastronardi;Vito Santarcangelo;Rocco Scaramuzzi	2009	Journal of Circuits, Systems, and Computers	10.1142/S0218126609005721	computer vision;speech recognition;engineering;artificial intelligence	ML	33.0157283451342	-75.64076810592115	39136
e35f29ba92f5c7486c969c861f88a629049fc4c5	graph-based shape matching for deformable objects	graph theory;object recognition;clutter;image segmentation;deformable shape;edge detection;image matching;shape recognition;shape deformation;deformable objects;shape recognition graph theory image matching image segmentation object recognition;deformable shape shape matching;shape;image edge detection;shape matching;image segmentation graph based shape matching deformable objects optimal cycle shape template shape deformation background clutter;shape image edge detection image segmentation clutter conferences object detection;object detection;conferences	In this paper, we propose a graph-based shape matching method for deformable objects. In our approach, a graph is generated from an over-segmented input image, and the shape matching problem is treated as finding an optimal cycle in the graph. Given a shape template and a graph generated from the input, a product graph is generated to consider every possible correspondence between graph edges and template sub-parts. Because the proposed approach can estimate reasonable correspondences between a target object and a template, it is possible to extract the target object robustly in the presence of shape deformation and background clutter. The experiments on various examples are also presented to verify the performance of proposed method.	clutter;experiment;shape context	Hanbyul Joo;Yekeun Jeong;Olivier Duchenne;In-So Kweon	2011	2011 18th IEEE International Conference on Image Processing	10.1109/ICIP.2011.6116266	computer vision;geometric graph theory;edge detection;graph bandwidth;null graph;shape;computer science;graph theory;cognitive neuroscience of visual object recognition;pattern recognition;mathematics;clutter;geometry;image segmentation;strength of a graph	Robotics	44.71614210034482	-53.34714038582257	39151
9b24a0fd6b446a418ebd00f00306a480471d2491	automatic skin lesion segmentation on dermoscopic images by the means of superpixel merging.		We present a superpixel-based strategy for segmenting skin lesion on dermoscopic images. The segmentation is carried out by over-segmenting the original image using the SLIC algorithm, and then merge the resulting superpixels into two regions: healthy skin and lesion. The mean RGB color of each superpixel was used as merging criterion. The presented method is capable of dealing with segmentation problems commonly found in dermoscopic images such as hair removal, oil bubbles, changes in illumination, and reflections images without any additional steps. The method was evaluated on the PH2 and ISIC 2017 dataset with results comparable to the state-of-art.	algorithm;color;f1 score;preprocessor;reflection (computer graphics)	Diego Patiño;Jonathan Avendaño;John Willian Branch	2018		10.1007/978-3-030-00937-3_83	artificial intelligence;lesion;pattern recognition;computer vision;computer science;merge (version control);rgb color model;segmentation	Vision	37.03451819346653	-73.83439074374397	39177
a294d01960e3f91196c7b1590a457cfb28540466	ultrasound image enhancement using structure-based filtering	software;liver;normal distribution;anisotropy;image processing computer assisted;artifacts;image interpretation computer assisted;algorithms;humans;ultrasonography;diffusion tensor imaging;kidney	Ultrasound images are prone to speckle noises. Speckles blur features which are essential for diagnosis and assessment. Thus despeckling is a necessity in ultrasound image processing. Linear filters can suppress speckles, but they smooth out features. Median filter based despeckling algorithms produce better results. However, they may produce artifact patterns in the resulted images and oversmooth nonuniform regions. This paper presents an innovative despeckle procedure for ultrasound images. In the proposed method, the diffusion tensor of intensity is computed at each pixel at first. Then the eigensystem of the diffusion tensor is calculated and employed to detect and classify the underlying structure. Based on the classification result, a feasible filter is selected to suppress speckles and enhance features. Test results show that the proposed despeckle method reduces speckles in uniform areas and enhances tissue boundaries and spots.	algorithm;exanthema;gaussian blur;image editing;image processing;large;median filter;noise reduction;normal statistical distribution;pixel;refinement (computing);interest	Shyh-Kuang Ueng;Cho-Li Yen;Guan-Zhi Chen	2014		10.1155/2014/758439	normal distribution;diffusion mri;computer vision;simulation;radiology;medicine;ultrasonography;mathematics;optics;anisotropy;algorithm;statistics	Vision	40.48150091394615	-76.04832887764458	39185
01e11bb2c53ace17d3fe5fec976de07041fe31d2	resampling 4d images using adaptive filtering	image processing;adaptive filters magnetic resonance imaging interpolation image segmentation heart ultrasonic imaging biomedical imaging robustness active appearance model computer science;time series;adaptive filters;time series image processing adaptive filters;cardiac mri;interpolation method;linear interpolation 4d image resampling adaptive filtering 3d time series image resampling image noise high quality image resampling;adaptive filter	We present an adaptive filtering based methodology for resampling 3D time series images using an extension of the method presented by simultaneously reducing the artifacts due to image noise and resample the data on a finer grid along the time dimension. This provides a methodology for obtaining high quality image resampling without the disadvantages of staircase artifacts created by more common interpolation methods such as linear interpolation. We present qualitative results of the algorithm on a data set of 4D cardiac MRI. This is a useful approach for any situation where we have a data set of 4D images needing to be resampled.	adaptive filter;algorithm;display resolution;image noise;image scaling;linear interpolation;time series	Alexander Andreopoulos;John K. Tsotsos	2005	The 2nd Canadian Conference on Computer and Robot Vision (CRV'05)	10.1109/CRV.2005.69	demosaicing;adaptive filter;computer vision;mathematical optimization;bilinear interpolation;image processing;computer science;stairstep interpolation;mathematics;multivariate interpolation;statistics;image scaling	Vision	50.901479359344094	-76.37262750391649	39244
6895d1f16cf9c846bc85419202a6c577e83cc7bc	a novel method for reconstructing degraded digits	databases;image reconstruction character recognition document image processing;image reconstruction history image segmentation databases nist extrapolation skeleton;nist;image segmentation;history;document images;extrapolation;character recognition document images digit degradation digit reconstruction inertia;skeleton;image reconstruction;automatic character recognition degraded digits reconstruction inertia based techniques digit stroke digit integrity nist sd19 digit database;document image processing;digit degradation;character recognition;inertia;digit reconstruction	This paper presents a new method for reconstructing degraded, or broken, digits. The proposed method uses inertia based techniques to exam the digit's stroke where degradation may be found and then extrapolate the stroke in order to reconstruct the digit. The main goal is to create strokes that remain as natural as possible, maintaining digit integrity. Experiments were performed using an artificially created degraded digit set, where the original digits were extracted from the NIST SD19 digit database. The proposed method succeeds in reconstructing the digits by extrapolating the strokes after attaining pertinent information from the digits themselves. The results were analyzed using automatic character recognition and the hit rate increased to 94%.	algorithm;check digit;elegant degradation;experiment;extrapolation;mojibake;optical character recognition;relevance;string (computer science)	Alberto N. G. Lopes Filho;Carlos A. B. Mello	2012	2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/ICSMC.2012.6377814	iterative reconstruction;arithmetic;inertia;computer vision;speech recognition;nist;computer science;image segmentation;extrapolation;skeleton	Robotics	33.07333353972154	-66.45498354418078	39301
3b4b07a3f0f617da07aad28db1da022728c15de1	fingerprint matching based on linking information structure of minutiae	information structure;chip;fingerprint recognition;false accept rate	  In this paper, we propose a new fingerprint recognition technique by using minutiae linking information. We introduce matching  process using minutiae linking information. Introduction of linking information into the minutiae matching process is a simple  but accurate way, which solves the problem of reference minutiae pair selection with low cost in comparison stage of two fingerprints.  This algorithm is invariant to translation and rotation of fingerprint. The matching algorithm was tested on 500 images from  the semiconductor chip style scanner. Experimental result revealed the false acceptance rate is decreased and genuine acceptance  rate is increased than existing method.    	fingerprint;minutiae	Jeong-Hee Cha;HyoJong Jang;Gye-Young Kim;Hyung-Il Choi	2004		10.1007/978-3-540-24707-4_6	chip;computer vision;computer science;pattern recognition;data mining;fingerprint recognition	Vision	32.35903759925864	-62.293519660265446	39303
23a0d1bacdb81e7313eca4d1d851ffc210576330	deep transfer learning for characterizing chondrocyte patterns in phase contrast x-ray computed tomography images of the human patellar cartilage	convolutional neural network;deep transfer learning;patellar cartilage;phase contrast imaging	Abstract Phase contrast X-ray computed tomography (PCI-CT) has been demonstrated to be effective for visualization of the human cartilage matrix at micrometer resolution, thereby capturing osteoarthritis induced changes to chondrocyte organization. This study aims to systematically assess the efficacy of deep transfer learning methods for classifying between healthy and diseased tissue patterns. We extracted features from two different convolutional neural network architectures, CaffeNet and Inception-v3 for characterizing such patterns. These features were quantitatively evaluated in a classification task measured by the area (AUC) under the Receiver Operating Characteristic (ROC) curve as well as qualitative visualization through a dimension reduction approach t-Distributed Stochastic Neighbor Embedding (t-SNE). The best classification performance, for CaffeNet, was observed when using features from the last convolutional layer and the last fully connected layer (AUCs u003e 0.91 ). Meanwhile, off-the-shelf features from Inception-v3 produced similar classification performance (AUC u003e 0.95 ). Visualization of features from these layers further confirmed adequate characterization of chondrocyte patterns for reliably distinguishing between healthy and osteoarthritic tissue classes. Such techniques, can be potentially used for detecting the presence of osteoarthritis related changes in the human patellar cartilage.		Anas Z. Abidin;Botao Deng;Adora M. DSouza;Mahesh B. Nagarajan;Paola Coan;Axel Wismüller	2018	Computers in biology and medicine	10.1016/j.compbiomed.2018.01.008	transfer of learning;cartilage;convolutional neural network;osteoarthritis;pattern recognition;visualization;computer science;dimensionality reduction;artificial intelligence;receiver operating characteristic;chondrocyte	ML	31.191017533567415	-76.57204776082928	39328
1bce0918c19fa8cfd6868ebd1e5d4ae072c9e05b	an adaptive gaussian model for satellite image deblurring	transformation ondelette;satellite images;traitement signal;processus gauss;metodo adaptativo;satellite data;texture;problema mal planteado;high resolution;ill posed inverse problem;observation par satellite;restauration image;image processing;signal estimation;maximum likelihood;bayes methods;observacion por satelite;probleme mal pose;maximum vraisemblance;inhomogeneous gaussian models;procesamiento imagen;image restoration;methode adaptative;maximum likelihood estimation;estimacion a priori;image bruitee;traitement image;satellites image restoration deconvolution maximum likelihood estimation parameter estimation inverse problems bayesian methods context modeling image reconstruction noise robustness;desconvolucion;reduccion ruido;algorithme;wavelet transforms;imagen sonora;a priori estimation;algorithm;restauracion imagen;haute resolution;satellite observation;maximum likelihood estimate;hybrid method;imagen borrosa;algorithms artificial intelligence computer simulation environmental monitoring feedback image enhancement image interpretation computer assisted information storage and retrieval models statistical normal distribution pattern recognition automated reproducibility of results sensitivity and specificity signal processing computer assisted spacecraft;blurred image;image reconstruction;signal processing;noise reduction;noisy image;ill posed problem;adaptive method;estimacion senal;textura;alta resolucion;reduction bruit;estimacion parametro;estimation a priori;deconvolution;image reconstruction deconvolution inverse problems maximum likelihood estimation bayes methods wavelet transforms;satellite image;deconvolution estimation techniques;rapport signal bruit;relacion senal ruido;transformacion ondita;gaussian process;image floue;parameter estimation;estimation parametre;signal to noise ratio;proceso gauss;procesamiento senal;estimation signal;high resolution satellite images;maxima verosimilitud;wavelet transformation;inverse problems;algoritmo	The deconvolution of blurred and noisy satellite images is an ill-posed inverse problem, which can be regularized within a Bayesian context by using an a priori model of the reconstructed solution. Since real satellite data show spatially variant characteristics, we propose here to use an inhomogeneous model. We use the maximum likelihood estimator (MLE) to estimate its parameters and we show that the MLE computed on the corrupted image is not suitable for image deconvolution because it is not robust to noise. We then show that the estimation is correct only if it is made from the original image. Since this image is unknown, we need to compute an approximation of sufficiently good quality to provide useful estimation results. Such an approximation is provided by a wavelet-based deconvolution algorithm. Thus, a hybrid method is first used to estimate the space-variant parameters from this image and then to compute the regularized solution. The obtained results on high resolution satellite images simultaneously exhibit sharp edges, correctly restored textures, and a high SNR in homogeneous areas, since the proposed technique adapts to the local characteristics of the data.	algorithm;approximation;approximation algorithm;bayesian network;deblurring;deconvolution;estimated;estimation theory;gaussian blur;gradient;image resolution;interaction;iterative method;k-nearest neighbors algorithm;markov random field;new type;normal statistical distribution;population parameter;sample variance;signal-to-noise ratio;simulation;texture mapping;thresholding (image processing);wavelet;wavelet packet decomposition;well-posed problem	André Jalobeanu;Laure Blanc-Féraud;Josiane Zerubia	2004	IEEE Transactions on Image Processing	10.1109/TIP.2003.819969	image restoration;computer vision;econometrics;mathematical optimization;image processing;computer science;signal processing;mathematics;maximum likelihood;statistics	Vision	53.533760211222685	-67.6962934178528	39435
1600828324f27988e3459d73ee0672b2ec32ebe6	multimodal medical volumetric data fusion using 3-d discrete shearlet transform and global-to-local rule	kullback leibler distance three dimensional 3 d medical image fusion 3 d shearlet transform generalized gaussian density ggd;image fusion;medical image processing biomedical mri discrete transforms image fusion;discrete transforms;synthetic data multimodal medical volumetric data fusion method 3d discrete shearlet transform two dimensional fusion framework 2d fusion framework three dimensional mri slices 3d mri slices average maximum fusion rule local window region global local fusion rule high pass subbands heavy tailed phenomenon generalized gaussian density kullback leibler distance fused global information kld asymmetry;medical image processing;wavelet transforms image fusion magnetic resonance imaging medical diagnostic imaging positron emission tomography;biomedical mri	Traditional two-dimensional (2-D) fusion framework usually suffers from the loss of the between-slice information of the third dimension. For example, the fusion of three-dimensional (3-D) MRI slices must account for the information not only within the given slice but also the adjacent slices. In this paper, a fusion method is developed in 3-D shearlet space to overcome the drawback. On the other hand, the popularly used average-maximum fusion rule can capture only the local information but not any of the global information for it is implemented in a local window region. Thus, a global-to-local fusion rule is proposed. We firstly show the 3-D shearlet coefficients of the high-pass subbands are highly non-Gaussian. Then, we show this heavy-tailed phenomenon can be modeled by the generalized Gaussian density (GGD) and the global information between two subbands can be described by the Kullback-Leibler distance (KLD) of two GGDs. The finally fused global information can be selected according to the asymmetry of the KLD. Experiments on synthetic data and real data demonstrate that better fusion results can be obtained by the proposed method.	c++;coefficient;epilepsy, generalized;experiment;game design document;image fusion;information theory;inspiration function;iterative method;kullback–leibler divergence;medical image;mental suffering;multimodal interaction;normal statistical distribution;population parameter;shearlet;synthetic data;tail;wavelet analysis;wavelet transform	Lei Wang;Bin Li;Lianfang Tian	2014	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2013.2279301	computer vision;speech recognition;radiology;medicine;pattern recognition;mathematics;image fusion	Vision	49.511526776496154	-76.23640258025014	39472
b7ea39fc88c25ce4cc460ff84253ae2d3cba0ea3	extraction of trend lines and extrema from multiscale curves	vision ordenador;image processing;geometrie algorithmique;aproximacion;computational geometry;procesamiento imagen;intelligence artificielle;traitement image;approximation;computer vision;geometria algoritmica;pattern recognition;artificial intelligence;vision ordinateur;inteligencia artificial;reconnaissance forme;reconocimiento patron	"""-Multiscale planar curves are curves conveying information at several levels of detail. To extract polygonal approximations of such curves at different resolutions, we propose a parallel method based on connecting locally computed centroids. The implementation makes use of a new pyramidal data structure, the chain pyramid. Coarser and coarser approximations are obtained through a hierarchy of increasingly coarse tessellations. Significant extrema of the curves are localized at the highest resolution by segmenting at a """"natural scale"""" and employing the structure of the chain pyramid for down-projection. Image pyramids Multiscale curves Polygonal approximation Extrema detection"""	approximation;data structure;level of detail	Peter Meer;Ernest S. Baugher;Azriel Rosenfeld	1988	Pattern Recognition	10.1016/0031-3203(88)90056-8	computer vision;image processing;computational geometry;computer science;artificial intelligence;machine learning;approximation;algorithm;computer graphics (images)	Vision	48.392124636634186	-61.756397338450725	39491
e929128d75b59439b1db6336edde56253b59672f	m-sift: a new method for vehicle logo recognition	image recognition;vehicle manufacturer m sift vehicle logo recognition merge scale invariant feature transform;transforms;databases vehicles image recognition equations mathematical model transforms feature extraction;vehicles;vehicles image recognition transforms	In this paper, a new algorithm for Vehicle Logo Recognition is proposed, on the basis of an enhanced Scale Invariant Feature Transform (Merge-SIFT or M-SIFT). The algorithm is assessed on a set of 1500 logo images that belong to 10 distinctive vehicle manufacturers. A series of experiments are conducted, splitting the 1500 images to a training set (database) and to a testing set (query). It is shown that the MSIFT approach, which is proposed in this paper, boosts the recognition accuracy compared to the standard SIFT method. The reported results indicate an average of 94.6% true recognition rate in vehicle logos, while the processing time remains low (~0.8sec).	algorithm;database;experiment;homography (computer vision);image processing;logo;probabilistic neural network;real-time clock;real-time computing;reflection (computer graphics);scale-invariant feature transform;test set	Apostolos P. Psyllos;Christos-Nikolaos Anagnostopoulos;Eleftherios Kayafas	2012	2012 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2012)	10.1109/ICVES.2012.6294277	computer vision;speech recognition;feature;computer science;pattern recognition	Robotics	32.90519309306648	-58.800258694817515	39560
6623d8efb11bdca7348249c357902a5527a71e84	a new descriptor of gradients self-similarity for smile detection in unconstrained scenarios	extreme learning machines;smile detection;histogram of oriented gradients;adaboost;support vector machine;self similarity of gradients	Smile detection is a sub-problem of facial expression recognition field, which has attracted more and more interests from researchers because of its wide application market. As for smile detection problem itself, the ‘wild’ unconstrained scenario is more challenging than the laboratory constrained scenario. Therefore, in this paper, we mainly focus on solving smile detection problem in unconstrained scenarios. To this end, a new descriptor, Self-Similarity of Gradients (GSS), is proposed. Inspired by Self-Similarity on Color channels (CSS) feature in pedestrian detection area, GSS can effectively describe the similarities in a HOG feature map, while these similarities are useful and helpful for constructing a high-performance practical smile detector. Moreover, since a smile detector using multiple features and multiple classifiers simultaneously shows superior performance, they are also adopted by us. Finally, experimental results indicate that the combined features (HOG31+GSS+Raw pixel) using AdaBoost with linear Extreme Learning Machines (ELM) achieve improved performance over the state-of-the-arts on the real-world smile dataset (GENKI-4K).	adaboost;cascading style sheets;experiment;image gradient;pedestrian detection;pixel;self-similarity	Yuan Gao;Hong W. Liu;Pingping Wu;Can Wang	2016	Neurocomputing	10.1016/j.neucom.2015.10.022	adaboost;support vector machine;computer vision;histogram of oriented gradients;computer science;machine learning;data mining	Vision	32.83820409582316	-55.53639754802827	39577
f2302fe41b64eb7adddd0d2e17b96f8df55fd0a3	boosting active contours for weld pool visual tracking in automatic arc welding	sensors;welding active contours image edge detection shape probabilistic logic visualization sensors;welding;active contours;visualization;shape;image edge detection;probabilistic logic;weld pool tracking active contours adaboost machine vision welding automation	Detecting the shape of the non-rigid molten metal during welding, so-called weld pool visual sensing, is one of the central tasks for automating arc welding processes. It is challenging due to the strong interference of the high-intensity arc light and spatters as well as the lack of robust approaches to detect and represent the shape of the nonrigid weld pool. We propose a solution using active contours including an prior for the weld pool boundary composition. Also, we apply Adaboost to select a small set of features that captures the relevant information. The proposed method is applied to weld pool tracking and the presented results verified its feasibility.	active contour model;adaboost;evolutionary algorithm;experiment;heuristic (computer science);image processing;interference (communication);medical imaging;robot welding;video tracking	Jinchao Liu;Zhun Fan;Søren Ingvor Olsen;Kim Hardam Christensen;Jens Klæstrup Kristensen	2017	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2015.2498929	structural engineering;computer vision;visualization;shape;engineering;sensor;mathematics;probabilistic logic;engineering drawing;welding	Vision	46.9923444122716	-53.432846207834885	39656
32a737b32945086f24f7ef0bd95d88d6711955b1	about the limiting behaviour of iterated robust morphological operators	discrete dynamical system;mathematical morphology;image numerique;morfologia matematica;image processing;procesamiento imagen;morphological operation;imagen nivel gris;traitement image;image niveau gris;imagen numerica;digital image;grey level image;morphologie mathematique	We study the limiting behaviour of the repeated application of a discrete image operator that belongs to a recently introduced class of morphological operators. To this purpose, we describe the implied iterative process by a discrete dynamical system.The convergence is derived for binary and gray scale images.	iterated function;mathematical morphology	Johan Van Horebeek;Ernesto Tapia	2000		10.1007/3-540-45576-0_26	computer vision;mathematical morphology;image processing;computer science;artificial intelligence;calculus;mathematics;digital image	Vision	49.374203587301594	-63.9790868241225	39663
abe51eff24065f7e54dc64a441984296bf1a21ac	change classification in graphics-intensive digital documents	change detection;document image analysis;computer vision;electronic documents	This paper proposes an approach for the automatic detection and classification of changes occurring in images of documents with identical content, but generated with different software versions, or under different operating platforms. Our work is performed on a database of digitally-born business documents created using financial reporting tools. The proposed method involves a multi-stage process, where the end goal is to present to a human user the reports which have changed and the changes which were detected. Our main contribution is related to matching and comparing of graphical document elements. This paper focuses on detection of local, translation-based changes. Future work will explore other local changes involving size, color, and rotation.	color;database;document;graphics;matching (graph theory);software versioning	Jeremy Svendsen;Alexandra Branzan Albu	2015		10.1145/2682571.2797079	computer science;data mining;database;world wide web;change detection;information retrieval	Web+IR	36.546128487831304	-65.37777667957418	39723
d2a05d1587656109417e748e491043a731722b38	combining fast extracted edge descriptors and feature sharing for rapid object detection	shared feature;basic feature;edge descriptors;object detection;rapid object detection;proposed feature;feature sharing problem;equivalent efficiency;contour descriptors;reusing framework;real-adaboost algorithm;object detection method	shared feature;basic feature;edge descriptors;object detection;rapid object detection;proposed feature;feature sharing problem;equivalent efficiency;contour descriptors;reusing framework;real-adaboost algorithm;object detection method	object detection	Yali Li;Fei He;Wenhao Lu;Shengjin Wang	2012		10.1007/978-3-642-37484-5_39	computer vision;computer science;viola–jones object detection framework;machine learning;pattern recognition;feature	Vision	33.672647776007665	-56.074287954712545	39744
663b9c36b1318bda2943013aceb34b514289393c	affine invariants for object recognition using the wavelet transform	object recognition;invariant features;wavelet transform;affine transformation;planar object recognition;dyadic wavelet transform;invariant feature	Dyadic wavelet transform has been used to derive affine invariant functions. The invariant functions are based on the dyadic wavelet transform of the object boundary. Three invariant functions have been calculated using different numbers of dyadic levels. Experimental results show that these invariant functions outperform some traditional invariant functions. The stability of these invariant functions have been tested for a large perspective transformation.	outline of object recognition;wavelet transform	Mahmoud I. Khalil;Mohamed M. Bayoumi	2002	Pattern Recognition Letters	10.1016/S0167-8655(01)00102-7	wavelet;mathematical analysis;discrete mathematics;harmonic wavelet transform;topology;second-generation wavelet transform;continuous wavelet transform;cognitive neuroscience of visual object recognition;invariant;affine transformation;mathematics;geometry;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;wavelet transform	Vision	41.37969533323773	-58.76065013697829	39861
5ed1810f01fb7291d9ddc4699f7f6851e515501d	automatic speaker recognition using circular dft sectors	sectors;banking sector;spectrum;euclidean distance;phone banking;speaker recognition;feature vector;automatic speaker recognition;discrete fourier transform;discrete fourier transform dft;database services	In this paper, we propose automatic speaker recognition using circular DFT (Discrete Fourier Transform) sectors. In the first method, the feature vectors are extracted by dividing the complex DFT spectrum into circular sectors and then taking the weighted density count of the number of points in each of these sectors. In the second and third method, the circular sectors are further divided and then weighted density count of the number of samples is used as feature vector. The results show that this approach gives fairly good speaker recognition (70 % - 80%) Also the results improve as the circular sectors are further divided.	circular shift;discrete fourier transform;feature vector;speaker recognition	H. B. Kekre;V. B. Kulkarni	2011		10.1145/1980022.1980305	arithmetic;speech recognition;pattern recognition;mathematics	Vision	32.832563946804974	-64.47683250083702	39894
41508e0835162d2b45bb356e2c35b0476c117a72	segmentation of non-convex regions within uterine cervix images	image segmentation pixel shape cervical cancer image databases lesions biomedical engineering gaussian processes biomedical imaging colored noise;agglomerative clustering;bottom up;image segmentation;uterine cervix;cancer;indexing terms;medical image processing cancer gynaecology image segmentation;gynaecology;cervigrams;lesions;uterine cervix images;cervical cancer;graph cut;medical image processing;agglomerative clustering uterine cervix images image segmentation cervigrams cervical cancer lesions graph cut criterion;national cancer institute;graph cut criterion	"""The National Cancer Institute has collected a large database of uterine cervix images, termed """"cervigrams"""" for cervical cancer screening research. Tissues of interest within the cervigram, in particular the lesions, are of varying sizes and complex, non-convex shapes. The current work proposes a new methodology that enables the segmentation of non-convex regions, thus providing a major step forward towards cervigram tissue detection and lesion delineation. The framework transitions from pixels to a set of small coherent regions (superpixels), which are grouped bottom-up into larger, non-convex, perceptually similar regions, utilizing a new graph-cut criterion and agglomerative clustering. Superpixels similarity is computed via a combined region and boundary information measure. Results for a set of 120 cervigrams, manually marked by a medical expert, are shown."""	bottom-up parsing;cluster analysis;coherence (physics);cut (graph theory);pixel	Shiri Gordon;Hayit Greenspan	2007	2007 4th IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2007.356851	computer vision;index term;cut;medicine;pathology;computer science;gynecology;machine learning;top-down and bottom-up design;hierarchical clustering;image segmentation;cancer	Vision	39.330299173911314	-75.07432821394073	39955
18d6e4ee651f23ec30843ab01ed7679edc9d3173	real-time camera calibration for virtual studio	lens distortion;frames per second;video techniques;image processing;etude experimentale;real time;technique video;real time processing;traitement image;extraccion parametro;methode calcul;parameter extraction;algorithme;tratamiento tiempo real;traitement temps reel;extraction parametre;imagen virtual;image virtuelle;radio studios;calculation methods;parameter space;pattern recognition;algorithms;etalonnage;maquina fotografica;studio radiodiffusion;reconnaissance forme;camera calibration;nonlinear optimization;real time application;virtual image;calibration;appareil photographique;camera;real time systems	I n this paper, we present an overall algorithm for real-time camera parameter extraction, which is one of the key elements in implementing virtual studio, and we also present a new method for calculating the lens distortion parameter in real time. In a virtual studio, the motion of a virtual camera generating a graphic studio must follow the motion of the real camera in order to generate a realistic video product. This requires the calculation of camera parameters in real-time by analyzing the positions of feature points in the input video. Towards this goal, we first design a special calibration pattern utilizing the concept of cross-ratio, which makes it easy to extract and identify feature points, so that we can calculate the camera parameters from the visible portion of the pattern in real-time. It is important to consider the lens distortion when zoom lenses are used because it causes nonnegligible errors in the computation of the camera parameters. However, the Tsai algorithm, adopted for camera calibration, calculates the lens distortion through nonlinear optimization in triple parameter space, which is inappropriate for our real-time system. Thus, we propose a new linear method by calculating the lens distortion parameter independently, which can be computed fast enough for our real-time application. We implement the whole algorithm using a Pentium PC and Matrox Genesis boards with five processing nodes in order to obtain the processing rate of 30 frames per second, which is the minimum requirement for TV broadcasting. Experimental results show this system can be used practically for realizing a virtual studio.	algorithm;block cipher mode of operation;camera resectioning;composite video;computation;distortion;experiment;feature model;feature vector;genesis;lookup table;mathematical optimization;nonlinear programming;nonlinear system;real-time clock;real-time computer graphics;real-time computing;real-time transcription;sgi onyx2;stationary process;time complexity;virtual camera system;virtual studio;webcam	Seong-Woo Park;Yongduek Seo;Ki-Sang Hong	2000	Real-Time Imaging	10.1006/rtim.1999.0199	distortion;smart camera;computer vision;camera auto-calibration;real-time computing;calibration;virtual image;camera resectioning;simulation;image processing;computer science;parameter space;frame rate;pinhole camera model;computer graphics (images)	Graphics	49.44936437160669	-56.63054550923129	40032
96b92799a4d2e8d815b54231ba09bdf00dce2fe7	automatic macula detection from retinal images by a line operator	image recognition;image segmentation;retinal image pixel;circular brightness profile;biometrics access control;line operator;object detection biometrics access control brightness image recognition;automatic macula detection;brightness;optical imaging;stare project dataset;macula detection;line operator retinal image analysis macula detection;retina;line segment detection;pixel;retina image segmentation brightness pixel optical imaging biomedical optical imaging;drive project dataset;image brightness variation;biomedical optical imaging;retinal image analysis;stare project dataset automatic macula detection retinal image analysis line operator circular brightness profile image brightness variation retinal image pixel line segment detection drive project dataset;retinal imaging;object detection	This paper presents an automatic macula detection technique that makes use of the circular brightness profile of the macula: the macula is usually darker than the surrounding pixels whose intensities increase gradually with their distances from the macula center. A line operator is designed to capture the macula circular brightness profile, which evaluates the image brightness variation along multiple line segments of specific orientations that pass through each retinal image pixel. The orientation of the line segment with the minimum/ maximum variation has specific patterns that indicate the position of the macula efficiently. The proposed technique has been tested over DRIVE project's dataset and the STARE project's dataset. Experiments show that the accuracies reach up to 100% and 95.45%, respectively, based on 35 and 44 retinal images having discernible macula within the two public datasets.	experiment;pixel	Shijian Lu;Joo-Hwee Lim	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5649080	computer vision;computer science;optical imaging;image segmentation;brightness;pixel;computer graphics (images)	Robotics	43.221359607778474	-65.26284038828787	40105
c53a49522e963e15a582408633d4c6d90ac083c5	principal geodesic analysis on symmetric spaces: statistics of diffusion tensors	symmetric positive definite;diffusion tensor images;vector space;magnetic resonance image;medical image analysis;principal component analysis;riemannian symmetric space;lie group;symmetric space;diffusion tensor	Diffusion tensor magnetic resonance imaging (DT-MRI) is emerging as an important tool in medical image analysis of the brain. However, relatively little work has been done on producing statistics of diffusion tensors. A main difficulty is that the space of diffusion tensors, i.e., the space of symmetric, positivedefinite matrices, does not form a vector space. Therefore, standard linear statistical techniques do not apply. We show that the space of diffusion tensors is a type of curved manifold known as a Riemannian symmetric space. We then develop methods for producing statistics, namely averages and modes of variation, in this space. In our previous work we introduced principal geodesic analysis, a generalization of principal component analysis, to compute the modes of variation of data in Lie groups. In this work we expand the method of principal geodesic analysis to symmetric spaces and apply it to the computation of the variability of diffusion tensor data. We expect that these methods will be useful in the registration of diffusion tensor images, the production of statistical atlases from diffusion tensor data, and the quantification of the anatomical variability caused by disease.	algorithm;apply;computation;image analysis;medical image computing;medical imaging;principal component analysis;principal geodesic analysis;resonance;spaces;spatial variability	P. Thomas Fletcher;Sarang C. Joshi	2004		10.1007/978-3-540-27816-0_8	diffusion mri;symmetric tensor;metric tensor;mathematical analysis;topology;symmetric bilinear form;vector space;magnetic resonance imaging;tensor contraction;mathematics;symmetric space;geometry;triple system;lie group;tensor product of hilbert spaces;principal component analysis	Vision	46.80599297005825	-77.43194136186801	40176
4846324abb72636730be08f9125e7b9ce618b6af	face detection using fast neural networks and image decomposition	fast face detection;neural net;time use;face detection;image decomposition;divide and conquer;parallel processing;neural network	In this paper, a new approach to reduce the computation time taken by fast neural nets for the searching process is presented. The principle of divide and conquer strategy is applied through image decomposition. Each image is divided into small in size sub-images and then each one is tested separately using a fast neural network. Compared to conventional and fast neural networks, experimental results show that a speed up ratio is achieved when applying this technique to locate human faces automatically in cluttered scenes. Furthermore, faster face detection is obtained by using parallel processing techniques to test the resulting sub-images at the same time using the same number of fast neural networks. Moreover, the problem of sub-image centering and normalization in the Fourier space is solved. c © 2002 Elsevier Science B.V. All rights reserved.	algorithm;artificial neural network;computation;database normalization;face detection;parallel computing;run time (program lifecycle phase);simulation;speedup;time complexity	Hazem M. El-Bakry	2002	Neurocomputing	10.1016/S0925-2312(02)00608-2	computer vision;face detection;divide and conquer algorithms;computer science;theoretical computer science;machine learning;time delay neural network;artificial neural network	AI	34.92074025448831	-59.53335126617237	40193
94782b7a499033196a0674f94a6c9664653d9caf	pattern recognition and image description by suitable textural information	image segmentation;unsupervised classification pattern recognition textural information image description feature spaces unsupervised segmentation;image classification;unsupervised segmentation;feature space;image texture;image segmentation image texture image classification;pattern recognition;unsupervised classification;image description;textural information;feature spaces;pattern recognition image segmentation energy resolution image resolution feature extraction data mining neural networks layout silicon compounds brightness	One of the difficulties in pattern recognition is to develop a good evaluation of the classes presented on a scene. To suitably describe those classes it is necessary to find feature spaces which allow distinguishing between them. In this work we propose an unsupervised segmentation/classification technique associated with textural description and report the encouraging results obtained.	pattern recognition;unsupervised learning	Arnaldo de Albuquerque Araújo;Leonardo Max Batista Claudino;Ricardo Augusto Rabelo Oliveira;S. Jamil	2000		10.1109/SIBGRA.2000.895828	image texture;computer vision;contextual image classification;feature detection;feature;feature extraction;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation;feature	Vision	40.01168635707034	-63.295036743173775	40194
7a12fa82e7050781d4db581ece2819112fed84df	defect repair for range data observed with a laser range scanner	image scanners;evolution methods;range data;image segmentation;laser ranging;region segmentation;color segmentation;image colour analysis;direct range repair method defect repair laser range scanner defect detection scheme region segmentation range and color data nonlinear time evolution method range and color segmentation building occlusion regions transportation based inpainting algorithm 3d point repair method;buildings image segmentation data engineering electric variables measurement rendering computer graphics digital cameras testing level set costs;image scanners laser ranging image segmentation image colour analysis;3d structure;laser range scanner;defect detection	Some types of laser range scanner can measure range and color data simultaneously, and are often used to acquire 3D structure of outdoor scenery. However, unfortunately a laser range scanner cannot give us perfect range information about the target objects such as buildings, and various factors incur critical defects of range data. We present a defect detection scheme based on region segmentation using observed range-and-color data, and apply a nonlinear time-evolution method to the repair of defect regions of range data. As to the defect detection, performing range-and-color segmentation, we divide observed data into several regions corresponding to buildings, the sky, the ground, etc. Using the segmentation results, we determine defect regions as occlusion regions of buildings. Given defect regions, their range data will be repaired from the observed data in their neighborhoods. For that purpose, we adapt the time-evolution algorithm, originally developed for the repair of an intensity image, for the repair of range data.	3d scanner;algorithm;hidden surface determination;image segmentation;inpainting;nonlinear system;software bug	Takahiro Saito;Takashi Komatsu;Shin-ichi Sunaga;Masayuki Hashiguchi	2003		10.1109/ICIP.2003.1247425	computer vision;range segmentation;computer science;image segmentation;scale-space segmentation;computer graphics (images)	Robotics	48.92232043949489	-52.62726454718696	40209
48775a266d98031d97d1ccd9e5d3edcd275755fc	imaging for detecting breast cancers using uwb radar technology	new imaging method;breast tumor;uwb pulse;higher detection accuracy;circle approximation;breast cancer;conventional method;proposal method;fdtd method;center position;center point;uwb radar technology	Ultra wide band (UWB) microwave imaging has recently been proposed for detecting small malignant breast tumors and is expected to detect breast tumors with safety, comfort and precision for high resolution of UWB pulse. In this paper, we propose a new imaging method that uses circle approximation to detect the cancer in order for automatically detection without doctors’ analysis. Our proposal method measures a radius of a cancer, and decides the center point of cancers on the circumference. The method is simulated by 2D FDTD method. As the result, our method showed higher detection accuracy of a center position and a radius of a circle formed cancer than conventional method.	approximation;finite-difference time-domain method;image resolution;microwave;radar;sensor	Yuta Okuyama;Thanh Pham;Kotaro Yamasue;Chika Sugimoto;Ryuji Kohno	2013			electronic engineering;telecommunications;engineering;optics	Robotics	38.31296479599383	-76.55410554394341	40251
11475b370c6eedc05bf5f0d09ff3c687f7f5ffcb	robust face recognition via non-linear correlation filter bank			facial recognition system;filter bank;nonlinear system	Motahareh Taheri	2018	IET Image Processing	10.1049/iet-ipr.2016.0873	computer vision;artificial intelligence;filter bank;facial recognition system;pattern recognition;nonlinear system;mathematics;correlation	Vision	30.609671089160692	-57.82756026328257	40255
574f05ab2f135fad33ccbde85debdd12bb41bc87	proposal-free network for instance-level object segmentation		Instance-level object segmentation is an important yet under-explored task. Most of state-of-the-art methods rely on region proposal methods to extract candidate segments and then utilize object classification to produce final results. Nonetheless, generating reliable region proposals itself is a quite challenging and unsolved task. In this work, we propose a Proposal-Free Network (PFN) to address the instance-level object segmentation problem, which outputs the numbers of instances of different categories and the pixel-level information on i) the coordinates of the instance bounding box each pixel belongs to, and ii) the confidences of different categories for each pixel, based on pixel-to-pixel deep convolutional neural network. All the outputs together, by using any off-the-shelf clustering method for simple post-processing, can naturally generate the ultimate instance-level object segmentation results. The whole PFN can be easily trained without the requirement of a proposal generation stage. Extensive evaluations on the challenging PASCAL VOC 2012 semantic segmentation benchmark demonstrate the effectiveness of the proposed PFN solution without relying on any proposal generation methods.	artificial neural network;benchmark (computing);biological neural networks;cluster analysis;convolutional neural network;evaluation;generic drugs;minimum bounding box;obstruction;pixel;video post-processing;all categories;biologic segmentation;statistical cluster	Xiaodan Liang;Liang Lin;Yunchao Wei;Xiaohui Shen;Jianchao Yang;Shuicheng Yan	2018	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2017.2775623	computer vision;convolutional neural network;artificial intelligence;pattern recognition;computer science;machine learning;object detection;artificial neural network;minimum bounding box;scale-space segmentation;image segmentation;segmentation-based object categorization;cluster analysis	Vision	29.761548200322206	-52.16067814053943	40310
bc9ef2ecc215dbde981aaccb5759e6e10f0f3c18	a fast palmprint verification system based on fractal coding	scene matching;biometrics;palmprint;fractal code;roi	This paper presents a fast palmprint verification system based on fractal coding. In the stage of registration, a sub-image from user’s training palmprints is intentionally extracted and stored as his or her template. In the stage of verification, the step of region of interest extraction is not needed, the sample image is directly matched with the template based on fractal coding, which can reduce the whole response time. Whether the sample image and the template are from the same person or not is decided by their matching scores. Experimental evaluation results on two databases clearly demonstrate the effectiveness of the proposed approach.	database;experiment;fingerprint;fractal;nl (complexity);numerical aperture;performance evaluation;region of interest;response time (technology);user interface	Huan Zhang	2013	I. J. Information Acquisition	10.1142/S0219878912500039	computer vision;return on investment;speech recognition;pattern recognition;biometrics	AI	35.13087530083655	-61.42218758332252	40316
0bda6b3a88c6b19048ad6fd62196d1650cc468f9	the monkeytyping solution to the youtube-8m video understanding challenge		This article describes the final solution 1 of team monkeytyping, who finished in second place in the YouTube-8M video understanding challenge. The dataset used in this challenge is a large-scale benchmark for multi-label video classification. We extend the work in [1] and propose several improvements for frame sequence modeling. We propose a network structure called Chaining that can better capture the interactions between labels. Also, we report our approaches in dealing with multi-scale information and attention pooling. In addition, We find that using the output of model ensemble as a side target in training can boost single model performance. We report our experiments in bagging, boosting, cascade, and stacking, and propose a stacking algorithm called attention weighted stacking. Our final submission is an ensemble that consists of 74 sub models, all of which are listed in the appendix.	algorithm;benchmark (computing);consistency model;experiment;interaction;multi-label classification;stacking	He-Da Wang;Teng Zhang;Ji Wu	2017	CoRR		pattern recognition;machine learning;stacking;boosting (machine learning);artificial intelligence;computer science;pooling;chaining	AI	24.925977425503735	-56.46545154891824	40321
fe259f99285ac804fedf579e89ba5a99e36881da	exceptional attributed subgraph mining to understand the olfactory percept		Human olfactory perception is a complex phenomenon whose neural mechanisms are still largely unknown and novel methods are needed to better understand it. Methodological issues that prevent such understanding are: (1) to be comparable, individual cerebral images have to be transformed in order to fit a template brain, leading to a spatial imprecision that has to be taken into account in the analysis; (2) we have to deal with inter-individual variability of the hemodynamic signal from fMRI images which render comparisons of individual raw data difficult. The aim of the present paper was to overcome these issues. To this end, we developed a methodology based on discovering exceptional attributed subgraphs which enabled extracting invariants from fMRI data of a sample of individuals breathing different odorant molecules.Four attributed graph models were proposed that differ in how they report the hemodynamic activity measured in each voxel by associating varied attributes to the vertices of the graph. An extensive empirical study is presented that compares the ability of each modeling to uncover some brain areas that are of interest for the neuroscientists.	algorithm;attributed graph grammar;encode;hemodynamics;sensitivity and specificity;social inequality;spatial variability;vertex (geometry);voxel	Andrew Bc Crumley;Marc Plantevit;Arnaud P. Fournel;Moustafa Bensafi;Céline Robardet	2018		10.1007/978-3-030-01771-2_18	machine learning;empirical research;raw data;voxel;olfactory perception;computer science;artificial intelligence;invariant (mathematics);graph;percept	ML	27.074138126439514	-79.25826148630503	40354
28749605c541cd73b3c8cce18a8335bcaeeb2da2	fast renal cortex localization by combining generalized hough transform and active appearance models	renal cortex;generalized hough transform;localization;active appearance model;kidney	Automatic localization of objects is one of great important steps in object recognition and analysis, such as segmentation, registration in many medical applications. In this paper, an automated method is proposed to recognize renal cortex on contrast-enhanced abdominal CT images. The proposed method is based on a strategic combination of the Generalized Hough Transform and Active Appearance Model. It consists of two main phases: training and localization. In the training phase, we train the mean shape models of renal cortex by using Active Appearance Model and compute Generalized Hough Transform parameters. In the localization phase, a modified Generalized Hough Transform algorithm is advanced to estimate potential center of gravity for improving the conventional Active Appearance Model matching method, and then a two-pass Active Appearance Model matching method is proposed based on Generalized Hough Transform. The Active Appearance Models and Generalized Hough Transform parameters were trained with 20 CT angiography datasets, and then the proposed method was tested on a clinical data set of 17 CT angiography datasets. The experimental results show that: 1 an overall cortex localization accuracy is 0.9920±0.0038, average distance is 11.00±9.34 pixels. 2 The proposed method is highly efficient such that the overall localization can be finalized within 1.2075±0.3738 seconds for each 2D slice.	active appearance model;generalised hough transform	Dehui Xiang;Xinjian Chen;Chao Jin	2013		10.1007/978-3-642-41083-3_20	hough transform;active appearance model;internationalization and localization	Vision	40.87892050636004	-78.01107293125942	40390
70e4d8b7c37833aa6c7aea193ed37ed1295c11b7	universal approach for dct-based constant-time gaussian filter with moment preservation		This paper presents a universal approach for constant-time Gaussian filters (O(1) GF) based on the Discrete Cosine Transform (DCT). It is well known that DCT has the eight types of definitions. Existing methods of O(1) GF use difference DCT type according to their original concepts. However, all types of DCT have not been studied comprehensively and quantitatively. Unlike existing methods, the proposed approach covers all types of DCT and moment preservation for arbitrary orders, which enables us to clarify differences of $O$(1) GF derived from each DCT through a comprehensive analysis. Based on the universal approach, a closed-form solution to optimize weight coefficients is also proposed based on a simple convex analysis. Experiments found that DCT-7 shows the highest approximate accuracy, which is a new conclusion different from existing methods.	approximation algorithm;coefficient;convex analysis;discrete cosine transform;experiment;grammatical framework	Kenjiro Sugimoto;Seisuke Kyochi;Sei-ichiro Kamata	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8461679	kernel (linear algebra);image processing;gaussian filter;convex analysis;mathematical optimization;computational complexity theory;discrete cosine transform;computer science;convolution;gaussian	Robotics	51.774774293039584	-64.52060933501625	40426
9a372759011fef4b90df7bbe183ffbbf553a19d4	learning structural element patch models with hierarchical palettes	libraries;image color analysis shape libraries image reconstruction indexes object recognition educational institutions;universal palettes;object recognition;image segmentation;computer graphics;variational techniques;caltech101 learning structural element patch model hierarchical palettes image patch image segmentation pattern universal palettes image collection learned shapelet library variational technique image descriptor shape representation color image analysis shapelet model sift caltech28;variational techniques computer graphics feature extraction image colour analysis image representation image segmentation learning artificial intelligence;learned shapelet library;conference paper;image patch;indexes;image segmentation pattern;shape representation;image collection;shape;sift;image color analysis;image colour analysis;image representation;feature extraction;image reconstruction;shapelet model;hierarchical palettes;caltech101;learning structural element patch model;learning artificial intelligence;color image analysis;image descriptor;caltech28;variational technique	Image patches can be factorized into `shapelets' that describe segmentation patterns called structural elements (stels), and palettes that describe how to paint the shapelets. We introduce local palettes for patches, global palettes for entire images and universal palettes for image collections. Using a learned shapelet library, patches from a test image can be analyzed using a variational technique to produce an image descriptor that represents local shapes and colors separately. We show that the shapelet model performs better than SIFT, Gist and the standard stel method on Caltech28 and is very competitive with other methods on Caltech101.	baseline (configuration management);brendan gregg;chua's circuit;code word;codebook;color;gist;graph coloring;standard test image;structural element;variational principle;visual descriptor	Jeroen Chua;Inmar E. Givoni;Ryan P. Adams;Brendan J. Frey	2012	2012 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2012.6247955	iterative reconstruction;database index;computer vision;feature extraction;shape;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;scale-invariant feature transform;image segmentation;computer graphics	Vision	35.02143659227504	-53.89199759761421	40454
558e52a5a4ac994c327e064cb59f54bf8ac9df2d	efficient 3d multi-region prostate mri segmentation using dual optimization	3d prostate mri;convex optimization;zonal segmentation	Efficient and accurate extraction of the prostate, in particular its clinically meaningful sub-regions from 3D MR images, is of great interest in image-guided prostate interventions and diagnosis of prostate cancer. In this work, we propose a novel multi-region segmentation approach to simultaneously locating the boundaries of the prostate and its two major sub-regions: the central gland and the peripheral zone. The proposed method utilizes the prior knowledge of the spatial region consistency and employs a customized prostate appearance model to simultaneously segment multiple clinically meaningful regions. We solve the resulted challenging combinatorial optimization problem by means of convex relaxation, for which we introduce a novel spatially continuous flow-maximization model and demonstrate its duality to the investigated convex relaxed optimization problem with the region consistency constraint. Moreover, the proposed continuous max-flow model naturally leads to a new and efficient continuous max-flow based algorithm, which enjoys great advantages in numerics and can be readily implemented on GPUs. Experiments using 15 T2-weighted 3D prostate MR images, by inter- and intra-operator variability, demonstrate the promising performance of the proposed approach.	algorithm;combinatorial optimization;customize;dual;entropy maximization;graphics processing unit;linear programming relaxation;mathematical optimization;maximum flow problem;numerous;optimization problem;peripheral;prostatic neoplasms;shadow volume;spatial variability;biologic segmentation	Wu Qiu;Jing Yuan;Eranga Ukwatta;Yue Sun;Martin Rajchl;Aaron Fenster	2013	Information processing in medical imaging : proceedings of the ... conference	10.1007/978-3-642-38868-2_26	computer vision;mathematical optimization;convex optimization;simulation;mathematics	Vision	41.005833859519136	-78.89650102103543	40513
3a69085b99171b870e8c129fcbbbc6e323f7a31d	an extended generative feature learning algorithm for image recognition			algorithm;computer vision	Bin Wang;Chuanjiang Li;Qian Zhang;Jifeng Huang	2017	TIIS	10.3837/tiis.2017.08.013	generative grammar;feature (computer vision);computer science;computer vision;feature extraction;feature (machine learning);machine learning;k-nearest neighbors algorithm;artificial intelligence;feature detection (computer vision);pattern recognition;feature learning	ML	30.125946915354223	-56.42145272111081	40519
97dacc574ad5471c0809cb77f087b95e58d8d455	superpixel segmentation based gradient maps on rgb-d dataset		Superpixels aim to group homogenous pixels by a series of characteristics in an image. They decimate redundancy that may be utilized later by more computationally expensive algorithms. The most popular algorithms obtain superpixels based on an energy function on a graph. However, these graph-based methods have a high computational time consumption. This study presents a fast and high quality over-segmentation method by a watershed transform based on computing the dissimilarity of pixels among RGB(D) cues and gradient maps. Specifically, we first capture a gradient map based on an image to enhance and explain directional variations in the image scene. A distance function then measures the similarity among adjacent pixels, which is calculated according to RGB(D) values. A fast marker-controlled watershed (MCW) algorithm traverses the entire image based on the distance function. Finally, we acquire all watersheds consisting of superpixel contours. Experimental results compare state-of-the-art algorithms and highlight the effectiveness of the proposed method. As an application, the proposed superpixel algorithm can be used in applications aiming for real-time, like mobile robot saliency detection and segmentation.	algorithm;analysis of algorithms;computational complexity theory;decimation (signal processing);display resolution;image gradient;map;mathematical optimization;mobile robot;pixel;real-time clock;robotics;time complexity;watershed (image processing)	Lixing Jiang;Huimin Lu;Vo Duc My;Artur Koch;Andreas Zell	2015	2015 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2015.7418960	computer vision;machine learning;segmentation-based object categorization;pattern recognition;mathematics;image segmentation;scale-space segmentation	Robotics	46.27742050988655	-68.34457900811131	40530
dc1bcca9ecf971018d9dcc179c61cc120e34c55a	fast image correspondence with global structure projection	object recognition;flat object;image correspondence;structure projection	This paper presents a method for recognizing images with flat objects based on global keypoint structure correspondence. This technique works by two steps: reference keypoint selection and structure projection. The using of global keypoint structure is an extension of an orderless bag-of-features image representation, which is utilized by the proposed matching technique for computation efficiency. Specifically, our proposed method excels in the dataset of images containing “flat objects” such as CD covers, books, newspaper. The efficiency and accuracy of our proposed method has been tested on a database of nature pictures with flat objects and other kind of objects. The result shows our method works well in both occasions.	book;computation;database;outline of object recognition	Qing-Liang Lin;Bin Sheng;Yang Shen;Zhifeng Xie;Zhihua Chen;Lizhuang Ma	2012	Journal of Computer Science and Technology	10.1007/s11390-012-1304-2	computer vision	Vision	39.213349894083706	-58.37109577495492	40744
379aa46d445c8a7ea0ab8df86c33452607c131b8	a mean approximation based bidimensional empirical mode decomposition with application to image fusion	image fusion;intrinsic mode function;期刊论文;mean approximation;empirical mode decomposition	Empirical mode decomposition (EMD) is an adaptive decomposition method, which is widely used in time-frequency analysis. As a bidimensional extension of EMD, bidimensional empirical mode decomposition (BEMD) presents many useful applications in image processing and computer vision. In this paper, we define the mean points in BEMD 'sifting' processing as centroid point of neighbour extrema points in Delaunay triangulation and propose using mean approximation instead of envelope mean in 'sifting'. The proposed method improves the decomposition result and reduces average computation time of 'sifting' processing. Furthermore, a BEMD-based image fusion approach is presented in this paper. Experimental results show our method can achieve more orthogonal and physical meaningful components and more effective result in image fusion application. We define the mean points in BEMD 'sifting' processing as centroid point of neighbour extrema points in Delaunay triangulation.Using mean approximation instead of envelope mean in BEMD 'sifting' processing.The proposed method improves the decomposition result and reduces average computation time of 'sifting' processing.A BEMD-based image fusion approach is proposed.	approximation;hilbert–huang transform;image fusion	Jianjia Pan;Yuan Yan Tang	2016	Digital Signal Processing	10.1016/j.dsp.2015.12.003	mathematical optimization;hilbert–huang transform;machine learning;mathematics;image fusion;statistics	Robotics	43.828168420418514	-62.81100581064323	40783
3d59e41f747f338a81151c24b9c1427fa30139ec	adaptive 3-d object recognition from multiple views	object representation;exploratory view sequences;tratamiento paralelo;object recognition;vision ordenador;object recognition machine vision testing analog computers concurrent computing machine intelligence biological system modeling deformable models video sequences history;matriz transicion;architecture systeme;modelo 3 dimensiones;traitement parallele;modele 3 dimensions;three dimensional shape;rapport aspect;picture processing;three dimensional model;reconnaissance objet;segmentation;forma tridimensional;transition matrix;multiple views;orientation spatiale;computer vision;image interpretation;interpretacion imagen;forme tridimensionnelle;relacion dimensional;adaptive systems;clustering;aspect transition matrices;image sequence;picture processing adaptive systems pattern recognition;pattern recognition;arquitectura sistema;vision ordinateur;secuencia imagen;3d object adaptive recognition;interpretation image;aspect transition matrices 3d object adaptive recognition pattern recognition clustering 3d appearance modelling segmentation exploratory view sequences;reconnaissance forme;reconocimiento patron;system architecture;orientacion espacial;parallel processing;sequence image;spatial orientation;matrice transition;aspect ratio;3d appearance modelling	The authors address the problem of generating representations of 3-D objects automatically from exploratory view sequences of unoccluded objects. In building the models, processed frames of a video sequence are clustered into view categories called aspects, which represent characteristic views of an object invariant to its apparent position, size, 2-D orientation, and limited foreshortening deformation. The aspects as well as the aspect transitions of a view sequence are used to build (and refine) the 3-D object representations online in the form of aspect-transition matrices. Recognition emerges as the hypothesis that has accumulated the maximum evidence at each moment. The 'winning' object continues to refine its representation until either the camera is redirected or another hypothesis accumulates greater evidence. This work concentrates on 3-D appearance modeling and succeeds under favorable viewing conditions by using simplified processes to segment objects from the scene and derive the spatial agreement of object features. >	outline of object recognition	Michael Seibert;Allen M. Waxman	1992	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.121784	parallel processing;computer vision;aspect ratio;spatial disorientation;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;pattern recognition;stochastic matrix;cluster analysis;segmentation;statistics	Vision	45.726328020433314	-55.78236068448247	40818
965bf5726891428a2af6922ead4779c0a1331392	image categorization using a semantic hierarchy model with sparse set of salient regions	image categorization;chunping liu yang zheng shengrong gong 图像分类 语义信息 层次模型 稀疏集 组织框架 图像数据库 检测模型 纹理基元 image categorization using a semantic hierarchy model with sparse set of salient regions;sparse set;salient region sparse set semantic hierarchy image annotation image categorization;image annotation;期刊论文;semantic hierarchy;salient region	Image categorization in massive image database is an important problem. This paper proposes an approach for image categorization, using sparse set of salient semantic information and hierarchy semantic label tree (HSLT) model. First, to provide more critical image semantics, the proposed sparse set of salient regions only at the focuses of visual attention instead of the entire scene was formed by our proposed saliency detection model with incorporating low and high level feature and Shotton’s semantic texton forests (STFs) method. Second, we also propose a new HSLT model in terms of the sparse regional semantic information to automatically build a semantic image hierarchy, which explicitly encodes a general to specific image relationship. And last, we archived image dataset using image hierarchical semantic, which is help to improve the performance of image organizing and browsing. Extension experimental results showed that the use of semantic hierarchies as a hierarchical organizing framework provides a better image annotation and organization, improves the accuracy and reduces human’s effort.	algorithm;archive;automatic image annotation;categorization;computer vision;high-level programming language;organizing (structure);preprocessor;sparse language;sparse matrix;texton	Chunping Liu;Yang Zheng;Shengrong Gong	2013	Frontiers of Computer Science	10.1007/s11704-013-2410-1	computer vision;semantic computing;feature detection;image retrieval;computer science;machine learning;pattern recognition;automatic image annotation	Vision	31.441587216007076	-53.55786549271968	40841
ad4a1b23ce25ccc9647ba5c5b2c71de0402a59ea	robust matching of building facades under large viewpoint changes	large viewing angle variations;detectors;object recognition;image segmentation;transformation model;building facade robust matching;edge detection;image matching;interest points;robust line fitting algorithm;wide viewpoint variations;computer vision;state of the art techniques;computational modeling;object recognition computer vision edge detection feature extraction image matching;planar convex quadrilateral;sift;image edge detection;pattern matching;feature extraction;symmetric patterns;projective transformation model;large viewpoint changes;feature descriptors;geometric properties;point correspondences;robustness computer vision pattern matching rendering computer graphics entropy feature extraction buildings object recognition object detection detectors;mser building facade robust matching large viewpoint changes point correspondences wide viewpoint variations symmetric patterns feature descriptors sift large viewing angle variations geometric properties robust line fitting algorithm planar convex quadrilateral projective transformation model state of the art techniques;mser;buildings	This paper presents a novel approach to finding point correspondences between images of building facades with wide viewpoint variations, and at the same time returning a large list of true matches between the images. Such images comprise repetitive and symmetric patterns, which render popular algorithms e.g., SIFT to be ineffective. Feature descriptors such as SIFT that are based on region patches are also unstable under large viewing angle variations. In this paper, we integrate both the appearance and geometric properties of an image to find unique matches. First we extract hypotheses of building facades based on a robust line fitting algorithm. Each hypothesis is defined by a planar convex quadrilateral in the image, which we call a “q-region”, and the four corners of each q-region provide the inputs from which a projective transformation model is derived. Next, a set of interest points are extracted from the images and are used to evaluate the correctness of the transformation model. The transformation model with the largest set of matched interest points is selected as the correct model, and this model also returns the best pair of corresponding q-regions and the most number of point correspondences in the two images. Extensive experimental results demonstrate the robustness of our approach in which we achieve a tenfold increase in true matches when compared to state of the art techniques such as SIFT and MSER.	algorithm;control theory;correctness (computer science);correspondence problem;feature vector;harris affine region detector;homography (computer vision);interest point detection;line fitting;maximally stable extremal regions;scale-invariant feature transform;viewing angle	Jimmy Addison Lee;Kin Choong Yow;Alex Yong Sang Chia	2009	2009 IEEE 12th International Conference on Computer Vision	10.1109/ICCV.2009.5459324	computer vision;detector;edge detection;feature extraction;computer science;cognitive neuroscience of visual object recognition;pattern matching;pattern recognition;scale-invariant feature transform;mathematics;geometry;image segmentation;maximally stable extremal regions;computational model	Vision	44.665875803095524	-53.187736352725416	40860
44bc1d8a4d65a4a3cb59239589e1fca9cd4b08cb	face recognition based on the multi-scale local image structures	reconnaissance visage;traitement signal;evaluation performance;methode section divisee;performance evaluation;image processing;learning;methode echelle multiple;image matching;biometrie;evaluacion prestacion;biometrics;template selection;biometria;procesamiento imagen;image multiple;metodo escala multiple;imagen multiple;holistic approach;traitement image;multiple image;algorithme;aprendizaje;algorithm;apprentissage;automatic recognition;local structure;face recognition;feature extraction;signal processing;template synthesis;pattern recognition;experimental validation;multiscale method;reconnaissance forme;extraction caracteristique;reconocimiento patron;local image structure;keypoint detection;procesamiento senal;appariement image;reconocimiento automatico;reconnaissance automatique;algoritmo;multistage method	This paper proposes a framework of face recognition based on the multi-scale local structures of the face image. While some basic tools in this framework are inherited from the SIFT algorithm, this work investigates and contributes to all major steps in the feature extraction and image matching. New approaches to keypoint detection, partial descriptor and insignificant keypoint removal are proposed specifically for human face images, a type of non-rigid and smooth visual objects. A strategy of keypoint search for the nearest subject and a two-stage image matching scheme are developed for the face identification task. They circumvent the problem that local structures matched with those in probe disperse into many different gallery images. Although the proposed framework can work for single template per subject, a training procedure is developed for multiple samples per subject. It contains template selection, unstable keypoint removal and template synthesis to meet different requirements in face recognition applications. Each ingredient of the proposed framework is experimentally validated and compared with its counterpart in the SIFT scheme. Results show that the proposed framework outperforms SIFT and some holistic approaches to face recognition. & 2011 Elsevier Ltd. All rights reserved.	computation;control theory;experiment;facial recognition system;feature extraction;holism;hough transform;image registration;k-nearest neighbors algorithm;machine learning;nearest neighbor search;outline of object recognition;requirement;scale-invariant feature transform;software deployment;visual objects	Cong Geng;Xudong Jiang	2011	Pattern Recognition	10.1016/j.patcog.2011.03.011	computer vision;image processing;feature extraction;computer science;artificial intelligence;machine learning;signal processing;three-dimensional face recognition;biometrics	Vision	45.356082188096515	-59.21595137689569	40877
7b8154f2d3fea55e1809d71f51521954130a096e	a computationally efficient approach to the estimation of two- and three-dimensional hidden markov models	analisis imagen;modelizacion;evaluation performance;metodo estadistico;observation par satellite;algorithm performance;image segmentation;viterbi training;performance evaluation;image processing;modelo 3 dimensiones;learning;maximum likelihood;hidden markov model;modele 3 dimensions;observacion por satelite;evaluacion prestacion;modele markov variable cachee;maximum vraisemblance;procesamiento imagen;three dimensional 3 d hmm;three dimensional model;statistical method;probabilistic approach;maximum likelihood estimation;traitement image;statistical model;three dimensional;algorithme;aprendizaje;modelisation;algorithm;large scale;apprentissage;satellite observation;maximum likelihood estimate;hidden markov models;resultado algoritmo;modelo 2 dimensiones;methode statistique;enfoque probabilista;approche probabiliste;hidden markov models parameter estimation image segmentation large scale systems image analysis two dimensional displays satellites viterbi algorithm computational efficiency stochastic processes;volume image processing hidden markov models hmms maximum likelihood estimation parameter estimation three dimensional 3 d hmm viterbi training;segmentation image;hidden markov models hmms;performance algorithme;estimacion parametro;modele 2 dimensions;stochastic modeling tool hidden markov models 2d hmm 3d hmm statistical modeling methods large scale image analysis parameter estimation algorithm satellite image segmentation variable state viterbi volume image segmentation volume image modeling;satellite image;algorithms computer graphics computer simulation image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval markov chains models statistical numerical analysis computer assisted signal processing computer assisted stochastic processes;image analysis;ground truth;maximum likelihood estimation image segmentation hidden markov models;stochastic model;parameter estimation;estimation parametre	Statistical modeling methods are becoming indispensable in today's large-scale image analysis. In this paper, we explore a computationally efficient parameter estimation algorithm for two-dimensional (2-D) and three-dimensional (3-D) hidden Markov models (HMMs) and show applications to satellite image segmentation. The proposed parameter estimation algorithm is compared with the first proposed algorithm for 2-D HMMs based on variable state Viterbi. We also propose a 3-D HMM for volume image modeling and apply it to volume image segmentation using a large number of synthetic images with ground truth. Experiments have demonstrated the computational efficiency of the proposed parameter estimation technique for 2-D HMMs and a potential of 3-D HMM as a stochastic modeling tool for volume images.	aerial photography;algorithmic efficiency;apache axis;axis vertebra;collections (publication);computational technique;computer vision;conditional entropy;dropping;estimation theory;extraction;feature vector;genetic algorithm;ground truth;hidden markov model;hyperactive behavior;hypertelorism, severe, with midface prominence, myopia, mental retardation, and bone fragility;image analysis;image segmentation;loss function;markov chain;markov random field;multidimensional digital pre-distortion;multiresolution analysis;optimization problem;performance;pixel;population parameter;probability;quantum decoherence;relevance;statistical model;stochastic modelling (insurance);synthetic intelligence;time complexity;unsupervised learning;biologic segmentation	Dhiraj Joshi;Jia Li;James Ze Wang	2006	IEEE Transactions on Image Processing	10.1109/TIP.2006.877039	computer science;machine learning;pattern recognition;mathematics;maximum likelihood;hidden markov model;statistics	Vision	51.154160955370095	-68.66855378476654	40885
b2a1897220e8b7016b85aeae9a280d6cd1b60bff	relative saliency model over multiple images with an application to yarn surface evaluation	yarn automatic optical inspection computer vision feature extraction gaze tracking;yarn visualization feature extraction inspection standards computational modeling integrated circuits;yarn surface evaluation comparison of multiple images relative saliency map visual attention;eye tracking technique relative saliency model yarn surface evaluation computer vision image understanding visual inspection visual attention model bottom up mechanism top down mechanism relative saliency evaluation structural feature extraction strategy mapping function multiimage content	Saliency models have been developed and widely demonstrated to benefit applications in computer vision and image understanding. In most of existing models, saliency is evaluated within an individual image. That is, saliency value of an item (object/region/pixel) represents the conspicuity of it as compared with the remaining items in the same image. We call this saliency as absolute saliency, which is uncomparable among images. However, saliency should be determined in the context of multiple images for some visual inspection tasks. For example, in yarn surface evaluation, saliency of a yarn image should be measured with regard to a set of graded standard images. We call this saliency the relative saliency, which is comparable among images. In this paper, a study of visual attention model for comparison of multiple images is explored, and a relative saliency model of multiple images is proposed based on a combination of bottom-up and top-down mechanisms, to enable relative saliency evaluation for the cases where other image contents are involved. To fully characterize the differences among multiple images, a structural feature extraction strategy is proposed, where two levels of feature (high-level, low-level) and three types of feature (global, local-local, local-global) are extracted. Mapping functions between features and saliency values are constructed and their outputs reflect relative saliency for multiimage contents instead of single image content. The performance of the proposed relative saliency model is well demonstrated in a yarn surface evaluation. Furthermore, the eye tracking technique is employed to verify the proposed concept of relative saliency for multiple images.	attention deficit hyperactivity disorder;autostereogram;bottom-up proteomics;computer vision;eye tracking;feature extraction;high- and low-level;histopathologic grade;medical imaging;pixel;requirement;silo (dataset);top-down and bottom-up design;visual inspection;contents - htmllinktype;mapped	Zhen Liang;Bingang Xu;Zheru Chi;David Dagan Feng	2014	IEEE Transactions on Cybernetics	10.1109/TCYB.2013.2281618	computer vision;computer science;machine learning;computer graphics (images)	Vision	38.23896159463768	-54.0372556926714	40908
18eb653ee9d1a6cfb54001f582722250c79031de	texture feature extraction and classification for iris diagnosis	digital image processing;traditional chinese medicine;estimation method;texture features;health surveillance;artificial intelligent;fractal dimension;gabor filter;texture analysis;feature extraction;support vector machine;medical diagnosis	Appling computer aided techniques in iris image processing, and combining occidental iridology with the traditional Chinese medicine is a challenging research area in digital image processing and artificial intelligence. This paper proposes an iridology model that consists the iris image pre-processing, texture feature analysis and disease classification. To the pre-processing, a 2-step iris localization approach is proposed; a 2-D Gabor filter based texture analysis and a texture fractal dimension estimation method are proposed for pathological feature extraction; and at last support vector machines are constructed to recognize 2 typical diseases such as the alimentary canal disease and the nerve system disease. Experimental results show that the proposed iridology diagnosis model is quite effective and promising for medical diagnosis and health surveillance for both hospital and public use.	feature extraction	Lin Ma;Naimin Li	2008		10.1007/978-3-540-77413-6_22	image texture;computer vision;speech recognition;engineering;pattern recognition	NLP	34.77900496488651	-74.19612841279942	40946
3d43396b70d5fc631cc2512c695068f9890f459c	a biologically inspired spiking model of visual processing for image feature detection	image feature detection;spiking neural networks;institutional repository research archive oaister	To enable fast reliable feature matching or tracking in scenes, features need to be discrete and meaningful, and hence edge or corner features, commonly called interest points are often used for this purpose. Experimental research has illustrated that biological vision systems use neuronal circuits to extract particular features such as edges or corners from visual scenes. Inspired by this biological behaviour, this paper proposes a biologically inspired spiking neural network for the purpose of image feature extraction. Standard digital images are processed and converted to spikes in a manner similar to the processing that transforms light into spikes in the retina. Using a hierarchical spiking network, various types of biologically inspired receptive fields are used to extract progressively complex image features. The performance of the network is assessed by examining the repeatability of extracted features with visual results presented using both synthetic and real images.	action potential;artificial neural network;digital image;feature (computer vision);feature detection (computer vision);feature detection (web development);feature extraction;feature model;repeatability;spiking neural network;synthetic intelligence	Dermot Kerr;T. Martin McGinnity;Sonya A. Coleman;Marine Clogenson	2015	Neurocomputing	10.1016/j.neucom.2015.01.011	computer vision;feature detection;computer science;artificial intelligence;machine learning;feature;spiking neural network	Vision	37.931544317097966	-55.24022973523902	40954
7cd5afdc7c5ae57b8174dfba1b5f562616ad4587	a new descriptor based on 2d dct for image retrieval	cbir;texture retrieval;face recognition;dct	Content-based image retrieval relies on fe atur comparison between images. So the selection o f feature vector is important. As many images are compressed by transforms, constructing the feature vector dire ctly in transform domain is a very popular topic. We pro pose a new feature vector in DCT domain. Our method selects part of DCT coefficients inside each block t o construct AC-Pattern and use DC coefficients betwe n neighboring blocks to construct DC-Pattern. Two his tograms are formed and parts of them are used to bu ild a descriptor vector integrating features to do imag e retrieval. Experiments are done both on face imag e databases and texture image database. Compared to ot her methods, results show that we can get better performance on both face and texture database by us ing the proposed method.	coefficient;content-based image retrieval;database;discrete cosine transform;feature vector;field electron emission	Cong Bai;Kidiyo Kpalma;Joseph Ronsin	2012			facial recognition system;image texture;computer vision;visual word;computer science;discrete cosine transform;pattern recognition;automatic image annotation;information retrieval	Vision	36.81981455644199	-59.8913384367948	40985
3118eed6edfc0ecabf14968906832510e4898e7f	detection of flooding events in social multimedia and satellite imagery using deep neural networks		This paper presents the solution of the DFKI-team for the Multimedia Satellite Task at MediaEval 2017. In our approach, we strongly relied on deep neural networks. The results show that the fusion of visual and textual features extracted by deep networks can be effectively used to retrieve social multimedia reports which provide a directed evidence of flooding. Additionally, we extend existing network architectures for semantic segmentation to incorporate RGB and Infrared (IR) channels into the model. Our results show that IR information is of vital importance for the detection of flooded areas in satellite imagery.	artificial neural network;deep learning;denial-of-service attack;german research centre for artificial intelligence	Benjamin Bischke;Prakriti Bhardwaj;Aman Gautam;Patrick Helber;Damian Borth;Andreas Dengel	2017			remote sensing;artificial neural network;satellite imagery;flooding (psychology);computer science	Web+IR	26.34061592229569	-56.16020943913702	41044
cb69155679b5d88eb22c145824f398dd45de5050	characterization of trabecular architecture in human femur radiographic images using directional multiresolution transform and adaboost model	radiographic images;human femur;curvelet transform;trabecular analysis;adaboost;osteoporosis	In this work, directional multiresolution curvelet transform is performed in radiographic images to characterize the trabecular structure. The trabecular regions of normal and abnormal human femur bone images are used for the study. The regions of interest such as femoral neck and head are analyzed and compared. The curvelet coefficients are calculated based on each scale and orientation for trabecular images. The mean and energy of the curvelet coefficients associated with each subband are computed. These values are used as the texture feature vector elements to evaluate changes taking place in the trabecular architecture. The three most significant mean and energy feature vector are found using principal component analysis and these values are used as an input to the Adaboost classifier. The results show that the architectural variations are more in the femoral neck when compared to femoral head. AdaBoost classifier performs better in terms of sensitivity (90%) and specificity (100%) for the chosen parameters for femoral neck region when compared to head regions.	adaboost;radiography	Thomas Christy Bobby;Swaminathan Ramakrishnan	2012		10.1007/978-3-642-35380-2_69	adaboost;computer vision;computer science;machine learning	Vision	35.697944108732585	-76.26885821629713	41056
9a5566545197cc16bb4f19daf0c537822e082c20	a new generalized hough transform for the detection of irregular objects	generalized hough transform;rotation invariance;hough transform	Abstract   In this paper, we introduce a new generalized Hough transform for the recognition of nonanalytic objects in a 2-D image. The main idea of our approach is to use pairs of boundary points with the same gradient angle to derive some rotation-invariant parameters to effect the fast Hough transform. Each voting to the Hough domain is contributed by a pair of edge pixels with the same gradient angle. The primary obstacle to using the Hough techniques, a large memory requirement, is overcome by our new voting approach. The conventional 4-D Hough domain is significantly reduced to a 2-D domain. This approach provides an easy method for determining the parameters of the object in question and an extremely effective solution for eliminating false votes in the transform.	generalised hough transform	Pui-Kin Ser;Wan-Chi Siu	1995	J. Visual Communication and Image Representation	10.1006/jvci.1995.1022	arithmetic;hough transform;computer vision;computer science;scale-invariant feature transform;mathematics;geometry	Vision	43.01742423661517	-55.74867070758382	41111
4305a544828a3374692910a6c86dbde7960e7893	an innovative method for pattern recognition and feature extraction using optimal rotational transformation technique	pattern recognition;feature extraction	Derivatives of 2-imino-1,3-dithiolane, 1,3-dithiole, 1,3-dithiane, 1,3-dithietane and 1,3-oxathiole have been found to reduce herbicidal injury to crop plants due to thiocarbamate and acetanilide herbicides.	feature extraction;pattern recognition	V. K. R. Jeyasingh;Christobel Manonmani	2007			acetanilide;thiocarbamate;mathematics;feature extraction;pattern recognition;artificial intelligence	Vision	31.90957326893139	-60.471143252271055	41112
8b3286628e75060d9966c377b973985a7b97de12	a novel method for detection of pigment network in dermoscopic images using graphs	computer aided diagnosis;edge detection;visual pigment;melanoma;dermoscopy;image enhancement;texture analysis;automatic detection;graph;pigment network detection;network structure;dermoscopic structures	We describe a novel approach to detect and visualize pigment network structures in dermoscopic images, based on the fact that the edges of pigment network structures form cyclic graphs which can be automatically detected and analyzed. First we perform a pre-processing step of image enhancement and edge detection. The resulting binary edge image is converted to a graph and the defined feature patterns are extracted by finding cyclic subgraphs corresponding to skin texture structures. We filtered these cyclic subgraphs to remove other round structures such as globules, dots, and oil bubbles, based on their size and color. Another high-level graph is created from each correctly extracted subgraph, with a node corresponding to a hole in the pigment network. Nodes are connected by edges according to their distances. Finally the image is classified according to the density ratio of the graph. Our results over a set of 500 images from a well known atlas of dermoscopy show an accuracy of 94.3% on classification of the images as pigment network Present or Absent.	atlases;classification;dermoscopy;distance;edge detection;extraction;graph - visual representation;high- and low-level;image editing;node - plant part;pigment;preprocessor	Maryam Sadeghi;Majid Razmara;Tim K. Lee;M. Stella Atkins	2011	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2010.07.002	computer vision;edge detection;computer science;mathematics;graph;computer graphics (images)	Vision	40.1761678348896	-71.36609949639737	41140
25fa457a400be2f1e41ba143a60e7a5dcccac40e	initializing receptive field-like weights in bp network	receptive field			Yun-jiu Wang;He Cui;Xiang-lin Qi	1998			pattern recognition;artificial intelligence;machine learning;initialization;receptive field;computer science	ML	27.894778583701573	-56.08920376457239	41174
29d73db72bf8cc83382e6065a277853ad0bc8415	shape-only features for plant leaf identification		This paper presents a novel feature set for shape-only leaf identification motivated by real-world, mobile deployment. The feature set includes basic shape features, as well as signal features extracted from local area integral invariants (LAIIs), similar to curvature maps, at multiple scales. The proposed methodology is evaluated on a number of publicly available leaf datasets with comparable results to existing methods which make use of colour and texture features in addition to shape. Over 90% classification accuracy is achieved on most datasets, with top-four accuracy for these datasets reaching over 98%. Rotation and scale invariance of the proposed features are demonstrated, along with an evaluation of the generalisability of the approach for generic shape matching.	automated species identification;feature extraction;gaussian blur;information extraction;mpeg-7;map;software deployment	Charlie Hewitt;Marwa Mahmoud	2018	CoRR			Vision	32.833341297218574	-56.07807744071452	41204
e94e8fbe4ebbfd6f89b23111293ad00f4a07588f	transfer learning for multicenter classification of chronic obstructive pulmonary disease		Chronic obstructive pulmonary disease (COPD) is a lung disease that can be quantified using chest computed tomography scans. Recent studies have shown that COPD can be automatically diagnosed using weakly supervised learning of intensity and texture distributions. However, up till now such classifiers have only been evaluated on scans from a single domain, and it is unclear whether they would generalize across domains, such as different scanners or scanning protocols. To address this problem, we investigate classification of COPD in a multicenter dataset with a total of 803 scans from three different centers, four different scanners, with heterogenous subject distributions. Our method is based on Gaussian texture features, and a weighted logistic classifier, which increases the weights of samples similar to the test data. We show that Gaussian texture features outperform intensity features previously used in multicenter classification tasks. We also show that a weighting strategy based on a classifier that is trained to discriminate between scans from different domains can further improve the results. To encourage further research into transfer learning methods for the classification of COPD, upon acceptance of this paper we will release two feature datasets used in this study on http://bigr.nl/research/projects/copd.	3d scanner;ct scan;chronic obstructive airway disease;cryptanalysis of the lorenz cipher;disease ontology;lung diseases, obstructive;lung diseases;naive bayes classifier;normal statistical distribution;protocols documentation;silo (dataset);statistical classification;supervised learning;test data;weight;x-ray computed tomography	Veronika Cheplygina;Isabel Pino Pe&#x00F1;a;Jesper Holst Pedersen;David A. Lynch;Lauge Sørensen;Marleen de Bruijne	2018	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2017.2769800	artificial intelligence;supervised learning;transfer of learning;computed tomography;domain adaptation;pattern recognition;test data;machine learning;computer science	ML	32.9111392068765	-75.7539949933379	41229
1ab99c92b541d0431c866863337e1c8947267a4f	point-of-gaze analysis reveals visual search strategies	analisis imagen;filtering;filtrage;eye;bottom up;metodo monte carlo;image processing;estudio comparativo;filtrado;exploracion visual;simulacion numerica;procesamiento imagen;methode monte carlo;image classification;search strategy;1 f noise;traitement image;observador;etude comparative;observateur;recherche visuelle;visual search;monte carlo method;simulation numerique;cognition;classification image;poursuite cible;comparative study;strategie recherche;copper indium disulfide;cognicion;ruido baja frecuencia;bruit basse frequence;image analysis;eye tracking;target tracking;monte carlo simulation;analyse image;observer;k means clustering;qualitative evaluation;numerical simulation;estrategia investigacion;kullback leibler distance	Seemingly complex tasks like visual search can be analyzed using a cognition-free, bottom-up framework. We sought to reveal strategies used by observers in visual search tasks using accurate eye tracking and image analysis at point of gaze. Observers were instructed to search for simple geometric targets embedded in 1/f noise. By analyzing the stimulus at the point of gaze using the classification image (CI) paradigm, we discovered CI templates that indeed resembled the target. No such structure emerged for a random-searcher. We demonstrate, qualitatively and quantitatively, that these CI templates are useful in predicting stimulus regions that draw human fixations in search tasks. Filtering a 1/f noise stimulus with a CI results in a ‘fixation prediction map’. A qualitative evaluation of the prediction was obtained by overlaying k-means clusters of observers’ fixations on the prediction map. The fixations clustered around the local maxima in the prediction map. To obtain a quantitative comparison, we computed the Kullback-Leibler distance between the recorded fixations and the prediction. Using random-searcher CIs in Monte Carlo simulations, a distribution of this distance was obtained. The z-scores for the human CIs and the original target were -9.70 and -9.37 respectively indicating that even in noisy stimuli, observers deploy their fixations efficiently to likely targets rather than casting them randomly hoping to fortuitously find the target.	algorithm;bottom-up parsing;cognition;embedded system;experiment;eye tracking;human visual system model;image analysis;image resolution;k-means clustering;kullback–leibler divergence;maxima and minima;monte carlo method;multiresolution analysis;pink noise;pixel;programming paradigm;randomness;simulation;top-down and bottom-up design	Umesh Rajashekar;Lawrence K. Cormack;Alan C. Bovik	2004		10.1117/12.537118	computer vision;geography;artificial intelligence;cartography	ML	50.778819090283704	-67.89047588727024	41233
afee0152b80149802604192fb981a39c818c4466	an automated method for counting and characterizing red blood cells using mathematical morphology	medical image processing blood image segmentation;binary image automated counting method red blood cells characterization blood sample overlapping characteristics mathematical morphological operations otsu thresholding method gray scale image thresholding erosion dilation hole filling process;mathematical morphology blood cell count image processing thresholding;biomedical imaging;accuracy;smoothing methods;shape;cells biology red blood cells accuracy shape smoothing methods biomedical imaging;red blood cells;cells biology	This paper presents an automated method for counting red blood cells present in a blood sample. The proposed method addresses the problems of holes present in blood cells and overlapping characteristics of the red blood cells. The procedure is quite simple and straightforward, which utilizes mathematical morphological operations of erosion and dilation for performing different steps. It first thresholds a gray scale image to obtain the binary image using the Otsu thresholding method, and then, performs the hole filling process on the red blood cells if they have holes. Then, the process moves on to the job of counting the red blood cells. For this, each red blood cell is extracted and its shape analysis is performed to decide whether it is circular, non-circular, overlapping or just partially present in the sample. If a cell is only partially present in the image, then it is discarded. In case of overlapping, the number of cells in the overlapped area is determined. Several experimental results have been presented to establish the effectiveness of the method. One of the important findings is that the proposed method gives accurate count of red blood cells of the blood sample, and classifies each cell into one of the four categories mentioned above.	binary image;dilation (morphology);erosion (morphology);grayscale;mathematical morphology;otsu's method;shape analysis (digital geometry);thresholding (image processing)	Pradipta Maji;Ankita Mandal;Madhura Ganguly;Sanjoy Saha	2015	2015 Eighth International Conference on Advances in Pattern Recognition (ICAPR)	10.1109/ICAPR.2015.7050674	biology;computer vision;engineering drawing;computer graphics (images)	Robotics	39.10423233669034	-74.5896463726354	41235
25a181e7094a10ebb1b73bfd07afbb428805bf5d	deconvolving convolution neural network for cell detection		Automatic cell detection in histology images is a challenging task due to varying size, shape and features of cells and stain variations across a large cohort. Conventional deep learning methods regress the probability of each pixel belonging to the centre of a cell followed by detection of local maxima. We present deconvolution as an alternate approach to local maxima detection. The ground truth points are convolved with a mapping filter to generate artifical labels. A convolutional neural network (CNN) is modified to convolve it’s output with the same mapping filter and is trained for the mapped labels. Output of the trained CNN is then deconvolved to generate points as cell detection. We compare our method with state-of-the-art deep learning approaches where the results show that the proposed approach detects cells with comparatively high precision and F1-score.	artificial neural network;convolution;convolutional neural network;deconvolution;deep learning;f1 score;ground truth;maxima and minima;pixel;preprocessor;television interface adaptor	Shan-e-Ahmed Raza;Khalid AbdulJabbar;Mariam Jamal-Hanjani;Selvaraju Veeriah;John Le Quesne;Charles Swanton;Yinyin Yuan	2018	CoRR		convolutional neural network;pattern recognition;deep learning;pixel;artificial intelligence;deconvolution;ground truth;convolution;maxima and minima;computer science	ML	31.03692807708951	-75.08179813208233	41246
d6cda0477d5b7892097604447c502f1845717185	recognition and classification of coating film defects on automobile body based on image processing		To realize online detection of coating film defects on automobile body and improve the efficiency of the identification of defects, a new classification method of coating film defect based on image processing was proposed. According to the types and characteristics of coating film defects, this paper selected six geometric features and sixteen grayscale characteristics as defect feature parameters. Image enhancement method based on morphology and image segmentation method based on graph theory were proposed to complete image processing. The process of using support vector machine (SVM) to identify the defects was elaborated, including data standardization and dimension reduction. The identification experiments on six kinds of coating film defects showed that four kinds of defects recognition rates including particles, sagging, scratches and orange were all beyond 90% and the other two kinds of defects recognition rates were 85.00% and 50.25% respectively. The time of testing a sample was about 2 seconds. The reason why the other two kinds of defects recognition rates were not ideal was that the characteristics of sparkling and pinhole were too close to recognize. But the recognition rate can be improved by the development of equipment and the increasing number of SVM training sample. Therefore, the method can satisfy the basic requirement of coating film defects on-line detection, and the method is convenient to apply.	dimensionality reduction;edge detection;experiment;graph theory;grayscale;hogging and sagging;image editing;image processing;image segmentation;mathematical morphology;online and offline;software bug;support vector machine	Pu Cheng;An Cui;Yujia Yang;Yawei Luo;Wenlong Sun	2017	2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)	10.1109/CISP-BMEI.2017.8302070	support vector machine;grayscale;computer vision;graph theory;image processing;pattern recognition;image segmentation;standardization;dimensionality reduction;artificial intelligence;computer science;coating		37.08632188358486	-68.4692609264969	41256
5d60ecc06050096d6cfc3e68dce8fa425f3c9a1d	integrating spatio-temporal information in image sequence analysis to enforce consistency of interpretation	hermite function;image sequence analysis;temporal information;texture analysis;infrared imaging;neural network	We present a technique of image-sequence analysis which ensures consistency of interpretation in terms of the classification of segmented regions, both spatially within an image and temporally through a sequence of forward-looking infrared images taken from a low-flying aircraft. The technique is based on classical relaxation labeling techniques but is novel in that it treats segmented regions assingle entitiesthat have both spatial and temporal neighbors. This enables classification probabilities both to be propagated through the sequence and to be used in the minimization of the Kullback entropy of information. Sample results are shown from the application of the method to a 12-s sequence of infrared images that have been segmented using co-occurrence-based techniques. For completeness, the paper also describes the whole analysis algorithm including segmentation, texture analysis using discrete Hermite functions, and classification using neural network techniques.© British Crown copyright 1998. Published with the permission of the Defence Evaluation and Research Agency on behalf of the Controller of HMSO.	sequence analysis	John F. Haddon;James F. Boyce	1998	Digital Signal Processing	10.1006/dspr.1998.0325	computer vision;computer science;machine learning;data mining;mathematics;artificial neural network;statistics	Vision	46.08240980571651	-65.88536115541496	41309
38116b324d2edde306047d59409d04b213a1aefc	tracking multiple features using relaxation	movimiento;concordance;image processing;occlusion;availability;disponibilidad;coaccion;contrainte;procesamiento imagen;concordancia;motion;etiquetage;traitement image;analyse;tracking movable target;relajacion;etiquetaje;constraint;smoothing;mouvement;alisamiento;pattern recognition;labelling;relaxation;analysis;poursuite;reconnaissance forme;reconocimiento patron;disponibilite;lissage;persecucion y continuacion;analisis	Abstract   A new algorithm is introduced for tracking multiple features in an image sequence. First, the proposed method iteratively reduces the disparity of each possible match by relaxation labeling. It is assumed that all trajectories are smooth and the smoothness is used as the measure for correspondence. Some cases of wrong correspondences can be recovered by a proposed scheme called constraint-aided exchange during the tracking process. Occluded or missing feature points can be detected and predicted in the proposed algorithm. Finally, the algorithm is applied to data obtained from real world scenes. The human motion analysis can be achieved by the tracking algorithm.	linear programming relaxation	Jim Z. C. Lai	1993	Pattern Recognition	10.1016/0031-3203(93)90179-Z	computer vision;image processing;computer science;artificial intelligence;pattern recognition;analysis;mathematics	Vision	48.84464129397541	-57.37178593778546	41311
207109225d9bff2cf8c48c837c384c036d7be9dd	computer aided diagnosis of pleural effusion in tuberculosis chest radiographs		Tuberculosis (TB) is one the leading killers in the world, and its early detection at scale is a challenge that remains. Computer Aided Detection of Tuberculosis is an important possibility for the world due to the mismatch in the incidences of this disease with the number of trained human readers for its identification. In this paper, we propose novel features for the detection of one of the symptoms observed in cases of TB, Pleural Effusion (PE). We begin by segmenting the lung regions, followed by creation of a novel feature set. We achieve an ROC of 0.961 on discriminating PE against Chest X-Rays (CXRs) without incidences of TB. To validate that our system discriminates against PE, we achieve an ROC of 0.864 against CXRs showing incidences of TB but a lack of PE. These features are then tested on two publicly available datasets (One collected from the United States, and the other from China). Due to the lack of other work for detection of PE on these datasets, a direct comparison is unfortunately not possible. However, the results obtained surpass those of work on PE detection on other private datasets.	radiography	Utkarsh Sharma;Brejesh Lall	2017		10.1007/978-3-319-68560-1_55	artificial intelligence;computer science;tuberculosis;pattern recognition;pleural effusion;radiology;computer-aided diagnosis	AI	33.119134160743364	-77.10369340238097	41317
94ce7361f5e8f06f700cd24c147b64b88c40a7c5	defect detection in textile fabrics using gabor wavelet networks	conference_paper;gabor wavelets;defect detection		gabor wavelet;software bug	Kai-Ling Mak;Pan Peng	2005			computer vision;speech recognition;gabor wavelet	Vision	41.10056650766305	-65.46792555430147	41329
f9329e2640d0a8913b9765cfe575c4b4cff0b51b	semi-automatic methods for airway and adjacent vessel measurement in bronchiectasis patterns in lung hrct images of cystic fibrosis patients		Airway and vessel characterization of bronchiectasis patterns in lung high-resolution computed tomography (HRCT) images of cystic fibrosis (CF) patients is very important to compute the score of disease severity. We propose a hybrid and evolutionary optimized threshold and model-based method for characterization of airway and vessel in lung HRCT images of CF patients. First, the initial model of airway and vessel is obtained using the enhanced threshold-based method. Then, the model is fitted to the actual image by optimizing its parameters using particle swarm optimization (PSO) evolutionary algorithm. The experimental results demonstrated the outperformance of the proposed method over its counterpart in R-squared, mean and variance of error, and run time. Moreover, the proposed method outperformed its counterpart for airway inner diameter/vessel diameter (AID/VD) and airway wall thickness/vessel diameter (AWT/VD) biomarkers in R-squared and slope of regression analysis.		Zeinab Naseri Samaghcheh;Soghra Sherafat;Hamid Abrishami Moghaddam;Mohammadreza Modaresi;Neda Pak;Fatemeh Zamani	2018	Journal of digital imaging	10.1007/s10278-018-0076-9	radiology;cystic fibrosis;computed tomography;airway;lung;bronchiectasis;computer science	Vision	36.149834399193516	-78.0111919826973	41391
cd5c0411635de3344ec5da39bd3a4317d8eadce5	effects of iris surface curvature on iris recognition	statistical analysis iris recognition;iris recognition;statistical analysis iris surface curvature iris recognition refractive power matching ability;statistical analysis;iris iris recognition shape lenses splines mathematics imaging shape measurement	To focus on objects at various distances, the lens of the eye must change shape to adjust its refractive power. This change in lens shape causes a change in the shape of the iris surface which can be measured by examining the curvature of the iris. This work isolates the variable of iris curvature in the recognition process and shows that differences in iris curvature degrade matching ability. To our knowledge, no other work has examined the effects of varying iris curvature on matching ability. To examine this degradation, we conduct a matching experiment across pairs of images with varying degrees of iris curvature differences. The results show a statistically significant degradation in matching ability. Finally, the real world impact of these findings is discussed.	elegant degradation;iris gl;iris recognition	Joseph Thompson;Patrick J. Flynn;Kevin W. Bowyer;Hector J. Santos-Villalobos	2013	2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS)	10.1109/BTAS.2013.6712693	computer vision;iris recognition;statistics	Vision	53.058813902375235	-57.13118638499012	41422
ed79ccc63a4e8bf03c9b555b3e61f962dfa7a89d	fingerprint image segmentation based on quadric surface model	modelizacion;distribucion espacial;model based reasoning;raisonnement base sur modele;base donnee;image segmentation;image processing;biometrie;biometrics;database;biometria;procesamiento imagen;base dato;classification;traitement image;modelisation;repartition spatiale;empreinte digitale;spatial distribution;fingerprint recognition;backpropagation algorithm;surface model;dactyloscopie;segmentation image;fingerprint;algorithme retropropagation;huella digital;reseau neuronal;modeling;clasificacion;red neuronal;fingerprint identification;variance;neural network;variancia;algoritmo retropropagacion	It is essential to segment fingerprint image from background effectively, which could improve image processing speed and fingerprint recognition accuracy. This paper proposes a novel fingerprint segmentation method at pixel level based on quadric surface model. Three parameters, Coherence, Mean and Variance of each pixel are extracted and spatial distribution model of fingerprint pixels is acquired and analyzed. Our study indicates that the performance of fingerprint image segmentation with a linear classifier is very limited. To deal with this problem, we develop a quadric surface formula for fingerprint image segmentation and acquire coefficients of the quadric surface formula using BP neural network trained on sample images. In order to evaluate the performance of our proposed method in comparison to linear classifiers, experiments are performed on public database FVC2000 DB2. Experimental result indicates that the proposed model can reduce pixel misclassification rate to 0.53%, which is significantly better than the linear classifiers misclassification rate of 6.8%.	algorithm;artificial neural network;coefficient;database;experiment;feature selection;fingerprint recognition;image processing;image segmentation;linear classifier;linear programming;nonlinear system;pixel	Yilong Yin;Yanrong Wang;Xiukun Yang	2005		10.1007/11527923_67	fingerprint;computer vision;image processing;computer science;pattern recognition;artificial neural network	Vision	44.36033543408617	-59.84211681356648	41423
63ab1c839750f1a712e699f149f09021fff9b2ce	estimation of the botanical composition of clover-grass leys from rgb images using data simulation and fully convolutional neural networks	clover-grass;deep learning;dry matter composition;precision agriculture;proximity sensing	Optimal fertilization of clover-grass fields relies on knowledge of the clover and grass fractions. This study shows how knowledge can be obtained by analyzing images collected in fields automatically. A fully convolutional neural network was trained to create a pixel-wise classification of clover, grass, and weeds in red, green, and blue (RGB) images of clover-grass mixtures. The estimated clover fractions of the dry matter from the images were found to be highly correlated with the real clover fractions of the dry matter, making this a cheap and non-destructive way of monitoring clover-grass fields. The network was trained solely on simulated top-down images of clover-grass fields. This enables the network to distinguish clover, grass, and weed pixels in real images. The use of simulated images for training reduces the manual labor to a few hours, as compared to more than 3000 h when all the real images are annotated for training. The network was tested on images with varied clover/grass ratios and achieved an overall pixel classification accuracy of 83.4%, while estimating the dry matter clover fraction with a standard deviation of 7.8%.	artificial neural network;biological neural networks;classification;convolutional neural network;emoticon;estimated;fertilization;image analysis;labor (childbirth);neural network simulation;overlay device component;pixel;plant weeds;top-down and bottom-up design;mixture	Søren Skovsen;Mads Dyrmann;Anders Krogh Mortensen;Kim Arild Steen;Ole Green;Jørgen Eriksen;René Gislum;Rasmus Nyholm Jørgensen;Henrik Karstoft	2017		10.3390/s17122930	convolutional neural network;electronic engineering;pixel;deep learning;precision agriculture;engineering;standard deviation;rgb color model;composition (visual arts);artificial intelligence;pattern recognition	ML	30.518832365367498	-70.21268765810692	41466
16f933ffedddde0c5be0a1eccdac824ec3d3a7e2	sar and optical images registration using shape context	remote sensing image;feature extraction image edge detection shape context remote sensing optical sensors image registration;object recognition;c band sar images;edge detection;image matching;hand written digit;edge feature extraction;c band sar images optical image registration shape context feature based multi sensor image registration system edge feature extraction hand written digit object recognition remote sensing image matching;airborne;feature based multi sensor image registration system;optical imaging;shape;synthetic aperture radar edge detection feature extraction image matching image registration object recognition remote sensing;optical image registration;image edge detection;edge features;feature extraction;remote sensing;image registration;sar image;shape context;feature dilation;optical sensors;context;remote sensing image matching;airborne image registration edge features feature dilation shape context;synthetic aperture radar	Image registration is the process of overlaying two or more images of the same scene taken at different times, from different view points, and /or by different sensors. A novel feature-based multi-sensor image registration system is developed. The system consists of two new points: first, edge features are extracted from images, and the features are dilated to suppress some certain kinds of noise arising from groves; second, the preprocessed features are matched using the improved shape context. The shape context has been found to be robust in hand written digit and object recognition, and now it is introduced into remote sensing image matching after some adjustments. The developed system is successfully applied to register airborne optical and C-band SAR images in our experiments, and the results demonstrate its robustness and accuracy.	airborne ranger;experiment;image registration;outline of object recognition;sensor;shape context	Lei Huang;Zhen Li;Rui Zhang	2010	2010 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2010.5653392	computer vision;synthetic aperture radar;edge detection;feature extraction;shape;computer science;image registration;cognitive neuroscience of visual object recognition;pattern recognition;optical imaging;physics;remote sensing	Vision	45.77265609692968	-65.57982433496902	41487
296a7d6c1a070104691381ed9e49795c31d7fa5e	computing the aspect graph for line drawings of polyhedral objects	graph theory;object recognition;optical refraction;geometry;computerised pattern recognition;object recognition shape computer science partitioning algorithms computer vision geometry optical refraction;gaussian sphere 3d shape representation computerised pattern recognition computerised picture processing aspect graph line drawings polyhedral objects object recognition;computer vision;line drawings;aspect graph;shape;graph theory computerised pattern recognition computerised picture processing;gaussian sphere;computerised picture processing;computer science;polyhedral objects;3d shape representation;partitioning algorithms	J.J. Koenderink and A.J. van Doorn (1979) introduced aspect graphs as a way of representing 3-D shape for object recognition. The set of viewpoints on the Gaussian sphere is partitioned into regions such that in each region, the qualitative structure of the line drawing remains the same. The viewing data of an object are the partition of the Gaussian sphere and representative line drawings for each region of the partition. An algorithm is presented for computing the viewing data of polyhedral objects. A full catalog of the visual events that occur for polyhedral objects is provided. >	polyhedron	Ziv Gigus;Jitendra Malik	1988		10.1109/ROBOT.1988.12288	computer vision;combinatorics;shape;computer science;graph theory;cognitive neuroscience of visual object recognition;gaussian surface;geometry	Vision	49.150070203035575	-61.13433736127923	41497
23e6b41d355e6ff8949f5ae37e8faae11219b5d9	information-theoretic active contour model for microscopy image segmentation using texture		High throughput technologies have increased the need for automated image analysis in a wide variety of microscopy techniques. Geometric active contour models provide a solution to automated image segmentation by incorporating statistical information in the detection of object boundaries. A statistical active contour may be defined by taking into account the optimisation of an information theoretic measure between object and background. We focus on a product-type measure of divergence known as Cauchy-Schwartz distance which has numerical advantages over ratio-type measures. By using accurate shape derivation techniques, we define a new geometric active contour model for image segmentation combining Cauchy-Schwartz distance and Gabor energy texture filters. We demontrate the versatility of this approach on images from the Brodatz dataset and phase-contrast microscopy images of cells.		Veronica Biga;Daniel Coca	2016		10.1007/978-3-319-67834-4_2	machine learning;computer science;computer vision;divergence;microscopy;scale-space segmentation;image segmentation;image texture;active contour model;artificial intelligence;region growing	Vision	49.291828729222075	-70.68582870022513	41540
e183abc21456dcd780fe5af43fe713a6336b840e	hand motion recognition using a distance sensor array		Many studies of hand motion recognition using a surface electromyogram (sEMG) have been conducted. However, it is difficult to get the activity of deep layer muscles from an sEMG. The pronation and supination of the forearm are caused by the activities of deep layer muscles. These motions are important in grasping and manipulating daily objects. We think it is possible to accurately recognize hand motions from the activity of the deep layer muscles using the forearm deformation. Forearm deformation is caused by a complex motion of the surface and deep layer muscles, tendons, and bones. In this study, we propose a novel hand motion recognition method based on measuring forearm deformation with a distance sensor array. The distance sensor array is designed based on a 3D model of the forearm. It can measure small deformations because the shape of the array is designed to fit the neutral position of the forearm. A Support Vector Machine (SVM) is used to recognize seven types of hand motion. Two types of features are extracted for the recognition based on the time difference of the forearm deformation. Using the proposed method, we perform hand motion recognition experiments. The experimental results showed that the proposed method correctly recognized hand motions caused by the activity of both surface and deep layer muscles, including the pronation and supination of the forearm. Moreover, the hand opening of small deformation motions was correctly recognized.	3d modeling;electromyography;experiment;sensor;support vector machine	Sung-Gwi Cho;Masahiro Yoshikawa;Ming Ding;Jun Takamatsu;Tsukasa Ogasawara	2017	2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2017.8172496	deformation (mechanics);artificial intelligence;computer vision;wrist;sensor array;forearm;feature extraction;computer science	Robotics	25.822975707802804	-67.34050434164791	41602
f2a58d8b8b17569f1138798bb0a0b3b85b0cd21b	face inpainting by feature guidance	databases;feature guidance;mouth;image databases;skin;face database;image restoration;damaged image;data mining;face recognition;shape;image occlusion;feature extraction;image reconstruction;pixel;face inpainting;artificial intelligence;face;image restoration face recognition feature extraction;humans;computer science;image restoration face inpainting feature guidance image occlusion face database damaged image;nose;image reconstruction artificial intelligence image databases humans face nose mouth skin educational institutions computer science	Face image partially occluded or damaged can be repaired automatically. We proposed a new inpainting algorithm, based on patch guidance deduced from an existing face database, to recover the damaged portions. This newly proposed concept of guided inpainting method produces seamless faces which are hardly seen drawbacks. Examples of our results can be retrieved from http://member.mine.tku.edu.tw/www/ISCAS09/.	algorithm;color;inpainting;seamless3d;world wide web	Nick C. Tang;Yueting Zhuang;Yushun Wang;Timothy K. Shih;Joseph C. Tsai	2009	2009 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2009.5118337	iterative reconstruction;facial recognition system;face;image restoration;computer vision;speech recognition;feature extraction;shape;computer science;pattern recognition;skin;pixel;inpainting	EDA	40.508497201327344	-61.446671423362595	41651
87e2075d954aa4474b674bde8dd1a26a0fe720c3	a modified fuzzy c-means algorithm for differentiation in mri of ophthalmology	nuclear magnetic resonance imaging;fuzzy c means algorithm;tissu;cluster algorithm;fuzzy c mean;analyse amas;ophthalmology;imagineria rmn;systeme aide decision;algoritmo borroso;logique floue;logica difusa;intelligence artificielle;segmentation;resonancia magnetica;sistema ayuda decision;classification;magnetic resonance image;fuzzy logic;tejido;decision support system;cluster analysis;parameter selection;magnetic resonance;fuzzy algorithm;tissue;algorithme flou;artificial intelligence;analisis cluster;imagerie rmn;inteligencia artificial;resonance magnetique;clasificacion;segmentacion;oftalmologia;ophtalmologie	In this paper we propose an algorithm, called the modified suppressed fuzzy c-means (MS-FCM), that simultaneously performs clustering and parameter selection for the suppressed FCM (S-FCM) proposed by Fan et al. [2]. Numerical examples illustrate the effectiveness of the proposed MS-FCM algorithm. Finally, the S-FCM and MS-FCM algorithms are applied in the segmentation of the magnetic resonance image (MRI) of an ophthalmic patient. In our comparisons of S-FCM, MS-FCM and alternative FCM (AFCM) proposed by Wu and Yang [14] for these MRI segmentation results, we find that the MS-FCM provides better detection of abnormal tissue than S-FCM and AFCM when based on a window selection. Overall, the MS-FCM clustering algorithm is more efficient and is strongly recommended as an MRI segmentation technique.	algorithm	Wen-Liang Hung;Yen-Chang Chang	2006		10.1007/11681960_33	fuzzy logic;biological classification;computer science;artificial intelligence;magnetic resonance imaging;mathematics;cluster analysis;segmentation;algorithm	Vision	43.01568703177975	-72.39594824535044	41662
bc971c3714f6c0fd769ada3f61d62ab61d0a2b08	a rigid image registration based on the nonsubsampled contourlet transform and genetic algorithms	wavelet analysis;multi resolution analysis;image processing computer assisted;models genetic;wavelet transform;image registration;nonsubsampled contourlet transform;algorithms;genetic algorithms;computer simulation	Image registration is a fundamental task used in image processing to match two or more images taken at different times, from different sensors or from different viewpoints. The objective is to find in a huge search space of geometric transformations, an acceptable accurate solution in a reasonable time to provide better registered images. Exhaustive search is computationally expensive and the computational cost increases exponentially with the number of transformation parameters and the size of the data set. In this work, we present an efficient image registration algorithm that uses genetic algorithms within a multi-resolution framework based on the Non-Subsampled Contourlet Transform (NSCT). An adaptable genetic algorithm for registration is adopted in order to minimize the search space. This approach is used within a hybrid scheme applying the two techniques fitness sharing and elitism. Two NSCT based methods are proposed for registration. A comparative study is established between these methods and a wavelet based one. Because the NSCT is a shift-invariant multidirectional transform, the second method is adopted for its search speeding up property. Simulation results clearly show that both proposed techniques are really promising methods for image registration compared to the wavelet approach, while the second technique has led to the best performance results of all. Moreover, to demonstrate the effectiveness of these methods, these registration techniques have been successfully applied to register SPOT, IKONOS and Synthetic Aperture Radar (SAR) images. The algorithm has been shown to work perfectly well for multi-temporal satellite images as well, even in the presence of noise.	analysis of algorithms;aperture (software);bands;computation;computational complexity theory;contourlet;entity name part qualifier - adopted;genetic algorithm;image processing;image registration;image resolution;ll parser;mathematical optimization;muscle rigidity;numerous;published comment;radar;simulation;time complexity;wavelet;cell transformation;non-t, non-b, calla negative childhood acute lymphoblastic leukemia;registration - actclass;sensor (device)	Fatiha Meskine;Miloud Chikr El-Mezouar;Nasreddine Taleb	2010		10.3390/s100908553	computer simulation;wavelet;computer vision;genetic algorithm;computer science;image registration;machine learning;wavelet transform;computer graphics (images)	Vision	50.45377658599801	-78.49583656280284	41674
12006844ce2cdbedeaa506e0e860de630076778a	the 3d moore-rayleigh test for the quantitative groupwise comparison of mr brain images	clinical data;nonparametric test;three dimensional;distribution function;mr imaging;non rigid registration;brain imaging;synthetic data;permutation test	Non-rigid registration of MR images to a common reference image results in deformation fields, from which anatomical differences can be statistically assessed, within and between populations. Without further assumptions, nonparametric tests are required and currently the analysis of deformation fields is performed by permutation tests. For deformation fields, often the vector magnitude is chosen as test statistic, resulting in a loss of information. In this paper, we consider the three dimensional Moore-Rayleigh test as an alternative for permutation tests. This nonparametric test offers two novel features: first, it incorporates both the directions and magnitude of the deformation vectors. Second, as its distribution function is available in closed form, this test statistic can be used in a clinical setting. Using synthetic data that represents variations as commonly encountered in clinical data, we show that the Moore-Rayleigh test outperforms the classical permutation test.	clinical data;muscle rigidity;non-parametric test;population;rayleigh–ritz method;resampling (statistics);synthetic data	Alize E. H. Scheenstra;Michael Muskulus;Marius Staring;Arn M. J. M. van den Maagdenberg;Sjoerd Verduyn Lunel;Johan H. C. Reiber;Louise van der Weerd;Jouke Dijkstra	2009	Information processing in medical imaging : proceedings of the ... conference	10.1007/978-3-642-02498-6_47	nonparametric statistics;three-dimensional space;computer vision;econometrics;resampling;distribution function;mathematics;statistics;neuroimaging;synthetic data	ML	48.0246393693665	-79.44523078799621	41708
f44509dc9bfeabda844c2321b4c5a48ffa6fb95a	invariant texture segmentation with reduced illumination sensitivity	object recognition;vision ordenador;image processing;illumination;analisis textura;multi channel approach;illumination sensitivity;procesamiento imagen;filtro adaptado;texture segmentation;segmentation;classification;filtro multicanal;traitement image;computer vision;gabor filter;texture analysis;filtre multicanal;feature extraction;multichannel filter;pattern recognition;vision ordinateur;pattern analysis;rotacion;reconnaissance forme;matched filter;reconocimiento patron;classification accuracy;rotation;eclairement;analyse texture;clasificacion;filtre adapte;segmentacion;scale invariance;alumbrado	"""A method for rotation and scale-invariant texture segmentation is proposed, which can also be employed for object recognition based on pattern analysis in noisy images. The segmentation scheme is based on a supervised rotation and scale-invariant texture recognition using multi-channel polar logarithmic Gabor """"lters for feature extraction. The polar logarithmic arrangement works like a Fourier}Mellin descriptor providing orientation and scale invariance. The classi""""cation of the features is carried out by symmetric phase-only matched """"ltering. The classi""""cation accuracy is about 90% at arbitrary rotation angle and for scale factors between 0.25 and 4.0. Rotation angle and scale factor can be determined with high precision by the classi""""cation scheme. Prior to the segmentation, a normalization scheme as preprocessing step is used to reduce illumination gradients, which is also able to treat illumination, edges like shades. 2001 Elsevier Science B.V. All rights reserved."""	chroma subsampling;computation;computer vision;feature extraction;gradient;image scaling;numerical analysis;outline of object recognition;pattern recognition;preprocessor;time complexity	Manfred Bresch;Bedrich J. Hosticka;Olaf Schrey	2001	Signal Processing	10.1016/S0165-1684(00)00225-5	computer vision;image processing;feature extraction;biological classification;rotation;computer science;cognitive neuroscience of visual object recognition;scale invariance;pattern recognition;mathematics;matched filter;scale-space segmentation;segmentation	Vision	45.422856145642655	-60.862027391634676	41715
8872a136642b7c45de906e5f3350d08da8915e31	dirboost: an algorithm for boosting deformable image registration	diagnostic imaging;deformable image registration;computed tomography;ensemble learning;niftyreg registration algorithm deformable image registration boosting algorithm dirboost algorithm hypothesis boosting machine learning image classifier landmark based registration error detection voronoi tessellation dense estimate image registration quality iterative registration ct pulmonary breathhold inspiration scan ct pulmonary breathhold expiration scan;computational geometry;prediction algorithms;image classification;iterative methods;boosting;medical image processing computational geometry computerised tomography image classification image registration iterative methods learning artificial intelligence;machine learning;medical image processing;image registration;pattern recognition deformable image registration boosting ensemble learning;computerised tomography;pattern recognition;voronoi tessellation;boosting image registration algorithm design and analysis prediction algorithms computed tomography medical diagnostic imaging;error detection;learning artificial intelligence;algorithm design;algorithm design and analysis;medical diagnostic imaging	We introduce a novel boosting algorithm to boost - i.e. improve on - existing methods for deformable image registration. The proposed DIRBoost algorithm is inspired by the theory on hypothesis boosting, well-known in the field of machine learning. DIRBoost involves a classifier for landmark-based Registration Error Detection (RED). Based on these RED predictions a Voronoi tessellation is generated to obtain a dense estimate of local image registration quality. All areas predicted as erroneous registration are subjected to boosting, i.e. undergo iterative registrations by employing boosting masks on both the fixed and moving image. We evaluated the DIRBoost algorithm on five CT pulmonary breathhold inspiration and expiration scan pairs, employing the NiftyReg registration algorithm. DIRBoost could boost about 50% of the wrongly registered areas which in turn also improved the average landmark registration error by 24%.	algorithm;boosting (machine learning);image registration;iteration;machine learning;voronoi diagram	Sascha E. A. Muenzing;Bram van Ginneken;Josien P. W. Pluim	2012	2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2012.6235813	algorithm design;computer vision;computational geometry;computer science;machine learning;pattern recognition;mathematics;ensemble learning	Vision	41.62916985049741	-76.44663492640323	41791
d5d020e92c1fe2822dda4d4784be860ab38938c4	atherosclerotic blood vessel tracking and lumen segmentation in topology changes situations of mr image sequences	topology;image motion analysis;decision tree;image segmentation;carotid artery vessel tracking;edge detection;optimal lumen contours;mr image sequences;ultrasonic imaging;optimal lumen contours atherosclerotic blood vessel tracking lumen segmentation topology changes situations mr image sequences carotid artery vessel tracking atherosclerotic plaque active contour model snake magnetic resource image sequences decision tree minimal path snake algorithm mps algorithm;haemodynamics;feature extraction image sequences tracking biomedical mri medical image processing image segmentation blood vessels edge detection image motion analysis haemodynamics;biomedical imaging;active contours;minimal path snake algorithm;blood vessel;carotid arteries;lumen segmentation;blood vessels topology biomedical imaging image segmentation image sequences ultrasonic imaging carotid arteries active contours diseases optical imaging;mr imaging;optical imaging;carotid artery;feature extraction;medical image processing;atherosclerotic blood vessel tracking;diseases;mps algorithm;topology changes situations;atherosclerotic plaque;active contour model snake;blood vessels;active contour model;tracking;biomedical mri;image sequences;magnetic resource image sequences	Carotid artery vessel tracking and lumen segmentation is an important task for atherosclerotic plaque study, where active contour model (SNAKE) has become one of the most powerjfid techniques for this purpose. However, its intrinsic weakness in initialization and topology changes handling limits its application in complicated situations. In this research, we focus our work on atherosclerotic blood vessel tracking and lumen contour segmentation of Magnetic Resource (MR) image sequences, along which the blood vessel bifurcates at indefinite position. To automatically capture this topology change in the processing, a practical solution is proposed by extending our previous research work. The procedure first presegments each MR slice into regions, and then uses decision tree to track blood vessel’s topology change. Finally, Minimal Path Snake (MPS) algorithm is applied to further search optimal lumen contours. Some experimental results in the preliminary study are provided to demonstrate its encouraging per$ormance.	active contour model;algorithm;decision tree	Dongxiang Xu;Jenq-Neng Hwang;Chun Yuan	2000		10.1109/ICIP.2000.901039	medical imaging;computer vision;edge detection;feature extraction;computer science;decision tree;hemodynamics;optical imaging;active contour model;mathematics;tracking;image segmentation	Vision	41.08842391027117	-76.37641446567852	41808
eb03f0ddf6e1dbed41bdc075df8a5c6c136fe276	class-wise two-dimensional pca method for face recognition		Interests in biometric identification systems have led to many face recognition task oriented studies. These studies often address the detection of face images taken from a camera and the recognition of faces via extracted meaningful features. To meet the requirement of defining data with fewer features, Principal Component Analysis (PCA) based techniques are widely used due to their efficiency and simplicity. There is a remarkable interest in the use efficiency of PCA by extending this traditional technique with various aspects. From this viewpoint, this study is specifically focused on the PCA-based face recognition techniques. By enhancing the methods in the reviewed studies, a novel class-wise two-dimensional PCA-based face recognition algorithm is presented in this study. Unlike the traditional method, this method generates more than one subspace considering within-class scattering. A system based on the presented approach can successively detect and recognize faces in not only images but also in video files. In addition, analyzes were conducted to evaluate the efficiency of proposed algorithm and its extension comparing with other addressed PCA-based methods. On the basis of the experiment results, it is clear to say that the presented approach and its extension are superior to the compared PCA-based algorithms.	algorithm;algorithmic efficiency;benchmark (computing);biometrics;computation;database;digital library;experiment;facial recognition system;interval exchange transformation;preprocessor;principal component analysis;real-time clock;real-time locating system;variational principle;video file format	Ceren Guzel Turhan;Hasan S. Bilge	2017	IET Computer Vision	10.1049/iet-cvi.2016.0135	computer vision;mathematics;pattern recognition;facial recognition system;artificial intelligence	AI	34.03180860173583	-59.1226079341109	41873
66fb1aa8427882411c098af5b588dce01fbb64c8	human identification using heartbeat interval features and ecg morphology		This paper presents a novel method to characterize the ECG signal for human identification. The characterization process utilizes the analytical and appearance based techniques to analyze the ECG signal with an aim to make the measurements insensitive to noise and non-signal artifacts. We extract heartbeat interval features and interbeat interval features using analytical based technique and use them as a complementary information with the morphological features that are extracted using appearance based technique for improved identification accuracy. We perform identification using one-to-many comparisons based on match scores that are generated using statistical pattern matching technique. Results demonstrate that the proposed method for automated characterization of the ECG signal is efficiently used in identifying the normal as well as the arrhythmia subjects. In particular, the recognition accuracy for the subjects of MIT-BIH Arrhythmia database is reported to 87.37% whereas the subjects of our IIT(BHU) database are recognized with an accuracy of 92.88%.	mathematical morphology	Yogendra Narain Singh;Sanjay Kumar Singh	2012		10.1007/978-81-322-1038-2_8	heartbeat;interbeat interval;pattern matching;artificial intelligence;computer science;pattern recognition	NLP	28.990619005641552	-64.76067634193909	41891
987eb428c851a0c6203b5464675b4192bdd4b98f	hippocampus temporal lobe epilepsy detection using a combination of shape-based features and spherical harmonics representation		Most of the temporal lobe epilepsy detection approaches are based on hippocampus deformation and use complicated features, resulting, detection is done with complicated features extraction and pre-processing task. In this paper, a new detection method based on shape-based features and spherical harmonics is proposed which can analysis the hippocampus shape anomaly and detection asymmetry. This method consisted of two main parts; (1) shape feature extraction, and (2) image classification. For evaluation, HFH database is used which is publicly available in this field. Nine different geometry and 256 spherical harmonic features are introduced then selected Eighteen of them that detect the asymmetry in hippocampus significantly in a randomly selected subset of the dataset. Then a support vector machine (SVM) classifier was employed to classify the remaining images of the dataset to normal and epileptic images using our selected features. On a dataset of 25 images, 12 images were used for feature extraction and the rest 13 for classification. The results show that the proposed method has accuracy, specificity and sensitivity of, respectively, 84%, 100%, and 80%. Therefore, the proposed approach shows acceptable result and is straightforward also; complicated pre-processing steps were omitted compared to other methods.	acoustic lobing;algorithm;anomaly detection;coefficient;computer vision;feature extraction;preprocessor;randomness;sensitivity and specificity;sensor;support vector machine	Zohreh Kohan;Hamidreza Farhidzadeh;Reza Azmi;Behrouz Gholizadeh	2016	CoRR		computer vision;machine learning;pattern recognition;mathematics	Vision	32.86066222104192	-76.62613141945698	41968
95d349e633594768a948bd48b772edcff6c49353	breast compression parameters among women imaged with full field digital mammography and breast tomosynthesis in breastscreen norway		Text: Breast compression is used in mammography to improve image quality and reduce radiation dose. However, the compression may lead to discomfort or pain for the women. Breast compression time lasts longer for digital breast tomosynthesis (DBT) than for full field digital mammography (FFDM). We aimed to explore breast compression parameters with FFDM and DBT. We included information from 16,832 women participating in the Bergen Tomosynthesis Trial between January 2016 and April 2017. We compared mean values of applied compression force (N), compression pressure (kPa) and compressed breast thickness (mm), for FFDM and DBT, by view (craniocaudal, CC, and mediolateral-oblique, MLO). Two-sample t-tests were used to test statistical significance. Number of women screened with FFDM or DBT were similar (DM: n= 8354 and DBT: n= 8478). Mean compression force was statistically significantly higher for FFDM compared to DBT for CC and MLO view (CC: 108.6 N versus 102.7 N; MLO: 122.4 N versus 120.8 N, p <0.01). Mean compression pressure was higher for FFDM compared to DBT for CC view (13.9 kPa versus 13.0 kPa, p<0.01). For MLO view, no difference in compression pressure was observed (DM and DBT: 9.7 kPa, p= 0.55). Mean compressed breast thickness did not differ statistically significantly for FFDM compared to DBT (CC: 58.7 mm N versus 58.6 mm, p= 0.72; MLO: 60.1 mm versus 59.9 mm, p= 0.23). Radiographers applied statistically significantly less breast compression with DBT compared to FFDM. However, the observed differences were negligible. Further research should investigate the clinical implications of the differences, such as image quality. Can radiologists improve their breast cancer detection in mammography when using a deep learning-based computer system as decision support? Full Author List: A. Rodriguez-Ruiz, Radboud University Medical Center (Netherlands); J. Mordang, Screenpoint Medical BV (Netherlands); N. Karssemeijer, Radboud University Medical Ctr (Netherlands) and Screenpoint Medical BV (Netherlands); I. Sechopoulos, R. Mann, Radboud University Medical Center (Netherlands) Abstract Text: For more than a decade, radiologists have used traditional computer aided detection systems to read mammograms, but mainly because of a low computer specificity may not improve their screening performance, according to several studies. The breakthrough in deep learning techniques has boosted the performance of machine learning algorithms, also for breast cancer detection in mammography. The objective of this study was to determine whether radiologists improve their breast cancer detection performance when they concurrently use a deep learning-based computer system for decision support, compared to when they read mammography unaided. A retrospective, fully-crossed, multi-reader multi-case (MRMC) study was designed to compare this. The employed decision support system was TransparaTM (Screenpoint Medical, Nijmegen, ehe Netherlands). Radiologists interact by clicking an area on the mammogram, for which the computer system displays its cancer likelihood score (1-100). In total, 240 cases (100 cancers, 40 false positive recalls, 100 normals) acquired with two different mammography systems were retrospectively collected. Seven radiologists scored each case once with, and once without the use of decision support, providing a forced BI-RADS® score and a level of suspiciousness (1100). MRMC analysis of variance of the area under the receiver operating characteristic curves (AUC), and specificity and sensitivity were computed. When using decision support, the AUC increased from 0.87 to 0.89 (P=0.043) and specificity increased from 73% to 78% (P=0.030), while sensitivity did not significantly increment (84% to 87%, P=0.180). In conclusion, radiologists significantly improved their performance when using a deep learning-based computer system as decision support.Text: For more than a decade, radiologists have used traditional computer aided detection systems to read mammograms, but mainly because of a low computer specificity may not improve their screening performance, according to several studies. The breakthrough in deep learning techniques has boosted the performance of machine learning algorithms, also for breast cancer detection in mammography. The objective of this study was to determine whether radiologists improve their breast cancer detection performance when they concurrently use a deep learning-based computer system for decision support, compared to when they read mammography unaided. A retrospective, fully-crossed, multi-reader multi-case (MRMC) study was designed to compare this. The employed decision support system was TransparaTM (Screenpoint Medical, Nijmegen, ehe Netherlands). Radiologists interact by clicking an area on the mammogram, for which the computer system displays its cancer likelihood score (1-100). In total, 240 cases (100 cancers, 40 false positive recalls, 100 normals) acquired with two different mammography systems were retrospectively collected. Seven radiologists scored each case once with, and once without the use of decision support, providing a forced BI-RADS® score and a level of suspiciousness (1100). MRMC analysis of variance of the area under the receiver operating characteristic curves (AUC), and specificity and sensitivity were computed. When using decision support, the AUC increased from 0.87 to 0.89 (P=0.043) and specificity increased from 73% to 78% (P=0.030), while sensitivity did not significantly increment (84% to 87%, P=0.180). In conclusion, radiologists significantly improved their performance when using a deep learning-based computer system as decision support. Detection of the abnormal gist in the prior mammograms even with no overt sign of breast cancer Full Author List: Z. Gandomkar, E. U. Ekpo, S. J. Lewis, University of Sydney (Australia); K. K. Evans, University of York (United Kingdom); K. Tapia, P. Trieu, University of Sydney (Australia); J. M. Wolfe, Harvard University (United States); P. C. Brennan, University of Sydney (Australia) Abstract Text: Can radiologists distinguish prior mammograms with no overt signs of cancer from women who were later diagnosed with breast cancer from the prior mammograms of women reported as normal and subsequently confirmed to be cancer-free? Twenty-three radiologists and breast physicians viewed 200 craniocaudial mammograms for a half-second and rated whether the woman would be recalled on a scale of 0 (clearly normal) to 100 (clearly abnormal). The dataset included five categories of mammograms, with each category containing 40 cases. The categories were Cancer (current cancercontaining mammograms), Prior-Vis (prior mammograms with visible cancer signs), Contra (current ‘normal’ mammograms contralateral to the cancer), Prior-Invis (priors without visible cancer signs), and Normal (priors of normal cases). For each radiologist, four pairs of analyses were performed to evaluate whether the radiologists could distinguish mammograms in each category from the normal mammograms: Cancer vs Normal, Prior-Vis vs Normal, Contra vs Normal, and Prior-Invis vs Normal. The Area under Receiver Operating Characteristic curves (AUC) was calculated for each paired grouping and each radiologist. Wilcoxon Signed Rank test showed the AUC values were abovechance for all comparisons: Cancer (z=4.20, P<0.001); Prior-Vis (z=4.11, P<0.001); Contra (z=4.17, P<0.001); Prior-Invis (z=3.71, P<0.001). The results suggest that radiologists can distinguish patients who were diagnosed with cancer from individuals without breast cancer at an above-Text: Can radiologists distinguish prior mammograms with no overt signs of cancer from women who were later diagnosed with breast cancer from the prior mammograms of women reported as normal and subsequently confirmed to be cancer-free? Twenty-three radiologists and breast physicians viewed 200 craniocaudial mammograms for a half-second and rated whether the woman would be recalled on a scale of 0 (clearly normal) to 100 (clearly abnormal). The dataset included five categories of mammograms, with each category containing 40 cases. The categories were Cancer (current cancercontaining mammograms), Prior-Vis (prior mammograms with visible cancer signs), Contra (current ‘normal’ mammograms contralateral to the cancer), Prior-Invis (priors without visible cancer signs), and Normal (priors of normal cases). For each radiologist, four pairs of analyses were performed to evaluate whether the radiologists could distinguish mammograms in each category from the normal mammograms: Cancer vs Normal, Prior-Vis vs Normal, Contra vs Normal, and Prior-Invis vs Normal. The Area under Receiver Operating Characteristic curves (AUC) was calculated for each paired grouping and each radiologist. Wilcoxon Signed Rank test showed the AUC values were abovechance for all comparisons: Cancer (z=4.20, P<0.001); Prior-Vis (z=4.11, P<0.001); Contra (z=4.17, P<0.001); Prior-Invis (z=3.71, P<0.001). The results suggest that radiologists can distinguish patients who were diagnosed with cancer from individuals without breast cancer at an abovechance level based on a half-second glimpse of mammogram even before the lesion becomes apparently visible (Prior-Invis). Apparently, something about the breast parenchyma can look abnormal before the appearance of a localized lesion. Session 2: Deep Learning: Lesion Detection & Classification Automated lesion detection and segmentation in digital mammography using a u-net deep learning network Full Author List: T. de Moor, A. Rodriguez-Ruiz, R. Mann M.D., A.G. Merida, J. Teuwen, Radboud University Medical Center (Netherlands) Abstract Text: Computer-aided detection or decision support systems aim to improve breast cancer screening programs by helping radiologists to evaluate digital mammography (DM) exams. Commonly such methods proceed in two steps: selection of candidate regions for malignancy, and later classification as eit	algorithm;bi-rads;computer;decision support system;deep learning;gist;image quality;machine learning;markov reward model checker;oblique projection;projection screen;radiology;receiver operating characteristic;sensitivity and specificity;thickness (graph theory);tomosynthesis	Gunvor G. Wåde;Åsne Holen;B. Hanestad;S. Sebuødegård;N. Moshina;Kristin Pedersen;Hofvind	2018		10.1117/12.2317918	radiology;tomosynthesis;digital mammography;computer science	HCI	33.332248356870494	-78.40231868977067	41997
68cb9d87bd10f95e9574aec093effdea54778710	robust verification with subsurface fingerprint recognition using full field optical coherence tomography		Fingerprint recognition has been extensively used in numerous civilian applications ranging from border control to everyday identity verification. The threats to current systems emerge from two facts that can be attributed to potential loss in accuracy due to damaged external fingerprints and attacks on the sensors by creation of an artefacts (e.g. silicone finger) simply by lifting the latent fingerprints. In the growing need for attack resistant biometric fingerprint recognition that can be operated without supervision, a new generation of sensors has been investigated, which can capture the subsurface fingerprint pattern. In this work, we explore a subsurface fingerprint imaging technique by employing a custom-built in-house Full-Field Optical Coherent Tomography (FF-OCT) sensor for capturing the subsurface fingerprint. Further, we evaluate a newly constructed database of 200 unique fingerprint samples collected in 2 different sessions with 6 layers of fingerprint images corresponding to 6 subsurface fingerprints. We also propose a framework based on quality metrics to fuse the subsurface fingerprint images to achieve a robust verification accuracy, which has resulted in Equal Error Rate (EER) of 0%. We also provide an extensive set of experiments to gauge the reliability of subsurface fingerprint recognition and deduce a set of important conclusions for the path forward in FFOCT subsurface fingerprint imaging.	acoustic fingerprint;biometrics;coherent;enhanced entity–relationship model;experiment;fingerprint recognition;identity verification service;lifting scheme;sensor;tomography	Kiran B. Raja;Egidijus Auksorius;Ramachandra Raghavendra;A. Claude Boccara;Christoph Busch	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)	10.1109/CVPRW.2017.93	word error rate;pattern recognition;artificial intelligence;computer vision;fingerprint recognition;computer science;fingerprint;optical coherence tomography;biometrics;ranging	Vision	28.198294088157184	-69.02062422492584	42018
3adab5a6d1bb88954dd42df8ad634b9849eedd68	fast anisotropic gauss filtering	algorithme rapide;traitement signal;methode recursive;erreur troncature;evaluation performance;vision ordenador;transformation affine;desviacion tipica;feature detection;performance evaluation;image processing;approximation error;methode echelle multiple;convolution;edge detection;implementation;standard deviation;evaluacion prestacion;metodo recursivo;procesamiento imagen;recursive method;convolucion;metodo escala multiple;recursive filters;filtrage recursif;indexing terms;universiteitsbibliotheek;traitement image;error aproximacion;directional derivative;computer vision;deteccion contorno;etat actuel;ejecucion;detection contour;anisotropic magnetoresistance gaussian processes filters filtering application software convolution computer vision image edge detection finite wordlength effects approximation error;accuracy;gauss filter;precision;scale space;feature extraction;signal processing;affine transformation;fast algorithm;state of the art;poursuite cible;ecart type;convolution filtering theory recursive filters edge detection feature extraction;orientation scale space;truncation error;estado actual;vision ordinateur;multiscale method;filtrado recursivo;extraction caracteristique;orientation scale space analysis anisotropic gaussian decomposition fast anisotropic gauss filtering 1d gauss filter nonorthogonal direction recursive filtering directed derivative filters image filtering standard deviation filter orientation truncation error recursive approximation error anisotropic gaussian filtering method edge maps ridge maps high spatial accuracy high angular accuracy tracking applications anisotropic convolution dashed lines detection engineering drawings feature detection affine invariant edge detection affine invariant ridge detection computer vision computational filtering method;directional filter;target tracking;error truncamiento;procesamiento senal;gaussian derivatives;algoritmo rapido;recursive filtering;filtering theory;transformacion afin	We derive the decomposition of the anisotropic Gaussian in a one-dimensional (1-D) Gauss filter in the x-direction followed by a 1-D filter in a nonorthogonal direction phi. So also the anisotropic Gaussian can be decomposed by dimension. This appears to be extremely efficient from a computing perspective. An implementation scheme for normal convolution and for recursive filtering is proposed. Also directed derivative filters are demonstrated. For the recursive implementation, filtering an 512 x 512 image is performed within 40 msec on a current state of the art PC, gaining over 3 times in performance for a typical filter, independent of the standard deviations and orientation of the filter. Accuracy of the filters is still reasonable when compared to truncation error or recursive approximation error. The anisotropic Gaussian filtering method allows fast calculation of edge and ridge maps, with high spatial and angular accuracy. For tracking applications, the normal anisotropic convolution scheme is more advantageous, with applications in the detection of dashed lines in engineering drawings. The recursive implementation is more attractive in feature detection applications, for instance in affine invariant edge and ridge detection in computer vision. The proposed computational filtering method enables the practical applicability of orientation scale-space analysis.	angularjs;approximation error;computation (action);computational technique;computer vision;convolution;direction finding;drawings (art);engineering drawing;feature detection (computer vision);feature detection (web development);gauss;gaussian blur;map;normal statistical distribution;protein truncation abnormality;recursion (computer science);ridge detection;scale space;truncation error	Jan-Mark Geusebroek;Arnold W. M. Smeulders;Joost van de Weijer	2003	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/TIP.2003.812429	computer vision;mathematical optimization;image processing;computer science;signal processing;mathematics;geometry;accuracy and precision;statistics	Vision	49.8190249278984	-60.74233592220136	42048
29ed61ee4d88984ad213a2df7e00d1907d7698c6	an experimental investigation on self adaptive facial recognition algorithms using a long time span data set	adaptive systems;lighting;face;principal component analysis;face recognition;videos	Nowadays, facial authentication systems are present in many daily life devices. Their performance is influenced by the appearance of the facial trait that changes according to many factors such as lighting, pose, variations over time and obstructions. Adaptive systems follow these variations by updating themselves through images acquired during system operations. Although the literature proposes many possible approaches, their evaluation is often left to data set not explicitly conceived to simulate a real application scenario. The substantial absence of an appropriate and objective evaluation set is probably the motivation of the lack of implementation of adaptive systems in real devices. This paper presents a facial dataset acquired by videos in the YouTube platform. The collected images are particularly suitable for evaluating adaptive systems as they contain many changes during the time-sequence. A set of experiments of the most representative self adaptive approaches recently appeared in the literature is also performed and discussed. They allow to give some initial insights about pros and cons of facial adaptive authentication systems by considering a medium-long term time window of the investigated systems performance.		Giulia Orrù;Gian Luca Marcialis;Fabio Roli	2018	2018 Eighth International Conference on Image Processing Theory, Tools and Applications (IPTA)	10.1109/IPTA.2018.8608134	principal component analysis;pattern recognition;facial recognition system;artificial intelligence;term (time);machine learning;adaptive system;trait;computer science;authentication	Visualization	28.25239824317268	-60.76994228914906	42091
8bb7e1caaf8ce3a84d94f9ff4094747525abab1e	a fast anchor shot detection algorithm on compressed video	algorithme rapide;audio visual systems;systeme audiovisuel;fast anchor shot detection;compression image;image compression;fast algorithm;produccion video;detection algorithm;video production;mpeg;production video;algoritmo rapido;compressed video;compresion imagen	Detecting anchor shots accurately is very important for automatically parsing news video and extracting news items. The paper presents a fast anchor shot detection algorithm, based on background chrominance and skin tone models. The algorithm involves only simple computation, but robust. Moreover it operates in MPEG compression domain, which makes the detection speed very fast. The algorithm was evaluated on a big test set containing more than 480000 frames and news video from two different TV stations. More than 98.9% accuracy and 100% recall have been obtained. The experiment results also show the system has an average detection speed of 77.55 f/s. The statistics indicates the algorithm is fast and effective.	algorithm;closed-circuit television;computation;computer performance;consistency model;moving picture experts group;parsing;robustness (computer science);shot transition detection;tv tuner card;test set	Weiqiang Wang;Wen Gao	2001		10.1007/3-540-45453-5_114	video compression picture types;computer vision;video production;image compression;computer science;video tracking;block-matching algorithm;multimedia;algorithm;multiview video coding;computer graphics (images)	Vision	45.29304818932933	-57.06016356555226	42092
ca3e1fa7253959e2471503787fb4cf7d4dfd4f2e	an improved method to reduce over-segmentation of watershed transformation and its application in the contour extraction of brain image	image segmentation;magnetic resonance image;watershed transform;multi scale alternating sequential filtering by reconstruction;medical image;feature extraction;image reconstruction;medical image processing;contour extraction;over segmentation watershed transformation h minima multi scale alternating sequential filtering by reconstruction contour extraction;mri brain image watershed transformation segmentation brain image contour extraction image segmentation medical image segmentation magnetic resonance imaging multiscale alternating sequential filtering noise elimination image reconstruction h minima minima imposition local minima watershed algorithm;brain imaging;medical image processing biomedical mri feature extraction image reconstruction image segmentation;over segmentation;medical image segmentation;local minima;brain magnetic resonance imaging image segmentation biomedical imaging data mining information filtering information filters magnetic separation image reconstruction magnetic noise;h minima;biomedical mri;watershed transformation	Watershed transformation is a common technique for image segmentation. However, its use for medical image segmentation has been limited particularly due to over-segmentation. In response to the characteristics of medical image, especially the contour extraction from the MRI (Magnetic Resonance Imaging) brain image, this paper proposes an improved method in order to overcome the drawbacks. Firstly, multi-scale alternating sequential filtering by reconstruction is introduced to eliminate the noise and simplify the input images, and the loss of boundary information can be avoided. Secondly, two methods of h-minima and minima imposition are imposed on the gradient image to mark the minima regions, so all its local minima are suppressed. Finally, the watershed algorithm is applied to the marked gradient images to get the contour of brain. Experimental results show that the improved method can be applied to contour extraction of MRI brain image with good result, and the mean reduction of local minima in the over-segmented image of regions is 68.26% compared to the watershed transformation based on mark extraction.	algorithm;contour line;gradient;image segmentation;maxima and minima;resonance;watershed (image processing)	Hui Zhu;Bofeng Zhang;Anping Song;Wu Zhang	2009	2009 Eighth IEEE International Conference on Dependable, Autonomic and Secure Computing	10.1109/DASC.2009.116	iterative reconstruction;computer vision;watershed;feature extraction;computer science;magnetic resonance imaging;machine learning;maxima and minima;pattern recognition;image segmentation;neuroimaging	Vision	45.24412900232547	-73.67630352760368	42132
9b815802ba4fc5f3e5d23a02b6b0e5e80b81ca8a	face recognition for video indexing: randomization of face templates improves robustness to facial expression	reconnaissance visage;mimica;acoplamiento grafo;base donnee;random perturbation;facies;mimique;database;base dato;probabilistic approach;high strain;graph matching;grande deformation;video indexing;aleatorizacion;couplage graphe;face recognition;senal video;signal video;indexing;enfoque probabilista;approche probabiliste;robustesse;indexation;image sequence;indizacion;pattern recognition;randomisation;video signal;robustness;secuencia imagen;reconnaissance forme;gran deformacion;facial expression;reconocimiento patron;randomization;sequence image;robustez	Face recognition systems based on elastic graph matching work by comparing the positions and image neighborhoods of a number of detected feature points on faces in input images with those in a database of pre-registered face templates. Such systems can absorb a degree of deformation of input faces due for example to facial expression, but may generate recognition errors if the deformation becomes significantly large. We show that, somewhat counter-intuitively, robustness to facial expressions can be increased by applying random perturbations to the positions of feature points in the database of face templates. We present experimental results on video sequences of people smiling and talking, and discuss the probable origin of the observed effect.		Simon Clippingdale;Mahito Fujii	2003		10.1007/978-3-540-39798-4_7	randomization;facial recognition system;computer vision;search engine indexing;speech recognition;facies;computer science;artificial intelligence;machine learning;pattern recognition;three-dimensional face recognition;database;programming language;facial expression;face hallucination;robustness;matching	Vision	43.0371240855021	-60.45731960245675	42149
4e2c7fe486bf6a613b3a573365a98c53b238824e	separating style and content with bilinear models	lettre alphabet;learning algorithm;efficient algorithm;computer model;singular value decomposition;algorithme apprentissage;systeme bilineaire;expectation maximization;bilinear system;letra alfabeto;reseau neuronal;letter;algoritmo aprendizaje;red neuronal;sistema bilineal;neural network	Perceptual systems routinely separate content from style, classifying familiar words spoken in an unfamiliar accent, identifying a font or handwriting style across letters, or recognizing a familiar face or object seen under unfamiliar viewing conditions. Yet a general and tractable computational model of this ability to untangle the underlying factors of perceptual observations remains elusive (Hofstadter, 1985). Existing factor models (Mardia, Kent, & Bibby, 1979; Hinton & Zemel, 1994; Ghahramani, 1995; Bell & Sejnowski, 1995; Hinton, Dayan, Frey, & Neal, 1995; Dayan, Hinton, Neal, & Zemel, 1995; Hinton & Ghahramani, 1997) are either insufficiently rich to capture the complex interactions of perceptually meaningful factors such as phoneme and speaker accent or letter and font, or do not allow efficient learning algorithms. We present a general framework for learning to solve two-factor tasks using bilinear models, which provide sufficiently expressive representations of factor interactions but can nonetheless be fit to data using efficient algorithms based on the singular value decomposition and expectation-maximization. We report promising results on three different tasks in three different perceptual domains: spoken vowel classification with a benchmark multi-speaker database, extrapolation of fonts to unseen letters, and translation of faces to novel illuminants.	approximation algorithm;benchmark (computing);bilinear filtering;bilinear transform;brain;classification;cobham's thesis;computational model;decision problem;electron microscopy;engineering;expectation–maximization algorithm;extrapolation;face;hofstadter's law;interaction;machine learning;multi-factor authentication;numerous;orthographic projection;phoneme;photometric stereo;shading;singular value decomposition;solutions;speech disorders;speech recognition;structure from motion;tomasi–kanade factorization;utility	Joshua B. Tenenbaum;William T. Freeman	2000	Neural Computation	10.1162/089976600300015349	psychology;speech recognition;letter;expectation–maximization algorithm;computer science;artificial intelligence;machine learning;mathematics;communication;singular value decomposition;artificial neural network;statistics	ML	45.80874269352379	-56.735708971938124	42153
1074bdd8d4c42591401899d6f600ae922a3e1c99	gesture recognition using quadratic curves	hand;calcul matriciel;modelizacion;duracion;vision ordenador;trajectoire;reconnaissance geste;piel;image processing;algorithme glouton;peau;surveillance;technology;gesture;computer science artificial intelligence;skin;database;procesamiento imagen;base dato;traitement image;duration;computer vision;modelisation;feature vector;skin color;integral curvilinea;matrix computation;trajectory;science technology;base de donnees;mano;greedy algorithm;invariante;algoritmo gloton;vision ordinateur;trayectoria;matrix calculus;computer science;main;curvilinear integral;modeling;computer science theory methods;geste;gesture recognition;invariant;calculo de matrices;integrale curviligne;duree;gesto	This paper presents a novel method for human gesture recognition based on quadratic curves. Firstly, face and hands in the images are extracted by skin color and their central points are kept tracked by a modified Greedy Exchange algorithm. Then in each trajectory, the central points are fitted into a quadratic curve and 6 invariants from this quadratic curve are computed. Following these computations, a gesture feature vector composed of 6n such invariants is constructed, where n is the number of the trajectories in this gesture. Lastly, the gesture models are learnt from the feature vectors of gesture samples and an input gesture is recognized by comparing its feature vector with those of gesture models. In this gesture recognition method, the computational cost is low because the gesture duration does not need to be considered and only simple curvilinear integral and matrix computation are involved. Experiments on hip-hop dance show that our method can achieve a recognition rate as high as 97.65% on a database of 16 different gestures, each performed by 8 different people for 8 different times.	computation;computational complexity theory;experiment;feature vector;gesture recognition;greedy algorithm;invariant (computer science);numerical linear algebra;quadratic function	Qiulei Dong;Yihong Wu;Zhanyi Hu	2006		10.1007/11612032_82	computer vision;greedy algorithm;speech recognition;feature vector;image processing;matrix calculus;computer science;artificial intelligence;trajectory;machine learning;invariant;duration;gesture recognition;skin;gesture;technology	Vision	45.34148572870806	-58.829065731651795	42175
8073551045611488bfb11a9bc1826ccd0cf8eca3	synthesized images for pattern recognition	relative position;trazado rayos;image recognition;reconocimiento imagen;image processing;illumination;reutilizacion;texture mapping;trace rayon;reuse;sintesis imagen;image synthesis;setup time;light intensity;ray tracing;reconnaissance image;pattern recognition;fractal;synthese image;reconnaissance forme;reconocimiento patron;pavement distress;eclairement;reutilisation;alumbrado	Abstract   Since there is no generic procedure for machine pattern recognition due to its complexity,  ad hoc  computer algorithms have been developed for each class of problems. In visual pattern recognition, depending on the area of investigation, it is difficult to obtain test images with the desired characteristics. Capturing the original images in the first place may require special and/or expensive equipment, setups, timing, lighting conditions, relocation of equipment and personnel. Due to these difficulties, researchers often reuse the same few available test images, which may compromise the thoroughness of the investigation. Also, when existing images need major changes in optical parameters (viewpoint, illumination, relative position of objects) the original environment and objects may not be available. This paper proposes generating graphic images by computer with characteristics close enough to reality for testing new pattern recognition algorithms. For demonstration of the idea, we use the graphics resources: ray tracing, fractals, texture-mapping and smooth surfaces, such as spheres and Bezier patches. Two illustrative examples are presented: (1) Moire patterns by placing a cylinder array over a Bezier patch and sphere; (2) pavement distress images (cracks and potholes) from fractal backbone lines. At a relatively low cost, the image is synthesized in the form of a light intensity map file, which can be readily input to the pattern recognition algorithms under investigation. After an algorithm produces acceptable results using synthesized images, then we can validate it by capturing real images under the combination of parameters chosen in the previous step. In order to reduce costs, the field setup parameters may be decided from the best simulation settings. The proposed approach to the development of algorithms for pattern recognition will save time, money and resources at research sites where quality graphics can be rendered.	pattern recognition	Mario Miyojim;Heng-Da Cheng	1995	Pattern Recognition	10.1016/0031-3203(94)00123-4	texture mapping;ray tracing;computer vision;simulation;fractal;image processing;computer science;machine learning;reuse;algorithm;computer graphics (images)	Vision	47.88261542059214	-58.53767462122691	42183
2c375f93c0d0db944ea3ee5e5b4428c5b647f3fa	automatic body segmentation with graph cut and self-adaptive initialization level set (sails)	motion estimation and compensation;body segmentation;level set;background contrast removal;motion estimation;object segmentation;graph cut;human body;face detection;object detection	1047-3203/$ see front matter 2011 Elsevier Inc. A doi:10.1016/j.jvcir.2011.03.003 ⇑ Corresponding author. E-mail address: qliu@ee.cuhk.edu.hk (Q. Liu). In this paper, we propose an automatic human body segmentation system which mainly consists of human body detection and object segmentation. Firstly, an automatic human body detector is designed to provide hard constraints on the object and background for segmentation. And a coarse-to-fine segmentation strategy is employed to deal with the situation of partly detected object. Secondly, background contrast removal (BCR) and self-adaptive initialization level set (SAILS) are proposed to solve the tough segmentation problems of the high contrast at object boundary and/or similar colors existing in the object and background. Finally, an object updating scheme is proposed to detect and segment new object when it appears in the scene. Experimental results demonstrate that our body segmentation system works very well in the live video and standard sequences with complex background. 2011 Elsevier Inc. All rights reserved.	algorithm;binding corporate rules;color;cut (graph theory);graph cuts in computer vision;real-time clock;whole earth 'lectronic link	Qiang Liu;Hongliang Li;King Ngi Ngan	2011	J. Visual Communication and Image Representation	10.1016/j.jvcir.2011.03.003	computer vision;face detection;human body;cut;computer science;level set;viola–jones object detection framework;machine learning;segmentation-based object categorization;pattern recognition;motion estimation;mathematics;image segmentation;scale-space segmentation;segmentation	Vision	44.89410193513735	-65.50364981768415	42213
7c7f0e1d1bcc8c4cb02771b481c9db78c655d3de	3d tubular structure extraction using kernel-based superellipsoid model with gaussian process regression	gaussian processes;kernel gaussian processes solid modeling nerve fibers electron tubes shape noise;gaussian process 3d tubular structure extraction superellipsoid model nonlinear prediction;feature extraction;stereo image processing;tracking energy 3d tubular structure extraction kernel based superellipsoid model gaussian process regression centerline record robust and automated technique;regression analysis;stereo image processing feature extraction gaussian processes regression analysis	To analyze the tubular structure correctly and obtain a record of the centerlines has become significantly more challenging and infers countless applications in a large amount of fields. Hence, a robust and automated technique for extracting the centerlines of the tubular structure is required. To address complicated 3D tubular objects, a novel kernel-based modeling approach with regard to minimizing tracking energy is presented in this paper. The 3D tubular structure can be demonstrated as a kernel-based superellipsoid model with non-uniform weights. To improve the performance, Gaussian process is also introduced to update the parameters of the kernel-based model, especially for the complicated structure with cross sections, varying radii, and complicated branches. At last, the extensive experimental results on 3D tubular data demonstrate that our proposed method deals effectively with complicated tubular structure.	cross section (geometry);gaussian process;kernel (operating system);kriging;superellipsoid	Qingxiang Zhu;Dayu Zheng;Hongkai Xiong	2012	2012 Visual Communications and Image Processing	10.1109/VCIP.2012.6410763	feature extraction;computer science;machine learning;pattern recognition;gaussian process;mathematics;regression analysis;statistics	ML	44.56545869160994	-76.43271206810383	42263
ce4a6412da4178b2038b465438df6fb62456e0dc	recognition of scenery images considering positional relation using fuzzy inference neural networks	image recognition;fuzzy neural nets;image segmentation;neural networks;learning;fuzzy inference neural network;application software;color;rule extraction;inference mechanisms;regional segmentation;data mining;image segmentation image recognition fuzzy neural nets inference mechanisms learning artificial intelligence;regions;fuzzy;pixel;computer science;neural network image recognition rule extraction fuzzy inference neural network scenery images learning regional segmentation;learning artificial intelligence;fuzzy neural networks;scenery images;neural network;image recognition fuzzy neural networks neural networks image segmentation data mining regions pixel color computer science application software	In this paper, we propose a new system for recognition of scenery images, by learning. The proposed system consists of 2 parts. One is the part which infers based on absolute position of target. The other is the part which infers based on relative position of target. Each part consists of Fuzzy Inference Neural Network (FINN) which can extract fuzzy if-then rules automatically. So the system can extract knowledge about absolute position and relative position. Through computer experiments, it can be seen that the proposed system can recognize the image much correctly.	neural networks	Atsushi Yamamura;Masafumi Hagiwara	2001		10.1109/ICSMC.2001.973084	fuzzy logic;computer vision;application software;adaptive neuro fuzzy inference system;computer science;machine learning;pattern recognition;image segmentation;artificial neural network;pixel	NLP	33.12513363494565	-68.82511437141395	42279
56a20b31fb0b3663e593aea71e1e2b64e5db1ecb	particle detection in crowd regions using cumulative score of cnn		In recent years, convolutional neural network gave the state-of-the-art performance on various image recognition benchmarks. Although CNN requires a large number of training images including various locations and sizes of a target, we cannot prepare a lot of supervised intracellular images. In addition, the properties of intracellular images are different from standard images used in computer vision researches. Overlap between particles often occurred in dense regions. In overlapping area, there are ambiguous edges at the peripheral region of particles. This induces the detection error by the conventional method. However, all edges of overlapping particles are not ambiguous. We should use the obvious peripheral edges. Thus, we try to predict the center of a particle from the peripheral regions by CNN, and the prediction results are voted. Since the particle center is predicted from peripheral views, we can prepare many training samples from one particle. High accuracy is obtained in comparison with the conventional binary detector using CNN as a binary classifier.		Kenshiro Nishida;Kazuhiro Hotta	2016		10.1007/978-3-319-50832-0_55	computer vision;simulation	Vision	31.124102068433043	-71.67729411368869	42287
b424ae73424d688ca98cb37ca9db8c0b9f9f2fa4	data-driven brain mri segmentation supported on edge confidence and a priori tissue information	nonparametric density estimation;biological tissues;brain;white matter;image segmentation;nonparametric estimation;brain mri;edge detection;mean shift;magnetic resonance imaging image segmentation image edge detection brain neuroimaging pattern recognition maximum likelihood estimation stability convergence noise robustness;magnetic resonance image;region segmentation;medical image processing;gray matter;nonparametric estimation brain mri edge detection image segmentation mean shift;white matter data driven brain mri segmentation brain magnetic resonance imaging edge confidence map a priori tissue information nonparametric density estimation cerebral tissue standard probability maps region segmentation edge detection tanimoto indexes gray matter;biological tissues brain biomedical mri medical image processing image segmentation edge detection;synthetic data;algorithms artificial intelligence brain computer simulation databases factual image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval magnetic resonance imaging models biological pattern recognition automated reproducibility of results sensitivity and specificity subtraction technique;biomedical mri	Brain magnetic resonance imaging segmentation is accomplished in this work by applying nonparametric density estimation, using the mean shift algorithm in the joint spatial-range domain. The quality of the class boundaries is improved by including an edge confidence map, that represents the confidence of truly being in the presence of a border between adjacent regions; an adjacency graph is then constructed with the labeled regions, and analyzed and pruned to merge adjacent regions. In order to assign image regions to a cerebral tissue type, a spatial normalization between image data and standard probability maps is carried out, so that for each structure a maximum a posteriori probability criterion is applied. The method was applied to synthetic and real images, keeping all parameters constant throughout the process for each type of data. The combination of region segmentation and edge detection proved to be a robust technique, as adequate clusters were automatically identified, regardless of the noise level and bias. In a comparison with reference segmentations, average Tanimoto indexes of 0.90-0.99 were obtained for synthetic data and of 0.59-0.99 for real data, considering gray matter, white matter, and background.	edge detection;graph - visual representation;gray matter;histocompatibility testing;jaccard index;magnetic resonance imaging;map;mean shift;noise (electronics);segmentation action;synthetic data;synthetic intelligence;tracer;white matter;algorithm;biologic segmentation	J. R. Jimenez-Alaniz;Verónica Médina-Bañuelos;Oscar Yáñez-Suárez	2006	IEEE Transactions on Medical Imaging	10.1109/TMI.2005.860999	computer vision;edge detection;mean-shift;computer science;magnetic resonance imaging;machine learning;pattern recognition;image segmentation;synthetic data	Vision	42.57113825735736	-76.20430610240918	42302
8ceb4f3240631588f2c71f4edcf89dc3b05ae9c6	shallow vs deep learning architectures for white matter lesion segmentation in the early stages of multiple sclerosis		In this work, we present a comparison of a shallow and a deep learning architecture for the automated segmentation of white matter lesions in MR images of multiple sclerosis patients. In particular, we train and test both methods on early stage disease patients, to verify their performance in challenging conditions, more similar to a clinical setting than what is typically provided in multiple sclerosis segmentation challenges. Furthermore, we evaluate a prototype naive combination of the two methods, which refines the final segmentation. All methods were trained on 32 patients, and the evaluation was performed on a pure test set of 73 cases. Results show low lesion-wise false positives (30%) for the deep learning architecture, whereas the shallow architecture yields the best Dice coefficient (63%) and volume difference (19%). Combining both shallow and deep architectures further improves the lesion-wise metrics (69% and 26% lesion-wise true and false positive rate, respectively).	coefficient of determination;deep learning;prototype;sørensen–dice coefficient;test set	Francesco La Rosa;Mário João Fartaria;Tobias Kober;Jonas Richiardi;Cristina Granziera;Jean-Philippe Thiran;Meritxell Bach Cuadra	2018	CoRR		machine learning;sørensen–dice coefficient;white matter;false positive rate;architecture;deep learning;false positive paradox;artificial intelligence;mathematics;hyperintensity;test set	ML	31.359041964719665	-76.14469304759014	42358
5d9f0fb0e82268a66fedae6ab82a5cff15a11d4a	an unsupervised network for fast microscopic image registration		At present, deep learning is widely used and has achieved excellent results in many fields except in the field of image registration, the reasons are two-fold: Firstly all the steps of deep learning should be derivable; nevertheless, the nonlinear deformation which is usually used in registration algorithms is hard to be depicted by explicit function. Secondly, success of deep learning is based on a large amount of labeled data, this is problematic for the application in real scenes. To address these concerns, we propose an unsupervised network for image registration. In order to integrate registration process into deep learning, image deformation is achieved by resampling, which can make deformation step derivable. The network optimizes its parameters directly by minimizing the loss between registered image and reference image without ground truth. To further improve algorithmu0027s accuracy and speed, we incorporate coarse-to-fine multi-scale iterative scheme. We apply our method to register microscopic section images of neuron tissue. Compared with highly fine-tuning method sift flow, our method achieves similar accuracy with much less time.	image registration	Chang Shu;Xi Chen;Qiwei Xie;Hua Han	2018		10.1117/12.2293264	convolutional neural network;computer vision;unsupervised learning;resampling;deep learning;ground truth;image registration;scale-invariant feature transform;nonlinear system;artificial intelligence;computer science	Vision	28.499403999637558	-53.26907786144412	42395
9faace197801edfd11888d811c2c6d9d2daf0ff9	implementation of mfcc based hand gesture recognition on hoap-2 using webots platform	euclidean distance indian sign language mfcc;mel frequency cepstral coefficient gesture recognition robots lighting feature extraction histograms assistive technology;sign language recognition cepstral analysis humanoid robots image classification robot vision;mfcc minimum distance classifier skig dataset sheffield kinect gesture isl gestures indian sign language computer vision webot platform hoap 2 robot hand gesture recognition mel frequency ceptral coefficients	Hand gestures are the only means of communication and interaction for hearing impaired. This paper proposed a computer vision based technique to identify hand gestures from library of Indian Sign Language (ISL) gestures and Sheffield Kinect Gesture (SKIG) Dataset. Mel Frequency Ceptral Coefficients (MFCC) is used as feature vector due to its high quality of discriminating power in different classes. Minimum distance classifier (Euclidean distance metric) is used for classification of different gestures of a same person in two different lighting conditions, yellow light and white light as well as on SKIG data set. Performance of the proposed technique is evaluated on ten types of ISL gestures (5 are dynamic and 5 are static gestures) and five types of SKIG Kinect gestures and compared with the existing techniques which are also performed on SKIG gesture dataset and ISL dataset. Comparative analysis of our proposed method is performed with the existing method. Performance analysis of our proposed method shows better results than the orientation histogram based technique. Here ISL gestures are simulated on HOAP-2 Robot in Webots platform, for establishing interaction between robot and human.	computer vision;display resolution;euclidean distance;feature vector;gesture recognition;hoap;kinect;robot;isl	Neha Baranwal;Neha Singh;Gora Chand Nandi	2014	2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2014.6968332	computer vision;speech recognition;computer science	Robotics	32.18040131525364	-58.90085459411917	42407
51b70582fb0d536d4a235f91bf6ad382f29e2601	detection of emotions from video in non-controlled environment. (détection des émotions à partir de vidéos dans un environnement non contrôlé)		Communication in any form i.e. verbal or non-verbal is vital to complete various daily routine tasks and plays a significant role in life. Facial expression is the most effective form of non-verbal communication and it provides a clue about emotional state, mindset and intention. Generally automatic facial expression recognition framework consists of three step: face tracking, feature extraction and expression classification. In order to built robust facial expression recognition framework that is capable of producing reliable results, it is necessary to extract features (from the appropriate facial regions) that have strong discriminative abilities. Recently different methods for automatic facial expression recognition have been proposed, but invariably they all are computationally expensive and spend computational time on whole face image or divides the facial image based on some mathematical or geometrical heuristic for features extraction. None of them take inspiration from the human visual system in completing the same task. In this research thesis we took inspiration from the human visual system in order to find from where (facial region) to extract features. We argue that the task of expression analysis and recognition could be done in more conducive manner, if only some regions are selected for further processing (i.e. salient regions) as it happens in human visual system. In this research thesis we have proposed different frameworks for automatic recognition of expressions, all getting inspiration from the human vision. Every subsequently proposed addresses the shortcomings of the previously proposed framework. Our proposed frameworks in general, achieve results that exceeds state-of-the-art methods for expression recognition. Secondly, they are computationally efficient and simple as they process only perceptually salient region(s) of face for feature extraction. By processing only perceptually salient region(s) of the face, reduction in feature vector dimensionality and reduction in computational time for feature extraction is achieved. Thus making them suitable for real-time applications.	algorithmic efficiency;analysis of algorithms;bibliothèque de l'école des chartes;computation;feature extraction;feature vector;heuristic;human visual system model;real-time clock;real-time computing;time complexity	Rizwan Ahmed Khan	2013				Vision	36.68275501088951	-52.41569697959985	42437
cbf4d4b9e05e27faa357f66df4292abd9aeb2313	multiresolution approach for multiple human detection using moments and local binary patterns	multi resolution analysis;multiple human detection;moments;gray scale invariant;local binary patterns;support vector machine	Human detection is a central problem in development of any surveillance application. In this study, we present a simple and efficient, multi-resolution gray scale invariant approach for multiple human detection. The multiresolution is important for objects of different size and gray scale invariance is important due to uneven illumination and within-class variability. The proposed method is based on integration of central moments upon multi-resolution gray scale invariant local binary patterns operator. Since, the local binary patterns operator is invariant against different resolutions of space scale and monotonic change in gray scale, therefore the proposed method is robust in terms of variations in space scale as well as gray scale. Another advantage is high computational accuracy of the method due to use of moment operator which enhances the efficiency of the proposed method. Moreover, the proposed method is simple, as these operations can be performed within a few steps in a small neighborhood and a lookup table. The proposed method is tested on multiple human images and experimentally found appropriate for multiple human detection. The proposed method has been evaluated over two datasets, one is our own created dataset and the other is standard INRIA human detection dataset. Experimental results obtained from the proposed method demonstrate that better discrimination can be achieved for human and non-human objects in real scenes.	belief propagation;computation;experiment;feature vector;gradient;grayscale;histogram of oriented gradients;illumination (image);image moment;local binary patterns;lookup table;multiresolution analysis;robustness (computer science);sensor;spatial variability	Swati Nigam;Ashish Khare	2014	Multimedia Tools and Applications	10.1007/s11042-014-1951-0	support vector machine;computer vision;local binary patterns;computer science;machine learning;data mining;moment;statistics	Vision	39.78208416271691	-55.48729623330627	42450
169731093e6b1a5ca51805a876011a9c250f11cb	skin injury model classification based on shape vector analysis	sensitivity and specificity;imaging three dimensional;skin;image enhancement;image interpretation computer assisted;imaging radiology;reproducibility of results;phantoms imaging;algorithms;pattern recognition automated;humans	BACKGROUND Skin injuries can be crucial in judicial decision making. Forensic experts base their classification on subjective opinions. This study investigates whether known classes of simulated skin injuries are correctly classified statistically based on 3D surface models and derived numerical shape descriptors.   METHODS Skin injury surface characteristics are simulated with plasticine. Six injury classes - abrasions, incised wounds, gunshot entry wounds, smooth and textured strangulation marks as well as patterned injuries - with 18 instances each are used for a k-fold cross validation with six partitions. Deformed plasticine models are captured with a 3D surface scanner. Mean curvature is estimated for each polygon surface vertex. Subsequently, distance distributions and derived aspect ratios, convex hulls, concentric spheres, hyperbolic points and Fourier transforms are used to generate 1284-dimensional shape vectors. Subsequent descriptor reduction maximizing SNR (signal-to-noise ratio) result in an average of 41 descriptors (varying across k-folds). With non-normal multivariate distribution of heteroskedastic data, requirements for LDA (linear discriminant analysis) are not met. Thus, shrinkage parameters of RDA (regularized discriminant analysis) are optimized yielding a best performance with λ = 0.99 and γ = 0.001.   RESULTS Receiver Operating Characteristic of a descriptive RDA yields an ideal Area Under the Curve of 1.0 for all six categories. Predictive RDA results in an average CRR (correct recognition rate) of 97,22% under a 6 partition k-fold. Adding uniform noise within the range of one standard deviation degrades the average CRR to 71,3%.   CONCLUSIONS Digitized 3D surface shape data can be used to automatically classify idealized shape models of simulated skin injuries. Deriving some well established descriptors such as histograms, saddle shape of hyperbolic points or convex hulls with subsequent reduction of dimensionality while maximizing SNR seem to work well for the data at hand, as predictive RDA results in CRR of 97,22%. Objective basis for discrimination of non-overlapping hypotheses or categories are a major issue in medicolegal skin injury analysis and that is where this method appears to be strong. Technical surface quality is important in that adding noise clearly degrades CRR.   TRIAL REGISTRATION This study does not cover the results of a controlled health care intervention as only plasticine was used. Thus, there was no trial registration.	anterior descending branch of left coronary artery;categories;class;classification;cross infection;cross-validation (statistics);cumulative trauma disorders;death by strangulation;decision making;dermatologic disorders;description;gunshot wound;health care;hypothalamic area, lateral;linear discriminant analysis;numerical analysis;receiver operating characteristic;recommended daily allowances;remote database access;requirement;scanner device component;signal-to-noise ratio;standard deviation;vertex;wounds, stab;plasticine;representational difference analysis;skin injury	Emil Röhrich;Michael Thali;Wolf Schweitzer	2012		10.1186/1471-2342-12-32	computer vision;simulation;pathology;skin;algorithm;statistics	Vision	33.33776929167913	-79.52143102807172	42478
b1c8feeac5a957ab8442616bba2d987b72668d47	implementation of multimodal biometrics recognition system combined palm print and palm geometry features	palm geometry;image recognition;palm print;biometric feature;false reject rate;knowledge based system;image processing technique;biometrics access control;multimodal biometrics recognition system;scoring fusion recognition system multimodal palm print palm geometry;object detection biometrics access control feature extraction image recognition;geometry;iris recognition;testing;line detection;16 point marker;palm print features;recognition system;scoring fusion;false acceptance rate;feature extraction geometry knowledge based systems iris recognition testing fingers;feature extraction;fingers;genuine acceptance rate;multimodal;palm geometry features;image processing techniques;false rejection rate;50 50 scoring fusion mechanism;knowledge based systems;false accept rate;object detection;genuine acceptance rate multimodal biometrics recognition system palm print features palm geometry features biometric feature image processing technique 16 point marker line detection palm roi 50 50 scoring fusion mechanism false rejection rate false acceptance rate;palm roi	The study of biometric for recognition system has been extensively evolved because this system has many advantages compared to conventional system. Palm geometry is one example of biometric feature that able to used for determine/recognize people. It say that each people have a unique feature of palm geometry that able to distinguish between one person which another.	biometrics;multimodal interaction;palm print	Yanuar Adhinagara;B. W. Tjokorda Agung;Dayawati Retno Novi	2011	Proceedings of the 2011 International Conference on Electrical Engineering and Informatics	10.1109/ICEEI.2011.6021546	computer vision;speech recognition;feature extraction;computer science;engineering;artificial intelligence;knowledge-based systems;multimodal interaction;pattern recognition;iris recognition;software testing	Robotics	32.83304418515821	-62.465015803168704	42505
088fa67861cb8914c1b7ca74708e5f2da6c1c8b2	classification of smri for alzheimer's disease diagnosis with cnn: single siamese networks with 2d+? approach and fusion on adni		The methods of Content-Based visual information indexing and retrieval penetrate into Healthcare and become popular in Computer-Aided Diagnostics. The PhD research we have started 13 months ago is devoted to the multimodal classification of MRI brain scans for Alzheimer Disease diagnostics. We use the winner classifier, such as CNN. We first proposed an original 2D+ approach. It avoids heavy volumetric computations and uses domain knowledge on Alzheimer biomarkers. We study discriminative power of different brain projections. Three binary classification tasks are considered separating Alzheimer Disease (AD) patients from Mild Cognitive Impairment (MCI) and Normal Control subject (NC). Two fusion methods on FC layer and on the single-projection CNN output show better performances, up to 91% of accuracy is achieved. The results are competitive with the SOA which uses heavier algorithmic chain.	binary classification;computation;multimodal interaction;performance	Karim Aderghal;Jenny Benois-Pineau;Karim Afdel	2017		10.1145/3078971.3079010	artificial intelligence;machine learning;discriminative model;computer science;search engine indexing;deep learning;binary classification;pattern recognition;alzheimer's disease	Vision	31.718617468509755	-74.27346641343848	42509
df619a202c5c359e1eeb3c6028ee53c4f8971ad3	an mlp-based texture segmentation method without selecting a feature set	simulation ordinateur;systeme temps reel;learning algorithm;algorithm performance;image processing;analisis textura;real time;extraction forme;procesamiento imagen;texture segmentation;segmentation;algorithme apprentissage;multilayer perceptron;backpropagation;traitement image;texture analysis;extraccion forma;resultado algoritmo;smoothing;feature extraction;backpropagation algorithm;performance algorithme;alisamiento;back propagation algorithm;algorithme retropropagation;real time system;sistema tiempo real;simulacion computadora;perceptron;reseau neuronal;algoritmo aprendizaje;visual system;analyse texture;computer simulation;pattern extraction;lissage;red neuronal;segmentacion;neural network;algoritmo retropropagacion	A texture segmentation technique which employs a multilayer perceptron (MLP) and does not consider the selection of features is presented in this paper. Thus, users can avoid selection and computation of the feature set and hence real-time segmentation may be possible. The technique apparently works in a fashion similar to our visual system whereby we do not consciously compute any feature for texture discrimination. A detailed study has been made for the selection of the network size. A newly proposed variant of the backpropagation algorithm has been used for more efficient training of the network. An edge-preserving noise-smoothing approach has been proposed to remove noise from the segmented image.	algorithm;artificial intelligence;backpropagation;computation;consciousness;fractal;heuristic;image scaling;image segmentation;memory segmentation;memory-level parallelism;microsoft windows;multilayer perceptron;ncsa mosaic;quad flat no-leads package;real life;real-time clock;simulation;smoothing;universality probability;user-generated content;xfig	Ujjwal Bhattacharya;Bidyut Baran Chaudhuri;Swapan K. Parui	1997	Image Vision Comput.	10.1016/S0262-8856(97)00035-8	computer simulation;image processing;computer science;artificial intelligence;backpropagation;machine learning;scale-space segmentation;algorithm	Vision	45.39599303414309	-63.354152813004156	42528
9d7577012af0e3c91d7d3d2244adc5987df43d4a	a neural approach to extract foreground from human movement images	human movement;neural networks;segmentation;quality assessment;human body;unsupervised neural network;kohonen map;human movement analysis;neural network	In recent years many approaches to foreground extraction from images related to human movement have been presented. The foreground extraction represents a pre-processing procedure to be implemented in a system for capturing human movement in order to facilitate the tracking of anatomical landmarks on human bodies. In this work, an approach based on an unsupervised neural network has been studied: a Kohonen map has been designed to recognize and separate structures characterizing foreground and background. The proposed technique is fully automatic and its performance has been compared with those of two further approaches based on differences between foreground and background images. In order to quantify the segmentation quality, an already validated, objective, and automatic criterion has been used. The obtained results are adequate with the final aim of the application and show the feasibility of the proposed approach.	artificial neural network;automatic differentiation;biological neural networks;human body;preprocessor;self-organizing map	Silvia Conforto;Maurizio Schmid;Alessandro Neri;Tommaso D'Alessio	2006	Computer methods and programs in biomedicine	10.1016/j.cmpb.2006.02.005	computer vision;human body;computer science;artificial intelligence;machine learning;segmentation;artificial neural network	AI	31.511864001016647	-73.34126247461914	42540
a5509c36be21984654e37b331ee14e3bba5531fa	scene semantic recognition based on probability topic model		In recent years, scene semantic recognition has become the most exciting and fastest growing research topic. Lots of scene semantic analysis methods thus have been proposed for better scene content interpretation. By using latent Dirichlet allocation (LDA) to deduce the effective topic features, the accuracy of image semantic recognition has been significantly improved. Besides, the method of extracting deep features by layer-by-layer iterative computation using convolutional neural networks (CNNs) has achieved great success in image recognition. The paper proposes a method called DF-LDA, which is a hybrid supervised–unsupervised method combined CNNs with LDA to extract image topics. This method uses CNNs to explore visual features that are more suitable for scene images, and group the features of salient semantics into visual topics through topic models. In contrast to the LDA as a tool for simply extracting image semantics, our approach achieves better performance on three datasets that contain various scene categories.	algorithm;artificial neural network;benchmark (computing);cluster analysis;computation;computer vision;convolutional neural network;direction finding;distortion;experiment;fastest;high- and low-level;iterative method;latent dirichlet allocation;linear discriminant analysis;relevance;rollover (key);topic model	Jiangfan Feng;Amin Fu	2018	Information	10.3390/info9040097	topic model;artificial intelligence;convolutional neural network;machine learning;computer science;latent dirichlet allocation;semantics;computation	Vision	26.76586584843811	-53.05358133727427	42555
7b4e5466a3b83e009ebef089acfb52d26af410c9	a new detection approach for the fingerprint core location using extended relation graph	image recognition;reconocimiento imagen;tecnologia electronica telecomunicaciones;graphe relationnel;biometrie;localization;biometrics;biometria;localizacion;segmentation;core detection;extended relational graph;localisation;dactyloscopie;ridge directional image;reconnaissance image;relational graph;pattern recognition;fingerprint;reconnaissance forme;tecnologias;reconocimiento patron;grupo a;segmentacion;fingerprint identification	This paper describes a new approach to detect a fingerprint core location using the extended relational graph, which is generated by the segmentation of the ridge directional image. The extended relational graph presents the adjacency between segments of the directional image and the boundary information between segments of the directional image. The boundary curves generated by the boundary information in the extended relational graph is approximated to the straight lines. The fingerprint core location is calculated as center of the gravity in the points of intersection of these approximated lines. Experimental results show that 90.8% of the 130 fingerprint samples are succeeded to detect the core location.	fingerprint	Tomohiko Ohtsuka;Takeshi Takahashi	2005	IEICE Transactions	10.1093/ietisy/e88-d.10.2308	fingerprint;computer vision;computer science;machine learning	Vision	48.60003855931605	-59.84102000698257	42672
f52b93160a465a45b006691ce36bdc4d2fd28300	image fakery and neural network based detection	contenu image;image numerique;image content;detecteur image;computer graphics;fonction base radiale;computer graphic;radial basis function;rbf neural network;imaging;imagen numerica;formation image;detector imagen;formacion imagen;digital image;reseau neuronal;contenido imagen;funcion radial base;grafico computadora;infographie;red neuronal;image sensor;neural network	By right of the great convenience of computer graphics and digital imaging, it is much easier to alter the content of an image than before without any visually traces. Human has not believed what they see. Many digital images can not be judged whether they are real or feigned visually, i.e., many fake images are produced whose content is feigned. In this paper, firstly, image fakery is introduced, including how to produce fake images and its characters. Then, a fake image detection scheme is proposed, which uses radial basis function (RBF) neural network as a detector to make a binary decision on whether an image is fake or real. The experimental results also demonstrated the effectiveness of the proposed scheme.	artificial neural network;computer graphics;digital image;digital imaging;radial (radio);radial basis function;tracing (software)	Wei Lu;Korris Fu-Lai Chung;Hongtao Lu	2006		10.1007/11760023_90	medical imaging;computer vision;radial basis function;computer science;artificial intelligence;machine learning;image sensor;computer graphics;digital image;artificial neural network;computer graphics (images)	Vision	44.84766175767146	-63.157840368206415	42688
3aa6328ea3619092347fe5f4dcffffc6c7d4a169	performance improved modified fuzzy c-means algorithm for image segmentation applications		Fuzzy C-Means (FCM) algorithm is one of the commonly preferred fuzzy algorithms for image segmentation applications. Even though FCM algorithm is sufficiently accurate, it suffers from the computational complexity problem which prevents the usage of FCM in real-time applications. In this work, this convergence problem is tackled through the proposed Modified FCM (MFCM) algorithm. In this algorithm, several clusters among the input data are formed based on similarity measures and one representative data from each cluster is used for FCM algorithm. Hence, this methodology minimizes the convergence time period requirement of the conventional FCM algorithm to higher extent. This proposed approach is experimented on Magnetic Resonance (MR) brain tumor images. Experimental results suggest promising results for the MFCM algorithm in terms of the performance measures.	algorithm;cluster analysis;computational complexity theory;fuzzy cognitive map;image segmentation;real-time clock;resonance	D. Jude Hemanth;J. Anitha;Valentina Emilia Balas	2015	Informatica, Lith. Acad. Sci.		mathematical optimization;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation	ML	43.1710152619795	-72.58963174058471	42694
9dff2ffc6202b3bd45861af8f62327ce0e086fd6	color image segmentation in a quaternion framework	biological patents;distance function;closed form solution;biomedical journals;text mining;europe pubmed central;citation search;citation networks;gabor filter;research articles;mixture model;abstracts;open access;life sciences;clinical guidelines;full text;analytic solution;rest apis;orcids;europe pmc;biomedical research;color image;color image segmentation;bioinformatics;literature search	In this paper, we present a feature/detail preserving color image segmentation framework using Hamiltonian quaternions. First, we introduce a novel Quaternionic Gabor Filter (QGF) which can combine the color channels and the orientations in the image plane. Using the QGFs, we extract the local orientation information in the color images. Second, in order to model this derived orientation information, we propose a continuous mixture of appropriate hypercomplex exponential basis functions. We derive a closed form solution for this continuous mixture model. This analytic solution is in the form of a spatially varying kernel which, when convolved with the signed distance function of an evolving contour (placed in the color image), yields a detail preserving segmentation.		Özlem N. Subakan;Baba C. Vemuri	2009	Energy minimization methods in computer vision and pattern recognition. International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition	10.1007/978-3-642-03641-5_30	color histogram;computer vision;closed-form expression;text mining;computer science;data science;machine learning;data mining;mathematics;image segmentation;scale-space segmentation;statistics	Vision	49.88048304215221	-70.1176330523342	42745
b7b74722a64eb97b8b21b6faf4661b23b57e7555	skull identification via correlation measure between skull and face shape	skull identification method forensic medicine craniofacial reconstruction craniofacial superimposition region fusion strategy analysis model canonical correlation analysis face shape correlation measure;shape recognition correlation methods forensic science image fusion image matching image reconstruction;face shape correlation skin three dimensional displays training image reconstruction	Skull identification is an important subject for research in forensic medicine. Current research can be divided into two categories: 1) craniofacial superimposition and 2) craniofacial reconstruction. Both categories rely essentially on the accurate extraction and representation of the intrinsic relationship between the skull and face in terms of the morphology, which still remain unsolved. They have high uncertainty and a low identification capability. This paper proposes a novel skull identification method that matches an unknown skull with enrolled 3D faces, in which the mapping between the skull and face is obtained using canonical correlation analysis. Unlike existing techniques, this method needs no accurate relationship between the skull and face, and measures only the correlation between them. In order to measure the correlation more reliably and improve the identification capability of the correlation analysis model, a region fusion strategy is adopted. Experimental results validate the proposed method, and show that the region-based method can significantly boost the matching accuracy. The correct identification rate reaches 94% when using a CT data set. This paper can provide a theory support for research on craniofacial superimposition and craniofacial reconstruction.	anthropometry;ct scan;cost efficiency;data acquisition;database;galaxy morphological classification;holism;mathematical morphology	Fuqing Duan;Yanchao Yang;Yan Li;Yun Tian;Ke Lu;Zhongke Wu;Mingquan Zhou	2014	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2014.2332981	computer vision;speech recognition	Vision	36.22523964535427	-72.50127053155686	42747
970a947df38907d4151d861337a4713823a9c8eb	effects of different classifiers in detecting infectious regions in chest radiographs	naive bayes;chest radiograph;statistical analysis bayes methods diagnostic radiography diseases feature extraction image classification lung medical image processing sensitivity analysis;classification;image feature computation chest radiographs rule based classifiers bayesian classifiers k nearest neighbour classifiers kappa statistic roc area infectious lung region extraction;ir;k nn;bayes network;lung infection;chest radiograph classification naive bayes bayes network k nn ir lung infection;lungs training diagnostic radiography diseases bayes methods accuracy	This paper presents the effects of different types of classifiers when analysing the normal and infectious regions in chest radiographs. Three types of classifiers are experimented on: Rule-based, Bayesian and k-nearest neighbour's. The evaluation is based on a few criteria, namely, the classification accuracy, misclassification (error), speed, Kappa statistic, ROC area, and other performance measures specifically the true and false positive rates, and precision and recall. The dataset consists of image features from a total of 102 chest radiographs. The normal and infectious lung regions are extracted and divided into non-overlapping sub-blocks prior to the image feature computation. The quantitative results are presented and discussed for consideration in further analysis of infectious lungs.	computation;feature (computer vision);k-nearest neighbors algorithm;precision and recall;radiography;sensor	Wan Siti Halimatul Munirah Wan Ahmad;Rajasvaran Logeswaran;Mohammad Faizal Ahmad Fauzi;Wan Mimi Diyana Wan Zaki	2014	2014 IEEE International Conference on Industrial Engineering and Engineering Management	10.1109/IEEM.2014.7058696	naive bayes classifier;biological classification;computer science;machine learning;pattern recognition;bayesian network	Visualization	35.26440490120606	-76.37886819286108	42793
9829a684b98828fb651a2a36d36d2074cb444cd3	vicopt: a robust system for content-based video copy detection in large databases	estensibilidad;protection information;television;analisis contenido;on line systems;video databases;cluster algorithm;video identification;protection copie;video signal processing;asymmetry;flexibilidad;heuristic method;copy protection;database;base dato;metodo heuristico;base donnee video;asymetrie;archive;indexing method;algorithme;algorithm;local video descriptors;content analysis;video copy detection;internet;monitoring;proteccion informacion;indexing;archivo;systeme en ligne;information protection;robustesse;indexation;signal classification;indizacion;base de donnees;traitement signal video;classification signal;asimetria;robustness;flexibilite;extensibilite;scalability;methode heuristique;monitorage;analyse contenu;classification automatique;monitoreo;automatic classification;video database;clasificacion automatica;flexibility;point of interest;robustez;algoritmo	This paper presents an efficient approach for copy detection in large archives containing several hundred hours of videos, called ViCopT for Video Copy Tracking. Our video content indexing method consists in computing trends of behaviors of points of interest and then to assign them a label of behavior. Two methods are proposed to assign the labels: one uses heuristic tresholds and the other one uses a clustering algorithm. Such an indexing approach has several interesting properties: it provides a rich, compact and generic description, while labels of behavior provide a high-level description of the video content. A dedicated online retrieval method for copy detection is described, compared and evaluated on a large video database (1,000 h). This evaluation is done on a framework proposed for video copy detection: ViCopT displays excellent robustness to various severe signal transformations and the ability to accurately identify copies from highly similar videos. Other evaluation focuses on the flexibility of ViCopT due to the asymmetry of the video description. This allow the system to be highly scalable and very flexible regarding the situation faced: searching for copies on the internet or monitoring TV stream.	algorithm;archive;audio description;cluster analysis;database;digital video;heuristic;high- and low-level;internet;point of interest;scalability;video copy detection	Julien Law-To;Olivier Buisson;Valérie Gouet-Brunet;Nozha Boujemaa	2009	Multimedia Systems	10.1007/s00530-009-0164-2	search engine indexing;scalability;the internet;point of interest;content analysis;telecommunications;computer science;video tracking;data mining;television;world wide web;information protection policy;asymmetry;robustness	Vision	42.058229403862256	-60.27450855368081	42875
9390889b2992203f0caaad9315022c32f92fe396	a lip extraction algorithm using region-based acm with automatic contour initialization	active appearance model;speaker facial feature lip extraction algorithm automatic contour initialization lipreading system speech recognition facial feature feature detection global region based acm localized region based acm;face recognition;shape;image edge detection;image color analysis;feature extraction;speech recognition face recognition feature extraction object detection;image color analysis face mathematical model feature extraction image edge detection shape active appearance model;mathematical model;speech recognition;face;object detection	In a lipreading system, lip extraction is a fundamental method that directly affects the final speech recognition results. However, most existing systems need to detect some facial features as prior-knowledge to construct the initial contour, and any erroneous feature detection will lead to an incorrect lip extraction. In order to solve this problem, this paper presents a new framework which integrates both global region-based Active Contour Model (ACM) and localized region-based ACM. With the utilization of the proposed framework, the initial contour does not need to be specified according to the speaker facial features before extracting the lip, so that any erroneous extraction introduced by an incorrect initial contour is effectively eliminated. Experimental results show the efficiency of the proposed method in comparison with the existing methods.	active contour model;algorithm;color space;contour line;feature detection (computer vision);feature detection (web development);information extraction;mathematical optimization;pc speaker;speech recognition;ti advanced scientific computer;the australian	Chao Sui;Mohammed Bennamoun;Roberto Togneri;Serajul Haque	2013	2013 IEEE Workshop on Applications of Computer Vision (WACV)	10.1109/WACV.2013.6475029	facial recognition system;face;computer vision;active appearance model;speech recognition;feature extraction;shape;computer science;pattern recognition;mathematical model;geometry;feature	Vision	44.02618280194514	-65.40200367125735	42889
41dd96c2d18793b4d974e26ea45c7653a7428953	lung cancer classification using radial basis function neural network model with point operation		In this paper, we propose radial basis function neural network (RBFNN) model to classify the lung cancer through lung photo/image called chest X-ray. We also present the benefit of image improvement of point operation. The point operation specifically aims to improve the intensity of the lung image. The RBFNN model involves two kind of learning processes. Here, we consider K-means clustering and global ridge regression methods to learn the center and the width parameters and also the weights of RBFNN model, respectively. Three classifications of lung conditions including normal, benign, and malignant are examined. The structure of RBFNN model is generated based on the parameters resulted from the images extraction Gray Level Co-occurrence Matrix (GLCM) method. The experimental result shows the superiority of RBFNN model with point operation over the RBFNN model without point operation.	artificial neural network;cluster analysis;co-occurrence matrix;k-means clustering;network model;radial (radio);radial basis function	Dhoriva Urwatul Wutsqa;Humairoh Luthfi Ratih Mandadara	2017	2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)	10.1109/CISP-BMEI.2017.8302285	artificial intelligence;cluster analysis;pattern recognition;lung cancer;artificial neural network;matrix (mathematics);radial basis function;computer science;histogram	ML	34.685888022762136	-75.16451027379148	42960
d679b7398605fb5d60c25268aee50cd9eeeeaf36	mapping the retinas of a patient using a mixed set of fundus photographs from both eyes	biomedical imaging;sensitivity;optical imaging;retina;pathology;blood vessels;adaptive optics	With the increased prevalence of retinal pathologies, automating the detection and progression measurement of these pathologies is becoming more and more relevant. Color fundus photography is the leading modality for assessing retinal pathologies. Because eye fundus cameras have a limited field of view, multiple photographs are taken from each retina during an eye fundus examination. However, operators usually don't indicate which photographs are from the left retina and which ones are from the right retina. This paper presents a novel algorithm that automatically assigns each photograph to one retina and builds a composite image (or “mosaic”) per retina, which is expected to push the performance of automated diagnosis forward. The algorithm starts by jointly forming two mosaics, one per retina, using a novel graph theoretic approach. Then, in order to determine which mosaic corresponds to the left retina and which one corresponds to the right retina, two retinal landmarks are detected robustly in each mosaic: the main vessel arch surrounding the macula and the optic disc. The laterality of each mosaic derives from their relative location. Experiments on 2790 manually annotated images validate the very good performance of the proposed framework even for highly pathological images.	blood vessel tissue;color gradient;gastric fundus carcinoma in situ;graph - visual representation;graph theory;modality (human–computer interaction);mosaic - computer software;optic disk;patients;structure of both eyes;structure of fundus of eye;structure of retina of left eye;structure of retina of right eye;virtual retinal display;algorithm;photograph	Gwénolé Quellec;Mathieu Lamard;Guy Cazuguel;Ali Erginay;Béatrice Cochener	2016	2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2016.7591419	medical imaging;computer vision;radiology;medicine;sensitivity;optical imaging;optics;adaptive optics;physics;anatomy	Vision	40.263069507043795	-78.34293290873669	42994
b424080b9d7b298ae9efbfc4225baf7524fbdebe	sketch-based human motion retrieval via selected 2d geometric posture descriptor	sketch based;feature selection;computer animation;motion retrieval	Sketch-based human motion retrieval is a hot topic in computer animation in recent years. In this paper, we present a novel sketch-based human motion retrieval method via selected 2-dimensional (2D) Geometric Posture Descriptor (2GPD). Specially, we firstly propose a rich 2D pose feature call 2D Geometric Posture Descriptor (2GPD), which is effective in encoding the 2D posture similarity by exploiting the geometric relationships among different human body parts. Since the original 2GPD is of high dimension and redundant, a semi-supervised feature selection algorithm derived from Laplacian Score is then adopted to select the most discriminative feature component of 2GPD as feature representation, and we call it as selected 2GPD. Finally, a posture-by-posture motion retrieval algorithm is used to retrieve a motion sequence by sketching several key postures. Experimental results on CMU human motion database demonstrate the effectiveness of our proposed approach.		Jun Xiao;Zhangpeng Tang;Yinfu Feng;Zhidong Xiao	2015	Signal Processing	10.1016/j.sigpro.2015.01.004	computer vision;computer science;machine learning;pattern recognition;computer animation;multimedia;feature selection	Vision	35.80047299331186	-54.09582211829717	43015
8c93907f376fe93b9ec847f5034afd623b9774e6	spatial pyramid face feature representation and weighted dissimilarity matching for improved face recognition		In this paper, we present a novel face recognition (FR) algorithm based on multiresolution spatial pyramid. In our method, a face is subdivided into increasingly finer subregions (local regions) and represented at multiple levels of histogram representations. To address image misalignment problem, overlapped patch-based local descriptor extraction has been also developed in an effective way. To preserve multiple levels of detail in facial local characteristics and to encode holistic spatial configuration, face features obtained for concatenated histograms (coming from all levels of spatial pyramid) are integrated into a combined feature set, termed spatial pyramid face feature representation (SPFR). In addition, to perform recognition by matching between the pair of probe and gallery SPFR sets, we propose the use of a weighted sum of the dissimilarity scores computed at all spatial pyramid levels. For this purpose, we develop a novel weight determination solution based on class-wise discriminant power estimation for face feature at a specific pyramid level. We incorporate our proposed algorithm into general FR pipeline and achieve encouraging identification results on the CMU-PIE, FERET, and LFW datasets, compared to previously developed methods. In addition, the feasibility of our method has been successfully demonstrated by making comparisons with other state-of-the-art FR methods (including deep CNN based method) under the FERET and FRGC 2.0 evaluation protocols. Based on results, our method is advantageous in terms of high recognition accuracy and low complexity, as well as straightforward implementation.	algorithm;computation;concatenation;discriminant;encode;feret (facial recognition technology);facial recognition system;holism;illumination (image);performance;wavelength-division multiplexing;weight function	Jae Young Choi	2017	The Visual Computer	10.1007/s00371-017-1429-y	spatial configuration;pyramid (image processing);computer vision;artificial intelligence;computer science;facial recognition system;pyramid;feret;histogram;pattern recognition	Vision	38.399494547749875	-56.67105986802566	43016
0cecadee252e4b78101d473796bb64c7f427a7d5	correction of mr k-space data corrupted by spike noise	artefacto;pulse noise;nuclear magnetic resonance imaging;traitement signal;filtering;filtrage;medical imagery;image processing;systeme nerveux central;fourier transform;implementation;frequency domain analysis;standard deviation;filtrado;hombre;image restoration;bruit impulsion;encefalo;indexing terms;satisfiability;magnetic resonance image;artefact;low spatial frequency;reduccion ruido;imageria rmn;ejecucion;sistema nervioso central;random noise;neighboring pixels interpolations digitized raw data magnetic resonance images reconstruction spatial frequency domain mr k space data spike noise corrupted data striation artifact structure analytical solution full width at half maximum point spread function spike magnitude window filter k space random noise medical diagnostic imaging intermediate domain;encephale;fourier transformation;point spread function;medical image processing;signal processing;noise reduction;frequence spatiale;discrete fourier transform;transformation fourier;human;reduction bruit;imagerie medicale;imagerie rmn;image restoration biomedical mri medical image processing noise discrete fourier transforms frequency domain analysis;imageneria medical;frecuencia espacial;discrete fourier transforms;image restoration filters interpolation fourier transforms magnetic resonance imaging image reconstruction magnetic separation frequency domain analysis coils hardware;analytic solution;procesamiento senal;artifacts brain fourier analysis humans image processing computer assisted magnetic resonance imaging;ruido impulso;full width at half maximum;central nervous system;spatial frequency;noise;biomedical mri;homme;transformacion fourier;brain vertebrata	Magnetic resonance images are reconstructed from digitized raw data, which are collected in the spatial-frequency domain (also called k-space). Occasionally, single or multiple data points in the k-space data are corrupted by spike noise, causing striation artifacts in images. Thresholding methods for detecting corrupted data points can fail because of small alterations, especially for data points in the low spatial frequency area where the k-space variation is large. Restoration of corrupted data points using interpolations of neighboring pixels can give incorrect results. The authors propose a Fourier transform method for detecting and restoring corrupted data points using a window filter derived from the striation-artifact structure in an image or an intermediate domain. The method provides an analytical solution for the alteration at each corrupted data point. It can effectively restore corrupted k-space data, removing striation artifacts in images, provided that the following 3 conditions are satisfied. First, a region of known signal distribution (for example, air background) is visible in either the image or the intermediate domain so that it can be selected using a window filter. Second, multiple spikes are separated by the full-width at half-maximum of the point spread function for the window filter. Third, the magnitude of a spike is larger than the minimum detectable value determined by the window filter and the standard deviation of k-space random noise.	data point;interpolation;noise (electronics);pixel;resonance;ringing artifacts;sensor;thresholding (image processing)	Yi-Hsuan Kao;James R. MacFall	2000	IEEE Transactions on Medical Imaging	10.1109/42.875184	fourier transform;computer vision;speech recognition;image processing;computer science;magnetic resonance imaging;signal processing;mathematics	Vision	51.58718936875706	-75.9043465978054	43017
63aa0b9ea35deb57d31685538ff6e71dae3bd63e	creation of retinal mosaics for diabetic retinopathy screening: a comparative study		The creation of retinal mosaics from sets of fundus photographs can significantly reduce the time spent on the diabetic retinopathy (DR) screening, because through mosaic analysis the ophthalmologists can examine several portions of the eye at a single glance and, consequently, detect and grade DR more easily. Like most of the methods described in the literature, this methodology includes two main steps: image registration and image blending. In the registration step, relevant keypoints are detected on all images, the transformation matrices are estimated based on the correspondences between those keypoints and the images are reprojected into the same coordinate system. However, the main contributions of this work are in the blending step. In order to combine the overlapping images, a color compensation is applied to those images and a distance-based map of weights is computed for each one. The methodology is applied to two different datasets and the mosaics obtained for one of them are visually compared with the results of two state-of-the-art methods. The mosaics obtained with our method present good quality and they can be used for DR grading.		Tânia Melo;Ana Maria Mendonça;Aurélio Campilho	2018		10.1007/978-3-319-93000-8_76	artificial intelligence;computer vision;pattern recognition;computer science;image registration;diabetic retinopathy screening;diabetic retinopathy;retinal;transformation matrix;fundus (eye)	Vision	38.64136011940253	-71.25783680008921	43029
b818c18c022863c250a18e3482ba9f4c574dbca0	automatic liver segmentation and hepatic fat fraction assessment in mri	deformable model segmentation mri;segmentation;statistical analysis biomedical mri diseases image registration image segmentation medical image processing patient monitoring;mr volumetric scans automatic liver segmentation hepatic fat fraction assessment mri liver fat fraction disease quantification therapy monitoring drug development liver anatomy single statistical atlas registration liver assessment robust deformable model fat fraction map chemical shift based method magnetic resonance volumetric scans automatic graph cut method;mri;liver image segmentation deformable models magnetic resonance imaging robustness accuracy computational modeling;deformable model	Automated assessment of hepatic fat fraction is clinically important. A robust and precise segmentation would enable accurate, objective and consistent measurement of liver fat fraction for disease quantification, therapy monitoring and drug development. However, segmenting the liver in clinical trials is a challenging task due to the variability of liver anatomy as well as the diverse sources the images were acquired from. In this paper, we propose an automated and robust framework for liver segmentation and assessment. It uses single statistical atlas registration to initialize a robust deformable model to get fine segmentation. Fat fraction map is computed by using chemical shift based method in the delineated region of liver. This proposed method is validated on 14 abdominal magnetic resonance (MR) volumetric scans. The qualitative and quantitative comparisons show that our proposed method can achieve better segmentation accuracy with less variance comparing with an automatic graph cut method. Experimental results demonstrate the promises of our assessment framework.	cut (graph theory);file allocation table;graph cuts in computer vision;resonance;spatial variability;texture atlas	Zhennan Yan;Chaowei Tan;Shaoting Zhang;Yan Zhou;Boubakeur Belaroussi;Hui Jing Yu;Colin Miller;Dimitris N. Metaxas	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.565	computer vision;magnetic resonance imaging;segmentation	Vision	41.08020535683435	-79.44382561827024	43059
e477ff8d7dac66b192310bcd7f53680b2c256b72	computer-aided detection of prostate cancer	k nearest neighbors;transrectal ultrasound;computer aided diagnosis;ultrasound;hidden markov model;prostate carcinoma;texture analysis;computer aided detection;developing country;k nearest neighbor;prostate cancer	BACKGROUND Prostate cancer is one of the most frequent cancers in men and is a major cause of mortality in developed countries. Detection of prostate carcinoma at an early stage is crucial for successful treatment.   MATERIAL AND METHODS A method for the analysis of transrectal ultrasound images aimed at computer-aided diagnosis of prostate cancer is tested in this paper. First, two classifiers based on k-nearest neighbors and Hidden Markov models are compared. Second, the diagnostic capacity of our system is tested by means of a set of experiments where humans with varying degrees of experience classified a set of ultrasound images with and without the aid of the computer-aided system. The corpus used in this study was specifically acquired for this purpose. It consists of 4944 ultrasound images corresponding to 303 patients, and is publicly available for non-commercial use upon request.   RESULTS The best classification results achieve an area under the receiver operating characteristic curve of 61.6%. However, the diagnostic capacity of an expert urologist using the computer-aided system improves only slightly compared with his/her capacity without the aid of the system.   CONCLUSIONS Despite the difficulty of this task, the obtained results indicate that discrimination between cancerous and non-cancerous tissue is possible to a certain degree. The computer-aided system helps an inexperienced user to make a better diagnosis, however it must be able to perform better in order to be useful in a real-world clinical context.		Rafael Llobet;Juan Carlos Pérez-Cortes;Alejandro Héctor Toselli;Alfons Juan-Císcar	2007	International journal of medical informatics	10.1016/j.ijmedinf.2006.03.001	speech recognition;medicine;pathology;computer science;gynecology;machine learning;k-nearest neighbors algorithm;hidden markov model	Vision	33.52185460222546	-78.2377097212071	43066
5c177cc55835126fc2a240a7ffcd9a5f4bab4fb0	learning deep compact descriptor with bagging auto-encoders for object retrieval	video surveillance binary codes content based retrieval convolution feature extraction learning artificial intelligence neural nets video coding video retrieval;100k visual object dataset deep compact descriptor learning bagging autoencoders content based object retrieval large scale surveillance video dataset discriminative cnn convolutional neural network deep feature extraction background noise filtering high dimensional real valued cnn features short binary codes;bagging feature extraction training surveillance visualization binary codes vehicles;auto encoder object retrieval bagging	Content based object retrieval across large scale surveillance video dataset is a significant and challenging task, in which learning an effective compact object descriptor plays a critical role. In this paper, we propose an efficient deep compact descriptor with bagging auto-encoders. Specifically, we take advantage of discriminative CNN to extract efficient deep features, which not only involve rich semantic information but also can filter background noise. Besides, to boost the retrieval speed, auto-encoders are used to map the high-dimensional real-valued CNN features into short binary codes. Considering the instability of auto-encoder, we adopt a bagging strategy to fuse multiple auto-encoders to reduce the generalization error, thus further improving the retrieval accuracy. In addition, bagging is easy for parallel computing, so retrieval efficiency can be guaranteed. Retrieval experimental results on the dataset of 100k visual objects extracted from multi-camera surveillance videos demonstrate the effectiveness of the proposed deep compact descriptor.	autoencoder;binary code;closed-circuit television;encoder;generalization error;instability;parallel computing;visual objects	Haiyun Guo;Jinqiao Wang;Hanqing Lu	2015	2015 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2015.7351389	computer vision;computer science;machine learning;pattern recognition	Vision	26.439946088551675	-52.64608104061529	43073
b5758b70b146a604591f0f2072881b6f6a2c82c9	recognition of partial planar shapes in limited memory environments	restricted memory environment;vision ordenador;forma planaria;occlusion;limitation;heuristic method;espacio 2 dimensiones;oclusion;metodo heuristico;capacidad memoria;computer vision;heuristic search;planar form;capacite memoire;memory capacity;limitacion;two dimensional space;pattern recognition;forme planaire;espace 2 dimensions;vision ordinateur;methode heuristique;reconnaissance forme;reconocimiento patron;model based object recognition	Industrial vision systems should be capable of recognising noisy objects, partially occluded objects and randomly located and/or oriented objects. This paper considers the problem of recognition of partially occluded planar shapes using contour segment-based features. None of the techniques suggested in the literature for solving the above problem guarantee reliable results for problem instances which require memory in excess of what is available. In this paper, a heuristic search-based recognition algorithm is presented, which guarantees reliable recognition results even when memory is limited. This algorithm identifies an object, the maximum portion of whose contour is visible in a conglomerate of objects. For increasing efficiency of the method, a two-stage recognition scheme has been designed. In the first phase, a relevant subset of the known model shapes is chosen and in the second stage, matching between the unknown shape and elements of the relevant subset is attempted using the above approach. The technique is general in the sense that it can be used with any kind of contour features. To evaluate the efficiency of the method, experimentation was carried out using polygonal approximations of the object contours. Results are cited for establishing the effectiveness of the approach.		Santanu Chaudhury;S. Subramanian;Parthasarathy Guturu	1990	IJPRAI	10.1142/S0218001490000344	computer vision;two-dimensional space;heuristic;computer science;artificial intelligence;pattern recognition	ML	47.86014010057861	-59.0265384287224	43095
dbdf930ae8f1ede4238d40fa465de497223181ad	shape extraction: a comparative study between neural network-based and conventional techniques	object recognition;estimator robustness;learning algorithm;image processing;esqueleto;binary image;procesamiento imagen;algorithme apprentissage;classification;image bruitee;noise robustness;traitement image;gray scale;skeleton;algorithme;imagen sonora;algorithm;robustez estimador;noisy image;image binaire;comparative study;estimacion parametro;pattern recognition;autoorganizacion;squelette;imagen binaria;self organization;data reduction;reconnaissance forme;parameter estimation;estimation parametre;reseau neuronal;reconocimiento patron;signal to noise ratio;echelle gris;algoritmo aprendizaje;clasificacion;red neuronal;medial axis;autoorganisation;escala gris;neural network;algoritmo;robustesse estimateur	Extraction of the skeletal shape of an elongated object is often required in object recognition and classification problems. Various techniques have so far been developed for this purpose. A comprehensive comparative study is carried out here between neural network-based and conventional techniques. The main problems with the conventional methods are noise sensitivity and rotation dependency. Most of the existing algorithms are sensitive to boundary noise and interior noise. Also, they are mostly rotation dependent, particularly if the angle of rotation is not a multiple of 90°. On the other hand, the neural network based technique discussed here is found to be highly robust in terms of boundary noise as well as interior noise. The neural method produces satisfactory results even for a very low (close to 1) Signal to Noise Ratio (SNR). The algorithm is also found to be efficient in terms of invariance under arbitrary rotations and data reduction. Moreover, unlike the conventional algorithms, it is grid independent. Finally, the neural technique is easily extendible to dot patterns and grey-level patterns also.	algorithm;artificial neural network;extensibility;outline of object recognition;signal-to-noise ratio	Amitava Datta;Swapan K. Parui	1998	Neural Computing & Applications	10.1007/BF01428125	gradient noise;computer vision;data reduction;self-organization;medial axis;binary image;image processing;biological classification;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;comparative research;estimation theory;signal-to-noise ratio;skeleton;artificial neural network;grayscale	ML	46.370529192081094	-60.87384584303293	43132
96222ab89d32226c5a7b7feffc1d0840a6155d11	color-based image retrieval using spatial-chromatic histograms	histograms;image databases;images database;information retrieval;image database;spatial chromatic histogram;high retrieval accuracy;high retrieval accuracy color based image retrieval spatial chromatic histograms content based image retrieval values information pixels images database;color similarityvolume ii;image retrieval histograms image databases information retrieval spatial databases content based retrieval pixel indexing feature extraction robot vision systems;indexing;image colour analysis;feature extraction;pixel;spatial databases;values information;pixels;color based image retrieval;visual databases content based retrieval image colour analysis;spatial chromatic histograms;content based image retrieval;content based retrieval;robot vision systems;spatial information;visual databases;image retrieval	We propose a methodology to integrate color and spatial information for content-based image retrieval. This methodology, called SpatialChromatic Hist ogram (SCH), synthesizes in few values information about the location of pixels having the same color and their arrangement within the image. We have performed experiments on n three hundred images database and our results show a high retrieval accuracy.	.sch;color;content-based image retrieval;experiment;monumenta germaniae historica;pixel;spatial anti-aliasing	Luigi Cinque;Stefano Levialdi;Kai A. Olsen;A. Pellicanò	1999		10.1109/MMCS.1999.778621	color histogram;image texture;computer vision;visual word;color normalization;color image;image retrieval;computer science;pattern recognition;automatic image annotation;histogram equalization;information retrieval;pixel;statistics	Vision	39.31697771937173	-60.576741579870735	43190
c2d69414c920ab297cd9dfd80001c354c27e3fd6	automatic classification of the interferential tear film lipid layer using colour texture analysis	tear film lipid layer;texture analysis;machine learning;principal component analysis;guillon categories	The tear film lipid layer is heterogeneous among the population. Its classification depends on its thickness and can be done using the interference pattern categories proposed by Guillon. This papers presents an exhaustive study about the characterisation of the interference phenomena as a texture pattern, using different feature extraction methods in different colour spaces. These methods are first analysed individually and then combined to achieve the best results possible. The principal component analysis (PCA) technique has also been tested to reduce the dimensionality of the feature vectors. The proposed methodologies have been tested on a dataset composed of 105 images from healthy subjects, with a classification rate of over 95% in some cases.	categories;color space;feature extraction;feature vector;genetic heterogeneity;interference (communication);paper;principal component analysis;thickness (graph theory)	Beatriz Remeseiro;Marta Penas;Noelia Barreira;Antonio Mosquera González;Jorge Novo;Carlos García-Resúa	2013	Computer methods and programs in biomedicine	10.1016/j.cmpb.2013.04.007	computer vision;computer science;machine learning;principal component analysis	Vision	34.327921263072184	-71.70481536258261	43215
8df5aa3136335f7533d7ac8f9812b42b58957fae	image matching and retrieval by repetitive patterns	line pattern representation;repetitive pattern detection;lattices;image matching;shift invariant descriptor;computer vision;computational modeling;lattice representation;image representation;pattern matching;image retrieval computer vision image matching image representation;tiles;repetitive patterns;tiles lattices image retrieval image matching computational modeling;pattern matching image matching image retrieval repetitive pattern detection computer vision lattice representation line pattern representation shift invariant descriptor;shift invariant;image retrieval repetitive patterns;image retrieval	Detection of repetitive patterns in images has been studied for a long time in computer vision. This paper discusses a method for representing a lattice or line pattern by shift-invariant descriptor of the repeating element. The descriptor overcomes shift ambiguity and can be matched between different a views. The pattern matching is then demonstrated in retrieval experiment, where different images of the same buildings are retrieved solely by repetitive patterns.	computer vision;image registration;pattern matching	Petr Doubek;Jiri Matas;Michal Perdoch;Ondrej Chum	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.782	computer vision;image retrieval;computer science;theoretical computer science;pattern matching;pattern recognition;lattice;mathematics;computational model;shift-invariant system	Vision	40.96654595583954	-59.008463330655495	43244
73334349b483812c6215caa6cc24c59dbead17e2	detection of high-risk macular edema using texture features and classification using svm classifier	support vector machines;optical filters;training;diabetes;accuracy;optical imaging;feature extraction	In digital retinal images, positive means of texture feature detection around the macula region with specified radius is still an open issue. Diabetic macular edema is a complication caused due to Diabetic Retinopathy (DR) and is the true cause of blindness and visual loss. In this paper, we have presented a computerized method for texture feature extraction around the specified radius taking macula as the centre. By proper segmentation techniques, the region of 1DD (Disc Diameter) around the macula centre, was extracted out. The extracted region contained a great amount of abnormalities like micro-aneurysms, hard-exudates and hemorrhages, thereby texture features varied greatly. Unlike other well-known approaches of machine learning classifier techniques, we propose a combination of texture feature extraction from the region of interest around macula and grading using Support Vector Machine (SVM) classifier. The segmented region containing abnormalities differ greatly in texture and a promising “accuracy > 86%” was obtained between the “normal” and “abnormal” type classification. The performance evaluation of the automated system was determined by parameters, namely Sensitivity, Specificity and Accuracy with values obtained about 91%, 75% & 86 % respectively.	feature detection (computer vision);feature detection (web development);feature extraction;machine learning;micro isv;performance evaluation;region of interest;sensitivity and specificity;support vector machine	Aditya Kunwar;Shrey Magotra;M. Partha Sarathi	2015	2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2015.7275958	support vector machine;computer vision;speech recognition;feature extraction;computer science;engineering;machine learning;pattern recognition;optical imaging;optical filter;accuracy and precision	Vision	35.669897403041176	-75.46142031736494	43269
2ccdbb51c663b629f2188612884adc939d8eb2b0	local symmetry modeling in multi-dimensional images	espacio n dimensiones;multidimensional space;modelizacion;espace n dimensions;vision ordenador;detection forme;image processing;voisinage;producto matriz;sistema informatico;procesamiento imagen;computer system;shape detection;traitement image;symetrie;symmetry;computer vision;eigenvalue;modelisation;multi dimensional;deteccion forma;valor propio;vision ordinateur;valeur propre;systeme informatique;simetria;produit matrice;modeling;matrix product	Hansen, O. and J. Bigtin, Local symmetry modeling in multi-dimensional images, Pattern Recognition Letters ! 3 (1992) 253-262. This paper introduces a method for modeling symmetries in a local neighborhood of a multi-dimensional image. The symmetries are described by means of a set of functions, which have orthogonal gradients. Based on this model a detection process can be constructed by means of a set of matrix multiplications, and a final eigenvalue evaluation. The matrix multiplications are performed between a directional vector and a matrix kernel. Tile results of tile algorithm are proposed to be partly a cont'idence measure represent;,lg the quality of the detection, and partly a vector measure representing the parameters characterizing the individual symmetries. All extension of tile method permitting detection ill every local neighborhood avoiding the eigenvalue analysis is developed. Tile inethod is implenlented ill tile 3-dimensional case and applied to a set of test images. The results indicate the validity of the theory, which provides a compact mathematical model of the local symn~etries.	algorithm;gradient;kernel (linear algebra);mathematical model;pattern recognition letters;the matrix;vector graphics	Ole Hansen;Josef Bigün	1992	Pattern Recognition Letters	10.1016/0167-8655(92)90076-C	computer vision;systems modeling;image processing;eigenvalues and eigenvectors;matrix multiplication;computer science;mathematics;geometry;symmetry;algorithm	Vision	49.38275024013862	-60.81714309839334	43293
857e65cf3cdb4b5f380f0072636f13ccf6a2144f	convolutional neural network for sar image classification at patch level	databases;synthetic aperture radar databases feature extraction support vector machines training neural networks neurons;neural networks;support vector machines;photogrammetrie und bildanalyse;training;final five class softmax convolutional neural network sar image classification patch level benchmark work sar image patches wuhan china;feature extraction;neurons;gpu sar image classification patch level convolutional neural network caffe;synthetic aperture radar neural nets remote sensing;synthetic aperture radar	Convolutional Neural Network (CNN) has attracted much attention for feature learning and image classification, mostly related to close range photography. As a benchmark work, we trained a relatively large CNN to classify SAR image patches into five different categories, where the image patches tiled and annotated from a typical TerraSAR-X spotlight scene of Wuhan, China. The neural network designed in this paper consists of seven layers, including one input layer, two convolutional layers where each followed by a max-pooling layer, as well as two fully-connected layers with a final five-class softmax. Using the toolkit caffe, we achieved the training and testing accuracy of 85.7% and 85.6% respectively, which is considerably better than the traditional feature extraction and classification based SVM method and shows great potential of CNN used for SAR image interpretation. In order to accelerate the training process, a very efficient GPU implementation was employed.	artificial neural network;benchmark (computing);computer vision;convolutional neural network;cylon (reimagining);dbpedia;feature extraction;feature learning;graphics processing unit;softmax function	Juanping Zhao;Weiwei Guo;Shiyong Cui;Zenghui Zhang;Wenxian Yu	2016	2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2016.7729239	support vector machine;computer vision;synthetic aperture radar;feature extraction;computer science;machine learning;pattern recognition;artificial neural network	Vision	27.86506568419711	-54.00035554404189	43309
53d62366d5162dc5ce4e65652ba77df97031b84f	approved hg-cfar method for infrared small target detection	morphological filters;histograms;residual image;image segmentation;object detection filtering theory gaussian distribution image segmentation infrared imaging;constant false alarm rate;hg cfar;estimation algorithm;infrared small target detection;infrared detectors object detection gaussian distribution mercury metals image segmentation infrared imaging filters parameter estimation hardware robustness;infrared image;infrared imaging;pixel;model parameter estimation hg cfar method infrared small target detection constant false alarm rate half side gaussian model target segmentation infrared image residual image morphological filters gaussian distribution;target segmentation;mathematical model;hg cfar method;infrared small target;small target detection;parameter estimation;infrared;target detection;model parameter estimation;half side gaussian model;algorithm design and analysis;gaussian distribution;filtering theory;object detection;infrared small target hg cfar small target detection	An approved CFAR (constant false alarm rate) method based on half side Gaussian model (HG-CFAR) is presented for the target segmentation in infrared image. Firstly, the distribution of the residual image after preprocessing based on morphological filters is exploited. Although widely used and useful, the traditional Gaussian distribution does not appear to be the best choice for modeling the residual images. Half side Gaussian distribution (HG) is adopted to model the residuals since it fits the data better. Then, based on the HG model a new CFAR threshold method called HG-CFAR is proposed. Secondly, a novel algorithm for model parameter estimation is given. The estimation algorithm has at least two merits: one is very simple and efficient can be realized on hardware easily. Another is robust to the number and size of the targets. At last, comparisons are made between HG-CFAR and traditional CFAR based on Gaussian distribution. The results show that the new method is more efficient.	constant false alarm rate;estimation theory;fits;genetic algorithm;preprocessor	Xiao Zhou;Guohua Zhang;Guilin Zhang	2008	2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application	10.1109/PACIIA.2008.329	normal distribution;algorithm design;computer vision;infrared;computer science;pattern recognition;mathematical model;constant false alarm rate;histogram;mathematics;image segmentation;estimation theory;pixel;statistics	Vision	49.519819041290056	-68.30596425481392	43333
d7ad716796658353c3b88067c9abc203927610bd	directional coherence-based spatiotemporal descriptor for object detection in static and dynamic scenes	dominant orientation;object and action detection;space time descriptor;histdo;coherence	This paper presents a simple, yet powerful local descriptor, so-called the histograms of space–time dominant orientations (HiSTDO). Specifically, our HiSTDO is composed of two main components, i.e., the dominant orientation and its coherence, which represents how intensively gradients in the local region are distributed along the space–time dominant orientation. By incorporating them into the histogram, we define it as our HiSTDO descriptor. In contrast to previous methods vulnerable to the presence of the background clutter and the camera noise, our HiSTDO greatly encodes the space–time shape of underlying structures even under such challenging conditions, and it can thus be efficiently applied to various applications (e.g., object and action detection). Experimental results on diverse datasets demonstrate that the proposed descriptor is effective for human action as well as object detection.	approximation algorithm;clutter;data descriptor;gradient;object detection;video	Wonjun Kim;Jae-Joon Han	2016	Machine Vision and Applications	10.1007/s00138-016-0801-7	computer vision;local binary patterns;coherence;gloh;mathematics	Vision	39.75013521475007	-54.65174544045465	43359
d2bbbad402d0e00d13b63f12b90be03b817de6e8	precise segmentation of multiple organs in ct volumes using learning-based approach and information theory	learning-based approach;ct image;multiple organ;diverse ct volume;excellent segmentation accuracy;ct volume;information theory;precise segmentation;diverse source;accurate pelvic organ segmentation;segmentation performance;challenging segmentation problem	In this paper, we present a novel method by incorporating information theory into the learning-based approach for automatic and accurate pelvic organ segmentation (including the prostate, bladder and rectum). We target 3D CT volumes that are generated using different scanning protocols (e.g., contrast and non-contrast, with and without implant in the prostate, various resolution and position), and the volumes come from largely diverse sources (e.g., diseased in different organs). Three key ingredients are combined to solve this challenging segmentation problem. First, marginal space learning (MSL) is applied to efficiently and effectively localize the multiple organs in the largely diverse CT volumes. Second, learning techniques, steerable features, are applied for robust boundary detection. This enables handling of highly heterogeneous texture pattern. Third, a novel information theoretic scheme is incorporated into the boundary inference process. The incorporation of the Jensen-Shannon divergence further drives the mesh to the best fit of the image, thus improves the segmentation performance. The proposed approach is tested on a challenging dataset containing 188 volumes from diverse sources. Our approach not only produces excellent segmentation accuracy, but also runs about eighty times faster than previous state-of-the-art solutions. The proposed method can be applied to CT images to provide visual guidance to physicians during the computer-aided diagnosis, treatment planning and image-guided radiotherapy to treat cancers in pelvic region.	bladder tissue;body dysmorphic disorders;ct scan;computer assisted diagnosis;curve fitting;eighty;genetic heterogeneity;handling (psychology);inference;information theory;intrinsic drive;jensen's inequality;learning disorders;lipomatosis, multiple symmetrical;malignant neoplasms;marginal model;organ;patients;pelvic viscus;protocols documentation;radiotherapy, image-guided;rectum;scanning;shannon (unit);shannon–hartley theorem;silo (dataset);solutions;urinary bladder;biologic segmentation	Chao Lu;Yefeng Zheng;Neil Birkbeck;Jingdan Zhang;Timo Kohlberger;Christian Tietjen;Thomas Boettger;James S. Duncan;Shaohua Kevin Zhou	2012	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-33418-4_57	computer vision;pathology;computer science;scale-space segmentation;anatomy	Vision	43.57361246295027	-78.3960573927966	43371
a8c2c787fb1ab0bbb09a412fe2e52fdb2ea2435f	a fast technique for motion correction in dsa using a feature-based, irregular grid	clinical data;blood vessel;irregular grid;motion correction;human body;clinical practice;digital subtraction angiography	In Medical Image Computing and Computer-Assisted Intervention – MICCAI 1998, W. M. Wells, A. Colchester, S. Delp (eds.), vol. 1496 of Lecture Notes in Computer Science, Springer-Verlag, Berlin, 1998, pp. 590–597. Abstract. In clinical practice, Digital Subtraction Angiography (DSA) is a powerful technique for the visualization of blood vessels in the human body. However, due to patient motion the diagnostic relevance of the images is often reduced by the introduction of artifacts. In this paper, we propose a new approach to the registration of DSA images, which is both effective, and very fast. The computational speed of our algorithm is achieved by applying a gradient based control point selection mechanism, which allows for a more efficient positioning of a reduced number of control points as compared to approaches based on regular grids. The results of preliminary experiments with several clinical data sets clearly show the applicability of the algorithm.	algorithm;artifact (software development);computation;control point (mathematics);delaunay triangulation;displacement mapping;experiment;gradient;graphics hardware;hill climbing;lecture notes in computer science;linear interpolation;mathematical optimization;medical image computing;pixel;real-time clock;relevance;springer (tank);thresholding (image processing);unstructured grid	Erik H. W. Meijering;Karel J. Zuiderveld;Max A. Viergever	1998		10.1007/BFb0056244	computer vision;human body;simulation;medicine;computer science;computer graphics (images)	Vision	45.59929912034818	-75.0112300986002	43431
42b962b3087649944aff71f92252340ff2a9fd0b	using local discriminant topic to improve generative model based image annotation	semantic similarity;discriminant classification automatic image annotation generative model;estimation theory;probability;discriminative classification;generic model;semantic keyword;automatic image annotation;singular value decomposition;image classification;local discriminant topic;image annotation;image generation probability support vector machines labeling information technology support vector machine classification singular value decomposition image retrieval machine learning;eccv2002 benchmark;image retrieval local discriminant topic image annotation statistical generative model visual generative probabilities semantic gap discriminative classification singular value decomposition joint probability semantic keyword unlabeled image estimation eccv2002 benchmark;semantic gap;singular value decomposition estimation theory image classification image retrieval probability;visual generative probabilities;generative model;unlabeled image estimation;statistical generative model;discriminant classification;joint probability;image retrieval	"""Statistical generative model based image annotation propagates the semantic labels of the training images to the unlabeled ones according to their visual generative probabilities. However, it suffers from the problem of """"semantic gap"""", that is, sometimes visual similarity does not reflect semantic similarity. In order to alleviate this problem, we propose a novel image annotation approach which combines the advantages of the generative model and discriminative classification. Based on generative model, we exploit the local discriminants of the visual similar training images (neighborhood) of the unlabeled image. The semantic similar images in the neighborhood are grouped as topics by singular value decomposition (SVD). The discriminative information between different topics is exploited to obtain the semantic relevant topic, which reduces the influence of the images with high visual similarity but irrelevant semantics. Thus, the joint probability of the semantic keyword and the unlabeled image estimated on the obtained relevant topic is more accurate. The experimental results on the ECCV2002 benchmark (P. Duygulu et al., 2002) show that our method outperforms state-of-the-art annotation models MBRM and ASVM-MIL."""	automatic image annotation;benchmark (computing);discriminant;generative model;relevance;semantic similarity;singular value decomposition	Mei Wang;Lan Lin;Xiangdong Zhou	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4517835	contextual image classification;semantic similarity;computer science;machine learning;pattern recognition;probability;mathematics;joint probability distribution;estimation theory;generative model;singular value decomposition;automatic image annotation;information retrieval;semantic gap;statistics	Vision	34.3032237365301	-54.69241787939994	43457
25cf327526012a10429b7c8aefb67760614f9dae	multiple texture mapping of alveolar bone area for implant treatment in prosthetic dentistry	texture mapping;dental implants;bone density;prosthetic dentistry;graph cut algorithm	Treatment using implants is frequently employed in prosthetic dentistry. In this method, determining the bone density of the upper and lower jaws is important. Generally, a dentist can recognize the condition of the alveolar bone to be manipulated using a cone-beam computed tomography (CBCT) image. However, communicating the data to the patient is a challenge because it is difficult for the nonprofessional person to interpret the image, which contains a distribution of pixels with similar density. We present an intuitive texture mapping method of the alveolar bone area for application in implant treatment. Our method aims to help patients better understand the treatment process by using a textured image that includes several different texture patterns that reflect the density of the alveolar bone area. We segment the area in accordance with the density of corresponding parts in the alveolar bone and the gingiva. By simplifying the boundary of each segmented region, the distribution of pixels with similar density on the alveolar bone area can be easily recognized. Next, the texture patterns for several segmented regions are mapped onto the alveolar bone area using the graph-cut algorithm, which is used for smooth texture mapping at the boundary of the segmented region. The result is an applied texture on the alveolar bone area that corresponds to the bone structure. Our method is helpful for facilitating communication and understanding of treatment using dental implants.		Koo-Joo Kwon;Dong-Su Kang;Byeong Seok Shin	2015	Computers in biology and medicine	10.1016/j.compbiomed.2014.11.005	texture mapping;computer science;dentistry;surgery	Graphics	39.14585483978856	-79.78614507106101	43461
c2e68188ce5286dd33bc640b94796b4fd2b172e0	analysis of breast ct lesions using computer-aided diagnosis: an application of neural networks on extracted morphologic and texture features	networks;neural networks;computer aided diagnosis;cancer;breast ct;breast;receivers;artificial neural networks;scanners;matrices;medical diagnostics;biopsy;mammography;structural analysis;quantitative imaging;breast cancer;lesion characterization;artificial neural network;x rays	Dedicated cone-beam breast CT (bCT) scanners have been developed as a potential alternative imaging modality to conventional X-ray mammography in breast cancer diagnosis. As with other modalities, quantitative imaging (QI) analysis can potentially be utilized as a tool to extract useful numeric information concerning diagnosed lesions from high quality 3D tomographic data sets. In this work, preliminary QI analysis was done by designing and implementing a computer-aided diagnosis (CADx) system consisting of image preprocessing, object(s) of interest (i.e. masses, microcalcifications) segmentation, structural analysis of the segmented object(s), and finally classification into benign or malignant disease. Image sets were acquired from bCT patient scans with diagnosed lesions. Iterative watershed segmentation (IWS), a hybridization of the watershed method using observer-set markers and a gradient vector flow (GVF) approach, was used as the lesion segmentation method in 3D. Eight morphologic parameters and six texture features based on gray level co-occurrence matrix (GLCM) calculations were obtained per segmented lesion and combined into multi-dimensional feature input data vectors. Artificial neural network (ANN) classifiers were used by performing cross validation and network parameter optimization to maximize area under the curve (AUC) values of the resulting receiver-operating characteristic (ROC) curves. Within these ANNs, biopsy-proven diagnoses of malignant and benign lesions were recorded as target data while the feature vectors were saved as raw input data. With the image data separated into post-contrast (n = 55) and pre-contrast sets (n = 39), a maximum AUC of 0.70 ± 0.02 and 0.80 ± 0.02 were achieved, respectively, for each data set after ANN application.© (2012) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	artificial neural network	Shonket Ray;Nicolas D. Prionas;Karen K. Lindfors;John M. Boone	2012		10.1117/12.910982	computer vision;breast cancer;structural analysis;artificial neural network;matrix;cancer	AI	34.68240657183143	-77.57090314506017	43490
b16b3dc046a9d1f2116f06e544560aaca04f5a04	brain mri image segmentation based on learning local variational gaussian mixture models	variational bayes inference;image segmentation;magnetic resonance imaging;probabilistic brain atlas	Measuring the distribution of major brain tissues, including the gray matter, white matter and cerebrospinal fluid (CSF), using magnetic resonance imaging (MRI) has attracted extensive research efforts. Many brain MRI image segmentation methods in the literature are based on the Gaussian mixture model (GMM), which however is not strictly followed due to the intrinsic complex nature of MRI data and may lead to less accurate results. In this paper, we introduce the variational Bayes inference to brain MRI image segmentation, and thus propose a novel segmentation algorithm based on learning a cohort of local variational Gaussian mixture (LVGM) models. By assuming all Gaussian parameters to be random variables, the LVGM model has more flexibility than GMM in characterizing the complexity of brain voxel distributions. To alleviate the impact of bias field, we train each LVGM model on a sampled small data volume and linearly combine the trained models to classify each brain voxel. We also construct a co-registered probabilistic brain atlas for each MRI image to incorporate the prior knowledge about brain anatomy into the segmentation process. The proposed LVGM learning algorithm has been evaluated against five state-of-the-art brain MRI image segmentation methods on both synthetic and clinical data. Our results suggest that the LVGM algorithm can segment brain MRI images more effectively and provide more precise distribution of major brain tissues. Keywords—Image segmentation; magnetic resonance imaging; variational Bayes inference; probabilistic brain atlas	algorithm;brain atlas;calculus of variations;google map maker;image segmentation;mixture model;resonance;synthetic intelligence;variational principle;voxel	Yong Xia;Zexuan Ji;Yanning Zhang	2016	Neurocomputing	10.1016/j.neucom.2015.08.125	computer vision;computer science;magnetic resonance imaging;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation;voxel-based morphometry	ML	43.71976829487968	-77.90968726478418	43531
693fd5ebb9e2c5a244c249e5b6bfe5f46b96fd89	estimation of white matter fiber parameters from compressed multiresolution diffusion mri using sparse bayesian learning	compressive sensing;diffusion mri;fiber orientation;linear unmixing;sparse bayesian learning;sparse signal recovery	We present a sparse Bayesian unmixing algorithm BusineX: Bayesian Unmixing for Sparse Inference-based Estimation of Fiber Crossings (X), for estimation of white matter fiber parameters from compressed (under-sampled) diffusion MRI (dMRI) data. BusineX combines compressive sensing with linear unmixing and introduces sparsity to the previously proposed multiresolution data fusion algorithm RubiX, resulting in a method for improved reconstruction, especially from data with lower number of diffusion gradients. We formulate the estimation of fiber parameters as a sparse signal recovery problem and propose a linear unmixing framework with sparse Bayesian learning for the recovery of sparse signals, the fiber orientations and volume fractions. The data is modeled using a parametric spherical deconvolution approach and represented using a dictionary created with the exponential decay components along different possible diffusion directions. Volume fractions of fibers along these directions define the dictionary weights. The proposed sparse inference, which is based on the dictionary representation, considers the sparsity of fiber populations and exploits the spatial redundancy in data representation, thereby facilitating inference from under-sampled q-space. The algorithm improves parameter estimation from dMRI through data-dependent local learning of hyperparameters, at each voxel and for each possible fiber orientation, that moderate the strength of priors governing the parameter variances. Experimental results on synthetic and in-vivo data show improved accuracy with a lower uncertainty in fiber parameter estimates. BusineX resolves a higher number of second and third fiber crossings. For under-sampled data, the algorithm is also shown to produce more reliable estimates.		P. Kumar PramodKumar;Stamatios N. Sotiropoulos;Julio Martin Duarte-Carvajalino;Guillermo Sapiro;Christophe Lenglet	2018	NeuroImage	10.1016/j.neuroimage.2017.06.052	compressed sensing;hyperparameter;prior probability;parametric statistics;k-svd;estimation theory;sparse approximation;pattern recognition;artificial intelligence;bayesian inference;computer science	ML	49.720891449963744	-79.23031775449856	43539
ca69678d3f233f6f5956105e0d63be2423948481	incorporation of regional information in optimal 3-d graph search with application for intraretinal layer segmentation of optical coherence tomography images	graph search;optical coherence tomography;objective function;weighted graph	"""We present a method for the incorporation of regional image information in a 3-D graph-theoretic approach for optimal multiple surface segmentation. By transforming the multiple surface segmentation task into finding a minimum-cost closed set in a vertex-weighted graph, the optimal set of feasible surfaces with respect to an objective function can be found. In the past, this family of graph search applications only used objective functions which incorporated """"on-surface"""" costs. Here, novel """"in-region"""" costs are incorporated. Our new approach is applied to the segmentation of seven intraretinal layer surfaces of 24 3-D macular optical coherence tomography images from 12 subjects. Compared to an expert-defined independent standard, unsigned border positioning errors are comparable to the inter-observer variability (7.8 +/- 5.0 microm and 8.1 +/- 3.6 microm, respectively)."""		Mona Haeker;Xiaodong Wu;Michael D. Abràmoff;Randy Kardon;Milan Sonka	2007	Information processing in medical imaging : proceedings of the ... conference	10.1007/978-3-540-73273-0_50	computer vision;mathematical optimization;mathematics;scale-space segmentation	Vision	41.45345206150404	-79.31446087157474	43544
050cf6ab2c585ba62c8c964df2ec6439fb6cc8fe	retinal vessel segmentation based on fully convolutional neural networks		The retinal vascular condition is a reliable biomarker of several ophthalmologic and cardiovascular diseases, so automatic vessel segmentation may be crucial to diagnose and monitor them. In this paper, we propose a novel method that combines the multiscale analysis provided by the Stationary Wavelet Transform with a multiscale Fully Convolutional Neural Network to cope with the varying width and direction of the vessel structure in the retina. Our proposal uses rotation operations as the basis of a joint strategy for both data augmentation and prediction, which allows us to explore the information learned during training to refine the segmentation. The method was evaluated on three publicly available databases, achieving an average accuracy of 0.9576, 0.9694, and 0.9653, and average area under the ROC curve of 0.9821, 0.9905, and 0.9855 on the DRIVE, STARE, and CHASE DB1 databases, respectively. It also appears to be robust to the training set and to the inter-rater variability, which shows its potential for real-world applications.		Américo Oliveira;Sérgio Pereira;Carlos A. Silva	2018	Expert Syst. Appl.	10.1016/j.eswa.2018.06.034	convolutional neural network;machine learning;artificial intelligence;stationary wavelet transform;training set;segmentation;computer science;pattern recognition	ML	32.42168250717889	-76.3500421547826	43558
f4a143d2f855204820aae8f0db6bd0e1af729679	a parallel fuzzy scale-space approach to the unsupervised texture separation	density gradient;fuzzy gradient;multiple scales;scale space;nonlinear scale space;texture separation	In this paper we consider the problem of unsupervised boundary localization in textured images reporting a parallel texture separation algorithm which extracts textural density gradients by a nonlinear multiple scale-space analysis of the image. The scale-space analysis is modeled by a differential morphological filter, and texture boundaries are extracted by segmenting the images resulting from a multiscale fuzzy gradient operation applied to the detail images, which are the differences between images at successive scales. Experiments and comparisons on Brodatz real textures are reported.	scale space	Michele Ceccarelli;Alfredo Petrosino	2002	Pattern Recognition Letters	10.1016/S0167-8655(01)00151-9	computer vision;scale space;computer science;machine learning;pattern recognition;mathematics	Vision	47.87839335586483	-68.29124059117844	43560
1e436b5d607c47e53897e07ee438c8bb0ba3a3ae	fast, approximately optimal solutions for single and dynamic mrfs	boosting computer vision optimization methods computer science pervasive computing costs computational efficiency inference algorithms;graph theory;optimal solution;pervasive computing;real time;optimal method;dual problem;computer vision;mrf optimization algorithm;boosting;np hard problems;stereoscopic sequences;inference algorithms;graph theory computer vision;weighted graph;computer science;computational efficiency;mrf optimization algorithm np hard problems stereoscopic sequences computer vision weighted graph;optimization methods	A new efficient MRF optimization algorithm, called Fast-PD, is proposed, which generalizes a-expansion. One of its main advantages is that it offers a substantial speedup over that method, e.g. it can be at least 3-9 times faster than a-expansion. Its efficiency is a result of the fact that Fast-PD exploits information coming not only from the original MRF problem, but also from a dual problem. Furthermore, besides static MRFs, it can also be used for boosting the performance of dynamic MRFs, i.e. MRFs varying over time. On top of that, Fast-PD makes no compromise about the optimality of its solutions: it can compute exactly the same answer as a-expansion, but, unlike that method, it can also guarantee an almost optimal solution for a much wider class of NP-hard MRF problems. Results on static and dynamic MRFs demonstrate the algorithm's efficiency and power. E.g., Fast-PD has been able to compute disparity for stereoscopic sequences in real time, with the resulting disparity coinciding with that of a-expansion.	algorithm;binocular disparity;computer vision;cut (graph theory);duality (optimization);markov random field;mathematical optimization;np-hardness;optimization problem;reference frame (video);speedup;stereoscopy	Nikos Komodakis;Georgios Tziritas;Nikos Paragios	2007	2007 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2007.383095	computer vision;mathematical optimization;duality;computer science;graph theory;theoretical computer science;machine learning;np-hard;boosting	Vision	53.64720265047124	-72.8842305386801	43570
92f9fb9916476b4b40a0a99836534a5be023ca99	fast kidney detection and segmentation with learned kernel convolution and model deformation in 3d ultrasound images	databases;template deformation kidney detection segmentation 3d ultrasound support vector machine template matching;kernel;image segmentation;convolution;ultrasonic imaging;support vector machines biomedical ultrasonics convolution deformation image segmentation kidney medical image processing speckle;intuitive interaction functions kidney detection kidney segmentation learned kernel convolution model deformation 3d ultrasound images kidney appearance artifacts shadows speckle noise computation time clinical acceptance support vector machine based detection algorithm model based deformation technique pathologies kidney deformations;three dimensional displays;kidney three dimensional displays image segmentation kernel convolution ultrasonic imaging databases;kidney	We present a method to segment kidneys in 3D ultrasound images. The main challenges are the high variability in kidney appearance, the frequent presence of artifacts (shadows, speckle noise, etc.) and a strong constraint on computation time for clinical acceptance (less than 10 seconds). Our algorithm leverages a database of 480 3D images through a support vector machine(SVM)-based detection algorithm followed by a model-based deformation technique. Since severe pathologies induce strong deformations of kidneys, the proposed method encompasses intuitive interaction functions allowing the user to refine the result with a few clicks. Validation has been performed by learning on 120 cases and testing on 360; a perfect segmentation was reached automatically in 50% of the cases, and in 90% of the cases in less than 3 clicks.	algorithm;computation;convolution;kernel (operating system);spatial variability;support vector machine;time complexity	Roberto Ardon;Rémi Cuingnet;Ketan Bacchuwar;Vincent Auvray	2015	2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2015.7163865	computer vision;kernel;computer science;machine learning;pattern recognition;mathematics;image segmentation;convolution;scale-space segmentation	Vision	40.71587321220209	-79.18559400394716	43584
7f5f425feeff9341a7e61d609abf350512ea1b34	favorite object extraction using web images	shape image segmentation computer vision feature extraction object segmentation prototypes pattern recognition;shape variations favorite object extraction web images object discovery object segmentation natural images shape based common template median graph theory shape descriptor directional shape representation;internet feature extraction graph theory image representation image segmentation	In this paper, we propose a framework to discover and segment favorite object from the natural images. The main idea is to first generate the shape based common template of the favorite object using the images collected from the web. Then, the common template is used to extract the favorite object from the original images. In the common template generation, co-segmentation is used to provide the initial segments. The median graph theory is employed to construct the common template. We also propose a new shape descriptor namely directional shape representation to handle shape variations. We test our method on the images collected from image datasets and web. Experimental results demonstrate the effectiveness of the proposed method.	graph theory;median graph;shape context	Fanman Meng;Bing Luo;Chao Huang;Liangzhi Tang;Bing Zeng;Nini Rao	2014	2014 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2014.6865137	computer vision;computer science;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation	Vision	38.259842562964145	-57.284007854799455	43663
9775dab60bf5312d1946625dce40ca1ea16516b4	incorporating mean template into finite mixture model for image segmentation	probability;image segmentation;probability noise image segmentation robustness approximation methods nickel learning systems;probability image segmentation;weighted arithmetic mean template finite mixture model image segmentation conditional probability mathematical formula prior probability weighted geometric mean template;spatial constraints expectation maximization em algorithm finite mixture model image segmentation mean template	The well-known finite mixture model (FMM) has been regarded as a useful tool for image segmentation application. However, the pixels in FMM are considered independent of each other and the spatial relationship between neighboring pixels is not taken into account. These limitations make the FMM more sensitive to noise. In this brief, we propose a simple and effective method to make the traditional FMM more robust to noise with the help of a mean template. FMM can be considered a linear combination of prior and conditional probability from the expression of its mathematical formula. We calculate these probabilities with two mean templates: a weighted arithmetic mean template and a weighted geometric mean template. Thus, in our model, the prior probability (or conditional probability) of an image pixel is influenced by the probabilities of pixels in its immediate neighborhood to incorporate the local spatial and intensity information for eliminating the noise. Finally, our algorithm is general enough and can be extended to any other FMM-based models to achieve super performance. Experimental results demonstrate the improved robustness and effectiveness of our approach.	algorithm;analog;clinical use template;effective method;fast multipole method;image segmentation;mathematics;median filter;mixture model;normal statistical distribution;pixel;population parameter;probability;segmentation action;whole earth 'lectronic link;algorithm;biologic segmentation;lapatinib	Hui Zhang;Q. M. Jonathan Wu;Thanh Minh Nguyen	2013	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2012.2228227	template matching;computer science;machine learning;pattern recognition;probability;mathematics;image segmentation;scale-space segmentation;statistics	Vision	50.50434304657199	-69.13356528881197	43672
33b43c71f313f201a07a4e1bf9ac79f4168f02cb	feature based nonrigid brain mr image registration with symmetric alpha stable filters	brain;heavy tail;frequency spectrum;feature vector;gabor filter;rotation invariance;mr imaging;magnetic resonance;feature extraction;medical image processing;image registration;nonrigid image registration;brain imaging;orientation selectivity;nonrigid registration;invariant feature;biomedical mri	A new feature based nonrigid image registration method for magnetic resonance (MR) brain images is presented in this paper. Each image voxel is represented by a rotation invariant feature vector, which is computed by passing the input image volumes through a new bank of symmetric alpha stable (S?S) filters. There are three main contributions presented in this paper. First, this work is motivated by the fact that the frequency spectrums of the brain MR images often exhibit non-Gaussian heavy-tail behavior which cannot be satisfactorily modeled by the conventional Gabor filters. To this end, we propose the use of S?S filters to model such behavior and show that the Gabor filter is a special case of the S?S filter. Second, the maximum response orientation (MRO) selection criterion is designed to extract rotation invariant features for registration tasks. The MRO selection criterion also significantly reduces the number of dimensions of feature vectors and therefore lowers the computation time. Third, in case the segmentations of the input image volumes are available, the Fisher's separation criterion (FSC) is introduced such that the discriminating power of different feature types can be directly compared with each other before performing the registration process. Using FSC, weights can also be assigned automatically to different voxels in the brain MR images. The weight of each voxel determined by FSC reflects how distinctive and salient the voxel is. Using the most distinctive and salient voxels at the initial stage to drive the registration can reduce the risk of being trapped in the local optimum during image registration process. The larger the weight, the more important the voxel. With the extracted feature vectors and the associated weights, the proposed method registers the source and the target images in a hierarchical multiresolution manner. The proposed method has been intensively evaluated on both simulated and real 3-D datasets obtained from BrainWeb and Internet Brain Segmentation Repository (IBSR), respectively, and compared with HAMMER, an extended version of HAMMER based on local histograms (LHF), FFD, Demons, and the Gabor filter based registration method. It is shown that the proposed method achieves the highest registration accuracy among the five widely used image registration methods.	abruptio placentae;adrenergic alpha-agonists;authorization;behavior;biasing;brain neoplasms;computation;dimensions;experiment;extraction;feature vector;free-form deformation;gabor filter;hammer;histogram;ieee xplore;image registration;influenza virus a hong kong ab:acnc:pt:ser:qn;large;local optimum;normal statistical distribution;personnameuse - assigned;plant roots;prostheses, dental, fixed, crown, total, temporary;resonance;tail;time complexity;voxel;weight;brain segmentation;registration - actclass	Shu Liao;Albert C. S. Chung	2010	IEEE Transactions on Medical Imaging	10.1109/TMI.2009.2028078	computer vision;frequency spectrum;radiology;feature vector;feature extraction;heavy-tailed distribution;computer science;image registration;magnetic resonance imaging;pattern recognition;mathematics;neuroimaging;computer graphics (images)	Vision	40.65757422547149	-75.04069262532174	43704
a8bc885585317d1b6be6e1ba46fab67fc0542768	using stacked auto-encoder to get feature with continuity and distinguishability in multi-object tracking		Good feature expression of targets plays an important role in multi-object tracking (MOT). Inspired by the self-learning concept of deep learning methods, an online feature extraction scheme is proposed in this paper, based on a conditional random field (CRF). The CRF model is transformed into a certain number of multi-scale stacked auto-encoders with a new loss function. Features obtained with our method contain both continuous and distinguishable characteristics of targets. The inheritance relationship of stacked auto-encoders between adjacent frames is implemented by an online process. Features extracted from our online scheme are applied to improve the network flow tracking model. Experiment results show that the features by our method achieve better performance compared with other handcrafted-features. The overall tracking performance are improved when our features are used in the MOT tasks.	encoder;scott continuity	Haoyang Feng;Peixin Liu;Ning Zhou	2017		10.1007/978-3-319-71607-7_31	computer vision;pattern recognition;autoencoder;artificial intelligence;deep learning;computer science;flow network;feature extraction;video tracking;conditional random field	Robotics	28.845621118154316	-52.093781286112566	43712
3184ffc364fffa50de0dc06d47d8324be82a4c6b	a comparative analysis of retrieval techniques in content based image retrieval		Basic group of visual techniques such as color, shape, texture are used in Content Based Image Retrievals (CBIR) to retrieve query image or sub region of image to find similar images in image database. To improve query result, relevance feedback is used many times in CBIR to help user to express their preference and improve query results. In this paper, a new approach for image retrieval is proposed which is based on the features such as Color Histogram, Eigen Values and Match Point. Images from various types of database are first identified by using edge detection techniques .Once the image is identified, then the image is searched in the particular database, then all related images are displayed. This will save the retrieval time. Further to retrieve the precise query image, any of the three techniques are used and comparison is done w.r.t. average retrieval time. Eigen value technique found to be the best as compared with other two techniques.	color histogram;content-based image retrieval;edge detection;eigen (c++ library);relevance feedback	Mohini P. Sardey;Gajanan K. Kharate	2015	CoRR		image texture;computer vision;feature detection;query expansion;visual word;image processing;image retrieval;computer science;data mining;automatic image annotation;information retrieval	Vision	39.033074683794304	-60.608865356514904	43730
ec0104286c96707f57df26b4f0a4f49b774c486b	an ensemble cnn2elm for age estimation		Age estimation is a challenging task, because it can be easily affected by gender, race, and other intrinsic and extrinsic attributes. At the same time, performing age estimation for a narrow age range may lead to better results. In this paper, to achieve robust age estimation, an ensemble structure referred to as CNN2ELM, which includes convolutional neural network (CNN) and extreme learning machine (ELM), is proposed for age estimation. The three-level system includes feature extraction and fusion, age grouping via an ELM classifier, and age estimation via an ELM regressor. Age-Net, Gender-Net, and Race-Net are trained using different targets, such as age class, gender class, and race class, respectively, and the three networks are used to extract features corresponding to age, gender, and race from the same image of a person during validation and test stages. Features related to the age property are enhanced by fusing these of race and gender properties. Then, to achieve a narrow age range, the ELM classifies the fusion results into one of the age groups. Afterward, an age decision is made using an ELM regressor. Our network is pretrained on an ImageNet database and then fine-tuned on the IMDB–WIKI database. The recently released Adience benchmark, ChaLearn Looking at People 2016 (LAP-2016), and MORPH-II are used to verify the performance of “Race-Net + Age-Net + Gender-Net + ELM classifier + ELM regressor (RAGN).” RAGN outperforms the existing state-of-the-art age estimation methods. The mean absolute error of the age estimation of RAGN for MORPH-II is determined to be 2.61 years; the accuracy of the age estimation for the Adience benchmark is 0.6649; and the normal score ( $\epsilon$ ) for the sequestered test set of the LAP-2016 data set is 0.3679.	approximation error;artificial neural network;benchmark (computing);convolutional neural network;elm;ensemble learning;experiment;feature extraction;imagenet;internet movie database (imdb);race condition;test set;wiki	Mingxing Duan;Keqin Li;Keqin Li	2018	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2017.2766583	artificial intelligence;pattern recognition;robustness (computer science);support vector machine;computer science;convolutional neural network;artificial neural network;extreme learning machine;feature extraction;normal score;test set	AI	28.43631378956202	-58.78519926222128	43787
45e4e5df604f5e0d2112c5b009312da1897bda48	visible and infrared image registration based on visual salient features	sensors;image registration	In order to improve the precision of visible and infrared (VIS/IR) image registration, an image regis- tration method based on visual salient (VS) features is presented. First, a VS feature detector based on the modified visual attention model is presented to extract VS points. Because the iterative, within-feature competi- tion method used in visual attention models is time consuming, an alternative fast visual salient (FVS) feature detector is proposed to make VS features more efficient. Then, a descriptor-rearranging (DR) strategy is adopted to describe feature points. This strategy combines information of both IR image and its negative image to over- come the contrast reverse problem between VIS and IR images, making it easier to find the corresponding points on VIS/IR images. Experiments show that both VS and FVS detectors have higher repeatability scores than scale invariant feature transform in the cases of blurring, brightness change, JPEG compression, noise, and viewpoint, except big scale change. The combination of VS detector and DR registration strategy can achieve precise image registration, but it is time-consuming. The combination of FVS detector and DR registration strat- egy can also reach a good registration of VIS/IR images but in a shorter time. © 2015 SPIE and IS&T (DOI: 10.1117/1. JEI.24.5.053017)	image registration	Feihong Wu;Bingjian Wang;Xiang Yi;Min Li;Jingya Hao;Hanlin Qin;Huixin Zhou	2015	J. Electronic Imaging	10.1117/1.JEI.24.5.053017	computer vision;computer science;sensor;image registration;computer graphics (images)	Vision	44.726206142919416	-55.29050043132237	43800
530caf2eeb790e0a252298057d7a1e1cf83e5724	multi-channel versus quaternion orthogonal rotation invariant moments for color image representation		Abstract Orthogonal rotation invariant moments (ORIMs) have been used in many pattern recognition and image processing applications in the last three decades. Most of the applications relate to monochrome and gray-scale images. Recently, the theory of image moments for gray-scale images has been extended to color images using quaternion moments to explore the benefit of color information while representing the color images by moments. In this paper, we propose multi-channel ORIMs (MORIMs) invariants for color images and compare their performance with the existing quaternion moments, called quaternion orthogonal rotation invariant moments (QORIMs). The theoretical and experimental analysis demonstrates the superiority of the proposed MORIMs over the QORIMs invariants in the color image recognition task. The experiments are conducted by considering Zernike moments (ZMs) and quaternion ZMs (QZMs) as the representatives of MORIMs and QORIMs, respectively.	color image;image moment	Chandan Singh;Jaspreet Singh	2018	Digital Signal Processing	10.1016/j.dsp.2018.04.001	mathematics;artificial intelligence;quaternion;image processing;pattern recognition;computer vision;zernike polynomials;color image;image moment;invariant (mathematics);monochrome;communication channel	Vision	34.70031591380821	-59.449743001265475	43817
e055ca12a0e3175696ae7ffc74e6d57d6eb629a8	hierarchical multi-atlas label fusion with multi-scale feature representation and label-specific patch partition	multi scale feature representation;multi atlas based segmentation;patch based labeling;sparse representation;label specific patch partition	Multi-atlas patch-based label fusion methods have been successfully used to improve segmentation accuracy in many important medical image analysis applications. In general, to achieve label fusion a single target image is first registered to several atlas images. After registration a label is assigned to each target point in the target image by determining the similarity between the underlying target image patch (centered at the target point) and the aligned image patch in each atlas image. To achieve the highest level of accuracy during the label fusion process it's critical for the chosen patch similarity measurement to accurately capture the tissue/shape appearance of the anatomical structure. One major limitation of existing state-of-the-art label fusion methods is that they often apply a fixed size image patch throughout the entire label fusion procedure. Doing so may severely affect the fidelity of the patch similarity measurement, which in turn may not adequately capture complex tissue appearance patterns expressed by the anatomical structure. To address this limitation, we advance state-of-the-art by adding three new label fusion contributions: First, each image patch is now characterized by a multi-scale feature representation that encodes both local and semi-local image information. Doing so will increase the accuracy of the patch-based similarity measurement. Second, to limit the possibility of the patch-based similarity measurement being wrongly guided by the presence of multiple anatomical structures in the same image patch, each atlas image patch is further partitioned into a set of label-specific partial image patches according to the existing labels. Since image information has now been semantically divided into different patterns, these new label-specific atlas patches make the label fusion process more specific and flexible. Lastly, in order to correct target points that are mislabeled during label fusion, a hierarchical approach is used to improve the label fusion results. In particular, a coarse-to-fine iterative label fusion approach is used that gradually reduces the patch size. To evaluate the accuracy of our label fusion approach, the proposed method was used to segment the hippocampus in the ADNI dataset and 7.0 T MR images, sub-cortical regions in LONI LBPA40 dataset, mid-brain regions in SATA dataset from MICCAI 2013 segmentation challenge, and a set of key internal gray matter structures in IXI dataset. In all experiments, the segmentation results of the proposed hierarchical label fusion method with multi-scale feature representations and label-specific atlas patches are more accurate than several well-known state-of-the-art label fusion methods.	alignment;anatomic structures;atlases;cervical atlas;experiment;gray matter;image analysis;iterative method;medical image computing;midbrain structure;n-hydroxysuccinimide s-acetylthioacetate;numerous;personnameuse - assigned;semiconductor industry;serial ata;silo (dataset);biologic segmentation;registration - actclass	Guorong Wu;Minjeong Kim;Gerard Sanroma;Qian Wang;Brent C. Munsell;Dinggang Shen	2015	NeuroImage	10.1016/j.neuroimage.2014.11.025	computer vision;computer science;pattern recognition;sparse approximation;data mining	Vision	42.80304448605608	-77.7273352507662	43820
665b3f2f89ff430c785ca8c292a8f1c6e399318d	multi library wavelet neural networks for 3d face recognition using 3d facial shape representation		This paper presents a new approach for 3D face modeling and recognition. Motivated by finding a representation that embodies a high power of discrimination between face classes, a new type of 3D shape descriptors is suggested. We have developed a fully automatic system which uses an alignment algorithm to register 3D facial scans. In addition, scalability in both time and space is achieved by converting 3D facial scans into compact wavelet metadata. Our system consists in two phases. The first phase is called enrolment composed of 3 steps: data processing, alignment and metadata generating. The metadata generating step is powered by the use of Multi Library Wavelet Neural Networks (MLWNN). The second phase is called Authentication it starts with the calculation of depth distances between a probe and gallery 3D face. A K-Nearest Neighbors (K-NN) technique is used for 3D face classification. The results of this contribution are more interesting, in comparison with some others works, in term of recognition rate using the GavabDB 3D facial database.	artificial neural network;authentication;facial recognition system;k-nearest neighbors algorithm;scalability;shape analysis (digital geometry);three-dimensional face recognition;wavelet	Wael Ben Soltana;Wajdi Bellil;Chokri Ben Amar;Adel M. Alimi	2009	2009 17th European Signal Processing Conference		computer vision;computer science;machine learning;pattern recognition;face hallucination	Vision	35.259911372927164	-60.44146980235472	43872
5e6da76e52e097adbd060597c09f36c91a340ef2	saliency detection using boundary information	saliency propagation;saliency detection;boundary information;期刊论文	Efficient and robust saliency detection is a fundamental problem in computer vision field for its wide applications, such as image segmentation and image retargeting, etc. In this paper, with the aim of uniformly highlighting the salient objects and suppressing the saliency of the background in images, we propose an efficient three-stage saliency detection method. First, boundary prior and connectivity prior are used to generate coarse saliency maps. To suppress the saliency value of the cluttered background, two supergraphs together with the adjacent graph are created so that the saliency of the background regions with similar appearances which are separated by other regions can be reduced effectively. Second, a local context-based saliency propagation is proposed to refine the saliency such that regions with similar features hold similar saliency. Finally, a logistic regressor is learned to combine the three refined saliency maps into the final saliency map automatically. The proposed method improves saliency detection on many cluttered images. The experimental results on two widely used public datasets with pixel accurate salient region annotations show that our method outperforms the state-of-the-art methods.	computer vision;image segmentation;map;object-based language;pixel;precision and recall;receiver operating characteristic;refinement (computing);retargeting;scott continuity;seam carving;software propagation	Beiji Zou;Qing Liu;Zailiang Chen;Shijian Liu;Xiaoyun Zhang	2014	Multimedia Systems	10.1007/s00530-014-0449-y	computer vision;kadir–brady saliency detector;machine learning;pattern recognition	Vision	46.748084950118546	-66.88611022957252	43873
b47c9bada4ba2c623913ba4ccd9bd26291487d77	motion entropy feature and its applications to event-based segmentation of sports video	signal image and speech processing;analisis contenido;change detection;entropia;image segmentation;image processing;video signal processing;procesamiento imagen;segmentation;time series;traitement image;sports video;algorithme;algorithm;content analysis;quantum information technology spintronics;dependance du temps;time dependence;deteccion cambio;entropie;image sequence;segmentation image;serie temporelle;serie temporal;point changement;traitement signal video;secuencia imagen;entropy;detection changement;analyse contenu;analisis semantico;analyse semantique;punto cambio;dependencia del tiempo;segmentacion;change point;sequence image;semantic analysis;algoritmo	An entropy-based criterion is proposed to characterize the pattern and intensity of object motion in a video sequence as a function of time. By applying a homoscedastic error model-based time series change point detection algorithm to this motion entropy curve, one is able to segment the corresponding video sequence into individual sections, each consisting of a semantically relevant event. The proposed method is tested on six hours of sports videos including basketball, soccer, and tennis. Excellent experimental results are observed.	algorithm;approximation algorithm;emoticon;feature extraction;linear model;machine learning;time series	Chen-Yu Chen;Jia-Ching Wang;Jhing-Fa Wang;Yu Hen Hu	2008	EURASIP J. Adv. Sig. Proc.	10.1155/2008/460913	computer vision;entropy;content analysis;image processing;computer science;artificial intelligence;block-matching algorithm;statistics	Vision	45.680594153584224	-57.32359742717074	43896
56019179f8f49e9e1c6c32d0ffa0953d381dfd47	detection of hematopoietic stem cells in microscopy images using a bank of ring filters	phase detection;ring filter;filter bank;stem cells;multiple radius ring shaped templates;quadratic form;filters;microscopy;pattern detection;ring radius;shape;phase contrast microscopy;image edge detection;hscs;medical image processing;quadratic surface;pixel;transforms;pattern recognition;matched filters;robustness;hematopoietic stem cells cell detection ring filter quadratic form;pattern recognition biomedical optical imaging cellular biophysics filters medical image processing;hough transform;stem cells microscopy filter bank phase detection shape matched filters cells biology robustness object detection in vitro;hematopoietic stem cells;correlation;biomedical optical imaging;ring radius hematopoietic stem cells phase contrast microscopy hscs hough transform pattern detection ring filter bank matched filters multiple radius ring shaped templates quadratic surface;matched filter;ring filter bank;cellular biophysics;in vitro;object detection;cells biology;cell detection;hematopoietic stem cell	We present a method for robustly detecting hematopoietic stem cells (HSCs) in phase contrast microscopy images. HSCs appear to be easy to detect since they typically appear as round objects. However, when HSCs are touching and overlapping, showing the variations in shape and appearance, standard pattern detection methods, such as Hough transform and correlation, do not perform well. The proposed method exploits the output pattern of a ring filter bank applied to the input image, which consists of a series of matched filters with multiple-radius ring-shaped templates. By modeling the profile of each filter response as a quadratic surface, we explore the variations of peak curvatures and peak values of the filter responses when the ring radius varies. The method is validated on thousands of phase contrast microscopy images with different acquisition settings, achieving 96.5% precision and 94.4% recall.	filter bank;hough transform;in-phase and quadrature components;matched filter;pattern recognition;sensor	Sungeun Eom;Ryoma Bise;Takeo Kanade	2010	2010 IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2010.5490394	computer vision;computer science;microscopy;mathematics;optics;matched filter	Vision	40.4535165390231	-74.9207800324817	44019
6718fa12a0d00de3d22d70b407053a8d84cf03ec	an iterative refinement dsa image registration algorithm using structural image quality measure	iterative refinement;spline;image registration iterative algorithms image quality biomedical imaging blood vessels signal processing algorithms data mining detectors angiography x ray imaging;mutual information image registration digital subtraction angiography image quality assessment;biomedical imaging;dsa image registration;data mining;digital angiography image;iterative methods;indexes;structural image quality measure;medical image processing;image registration;image quality;pixel;indexation;image quality assessment;mutual information;medical image processing diagnostic radiography image registration iterative methods;ssim index iterative refinement dsa image registration structural image quality measure digital angiography image;similarity measure;ssim index;digital subtraction angiography;diagnostic radiography;blood vessels	This paper proposes a iterative robust algorithm for the registration of digital angiography images. The registration is iteratively refined with the extracted vessel information and the SSIM index is employed as similarity measure. The experimental results show that proposed algorithm yields good global and local registration, and SSIM index outperforms MI as a similarity measure in the DSA image registration.	algorithm;image quality;image registration;iterative method;iterative refinement;refinement (computing);similarity measure;structural similarity	Jiang Wang;Jian Qiu Zhang	2009	2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIH-MSP.2009.33	image quality;medical imaging;spline;database index;computer vision;computer science;image registration;iterative method;mutual information;pixel;statistics	Robotics	42.28118465430776	-76.2173502016554	44102
a92f5bc02fc61abbb5312ba7cc1feab79e9421d3	information theoretic metrics in shot boundary detection	illumination;edge detection;luminance;informacion mutual;metric;intelligence artificielle;deteccion contorno;detection contour;information mutuelle;theoretical analysis;conditional entropy;mutual information;artificial intelligence;metrico;inteligencia artificial;theorie information;eclairement;information theoretic;metrique;information theory;shot boundary detection;alumbrado;entropy condition;teoria informacion;luminancia	A favorable difference metric is crucial to the shot boundary detection (SBD) performance. In this paper, we propose a new set of metrics, information theoretic metrics, to quantitatively measure the changes between frames. It includes image entropy difference, joint entropy, conditional entropy, mutual information and divergence. They all can be used to cut detection. Specially, the image entropy and joint entropy are good clues to fade detection, while mutual information, joint entropy and conditional entropy are less sensitive to illumination variations. The theoretic analysis and experimental results show that they are useful in SBD.	shot transition detection	Wengang Cheng;De Xu;Yiwei Jiang;Congyan Lang	2005		10.1007/11553939_56	information theory and measure theory;joint entropy;edge detection;generalized relative entropy;information diagram;binary entropy function;rényi entropy;transfer entropy;metric;information theory;maximum entropy probability distribution;computer science;principle of maximum entropy;machine learning;pattern recognition;mathematics;luminance;joint quantum entropy;differential entropy;mutual information;cross entropy;maximum entropy spectral estimation;conditional entropy;statistics	Vision	45.58349092484523	-62.50110719757809	44106
569c00adb32209ce9fbacd4aa0f7760031e19b9e	region matching and depth finding for 3d objects in stereo aerial photographs	deteccion borde;vision ordenador;image processing;vision estereoscopica;edge detection;espacio 3 dimensiones;vision stereoscopique;procesamiento imagen;pairing;segmentation;fotografia aerea;traitement image;computer vision;deteccion contorno;detection contour;photographie aerienne;espace 3 dimensions;region;three dimensional space;aerial photograph;vision ordinateur;emparejamiento;stereopsis;appariement;article;detection bord;segmentacion;aerial photography	The method consists of three steps: the local matching according to the similarity of moments, the global matching according to the angle consistency, and the refinement of matched pairs. After the region matching, the depth of objects can be found by stereomapping on the corresponding corners, which are intersections of adjusted straight edge segments. Several experimental results demonstrate that the approach is robust even in the presence of noise and occlusion	aerial photography	Hsi-Jian Lee;Wen-Ling Lei	1990	Pattern Recognition	10.1016/0031-3203(90)90050-U	three-dimensional space;computer vision;region;edge detection;computer science;stereopsis;pairing;segmentation;aerial photography	Vision	49.09664034680346	-58.32602484235228	44129
f2abab1675a87b1e9a0dcbfea005e82d7009fcb1	extraction of building polygons from sar images: grouping and decision-level in the gestalt system	dynamic programming;architectural design;vision ordenador;polygonal shape;programacion dinamica;forma poligonal;high resolution;radar abertura sintetica;forme polygonale;perceptual grouping;dynamic program;psychology;similitude;computer vision;building recognition;haute resolution;sar;object oriented;radar imaging;sar image;similarity;programmation dynamique;alta resolucion;pattern recognition;oriente objet;vision ordinateur;psychologie;imagerie radar;reconnaissance forme;similitud;structural pattern recognition;reconocimiento patron;gestalt perception;orientado objeto;radar ouverture synthetique;psicologia;synthetic aperture radar	The GESTALT-system is a stratified architecture for challenging computer vision tasks. This contribution focuses on the 3rd and 4th layer of it - the grouping and decision layers. As example application building recognition from high resolution SAR-data is presented. The 3rd layer contains an assessment driven perceptual grouping process with any-time capability and flexible control. Important grouping principles such as good continuation and symmetry are utilized. A dynamic programming optimization is used in the final decision and post-processing layer to find closed polygons that describe the outlines of buildings. Further post processing includes polygon editing and consistency enforcement.	computer vision;continuation;dynamic programming;gestalt psychology;image resolution;mathematical optimization;video post-processing	Eckart Michaelsen;Uwe Stilla;Uwe Soergel;Leo J. Doktorski	2008	2008 IAPR Workshop on Pattern Recognition in Remote Sensing (PRRS 2008)	10.1016/j.patrec.2009.10.004	computer vision;synthetic aperture radar;similarity;image resolution;computer science;specific absorption rate;artificial intelligence;similitude;dynamic programming;radar imaging;object-oriented programming;gestalt psychology	Vision	47.49864464881478	-60.77966438774351	44183
05eaabbe8b02d6b6e2701483666017e17c2a7a3e	voxelwise detection of cerebral microbleed in cadasil patients by leaky rectified linear unit and early stopping		It is important to detect cerebral microbleed voxels from the brain image of cerebral autosomal-dominant arteriopathy with subcortical infarcts and Leukoencephalopathy (CADASIL) patients. Traditional manual method suffers from intra-observe and inter-observe variability. In this study, we used the susceptibility weighted imaging (SWI) to scan 10 CADASIL patients and 10 healthy controls. We used slicing neighborhood processing (SNP) to extract “input” and “target” dataset from the 20 brain volumetric images. Afterwards, the undersampling technique was employed to handle the class-imbalanced problem. The single-hidden layer feedforward neural-network with scaled conjugate gradient was used as the classifier. We compared three activation functions: logistic sigmoid (LOSI), rectified linear unit (ReLU), and leaky rectified linear unit (LReLU). Early stopping and K-fold cross validation (CV) was used to avoid overfitting and statistical analysis. In the experiment, we generated 68,847 CMB voxels, and 68,829 non-CMB voxels. We observed that LReLU achieved the best result with a sensitivity of 93.05%, a specificity of 93.06%, and an accuracy of 93.06%. We also observed the effect of early stopping and K-fold CV. We found the optimal number of hidden neuron was 10 by grid searching method. Besides, our method performs better than three state-of-the-art methods. The results show our method is promising. In addition, LReLU is a better activation function that may replace traditional logistic sigmoid function in other applications.	activation function;big data;cloud computing;conjugate gradient method;cross-validation (statistics);deep learning;early stopping;feedforward neural network;heart rate variability;logistic regression;neuron;overfitting;recommender system;rectifier (neural networks);swi-prolog;sensitivity and specificity;sigmoid function;social media;undersampling;voxel;wearable computer;wearable technology	Yudong Zhang;Xiao-Xia Hou;Yi Chen;Hong Chen;Ming Yang;Jiquan Yang;Shuihua Wang	2017	Multimedia Tools and Applications	10.1007/s11042-017-4383-9	voxel;overfitting;computer science;early stopping;cross-validation;statistics;artificial intelligence;pattern recognition;susceptibility weighted imaging;undersampling;activation function;rectifier (neural networks)	ML	29.39269788639574	-77.62312544492214	44200
ddb06105111fcc8880c1f6a1441e9dd5ae46a28a	text localization in web images using probabilistic candidate selection model	histograms;web image text extraction text localization;image segmentation;web image;local binary pattern histogram fourier feature text localization probabilistic candidate selection model multimedia content web image information extraction multicolor text regions text extraction algorithm gaussian mixture model triangulation bayesian probabilistic model histogram of oriented gradient;gaussian processes;bayes methods;text analysis;text extraction;data mining;histograms feature extraction image segmentation probabilistic logic image color analysis computational modeling data mining;computational modeling;text analysis bayes methods feature extraction fourier analysis gaussian processes gradient methods internet mesh generation;internet;image color analysis;feature extraction;gradient methods;text localization;fourier analysis;probabilistic logic;mesh generation	Web has become increasingly oriented to multimedia content. Most information on the web is conveyed from images. Text localization in web image plays an important role in web image information extraction and retrieval. Current works on text localization in web images assume that text regions are in homogenous color and high contrast. Hence, the approaches may fail when text regions are in multi-color or imposed in complex background. In this paper, we propose a text extraction algorithm from web images based on the probabilistic candidate selection model. The model firstly segments text region candidates from input images using wavelet, Gaussian mixture model (GMM) and triangulation. The likelihood of a candidate region containing text is then learnt using a Bayesian probabilistic model from two features, namely, histogram of oriented gradient (HOG) and local binary pattern histogram Fourier feature (LBP-HF). Finally best candidate regions are integrated to form text regions. The algorithm is evaluated using 155 non-homogenous web images containing around 600 text regions. The results show that the proposed model is able to extract text regions from non-homogenous images effectively.	algorithm;belief propagation;binary pattern (image generation);color image;google map maker;gradient;image;information extraction;lazy evaluation;local binary patterns;mixture model;naive bayes classifier;naivety;pattern recognition;statistical model;super smash bros.;super-resolution imaging;wavelet	Liangji Situ;Ruizhe Liu;Chew Lim Tan	2011	2011 International Conference on Document Analysis and Recognition	10.1109/ICDAR.2011.273	mesh generation;text mining;the internet;feature extraction;computer science;machine learning;pattern recognition;data mining;gaussian process;histogram;image segmentation;fourier analysis;probabilistic logic;computational model;statistics	Vision	38.48712955794464	-62.112043770329166	44208
34e7ad79725a6a6477b0ae4b340d8aaf0c5de7e6	unsupervised image segmentation using a colony of cooperating ants	image segmentation;ant colony optimization;search space;combinatorial optimization problem;image;segmentation;objective function;optimization problem;max min ant system;clustering;local minima	In this paper, we present a novel method for unsupervised image segmentation. Image segmentation is cast as a clustering problem, which aims to partition a given set of pixels into a number of homogenous clusters, based on a similarity criterion. The clustering problem is a difficult optimization problem for two main reasons: first the search space of the optimization is too large, second the clustering objective function is typically non convex and thus may exhibit a large number of local minima. Ant Colony Optimization is a recent multi-agent approach based on artificial ants for solving hard combinatorial optimization problems. We propose the use of the Max-Min Ant System (MMAS) to solve the clustering problem in the field of image segmentation. Each pixel within the image is mapped to its closest cluster taking into account its immediate neighborhood. The obtained results are encouraging and prove the feasibility of the proposed algorithm.	algorithm;ant colony optimization algorithms;artificial ants;cluster analysis;combinatorial optimization;image segmentation;mathematical optimization;maxima and minima;multi-agent system;optimization problem;pixel	Salima Ouadfel;Mohamed Batouche	2002		10.1007/3-540-36181-2_11	correlation clustering;optimization problem;mathematical optimization;artificial intelligence;machine learning;segmentation-based object categorization;mathematics;image segmentation;scale-space segmentation;metaheuristic	ML	44.59571424645465	-68.95354174732246	44223
89181938d8776d59b63546e26df495e3836c2eee	exploration and visualization of segmentation uncertainty using shape and appearance prior information	histograms;time varying;probability;image segmentation;visualization tool;interaction analysis;interactive analysis;transfer functions;appearance knowledge;expert segmented image;training;appearance prior information;prior information;contextual information;biomedical imaging;shape recognition;shape image segmentation training probabilistic logic biomedical imaging histograms transfer functions;shape recognition data visualisation image segmentation medical image processing probability;functional imaging;data visualisation;time varying functional imaging dataset segmentation uncertainty appearance prior information interactive analysis visualization tool probabilistic segmentation medical imaging data exploration shape appearance knowledge expert segmented image multidimensional transfer function widget multivariate probabilistic field data population statistics;shape;medical image;algorithms brain brain diseases computer graphics computer simulation humans imaging three dimensional magnetic resonance imaging positron emission tomography;transfer function;probabilistic segmentation uncertainty visualization medical imaging;medical image processing;medical imaging;multidimensional transfer function widget;field data;segmentation uncertainty;data exploration;probabilistic logic;probabilistic segmentation;multivariate probabilistic field data;uncertainty visualization;time varying functional imaging dataset;population statistics	We develop an interactive analysis and visualization tool for probabilistic segmentation in medical imaging. The originality of our approach is that the data exploration is guided by shape and appearance knowledge learned from expert-segmented images of a training population. We introduce a set of multidimensional transfer function widgets to analyze the multivariate probabilistic field data. These widgets furnish the user with contextual information about conformance or deviation from the population statistics. We demonstrate the user's ability to identify suspicious regions (e.g. tumors) and to correct the misclassification results. We evaluate our system and demonstrate its usefulness in the context of static anatomical and time-varying functional imaging datasets.	abnormal behavior;atlases;cervical atlas;columbia (supercomputer);computation;computational mathematics;conformance testing;dimercaprol;functional imaging;imagery;medical imaging;natural science disciplines;neoplasms;positrons;radiology;transfer function;wdfy2 wt allele;x-ray computed tomography;algorithm;biologic segmentation	Ahmed Saad;Ghassan Hamarneh;Torsten Möller	2010	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2010.152	medical imaging;computer vision;radiology;computer science;machine learning;data mining;mathematics;transfer function;statistics	Visualization	43.238964313847006	-76.90406039976519	44242
0db935561c4ce244dbe011b7604830a84e5bc494	image segmentation with superpixel-based covariance descriptors in low-rank representation		This paper investigates the problem of image segmentation using superpixels. We propose two approaches to enhance the discriminative ability of the superpixel’s covariance descriptors. In the first one, we employ the Log-Euclidean distance as the metric on the covariance manifolds, and then use the RBF kernel to measure the similarities between covariance descriptors. The second method is focused on extracting the subspace structure of the set of covariance descriptors by extending a low rank representation algorithm on to the covariance manifolds. Experiments are carried out with the Berkly Segmentation Dataset, and compared with the state-of-the-art segmentation algorithms, both methods are competitive.	algorithm;distance (graph theory);distortion;euclidean distance;experiment;image segmentation;low-rank approximation;radial basis function kernel	Xianbin Gu;Jeremiah D. Deng;Martin K. Purvis	2016	CoRR		matérn covariance function;computer vision;covariance intersection;machine learning;pattern recognition;mathematics;scale-space segmentation;rational quadratic covariance function	Vision	34.89931235764793	-57.23111811409364	44270
e3745a1a05ef5d7980e8a69f6df2f2c37496b67a	unsupervised speech text localization in comic images	bayesian classifier;bayesian classifier text localization text line generation font set hypothesis test;speech synthesis;bayes methods;speech standards image color analysis algorithm design and analysis mobile handsets speech recognition training data;image classification;speech synthesis bayes methods image classification mobile computing;bayesian classifier unsupervised speech text localization method comic images mobile devices character concurrence character string generation;text localization;text line generation;mobile computing;font set;hypothesis test	Localizing speech texts in comic images is a crucial step for catering the growing needs of reading comics on mobile devices. For example, automatically reading speech texts while adding sound effects alongside can not only render comic contents vividly but also help visually impaired readers. Unlike conventional text localization methods, we present an effective unsupervised speech text localization method in this paper that is free of training data. The proposed method consists of two major stages: (1) based on the concurrence of characters, the first stage of our method is to generate some of the character strings (a row or column of characters that align horizontally or vertically) from the comic images while the fonts and gaps of the adjacent characters within the character string are also obtained, (2) in the second stage, the obtained fonts and gaps of adjacent characters are used to detect rest of the character strings within the comic image via Bayesian classifier. The proposed method is tested on a dataset consists of 1000 comic images from ten printed comic series and provide satisfactory results.	align (company);bayesian network;internationalization and localization;mobile device;naive bayes classifier;printing;sensor;string (computer science)	Luyuan Li;Yongtao Wang;Zhi Tang;Xiaoqing Lu;Liangcai Gao	2013	2013 12th International Conference on Document Analysis and Recognition	10.1109/ICDAR.2013.241	natural language processing;computer vision;statistical hypothesis testing;contextual image classification;naive bayes classifier;speech recognition;computer science;machine learning;pattern recognition;mobile computing;speech synthesis	Robotics	34.520504559589014	-65.86063372585593	44288
370166affbb09cf5327fe782b4379d2b82fc0e9b	noise adaptive fcm algorithm for segmentation of mri brain images using local and non-local spatial information	image segmentation;pattern clustering brain image denoising image filtering image segmentation magnetic resonance imaging medical image processing;image segmentation classification algorithms silicon standards nickel matlab;rician noise;magnetic resonance image;non local spatial information noise adaptive fcm algorithm mri brain image segmentation nonlocal spatial information fuzzy c means clustering algorithm image processing applications fcm algorithm sensitivity nonlocal information extraction adaptive filtering parameter mfcm;non local spatial;fuzzy c means;rician noise image segmentation fuzzy c means magnetic resonance image non local spatial	Image segmentation is an important task in many image processing applications. Fuzzy C means clustering algorithm has been widely used for the segmentation. There are so many extended versions of the traditional FCM algorithm which utilizes the local spatial information to decrease the sensitivity of FCM algorithm to noise, but all these algorithms fail to segment the images heavily contaminated by noise. In order to overcome this problem, non-local spatial information is extracted from the image. During the extraction of non-local information, the filtering parameter h is a crucial parameter which needs to be appropriately determined. Instead of using a constant value of h, it can be adaptively determined using the standard deviation of noise present in the image and the non local information calculated by using this adaptive filtering parameter h is termed as noise adaptive non local spatial information. This property of adaptively determining the filtering parameter is utilized in the FCM algorithm, which uses both the local and non local spatial information (MFCM) for the segmentation of MRI images. In this paper Modified FCM algorithm (MFCM) using the noise adaptive non-local information is proposed. This algorithm is called Noise adaptive FCM algorithm for segmentation of MRI brain images using local and non-local spatial information. The trade off parameter which controls the trade-off between the two spatial information is also calculated using the non local spatial information, making it also adaptive in accordance with filtering parameter. Therefore the proposed algorithm adaptively utilizes both the local and non local information making it more robust against the noise as well as preserving the image details. The efficiency of the proposed algorithm is demonstrated by validation studies on synthetic as well as simulated brain MRI images. The results of the proposed algorithm show that the proposed algorithm is very robust to noise and other image artifacts as compared to other state of the art algorithms.	adaptive filter;algorithm;brain simulation;cluster analysis;database;emoticon;fuzzy cognitive map;geographic information system;image processing;image segmentation;loss function;norm (social);optimization problem;similarity measure;smoothing;synthetic intelligence;visual artifact	Nitesh Arora;Rajoo Pandey	2015	2015 15th International Conference on Intelligent Systems Design and Applications (ISDA)	10.1109/ISDA.2015.7489187	image texture;computer vision;computer science;magnetic resonance imaging;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation	Vision	43.73799196808866	-72.62002965809562	44305
4e1e0b8381c3e8380565a872d9f3d9449b6a816b	image retrieval based on co-occurrence matrix using block classification characteristics	analisis coocurrencia;busqueda informacion;metodo adaptativo;analyse cooccurrence;metodo vectorial;saturacion;multimedia;image processing;recherche image;information retrieval;extraction forme;luminance;gradiente;procesamiento imagen;image classification;methode adaptative;gradient;cooccurrence analysis;traitement image;feature vector;histogram;histogramme;extraccion forma;recherche information;vector method;adaptive method;classification image;methode vectorielle;content based image retrieval;histograma;content based retrieval;pattern extraction;saturation;recherche par contenu;co occurrence matrix;image retrieval;luminancia	A new method of content-based image retrieval is presented that uses the color co-occurrence matrix that is adaptive to the classification characteristics of the image blocks. In the proposed method, the color feature vectors are extracted according to the characteristics of the block classification after dividing the image into blocks with a fixed size. The divided blocks are then classified as either luminance or color blocks depending on the average saturation of the block in the HSI (hue, saturation, and intensity) domain. Thereafter, the color feature vectors are extracted by calculating the co-occurrence matrix of a block average intensity for the luminance blocks and the co-occurrence matrix of a block average hue and saturation for the color blocks. In addition, block directional pattern feature vectors are extracted by calculating histograms after directional gradient classification of the intensity. Experimental results show that the proposed method can outperform conventional methods as regards a precision and a feature vector dimension.	co-occurrence matrix;document-term matrix;image retrieval	Tae-Su Kim;Seung-Jin Kim;Kuhn-Il Lee	2005		10.1007/11581772_83	computer vision;contextual image classification;speech recognition;feature vector;image processing;image retrieval;computer science;pattern recognition;histogram;mathematics;luminance;gradient;saturation;co-occurrence matrix	Vision	43.82471643560032	-61.43628746749917	44323
6fb152ac6c8181be261bfaea536174ff543f1712	on combination of face authentication experts by a mixture of quality dependent fusion classifiers	weighted averaging;face verification;system performance;image quality;quality measures	Face as a biometric is known to be sensitive to different fact ors, e.g., illumnation condition and pose. The resultant degradation in face image qua lity affects the system performance. To counteract this problem, we investigate the merit of comb ining a set of face verification systems incorporating image-related quality measures. We pro pose a fusion paradigm where the quality measures are quantised into a finite set of discrete quality states , e.g., “good illumnation vs. “bad illumination”. For each quality state, we desi gn a fusion classifier. The outputs of these fusion classifiers are then combined by a weighted aver aging controlled by thea posteriori probability of a quality state given the observed quality me asures. The use of quality states in fusion is compared to the direct use of quality measures wher e the density of scores and quality are jointly estimated. There are two advantages of using qua lity states. Firstly, much less traning data is needed in the former since the relationship between b ase classifier output scores and quality measures is not learnt jointly but separately via the con ditioning quality states. Secondly, the number of quality states provides an explicit controlover the complexity of the resulting fusion classifier. In all our experiments involving XM2VTS good and darken face data sets, there is a systematicimprovement in performance over the baseline method (witho ut using quality information) and the direct use of quality in two types of applicat ions: as a quality-dependent score normalisation procedure and as a quality-dependent classi fication method.	algorithm;authentication;baseline (configuration management);biometrics;comb filter;elegant degradation;experiment;naruto shippuden: clash of ninja revolution 3;overfitting;pose (computer vision);programming paradigm;resultant;statistical classification	Norman Poh;Guillaume Heusch;Josef Kittler	2007		10.1007/978-3-540-72523-7_35	engineering;machine learning;pattern recognition;data mining	Vision	27.15122345657872	-66.219587454533	44325
18cc2aa8e62c9c45c82dbb145590b1dda1878d46	some charactistical aspects of markread-a software package for automatic mark data entry	image recognition;object recognition;information technology;software packages optical character recognition software object detection information technology ordinary magnetoresistance image processing knowledge engineering image databases spatial databases character recognition;business forms mark scanning equipment object recognition pattern matching image recognition;pattern matching;business forms;software package;geometrical object detection markread software package automatic mark data entry information technology form recognition results database geometrical object isolation form pattern matching optical mark recognition image skew detection margin detection;mark scanning equipment	Automatic data entry plays an important role for improving speed and effectiveness for information technology. In order to recognize forms and join results into a database, it is necessary to correctly isolate geometrical objects and match forms with a pattern. Therefore, this paper presents some difficult problems of optical mark recognition such as detecting image skew, margins and basic geometrical objects, which are solved in the process of developing MarkRead, a software package for automatic mark data entry.		Ngo Quoc Tao;Do Nang Toan	2002		10.1109/APCCAS.2002.1115294	computer vision;intelligent character recognition;computer science;cognitive neuroscience of visual object recognition;pattern matching;data mining;database;information technology	NLP	34.75939131820444	-66.16100106559087	44331
2a9bb9c67698f1c3263c4260d5098e64f9e33c6d	transformational invariance - a primer	analisis imagen;curva;vision ordenador;detection forme;plane curve;theoretical framework;reference frame;invarianza;model based vision;courbe;shape detection;curve;computer vision;invariance;descripteur forme;deteccion forma;recognition;shape;indexation;pattern recognition;superficie;surface;image analysis;vision ordinateur;reconnaissance forme;reconocimiento patron;analyse image;curves and surfaces;coordinate system	The shape of objects seen in images depends on the viewpoint. This effect confounds recognition. We demonstrate a theoretical framework within which it is possible to construct descriptors for both curves and surfaces, which do not vary with viewpoint. These descriptors are known as invariants. We use this framework to construct invariant shape descriptors for plane curves. These invariant shape descriptors make it possible to recognise plane curves, without explicitly determining the relationship between the curve reference frame and the camera coordinate system, and can be used to index quickly and efficiently into a large model base of curves. Many of these ideas are demonstrated by experiments on real image data.	primer;transformational grammar	David A. Forsyth;Joseph L. Mundy;Andrew Zisserman	1992	Image Vision Comput.	10.1016/0262-8856(92)90082-E	reference frame;computer vision;plane curve;image analysis;shape;invariant;coordinate system;mathematics;geometry;curve;surface;computer graphics (images)	Vision	48.65656182271161	-59.88832357054864	44343
95927733e640e83ff6d1a59e861361bfe76eb386	computer vision based methods for detecting weeds in lawns	lawn;computer vision;morphology;high voltage;detection rate;bayes classifier;weeding	In this paper, two methods for detecting weeds in lawns using computer vision techniques are proposed. The first is based on an assumption about the differences in statistical values between the weed and grass areas in edge images and using Bayes classifier to discriminate them. The second also uses the differences in texture between both areas in edge images but instead applies only simple morphology operators. Correct weed detection rates range from 77.70 to 82.60% for the first method and from 89.83 to 91.11% for the second method. From the results, the methods show the robustness against lawn color change. In addition, the proposed methods together with a chemical weeding system as well as a non-chemical weeding system based on pulse high voltage discharge are simulated and the efficiency of the overall systems are evaluated theoretically. With a chemical based system, more than 72% of the weeds can be destroyed with a herbicide reduction rate of 90–94% for both methods. For the latter weeding system, killed weed rate varies from 58 to 85%.	computer vision;discharger;mathematical morphology;naive bayes classifier;robustness (computer science);sensor	Ukrit Watchareeruetai;Yoshinori Takeuchi;Tetsuya Matsumoto;Hiroaki Kudo;Noboru Ohnishi	2006	2006 IEEE Conference on Cybernetics and Intelligent Systems	10.1007/s00138-006-0039-x	computer vision;bayes classifier;simulation;morphology;computer science;high voltage;machine learning;lawn	Vision	37.519445675120515	-69.0559377578346	44438
237aa061c42643ecba44d2cb11c0f060093687a2	image visual saliency feature extraction based on multi-scale tensor space		In view of the traditional saliency detection method gets imprecise and vague region boundary, so that the detected object is not connected, the paper proposes image visual saliency feature extraction based on multi-scale tensor space. The method introduces the tensor space, using multiple low-level image features to construct the tensor space, after reducing dimension the image space structure and correlation features are preserved, making the detected object connective, which is beneficial to feature extraction and target detection, at last the features uncertainty weights are calculated for total saliency feature fusion. The experimental results show that the algorithm of feature extraction proposed in this paper is closer to the real object and achieves better results.	feature extraction	Shimin Wang;Wenyan Jiang;Jihua Ye;Mingwen Wang;Xinyu Zhou	2017		10.1109/CSE-EUC.2017.31	feature (computer vision);tensor;feature extraction;structure tensor;salience (neuroscience);stress (mechanics);computer vision;feature detection (computer vision);mathematics;pattern recognition;artificial intelligence;correlation	Vision	38.749248230978516	-55.37291339543045	44485
23a5adbad1736e82f0c0f3c19c72624dccc7ecf1	automatic recognition of bidimensional models learned by grammatical inference in outdoor scenes	comunicacion de congreso;automatic generation;a priori knowledge;pattern recognition;grammatical inference;pattern recognition systems	Automatic generation of models from a set of positive and negative samples and a-priori knowledge (if available) is a crucial issue for pattern recognition applications. Grammatical inference can play an important role in this issue since it is one of the methodologies that can be used to generate the set of model classes, where each class consists on the rules to generate the models. In this paper we present the recognition methodology to identify models in a outdoor scenes generated through a grammatical inference process. We will summarize how the set of model classes are generated and will explain the recognition process. An example of traffic sign identification will be shown.	grammar induction;pattern recognition	Alberto Sanfeliu;Miguel Sainz	1996		10.1007/3-540-61577-6_17	natural language processing;feature;computer science;machine learning;pattern recognition	Vision	42.21226288307008	-62.97040088988112	44501
2f790bf238f7ba45d64a504cfb9d3e91b4054322	constructing a hierarchical structure from symbol alphabets of technical line drawings	pattern clustering;structure of symbol alphabets hierarchical shape clustering technical line drawings;image matching;structure of symbol alphabets;pattern clustering image matching image retrieval;technical line drawings;symbol recognition spotting contest symbol alphabet analysis technical line drawings symbol dissimilarity hierarchical technical symbol structure agglomerative hierarchical clustering symbol similarity measure geometric matching symbol shape descriptor symbol spotting systems symbol recognition systems scalability;vectors shape databases accuracy text analysis visualization;hierarchical shape clustering;image retrieval	This paper presents a method for analysing symbol alphabets of technical line drawings and finding their underlying structure, which is important for investigating (dis)similarity of different symbols. The proposed method constructs a hierarchical structure of a set of technical symbols. The method is based on agglomerative hierarchical clustering that uses either of two variants as a similarity measure: either geometric matching between symbols' shapes, or an off-the-shelf shape descriptor. Identifying such a hierarchical structure of a set of symbols can improve symbol recognition / spotting systems, as it helps with scalability issues, and provides information on the degree of similarity among symbols, so that those systems can automatically adapt their parameter values for more accurate recognition. Our method has been tested on the symbol alphabet of the symbol recognition / spotting contest of GREC-2011, and achieved promising results.	ampersand;cluster analysis;feature learning;hierarchical clustering;hough transform;information;machine learning;scalability;similarity measure;vocabulary	Nibal Nayef;Thomas M. Breuel	2013	2013 12th International Conference on Document Analysis and Recognition	10.1109/ICDAR.2013.158	speech recognition;image retrieval;computer science;machine learning;pattern recognition	Robotics	38.78983054438961	-58.721045052243205	44580
0a501cf66cac252f2ce90fd6e608ef29aa286c92	biomarker selection system, employing an iterative peak selection method, for identifying biomarkers related to prostate cancer	mass spectrometry;spectrum;biomarker selection;classification;estimation algorithm;national cancer institute;prostate cancer	A biomarker selection system is proposed for identifying biomarkers related to prostate cancer. MS-spectra were obtained from the National Cancer Institute Clinical Proteomics Database. The system comprised two stages, a preprocessing stage, which is a sequence of MS-processing steps consisting of MSspectrum smoothing, novel iterative peak selection, peak alignment, and a classification stage employing the PNN classifier. The proposed iterative peak selection method was based on first applying local thresholding, for determining the MS-spectrum noise level, and second applying an iterative global threshold estimation algorithm, for selecting peaks at different intensity ranges. At each global threshold, an optimum sub-set of these peaks was used to design the PNN classifier for highest performance, in discriminating normal cases from cases with prostate cancer, and thus indicate the best m/z values. Among these values, the information rich biomarkers 1160.8, 2082.2, 3595.9, 4275.3, 5817.3, 7653.2, that have been associated with the prostate gland, are proposed for further investigation.	algorithm;iteration;iterative method;naive bayes classifier;noise (electronics);preprocessor;proteomics;smoothing;thresholding (image processing)	Panagiotis Bougioukos;Dionisis A. Cavouras;Antonis Daskalakis;Ioannis Kalatzis;Spiros A. Kostopoulos;Pantelis Georgiadis;George Nikiforidis;Anastasios Bezerianos	2007		10.1007/978-3-540-74272-2_25	spectrum;mass spectrometry;biological classification;bioinformatics;data mining;statistics	Comp.	37.444313547137234	-72.86840036076268	44608
a82bfd0b57fda5b0cf141bf014ad1f52ed46f4eb	on a high-speed hough transform algorithm mrht	hough transform	Line detection using IIor~gh transform is one of the robust image processing methods for noisy images. Hut Hough t,ransform has a problem whose computation cost is very large in general. In order to ease this problem, many high-speed algorithms had been proposed. In this paper, we propose a new high-speed algorithm called MRHT (Multiple Randomized Hough Transform) which combines randomized edge point selection process of RHT and block division process of CIIT. And we clarify experimentally and theoretically that the MRHT is faster than RHT and CHT.	computation;edge detection;experiment;image processing;randomized hough transform;randomized algorithm	Kunihito Kato;Toshio Endo;Kazuhito Murakami;Takashi Toriu;Hiroyasu Koshimizu	1998			computer vision;artificial intelligence;mathematics;lock (computer science);permutation;slider;acoustics;scale-invariant feature transform;hough transform	Vision	39.70069112481674	-65.80894556416321	44668
12fa86bdb5a45ec80709faf99ffb10904336fd7d	a novel approach to extract sublingual vein from color image	s component sublingual vein color image tongue characteristics traditional chinese medicine diagnosis tongue surface feature extraction spatial characteristics hsi color space h component;h component;traditional chinese medicine;color space;color;biological organs;biomedical imaging;veins;null;data mining;sublingual vein;physics;healthy subjects;traditional chinese medicine diagnosis;veins color tongue biomedical imaging data mining feature extraction medical diagnostic imaging space technology physics image analysis;feature extraction;s component;tongue;tongue characteristics;spatial characteristics;image analysis;space technology;biomedical optical imaging blood vessels biological organs;tongue surface feature extraction;biomedical optical imaging;hsi color space;blood vessels;color image;medical diagnostic imaging	Characteristics of tongue pose the most important information for traditional Chinese medicine diagnosis. So far, extensive studies have been made on extracting tongue surface features, but rarely refer to sublingual vein that is also diagnostically important. This paper presents a novel approach to extract spatial characteristics of sublingual vein based on the HSI color space using the H and S components. Sublingual vein structures have been successfully mapped for 113 out of 150 patients and healthy subjects.	color image;color space;horizontal situation indicator	Kuanquan Wang;Zifei Yan;Henggui Zhang	2005	18th IEEE Symposium on Computer-Based Medical Systems (CBMS'05)	10.1109/CBMS.2005.15	medical imaging;traditional chinese medicine;computer vision;image analysis;medicine;color image;pathology;feature extraction;computer science;space technology;color space	Embedded	36.00773171725883	-72.57950518681787	44771
99e86d3ea923e7221a3f837678d21b17dd08d9b6	extraction of individual filaments from 2d confocal microscopy images of flat cells	dna;centerline localization;microscopy confocal;image segmentation;image resolution;bifurcation;molecular imaging;microscopy;actin cytoskeleton;biology;image processing computer assisted;biological filament networks;microscopy image resolution bifurcation image segmentation biology three dimensional displays estimation;filament extraction;wounds biomedical optical imaging cancer cellular biophysics feature extraction image enhancement integer programming medical image processing optical microscopy tumours;estimation;three dimensional displays;individual filament extraction biological tissues integer programming based set combination reverse diffusion based filament localization filament enhancement step filament length distribution cellular cytoskeletal network cancer metastases wound healing flat cells 2d confocal microscopy images;filament extraction biological filament networks local network topology centerline localization;local network topology;algorithms;humans;computer simulation	A crucial step in understanding the architecture of cells and tissues from microscopy images, and consequently explain important biological events such as wound healing and cancer metastases, is the complete extraction and enumeration of individual filaments from the cellular cytoskeletal network. Current efforts at quantitative estimation of filament length distribution, architecture and orientation from microscopy images are predominantly limited to visual estimation and indirect experimental inference. Here we demonstrate the application of a new algorithm to reliably estimate centerlines of biological filament bundles and extract individual filaments from the centerlines by systematically disambiguating filament intersections. We utilize a filament enhancement step followed by reverse diffusion based filament localization and an integer programming based set combination to systematically extract accurate filaments automatically from microscopy images. Experiments on simulated and real confocal microscope images of flat cells (2D images) show efficacy of the new method.	body tissue;cytoskeletal filaments;cytoskeleton;inference;integer (number);integer programming;microscope device component;microscopy, atomic force;neoplasms;algorithm	Saurav Basu;Chi Liu;Gustavo K. Rohde	2015	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2014.2372783	computer simulation;computer vision;estimation;image resolution;computer science;microscopy;image segmentation;molecular imaging;genetics;dna;statistics	Comp.	40.37282075274997	-73.97381404066911	44779
6111ddc38df5faf677c5c2a6ed9672816314ee2f	a method for interactive shape detection in cattle images using genetic algorithms	energy function;fixed point;success rate;genetic algorithm;deformable model;point distribution model	Segmentation methods based on deformable models have proved to be successful with difficult images, particularly those using genetic algorithms to minimize the energy function. Nevertheless, they are normally conceived as fully automatic, and not always generate satisfactory results. In this work, a method to include the information of fixed points whithin a contour detection system using point distribution models and genetic algorithms is presented. Also, an interactive scheme is proposed to take advantage of this technique. The method has been tested against a database of 93 cattle images, with a significant improvement in the success rate of the detections, from 61% up to 95%.	genetic algorithm	Horacio M. González Velasco;Carlos J. García Orellana;Miguel Macías Macías;Ramón Gallardo Caballero;Fernando J. Álvarez-Franco	2007		10.1007/978-3-540-74272-2_86	point distribution model;computer vision;mathematical optimization;simulation;genetic algorithm;computer science;mathematics;fixed point	Vision	42.66674170471604	-69.18798815185309	44780
c2745254c020ff0597d509aae045d16b0a3d4538	algorithms of the cluster and morphological analysis for mineral rocks recognition in the mining industry		This paper describes an algorithm for automatic segmentation of color images of various ore types, using the methods of morphological and cluster analysis. There are some examples illustrating the usage of the algorithm to solve mineral recognition problems. The effectiveness of the proposed method lies in the area of automatic objects of interest identification inside the image, tuning the parameters of the amount allocated to the segments. This paper contains short description of morphological and cluster analysis algorithms for the mineral recognition in the mining industry.	algorithm	Olga E. Baklanova;Mikhail A. Baklanov	2016		10.1007/978-3-319-42294-7_23	computer science;pattern recognition;artificial intelligence;morphological analysis;algorithm	ML	35.18408175456209	-65.95973279010255	44788
ec75f4f7b6b0b81d8cbc822b7e7de0cf5403470d	automated melanoma recognition	especificidad;survival rate;analisis imagen;skin lesion;sensitivity and specificity;image recognition;analisis sensibilidad;informatica biomedical;local parameters;biomedical data processing;final knn classification;image segmentation;piel;image processing;cancer;tumor maligno;automatic system;peau;skin disease;microscopie optique;skin;melanoma maligno;bioluminescence;luminescence;informatique biomedicale;diagnostico;hombre;image classification;microscopy;biomedical imaging;segmentation;skin cancer;indexing terms;ultraviolet radiation;image processing computer assisted;melanoma;malignant tumors;classification;skin neoplasms;malignant tumors lesions image analysis microscopy image recognition cancer skin image segmentation shape radiometry;luminiscencia;automated melanoma recognition;radiometry;sensitivity;basic segmentation algorithms;specificity automated melanoma recognition computerized analysis elm epiluminescence microscopy early recognition malignant melanoma binary mask skin lesion basic segmentation algorithms fusion strategy shape features radiometric features global parameters local parameters malignancy statistical feature subset selection methods final knn classification sensitivity;shape;sistema automatico;peau pathologie;lesions;statistical feature subset selection methods;sensitivity analysis;feature extraction;medical image processing;shape features;computerized analysis;human;malignancy;feature subset selection;systeme automatique;analyse sensibilite;algorithms;image analysis;radiometric features;feature selection;melanome malin;tumeur maligne;humans;microscopia optica;global parameters;binary mask;specificity;early recognition;algorithms humans image processing computer assisted melanoma microscopy sensitivity and specificity skin neoplasms;specificite;epiluminescence microscopy;elm;diagnosis;malignant melanoma	A system for the computerized analysis of images obtained from ELM has been developed to enhance the early recognition of malignant melanoma. As an initial step, the binary mask of the skin lesion is determined by several basic segmentation algorithms together with a fusion strategy. A set of features containing shape and radiometric features as well as local and global parameters is calculated to describe the malignancy of a lesion. Significant features are then selected from this set by application of statistical feature subset selection methods. The final kNN classification delivers a sensitivity of 87% with a specificity of 92%.		Harald Ganster;Axel Pinz;Reinhard Röhrer;Ernst Wildling;Michael Binder;Harald Kittler	2001	IEEE transactions on medical imaging	10.1109/42.918473	computer vision;image analysis;pathology;image processing;computer science;microscopy;feature selection;cancer	Vision	37.062829686493124	-74.9751480782193	44791
e21eb6fa380103c8731235cf091f83e398d06790	image-based classification of paper surface quality using wavelet texture analysis	wavelet texture analysis;classification;variable selection;paper formation;texture analysis;feature extraction	The characteristics of paper surface play a central role in the overall quality of paper produced in modern paper machines. Among the surface features, paper formation, i.e., the level of homogeneity in the distribution of fibres on the surface of paper, is a key quality parameter, being currently monitored off-line, at low sampling rates relatively to the high production speeds achieved with modern paper machines. Therefore, in this paper, we address the problem of assessing the quality of paper formation, on-line, in situ, in an autonomous, efficient, objective and fast way, using features derived from images collected by a specially designed sensor, coupled with proper classification methodologies. The results obtained clearly demonstrate the potential of the proposed assessment approach either for the more complex three-class classification problem as well as for less demanding, but still important in practice, two-class “Accept”/“Reject” or “Pass”/“Fail” problem.	wavelet	Marco S. Reis;Armin Bauer	2010	Computers & Chemical Engineering	10.1016/j.compchemeng.2010.06.013	computer vision;feature extraction;biological classification;computer science;engineering;machine learning;data mining;feature selection;engineering drawing	SE	35.85723919895171	-70.13913802383361	44827
467f667023f7d766da22c869f6b0c5a4473145ce	a novel retake detection using lcs and sift algorithm	lcs;longest common subsequence;sift algorithm;retake detection;sequence matching;object location extraction	In this paper, a method to determine retake in rushes videos is proposed. This method first divides the video into shots, and then each shot that contains a single color, color bar or clapper board is eliminated. In each remaining shot, the similarity between consecutive frames is calculated using a SIFT matching algorithm and then converted into a string sequence. The similarity between two sequence is evaluated by the Longest Common Subsequence algorithm (LCS). This proposed SIFT - LCS based method was applied to the TRECVID BBC rushes videos of 2007 and 2008 as a competence test. The results support the notion that the proposed method provides a reasonably high degree of accuracy, and identifies the likely causes of poor accuracy for further improvements.	algorithm;scale-invariant feature transform	Nagul Cooharojananone;Narongsak Putpuek;Shin'ichi Satoh;Chidchanok Lursinsap	2009		10.1007/978-3-642-10467-1_68	computer vision;computer science;theoretical computer science;pattern recognition;longest common subsequence problem;scale-invariant feature transform;mathematics;algorithm	Robotics	39.9950335322353	-53.1069816420298	44842
02830dfd355e1a150410672f580b5987c10b71b4	color image canonical correlation analysis for face feature extraction and recognition	reconnaissance visage;color face recognition;analisis imagen;iterative method;traitement signal;evaluation performance;metodo estadistico;metodo analitico;performance evaluation;modele mathematique;image processing;color image cca cicca;image databank;canonical correlation analysis cca;biometrie;evaluacion prestacion;manufacturing process;biometrics;image database;biometria;procesamiento imagen;statistical method;modelo matematico;traitement image;journal;analyse canonique;metodo iterativo;algorithme;algorithm;red green and blue;automatic recognition;face recognition;statistical analysis;procedimiento fabricacion;methode statistique;methode iterative;canonical correlation analysis;feature extraction;signal processing;analytical method;banco imagen;banque image;analyse correlation;mathematical model;pattern recognition;methode analytique;analisis canonico;image analysis;reconnaissance forme;extraction caracteristique;iterative solution;reconocimiento patron;procede fabrication;imagen color;analytic solution;procesamiento senal;analyse image;correlation canonique;canonical analysis;correlacion canonica;image couleur;analisis correlacion;reconocimiento automatico;color image;reconnaissance automatique;canonical correlation;correlation analysis;algoritmo	Canonical correlation analysis (CCA) is a powerful statistical analysis technique, which can extract canonical correlated features from two data sets. However, it cannot be directly used for color images that are usually represented by three data sets, i.e., red, green and blue components. Current multi-set CCA (mCCA) methods, on the other hand, can only provide the iterative solutions, not the analytical solutions, when processing multiple data sets. In this paper, we develop the CCA technique and propose a color image CCA (CICCA) approach, which can extract canonical correlated features from three color components and provide the analytical solution. We show the mathematical model of CICCA, prove that CICCA can be cast as solving three eigen-equations, and present the realization algorithm of CICCA. Experimental results on the AR and FRGC-2 public color face image databases demonstrate that CICCA outperforms several representative color face recognition methods. & 2011 Elsevier B.V. All rights reserved.	algorithm;color image;database;eigen (c++ library);facial recognition system;feature extraction;iterative method;mathematical model	Xiao-Yuan Jing;Sheng Li;Chao Lan;David Zhang;Jingyu Yang;Qian Liu	2011	Signal Processing	10.1016/j.sigpro.2011.02.016	computer vision;canonical correlation;image analysis;image processing;computer science;artificial intelligence;signal processing;mathematics;statistics	Vision	44.64475840289353	-60.09079589651055	44855
d76b047b809e37a3fdc37323b5718b1486fb6b0e	feature level fused templates for multi-biometric system on smartphones	protocols;authentication;smart phones;feature extraction;matched filters;face;cameras	This work examines feature level fusion for protected biometric templates in a multi-biometric authentication system for smartphones. The modalities incorporated by the system are face and the left-right periocular region. The fusion methods considered are concatenation of the templates obtained from the three modalities, and combining the three templates using a simple XOR operation by varying the amount of overlap between them up to 100%. The impact on performance from applying the feature level fusion methods are evaluated on a moderate sized dataset consisting of images from 73 subjects, captured using a Samsung Galaxy S5. We show that the biometric performance can be improved in most of the cases by employing the fusion methods when compared to the performance of each individual modality while not compromising the security level provided by template protection schemes.	authentication;biometrics;concatenation;direct3d;exclusive or;modality (human–computer interaction);smartphone	Martin Stokkenes;Ramachandra Raghavendra;Kiran B. Raja;Morten K. Sigaard;Christoph Busch	2017	2017 5th International Workshop on Biometrics and Forensics (IWBF)	10.1109/IWBF.2017.7935110	computer vision;speech recognition;engineering;computer security	Mobile	30.252896270665513	-62.231008231377295	44899
6eee2b2c85617f819bd6145d1dcb16c9bd283ed4	the human facial expression classification using the center kernel subspace based the ridge regression	center kernel;two dimensional fourier transform;gabor filter;the ridge regression;facial expression	Email: arifmuntasa@if.trunojoyo.ac.id Abstract: The facial expression classification has been implemented on many devices. However, many researchers have conducted the research to improve the classification rate. This research has developed the algorithm to enhance the classification rate on the facial expression field. The proposed method is divided into five primary processes, which are, the first, create the center kernel subspace-based the ridge regression. Secondly, create five scales and eight orientations by using Gabor Filter Bank. The third is to obtain the new signal by using Two-dimensional-Fast Fourier Transform. Fourth, the results are used to build the feature space. It is conducted by the ridge regression of center kernel function. The last process, the primary features can be generated by multiplication between the center kernel and the Eigenvalue. The expression classification can be obtained by using the Mahalanobis method. The proposed method has been evaluated on JAFEE facial expression image database. Experimental shows that the classification rates for the first until the last scenarios are 83.33, 84.03, 86.61, 87.23, 87.24 and 89.79% respectively.		Arif Muntasa	2015	JCS	10.3844/jcssp.2015.1054.1059	speech recognition;machine learning;pattern recognition;variable kernel density estimation;facial expression	ML	34.30940544070031	-58.72031294057069	45027
79f2b6c37d48b71730f8666bcd8c4c44a9eff9f1	hierarchical bag-of-words model for joint multi-view object representation and classification	image matching;image classification;computational complexity;image representation;image retrieval	Multi-view object classification is a challenging problem in image retrieval. One common approach is to apply the visual bag-of-words (BoW) model to all view representations of each object class and compare them with the representation of the query image one by one so as to determine the closest view of the object class. This approach offers good matching performance, yet it demands a large amount of computation and storage space. To address these issues, we propose a novel hierarchical BoW model that provides a concise representation of each object class with multi-views. When the higher level BoW representation does not match with that of the query instance, further comparison can be saved. We can also incorporate similar views to reduce the storage space. We conduct experiments on a dataset of 3D object classes, and show that the proposed approach achieves higher efficiency in terms of lower computational complexity and storage space while preserving good matching performance.	algorithmic efficiency;bag-of-words model in computer vision;computation;computational complexity theory;experiment;image retrieval	Xiang Fu;Sanjay Purushotham;Daru Xu;C.-C. Jay Kuo	2012	Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference		computer vision;method;machine learning;pattern recognition;mathematics	Vision	36.654435627681465	-55.167744980342924	45043
9bd6bff7c3eae7ec6da8ed7aeb70491bcd40177e	optimal mass transport for registration and warping	optimal transport;partial differential equation;distance function;optimal transportation;gradient flows;reference frame;image registration;earth mover s distance;elastic registration;mass transport;gradient flow;mass preservation;image warping	Image registration is the process of establishing a common geometric reference frame between two or more image data sets possibly taken at different times. In this paper we present a method for computing elastic registration and warping maps based on the Monge–Kantorovich theory of optimal mass transport. This mass transport method has a number of important characteristics. First, it is parameter free. Moreover, it utilizes all of the grayscale data in both images, places the two images on equal footing and is symmetrical: the optimal mapping from image A to image B being the inverse of the optimal mapping from B to A. The method does not require that landmarks be specified, and the minimizer of the distance functional involved is unique; there are no other local minimizers. Finally, optimal transport naturally takes into account changes in density that result from changes in area or volume. Although the optimal transport method is certainly not appropriate for all registration and warping problems, this mass preservation property makes the Monge–Kantorovich approach quite useful for an interesting class of warping problems, as we show in this paper. Our method for finding the registration mapping is based on a partial differential equation approach to the minimization of the L 2 Kantorovich–Wasserstein or “Earth Mover's Distance” under a mass preservation constraint. We show how this approach leads to practical algorithms, and demonstrate our method with a number of examples, including those from the medical field. We also extend this method to take into account changes in intensity, and show that it is well suited for applications such as image morphing.	algorithm;elastic matching;frame language;grayscale;image registration;image warping;morphing;reference frame (video);transportation theory (mathematics)	Steven Haker;Lei Zhu;Allen R. Tannenbaum;Sigurd B. Angenent	2004	International Journal of Computer Vision	10.1023/B:VISI.0000036836.66311.97	reference frame;image warping;earth mover's distance;computer vision;mathematical optimization;metric;computer science;image registration;mathematics;geometry;balanced flow;partial differential equation;statistics;mass transfer	Vision	52.39618634204036	-71.49836270914003	45127
8e2d49a57c9eb9b215250e7ed798f011217832d1	a system for pcb automated inspection using fluorescent light	high sensitivity tv camera;printed circuits;fluorescence;silhouette image;circuit faults;ultraviolet rays;silhouette image computer vision fault detection short circuits pattern recognition violet illumination pcb automated inspection fluorescent light cuts nicks printed circuit board pattern ultraviolet rays glass epoxy glass polyimide optical fiber high sensitivity tv camera;short circuits;cuts;computerised pattern recognition;inspection;computer vision;nicks;printed circuit board pattern;optical fibers;fault detection;printed circuit testing circuit analysis computing computer vision computerised pattern recognition fault location fluorescence inspection;pattern recognition;fluorescent light;printed circuit testing;lighting;printed circuit board;tv;glass epoxy;optical fiber;optical materials;circuit analysis computing;violet illumination;high sensitivity;ultraviolet;pcb automated inspection;glass polyimide;electrical fault detection;inspection fluorescence printed circuits optical materials electrical fault detection fault detection circuit faults optical fibers lighting tv;fault location	Research was performed on the detection of faults such as shorts, cuts, and nicks in a printed circuit board pattern. The possibility was investigated of detecting a pattern by illuminating a printed circuit board with violet or ultraviolet rays and detecting the pattern using the (yellow or other) fluorescent light emitted by the base material consisting of glass-epoxy or glass-polyimide, etc. It was found that the pattern could be detected clearly by selecting an optical fiber that would separate the emitted fluorescent light from the illumination and using a detector consisting of a high-sensitivity TV camera that produces a silhouette image in which the base material is bright and the pattern is dark. A printed-circuit-board pattern inspector using this approach was developed. Test operation of the inspector in a plant demonstrated that it performs consistently good pattern inspections. >	printed circuit board	Yasuhiko Hara;Hideaki Doi;Koichi Karasaki;Tadashi Iida	1988	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.3868	computer vision;computer science;optical fiber;printed circuit board	Vision	36.95507641564515	-68.46466671208299	45162
cf6f55a46967f513cce95240b01f95224643ecac	unsupervised change detection using a novel fuzzy c-means clustering simultaneously incorporating local and global information		This paper presents a novel fuzzy c-means (FCM) clustering simultaneously incorporating local and global information (FLGICM) method to unsupervised change detection (CD) from remotely sensed images. A new factor including three local, global and edge parameters is added into the conventional FCM to enhance the insensitivity to noise and preserve detailed features. The spatial attraction between the central pixel and its neighborhood pixels is incorporated as a local parameter to utilize spatial information. A global parameter designed based on the estimated mean values of changed and unchanged pixels is introduced into the new factor to enhance its robustness and ability of separating changed from unchanged pixels. In addition, an edge parameter is also added to remain accurate edges and change details. Two experiments were carried out on Landsat images to test the performance of FLGICM. Experimental results indicate that FLGICM always achieves high accuracy and overperforms some state-of-the-art CD methods. Therefore, the proposed FLGIC provides an effective unsupervised CD method.	cluster analysis;edge enhancement;experiment;fuzzy clustering;fuzzy cognitive map;global optimization;pixel;unsupervised learning	Ming Hao;Hua Zhang;Zhenxuan Li;Bingqian Chen	2017	Multimedia Tools and Applications	10.1007/s11042-017-4354-1	robustness (computer science);fuzzy logic;computer vision;pixel;spatial analysis;computer science;cluster analysis;artificial intelligence;change detection;pattern recognition;machine learning;local parameter	AI	46.798960120432795	-68.93166674431814	45200
c23d62663da072f7504c790d976b1bc5174b6312	determining leishmania infection levels by automatic analysis of microscopy images		Analysis of microscopy images is one important tool in many fields of biomedical research, as it allows the quantification of a multitude of parameters at the cellular level. However, manual counting of these images is both tiring and unreliable and ultimately very time-consuming for biomedical researchers. Not only does this slow down the overall research process, it also introduces counting errors due to a lack of objectivity and consistency inherent to the researchers’ own human nature. This thesis addresses this issue by automatically determining infection indexes of macrophages infected by the Leishmania parasite in microscopy images using computer vision and pattern recognition methodologies. Initially images are submitted to a pre-processing stage that consists in a normalization of illumination conditions. Three algorithms are then applied in parallel to each image. Algorithm A intends to detect macrophage nuclei and consists of segmentation via adaptive multi-threshold, and classification of resulting regions using a set of collected features. Algorithm B intends to detect parasites and is similar to Algorithm A but the adaptive multi-threshold is parameterized with a different constraints vector. Algorithm C intends to detect the macrophages’ and parasites’ cytoplasm and consists of a cut-off version of the previous two algorithms, where the classification step is skipped. Regions with multiple nuclei or parasites are processed by a voting system that employs both a Support Vector Machine and a set of region features for determining the number of objects present in each region. The previous vote is then taken into account as the number of mixtures to be used in a Gaussian Mixture Model to decluster the said region. Finally each parasite is assigned to, at most, a single macrophage using minimum Euclidean distance to a cell’s nucleus, thus quantifying Leishmania infection levels. The software framework was implemented in Java, using Weka’s external libraries to train the Support Vector Machine and perform the Gaussian Mixture analysis. We were able to count macrophages and parasites with reasonably high accuracies (above 90%), and decluster regions with multiple nuclei or parasites with 75-85% accuracy. Ultimately, our results show our approach is able to replace a human in this task, alas with some room for improvement.	algorithm;computer vision;euclidean distance;java;library (computing);mixture model;objectivity/db;pattern recognition;preprocessor;software framework;support vector machine;weka	Paulo Afonso Nogueira	2013	CoRR		computer vision;bioinformatics	Vision	38.654266038761236	-73.8074075298249	45243
9d93c806240ac93ccaf3757f7713d17f747d2bd8	three-dimensional active contour model for characterization of solid breast masses on three-dimensional ultrasound images	active contour;computer aided diagnosis;cancer;transducers;breast;receiver operating characteristic curve;three dimensional;receivers;ultrasound imaging;biopsy;computing systems;feature selection;ultrasonography;classification accuracy;leave one out;active contour model	The accuracy of discrimination between malignant and benign solid breast masses on ultrasound images may be improved by using computer-aided diagnosis and 3-D information. The purpose of this study was to develop automated 3-D segmentation and classification methods for 3-D ultrasound images, and to compare the classification accuracy based on 2-D and 3-D segmentation techniques. The 3-D volumes were recorded by translating the transducer across the lesion in the z-direction while conventional 2-D images were acquired in the x-y plane. 2-D and 3-D segmentation methods based on active contour models were developed to delineate the mass boundaries. Features were automatically extracted based on the segmented mass shapes, and were merged into a malignancy score using a linear classifier. 3-D volumes containing biopsy-proven solid breast masses were collected from 102 patients (44 benign and 58 malignant). A leave-one-out method was used for feature selection and classifier design. The area Az under the test receiver operating characteristic curves for the classifiers using the 3-D and 2-D active contour boundaries were 0.88 and 0.84, respectively. More than 45% of the benign masses could be correctly identified using the 3-D features without missing a malignancy. Our results indicate that an accurate computer classifier can be designed for differentiation of malignant and benign solid breast masses on 3-D sonograms.© (2003) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	active contour model	Berkman Sahiner;Aditya Ramachandran;Heang-Ping Chan;Marilyn A. Roubidoux;Lubomir M. Hadjiiski;Mark A. Helvie;Nicholas Petrick;Chuan Zhou	2003		10.1117/12.483548	computer vision;pathology;engineering;biological engineering	Vision	35.11952131027848	-77.43428385116236	45258
00064b391c2d3bca8794770faa8ccfdd712e496d	word extraction from table regions in document images	mascara;analyse amas;text;localization;extraction forme;localizacion;texte;classification;biblioteca electronica;cluster analysis;localisation;extraccion forma;segment droite;segmento recta;analisis cluster;line segment;electronic library;masque;connected component;texto;pattern extraction;mask;clasificacion;bibliotheque electronique	This paper describes a method to extract words from table regions in document images. The proposed approach consists of two stages: cell detection and word extraction. In the cell detection module, a table frame is extracted first by analyzing connected components and then intersection points are detected by a method using masks in the table frame. We correct false intersections, and detect the location of the cells within the table. In the word extraction module, a text region in each cell is located by using the connected components information that was obtained during the cell extraction module, and segmented into text lines by using projection profiles. Finally we divide the segmented lines into words using gap clustering and special symbol detection. The method correctly included character components touching the table frame with words, so experimental results show that more than 99% of words were successfully extracted from table regions	cluster analysis;connected component (graph theory);digital library;library (computing);variable shadowing	Chang Bu Jeong;Sang-Cheol Park;Hwa Jeong Son;Soo-Hyung Kim	2005		10.1007/11599517_25	speech recognition;connected component;internationalization and localization;line segment;biological classification;computer science;machine learning;mask;cluster analysis;algorithm	ML	35.70718607019503	-67.22404568129507	45259
73ef9c0e16d0605a504ca802a4379f2cf26cd07e	image registration using hierarchical b-splines	image matching;scattered data approximation;image registration spline optical distortion shape magnetic resonance imaging nonlinear distortion iterative closest point algorithm iterative algorithms nonlinear optics image motion analysis;function approximation image registration splines mathematics biomedical mri image sequences image matching;splines mathematics;hierarchical b splines;scattered data approximation image registration hierarchical b splines shape modeling free form deformation mri iterative closest point optical flow;level of detail;function approximation;image registration;iterative closest point;free form deformation;optical flow;shape modeling;iterative closest point algorithm;index terms image registration;algorithms brain computer graphics computer simulation humans image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval magnetic resonance imaging numerical analysis computer assisted pattern recognition automated reproducibility of results sensitivity and specificity signal processing computer assisted subtraction technique user computer interface;biomedical mri;image sequences	Hierarchical B-splines have been widely used for shape modeling since their discovery by Forsey and Bartels. We present an application of this concept, in the form of free-form deformation, to image registration by matching two images at increasing levels of detail. Results using MRI brain data are presented that demonstrate high degrees of matching while unnecessary distortions are avoided. We compare our results with the nonlinear ICP (iterative closest point) algorithm (used for landmark-based registration) and optical flow (used for intensity-based registration).	algorithm;b-spline;computation;distortion;free-form deformation;image registration;iterative closest point;iterative method;matching;multimodal imaging;nonlinear system;optical flow;polyethylene terephthalate;positron-emission tomography;scanner device component;registration - actclass	Zhiyong Xie;Gerald E. Farin	2004	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2004.1260760	computer vision;mathematical optimization;function approximation;computer science;image registration;theoretical computer science;level of detail;optical flow;iterative closest point	Visualization	45.954568866142395	-77.26466252381925	45285
2e6e06ba995dd2de19c96d45a84f2c024f3ff9e7	support vectors machine-based identification of heart valve diseases using heart sounds	aortic regurgitation;heart disease;aortic stenosis;mitral stenosis;support vector machines;automated diagnosis;heart sounds;mitral regurgitation;biosignal processing;back propagation neural network;system performance;heart valve diseases;rural area;k nearest neighbour;support vector machine;bayes classifier;heart valve disease;primary healthcare	Taking into account that heart auscultation remains the dominant method for heart examination in the small health centers of the rural areas and generally in primary healthcare set-ups, the enhancement of this technique would aid significantly in the diagnosis of heart diseases. In this context, the present paper initially surveys the research that has been conducted concerning the exploitation of heart sound signals for automated and semi-automated detection of pathological heart conditions. Then it proposes an automated diagnosis system for the identification of heart valve diseases based on the Support Vector Machines (SVM) classification of heart sounds. This system performs a highly difficult diagnostic task (even for experienced physicians), much more difficult than the basic diagnosis of the existence or not of a heart valve disease (i.e. the classification of a heart sound as 'healthy' or 'having a heart valve disease'): it identifies the particular heart valve disease. The system was applied in a representative global dataset of 198 heart sound signals, which come both from healthy medical cases and from cases suffering from the four most usual heart valve diseases: aortic stenosis (AS), aortic regurgitation (AR), mitral stenosis (MS) and mitral regurgitation (MR). Initially the heart sounds were successfully categorized using a SVM classifier as normal or disease-related and then the corresponding murmurs in the unhealthy cases were classified as systolic or diastolic. For the heart sounds diagnosed as having systolic murmur we used a SVM classifier for performing a more detailed classification of them as having aortic stenosis or mitral regurgitation. Similarly for the heart sounds diagnosed as having diastolic murmur we used a SVM classifier for classifying them as having aortic regurgitation or mitral stenosis. Alternative classifiers have been applied to the same data for comparison (i.e. back-propagation neural networks, k-nearest-neighbour and naïve Bayes classifiers), however their performance for the same diagnostic problems was lower than the SVM classifiers proposed in this work.	aortic valve insufficiency;aortic valve stenosis;artificial neural network;backpropagation;categorization;classification;diastole;heart auscultation;heart diseases;heart failure, systolic;heart sounds;heart valves;heart failure;heart valve disease;malignant fibrous histiocytoma;mitral valve insufficiency;mitral valve prolapse syndrome;mitral valve stenosis;murmurhash;naive bayes classifier;neural network simulation;regurgitation;semiconductor industry;silo (dataset);software propagation;support vector machine	Ilias Maglogiannis;Euripidis Loukis;Elias P. Zafiropoulos;Antonis Stasis	2009	Computer methods and programs in biomedicine	10.1016/j.cmpb.2009.01.003	support vector machine;medicine;pathology;computer science;machine learning;primary health care;computer performance;surgery;cardiology	ML	33.47375734634739	-78.29083791424497	45344
a6247fa38cc1d8f2dd5eee2970d10afa0a8d4e84	magnetic resonance image segmentation by contextual fuzzy clustering		This article presents a fuzzy c-mean clustering algorithm, named contextual thresholded fuzzy c-mean, for the segmentation of magnetic resonance brain images. This algorithm incorporates contextual information into the thresholded fuzzy c-mean algorithm. This is done by adjusting the membership of voxels adaptively based upon the membership context of the surrounding voxels. The performance of this algorithm was compared both to crisp and to fuzzy clustering algorithms using “phantom” data and a set of clinical examples. The contextual fuzzy c-mean algorithm gave the best results of those tested when the criteria were accuracy of volume measurements and homogeneity of brain tissue types. A graphical user interface was developed for these methods to provide an easy-to-use software tool for clinical environments.	fuzzy clustering;image segmentation;resonance	Nasser Kehtarnavaz;Minhwa Chung;L. A. Hayman;Richard E. Wendt	1993	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-1993-1404	fuzzy clustering;flame clustering;fuzzy classification;computer science;machine learning;pattern recognition;data mining	Robotics	42.739393921945755	-72.89853692126847	45348
7c152d7c6a4a47e555d1f98c42d8aa50f217e267	an outdoor time scenes simulation scheme based on support vector regression with radial basis function on dct domain	radial basis function rbf;support vector regression;discrete cosine transform;radial basis function;rbf neural network;regression estimator;support vector machine;scene;neural network	In this paper, a novel strategy for forecasting outdoor scenes is introduced. This new approach combines the support vector regression in neural network computation and the discrete cosine transform (DCT). In 1995, Vapnik introduced a neural-network algorithm called support vector machine (SVM). During the recent years, due to SVM's high generalization performance and attractive modeling features, it has received increasing attention in the application of regression estimation - which is called support vector regression (SVR). In SVR, a set of color-block images were transformed by the discrete cosine transformation to be the training data. We also used the radial basis function (RBF) of the training data as SVR's kernel to establish the RBF neural network. Finally, the time scenes simulation algorithm (TSSA) is able to synthesize the corresponding scene of any assigned time of the original outdoor scene image. To explore the utility and demonstrate the efficiency of the proposed algorithm, simulations under various input images were conducted. The experiment results showed that our proposed algorithm can precisely simulate the desired scenes at an assigned time and has two advantages: (a) Using the color-block images instead of using the scene images of a place to create the reference database, the database can be used for any outdoor scene image taken at anywhere at anytime. (b) Taking the support vector regression on the DCT coefficients of scene images instead of taking the SVR on the spatial pixels of scene images, it simplifies the regression procedure and saves the processing time.	discrete cosine transform;radial (radio);radial basis function;simulation;support vector machine	Chen-Chung Liu;Kai-Wen Chuang	2009	Image Vision Comput.	10.1016/j.imavis.2009.04.007	support vector machine;computer vision;computer science;machine learning;pattern recognition;artificial neural network	Vision	28.94892079859987	-55.61041469900482	45541
bf0c75ba416425563c2e3814aa00a265e5ec9b9d	knowledge-based configuration of image segmentation processes	image segmentation;knowledge base	Abstract#R##N##R##N#The solution of an image interpretation problem using digital image analysis methods requires the configuration of an image analysis system to meet the requirements of this specific task the specific data material. This process includes the selection of the appropriate sequence of operators and the adaptation of the free parameters. A system has been developed and is described, which performs this configuration process automatically on the basis of a user-specified task definition, and general knowledge of an image analysis expert. The latter knowledge has been assessed, stored, and used by employing different paradigms of knowledge representation similar to expert systems.	image segmentation;knowledge-based configuration	Claus-E. Liedtke;Arnold Blömer;Thomas Gahm	1990	Int. J. Imaging Systems and Technology	10.1002/ima.1850020405	computer vision;feature detection;image processing;computer science;knowledge management;segmentation-based object categorization;data mining;image segmentation;scale-space segmentation;automatic image annotation	Robotics	41.4157137464098	-70.20485618808777	45576
f57654135e8f2ad1880a461183f227a49dc783b4	automatic modulation recognition of digital signals based on fisherface		This paper focuses on the design of dimensionality reduction based on Fisherface. We propose to apply the Fisherface algorithm in face recognition to automatic modulation recognition, and combine it with cyclic spectrum and k nearest neighbor classifier to realize the correct recognition of 9 kinds of modulation signals. Fisherface is an improved algorithm based on Fisher linear discriminant analysis, which can effectively reduce the sample dimension. This paper discusses the design process and gives the simulation results. The results show that the Fisherface algorithm is effective in reducing the feature dimension of digital signal in automatic modulation recognition. This can also be used for security detection and recognition.	confusion matrix;dimensionality reduction;facial recognition system;linear discriminant analysis;modulation;nearest neighbour algorithm;signal-to-noise ratio;simulation	Shanshan Jin;Yun Lin	2017	2017 IEEE International Conference on Software Quality, Reliability and Security Companion (QRS-C)	10.1109/QRS-C.2017.42	dimensionality reduction;feature extraction;digital signal;facial recognition system;k-nearest neighbors algorithm;artificial intelligence;statistical classification;feature dimension;linear discriminant analysis;pattern recognition;computer science	EDA	27.224848390699666	-61.673244391895516	45620
5ee21b7ca934f5d6fd0aa68593258bc7c60a8212	massive medical images retrieval system based on hadoop	distributed system;medical image retrieval;feature library;local binary patterns;brushlet transform	In order to improve the efficiency of massive medical images retrieval, against the defects of the single-node medical image retrieval system, a massive medical images retrieval system based on Hadoop is put forward. Brushlet transform and Local binary patterns algorithm are introduced firstly to extract characteristics of the medical example image, and store the image feature library in the HDFS. Then using the Map to match the example image features with the features in the feature library, while the Reduce to receive the calculation results of each Map task and ranking the results according to the size of the similarity. At the end, find the optimal retrieval results of the medical images according to the ranking results. The experimental results show that compared with other medical image retrieval systems, the Hadoop based medical image retrieval system can reduce the time of image storage and retrieval, and improve the image retrieval speed.	algorithm;apache hadoop;data-intensive computing;feature (computer vision);image retrieval;local binary patterns;medical imaging;real-time locating system;reduce;requirement;simulation	Qing-An Yao;Hong Zheng;Zhong-Yu Xu;Qiong Wu;Zi-Wei Li;Lifen Yun	2014	Journal of Multimedia	10.4304/jmm.9.2.216-222	image texture;computer vision;visual word;local binary patterns;image retrieval;computer science;machine learning;data mining;automatic image annotation;information retrieval	Vision	38.49752341285012	-60.89056897762472	45668
6469edde43921bb67ef26e34fe544279f1b302e6	photometric invariant region detection	color model;universiteitsbibliotheek;reflection model;k means clustering;color image	In this paper, we concentrate on determining homogeneously colored regions invariant to surface orientation change, illumination, shadows and highlights. To this end, the influence of various well-known color models (e.g. I , RGB,XY Z, I1I2I3, rgb, xyz,U V W ,L a b andISH) are examined, in theory, for the dichromatic reflection model and, in practice, for two distinct region-based segmentation methods: the k-means clustering technique and the split&merge algorithm. Experiments are conducted on color images taken from colored objects in real-world scenes. On the basis of the theoretical and experimental results it is concluded thatl1l2l3,H , S, c1c2c3, rgb andxyz all detect regions invariant to a change in surface orientation, viewpoint of the camera, and illumination intensity. Furthermore,l1l2l3 andH also detect regions independent of highlights. I , RGB, CMY , Y IQ, XY Z, andI1I2I3 provide segmentation results which are all sensitive to surface orientation and illumination intensity as well as color models incorporating brightness into their systems: I in HSI , L in L a b , andL in Luv.	algorithm;classical xy model;cluster analysis;color;horizontal situation indicator;k-means clustering;x–y plotter	Theo Gevers;Arnold W. M. Smeulders;Harro M. G. Stokman	1998		10.5244/C.12.66	computer vision;color model;color image;computer science;machine learning;k-means clustering	AI	44.64854718697201	-55.65784073682092	45826
4f2240a3f0464c1062c5802a8c356763be293045	dendritic spine shape analysis using disjunctive normal shape models	neuroimaging disjunctive normal shape model spine classification shape analysis kernel density estimation microscopy;kernel density estimation;likelihood ratio space two photon laser scanning microscopy dendritic spine shape analysis disjunctive normal shape models neuron functional behavior neuronal activity parametric shape representation segmentation problems feature extraction algorithm kernel density estimation based classification approach dendritic spine classification probabilistic framework;shape analysis;disjunctive normal shape model;microscopy;spine classification;qp physiology;neuroimaging;shape kernel image segmentation feature extraction training estimation neck;tk electrical engineering electronics nuclear engineering;two photon processes biomedical optical imaging feature extraction image classification image representation image segmentation laser applications in medicine medical image processing neurophysiology optical microscopy probability	Analysis of dendritic spines is an essential task to understand the functional behavior of neurons. Their shape variations are known to be closely linked with neuronal activities. Spine shape analysis in particular, can assist neuroscientists to identify this relationship. A novel shape representation has been proposed recently, called Disjunctive Normal Shape Models (DNSM). DNSM is a parametric shape representation and has proven to be successful in several segmentation problems. In this paper, we apply this parametric shape representation as a feature extraction algorithm. Further, we propose a kernel density estimation (KDE) based classification approach for dendritic spine classification. We evaluate our proposed approach on a data set of 242 spines, and observe that it outperforms the classical morphological feature based approach for spine classification. Our probabilistic framework also provides a way to examine the separability of spine shape classes in the likelihood ratio space, which leads to further insights about the nature of the shape analysis problem in this context.	algorithm;calculus of variations;dendritic spine;disjunctive normal form;feature extraction;kernel density estimation;linear separability;shape analysis (digital geometry);shape context	Muhammad Usman Ghani;Fitsum Mesadi;Sumeyra Demir Kanik;Ali Ozgur Argunsah;Inbal Israely;Devrim Ünay;Tolga Tasdizen;Müjdat Çetin	2016	2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2016.7493280	active shape model;kernel density estimation;computer vision;medicine;computer science;microscopy;machine learning;pattern recognition;shape analysis;mathematics;neuroimaging	Vision	41.85246975980309	-77.12307075638701	45865
c87152d018832d74eef826a816fa4a767bb00203	fully convolutional multi-scale residual densenets for cardiac segmentation and automated cardiac diagnosis using ensemble of classifiers	automated diagnosis;cardiac mri;deep learning;ensemble classifier;fully convolutional densenets.;segmentation	Deep fully convolutional neural network (FCN) based architectures have shown great potential in medical image segmentation. However, such architectures usually have millions of parameters and inadequate number of training samples leading to over-fitting and poor generalization. In this paper, we present a novel DenseNet based FCN architecture for cardiac segmentation which is parameter and memory efficient. We propose a novel up-sampling path which incorporates long skip and short-cut connections to overcome the feature map explosion in conventional FCN based architectures. In order to process the input images at multiple scales and view points simultaneously, we propose to incorporate Inception module's parallel structures. We propose a novel dual loss function whose weighting scheme allows to combine advantages of cross-entropy and Dice loss leading to qualitative improvements in segmentation. We demonstrate computational efficacy of incorporating conventional computer vision techniques for region of interest detection in an end-to-end deep learning based segmentation framework. From the segmentation maps we extract clinically relevant cardiac parameters and hand-craft features which reflect the clinical diagnostic analysis and train an ensemble system for cardiac disease classification. We validate our proposed network architecture on three publicly available datasets, namely: (i) Automated Cardiac Diagnosis Challenge (ACDC-2017), (ii) Left Ventricular segmentation challenge (LV-2011), (iii) 2015 Kaggle Data Science Bowl cardiac challenge data. Our approach in ACDC-2017 challenge stood second place for segmentation and first place in automated cardiac disease diagnosis tasks with an accuracy of 100% on a limited testing set (n=50). In the LV-2011 challenge our approach attained 0.74 Jaccard index, which is so far the highest published result in fully automated algorithms. In the Kaggle challenge our approach for LV volume gave a Continuous Ranked Probability Score (CRPS) of 0.0127, which would have placed us tenth in the original challenge. Our approach combined both cardiac segmentation and disease diagnosis into a fully automated framework which is computationally efficient and hence has the potential to be incorporated in computer-aided diagnosis (CAD) tools for clinical application.		Mahendra Khened;Alex Varghese;Ganapathy Krishnamurthi	2019	Medical image analysis	10.1016/j.media.2018.10.004	region of interest;network architecture;pattern recognition;convolutional neural network;mathematics;image segmentation;deep learning;cad;segmentation;artificial intelligence;weighting	Vision	31.615607740096955	-75.70452325773884	45903
bcfcff24ca68daa553b2f9809cf27fcf89014fb4	segmentation of phase contrast microscopy images based on multi-scale local basic image features histograms	segmentation;phase contrast microscopy;basic image features;random forest;local feature histograms;trainable segmentation	Phase contrast microscopy (PCM) is routinely used for the inspection of adherent cell cultures in all fields of biology and biomedicine. Key decisions for experimental protocols are often taken by an operator based on typically qualitative observations. However, automated processing and analysis of PCM images remain challenging due to the low contrast between foreground objects (cells) and background as well as various imaging artefacts. We propose a trainable pixel-wise segmentation approach whereby image structures and symmetries are encoded in the form of multi-scale Basic Image Features local histograms, and classification of them is learned by random decision trees. This approach was validated for segmentation of cell versus background, and discrimination between two different cell types. Performance close to that of state-of-the-art specialised algorithms was achieved despite the general nature of the method. The low processing time ( < 4 s per 1280 × 960 pixel images) is suitable for batch processing of experimental data as well as for interactive segmentation applications.	batch processing;biomedicine;blast phase;cell culture techniques;decision trees;decision tree;microscopy, phase-contrast;morphologic artifacts;numerous;pixel;protein-energy malnutrition;protocols documentation;trees (plant);algorithm;biologic segmentation	Nicolas Jaccard;Nicolas Szita;Lewis D. Griffin	2017		10.1080/21681163.2015.1016243	scale-space segmentation;operator (computer programming);feature (computer vision);image segmentation;random forest;pixel;artificial intelligence;computer vision;histogram;segmentation-based object categorization;computer science;pattern recognition	Vision	39.96528167548337	-73.1278976381497	45909
78e7e122773204b7cf3c321b01cdd3081e63af0c	a ssd-based crowded pedestrian detection method		Pedestrian detection has become a significant research topic in the field of computer vision. The performance of existing methods based on deep learning is not so good in pedestrian detection for complex background. Considering the problem of pedestrian detection in complex scenes with small and crowded objects, we propose a SSD-based crowded pedestrian detection method in this paper. Firstly, we increase density of default boxes on the horizontal direction by setting an offset, which can effectively eliminate the influence of missing matching default boxes and separate a person from the crowd much easier. So our detector is more suitable for complex scenes. Secondly, SSD is designed for general object detection, thus it is unfit for pedestrian detection because of the large aspect ratio of pedestrians. Therefore, we adopt abnormal 5*1 convolutional kernels instead of the standard 3*3 ones in order to adapt to pedestrian detection. Finally, we present experimental results on public benchmark datasets including Caltech dataset and INRIA dataset, which indicate that our method has better performance for pedestrian detection.		Wenjing Zhang;Lihua Tian;Chen Li;H. S. Li	2018	2018 International Conference on Control, Automation and Information Sciences (ICCAIS)	10.1109/ICCAIS.2018.8570435		Vision	30.45045729079623	-52.41290637620169	45948
e1ef2fe5bd8c9b5995a65161c72649084d5756b1	bi-level thresholding using pso, artificial bee colony and mrlde embedded with otsu method		Image segmentation is required to be studied in detail some particular features (areas of interest) of a digital image. It forms an important and exigent part of image processing and requires an exhaustive and robust search technique for its implementation. In the present work we have studied the working of MRLDE, a newly proposed variant of differential evolution combined with Otsu method, a well known image segmentation method for bi-level thresholding. The proposed variant, termed as Otsu+MRLDE, is tested on a set of 10 images and the results are compared with Otsu method and some other well known metaheuristics.	artificial bee colony algorithm;embedded system;otsu's method;particle swarm optimization;thresholding (image processing)	Sushil Kumar;Pravesh Kumar Tomar;Tarun Kumar Sharma;Millie Pant	2013	Memetic Computing	10.1007/s12293-013-0123-5	computer vision;artificial intelligence;otsu's method;pattern recognition;balanced histogram thresholding;mathematics;image segmentation	EDA	42.39949644993687	-68.60318787803223	45973
4993f53bedf94c742b46b9ca31ed7bd1ab241a8c	a framework for mri image retrieval using curvelet transform and euclidean distance	texture retrieval;euclidean distance;discrete curvelet;similarity matching;content based image retrieval	Content Based Image Retrieval (CBIR) system support s users to retrieve relevant medical images based o n their features. Current content based image retriev al systems are incapable of providing exact results to he users. To address this problem a consistent feature ext action method is required for content based me ical image retrieval system to extract similar features from the images. In this study discrete curvelet ba sed feature extraction technique is proposed to retriev e similar images and the similarity distance is cal cul ted by using Euclidean distance. The proposed method gi ves better precision and recall rate. Experimental results on a database of 200 MRI images.	content-based image retrieval;curvelet;database;euclidean distance;ext js javascript framework;feature extraction;precision and recall;sed;sensitivity and specificity;ical	K. Rajakumar;Muttan	2013	JCS	10.3844/jcssp.2013.285.290	computer vision;visual word;pattern recognition;euclidean distance;automatic image annotation;information retrieval	Vision	33.121158486258075	-71.61779848456747	45976
02a4fa96ac1895d5460cb2a4c1a8f4acf7db9318	tension in active shapes	minimisation;shape cost function vectors force minimization mathematical model active contours;image segmentation;edge detection;minimisation edge detection image segmentation;euler lagrange diffusion equations active shapes active contours shape information image segmentation minimization global optimum binary tree fish segmentation low quality underwater images;optimization image segmentation shape analysis	The concept of tension is introduced in the framework of active contours with prior shape information, and it is used to improve image segmentation. In particular, two properties of this new quantity are shown: 1) high values of the tension correspond to undesired equilibrium points of the cost function under minimization and 2) tension decreases if a curve is split into two or more parts. Based on these ideas, a tree is generated whose nodes are different local minima of the cost function. Deeper nodes in the tree are expected to correspond to lower values of the cost function. In this way, the search for the global optimum is reduced to visiting and pruning a binary tree. The proposed method has been applied to the problem of fish segmentation from low quality underwater images. Qualitative and quantitative comparison with existing algorithms based on the Euler-Lagrange diffusion equations shows the superiority of the proposed approach in avoiding undesired local minima.	algorithm;binary tree;euler;euler–lagrange equation;global optimization;image segmentation;loss function;maxima and minima;memory segmentation;tension;biologic segmentation	Giuseppe Papari	2014	IEEE Transactions on Image Processing	10.1109/TIP.2013.2288922	computer vision;minimisation;mathematical optimization;edge detection;computer science;machine learning;segmentation-based object categorization;mathematics;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation	Vision	48.53790512454539	-71.3439509507715	46042
03fa44a4d47d1f5fd768bb290cddae7ebe6a8792	a sparsity-based atlas selection technique for multiple-atlas segmentation: application to neonatal brain labeling	brain;pediatrics;image segmentation;training;machine learning based label fusion technique sparsity based atlas selection technique multiple atlas segmentation neonatal brain labeling quantitative brain tissue volumes neonatal magnetic resonance imaging improved clinical decision making automated segmentation algorithms neonatal brain mr images;magnetic resonance imaging;distributed databases;pediatrics image segmentation magnetic resonance imaging training labeling distributed databases brain;medical image processing biomedical mri image segmentation learning artificial intelligence;labeling	Quantitative brain tissue volumes from neonatal magnetic resonance imaging (MRI) offer the possibility of improved clinical decision making and diagnosis. However, the neonatal brain presents specific challenges to automated segmentation algorithms. We developed a new method for automatic labeling of neonatal brain MR images. The method uses a new sparsity-based atlas selection strategy that requires a very limited number of atlases 'uniformly' distributed in the low-dimensional data space, combined with a machine learning based label fusion technique. The performance of the method for brain labeling from data of 66 newborns is evaluated and compared with results obtained using majority vote. The proposed method provides accurate brain labeling results with a mean Dice coefficient of 91%. As the proposed method can learn from partially labeled datasets, it can be used to segment large-scale datasets efficiently.	algorithm;dataspaces;machine learning;population;resonance;sparse matrix;sørensen–dice coefficient	Ahmed Serag;James P. Boardman;Alastair Graham Wilkinson;Gillian Macnaught;Scott I. Semple	2016	2016 24th Signal Processing and Communication Application Conference (SIU)	10.1109/SIU.2016.7496227	computer vision;computer science;artificial intelligence;machine learning;scale-space segmentation	Robotics	42.295311420972155	-76.6708032680327	46050
04fe413e609922262f29e0c9fd25d2aec3e49754	limbus impact on off-angle iris degradation	limbus height;biometrics;frontal iris images;iris recognition;image texture;hamming distance score;semitransparent tissue;off angle iris degradation;sclera;image acquisition angle;off angle iris images;iris recognition data acquisition image texture;data acquisition;occluded iris texture;cornea;off angle iris recognition systems;limbus height off angle iris degradation biometrics off angle iris recognition systems cornea sclera semitransparent tissue occluded iris texture image acquisition angle hamming distance score off angle iris images frontal iris images	The accuracy of iris recognition depends on the quality of data capture and is negatively affected by several factors such as angle, occlusion, and dilation. Off-angle iris recognition is a new research focus in biometrics that tries to address several issues including corneal refraction, complex 3D iris texture, and blur. In this paper, we present an additional significant challenge that degrades the performance of the off-angle iris recognition systems, called the “limbus effect”. The limbus is the region at the border of the cornea where the cornea joins the sclera. The limbus is a semitransparent tissue that occludes a side portion of the iris plane. The amount of occluded iris texture on the side nearest the camera increases as the image acquisition angle increases. Without considering the role of the limbus effect, it is difficult to design an accurate off-angle iris recognition system. To the best of our knowledge, this is the first work that investigates the limbus effect in detail from a biometrics perspective. Based on results from real images and simulated experiments with real iris texture, the limbus effect increases the hamming distance score between frontal and off-angle iris images ranging from 0.05 to 0.2 depending upon the limbus height.	biometrics;dilation (morphology);elegant degradation;experiment;gaussian blur;hamming distance;iris recognition	Mahmut Karakaya;Del R. Barstow;Hector J. Santos-Villalobos;Josef Thompson	2013	2013 International Conference on Biometrics (ICB)	10.1109/ICB.2013.6612971	image texture;computer vision;computer science;archaeology;iris recognition;data acquisition;biometrics	Vision	30.354205157385657	-61.70155801735582	46062
0b9213651d939b8195b0f4225fe409af6459effb	estimating 3d hand pose from a cluttered image	database indexing;clutter tolerant indexing;clutter tolerance 3d hand pose estimation cluttered image three dimensional hand configuration image matching image database indexing image retrieval synthetic hand image clutter tolerant indexing image to model chamfer distance approximation binary edge image embedding high dimensional euclidean space probabilistic line matching line segment correspondence;high dimensional euclidean space;object recognition;image segmentation;high dimensionality;image databases;clutter tolerance;edge detection;probabilistic line matching;information retrieval;image matching;image database;three dimensional;computer vision;3d hand pose estimation;cluttered image;indexing;indexation;impedance matching;stereo image processing;synthetic hand image;euclidean space;binary edge image embedding;line segment correspondence;humans;technical report;image database indexing;computer science;image to model chamfer distance approximation;image databases indexing impedance matching image retrieval image segmentation information retrieval computer vision computer science embedded computing humans;database indexing object recognition image matching visual databases edge detection stereo image processing;embedded computing;pose estimation;visual databases;image retrieval;three dimensional hand configuration	A method is proposed that can generate a ranked list of plausible three-dimensional hand configurations that best match an input image. Hand pose estimation is formulated as an image database indexing problem, where the closest matches for an input hand image are retrieved from a large database of synthetic hand images. In contrast to previous approaches, the system can function in the presence of clutter, thanks to two novel clutter-tolerant indexing methods. First, a computationally efficient approximation of the image-to-model chamfer distance is obtained by embedding binary edge images into a high-dimensional Euclidean space. Second, a general-purpose, probabilistic line matching method identifies those line segment correspondences between model and input images that are the least likely to have occurred by chance. The performance of this cluttertolerant approach is demonstrated in quantitative experiments with hundreds of real hand images.	3d pose estimation;algorithmic efficiency;approximation;approximation algorithm;chamfer;clutter;experiment;general-purpose modeling;randomness;similarity measure;synthetic intelligence	Vassilis Athitsos;Stan Sclaroff	2003		10.1109/CVPR.2003.1211500	database index;three-dimensional space;computer vision;search engine indexing;impedance matching;pose;edge detection;image retrieval;computer science;technical report;euclidean space;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;image segmentation	Vision	43.50143322272805	-54.78904717986997	46069
1097980f37dcb0a577b7b1f36531b152e352b0b7	a learning-based evolution of concept descriptions for an adaptive object recognition	texture recognition problem learning based evolution concept descriptions adaptive object recognition dynamic perceptual conditions closed loop integration recognition processes computer vision incremental machine learning;adaptive object recognition;image recognition;object recognition;image segmentation;incremental machine learning;learning based evolution;layout;image texture;computer vision;computer architecture;dynamic perceptual conditions;machine learning;machine vision;closed loop integration;texture recognition problem;concept descriptions;artificial intelligence;object recognition image recognition power system modeling layout computer architecture image segmentation artificial intelligence computer vision machine vision character recognition;learning artificial intelligence computer vision image recognition image texture;learning artificial intelligence;power system modeling;character recognition;recognition processes	A new approach is presented to the invariant recognition of objects under dynamic perceptual conditions. In this approach, images of a sequence are used to adapt object descriptions to perceived on-line variabilities of object characteristics. This adaptation is made possible by the close-loop integration of recognition processes of computer vision together with an incremental machine learning processes. Experiments presented in this paper were run for the texture recognition problem and were limited to a partially-supervised evolution of concept descriptions (models) rather than utilizing a fully autonomous model evolution. Obtained results are evaluated using the criteria of system recognition effectiveness and recognition stability.	autonomous robot;computer vision;evolution;machine learning;online and offline;outline of object recognition	Peter W. Pachowicz	1992		10.1109/TAI.1992.246422	image texture;layout;computer vision;feature;machine vision;intelligent character recognition;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;3d single-object recognition;image segmentation;sketch recognition	AI	35.98537698637206	-53.677810233283864	46070
ca73351816ff6dbedb53ab070221bafea5f155f7	biometric authentication based on infrared thermal hand vein patterns	biometric authentication;biometrics access control;fusion;edge detection;branch point;11 medical and health sciences;authentication;biometrics;gabor filters;veins;biometrics authentication veins feature extraction resilience image edge detection robustness cameras infrared imaging optical imaging;skeleton;and fusion rules biometric authentication infrared thermal hand vein patterns biometric modalities impostor attacks infrared thermal imaging region of interest gabor filter feature extraction techniques or fusion rules;gabor filter;thermal imaging;infrared imaging;hand vein patterns;feature extraction;region of interest;fusion rule;fusion biometrics hand vein patterns gabor filter;infrared;infrared imaging biometrics access control feature extraction gabor filters;cameras;false accept rate	Hand Vein patterns have been adjudged to be one of the safest biometric modalities due to their strong resilience against the impostor attacks. This paper presents a new approach for biometric authentication using infrared thermal hand vein patterns. In contrast to the existing features for hand vein patterns which are based solely on edge detection, we propose Box and branch point based approaches for multiple feature representations. A robust peg free camera set up is employed for infrared thermal imaging. A region of interest (ROI) is extracted from the vein patterns and is convolved with Gabor filter. The real part of this convolution is only preserved for further processing. Multiple features are extracted from the real parts of the convolved images using the proposed branch point based feature extraction techniques. The multiple features are then integrated at the decision level. AND and OR fusion rules are employed to combine the decisions taken by the individual matcher. Experiments conducted on a database of 100 users result in a False Acceptance Rate (FAR) of 0.1% for the Genuine Acceptance Rate (GAR) of 99% for decision level fusion.	acceptance testing;authentication;biometrics;convolution;database;edge detection;experiment;feature extraction;gabor filter;imaginary time;region of interest	Amioy Kumar;Madasu Hanmandlu;Vamsi Krishna Madasu;Brian C. Lovell	2009	2009 Digital Image Computing: Techniques and Applications	10.1109/DICTA.2009.63	computer vision;speech recognition;computer science;computer security;biometrics	Vision	33.42515221356172	-61.98586458795749	46071
adf5caca605e07ee40a3b3408f7c7c92a09b0f70	line-based pca and lda approaches for face recognition	reconnaissance visage;image recognition;reconocimiento imagen;analisis componente principal;image processing;facies;procesamiento imagen;matrice covariance;matriz covariancia;linear discriminate analysis;codigo bloque;traitement image;discriminant analysis;analyse discriminante;analisis discriminante;face recognition;covariance matrices;principal component analysis;reconnaissance image;analyse composante principale;pattern recognition;code bloc;reconnaissance forme;reconocimiento patron;discriminacion;block code;discrimination;eigenvectors;covariance matrix	Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) techniques are important and well-developed area of image recognition and to date many linear discrimination methods have been put forward. Despite these efforts, there persist in the traditional PCA and LDA some weaknesses. In this paper, we propose a new Line-based methodes called Line-based PCA and Line-based LDA that can outperform the traditional PCA and LDA methods. As opposed to conventional PCA and LDA, those new approaches are based on 2D matrices rather than 1D vectors. That is, we firstly divide the original image into blocks. Then, we transform the image into a vector of blocks. By using row vector to represent each block, we can get the new matrix which is the representation of the image. Finally PCA and LDA can be applied directly on these matrices. In contrast to the covariance matrices of traditional PCA and LDA approaches, the size of the image covariance matrices using new approaches are much smaller. As a result, those new approaches have three important advantages over traditional ones. First, it is easier to evaluate the covariance matrix accurately. Second, less time is required to determine the corresponding eigenvectors. And finally, block size could be changed to get the best results. Experiment results show our method achieves better performance in comparison with the other methods.	block size (cryptography);computer vision;facial recognition system;linear discriminant analysis;principal component analysis	Vo Dinh Minh Nhat;Sungyoung Lee	2005		10.1007/11539117_17	block code;covariance matrix;discrimination;speech recognition;facies;image processing;eigenvalues and eigenvectors;computer science;pattern recognition;mathematics;statistics;principal component analysis	Vision	44.30302129821567	-60.0030264036663	46075
137597f6cee31557cbd495020ed821774b9daf60	an indoor obstacle detection system using depth information and region growth	biological patents;obstacle detection;biomedical journals;text mining;europe pubmed central;citation search;citation networks;travel aid;kinect;research articles;abstracts;open access;life sciences;clinical guidelines;full text;depth map;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	This study proposes an obstacle detection method that uses depth information to allow the visually impaired to avoid obstacles when they move in an unfamiliar environment. The system is composed of three parts: scene detection, obstacle detection and a vocal announcement. This study proposes a new method to remove the ground plane that overcomes the over-segmentation problem. This system addresses the over-segmentation problem by removing the edge and the initial seed position problem for the region growth method using the Connected Component Method (CCM). This system can detect static and dynamic obstacles. The system is simple, robust and efficient. The experimental results show that the proposed system is both robust and convenient.	addresses (publication format);cane, includes canes of all materials, adjustable or fixed, with tip;hoarseness;image processing;information theory;institute for operations research and the management sciences;kinect;netware file system;programming languages;region of interest;region of interest:presence or identity:point in time:*:nominal;robot;sensor;visually impaired persons;biologic segmentation	Hsieh-Chang Huang;Ching-Tang Hsieh;Cheng-Hsiang Yeh	2015		10.3390/s151027116	embedded system;text mining;simulation;telecommunications;computer science;bioinformatics;engineering;electrical engineering;data mining;nanotechnology;depth map	Robotics	39.38820308247403	-67.5199140689497	46095
0fbe1685afdf4949ce01e71265dea5e5c0beac5d	local probability distribution of natural signals in sparse domains	histograms;statistical property;sparse transforms;transformation model;image processing;gaussian processes;hidden markov model;local probability distribution;probability density function;transforms three dimensional displays image processing histograms signal processing gaussian distribution hidden markov models;bessel k form density;sparse transformations;three dimensional;statistical properties;independent bessel k form;hidden markov models;central limit theorem;central limit theorem local probability distribution natural signals statistical property sparse domain coefficients independent bessel k form gamma local probability density function sparse transformations gaussian distribution;modeling of natural signals;signal processing gamma distribution gaussian processes;three dimensional displays;signal processing;wide sense stationary;probability distribution;transforms;gamma local probability density function;gamma distribution;heavy tailed distribution;sparse domain coefficients;natural signals;sparse transforms modeling of natural signals bessel k form density;gaussian distribution	In this paper we investigate the local probability density function (pdf) of natural signals in sparse domains. The statistical properties of natural signals are characterized more accurately in the sparse domains because the sparse domain coefficients (SDCs) have heavy-tailed distribution and have reduced correlation with adjacent coefficients. Our experiments show that a conditionally (given locally estimated variance and shape) independent Bessel K-form (BKF) pdf locally fits the sparse domain's coefficients of natural signals, accurately. To justify this observation, we also investigate the pdf of the locally estimated variance and suggest a Gamma pdf for the locally estimated variance. Since commonly used sparse transformations are orthonormal, the pdf of the sparse domain coefficients must converge to Gaussian distribution by virtue of central limit theorem assuming that natural signals are locally wide sense stationary for small window sizes. Interestingly, we observe that the pdf of the normalized data (on the locally estimated variance) exhibit a Gaussian pdf, which justifies why the BKF pdf is an appropriate fit.	automated theorem proving;bessel filter;coefficient;converge;experiment;fits;portable document format;sparse matrix;stationary process	Hossein Rabbani;Saeed Gazor	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5946647	normal distribution;probability distribution;three-dimensional space;stationary process;gamma distribution;mathematical optimization;probability density function;combinatorics;heavy-tailed distribution;central limit theorem;sparse approximation;gaussian process;histogram;mathematics;hidden markov model;statistics	ML	52.37183896338706	-74.02706551299437	46189
0a85afebaa19c80fddb660110a4352fd22eb2801	neural animation and reenactment of human actor videos		We propose a method for generating (near) video-realistic animations of real humans under user control. In contrast to conventional human character rendering, we do not require the availability of a production-quality photo-realistic 3D model of the human, but instead rely on a video sequence in conjunction with a (medium-quality) controllable 3D template model of the person. With that, our approach significantly reduces production cost compared to conventional rendering approaches based on production-quality 3D models, and can also be used to realistically edit existing videos. Technically, this is achieved by training a neural network that translates simple synthetic images of a human character into realistic imagery. For training our networks, we first track the 3D motion of the person in the video using the template model, and subsequently generate a synthetically rendered version of the video. These images are then used to train a conditional generative adversarial network that translates synthetic images of the 3D model into realistic imagery of the human. We evaluate our method for the reenactment of another person that is tracked in order to obtain the motion data, and show video results generated from artist-designed skeleton motion. Our results outperform the state-of-the-art in learning-based human image synthesis. Project page: this http URL	3d modeling;algorithm;artificial neural network;augmented reality;computer graphics;experiment;holomatix rendition;motion capture;pc game;polygonal modeling;speech synthesis;synthetic intelligence;text corpus;user interface;visual effects	Lingjie Liu;Weipeng Xu;Michael Zollhöfer;Hyeongwoo Kim;Florian Bernard;Marc Habermann;Wenping Wang;Christian Theobalt	2018	CoRR		machine learning;generative grammar;skeleton (computer programming);rendering (computer graphics);artificial intelligence;artificial neural network;animation;computer science	Vision	25.253106273888623	-53.86156182251961	46210
fc1d4ccfe5a3bc5dfeae5508bb13f8ddc79946a2	fuzzy morpholgogy with fuzzy adaptive structuring element and its application	mathematical morphology;mathematical morphology feature extraction fuzzy set theory;end face inspection fuzzy morphology fuzzy adaptive structuring element charateristic extraction optical fiber connector;fuzzy set theory;morphology inspection shape optical fibers connectors feature extraction optical imaging;feature extraction;fuzzy adaptive structuring element automatic inspection system fiber connector end face inspection set theoretic operation ambiguous image characteristic extraction method fuzzy mathematical morphology	Fuzzy mathematical morphology is generally a characteristic extraction method from an Ambiguous image. Fuzzy mathematical morphology is a set theoretic operation of object image and structuring element that have a shape and value. The structuring element's size, shape, and the value need to be selected before the operation, and the result of the selection will influence the applied image. In this paper, we show an end-face inspection example of fiber-connector using Fuzzy mathematical morphology using Fuzzy adaptive structuring element. Fuzzy Adaptive Structuring Element determines shapes, size and values of structuring element automatically by searching for the local region in an input image. The results show that the Fuzzy adaptive structuring element is sensitive to ambiguous images and useful for automatic inspection systems using fuzzy morphology and is effective for extraction characteristics.	ambiguous grammar;attachments;galaxy morphological classification;mathematical morphology;set theory;software bug;structuring element	Takuo Kikuchi	2013	2013 International Symposium on Intelligent Signal Processing and Communication Systems	10.1109/ISPACS.2013.6704560	computer vision;pattern recognition;mathematics;engineering drawing;top-hat transform	Arch	43.47630234441415	-65.73778332434394	46254
6cf9fc9f0c55c36e1179e2fd8bf3d1d05ab077df	studying cerebral vasculature using structure proximity and graph kernels	sensitivity and specificity;female;imaging three dimensional;circle of willis;male;radiographic image enhancement;cerebral angiography;reproducibility of results;algorithms;pattern recognition automated;humans;radiographic image interpretation computer assisted	An approach to study population differences in cerebral vasculature is proposed. This is done by (1) extending the concept of encoding cerebral blood vessel networks as spatial graphs and (2) quantifying graph similarity in a kernel-based discriminant classifier setup. We argue that augmenting graph vertices with information about their proximity to selected brain structures adds discriminative information and consequently leads to a more expressive encoding. Using graph-kernels then allows us to quantify graph similarity in a principled way. To demonstrate our approach, we assess the hypothesis that gender differences manifest as variations in the architecture of cerebral blood vessels, an observation that previously had only been tested and confirmed for the Circle of Willis. Our results strongly support this hypothesis, i.e, we can demonstrate non-trivial, statistically significant deviations from random gender classification in a cross-validation setup on 40 healthy patients.	blood vessel;blood supply aspects;cross-validation (statistics);discriminant;graph - visual representation;kernel (operating system);patients;preparation;sex characteristics;triangulation	Roland Kwitt;Danielle F. Pace;Marc Niethammer;Stephen R. Aylward	2013	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-40763-5_66	computer vision;computer science;artificial intelligence;mathematics;algorithm	Vision	27.288325179472043	-79.25603826213094	46274
334638a6025bf0944f8b28de82d94486dbee5df4	preprocessing correction for micronucleus image detection affected by contemporaneous alterations	gaussian noise;blood;blood flow measurement;cellular biophysics;image matching;medical image processing;gaussian noise;contemporaneous alteration;flow cytometer measurement device;human lymphocyte;micronucleus image detection;pattern-matching algorithm;preprocessing correction;exposure;gaussian noise;flow cytometer;image enhancement;image processing;out of focus	This paper presents a method that detects and corrects alterations of 1, exposure; 2, out-of-focus; and 3, Gaussian noise affecting, contemporaneously, the images that are acquired in flow cytometer measurement devices. These alterations reduce image quality and interfere with correct micronucleus (MN) detection in a lymphocyte. The objectives of the proposed correction are given as follows: 1, to correctly process the image with the pattern-matching algorithm in order to detect the MN in human lymphocytes; 2, to minimize doubtful detections; and 3, to enhance the confidence that, in rejected images, MNs cannot be detected. Numerical and experimental tests confirm the validity of the proposed correction method and permit the evaluation of the upper and lower bounds of the admissible variation range of each alteration.	algorithm;image quality;pattern matching;preprocessor;sensor	Domenico Luca Carnì;Domenico Grimaldi;Francesco Lamonaca	2007	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2007.900160		Vision	38.32325200876678	-76.32532970615392	46280
72ff0fb0665075b3bc36041c9429f8fbe9b0937b	data fusion approach in the possibilistic context : application to the segmentation of mr images		The paper presents the evaluation of the segmentation of MR images using the multispectral fusion approach in the possibility theory context. the process of fusion consists of three parts : (1) information extraction, (2) information aggregation, and (3) decision step. Information provided by T2-weighted and PDweighted images is extracted and modeled separately in each one using fuzzy logic, fuzzy maps obtained are combined with an operator which can managing the uncertainty and ambiguity in the images and the final segmented image is constructed in decision step. Some results are presented and discussed. Keywordsfusion; possibility theory; segmentation; MR images.	algorithm;fuzzy logic;image fusion;image segmentation;information extraction;map;multispectral image;numerical analysis;oracle fusion middleware;possibility theory;tomography	Lamiche Chaabane;Abdelouahab Moussaoui	2011			computer vision;sensor fusion;artificial intelligence;scale-space segmentation;segmentation;computer science	Vision	41.599646944018104	-72.13002116727046	46306
4b9b88c59eb2ea58391e7955ab9b0cc52d6fc07e	cardiac motion estimation by optimizing transmural homogeneity of the myofiber strain and its validation with multimodal sequences	cardiac strain;sensitivity and specificity;cardiac motion estimation;echocardiography three dimensional;motion;image enhancement;image interpretation computer assisted;myocytes cardiac;multimodal imaging;reproducibility of results;myocardial contraction;algorithms;humans;magnetic resonance imaging cine;diffeomorphic registration;myofiber orientation;elasticity imaging techniques	Quantitative motion analysis from cardiac imaging is important to study the function of heart. Most of existing image-based motion estimation methods model the myocardium as an isotropically elastic continuum. We propose a novel anisotropic regularization method which enforces the transmural homogeneity of the strain along myofiber. The myofiber orientation in the end-diastolic frame is obtained by registering it with a diffusion tensor atlas. Our method is formulated in a diffeomorphic registration framework, and tested on multimodal cardiac image sequences of two subjects using 3D echocardiography and cine and tagged MRI. Results show that the estimated transformations in our method are more smooth and more accurate than those in isotropic regularization.	atlases;cine procedure;diastole;echocardiography;echocardiography, doppler, color;elastic net regularization;manifold regularization;matrix regularization;motion estimation;multimodal interaction;myocardium;optimizing compiler;tracer;triune continuum paradigm;cell transformation;registration - actclass	Zhijun Zhang;David J. Sahn;Xubo B. Song	2013	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-40811-3_62	computer vision;motion;mathematics;geometry;nuclear medicine	Vision	43.66470660534721	-79.9109123881672	46346
29b9974810ccd1d0b6344e59b608e3e62df677da	hough transform with dynamic thresholding for robust and real-time detection of complex curves in images	real time systems hough transforms image segmentation object detection;image segmentation;shape detection;shape transforms robustness real time systems image edge detection noise equations;proceedings paper;hough transforms;hough transform;image signal processing;real time application image signal processing hough transform shape detection;real time application;object detection;first order directional derivative hough transform dynamic thresholding method real time detection complex curves edge pixels hough space equal width shape detection capability pixel selection omni images;real time systems	A dynamic thresholding method is proposed for use in the Hough transform to detect complex curves in images robustly. While determining edge pixels contributing to the peak in the Hough space for detecting a curve with noise and other errors, the proposed method can endure the errors by detecting pixels coming from an equal-width shape which is centered at the curve with a small width everywhere along the curve. This equal-width shape detection capability is accomplished by the use of a dynamic threshold for pixel selection, which is derived from the use of the first-order directional derivative of the function describing the curve. Three conventional methods are compared to show the superiority in robustness of the proposed method via experimental results, and a real-time application of the method for quick detection of lines in omni-images is also demonstrated.	directional derivative;first-order predicate;hough transform;pixel;real-time clock;real-time computing;sensor;thresholding (image processing)	Shen-En Shih;Wen-Hsiang Tsai	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6637892	hough transform;computer vision;computer science;pattern recognition;mathematics;image segmentation;computer graphics (images)	Vision	45.43263287165734	-65.70125377984347	46356
77c9c1210d3b9b0b0c33d890d91572fb97d79c9e	the colour in the upcoming mpeg-7 standard	image color analysis transform coding histograms feature extraction image coding layout standards;histograms;image coding;standards;layout;transform coding;video coding;image color analysis;feature extraction;mpeg 7 colour spaces image retrieval content based search feature histogram;image retrieval	The colour spaces supported by the different image and video coding standards are presented in the present communication. Extensive reference to the colour spaces and the relevant colour descriptors supported by the MPEG-7 standard is given, and experiments on colour-based image retrieval efficiency are illustrated.	color histogram;color space;data compression;database;experiment;image retrieval;key frame;mpeg-7;shot transition detection;video coding format	Charilaos Christopoulos;Daniel Berg;Athanassios N. Skodras	2000	2000 10th European Signal Processing Conference		computer vision;feature detection;visual word;computer science;pattern recognition;automatic image annotation;information retrieval	Vision	38.17143819207602	-52.136674541897676	46363
baa015c35bbf7a889f1e39857659c59b68ee306a	2d-pca based statistical shape model from few medical samples	statistical shape model;training;object shape variation;matrix algebra;data mining;shape feature;shape representation;shape liver feature extraction computed tomography image segmentation signal processing educational institutions information science biomedical engineering information analysis;shape;three dimensional displays;medical image processing;principal component analysis;solid modeling;principal component analysis 2d pca object shape variation shape representation method statistical shape modeling shape feature 2d matrices generalization;2d matrices;statistical shape modeling;principal component analysis matrix algebra medical image processing;shape representation method;generalization;2d pca;covariance matrix	Statistical shape model (SSM) is to model the shape variation of an object. In this paper, we propose an efficient shape representation method and a new 2D-PCA based statistical shape modeling. In our proposed method, we used the radii of these surface points as shape feature instead of their coordinates, and the shape is represented by a 2D matrices. We then apply 2D-PCA to construct a statistical shape model with generalization even from fewer samples.	feature model;shape context;statistical shape analysis	Tomoko Tateyama;Amir Hossein Foruzan;Yen-Wei Chen	2009	2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIH-MSP.2009.246	active shape model;shape of the distribution;generalization;point distribution model;computer vision;covariance matrix;active appearance model;shape;heat kernel signature;machine learning;pattern recognition;principal geodesic analysis;shape analysis;mathematics;solid modeling;statistics;principal component analysis	Robotics	44.07541451524998	-76.66569644292443	46364
9ea85a81fdcc3800cfeef8a3e6cffc8a9c0b101a	a new design based-svm of the cnn classifier architecture with dropout for offline arabic handwritten recognition		In this paper we explore a new model focused on integrating two classifiers; Convolutional Neural Network (CNN) and Support Vector Machine (SVM) for offline Arabic handwriting recognition (OAHR) on which the dropout technique was applied. The suggested system altered the trainable classifier of the CNN by the SVM classifier. A convolutional network is beneficial for extracting features information and SVM functions as a recognizer. It was found that this model both automatically extracts features from the raw images and performs classification. Additionally, we protected our model against over-fitting due to the powerful performance of dropout. In this work, the recognition on the handwritten Arabic characters was evaluated; the training and test sets were taken from the HACDB and IFN/ENIT databases. Simulation results proved that the new design based-SVM of the CNN classifier architecture with dropout performs significantly more efficiently than CNN based-SVM model without dropout and the standard CNN classifier. The performance of our model is compared with character recognition accuracies gained from state-of-the-art Arabic Optical Character Recognition, producing favorable results.	dropout (neural networks);online and offline	Mohamed Elleuch;Rania Maalej;Monji Kherallah	2016		10.1016/j.procs.2016.05.512	speech recognition;computer science;machine learning;pattern recognition	ML	24.833762867160267	-62.013102767541255	46423
5fbc65661bc1dfd5f29dc4851b1112d94e1181bf	slip detection on natural objects with a biomimetic tactile sensor		Slip detection enables robotic hands to perform complex manipulation tasks by predicting when a held object is about to be dropped. Here we use a support vector machine classifier to detect slip with a biomimetic optical tactile sensor: the TacTip. Previously, this method has been shown to be effective on various artificial stimuli such as flat or curved surfaces. Here, we investigate whether this method generalises to novel, everyday objects. Five different objects are tested which vary in shape, weight, compliance and texture as well as being common objects that one might encounter day-to-day. Success of up to 90% is achieved which demonstrates the classifier’s ability to generalise to a variety of previously unseen, natural objects.	biomimetics;tactile sensor	Jasper Wollaston James;Nathan F. Lepora	2018		10.1007/978-3-319-95972-6_24	support vector machine;tactile sensor;slip (materials science);computer vision;artificial intelligence;computer science	Robotics	25.745199797141527	-67.25160482769515	46430
25712cac60e6e5a7225f1f97c2bc7c6918b27a9b	drusen detection based on scale-space with feature stability	allied health professions and studies;biological sciences	This paper proposes a novel segmentation technique for drusen detection in retinal fundus images based on the scale space approach endowed with feature stability. To select significant blobs representing drusen, the stability of the features of scale-space blobs is taken into account in addition to conventional blobs' lifetime. The algorithm was tested with over 20,000 blobs from 26 retinal images and the results show that the method can detect variable size and variable shape drusen efficiently with Positive Predictive Value over 95%.	scale space	Cattleya Duanggate;Bunyarit Uyyanonvara;Stanislav S. Makhanov;Sarah Barman;Thomas H. Williamson	2011			computer vision;geography;optics;computer graphics (images)	Vision	37.073071822043666	-75.95137514319826	46508
49387473cb76ebfddd133ee7538be369d2af477c	lumen detection for capsule endoscopy	lumen detection;kernel;navigation endoscopes image sequences medical image processing;colon;video sequences;video sequences lumen detection capsule endoscopy navigation gastrointestinal tract;pixel kernel navigation endoscopes colon iris image color analysis;navigation;image color analysis;gastrointestinal tract;medical image processing;visual cues;pixel;endoscopes;capsule endoscopy;iris;image sequences	In this paper, two visual cues are proposed, to be exploited for the navigation of active endoscopic capsules within the gastrointestinal (GI) tract. These cues consist of the detection and tracking of the lumen and of an illumination highlight in capsule endoscopy (CE) images. The proposed approach aims at developing vision algorithms which are robust with respect to the challenging imaging conditions encountered in the GI tract and the great variability of the acquired images. Cases where no or more than one lumens exists, are also detected. The proposed approach extends the state-of-the-art in lumen detection, and is demonstrated for in-vivo video sequences acquired from endoscopic capsules.	airport time capsule;algorithm;spatial variability;tract (literature);video-in video-out	Xenophon Zabulis;Antonis A. Argyros;Dimitris P. Tsakiris	2008	2008 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2008.4650969	computer vision;navigation;kernel;sensory cue;computer science;pixel	Robotics	39.6554932977988	-75.98713745828834	46524
7033af1d832d9d81c374cd6b0a9b0996da09ce36	efficient robot object recognition technique based on distance kernel pca	object recognition;kernel;robot camera robot object recognition technique distance kernel pca principal component analysis feature extraction algorithm linear method decision making orl face database image illumination image distortion;training;image sensors;feature space;face recognition;robot vision;principal component analysis kernel feature extraction training robots equations object recognition;feature extraction;principal component analysis;robots;nearest neighbor;kernel pca;robot vision decision making face recognition feature extraction image sensors object recognition principal component analysis	Feature extraction is the key issue in a recognition system. Principal Component Analysis (PCA) is one of the most widely used feature extraction algorithms. But it is inadequate for this linear method to describe real images which contain complex nonlinear variations, such as illumination, distortion and so on. In this paper, an efficient object recognition method based on distance Kernel PCA (KPCA) is proposed. First, a new kernel called distance kernel is presented to set up the corresponding relation between the higher-dimensional feature space and the original input space. Then, PCA was performed in the higher-dimensional space and a nearest neighbor strategy was used for decision-making. The experiments on both ORL face database and general object image dataset collected by the robot camera illustrate that KPCA with the distance kernel outperforms PCA in robot object recognition: higher recognition accuracy and less computing time.	algorithm;clutter;database;distortion;experiment;feature extraction;feature vector;illumination (image);image processing;kernel (operating system);kernel principal component analysis;nonlinear system;outline of object recognition;performance;pose (computer vision);return loss;robot;scale-invariant feature transform	Jinfu Yang;Min Song;Ming-Ai Li	2010	2010 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2010.5723501	facial recognition system;robot;computer vision;kernel method;kernel;feature vector;feature;feature extraction;kernel principal component analysis;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;image sensor;3d single-object recognition;k-nearest neighbors algorithm;dimensionality reduction;principal component analysis	Robotics	33.09445243771932	-58.204091564318304	46528
ecd983a3850b1bd4d677aa6194ae50d8a1c69712	feature-level fusion for effective palmprint authentication	base donnee;image processing;authentication;database;procesamiento imagen;base dato;filtro gabor;traitement image;similitude;authentification;gabor filter;autenticacion;hamming distance;distance hamming;similarity;filtre gabor;fusion rule;similitud;distancia hamming	A feature-level fusion approach is proposed for improving the efficiency of palmprint identification. Multiple Gabor filters are employed to extract the phase information on a palmprint image, which is then merged according to a fusion rule to produce a single feature called the Fusion Code. The similarity of two Fusion Codes is measured by their normalized hamming distance. A database containing 7,752 palmprint images from 386 different palms is used to validate the performance of the proposed method. Empirically comparing our previous non-fusion approach and the proposed method, improvement in verification is ensured	authentication;byte;database;embedded system;feature extraction;fingerprint;hamming distance;preprocessor;run time (program lifecycle phase)	Adams Wai-Kin Kong;David Zhang	2004		10.1007/978-3-540-25948-0_103	computer vision;speech recognition;image processing;computer science;pattern recognition;authentication;mathematics;computer security	Vision	35.01736809249527	-61.22459416583249	46575
cd326628855404e6a2be4109466298ed36006f95	deep convolutional networks for pancreas segmentation in ct imaging	parallel computing;ct;networks;paper;heart;liver;image segmentation;computed tomography;neural networks;computer aided diagnosis;image classification;nvidia geforce gtx titan z;cuda;deep learning;pancreas;nvidia;abdomen;medicine;tomography;kidney	Automatic organ segmentation is an important prerequisite for many computer-aided diagnosis systems. The high anatomical variability of organs in the abdomen, such as the pancreas, prevents many segmentation methods from achieving high accuracies when compared to state-of-the-art segmentation of organs like the liver, heart or kidneys. Recently, the availability of large annotated training sets and the accessibility of affordable parallel computing resources via GPUs have made it feasible for “deep learning” methods such as convolutional networks (ConvNets) to succeed in image classification tasks. These methods have the advantage that used classification features are trained directly from the imaging data. We present a fully-automated bottom-up method for pancreas segmentation in computed tomography (CT) images of the abdomen. The method is based on hierarchical coarse-to-fine classification of local image regions (superpixels). Superpixels are extracted from the abdominal region using Simple Linear Iterative Clustering (SLIC). An initial probability response map is generated, using patch-level confidences and a two-level cascade of random forest classifiers, from which superpixel regions with probabilities larger 0.5 are retained. These retained superpixels serve as a highly sensitive initial input of the pancreas and its surroundings to a ConvNet that samples a bounding box around each superpixel at different scales (and random non-rigid deformations at training time) in order to assign a more distinct probability of each superpixel region being pancreas or not. We evaluate our method on CT images of 82 patients (60 for training, 2 for validation, and 20 for testing). Using ConvNets we achieve average Dice scores of 68% ± 10% (range, 43-80%) in testing. This shows promise for accurate pancreas segmentation, using a deep learning approach and compares favorably to state-of-the-art methods.	accessibility;ct scan;computer vision;convolutional neural network;deep learning;graphics processing unit;iterative method;minimum bounding box;parallel computing;random forest;spatial variability;tomography;top-down and bottom-up design	Holger Roth;Amal Farag;Le Lu;Evrim Turkbey;Ronald M. Summers	2015		10.1117/12.2081420	computer vision;contextual image classification;haplogroup ct;simulation;computer science;deep learning;tomography;image segmentation;scale-space segmentation;heart	Vision	31.786865210811	-75.46476775325087	46590
5440362112bc440205ab5b193aaa7ec5fad3308e	detection of longitudinal ulcer using roughness value for computer aided diagnosis of crohn's disease	crohn s disease;small and large intestines;ct image;roughness value;computer aided diagnosis;small intestine;digestive system;intestine;medical diagnostics;endoscopes;rough surface;inflammatory disease;digestive tract;false positive;diseases and disorders	The purpose of this paper is to present a new method to detect ulcers, which is one of the symptoms of Crohn's disease, from CT images. Crohn's disease is an inflammatory disease of the digestive tract. Crohn's disease commonly affects the small intestine. An optical or a capsule endoscope is used for small intestine examinations. However, these endoscopes cannot pass through intestinal stenosis parts in some cases. A CT image based diagnosis allows a physician to observe whole intestine even if intestinal stenosis exists. However, because of the complicated shape of the small and large intestines, understanding of shapes of the intestines and lesion positions are difficult in the CT image based diagnosis. Computer-aided diagnosis system for Crohn's disease having automated lesion detection is required for efficient diagnosis. We propose an automated method to detect ulcers from CT images. Longitudinal ulcers make rough surface of the small and large intestinal wall. The rough surface consists of combination of convex and concave parts on the intestinal wall. We detect convex and concave parts on the intestinal wall by a blob and an inverse-blob structure enhancement filters. A lot of convex and concave parts concentrate on roughed parts. We introduce a roughness value to differentiate convex and concave parts concentrated on the roughed parts from the other on the intestinal wall. The roughness value effectively reduces false positives of ulcer detection. Experimental results showed that the proposed method can detect convex and concave parts on the ulcers.© (2011) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.		Masahiro Oda;Takayuki Kitasaka;Kazuhiro Furukawa;Osamu Watanabe;Takafumi Ando;Hidemi Goto;Kensaku Mori	2011		10.1117/12.877507	digestion;type i and type ii errors	AI	37.30399410107556	-77.67970575455028	46665
8699dce4c02ec115fde13a0f09b040a157ea8064	a weighted discriminative dictionary learning method for depression disorder classification using fmri data	databases;atomic measurements;training;testing;magnetic resonance imaging;dictionaries;head	In this paper, we present a novel depression dis-order classification algorithm, named weighted discriminative dictionary learning (WDDL), based on functional magnetic resonance imaging (fMRI) data. The underlying relationship between samples and dictionary atoms is exploited by introducing an adaptive weighting scheme. Tested on fMRI data of 29 patients with depression and 29 healthy controls, our algorithm outperforms all other classification methods compared in this work. Furthermore, we detect the discriminative brain regions of patients which can reveal the pathogenesis of depression disorder.	algorithm;dictionary;limbo;machine learning;resonance	Xin Wang;Yanshuang Ren;Yehui Yang;Wensheng Zhang;Naixue N. Xiong	2016	2016 IEEE International Conferences on Big Data and Cloud Computing (BDCloud), Social Computing and Networking (SocialCom), Sustainable Computing and Communications (SustainCom) (BDCloud-SocialCom-SustainCom)	10.1109/BDCloud-SocialCom-SustainCom.2016.97	speech recognition;computer science;magnetic resonance imaging;machine learning;pattern recognition;software testing;head	Vision	29.472729073281652	-78.66062909392254	46674
65bdf101cd21e217ad089c076f0746dc28dea19f	detection of wide linear structures by fusion of width and gray	detectors;region threshold;image segmentation;natural scenes edge detection image fusion image segmentation image sequences;edge detection;parallel edges;image fusion;region of interest roi;region threshold line width parallel edges region of interest roi;estimation;image edge detection;roads;feature extraction;line width;transforms;edge detection wide linear structure detection line width feature line gray feature fusion line detection line position detection line thickness higher level feature structure asymmetry parallel edges line orientation region of interest roi otsu region threshold wide line structure segmentation test sequence image samples natural scene;natural scenes;image edge detection estimation detectors feature extraction image segmentation transforms roads;image sequences	Lines provide important information in images and line detection is crucial in many applications. Many line features can be used to detect line position while line width (i.e., thickness) is a more structured, higher-level feature compared to edge or other line features. Every point of the wide line structure has its own width in spite of the structure's asymmetry. In this paper, we use the parallel edges to get the line orientation and width. We do not need to know the actual width of the line, but rather recover it to get the region of interest (ROI). Then use a modified OTSU obtaining proper region threshold T to segment the wide line structures. By fusing feature of width and gray, a sequence of tests has been conducted on a variety of image samples obtained from simple natural scene and our experimental results demonstrate the practical and robust of the proposed method.	edge detection;multiple edges;need to know;region of interest;thickness (graph theory)	Anna Zhu;Guoyou Wang;Ran Wang	2013	2013 IEEE International Conference on Multimedia and Expo (ICME)	10.1109/ICME.2013.6607574	computer vision;estimation;detector;edge detection;multiple edges;feature extraction;computer science;pattern recognition;image segmentation;image fusion;computer graphics (images)	Robotics	45.72406755871011	-65.38664768578035	46712
bcd8cea47c755b455b74982d54fb5e4105732b56	active vector graph for regularized tesselation	active contours image segmentation object detection image edge detection pixel trajectory equations;graph theory;optimisation;active contour vector graph regularized tesselation discretized parametric curve sparse graph optimization;tesselation;active contour;image segmentation;edge detection;nickel;biological system modeling;tesselation graph active contour;active contours;optimisation edge detection graph theory;image edge detection;data structures;graph;parametric curve;data models	A discretized parametric curve can be seen as a sparse graph of vectors where each vertex is linked to two other vertices. Following this observation, we propose to generalize parametric active contours to a larger framework we call active vector graphs. This can be achieved by allowing each vertex of a graph of vectors to be linked to more than two vertices. An active graph does not need to be parameterized and the computation of its energy can be achieved by integrating over all its vertices. The optimization scheme pushes the graph toward the edges and in the direction of the normal which we show can be defined for all vertices. This offers a regularized model which adresses in an elegant and very fast way a certain set of problems such as the segmentation of connected regions. The method is described along with an exemple.	computation;discretization;mathematical optimization;sparse graph code;sparse matrix;vertex (geometry);vertex (graph theory)	Auguste Genovesio	2009	2009 16th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2009.5414154	loop;nickel;graph power;data modeling;computer vision;mathematical optimization;topological graph;independent set;edge detection;multiple edges;level structure;graph center;parametric equation;degree;computer science;graph theory;hypercube graph;pattern recognition;cycle graph;vertex;active contour model;path graph;mathematics;biconnected graph;tessellation;image segmentation;path;graph;wheel graph;distance;quartic graph;complement graph;neighbourhood;strength of a graph	Robotics	48.534911358268175	-67.67053883317664	46715
f4a7ec4ea46529e83603adcc41b2a051785dff73	gpca-sift: a new local feature descriptor for scene image classification		In this paper, a new local feature descriptor called GPCA-SIFT is proposed for scene image classification. Like PCA-SIFT, we get the key points using the detection method in Scale Invariant Feature Transform (SIFT) and extract a 41 * 41 patch for each key point. Then we calculate the horizontal and vertical gradient of each pixel in the patch. However, instead of concatenating two gradient matrices, we directly work with the two-dimensional matrix and apply Generalized Principal Component Analysis (GPCA) to reduce it to a lower-dimensional matrix. Finally, we concatenate the reduced matrix and form a 1D vector. Compared with Principal Component Analysis (PCA), it preserves more spatial locality information. When applied in multi-class scene image classification, our proposed descriptor outperforms other related algorithms in terms of classification accuracy.	computer vision;scale-invariant feature transform	Lei Ju;Ke Xie;Hao Zheng;Baochang Zhang;Wankou Yang	2016		10.1007/978-981-10-3005-5_24	contextual image classification;feature detection;local binary patterns;gloh;feature	Vision	35.42543547234576	-58.510021581379334	46722
caa53b18d7b7dfb67ab954a2efadb6dac7ab4e5b	efficient sketch recognition based on shape features and multidimensional indexing		Face sketch recognition on real forensic mug shot photo galleries is a complex task since a large amount of images needs to be matched in few seconds to produce a useful outcome. Several effective solutions for sketch-based subject identification have been recently proposed, but the cost of linear search makes them not scalable when large databases have to be scanned. In this work we propose an approach which combines the use of efficient shape features for sketch-photo matching with a suitable indexing structure based on dimensionality reduction. The proposed method provides a preliminary set of candidate photos to be used as input for the final identification based on state-of-the-art techniques, offering scalability and time efficiency without noticeably compromising recognition accuracy, as confirmed by the experimental results.		Simone Buoncompagni;Annalisa Franco;Dario Maio	2017		10.1007/978-3-319-59162-9_17	sketch recognition	Vision	36.42251918913009	-55.61414625174832	46736
b27dbd1e1490f1c11a91b69b0a4bd1dec8e21f34	subpixel estimation of shifts directly in the fourier domain	group delay;senal bidimensional;shape constraints;quadratic function;funcion cuadratica;fonction quadratique;validacion cruzada;retardo grupo;image resolution;cost function;retard groupe;retardo fase;phase difference;subpixel alignment;subpixel alignment phase correlation registration;matrix algebra;image registration fourier analysis image resolution matrix algebra expectation maximisation algorithm;funcion coste;retard phase;interpolation phase estimation magnetic resonance imaging cost function robustness frequency shape filters delay image analysis;generalized cross validation;expectation maximization;mixture model;image registration;validation croisee;registration;algorithme em;fourier analysis;fonction cout;signal bidimensionnel;teoria mezcla;algoritmo em;two dimensional signal;cross validation;mixture theory;em algorithm;theorie melange;phase delay;phase correlation;algorithms artificial intelligence computer graphics image enhancement image interpretation computer assisted information storage and retrieval models statistical numerical analysis computer assisted pattern recognition automated signal processing computer assisted subtraction technique;expectation maximization subpixel estimation fourier domain continuous phase difference discrete phase difference shifted images two dimensional sawtooth signal subpixel registration phase difference matrix frequency axis noninteger fraction overdetermined homogeneous quadratic cost function rank constraint shape constraint group delay generalized cross validation mixture model;expectation maximisation algorithm	In this paper, we establish the exact relationship between the continuous and the discrete phase difference of two shifted images, and show that their discrete phase difference is a two-dimensional sawtooth signal. Subpixel registration can, thus, be performed directly in the Fourier domain by counting the number of cycles of the phase difference matrix along each frequency axis. The subpixel portion is given by the noninteger fraction of the last cycle along each axis. The problem is formulated as an overdetermined homogeneous quadratic cost function under rank constraint for the phase difference, and the shape constraint for the filter that computes the group delay. The optimal tradeoff for imposing the constraints is determined using the method of generalized cross validation. Also, in order to robustify the solution, we assume a mixture model of inlying and outlying estimated shifts and truncate our quadratic cost function using expectation maximization.	apache axis;axis vertebra;cross reactions;expectation–maximization algorithm;group delay and phase delay;loss function;mixture model;pixel;robustification;sawtooth (cellular automaton);truncation	Murat Balci;Hassan Foroosh	2006	IEEE Transactions on Image Processing	10.1109/TIP.2006.873457	computer vision;mathematical optimization;expectation–maximization algorithm;computer science;machine learning;group delay and phase delay;mathematics;statistics	Vision	50.11794070387473	-75.17926748843456	46745
0beca2d7ba2d4036da7fae7514b72eb83d44be78	efficient statistical/morphological cell texture characterization and classification	neural networks morphological cell texture characterization statistical cell texture characterization morphological cell texture classification statistical cell texture classification automatic fluorescence labelled cell classification method statistical texture descriptors morphological texture descriptors supervised classification logistic regression random forest;neural nets;statistical analysis image classification image texture learning artificial intelligence neural nets;image classification;logistics pattern recognition image analysis feature extraction neural networks speckle shape;image texture;statistical analysis;learning artificial intelligence	This paper presents the different steps for an automatic fluorescence-labelled cell classification method. First a data features study is discussed in order to describe cell texture by means of morphological and statistical texture descriptors. Then, results on supervised classification using logistic regression, random forest and neural networks, for both morphological and statistical descriptors, is presented. We propose a final consolidated classifier based on a weighted probability for each class, where the weights are given by the empirical classification performances. The method is evaluated on ICPR'12 HEp-2 dataset contest.	artificial neural network;cell (microprocessor);granulometry (morphology);logistic regression;machine learning;morphological pattern;performance;random forest;statistical classification;supervised learning	Guillaume Thibault;Jesús Angulo	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		image texture;computer vision;contextual image classification;computer science;machine learning;pattern recognition;artificial neural network	Vision	35.627232949555136	-73.17647133179395	46815
0b63324fba6df9269610aaee8c33cf157315ddc5	a markov process using curvature for filtering curve images	stochastic process;image processing;modelo markov;non linear filter;edge detection;procesamiento imagen;courbure;stochastic differential equation;image bruitee;traitement image;deteccion contorno;imagen sonora;detection contour;markov model;noisy image;markov process;processus stochastique;curvatura;curvature;filtro no lineal;modele markov;proceso estocastico;filtre non lineaire	A Markov process model for contour curvature is introduced via a stochastic differential equation. We analyze the distribution of such curves, and show that its mode is the Euler spiral, a curve minimizing changes in curvature. To probabilistically enhance noisy and low contrast curve images (e.g., edge and line operator responses), we combine this curvature process with the curve indicator random field, which is a prior for ideal curve images. In particular, we provide an expression for a nonlinear, minimum mean square error filter that requires the solution of two elliptic partial differential equations. Initial computations are reported, highlighting how the filter is curvature-selective, even when curvature is absent in the input.		Jonas August;Steven W. Zucker	2001		10.1007/3-540-44745-8_33	total curvature;stochastic process;mathematical optimization;stochastic differential equation;edge detection;topology;fundamental theorem of curves;image processing;osculating circle;tripling-oriented doche–icart–kohel curve;asymptotic curve;mathematics;geometry;torsion of a curve;curvature;markov process;markov model;statistics;curve fitting	Vision	52.07128376312941	-67.6972846231636	46829
2177da6e8d0cf1d017ccd5f2c2caa1939cb04d20	human gait and posture analysis for diagnosing neurological disorders	patient diagnosis;image recognition;image recognition medical image processing neurophysiology gait analysis video signal processing image sequences neural nets image motion analysis feature extraction;image motion analysis;still frame images;neural nets;video signal processing;gait abnormalities;video analysis;parkinson s disease human gait posture analysis neurological disorders video analysis system gait abnormalities static human posture analysis visual features still frame images walking sequence neural network patient diagnosis;walking sequence;static human posture analysis;feature extraction;medical image processing;neurological disorders;pattern classification;gait analysis;visual features;parkinson s disease;biomedical image processing;image analysis;posture analysis;video analysis system;neurophysiology;human gait;humans image color analysis image motion analysis image processing neural networks laboratories hardware software performance information analysis performance analysis;neural network;image sequences	This paper describes a number of new techniques to enhance the performance of a video analysis system, free from motion markers and complicated setup procedures, for the purpose of quantitatively identifying gait abnormalities in static human posture analysis. Visual features are determined from still frame images out of the entire walking sequence. The features are used as a guide to train a neural network, in an attempt to providing assistance to clinicians in diagnosing patients with neurological disorders.		Howard Lee;Ling Guan;John A. Burne	2000		10.1109/ICIP.2000.899439	computer vision;speech recognition;gait analysis;gait;feature extraction;computer science;machine learning;artificial neural network	Vision	26.7364937268086	-72.18468617623257	46830
fec3c442dfd26022a973f70af878e3deb5faef3f	intelligent retrieval and reuse of cad solid models	search and retrieval;design automation;information retrieval;manufacturing industries;indexing;computer aided manufacturing;indexation;solid modeling;spatial databases;performance analysis;timing analysis;manufacturing industry;spatial relationships;database search;shape design;content based retrieval;virtual manufacturing;solid modeling spatial databases design automation information retrieval manufacturing industries computer aided manufacturing virtual manufacturing indexing content based retrieval performance analysis	The fact that a lot of time in a manufacturing industry is spent in searching for similarly shaped designs from a database of previously manufactured parts and the fact that most of the new designs are modified versions of previous designs, resulted in the need for an efficient system for retrieval and reuse of CAD models. Features and the spatial relationships between the features, form a signature, which can be used to uniquely identify each part. Using this signature we develop an indexing scheme to speed up database searching. In this work we propose a content based search technique to retrieve similar parts from a database of old parts. We also perform a running time analysis of the search and retrieve algorithm.	algorithm;computer-aided design;database;digital signature;time complexity	Chandan Pitta;Michael M. Marefat	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570313	electronic design automation;computer science;engineering;data mining;database;manufacturing;information retrieval;computer-aided manufacturing	Robotics	40.84365442741863	-58.67167317707721	46847
69cafd730f3c0937cbc4c451a02410d0b95cd59f	beta-measure for probabilistic segmentation	image segmentation;half quadratic;spatial coherence;model generation;random measure;markov random field;probability distribution;information and divergence measures;probabilistic segmentation;markov random measure field	We propose a new model for probabilistic image segmentation with spatial coherence through a Markov Random Field prior. Our model is based on a generalized information measure between discrete probability distribution (βMeasure). This model generalizes the quadratic Markov measure field models (QMMF). In our proposal, the entropy control is achieved trough the likelihood energy. This entropy control mechanism makes appropriate our method for being used in tasks that require of the simultaneous estimation of the segmentation and the model parameters.	coherence (physics);image segmentation;markov chain;markov random field;probabilistic automaton;subshift of finite type	Oscar Dalmau Cedeño;Mariano Rivera	2010		10.1007/978-3-642-16761-4_28	probability distribution;markov chain;maximum-entropy markov model;random field;random measure;gibbs measure;markov property;computer science;machine learning;segmentation-based object categorization;pattern recognition;mathematics;image segmentation;markov model;scale-space segmentation;statistics;variable-order markov model;divergence-from-randomness model	Vision	50.797098313778626	-69.83289162139539	46876
1eb22654fbb7516c21a3a454c0c7e9bee1e5e9b5	an intelligent character recognition system with high accuracy and high speed by integrating image-type and logical-type information processings	image recognition;intelligent systems character recognition pattern matching information processing measurement standards image recognition humans image segmentation systolic arrays;image segmentation;associative pattern matching;systolic arrays;optical character recognition;relaxation matching technique;relaxation matching technique ocr image type information processing intelligent character recognition system logical type information processings associative pattern matching rough classification logical type processing structural analysis;pattern matching;logical type processing;information processing;intelligent systems;ocr;humans;logical type information processings;measurement standards;structural analysis;image type information processing;character recognition;high speed;rough classification;intelligent character recognition system;structure analysis	The study presented in this paper is intended to realize an intelligent character recognition system with high accuracy and high speed by integrating an image-type and a logical-type information processing modules. As for imagetype information processing, a new pattern matching technique called associative pattern matching is proposed and the usefulness is verified by some experiments. The results tells us it is useful for rough classification of input patterns. As for logical-type processing, structural analysis of characters is realized by a new relaxation matching technique, which is described in its detail and some experimental results are shown. In the last, integration of these two technique is discussed.	experiment;information processing;intelligent character recognition;linear programming relaxation;optical character recognition;pattern matching;rough set;structural analysis;type theory	Mai Kimura;T. Ejima;H. Aso;H. Yashiro;N. Son;M. Suzuki	1988		10.1109/ICPR.1988.28167	computer vision;information processing;computer science;machine learning;pattern recognition;structural analysis	Robotics	35.7549556928225	-68.25525881585926	46889
e460cb2d50b725be0ed1bbb77138791bc0d8cdd8	fast frequency template matching using higher order statistics	second order;fast frequency template matching;gaussian noise;metodo estadistico;kernel;order statistic;image processing;cost function;complexite calcul;image matching;frequency domain analysis;statistique ordre;simulation;ruido gaussiano;second order statistics sos;additive noise;ruido aditivo;orden 2;central moments;fast fourier transform fast frequency template matching higher order statistics fourth central moment additive gaussian noise;simulacion;bruit additif;statistical method;higher order statistics gaussian noise noise robustness cost function additive noise frequency domain analysis image processing image matching kernel arithmetic;awgn;correlation methods;noise robustness;transformacion fourier rapida;higher order statistics;fourth central moment;fast fourier transform;algorithme;algorithm;complejidad computacion;methode domaine frequence;computational complexity;methode statistique;frequency domain method;pattern matching;robustesse;fonction correlation;bruit gaussien;additive gaussian noise;estadistica orden;correlation function;estadistica orden superior;pattern recognition;statistique ordre superieur;arithmetic;funcion correlacion;robustness;concordance forme;reconnaissance forme;ordre 2;metodo dominio frecuencia;higher order statistic;reconocimiento patron;template matching central moments frequency domain gaussian noise higher order statistics hos second order statistics sos;frequency domain;second order statistics;transformation fourier rapide;template matching;higher order statistics awgn correlation methods;fast fourier transformation;higher order statistics hos;robustez;algoritmo	This correspondence proposes a novel template matching technique using a fourth central moment. The fourth central moment is an established estimator which uses higher order statistics theory, important in the presence of an additive Gaussian noise. By use of some substitutions and complex arithmetic, computation of the fourth central moment is derived from correlation functions of substituting functions. The fourth central moment can be computed using the fast Fourier transform (FFT) approach. Simulation results show that the proposed algorithm performs better than the classical estimators in terms of robustness, while the extra computational cost is negligible.	algorithm;algorithmic efficiency;clinical use template;computation;fast fourier transform;gaussian blur;normal statistical distribution;simulation;template matching;utility functions on indivisible goods	Fedwa Essannouni;Driss Aboutajdine	2010	IEEE Transactions on Image Processing	10.1109/TIP.2009.2037079	computer vision;fast fourier transform;image processing;computer science;calculus;mathematics;frequency domain;algorithm;statistics	Vision	52.562960265485124	-66.58945034075785	46913
c76598bd2542ae1661fc8af314de3a35a438889f	places clustering of full-length film key-frames using latent aspect modeling over sift matches	video indexing duplicate detection scene categorization scene matching video description;performance measure;modelizacion;scene matching;full length film key frames;agregacion;latent aspect modeling;evaluation performance;categorisation;deteccion blanco;duplicate detection;performance evaluation;measurement;motion pictures;video signal processing;application software;cluster recurrent physical locations;probabilistic latent space model;classification non supervisee;helium;information retrieval;image matching;evaluacion prestacion;localization;object background detection;false alarm rate;arriere plan;localizacion;layout;probabilistic approach;representation sous forme image;aggregation;full length movies;detection cible;modelisation;probabilistic model;video indexing;video description;detection objet;full length;categorizacion;public image datasets;background;localisation;false alarm rate place clustering full length film key frames latent aspect modeling sift matches unsupervised classification method feature extraction cluster recurrent physical locations probabilistic latent space model public image datasets full length movies object background detection;senal video;signal video;indexing;enfoque probabilista;approche probabiliste;feature extraction;scene categorization;indexation;clasificacion no supervisada;motion pictures layout indexing cameras object detection measurement information retrieval application software production;signal classification;indizacion;modele probabiliste;agregation;classification signal;unsupervised classification;production;video signal;frame based representation;place clustering;unsupervised classification method;sift matches;classification automatique;automatic classification;taux fausse alarme;modeling;target detection;clasificacion automatica;porcentaje falsa alarma;video signal processing feature extraction image matching object detection;cameras;object detection;categorization;modelo probabilista	An improved unsupervised classification method to extract and link places features and cluster recurrent physical locations (key-places) within a movie is presented. Our approach finds links between key frames of a common key-place based on the use of a probabilistic latent space model over the possible local matches between the key frames image set. This allows the extraction of significant groups of local matching descriptors that may represent characteristic elements of a key-place. An exhaustive evaluation of our approach was conducted on in-house and public image datasets, as well as on full-length movies. Results revealed that our method is very efficient for near-duplicate object/background detection with weak overlap. Performance measurements on full-length movies indicate a recognition rate of about 75% on the key-places clustering with a false alarm rate (FAR) of approximately 2%.	cluster analysis;key frame;unsupervised learning	Maguelonne Héritier;Langis Gagnon;Samuel Foucher	2009	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2009.2017304	layout;statistical model;computer vision;search engine indexing;application software;systems modeling;internationalization and localization;feature extraction;computer science;machine learning;pattern recognition;constant false alarm rate;helium;measurement;statistics;categorization	Vision	45.068971985559266	-58.32525921542683	46930
2cfbc7480a449a5b7821d6123d7e95ce48ebaf5e	automatic image matting using component-hue-difference-based spectral matting	spectral matting;image matting;hue difference;alpha matte	This paper presents automatic image matting using component-hue-difference-based spectral matting to obtain accurate alpha mattes. Spectral matting is the state-of-the-art image matting and it is also a milestone in theoretic matting research. However, the accuracy of alpha matte using spectral matting is usually low without user intervention. In the proposed method, k-means algorithm is used to generate components of a given image. Next, component classification is used based on the hue difference of components to obtain the foreground, background, and unknown components. The corresponding matting components of the foreground, background, and unknown components are obtained via a linear transformation of the smallest eigenvectors of the matting Laplacian matrix. Finally, only matting components of the foreground and unknown components are combined to form the complete alpha matte based on minimizing the matte cost. Experimental results show that the proposed method outperforms the state-of-the-art methods based on spectral matting.		Wu-Chih Hu;Jung-Fu Hsu	2012		10.1007/978-3-642-28490-8_16	computer vision;pattern recognition;computer graphics (images)	Vision	53.31383494956256	-63.158357906202454	46947
7a4fa8ff110b2639860f328505d5ea6db3445cda	infinity laplacian on graphs with gradient terms for image and data clustering	laplacian;segmentation;pde;unsupervised;classification;weighted graphs	In this paper, we introduce a new family of graph-based operators for semi-supervised and unsupervised classification. These operators interpolate between two morphological gradient operators introduced on graphs, and are linked with the discrete infinity Laplacian. Then, we consider semi-supervised classification as the Dirichlet problem associated with this new family of operators. We show the proof of existence and uniqueness of the solution of this problem and propose an implementation. Similarly, we consider unsupervised classification as a diffusion problem associated with this new family of operators to handle it. We finally illustrate these two approaches on image segmentation and data clustering. 2013 Elsevier B.V. All rights reserved.	cluster analysis;image segmentation;interpolation;machine learning;morphological gradient;proof of existence;semi-supervised learning;semiconductor industry;supervised learning;unsupervised learning	Sadia Alkama;Xavier Desquesnes;Abderrahim Elmoataz	2014	Pattern Recognition Letters	10.1016/j.patrec.2013.11.024	mathematical optimization;combinatorics;laplace operator;discrete mathematics;laplacian matrix;biological classification;infinity laplacian;mathematics;segmentation;spectral clustering	AI	52.630397562507994	-70.73958095747395	46955
708f70933c3972104fa1e644c28b354ae3e73fd6	towards real-time traffic sign recognition by class-specific discriminative features	real time;real time traffic;conference paper;minimum distance;local features;principal component analysis;error rate;feature selection;distance transform	Real-time road sign recognition has been of great interest for many years. This problem is often addressed in a two-stage procedure involving detection and classification. In this paper a novel approach to sign representation and classification is proposed. In many previous studies focus was put on deriving a set of discriminative features from a large amount of training data using global feature selection techniques e.g. Principal Component Analysis or AdaBoost. In our method we have chosen a simple yet robust image representation built on top of the Colour Distance Transform (CDT). Based on this representation, we introduce a feature selection algorithm which captures a variable-size set of local image regions ensuring maximum dissimilarity between each individual sign and all other signs. Experiments have shown that the discriminative local features extracted from the template sign images enable minimum-distance classification with error rate not exceeding 7%.	adaboost;digital video;distance transform;eclipse;experiment;feature selection;principal component analysis;real-time transcription;selection algorithm;statistical classification;traffic sign recognition	Andrzej Ruta;Yongmin Li;Xiaohui Liu	2007		10.5244/C.21.24	speech recognition;word error rate;computer science;machine learning;pattern recognition;mathematics;distance transform;feature selection;principal component analysis	Vision	32.46183921085221	-57.12612895359413	46960
e2e0d3be31fdd6bfa01f209cc0d1d33d427aede3	facial expression analysis from 3d range images; comparison with the analysis from 2d images and their integration	image classification;facial expression analysis;face recognition;image analysis principal component analysis electromagnetic compatibility humans face recognition image recognition pixel facial features light scattering;range image;subspace method;image classification rate facial expression analysis 3d range image image integration 2d luminance image facial pose subspace method luminance image image characteristic;image classification face recognition	Even if facial expression analysis from 2D luminance images is the present mainstream, it has problems due to changes in facial pose and lighting. In this paper, we use 3D range images which do not maintain such problems for facial expression analysis. We first apply the subspace method to range and luminance images, and clarify their differences in image characteristics. Examining the validity of range images for facial expression analysis, we consider improvement in correct classification rates by integrating results from range and luminance images. We employ the linear combination for their integration and show experimental results.		Tomohiko Yabui;Yukiko Kenmochi;Kazunori Kotani	2003		10.1109/ICIP.2003.1246821	facial recognition system;computer vision;contextual image classification;speech recognition;computer science;pattern recognition;three-dimensional face recognition;mathematics;face hallucination	Vision	43.9514867470126	-57.37174423049496	47043
0102eac7ce63b0ccca21db55e832a3340172c97a	aggregating deep convolutional neural network scans of broad-area high-resolution remote sensing imagery		Here we present techniques and algorithms to apply trained deep convolutional neural networks (DCNN) to high-resol-ution remote sensing imagery datasets covering large areas of the Earth. First, trained DCNN are used to process broad swaths of imagery in an area of interest (AOI) to produce a classification vector response field (CVRF). The CVRF is then aggregated using mode-seeking algorithms to detect potential objects of interest within the AOI. Our research explores the challenges and opportunities of transitioning DCNN out of the training-validation laboratory setting and into the real-world application domain. We show a scalable approach to leverage state-of-the-art DCNN for broad area automated search, detection, and annotation of objects such as tennis courts, storage tanks, runways, and airplanes.	algorithm;application domain;artificial neural network;convolutional neural network;scalability	Grant J. Scott;James Alex Hurt;Richard A. Marcum;Derek Anderson;Curt H. Davis	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8519300	convolutional neural network;remote sensing;computer vision;application domain;cluster analysis;scalability;feature extraction;artificial intelligence;object detection;visualization;computer science	Arch	27.601955858710355	-53.973543128664986	47113
52fc4ea4260cf8427043d3d59a66b4050197db58	method of detection of real fingerprints on the basis of the radon transform	fuzzy c mean;biometric technologies;radon transform;fingerprint recognition;algorithm of fuzzy c means;detection of liveness;fingerprints;spoofing attacks	An effective approach for the detection of real fingerprints based on the Radon transform is proposed. The results demonstrate that the method well distinguishes false fingers from real ones. The method proposed uses only one image, does not require additional equipment, and is easily integrated into existing fingerprint recognition systems.	fingerprint recognition	Ya. N. Imamverdiev;L. E. Kerimova;V. Ya. Mussaev	2009	Automatic Control and Computer Sciences	10.3103/S0146411609050071	fingerprint;computer vision;radon transform;computer science;theoretical computer science;mathematics;computer security;fingerprint recognition	Vision	30.65130247729433	-63.24785727036328	47122
855854b5c76fd7c79f4ad22eda78a8341721c847	feature-based roi generation for stereo-based pedestrian detection		Region of interest (ROI) generation is an important step in stereo-based pedestrian detection systems. In this paper, we propose an ROI generation method by fusing the color and depth information obtained from a stereo camera mounted on a vehicle. In our proposed method, a feature-based method which uses contour properties of the image is used to find the ROIs. In our feature-based ROI extraction method, we extract four features which are contour density, maximum area, maximum perimeter and matching score. Then we create a feature vector from these features and classify them using SVM. ROIs are then classified into the pedestrian and non-pedestrian classes using Histogram of Oriented Gradients (HOG)/Linear SVM. We have tested our proposed method on the Daimler dataset and experimental results show that our proposed method has a 96.5% accuracy for 1 false positive per frame and outperforms existing monocular and stereo-based methods.	feature vector;histogram of oriented gradients;image gradient;pedestrian detection;perimeter;region of interest;stereo camera	Maral Mesmakhosroshahi;Maziar Loghman;Joohee Kim	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7952452	artificial intelligence;support vector machine;histogram of oriented gradients;computer science;pattern recognition;region of interest;feature extraction;feature vector;computer vision;stereo camera;pedestrian detection	Robotics	33.42901453954811	-56.55445230304408	47155
f0be51119db4d3376510ac6f44c686cebf489de7	3d motion recovery via affine epipolar geometry	moving image;kalman filtering;modelizacion;epipolar geometry minimisation;transformation affine;algebra afin;formation image tridimensionnelle;filtrage kalman;algorithm performance;image processing;3d imaging;geometrie algorithmique;perspective projection;computational geometry;procesamiento imagen;motion estimation;movie camera;imagen movil;image bruitee;traitement image;image mobile;modelisation;imagen sonora;epipolar geometry;camara;algebre affine;resultado algoritmo;affine transformation;noisy image;performance algorithme;affine epipolar equation;projection perspective;geometria computacional;formacion imagen tridimensional;proyeccion perspectiva;modeling;filtrado kalman;affine algebra;transformacion afin;camera	Algorithms to perform point-based motion estimation under orthographic and scaled orthographic projection abound in the literature. A key limitation of many existing algorithms is that they operate on the minimum amount of data required, often requiring the selection of a suitable minimal set from the available data to serve as a “local coordinate frame”. Such approaches are extremely sensitive to errors and noise in the minimal set, and forfeit the advantages of using the full data set. Furthermore, attention is seldom paid to the statistical performance of the algorithms. We present a new framework that allowsall available features to be used in the motion computations, without the need to select a frame explicitly. This theory is derived in the context of theaffine camera, which preserves parallelism and generalises the orthographic, scaled orthographic and para-perspective models. We define the affine epipolar geometry for two such cameras, giving the fundamental matrix in this case. The noise resistant computation of the epipolar geometry is discussed, and a statistical noise model constructed so that confidence in the results can be assessed. The rigid motion parameters are then determineddirectly from the epipolar geometry, using the novel rotation representation of Koenderink and van Doorn (1991). The two-view partial motion solution comprises the scale factor between views, the projection of the 3D axis of rotation and the cyclotorsion angle, while the addition of a third view allows the true 3D rotation axis to be computed (up to a Necker reversal). The computed uncertainties in these parameters permit optimal estimates to be obtained over time by means of a linear Kalman filter. Our theory extends work by Huang and Lee (1989), Harris (1990), and Koenderink and van Doorn (1991), and results are given on both simulated and real data.	algorithm;apache axis;computation;epipolar geometry;fundamental matrix (computer vision);harris affine region detector;image noise;kalman filter;motion estimation;optic axis of a crystal;orthographic projection;parallel computing;simulation	Larry S. Shapiro;Andrew Zisserman;Michael Brady	1995	International Journal of Computer Vision	10.1007/BF01539553	kalman filter;stereoscopy;computer vision;perspective;systems modeling;topology;image processing;computational geometry;computer science;motion estimation;affine transformation;mathematics;geometry;epipolar geometry	Vision	49.91366764995684	-57.59746845633845	47177
947fc2e04636c7cde5568f074671e5b78c572e4f	a novel iterative algorithm to text segmentation for web born-digital images	image segmentation;chemical species	Since web born-digital images have low resolution and dense text atoms, text region over-merging and miss detection are still two open issues to be addressed. In this paper a novel iterative algorithm is proposed to locate and segment text regions. In each iteration, the candidate text regions are generated by detecting Maximally Stable Extremal Region (MSER) with diminishing thresholds, and categorized into different groups based on a new similarity graph, and the texted region groups are identified by applying several features and rules. With our proposed overlap checking method the final well-segmented text regions are selected from these groups in all iterations. Experiments have been carried out on the web born-digital image datasets used for robust reading competition in ICDAR 2011 and 2013, and the results demonstrate that our proposed scheme can significantly reduce both the number of over-merge regions and the lost rate of target atoms, and the overall performance outperforms the best compared with the methods shown in the two competitions in term of recall rate and f-score at the cost of slightly higher computational complexity. © (2015) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	algorithm;digital image;iterative method;text segmentation	Zhigang Xu;Yuesheng Zhu;Ziqiang Sun;Zhen Liu	2015		10.1117/12.2197039	computer science;theoretical computer science;data mining;information retrieval	Vision	38.77268067295292	-67.27423186933024	47222
606363a54c106728e3bca50895f2eb3cd22159bb	the role of color attributes and similarity grouping in 3-d building reconstruction	image tridimensionnelle;eficacia sistema;sistema experto;architecture systeme;image processing;edge detection;extraction forme;performance systeme;procesamiento imagen;intelligence artificielle;surface reconstruction;fotografia aerea;system performance;traitement image;deteccion contorno;aerial image;detection contour;reconstruction surface;photographie aerienne;extraccion forma;building reconstruction;reference data;tridimensional image;artificial intelligence;arquitectura sistema;inteligencia artificial;reconstruccion superficie;systeme expert;system architecture;imagen color;pattern extraction;image couleur;aerial photography;imagen tridimensional;color image;expert system	This paper addresses two major issues: 3-D building reconstruction and the role of color attributes and similarity grouping. We present ARUBA, a general framework for automated 3-D building reconstruction from multiple color aerial images. After highlighting the strategy and concisely describing the framework and its 2-D and 3-D processing modules, we evaluate the reconstructed roofs with respect to accurate reference data. The second part of the paper shows that geometry, although important, should not be the only source of information exploited in the reconstruction process. The main objectives are to demonstrate that (1) color is a very important cue in reconstructing a general class of objects, (2) it is crucial to retain all information during the entire processing chain, (3) a general class of objects parts can be e ciently extracted by grouping edges and lines by means of similarity, and (4) a mutual interaction between 2-D and 3-D processing is important. List of Symbols ? h !	aerial photography;color;information source	Olof Henricsson	1998	Computer Vision and Image Understanding	10.1006/cviu.1998.0718	computer vision;edge detection;surface reconstruction;color image;image processing;reference data;computer science;artificial intelligence;expert system;aerial photography	Vision	47.85587935328141	-59.63956890699442	47249
be3ff1c85c81abce672c80a1cbca017a2b270c9f	pm-huber: patchmatch with huber regularization for stereo matching	image matching;patchmatch;variational formulation;cameras stereo vision smoothing methods mathematical model benchmark testing equations minimization;smoothing methods;stereo image processing;quadratic relaxation;second order prior;subpixel stereo matching;stereo image processing image matching smoothing methods;patchmatch subpixel stereo matching second order prior variational formulation quadratic relaxation;sub pixel accurate disparity estimation pm huber huber regularization integer valued disparities stereo correspondence algorithms stereo matching algorithms match support windows patchmatch stereo algorithm variational smoothing formulation quadratic relaxation estimated plane parameters middlebury benchmark integer valued disparity strategy	Most stereo correspondence algorithms match support windows at integer-valued disparities and assume a constant disparity value within the support window. The recently proposed Patch Match stereo algorithm by Bleyer et al. overcomes this limitation of previous algorithms by directly estimating planes. This work presents a method that integrates the Patch Match stereo algorithm into a variational smoothing formulation using quadratic relaxation. The resulting algorithm allows the explicit regularization of the disparity and normal gradients using the estimated plane parameters. Evaluation of our method in the Middlebury benchmark shows that our method outperforms the traditional integer-valued disparity strategy as well as the original algorithm and its variants in sub-pixel accurate disparity estimation.	algorithm;benchmark (computing);binocular disparity;calculus of variations;computer stereo vision;gradient;graphics processing unit;heightmap;linear programming relaxation;manifold regularization;matrix regularization;microsoft windows;opencl api;optical flow;patchmatch;pixel;point cloud;randomized algorithm;real-time clock;sampling (signal processing);smoothing;variational principle	Philipp Heise;Sebastian Klose;Brian Jensen;Alois Knoll	2013	2013 IEEE International Conference on Computer Vision	10.1109/ICCV.2013.293	computer vision;mathematical optimization;machine learning;mathematics	Vision	53.19661409273479	-72.5701125413038	47289
33c009495557e96607fb0c10c045b8d4c54402fb	multi-subject registration for unbiased statistical atlas construction	institutional repositories;fedora;transformation model;vital;preterm infant;spatial distribution;affine transformation;gradient estimate;vtls;tetrahedral mesh;similarity measure;ils;coordinate system	This paper introduces a new similarity measure designed to bring a population of segmented subjects into alignment in a common coordinate system. Our metric aligns each subject with a hidden probabilistic model of the common spatial distribution of anatomical tissues, estimated using STAPLE. Our approach does not require the selection of a subject of the population as a “target subject”, nor the identification of “stable” landmarks across subjects. Rather, the approach determines automatically from the data what the most consistent alignment of the joint data is, subject to the particular transformation family used to align the subjects. The computational cost of joint simultaneous registration of the population of subjects is small due to the use of an efficient gradient estimate used to solve the optimization transform aligning each subject. The efficacy of the approach in constructing an unbiased statistical atlas was demonstrated by carrying out joint alignment of 20 segmentations of MRI of healthy preterm infants, using an affine transformation model and a FEM volumetric tetrahedral mesh transformation model.	algorithm;algorithmic efficiency;align (company);finite element method;gradient;mathematical optimization;refinement (computing);similarity measure;spatial variability;statistical model	Mathieu De Craene;Aloys du Bois d'Aische;Benoit M. Macq;Simon K. Warfield	2004		10.1007/978-3-540-30135-6_80	computer vision;coordinate system;data mining;affine transformation;mathematics	Vision	43.82633504948943	-78.60498724106043	47316
d62ffc82b5d8f5e4146bacc3632156355f1a9686	unsupervised scaling of multi-descriptor similarity functions for medical image datasets	databases;histograms;content based search;biomedical imaging fractals computer science medical diagnostic imaging picture archiving and communication systems image databases image retrieval performance evaluation feature extraction application software;distance function;fractals;weighting method;average precision;medical image databases;index structure;biomedical imaging;data mining;medical image database;optimal scaling;medical image;medical information systems;unsupervised scaling;feature extraction;magnetic resonance imaging;multidescriptor similarity function;fractal theory;fractal scaled product metric;similarity function;medical image dataset;content based retrieval;image descriptor;fractal theory unsupervised scaling multidescriptor similarity function medical image dataset content based search medical image database image descriptor distance function image retrieval weighting method fractal scaled product metric;visual databases content based retrieval fractals image retrieval medical information systems;visual databases;image retrieval;image similarity	Content-based search has proven to be a proper complement to textual queries over medical image databases. In many applications, employing multiple image descriptors and combining the respective distance functions using adequate scale factors improves the retrieval accuracy. However, the existing weighting methods are either exhaustive or supervised. In this paper, we present the Fractal-scaled Product Metric, an unsupervised method to determine a scale factor among features in multi-descriptor image similarity assessment based on the Fractal Theory. The composite distance function obtained is not limited to dimensional image descriptors and enables using scalable indexing structures. Experiments have shown that the proposed method determines near-optimal scale factors for the descriptors involved, and always improves the precision of the results, outperforming the individual descriptors up to 31% on the average precision.	algorithm;database;dimensionality reduction;experiment;fractal;fractal dimension;image scaling;information retrieval;scalability;supervised learning;unsupervised learning;visual descriptor	Renato Bueno;Daniel dos Santos Kaster;Adriano Arantes Paterlini;Agma J. M. Traina;Caetano Traina	2009	2009 22nd IEEE International Symposium on Computer-Based Medical Systems	10.1109/CBMS.2009.5255275	medical imaging;computer vision;radiology;fractal;image retrieval;computer science;magnetic resonance imaging;pattern recognition;information retrieval	Vision	32.599290432795364	-71.36255737102091	47324
