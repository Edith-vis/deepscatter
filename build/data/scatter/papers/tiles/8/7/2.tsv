id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
399b7f5283fe2905c268d7a080a76cd98a84a58d	the noise reduction of speech signals based on rbfn	discrete wavelet transforms;frequency domain analysis;speech processing;speech;speech enhancement rbfn awgn;speech signal to noise ratio frequency domain analysis noise reduction speech processing discrete wavelet transforms;noise reduction;signal to noise ratio;speech processing awgn microphones radial basis function networks signal denoising signal restoration;awgn speech signal noise reduction rbfn sound absorbing cotton directional microphone voice processing system radial basis function networks authentic speech signal restoration speech signal source feature matching additive white gaussian noise	The speech signals in the transmission are often accompanied with a lot of unnecessary disturbing noise. Usually, sound-absorbing cotton or directional microphones are applied on the hardware to suppress the background noise that caused by the unwanted signals, such as sound of wind and human voice. In addition, the channel effects are generated among various voice-processing systems when voice signals are transferred. This paper takes advantages of the Radial Basis Function Networks (RBFN), in which the noise signals can be figured simply in time period without the transfer through frequency domain, by matching the features of the sources of speech signals within the samples speech frame, the authentic speech signals can be restored. The simulation results show that the propose RBFN method works well to reduce the noise signals and provides the same quality as the original speech signals under Additive White Gaussian Noise (AWGN).	additive model;additive white gaussian noise;microphone;noise reduction;radial (radio);radial basis function;simulation	Jui-Chuan Cheng;Te-Jen Su;Tsung-Ying Li;Chia-Hua Wu	2015	2015 International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP)	10.1109/IIH-MSP.2015.111	voice activity detection;gaussian noise;computer vision;linear predictive coding;speech recognition;colors of noise;computer science;noise measurement;speech;digital signal processing;speech coding;noise;noise reduction;speech processing;noise floor;signal-to-noise ratio;frequency domain	EDA	83.51353964488555	-32.91814560832727	18994
e53de4fe4a9d8f86e280a4f57e950aa5a051ec9b	hrtf-based robust least-squares frequency-invariant beamforming	microphones;robot sensing systems;array signal processing;robot audition spatial filtering robust superdirective beam forming white noise gain signal enhancement;arrays;microphones robustness robot sensing systems optimization array signal processing arrays;robustness;optimization	In this work, a Head-Related Transfer Function (HRTF)-based Robust Least-Squares Frequency-Invariant (RLSFI) beamformer design is proposed. The HRTF-based RLSFI beamformer accounts for the influence of a robot's head on the sound field. The performance of the new HRTF-based RLSFI beamformer is evaluated using signal-based measures and word error rates for an off-the-shelf speech recognizer, and is compared to the performance of the original free-field RLSFI beamformer design. The experimental results confirm the efficacy of the proposed HRTF-based beamformer design for robot audition.	beamforming;finite-state machine;head-related transfer function;least squares;robot;speech recognition	Hendrik Barfuss;Christian Huemmer;Gleni Lamani;Andreas Schwarz;Walter Kellermann	2015	2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)	10.1109/WASPAA.2015.7336933	electronic engineering;speech recognition;acoustics;computer science;engineering;adaptive beamformer;robustness	Robotics	85.11236522650415	-35.20151542074697	19265
0d987f4bcdf3ff2b22ec117d984844e524257db4	normalized observation vector clustering approach for sparse source separation	vectors array signal processing blind source separation pattern clustering sensor arrays;3 dimensionally distributed sources normalized observation vector clustering approach blind sparse source separation linear sensor array;abstracts microwave integrated circuits nickel loudspeakers	This paper presents a new method for the blind separation of sparse sources whose number N can exceed the number of sensors M. Recently, sparseness based blind separation has been actively studied. However, most methods utilize a linear sensor array (or only two sensors), and therefore have certain limitations; e.g., they cannot be applied to symmetrically positioned sources. To allow the use of more than two sensors that can be arranged in a non-linear/non-uniform way, we propose a new method that includes the normalization and clustering of the observation vectors. We report promising results for the speech separation of 3-dimensionally distributed five sources with a non-linear/non-uniform array of four sensors in a room (RT60= 120 ms).	blind signal separation;cluster analysis;database normalization;neural coding;nonlinear system;sensor;source separation;sparse matrix	Shoko Araki;Hiroshi Sawada;Ryo Mukai;Shoji Makino	2006	2006 14th European Signal Processing Conference		electronic engineering;speech recognition;engineering;machine learning;blind signal separation	Robotics	84.03800563863997	-37.11554113246594	19898
79e0587f05b81c6a8d81033193d2a37201e65b53	linear prediction on a warped frequency scale [speech processing]	pulse code modulation;deemphasis filter frequency warped predictor adaptive differential pulse code modulation speech quality preemphasis filter;speech processing;linear predictive;filtering and prediction theory;speech analysis and processing filtering and prediction theory pulse code modulation;speech analysis and processing;speech processing filters frequency synthesizers signal processing bit rate ear energy resolution signal resolution bandwidth acoustics;measurement noise;adaptive differential pulse code modulation	An ordinary predictor and a frequency warped predictor are compared in an ADPCM (adaptive differential pulse code modulation) system. The experimental results show that for an unwarped predictor of order ten, the order of the warped predictor can be reduced by two for the same speech quality. The audible differences between the normal and the warped predictors are very small, so the statements of the test subjects are widely spread. The measured noise of the system with the warped predictor is about 2 dB higher than the normal predictor, but it has lower audible noise. However, the plosives (p, t, etc.) are more blurred. The measured SNR was taken from the difference of the signals before the preemphasis filter and behind the deemphasis filter at the end of the system. Comparing the computing time needed to obtain the predictor coefficients, the difference between the normal and the warped predictor is negligible. >	speech processing	Elmar Kr√ºger;Hans Werner Strube	1988	IEEE Trans. Acoustics, Speech, and Signal Processing	10.1109/29.90384	pulse-code modulation;electronic engineering;speech recognition;acoustics;computer science;speech processing	Arch	83.66878211949356	-32.45784807065604	19977
a65ea554562937ceebfc3d058cc7391147a735c5	combined architecture of adaptive beamforming and blind source separation for speech recognition of intelligent service robots	digital literacy;hangul social networking site;english language;computer aided instruction;information science education;college students;bss system adaptive beamforming algorithm blind source separation algorithm speech recognition system intelligent service robots permutation ambiguity computational complexity adaptive generalized sidelobe canceller;korean student;cell phone videocams;array signal processing blind source separation speech recognition intelligent robots service robots source separation working environment noise hardware acoustic noise noise level;ubiquitous computing;l2 digital literacy;mobile computing;speech recognition array signal processing blind source separation intelligent robots service robots;social networking sites;college campus;l2 english video guide	Successful speech recognition in noisy environments for intelligent robots depends on the performance of preprocessing elements employed. Even though acoustic signals are often corrupted in the high noise level environment, speech recognition systems such as the widely-used HTK do not deal with signal distortion problems. We propose an architecture that effectively combines adaptive beamforming (ABF) and blind source separation (BSS) algorithms in the spatial domain. To avoid permutation ambiguity and heavy computational complexity in the BSS system, the adaptive generalized sidelobe canceller is employed in front of the BSS system. We slightly modified the conventional convolutive mixture model of the BSS for fast processing in hardware implementations. Unlike the conventional BSS, this does not suffer from permutation ambiguity since the target angle of the front-line beamformer is fixed so it always provides enhanced and reference noise signals to the predefined two inputs of the BSS. The proposed system also reduces heavy computations in the BSS when the BSS have more than two inputs. The proposed time domain approach can be easily implemented into hardware in real-time. We evaluated the structure and assessed its performance with a DSP module. The experimental results of speech recognition test show that the proposed combined system guarantees high speech recognition rate in the noisy environment and better performance than the ABF and BSS system.	acoustic cryptanalysis;algorithm;ambiguity function;applications-by-forms;beamforming;blind signal separation;computation;computational complexity theory;digital signal processor;distortion;htk (software);mixture model;noise (electronics);preprocessor;real-time clock;reference noise;robot;sensitivity and specificity;source separation;speech recognition	Sungmin Woo;Sanghoon Lee;Hong Jeong	2007	The 2007 International Conference on Intelligent Pervasive Computing (IPC 2007)	10.1109/IPC.2007.72	speech recognition;computer science;multimedia;communication	Robotics	85.35490616409855	-35.051258327550855	20468
b1c158c476d65c9c9342c6f8df6e81bab5b98bd7	a blind speech enhancement algorithm for the suppression of late reverberation and noise	spectral weighting speech enhancement dereverberation blind estimation;background noise;reverberation;hearing aids;speech enhancement reverberation acoustic noise background noise acoustic distortion additive noise acoustic reflection delay mobile communication hearing aids;acoustic distortion;blind estimation;transient response echo suppression reverberation speech enhancement;rule based;additive noise;low signal delay;background noise suppression;speech;dereverberation;speech enhancement;indexing terms;spectral weighting rule;noise measurement;low signal delay blind speech enhancement algorithm late reverberation suppression background noise suppression spectral weighting rule late room reflection impulse response;room impulse response;transient response;a priori knowledge;estimation;acoustic noise;acoustic reflection;mobile communication;echo suppression;impulse response;spectral weighting;late room reflection;blind speech enhancement algorithm;hearing aid;noise;late reverberation suppression	This paper proposes a new speech enhancement algorithm for the suppression of background noise and late reverberation without a priori knowledge. A generalized spectral weighting rule based on estimations for the spectral variances of the late reverberant speech and background noise is used for speech enhancement. This allows to suppress speech distortions due to late room reflections without knowledge about the complete room impulse response. In contrast to existing methods, all needed quantities are estimated entire blindly from the reverberant and noisy speech signal. The new algorithm has also a low signal delay which is important, e.g., for speech enhancement in mobile communication devices or hearing aids.	algorithm;amiga reflections;distortion;speech enhancement;zero suppression	Heinrich W. L√∂llmann;Peter Vary	2009	2009 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2009.4960502	rule-based system;estimation;a priori and a posteriori;speech recognition;index term;mobile telephony;impulse response;reverberation;computer science;noise measurement;noise;speech;noise;background noise;transient response	Robotics	83.50146832420768	-33.76702297606136	21717
85e2dbbf151110b9de85077cbab2eeb4c851f5e3	a model-based approach to active noise cancellation using loudspeaker array	active noise cancellation;theoretical model;lms algorithm;least mean squares methods;transfer functions;real time;model based approach;acoustic signal processing;array signal processing;three dimensional;noise cancellation sensor arrays adaptive arrays transfer functions noise reduction computer errors adaptive systems loudspeakers sensor systems open loop systems;error analysis;adaptive signal processing;loudspeakers;transfer function;system performance model based approach active noise cancellation loudspeaker array adaptive noise cancellation system error sensor array noise reduction three dimensional region open loop system transfer functions propagation model error measures lms algorithm computer simulation results experiments real time active noise control hardware;acoustic noise;noise reduction;sensor array;adaptive noise canceller;error analysis loudspeakers acoustic transducer arrays direction of arrival estimation array signal processing active noise control acoustic noise adaptive signal processing acoustic signal processing transfer functions acoustic wave propagation least mean squares methods;acoustic transducer arrays;computer simulation;active noise control;direction of arrival estimation;acoustic wave propagation	This paper presents a new model-based adaptive noise cancellation system using loudspeaker array and error sensor array which can be used to reduce the noise in a speci c three-dimensional region. First, open loop system transfer functions are designed using a theoretical propagation model. The transfer functions thus found are regarded as the nominal values for the complete system. Second, to compensate for deviations from the theoretical model, the transfer functions are adapted using error measures from error sensor array by LMS algorithm. Computer simulation results shows that our approach is e ective for noise reduction in 3-D space. Experiments using real-time active noise control hardware also con rms the performance of the system.	algorithm;computer simulation;control system;loudspeaker;naruto shippuden: clash of ninja revolution 3;noise reduction;real-time clock;real-time computing;real-time operating system;software propagation;theory;transfer function	Jie Gu;Sze Fong Yau	1997		10.1109/ICASSP.1997.599652	computer simulation;computer vision;speech recognition;computer science;noise measurement;active noise control;transfer function	Robotics	85.63471371619694	-32.750570367706935	22271
0c1bc1cee68e5bf9fbba600d7bc75001b4354425	robust estimation of the discrete spectrum of relaxations for electromagnetic induction responses	model parameters;polarisability electromagnetic induction geophysical techniques;magnetic polarizabilities electromagnetic induction response real exponentials model parameters time constants nonlinear iterative search relaxation parameter space nonnegative constraint synthetic data laboratory measurement discrete spectrum of relaxation frequencies;time constant;robust estimator;parametric statistics;nonnegative constraint;magnetic polarizabilities;sum of exponentials discrete spectrum of relaxation frequencies dsrfs electromagnetic induction emi magnetic polarizabilities;magnetic sensors;polarization;frequence;discrete spectrum;robustness electromagnetic induction electromagnetic interference magnetic field measurement magnetic sensors frequency measurement dielectric materials parametric statistics shape frequency response;sum of exponentials;real exponentials;laboratory measurement;discrete spectrum of relaxation frequencies;frequency measurement;electromagnetic induction emi;polarizacion;algorithme;frequency response;electromagnetic induction response;modelo;frecuencia;thesis;shape;magnetic field measurement;induccion electromagnetica;electromagnetic induction;parameter space;discrete spectrum of relaxation frequencies dsrf;nonlinear iterative search;relaxation parameter space;algorithms;robustness;dielectric materials;electromagnetic interference;modele;polarisation;synthetic data;time constants;induction electromagnetique;frequency;discrete spectrum of relaxation frequencies dsrfs;models;geophysical techniques;algoritmo;polarisability	The electromagnetic induction response of a target can be accurately modeled by a sum of real exponentials. However, it is difficult to obtain the model parameters from measurements when the number of exponentials in the sum is unknown or the terms are strongly correlated. Traditionally, the time constants and residues are estimated by nonlinear iterative search. In this paper, a constrained linear method of estimating the parameters is formulated by enumerating the relaxation parameter space and imposing a nonnegative constraint on the parameters. The resulting algorithm does not depend on a good initial guess to converge to a solution. By using tests on synthetic data and laboratory measurement of known targets, the proposed method is shown to provide accurate and stable estimates of the model parameters.	algorithm;converge;iterative method;linear programming relaxation;nonlinear system;strongly correlated material;synthetic data	Mu-Hsin Wei;Waymond R. Scott;James H. McClellan	2010	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2009.2029981	mathematical optimization;polarization;mathematics;time constant;nuclear magnetic resonance;physics;quantum mechanics;statistics	Vision	88.99897403742702	-40.109658627189646	22280
a31eb95b9a1d5d1efd1a73e7056a62da80cb393c	moving sound source parameter estimation using a single microphone and signal extrema samples	frequency modulation;acoustics;am fm signal moving sources doppler effect if estimation if profile;arbitrary trajectory motion parameter estimation moving sound source parameter estimation single microphone low power source monitoring applications contact less source monitoring applications industrial robotics bioacoustics motion attributes doppler effect time varying sinusoids instantaneous frequency smooth if profile estimation analytic signal approach energy separation approach oscillatory behavior nonuniformly spaced signal extrema samples;receivers;doppler effect;trajectory;estimation;smoothing methods doppler effect microphones parameter estimation;frequency modulation estimation trajectory ip networks doppler effect receivers acoustics;ip networks;electrical communication engineering	Estimating the parameters of moving sound sources using only the source signal is of interest in low-power, and contact-less source monitoring applications, such as, industrial robotics and bio-acoustics. The received signal embeds the motion attributes of the source via Doppler effect. In this paper, we analyze the Doppler effect on mixture of time-varying sinusoids. Focusing, on the instantaneous frequency (IF) of the received signal, we show that the IF profile composed of IF and its first two derivatives can be used to obtain source motion parameters. This requires a smooth estimate of IF profile. However, the numerical implementation of traditional approaches, such as analytic signal and energy separation approach, gives oscillatory behavior hence a non-smooth IF estimate. We devise an algorithm using non-uniformly spaced signal extrema samples of the received signal for smooth IF profile estimation. Using the smooth IF profiles for a source moving on a linear trajectory with constant velocity, an accurate estimate of moving source parameters is obtained. We see promise of this approach for an arbitrary trajectory motion parameter estimation.	algorithm;analytic signal;british informatics olympiad;covox speech thing;doppler effect;estimation theory;industrial robot;instantaneous phase;low-power broadcasting;microphone;numerical analysis;robotics;velocity (software development)	Neeraj Kumar Sharma;Sai Gunaranjan Pelluri;Thippur V. Sreenivas	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7178387	frequency modulation;estimation;speech recognition;doppler effect;telecommunications;trajectory;statistics	Robotics	85.03379006406166	-38.181107417292154	22757
e3d8c121cb2011bd220b6744828c75f91e835b2d	rendering ghost ships and other phenomena in the arctic atmosphere	inhomogeneous media;arctic atmosphere;curved ray tracing	The unique characteristics of the arctic atmosphere make for very interesting effects that cannot be seen anywhere else in the planet. The extremely cold temperatures, along with the existence of inversion layers in the temperature gradients, make the medium highly inhomogeneous. Its properties, including the index of refraction that rules the behavior of light, are no longer constant. As a consequence, light rays get bent while traversing the atmosphere, and the result is some spectacular phenomena; several examples are the arctic mirages (that have probably given rise to numerous ghost ship legends), the Fata Morgana or the Novaya-Zemlya effect. We present here an implementation of a ray tracer that can render all these effects, thus depicting phenomena never ray-traced before, as far as the authors know. We first build an accurate temperature profile for the arctic atmosphere, based on experimental data, then calculate the curved paths of the light rays as the index of refraction changes as a function of temperature, by solving the physically-based differential equation that describes their trajectory. The scenes are modelled using real data for the Earth and Sun dimensions and relative distance, thus maintaining accuracy in the results obtained.		Diego Gutierrez;Francisco J. Ser√≥n;Adolfo Mu√±oz;Oscar Anson	2005				NLP	83.11573484234722	-51.83074506721728	22773
503160de8ad298b5294d95f057b7197be42eef56	alternative formulation and robustness analysis of the multichannel wiener filter for spatially distributed microphones	microphones;wiener filters correlation methods microphones speech enhancement;speech;estimation errors robustness analysis multichannel wiener filter spatially distributed microphones multimicrophone noise reduction technique speech component microphone signals speech correlation matrix;robustness multichannel wiener filter spatially distributed microphones;robustness;estimation error;correlation;signal to noise ratio;speech correlation microphones signal to noise ratio estimation error robustness	The multichannel Wiener filter (MWF) is a well-known multi-microphone noise reduction technique, which aims to estimate the speech component in one of the microphone signals. Assuming a single speech source, the rank-one property of the speech correlation matrix can be exploited to derive the so-called rank-one MWF (R1-MWF). In this paper, we present an alternative formulation of the MWF (A-MWF), which exploits the assumed rank-one property of the speech correlation matrix in a different way as the R1-MWF. Furthermore, we present a theoretical robustness analysis of the different MWF formulations in presence of spatially white noise. Experimental results show that similarly to the R1-MWF, the proposed A-MWF is less sensitive to estimation errors of the speech correlation matrix and yields a higher output SNR than the standard MWF.	microphone;noise reduction;signal-to-noise ratio;white noise;wiener filter	Toby Christian Lawin-Ore;Sebastian Stenzel;J√ºrgen Freudenberger;Simon Doclo	2014	2014 14th International Workshop on Acoustic Signal Enhancement (IWAENC)	10.1109/IWAENC.2014.6954008	electronic engineering;speech recognition;acoustics;computer science;wiener filter	ML	83.43524421454681	-35.6126128500357	23188
b67ba853529049d4d1604633b95e886016fcf195	geometrical interpretation of the pca subspace approach for overdetermined blind source separation	signal image and speech processing;traitement signal;evaluation performance;metodo estadistico;analisis componente principal;performance evaluation;separation aveugle source;low frequency;blind source separation;evaluacion prestacion;statistical method;metodo subespacio;independent component analysis;methode geometrique;geometrical method;methode sous espace;reduccion ruido;haute frequence;quantum information technology spintronics;methode statistique;signal processing;principal component analysis;noise reduction;basse frequence;reduction bruit;analyse composante principale;analyse composante independante;subspace method;baja frecuencia;metodo geometrico;analisis componente independiente;alta frecuencia;procesamiento senal;high frequency	We discuss approaches for blind source separation where we can use more sensors than sources to obtain a better performance. The discussion focuses mainly on reducing the dimensions of mixed signals before applying independent component analysis. We compare two previously proposed methods. The first is based on principal component analysis, where noise reduction is achieved. The second is based on geometric considerations and selects a subset of sensors in accordance with the fact that a low frequency prefers a wide spacing, and a high frequency prefers a narrow spacing. We found that the PCA-based method behaves similarly to the geometry-based method for low frequencies in the way that it emphasizes the outer sensors and yields superior results for high frequencies. These results provide a better understanding of the former method.	blind signal separation;independent component analysis;noise reduction;principal component analysis;sensor;source separation	Stefan Winter;Hiroshi Sawada;Shoji Makino	2006	EURASIP J. Adv. Sig. Proc.	10.1155/ASP/2006/71632	independent component analysis;computer vision;speech recognition;telecommunications;computer science;machine learning;signal processing;high frequency;noise reduction;blind signal separation;low frequency;principal component analysis	HPC	89.87162583146468	-38.86293024827426	23422
d8bc22e2cbf5cd78af7ceffb632f248ea2cd85e9	a multichannel mmse-based framework for speech source separation and noise reduction	probability;least mean squares methods;blind source separation;wiener filters;speech enhancement;higher order statistics;wiener filters blind source separation expectation maximisation algorithm gaussian distribution higher order statistics least mean squares methods probability signal denoising speech enhancement;blind source separation multichannel mmse based framework joint multichannel speech source separation acoustic noise reduction minimum mean square error based solution multiple simultaneous speakers background noise latent variable n 1 possible discrete states n speech signals plus additive noise mixture posterior probability mmse based speech enhancement second order statistics speech signals multichannel wiener based filters minimum variance distortionless response linear filters signal estimates multichannel recordings sound mixtures normalized observation vector gaussian mixture like model pretrained gaussian mixture model log spectra expectation maximization estimation independent component analysis;gaussian distribution;wiener filter blind source separation microphone arrays minimum variance distortionless response minimum mean square error noise reduction;signal denoising;expectation maximisation algorithm	We propose a new framework for joint multichannel speech source separation and acoustic noise reduction. In this framework, we start by formulating the minimum-mean-square error (MMSE)-based solution in the context of multiple simultaneous speakers and background noise, and outline the importance of the estimation of the activities of the speakers. The latter is accurately achieved by introducing a latent variable that takes N+1 possible discrete states for a mixture of N speech signals plus additive noise. Each state characterizes the dominance of one of the N+1 signals. We determine the posterior probability of this latent variable, and show how it plays a twofold role in the MMSE-based speech enhancement. First, it allows the extraction of the second order statistics of the noise and each of the speech signals from the noisy data. These statistics are needed to formulate the multichannel Wiener-based filters (including the minimum variance distortionless response). Second, it weighs the outputs of these linear filters to shape the spectral contents of the signals' estimates following the associated target speakers' activities. We use the spatial and spectral cues contained in the multichannel recordings of the sound mixtures to compute the posterior probability of this latent variable. The spatial cue is acquired by using the normalized observation vector whose distribution is well approximated by a Gaussian-mixture-like model, while the spectral cue can be captured by using a pre-trained Gaussian mixture model for the log-spectra of speech. The parameters of the investigated models and the speakers' activities (posterior probabilities of the different states of the latent variable) are estimated via expectation maximization. Experimental results including comparisons with the well-known independent component analysis and masking are provided to demonstrate the efficiency of the proposed framework.	acoustic cryptanalysis;additive white gaussian noise;approximation algorithm;entropy maximization;expectation‚Äìmaximization algorithm;independent component analysis;latent variable;mixture model;multi-source;neural coding;noise reduction;powered speakers;signal-to-noise ratio;software propagation;source separation;speech enhancement;stellar classification;utility functions on indivisible goods;whole earth 'lectronic link	Mehrez Souden;Shoko Araki;Keisuke Kinoshita;Tomohiro Nakatani;Hiroshi Sawada	2013	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2013.2263137	normal distribution;speech recognition;pattern recognition;probability;mathematics;blind signal separation;statistics	ML	82.92955811641716	-36.39803857101282	23558
ef934a4b75313fe45eb1b34b0ce44b2dcf59d640	a statistical approach to reverberation in non-diffusive rectangular rooms based on the image source model	reverberation;estimation theory;probability;image source model;attenuation reverberation mathematical model estimation reflection absorption;energy decay curve;architectural acoustics;acoustic signal processing;unhomogeneous walls statistical approach reverberation nondiffusive rectangular rooms image source model energy decay curve estimation rectangular nondiffusive rooms sound intensity room characteristic factor attenuation factor probability density function exact estimation heavily irregular rooms;acoustic intensity;reverberation acoustic intensity acoustic signal processing architectural acoustics estimation theory probability;image source model reverberation energy decay curve;conference lecture	In this paper, a novel procedure for the estimation of the energy decay curve of the reverberation on rectangular non-diffusive rooms is presented. It is based on the calculation of the expected sound intensity using a room characteristic factor, the specific attenuation factor, also introduced in the paper. Complete knowledge of the probability density function of this factor leads to exact estimation of the energy decay curve of reverberation, even in the case of heavily irregular rooms and/or un-homogeneous walls.	approximation;open-source software;portable document format	Albino Nogueiras;Jordi Colom Olivares	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6637687	speech recognition;reverberation;probability;mathematics;estimation theory;statistics	Robotics	86.88915150843503	-33.60827661360458	23685
49dda4e7c4f46927f6375244a1b75da56f242cdb	development of a digital-convolution-based process emulator for three-dimensional microstructure fabrication using electron-beam lithography	fabrication;taper;computer aided design;nanoimprint;design tool;electron irradiation distribution;electron irradiation;element growth method;proximity effect lithography;convolution;cad;roller imprint;process simulation computer aided design cad electron beam lithography ebl microfabrication;molecular dynamics;kernel function;scattering;opengl environment;electron radiation;microfabrication;three dimensional;process design;electrons;proximity effect lithography convolution crystal microstructure electron beam lithography electron radiation electronic design automation;lithography;computer aided design tools;3 d micropolymer structures;microstructure;electron beam lithography ebl;digital convolution based process emulator;shape;process parameters;electron beam lithography;computer aided design cad;cad digital convolution based process emulator three dimensional microstructure fabrication electron beam lithography 3 d micropolymer structures proximity effect forward scatterings backward scatterings electron irradiation distribution computer aided design tools element growth method product development opengl environment kernel function 3 d microstructures e beam lithography;three dimensional microstructure fabrication;forward scatterings;utility computing;process simulation;microstructure fabrication lithography costs convolution proximity effect scattering electrons process design shape;crystal microstructure;backward scatterings;nanotribology;microstructures;3 d microstructures;e beam lithography;proximity effect;electronic design automation;product development	Although electron-beam lithography has been demonstrated to be feasible in creating 3-D micropolymer structures, the proximity effect due to forward and backward scatterings usually makes it difficult to precisely determine the distribution of electron irradiation. The process design for creating the desired shape still largely depends on a trial-and-error basis. Therefore, in order to reduce the cost and to accelerate product development, it is important to utilize computer-aided design tools. A method, called as element growth method, which is based on digital convolution approach, is developed and presented under an OpenGL environment to reduce the cost and the developmental period for fabrication. By using such a convolution approach, this emulator converts the processing parameters into a final spatial-dosage distribution and subsequently into the final geometry of structures. In addition, a physically based kernel function is also proposed and used. Examples of 3-D microstructures such as the microlens are presented. By these tools, it is possible to provide guidelines for optimizing the fabrication process and to reduce the cost for the related e-beam lithography-based 3-D fabrication.	computer-aided design;convolution;electron beam tomography;emulator;explanation-based learning;new product development;opengl;semiconductor device fabrication	Hsiu-Ming Yeh;Kuo-Shen Chen	2009	IEEE Transactions on Industrial Electronics	10.1109/TIE.2008.2006030	electron-beam lithography;lithography;molecular dynamics;electronic engineering;process simulation;electronic design automation;microstructure;engineering;nanotechnology;engineering drawing;physics	EDA	85.12015791349401	-24.55109229387035	24341
206f7e8dc83a0e09c09869405ad8c6671921be8f	improvement of the imaging of moving acoustic sources by the knowledge of their motion	image resolution;radiation pattern;acoustic imaging microphone arrays frequency acoustic arrays signal processing spatial resolution image resolution signal resolution sampling methods vehicles;noise measurement;doppler effect;spatial distribution;microphone array;signal processing;signal resolution;acoustic imaging;vehicles;microphone arrays;sampling methods;frequency;acoustic arrays;spectral resolution;spatial resolution	To obtain, as a function of frequency, the directivity and spatial distribution of an acoustic source in motion, we make it pass, at the velocity V, in front of a linear microphone array. In classical methods, as the numerical processings of the signals concern T - duration windows, there results that the spectral resolution is limited by the Doppler spreading effect on spectral lines, and also that the source imaging is deteriorated by the blurring effect (VT) whose order of magnitude may reach the dimensions of the source. The purpose of this paper is to propose a method which takes advantage of the knowledge of the source motion to suppress the Doppler and blurring effects through an appropriate choice of sampling times. We present the mathematical formulation, which is illustrated by real applications on vehicles (motor car and air cushion train).	acoustic cryptanalysis	Jacques Hay	1981		10.1109/ICASSP.1981.1171132	speech recognition;image resolution;signal processing	Vision	86.21009764316392	-38.41836564859599	24421
05c30182fc3e86558722bb21e65c9624125306ce	active noise control of noisy periodic signals using signal separation	signal separation;noisy periodic signals;adaptive filtering;random signal;acoustic signal processing;anc;source separation acoustic signal processing active noise control adaptive filters;random noise;adaptive filters;acoustic noise;anc active noise control acoustic signal processing;active noise reduction source separation acoustic noise noise cancellation noise level background noise signal processing attenuation stochastic resonance signal generators;noise attenuation level;source separation;adaptive filter;white noise;large classes;active noise control;adaptive filtering active noise control noisy periodic signals signal separation periodic noise acoustic noise random signal noise attenuation level;periodic noise	Periodic signals (since they can be easily predicted) can be canceled much more effectively when compared to non- periodic/stochastic signals. A large class of acoustic noise sources have an underlying periodic process that generates a periodic noise component, and thus the acoustic noise can in general be modeled as the sum of a periodic signal and a random signal (usually a background noise). In this paper we present the idea that separating the acoustic noise into periodic and random noise components and doing separate active noise control(ANC) for each tends to increase the over-all noise attenuation level (NAL). Formulae for the exact improvement in noise attenuation levels are derived. A novel signal separation and noise cancelation scheme based on adaptive filtering is developed and its effectiveness is shown for several periodic signal in white noise cases.	acoustic cryptanalysis;adaptive filter;network abstraction layer;noise (electronics);signal-to-noise ratio;stochastic process;white noise	Govind Kannan;Ali A. Milani;Issa M. S. Panahi	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4517935	gradient noise;adaptive filter;gaussian noise;effective input noise temperature;noise spectral density;computer vision;noise;speech recognition;colors of noise;value noise;noise temperature;computer science;noise measurement;noise;mathematics;noise figure;noise floor;stochastic resonance;noise;statistics;salt-and-pepper noise	Robotics	83.69110182819736	-33.045635046913645	24487
0be6c663fc2dfa7014a6c1a74ea314085e1f2287	soft decision-based acoustic echo suppression in a frequency domain	frequency domain	In this paper, we propose a novel acoustic echo suppression (AES) technique based on soft decision in a frequency domain. The proposed approach provides an ef cient and uni ed framework for such procedures as AES gain computation, AES gain modi cation using soft decision, and estimation of relevant parameters based on the same statistical model assumption of the near-end and far-end signal instead of the conventional strategies requiring the additional residual echo suppression (RES) step. Performances of the proposed AES algorithm are evaluated by objective tests under various environments and better results compared with the conventional AES method are obtained.	acoustic coupler;acoustic cryptanalysis;algorithm;computation;echo suppression and cancellation;performance;statistical model;zero suppression	Yun-Sik Park;Ji-Hyun Song;Jae-Hun Choi;Joon-Hyuk Chang	2009			speech recognition;telecommunications;computer science;frequency domain	Vision	83.04859157745301	-33.69947437348825	24584
e78336a5bbed3e606275683bf6d193adb1e1ce97	measurement of sound fields using moving microphones		The sampling of sound fields involves the measurement of spatially dependent room impulse responses, where the Nyquist-Shannon sampling theorem applies in both the temporal and spatial domains. Therefore, sampling inside a volume of interest requires a huge number of sampling points in space, which comes along with further difficulties such as exact microphone positioning and calibration of multiple microphones. In this paper, we present a method for measuring sound fields using moving microphones whose trajectories are known to the algorithm. At that, the number of microphones is customizable by trading measurement effort against sampling time. Through spatial interpolation of the dynamic measurements, a system of linear equations is set up which allows for the reconstruction of the entire sound field inside the volume of interest.	algorithm;linear equation;microphone;multivariate interpolation;nyquist‚Äìshannon sampling theorem;region of interest;sampling (signal processing);shannon (unit);system of linear equations	Fabrice Katzberg;Radoslaw Mazur;Marco Maa√ü;Philipp Koch;Alfred Mertins	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7952753	speech recognition;acoustics;mathematics	Robotics	87.80962042527219	-38.66044659166811	24773
d82578b8fcef339dd64a04dd431aa31c3c95ae45	compensating of room acoustic transfer functions affected by change of room temperature	inverse filtering based dereverberation;speech intelligibility room acoustic transfer functions room temperature efficient compensation method first order approximation time axis scaling sound velocity impulse response measurement environmental conditions real environment successive re estimation inverse filtering based dereverberation speech recognition rates;microphones;transfer functions temperature loudspeakers speech recognition filters acoustic measurements microphones acoustic waves acoustic pulses acoustical engineering;reverberation;speech intelligibility;impulse response measurement;real environment;acoustic pulses;time axis scaling;room acoustic transfer functions;transfer functions;environmental conditions;filters;architectural acoustics;acoustic signal processing;speech recognition rates;successive re estimation;approximation theory;room impulse response;transient response;first order;efficient compensation method;acoustic wave velocity;loudspeakers;transfer function;acoustical engineering;temperature architectural acoustics acoustic signal processing transfer functions acoustic wave velocity transient response reverberation filtering theory speech recognition speech intelligibility inverse problems approximation theory;speech recognition;acoustic waves;temperature;room temperature;acoustic measurements;room acoustics;sound velocity;filtering theory;first order approximation;inverse problems	This paper proposes an efficient compensation method using a first-order approximation of time axis scaling for the variations of the room acoustic transfer function. The time axis scaling model is based on the fact that the change of the sound velocity due to the change of room temperature is a dominant factor for the variations of room impulse response affected by environmental conditions. In this paper, the effectiveness of the compensation method is evaluated using room impulse responses measured in the real environment. As the results, it is clarified that the variations of room impulse response can be modeled by the first-order approximated time axis scaling when the successive re-estimation is performed every small change of temperature. Furthermore, it is shown that the compensation method applied to an inverse filtering based dereverberation approach improves the intelligibility and speech recognition rates dramatically.	acoustic cryptanalysis;apache axis;approximation algorithm;chinese room;first-order reduction;image scaling;intelligibility (philosophy);inverse filter;order of approximation;speech recognition;transfer function;velocity (software development)	Michiaki Omura;Motohiko Yada;Hiroshi Saruwatari;Shoji Kajita;Kazuya Takeda;Fumitada Itakura	1999		10.1109/ICASSP.1999.759827	speech recognition;acoustical engineering;transfer function	Robotics	85.20164375893357	-33.587760343590055	25268
d8a7990f4eefed74c19f6cda7811b1358be8f9cb	speech analysis and modelling using a sequential arma estimation technique	nonlinear filters;speech synthesis;speech processing;speech analysis;vocal tract;arma model;speech coding;poles and zeros;speech analysis speech synthesis speech coding speech processing nonlinear filters signal synthesis telecommunications poles and zeros speech recognition acoustical engineering;acoustical engineering;speech recognition;impulse response;signal synthesis;telecommunications	Pole/zero modelling of speech has - been investigated for many years, yet the techniques developed so far have not proven satisfactory for most speech processing applications. Often these techniques separate the modelling problem in two: first and attempt is made to estimate the vocal tract impulse response; then an ARMA model is fit to such impulse response. The purpose of this paper is to discuss a different approach which is best-suited for speech analysis. This approach consist in first deriving from the speech signal a running approximation of a pseudo glottal excitation. Using a sequential minimization technique, the parameters of the ARMA model are then derived to fit a system whose input is the excitation signal and whose output is the speech signal.		R. Garc√≠a G√≥mez;Jos√© M. Tribolet	1982		10.1109/ICASSP.1982.1171684	autoregressive‚Äìmoving-average model;vocal tract;pole‚Äìzero plot;linear predictive coding;speech recognition;acoustical engineering;impulse response;computer science;speech coding;speech processing;acoustic model;speech synthesis	EDA	85.28039388673005	-32.91572319581473	25374
a75b7891448dfad78160604bf2196462419722b6	a robust method to count and locate audio sources in a stereophonic linear anechoic mixture	audio source location;demix anechoic estimates audio source location stereophonic linear anechoic mixture time delay parameter estimation;cognitive science;phase measurement;stereophonic linear anechoic mixture;audio signal processing;mixing condition;attenuation measurement;confidence measure;phase difference;signal analysis;time frequency;point location;delay effects;frequency estimation;frequency measurement;audio recording;time delay;time delay parameter estimation;phase estimation;discrete fourier transform;cognitive science signal analysis discrete fourier transforms delay estimation audio recording;robust method;robustness;parameter estimation;discrete fourier transforms;time frequency analysis;delay estimation;demix anechoic estimates;robustness delay estimation delay effects time frequency analysis frequency estimation attenuation measurement frequency measurement phase measurement phase estimation parameter estimation	We propose a new method, called DEMIX anechoic, to estimate the mixing conditions, i.e. number of audio sources plus attenuation and time delay of each sources, in an underdetermined anechoic mixture. The method relies on the assumption that in the neighborhood of some time-frequency points, only one source contributes to the mixture. Such time-frequency points, located with a local confidence measure, provide estimates of the attenuation, as well as the phase difference at some frequency, of the corresponding source. The time delay parameters are estimated, by a method similar to GCC-PHAT, on points having close attenuations. As opposed to DUET like methods, our method can estimate time-delay higher than only one sample. Experiments show that DEMIX anechoic estimates, in more than 65% of the cases, the number of directions until 6 sources and outperforms DUET in the accuracy of the estimation by a factor of 10.	broadcast delay;decade (log scale);experiment	Simon Arberet;R√©mi Gribonval;Fr√©d√©ric Bimbot	2007	2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07	10.1109/ICASSP.2007.366787	speech recognition;time‚Äìfrequency analysis;computer science;signal processing;mathematics;statistics	Robotics	83.6519757574859	-36.02402557117357	26219
0e97ff6de10da675ae47047354000b5ae67b6e3d	enhanced wiener post-processing based on partial projection back of the blind signal separation noise estimate	noise estimation;speech interfaces;diffuse background;wiener filters blind source separation frequency domain analysis human computer interaction microphone arrays noise abatement signal denoising speech enhancement speech recognition speech based user interfaces;speech enhancement;indexes;point source;hidden markov models;three dimensional displays signal to noise ratio abstracts indexes hidden markov models antennas;microphone array;three dimensional displays;abstracts;antennas;blind signal separation;speech recognition;speech recognition task partial projection blind signal separation noise estimate human machine hands free speech interface user voice microphone array diffuse background noise suppression speech estimate frequency domain blind signal separation fd bss wiener filter based postprocessing diffuse background noise estimation speech enhancement word recognition;wiener filter;signal to noise ratio;frequency domain	In this paper, we consider the human/machine hands-free speech interface where the user voice is picked at a distance with a microphone array. It is assumed that the user is close enough to the machine to be considered as a point source. The noise is a diffuse background noise, created by all the sources present in the environment. The proposed method aims at suppressing the diffuse background noise efficiently without distorting the speech estimate. This method is a modification of a method combining frequency domain blind signal separation (FD-BSS) and Wiener filter based postprocessing. Contrary to the conventional approach, we modify the estimate of the diffuse background noise given by FD-BSS before applying the Wiener filter based post-processing. We also have to build a modified observation using the FD-BSS in order to apply our modified post-processing. Simulation results show that the proposed approach can achieve a better speech enhancement, measured in term of word recognition in a speech recognition task, than the conventional Wiener filter based post-processing.	blind signal separation;distortion;microphone;simulation;speech enhancement;speech recognition;video post-processing;wiener filter	Jani Even;Hiroshi Saruwatari;Kiyohiro Shikano	2009	2009 17th European Signal Processing Conference		speech recognition;acoustics;computer science;wiener filter;communication;wiener deconvolution	ML	84.217293297283	-35.02960211116606	26231
aac3788ac6048ec0176c837f82bd2658f3bcb45b	broad band filter selection by approximating principal components of reflectance spectra			rca spectra 70	Stephan Helling	2008			analytical chemistry;spectral line;reflectivity;principal component analysis;chemistry	Vision	83.56876314982064	-47.143030348621764	26934
ca0b217cde31a0bde27a6c6591feb149148dbc6e	magnitude-only estimation of handset nonlinearity with application to speaker recognition	distorted signal;nonlinear filters;model parameters;degradation;speech recognition algorithm;finite length linear filters;iterative algorithms;nonlinear channels;speech processing;magnitude only representation;telephone sets;speech processing speaker recognition parameter estimation spectral analysis telephone sets telecommunication channels signal representation filtering theory memoryless systems iterative methods finite element analysis;mean square;telephone channels telephone handset nonlinearity magnitude only estimation spectral magnitude matching distorted signal nonlinear channel model undistorted reference magnitude only representation speech formants nonlinear channels speech recognition algorithm speaker recognition algorithm distortion model memoryless polynomial nonlinearity finite length linear filters mean squared spectral magnitude error minimization model parameters iterative estimation gradient descent technique iterative correction term finite element approximation;telephone channels;memoryless polynomial nonlinearity;telephony;speech formants;linear filtering;polynomials;speaker recognition;iterative methods;gradient descent technique;nonlinear distortion;telephone sets iterative algorithms telephony nonlinear distortion degradation speech recognition polynomials nonlinear filters error correction jacobian matrices;spectral magnitude matching;finite element approximation;channel model;gradient descent;error correction;signal representation;speech recognition;iterative correction term;telephone handset nonlinearity;speaker recognition algorithm;mean squared spectral magnitude error minimization;finite element analysis;parameter estimation;spectral analysis;telecommunication channels;memoryless systems;jacobian matrices;iterative estimation;distortion model;magnitude only estimation;nonlinear channel model;filtering theory;undistorted reference	"""A method is described for estimating telephone handset nonlinearity by matching the spectral magnitude of the distorted signal to the output of a nonlinear channel model, driven by an undistorted reference. This \magnitude-only"""" representation allows the model to directly match unwanted speech formants that arise over nonlinear channels and that are a potential source of degradation in speaker and speech recognition algorithms. As such, the method is particularly suited to algorithms that use only spectral magnitude information. The distortion model consists of a memoryless polynomial nonlinearity sandwiched between two nite-length linear lters. Minimization of a mean-squared spectral magnitude error, with respect to model parameters, relies on iterative estimation via a gradient descent technique, using a Jacobian in the iterative correction term with gradients calculated by nite-element approximation. Initial work has demonstrated the algorithm's usefulness in speaker recognition over telephone channels by reducing mismatch between highand low-quality handset conditions."""	algorithm;approximation;channel (communications);distortion;elegant degradation;gradient descent;iterative method;jacobian matrix and determinant;nonlinear system;polynomial;speaker recognition;speech recognition	Thomas F. Quatieri;Douglas A. Reynolds;Gerald C. O'Leary	1998		10.1109/ICASSP.1998.675372	gradient descent;speaker recognition;nonlinear distortion;error detection and correction;speech recognition;degradation;computer science;machine learning;finite element method;linear filter;speech processing;mathematics;iterative method;telephony;estimation theory;polynomial	ML	85.77315903001663	-32.94930072064994	27395
cbae92e71dc433b192f992ff733daebabe7506f2	acoustic scene change detection by spectro-temporal filtering on spectrogram using chirps	reverberation;filtering;chirp;sensors;spectrogram;proceedings paper;modulation	Indoor acoustic scene change detection systems using periodic impulse signals were developed in the past. Comparing with impulse signals, the chirp signal is more robust against environmental noise due to its specific spectro-temporal structure, which can be easily detected using a spectro-temporal modulation filtering mechanism. In this paper, we demonstrate a system which employs the two-dimensional spectro-temporal filtering mechanism on Fourier spectrogram to measure the total energy of reverberations of the chirp signal and compares the energy difference between consecutive chirps with a predefined threshold to automatically detect the change of the acoustic scene. Simulation results show the proposed system is very effective in detecting the acoustic scene change in a real living room with great robustness against noise recorded from real-world.	acoustic cryptanalysis;chirp;modulation;sensor;signal-to-noise ratio;simulation;spectrogram	Chang-Hong Lin;Kah-Meng Cheong;Mao-Chang Huang;Ming-Yen Chen;Chen-Kuei Chang;Tai-Shih Chi	2016	2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)	10.1109/APSIPA.2016.7820783	electronic engineering;speech recognition;acoustics;engineering	Robotics	85.44035260284598	-39.624367581646865	27469
ea34d1b23f02c69802c5c8fe1b1e9f3dc0ab4355	reverberation robust multi-channel post-filtering using modified signal presence probability	reverberation;speech signal to noise ratio reverberation sensors estimation signal detection;sensors;signal detection;noise reduction reverberation robust multichannel post filtering modified signal presence probability sp p direct to reverberate ratio drr signal detection scheme residual interference estimation signal preservation;signal detection estimation theory filtering theory interference signal reverberation signal denoising;speech;estimation;signal to noise ratio;signal detection speech enhancement multi channel post filtering reverberation robust	A multi-channel post-filtering algorithm in reverberant environment based on detection and estimation scheme is proposed. The key estimator of signal presence probability (SP-P), which is in consideration of reverberation, is modified with direct-to-reverberate ratio (DRR). A new desired signal detection scheme is proposed to instruct the updating of transient noise and residual interference estimation, which takes advantage of SPP in the time-frequency domain. The proposed multi-channel post-filtering is tested in different non-stationary noisy and reverberant environments. Experimental results show that it outperforms the comparative algorithms on signal preservation of the desired speech with more noise reduction.	algorithm;deficit round robin;detection theory;interference (communication);noise reduction;self-propelled particles;stationary process;time‚Äìfrequency analysis;transient noise	Xiaofei Wang;Xu Li;Yanmeng Guo;Qiang Fu;Yonghong Yan	2015	2015 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP)	10.1109/ChinaSIP.2015.7230493	electronic engineering;speech recognition;acoustics;signal transfer function;engineering;noise;multiplicative noise;noise floor;signal-to-noise ratio;signal averaging	EDA	83.23072906632245	-34.73759237967182	27744
689de67c6a3d26ade6f3764a58f35395d6d8cc74	electroacoustic characterization of hearing aids: a system identification approach	linear systems;hearing aids;test stimuli;autoregressive moving average processes;real world signals;speech processing;speech analysis;auditory system;linear system identification;testing;distortion measurement;adaptive processing;linear system;speech based transient distortion measures electroacoustic characterization hearing aids system identification approach adaptive processing test stimuli steady state performance automatic signal processing hearing aids natural speech input signals linear system identification time varying models real world signals;frequency response;system identification;signal processing;identification;electroacoustic characterization;steady state performance;autoregressive moving average processes hearing aids speech processing identification;time varying models;speech based transient distortion measures;hearing aids auditory system testing signal processing distortion measurement frequency response speech processing speech analysis steady state linear systems;automatic signal processing hearing aids;development time;hearing aid;system identification approach;natural speech input signals;steady state	The accurate electroacoustic characterization of hearing aids is important for the design, assessment and fitting of these devices. With the prevalence of modern adaptive processing strategies (e.g., level-dependent frequency response, multi-band compression etc.) it has become increasingly important to evaluate hearing aids using test stimuli that are representative of the signals a hearing aid will be expected to process (e.g., speech). Nearly all current hearing aid tests use stationary test signals that can characterize only the steady-state performance of a hearing aid. The present research examines the characteristics of automatic signal processing hearing aids with natural-speech input signals that may cause the hearing aid response to time-vary. They have investigated a number of linear system identification techniques that can be used to develop time-varying models of hearing aids. Using these models, one can begin to characterize performance of hearing aids with real-world signals and explore speech-based transient distortion measures.		Todd Schneider;Donald G. Jamieson	1995		10.1109/ICASSP.1995.479746	speech recognition;computer science;signal processing;speech processing;linear system	ML	84.95062780654058	-32.42416196926599	28229
127820ec0d5c95d6dd0fffb38f0f1ae5307ba25c	frequency analysis of the detectability of virtual haptic gratings	sinusoidal gratings;explicative fourier series;haptic interfaces gratings wavelength measurement surface texture frequency measurement humans laboratories testing fourier series teeth;texture;estimation theory;touch physiological;wavelength measurement;detection threshold estimation;fourier series;frequency analysis;haptic device;degree of freedom;touch physiological estimation theory force feedback fourier analysis texture;gratings;sinusoidal tactile detectability;3 degrees of freedom;testing;frequency measurement;surface texture;0 2 to 25 6 mm frequency analysis virtual haptic gratings sinusoidal tactile detectability adaptive tracking detection threshold estimation 3 degrees of freedom force feedback haptic device square wave gratings explicative fourier series sinusoidal gratings;adaptive tracking;detection threshold;force feedback;force feedback haptic device;virtual haptic gratings;teeth;fourier analysis;humans;haptic interfaces;frequency domain;square wave gratings;0 2 to 25 6 mm;fundamental frequency	The tactile detectability of sinusoidal and square-wave virtual texture gratings were measured and analyzed. Using a three-interval one-up three-down adaptive tracking procedure, detection thresholds for virtual gratings were estimated using a custom-designed high position-resolution 3-degrees-of-freedom force-feedback haptic device. Two types of gratings were used, defined by sinusoidal and square waveforms, with spatial wavelengths of 0.2 to 25.6 mm. The results indicated that the participants demonstrated a higher sensitivity (i.e., lower detection threshold) to square-wave gratings than to sinusoidal ones at all the wavelengths tested. When the square-wave gratings were represented by the explicative Fourier series, it became apparent that the detectability of the square-wave gratings could be determined by that of the sinusoidal gratings at the corresponding fundamental frequencies. This was true for any square-wave grating as long as the detection threshold for the fundamental component was below those of the harmonic components	fourier analysis;frequency analysis;haptic technology	Steven A. Cholewiak;Hong Z. Tan	2007	Second Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems (WHC'07)	10.1109/WHC.2007.57	computer vision;electronic engineering;computer science;artificial intelligence;mathematics;optics;haptic technology;statistics	Visualization	87.45994192366345	-36.62399526146766	28850
e779001a34eecaac3454455e74b08aaca0d96020	development of anti intruders underwater systems: time domain evaluation of the self-informed magnetic networks performance	book chapter;magnetic systems;critical systems;port protection	This paper shows the result obtained during the operative test of an anti-intrusion undersea magnetic system based on a magnetometers' new self-informed network. The experi- ment takes place in a geomagnetic space characterized by medium-high environmental noise with a relevant human origin magnetic noise component. The system has two different input signals: the magnetic background field (natural + artificial) and a signal composed by the mag- netic background field and the signal due to the target magnetic field. The system uses the first signal as filter for the second one to detect the target magnetic signal. The effectiveness of the procedure is related to the position of the magnetic field observation points (reference devices and sentinel devices). The sentinel devices must obtain correlation in the noise observations and de-correlations in the target signal observations. The system, during four tries of intrusion, has correctly detected all magnetic signals generated by divers.	self-information	Osvaldo Faggioni;Maurizio Soldani;Amleto Gabellone;Paolo Maggiani;Davide Leoncini	2008		10.1007/978-3-540-88181-0_13	electronic engineering;telecommunications;engineering;electrical engineering	Robotics	92.30367105998238	-25.2234662327371	29368
42ba7d57d8c3fabd352c3671a02b8ca36367c8c2	on-line relaxation algorithm applicable to acoustic fluctuation for inverse filter in multichannel sound reproduction system	tecnologia electronica telecomunicaciones;relaxation of inverse filter;sound reproduction;reproductive system;on line adaptation;inverse filter;tecnologias;grupo a;room transfer function	In this paper, we propose a new on-line adaptive relaxation algorithm for an inverse filter in a multichannel sound reproduction system. The fluctuation of room transfer functions degrades reproduced sound in conventional sound reproduction systems in which the coefficients of the inverse filter are fixed. In order to resolve this problem, an iterative relaxation algorithm for an inverse filter performed by truncated singular value decomposition (adaptive TSVD) has been proposed. However, it is difficult to apply this method within the time duration of the sound of speech or music in the original signals. Therefore, we extend adaptive TSVD to an on-line-type algorithm based on the observed signal at only one control point, normalizing the observed signal with the original sound. The result of the simulation using real environmental data reveals that the proposed method can always carry out the relaxation process against acoustic fluctuation, for any time duration. Also, subjective evaluation in the real acoustic environment indicates that the sound quality improves without degrading the localization.	acoustic cryptanalysis;algorithm;inverse filter;linear programming relaxation;quantum fluctuation;relaxation (iterative method)	Yosuke Tatekura;Shigefumi Urata;Hiroshi Saruwatari;Kiyohiro Shikano	2005	IEICE Transactions	10.1093/ietfec/e88-a.7.1747	adaptive filter;speech recognition;kernel adaptive filter;telecommunications;reproductive system	Vision	83.69159837924188	-34.927151623557045	29580
3f2ed1ccc76435504bee0ee3c0199fe1b97c65d5	completing the rtf vector for an mvdr beamformer as applied to a local microphone array and an external microphone		A minimum variance distortionless response (MVDR) beamformer can be an effective multi-microphone noise reduction strategy‚Äô provided that a vector of transfer functions from the desired speech signal at a reference microphone to the other microphones, i.e. a vector of the relative transfer functions (RTFs), is known. When using a local microphone array (LMA) and an external microphone (XM), this RTF vector has two distinct parts: an RTF vector for that of only the LMA and a single RTF component for the XM, with the reference microphone on the LMA. Whereas a priori assumptions can be made for the RTF vector for the LMA, the RTF for the XM must be estimated as the XM position is generally unknown. This paper investigates a procedure for estimating this unknown RTF by making use of the a priori RTF vector for the LMA, thereby completing the RTF vector for use of the MVDR beamformer. It is shown that such a procedure results in an Eigenvalue Decomposition (EVD) of a 2√ó2 matrix for a system of M microphones in the LMA and one XM. The resulting performance is evaluated within the context of a monaural MVDR beamformer.	beamforming;microphone;noise reduction	Randall Ali;Toon van Waterschoot;Marc Moonen	2018	2018 16th International Workshop on Acoustic Signal Enhancement (IWAENC)	10.1109/IWAENC.2018.8521368		Robotics	84.18945837248175	-35.684728534336074	30576
a2cfc7a035f94d70513d0ae0826efffac2147249	designing modulation filters for improving speech intelligibility in reverberant environments	speech intelligibility	In this paper, we propose a new technique to design modulation filters to reduce degradation of speech intelligibility in reverberant environments. Using the inverse modulation transfer function, we design data-derived modulation filters for each speech frequency band. These filters preprocess speech signals between a microphone and a loudspeaker that radiates speech into a performance hall. Using our modulation filters, we conducted perceptual experiments with one hearingimpaired subject and two subjects with normal hearing. Test results indicate that our proposed method improves the intelligibility of reverberant speech.	elegant degradation;experiment;frequency band;intelligibility (philosophy);loudspeaker;microphone;modulation;preprocessor;transfer function	Tomoko Kitamura;Keisuke Kinoshita;Takayuki Arai;Akiko Amano-Kusumoto;Yuji Murahara	2000			speech recognition;modulation;loudspeaker;microphone;frequency band;intelligibility (communication);computer science;optical transfer function	ML	85.03274225444736	-34.216551390929325	31226
a63101a09746b96e2235ebfd23b2a46afc274916	parametric electric guitar synthesis	parametric electric guitar synthesis	The electric guitar is one of the most common musical instruments today. Several synthesis algorithms have been created to synthesize its sound (Sullivan 1990; Karjalainen et al. 2006; Pakarinen, Puputti, and V√§lim√§ki 2008; Smith 2008). However, these previous synthesis models lack a few features that contribute to, or alter, the characteristic electric guitar tone. Firstly, the magnetic pickup used in electric guitars alters the sound radically. The magnetic pickup acts as a bandpass filter and causes a comb filter‚Äìlike effect as a function of its position (Jungmann 1994). In addition, the response of the magnetic pickup has been found to be inharmonic, as are the vibrations of the string. Secondly, when using a distortion effect, the details of the attack and the sustain part of a tone are brought to an audible level, which is not the case with acoustic instruments. This is caused by the radically increased gain (0‚Äì120 dB) and the inherent compression of the distortion effect. Thirdly, the instrument can be played very expressively: The player has total control of the plucking event (plucking angle, force, and width) and can bend the string to alter the pitch. This article proposes a new parametric synthesis model that enables the creation of these sonic features. The synthesis model is based on the waveguide method (Jaffe and Smith 1983; Smith 1992; Karjalainen, V√§lim√§ki, and Tolonen 1998) with novel alterations. A new excitation model is introduced that recreates the plectrum scrape and the first displacement pulse created during the plucking event. The excitation model also accounts for different plucking forces, and the angle of the virtual plectrum is controllable. The string model is	acoustic cryptanalysis;algorithm;all-pass filter;comb filter;computer music journal;dispersive partial differential equation;displacement mapping;distortion;online and offline;piezoelectricity;signal processing;simulation;smoothing;software propagation;speech synthesis	Niklas Lindroos;Henri Penttinen;Vesa V√§lim√§ki	2011	Computer Music Journal	10.1162/COMJ_a_00066	waveguide;speech recognition;pickup;computer science;guitar;distortion;acoustics;parametric statistics;band-pass filter;vibration;electric guitar	Graphics	86.0764694427294	-30.80215697215816	31864
970d5d8cd2540a8d5720de1224f57eff1ff9075d	gabor expansion for stereophonic acoustic echo cancellation	echo cancellation;adaptive filters acoustic signal processing echo suppression decorrelation;cross correlation;acoustic signal processing;classical solution;adaptive filters;stereophonic acoustic echo cancellation;echo suppression;decorrelation;echo cancellers acoustic devices adaptive filters gabor filters decorrelation computational efficiency frequency digital signal processing teleconferencing convergence;adaptive filter;adaptive filtering gabor expansion stereophonic acoustic echo cancellation hands free stereophonic devices convergence problems cross correlation complexity misalignment decorrelating whitening cross filters;acoustic echo canceller	In hands-free stereophonic devices, a stereo acoustic echo canceller is usually included. This however can exhibit convergence problems caused by the strong cross-correlation between the signals of the two channels. In this paper a new stereo acoustic echo cancellation structure based on the Gabor expansion is presented, which allows one to get better performance than other classical solutions, both in terms of complexity and misalignment. In fact, the decorrelating and whitening capabilities of the Gabor expansion, recently proposed for monophonic echo cancellation, allow one to avoid the use of cross-filters and make the adaptive filtering in each sub-band more effective.	acoustic cryptanalysis;echo suppression and cancellation	L. Parolini;S. Bartoloni;Francesco Piazza	2001		10.1109/ISCAS.2001.921184	adaptive filter;computer vision;electronic engineering;speech recognition;computer science	NLP	84.0348392799691	-33.14992421259456	32366
fa324df65d3be4fce31d1855bc4728e8c8e7e7d7	analysis of a crossed-film cryoton shift register	delay lines;bibliographies;magnetostriction;shift registers delay lines magnetostriction bibliographies military computing aircraft navigation airborne radar reflection magnetic field induced strain material storage;material storage;shift registers;airborne radar;reflection;magnetic field induced strain;military computing;aircraft navigation		shift register	H. H. Edwards;V. L. Newhouse;J. W. Bremer	1961	IRE Trans. Electronic Computers	10.1109/TEC.1961.5219201	electronic engineering;reflection;engineering;electrical engineering;magnetostriction;shift register;physics;remote sensing	HCI	90.8059294695534	-25.654937264001678	32604
aa39a4b22122df2dfcc20bcce51e3b28df7a1044	hybrid electronic tongues applied to the quality control of wines		The legislation of food industry is becoming increasingly strict with regard to the quality of food products. Therefore, the market is demanding for automatic systems of analysis that allow fast and accurate monitoring of the evolution of quality parameters in agrofood products or permit obtaining information to optimize production processes. In this context, sensors andmore specifically microsensors play an important role since they allow fast and reproducible measurement of a large number of quality parameters with good reliability and can be implemented in portable systems. This paper presents a review of the results obtained with an electronic tongue based on different kinds of microsensors applied to wine analysis by the team of IMB-CNM. This multisensor system allows on one hand classifying the wine according to its features like grape variety, geographic origin, year, and organoleptic characteristics and on the other hand quantifying some parameters of interest in quality control, such as alcoholic degree, pH, ions, total acidity, glycerol, and color.	requirement;sensor;signal processing;throughput	Manuel Guti√©rrez-Capit√°n;Fina Capdevila;Jordi Vila-Planas;Carme Domingo;Stephanus B√ºttgenbach;Andreu Llobera;Anna Puig-Pujol;Cecilia Jim√©nez-Jorquera	2014	J. Sensors	10.1155/2014/598317	simulation;engineering	AI	86.1562584610758	-50.30455026414627	32772
87d4aed31e2b0b3364e9478d09c50afa511c14c5	a preprocessing filter for enhancing lpc analysis/synthesis of noisy speech	nonlinear filters;filtering;speech synthesis;distance measure;spectrogram;real time;speech analysis;spectrum;speech enhancement;linear predictive;linear predictive coding;speech analysis speech synthesis linear predictive coding speech enhancement signal synthesis data preprocessing nonlinear filters spectrogram real time systems filtering;signal synthesis;data preprocessing;noise removal;real time systems	"""The goal of this study was to develop an effective and computationally inexpensive method of enhancing the linear prediction analysis/synthesis of noisy speech. To this end, a preprocessing filter has been proposed that is capable of perfectly removing the """"expected"""" noise signal when the input speech spectrum is closely approximated by the noisy speech spectrum. The proposed filter has been evaluated by the linear prediction distance measure, perceptual listening, and spectrograms. This evaluation has demonstrated the effectiveness of the filter for broadband noise removal. The filter has also been implemented as a preprocessing filter in a real time LPC system. The total processing time for the filtering is only 2.6 msec per 22.5 msec frame. In this system, the LPC analysis and synthesis takes a combined time of 13 msec."""	preprocessor	Marvin R. Sambur	1979		10.1109/ICASSP.1979.1170595	filter;spectrum;linear predictive coding;speech recognition;computer science;spectrogram;root-raised-cosine filter;data pre-processing;filter design;speech synthesis	NLP	83.27424802080841	-33.63967615210335	33531
cf03dfbd92c4150343c93417d63546ee7b6e615b	study of the frequency-domain multichannel noise reduction problem with the householder transformation		This paper presents an approach to the multichannel noise reduction problem. It first transforms the multichannel noisy speech signals into the frequency domain. A Householder transformation is then constructed, which converts the multichannel coefficients in each frequency bin into two components: one dominated by speech and the other dominated by noise. A Wiener filter is subsequently formed to achieve an estimate of the noise in the speech dominated component from the noise dominated component. The enhanced speech is then obtained by subtracting the noise estimate from the speech dominated component. This approach consists of two critical steps: construction of the Householder transformation and formation of the noise reduction Wiener filter. If the source incidence angle is known a priori, the Householder transformation can be directly constructed using the steering vector and the optimal estimate of the signal of interest can then be obtained by applying the Wiener filter. If the source incidence angle is not known a priori, the Householder transformation can be constructed from a hypothesized incidence angle. Then, the optimal signal estimate is obtained by searching the maximum of the variance of the enhanced signal with the Wiener filter in the interested range of the incidence angle.	coefficient;householder transformation;incidence matrix;noise reduction;wiener filter	Gongping Huang;Jacob Benesty;Jingdong Chen	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7952203	mathematical optimization;bin;wiener filter;wiener deconvolution;frequency domain;noise reduction;noise measurement;householder transformation;reverberation;mathematics	Robotics	83.01563530777788	-34.68924060851413	34064
37e45bca236541436e0f465966255250b934a90d	a study on sampling of stft modifications in time and frequency domains for dnn-based speech dereverberation	reverberation;training;speech;discrete fourier transforms;time frequency analysis	We investigate the effects of time and frequency sampling on short-time Fourier transform modifications to be used for speech dereverberation based on deep neural networks (DNNs). We first show that by adopting a linear activation function at the output layer and globally normalizing the target features into zero mean and unit variance, better performances can be obtained than existing DNN approaches. Then we show that the quality of dereverberated speech could be degraded with denser sampling in time for longer reverberation times, even at the price of increased computational complexities, requiring an adaptive time sampling strategy. On the other hand, the difference between the unwrapped phases of reverberant and anechoic speech becomes negligible with a dense sampling in frequency, implying a reduced speech distortion. Therefore, there is a great potential to enhance DNN based acoustic signal processing if the conventional sampling strategy can be carefully adjusted.	acoustic cryptanalysis;activation function;analysis of algorithms;artificial neural network;computation;deep learning;distortion;performance;sampling (signal processing);short-time fourier transform;signal processing	Bo Wu;Kehuang Li;Minglei Yang;Chin-Hui Lee	2016	2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)	10.1109/APSIPA.2016.7820830	speech recognition;acoustics;engineering;communication	ML	83.93106906783501	-32.68476862614599	34330
171b60964e9c06d67bb691b8aeb4b48913da2bdf	sub-band feedback cancellation with variable step sizes for music signals in hearing aids	medical signal processing acoustic signal processing adaptive filters feedback hearing aids;frequency shifting adaptive feedback cancellation algorithms hearing aids biased adaptation tonal signals music signals distortion artifacts entrainment subband feedback cancellation system adaptation control general adaptive filter algorithms prediction error filtering;acoustics multiple signal classification hearing aids frequency control signal processing signal processing algorithms speech;hearing aids adaptive feedback cancellation nlms filter adaptation adaptation control	Standard adaptive feedback cancellation algorithms in hearing aids suffer from a biased adaptation if the input signal is spectrally colored, as it is for tonal signals, like music. Due to that, distortion artifacts (entrainment) are generated. In this paper, a sub-band feedback cancellation system is presented combined with an adaptation control to deal with those signals. Two control concepts for determining the variable step sizes [1, 2], known from general adaptive filter algorithms, are theoretically and practically analyzed and evaluated for an application to feedback cancellation. For feedback cancellation the control is combined with known methods to reduce the bias, such as prediction error filtering or frequency shifting. Based on this combination, a completely new setup for feedback cancellation is proposed. It relies entirely on signals accessible in real systems, shows a low computational complexity, and therefore has a strong practical relevance.	adaptive filter;algorithm;brainwave entrainment;computational complexity theory;distortion;feedback;heterodyne;relevance	Falco Strasser;Henning Puder	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6855201	speech recognition;computer science	Robotics	83.50320379652915	-33.225478210497734	34417
f5b5020ceb4933fd000b8dacf846471532238566	time-domain analysis of magnetic resonance spectra and chemical shift images	least mean square;high resolution;biomedical nmr;low resolution;prediction algorithms;chemical shift imaging;chemical analysis;nuclear magnetic resonance;lattice algorithms;chemical shift;time domain analysis;adaptive filters;spectral analysis biomedical nmr chemical shift;filtering algorithms;magnetic separation;magnetic resonance;hardware limitations;discrete fourier transform time domain analysis magnetic resonance spectra chemical shift images autocorrelation based yule walker algorithm signal to noise ratio prediction algorithms phase errors hardware limitations lattice algorithms;magnetic resonance spectra;discrete fourier transform;chemical shift images;time domain analysis magnetic resonance chemical analysis nuclear magnetic resonance filtering algorithms prediction algorithms signal resolution autocorrelation adaptive filters magnetic separation;signal resolution;autocorrelation based yule walker algorithm;spectral analysis;signal to noise ratio;phase errors;autocorrelation	The utility of adaptive prediction and filtering algorithms and the autocorrelation-based Yule-Walker algorithm to predict and filter complex NMR (nuclear magnetic resonance) data is demonstrated. The application of these methods improves the available signal-to-noise ratio using time-domain analysis, and increases the low resolution via prediction algorithms in data containing phase errors introduced by hardware limitations. The application of the complex least-mean-squares and the modified-least-mean-squares transversal and lattice algorithms to low- and high-resolution NMR data records is demonstrated. The resolution and windowing problems found in the discrete Fourier transform are overcome by these alternative methods. >	domain analysis;resonance	L. D. Canady;Ramiro Jordan;Ali Asgharzadeh;Glen P. Abousleman;Donna Koechner;Richard H. Griffey	1990		10.1109/CBMSYS.1990.109430	computer vision;image resolution;computer science;magnetic resonance imaging;statistics	Vision	83.17328856282208	-45.668996262793	35685
d83dc2a8396e6c9305948b9f16dcbf0eef2518b4	diamond recognition algorithm using two-channel x-ray radiographic separator	diamond;sensors;algorithms;computer hardware;calibration;x rays	ABSTRACT In this paper real time classification method for two-channel X-ray radiographic diamond separation is discussed. Proposed method does not require direct hardware calibration but uses sample images as a train dataset. It includes online dynamic time warping algorithm for inter-channel synchronization. Additionally, algorithms of online source signal control are discussed, including X-ray intensity control, optical noise detection and sensor occlusion detection. Keywords: object detection, radiographic separation, dynamic time warping, signal processing. 1. INTRODUCTION Diamond is a well-known, rare, but geographically widely spread mineral. From the mineralogical point of view diamond is a metastable allotrope of carbon with face-centered cubic crystal structure. Diamonds are mostly found in natural deposits of igneous rocks known as kimberlites and la mproites, such as in ¬ìBig Hole¬î (Kimberley, South Africa), ¬ìMir¬î (Mirny, Eastern Siberia, Russia) and ¬ìArgyle¬î (West Australia) [1]. Traditional usage of diamonds - as a precious stone - is actua l in the present and likely to continue being such in the future [2]. Since the end of the 19	algorithm;radiography	Dmitry P. Nikolaev;Andrey Gladkov;Timofey S. Chernov;Konstantin Bulatov	2014		10.1117/12.2181204	engineering;mineralogy;forensic engineering;cartography	Vision	84.86758825949049	-51.45465416462486	35833
114b0ab889b3e5ecf9c21e90f83d0b1a93185d1e	vehicle counting and moving direction identification based on small-aperture microphone array	vehicle counting;ugs;moving direction;small aperture microphone array	The varying trend of a moving vehicle's angles provides much important intelligence for an unattended ground sensor (UGS) monitoring system. The present study investigates the capabilities of a small-aperture microphone array (SAMA) based system to identify the number and moving direction of vehicles travelling on a previously established route. In this paper, a SAMA-based acoustic monitoring system, including the system hardware architecture and algorithm mechanism, is designed as a single node sensor for the application of UGS. The algorithm is built on the varying trend of a vehicle's bearing angles around the closest point of approach (CPA). We demonstrate the effectiveness of our proposed method with our designed SAMA-based monitoring system in various experimental sites. The experimental results in harsh conditions validate the usefulness of our proposed UGS monitoring system.	acoustic cryptanalysis;algorithm;bands;coherence (physics);direction of arrival;drug vehicle;frequency band;kernel density estimation;microphone device component;motion estimation;node - plant part;non-small cell lung carcinoma;sensor web;zero suppression	Xingshui Zu;Shaojie Zhang;Feng Guo;Qin Zhao;Xin Zhang;Xing You;Huawei Liu;Baoqing Li;Xiaobing Yuan	2017		10.3390/s17051089	embedded system;electronic engineering;simulation;engineering	Robotics	85.26809975086556	-41.91571849089278	35889
f2c1bc2c736049638dde55bab0d1df493cf357bf	depth discrimination for low-frequency sources using a horizontal line array of acoustic vector sensors based on mode extraction	acoustic vector sensor;depth discrimination;horizontal line array;mode extraction	Depth discrimination is a key procedure in acoustic detection or target classification for low-frequency underwater sources. Conventional depth-discrimination methods use a vertical line array, which has disadvantage of poor mobility due to the size of the sensor array. In this paper, we propose a depth-discrimination method for low-frequency sources using a horizontal line array (HLA) of acoustic vector sensors based on mode extraction. First, we establish linear equations related to the modal amplitudes based on modal beamforming in the vector mode space. Second, we solve the linear equations by introducing the total least square algorithm and estimate modal amplitudes. Third, we select the power percentage of the low-order modes as the decision metric and construct testing hypotheses based on the modal amplitude estimation. Compared with a scalar sensor, a vector sensor improves the depth discrimination, because the mode weights are more appropriate for doing so. The presented linear equations and the solution algorithm allow the method to maintain good performance even using a relatively short HLA. The constructed testing hypotheses are highly robust against mismatched environments. Note that the method is not appropriate for the winter typical sound speed waveguide, because the characteristics of the modes differ from those in downward-refracting sound speed waveguide. Robustness analysis and simulation results validate the effectiveness of the proposed method.	acoustic cryptanalysis;algorithm;beamforming;cordic;conceptualization (information science);conflict (psychology);estimated;extraction;least-squares analysis;less than;linear equation;mathematics-mechanization platform;max;medulloblastoma;microspectrophotometry;modal logic;natural science disciplines;offset binary;process-centered design;projections and predictions;protein array analysis;refresh rate;sessile serrated adenoma/polyp;simulation;velocity (software development);vertical bar;waveguide device component;weight;sensor (device)	Guolong Liang;Yifeng Zhang;Guangpu Zhang;Jia Feng;Ce Zheng	2018		10.3390/s18113692		EDA	85.7369007661976	-41.08866190130576	35938
ade67701536f4bacad6214ac6266a55c9d04513e	multichannel noise reduction in the karhunen-lo√®ve expansion domain	speech vectors correlation noise reduction microphones noise noise measurement;speech enhancement;correlation methods;signal denoising correlation methods filtering theory karhunen loeve transforms;tradeoff filter;optimal noise reduction filter multichannel noise reduction karhunen loeve expansion domain signal dependent transform interchannel correlation intermode correlation;karhunen loeve transforms;noise reduction;wiener filter karhunen loeve expansion kle maximum snr filter minimum variance distortionless response mvdr filter multichannel noise reduction speech enhancement tradeoff filter;wiener filter;karhunen loeve expansion kle;maximum snr filter;multichannel;minimum variance distortionless response mvdr filter;filtering theory;signal denoising	The noise reduction problem is traditionally approached in the time, frequency, or transform domain. Having a signal dependent transform has shown some advantages over the traditional signal independent transform. Recently, the single-channel noise reduction problem in the Karhunen-Lo√®ve expansion (KLE) domain has received special attention. In this paper, the noise reduction problem in the KLE domain is studied from a multichannel perspective. We present a new formulation of the problem, in which inter-channel and inter-mode correlations are optimally exploited. We derive different optimal noise reduction filters and present a set of useful performance measures within this framework. The performance of the different filters is then evaluated through experiments in which not only noise but also competing speech sources are present. It is shown that the proposed multichannel formulation is more robust to competing speech sources than the single-channel approach and that a better compromise between noise reduction and speech distortion can be obtained.	channel (communications);distortion;experiment;noise reduction	Yesenia Lacouture-Parodi;Emanuel A. P. Habets;Jingdong Chen;Jacob Benesty	2014	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2014.2311299	gradient noise;gaussian noise;computer vision;speech recognition;value noise;computer science;noise measurement;noise;noise reduction;mathematics;wiener filter;statistics	ML	83.61744999707167	-34.91050885624346	36230
2c38927a1de6900d7f551df4a73dc14e4d4de72d	denoising of human speech using combined acoustic and em sensor signal processing	speech signal;real time de noising filters;sensor systems;processing;general and miscellaneous mathematics computing and information science;combined glottal em sensor and acoustic signals;human speech;acoustics;real time;digital filters speech enhancement noise interference suppression acoustic signal processing acoustic filters;speech;acoustic signal processing;speech enhancement;interference;acoustic filters;interference suppression;low power;low power em radar like sensors;signal processing;noise reduction;combined acoustic em sensor signal processing;digital filters;noise reduction humans acoustic sensors speech enhancement sensor systems acoustic measurements power measurement production systems real time systems interference;production;production systems;humans;speech signal human speech combined acoustic em sensor signal processing low power em radar like sensors combined glottal em sensor and acoustic signals real time de noising filters;acoustic sensors;acoustic measurements;speech production;power measurement;noise;real time systems	Low Power EM radar-like sensors have made it possible to measure properties of the human speech production system in real-time, without acoustic interference. This greatly enhances the quality and quantify of information for many speech related applications. See Holzrichter, Burnett, Ng, and Lea, J. Acoustic. Soc. Am. 103 (1) 622 (1998). By using combined Glottal-EMSensorand Acoustic-signals, segments of voiced, unvoiced, and no-speech can be reliably defined. Real-time de-noising filters can be constructed to remove noise from the user s corresponding speech signal.	acoustic cryptanalysis;algorithm;interference (communication);noise reduction;production system (computer science);quantum number;radar;real-time clock;sampling (signal processing);sensor;signal processing	Lawrence C. Ng;Gregory C. Burnett;John F. Holzrichter;Todd J. Gable	2000		10.1109/ICASSP.2000.861925	voice activity detection;computer vision;speech recognition;computer science;speech;signal processing;speech processing	ML	84.96385719994697	-35.21523582390387	36483
db0e88733c71b1d1d16ca7a680903518e5bf6ad2	a support vector regression-based method for target direction of arrival estimation from hf radar data		High-frequency (HF) radars have great potential for maritime surveillance, and the multiple signal classification (MUSIC) algorithm is usually used to estimate the direction of arrival (DOA) of targets for a wide-beam radar. However, the performance of the MUSIC algorithm relies on the precision of the antenna pattern, which could be contaminated by nearby electromagnetic interference. Therefore, the actual antenna pattern must be measured and used. In order to remove the requirement of antenna pattern measurement, a new method for target DOA estimation from wide-beam HF radar data using support vector regression (SVR) is proposed in this letter. A system model that relates target bearing and radar data feature is obtained through the SVR-based machine learning using the automatic identification system data and data associated with the vessels successfully detected by the HF radar. Then, such a model is used to determine the DOAs of targets from new data. The field experimental results at two sites demonstrate that the performance of the SVR method is better than that of the MUSIC algorithm.	algorithm;automatic identification and data capture;direction of arrival;distortion;feature selection;helicon filter;helicon focus;interference (communication);kernel density estimation;music (algorithm);machine learning;many antennas;mathematical optimization;radar;radiation pattern;support vector machine	Ruokun Wang;Biyang Wen;Weimin Huang	2018	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2018.2807405	support vector machine;mathematics;computer vision;artificial intelligence;radiation pattern;multiple signal classification;radar;electromagnetic interference;system model;bearing (mechanical);direction of arrival	Visualization	84.53210813274289	-42.3445326723143	37090
5063e43e1c03ed0a282fce84ed356cabc43b3b0f	multi-modal localization and enhancement of multiple sound sources from a micro aerial vehicle		The ego-noise generated by the motors and propellers of a micro aerial vehicle (MAV) masks the environmental sounds and considerably degrades the quality of the on-board sound recording. Sound enhancement approaches generally require knowledge of the direction of arrival of the target sound sources, which are difficult to estimate due to the low signal-to-noise-ratio (SNR) caused by the ego-noise and the interferences between multiple sources. To address this problem, we propose a multi-modal analysis approach that jointly exploits audio and video to enhance the sounds of multiple targets captured from an MAV equipped with a microphone array and a video camera. We first address audio-visual calibration via camera resectioning, audio-visual temporal alignment and geometrical alignment to jointly use the features in the audio and video streams, which are independently generated. The spatial information from the video is used to assist sound enhancement by tracking multiple potential sound sources with a particle filter. Then we infer the directions of arrival of the target sources from the video tracking results and extract the sound from the desired direction with a time-frequency spatial filter, which suppresses the ego-noise by exploiting its time-frequency sparsity. Experimental demonstration results with real outdoor data verify the robustness of the proposed multi-modal approach for multiple speakers in extremely low-SNR scenarios.	aerial photography;camera resectioning;direction of arrival;microphone;modal logic;on-board data handling;particle filter;signal-to-noise ratio;sparse matrix;streaming media;video tracking	Ricardo Sanchez-Matilla;Lin Wang;Andrea Cavallaro	2017		10.1145/3123266.3123412	spatial filter;camera resectioning;computer vision;streams;artificial intelligence;video tracking;microphone array;computer science;sound recording and reproduction;direction of arrival;video camera	Robotics	85.90298063637533	-39.658493366214415	37580
731af6ca2ddca5aef76fcc340869efbc7eac2c22	hybrid algorithm for robust, real-time source localization in reverberant environments	reverberation;local algorithm;audio signal processing;source localization;robustness delay effects delay estimation microphone arrays acoustic noise position measurement sampling methods acoustic testing array signal processing working environment noise;real time;simulation;computations;reverberation beam steering array signal processing audio signal processing;array signal processing;microphone array geometry steered response pattern phase transform algorithm microphone array processing real time acoustical source location reverberant environments srp phat candidate locations spacing sampling rate;microphone array;beam steering;phase transformation;algorithms;methodology;models;hybrid algorithm;hybrid systems	The location of an acoustical source can be found robustly using the steered response pattern-phase transform (SRP-PHAT) algorithm. However SRP-PHAT can be computationally expensive, requiring a search of a large number of candidate locations. The required spacing between these locations is dependent on sampling rate, microphone array geometry, and source location. In this work, a novel method is presented that calculates a smaller number of test points using an efficient closed-form localization algorithm. This method significantly reduces the number of calculations, while still remaining robust in acoustical environments.	analysis of algorithms;hybrid algorithm;microphone;real-time clock;scsi rdma protocol;sampling (signal processing)	J. Michael Peterson;Chris Kyriakakis	2005	Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.	10.1109/ICASSP.2005.1416193	speech recognition;hybrid algorithm;audio signal processing;reverberation;computer science;beam steering;computation;methodology;hybrid system	Robotics	85.74511476876481	-36.181999042166375	37981
f82d5756faf66cfa0cf81ffa1a460e9c90800259	embedded optimization algorithms for multi-microphone dereverberation	nonlinear least squares;regularization;sparsity	In this paper we propose a new approach to multi-microphone dereverberation, based on the recent paradigm of embedded optimization. The rationale of embedded optimization in performing online signal processing tasks, is to replace traditional adaptive filtering algorithms based on closed-form estimators by fast numerical algorithms solving constrained and potentially non-convex optimization problems. In the context of dereverberation, we adopt the embedded optimization paradigm to arrive at a joint estimation of the source signal of interest and the unknown room acoustics. It is shown how the inherently non-convex joint estimation problem can be smoothed by including regularization terms based on a statistical late reverberation model and a sparsity prior for the source signal spectrum. A performance evaluation for an example multi-microphone dereverberation scenario shows promising results, thus motivating future research in this direction.	adaptive filter;algorithm;convex optimization;design rationale;embedded system;estimation theory;mathematical optimization;matrix regularization;microphone;numerical analysis;performance evaluation;programming paradigm;signal processing;smoothing;sparse matrix;spectral density	Toon van Waterschoot;Bruno Defraene;Moritz Diehl;Marc Moonen	2013	21st European Signal Processing Conference (EUSIPCO 2013)		mathematical optimization;speech recognition;machine learning;mathematics	EDA	83.33682835277365	-37.78155945230861	39039
a80f46a435abebca155c269c55cfc61d838223d0	single channel speech enhancement by frequency domain constrained optimization and temporal masking	frequency domain;constrained optimization		constrained optimization;mathematical optimization;speech enhancement	Wen Jin;Michael S. Scordilis	2006			artificial intelligence;frequency domain;speech recognition;pattern recognition;auditory masking;constrained optimization;computer science;speech enhancement;communication channel	ML	83.16008637447243	-34.82728709756226	39207
a3ff30b2a91be950f773bc9de39d10e36e0fe56c	nonnegative tensor factorization for directional blind audio source separation		We augment the nonnegative matrix factorization method for audio source separation with cues about directionality of sound propagation. This improves separation quality greatly and removes the need for training data, with only a twofold increase in run time. This is the first method which can exploit directional information from microphone arrays much smaller than the wavelength of sound, working both in simulation and in practice on millimeter-scale microphone arrays.	algorithm;fits;microphone;national transfer format;non-negative matrix factorization;run time (program lifecycle phase);simulation;software propagation;source separation;wingate 8	Noah D. Stein	2014	CoRR		speech recognition;machine learning;pattern recognition;mathematics;blind signal separation	Vision	84.04277755528291	-36.19482876685122	40781
05e2199ad312b79970d43413a911852a8da5263c	signal processing for an active sonar system suitable for advanced sensor technology applications and environmental adaptation schemes	direction-of-arrival estimation;sonar detection;sonar signal processing;active sonar system;advanced sensor technology applications;broadband adaptation methods;detection performance enhancement;environmental adaptation schemes;left/right ambiguity;signal processing chain;submarine targets;undersea targets localization;volatile littoral environments	An overview of the basic elements of an active sonar system in conjunction with a description of the signal processing chain utilized at the NATO Undersea Research Centre for detection and localization of undersea targets is presented. As the focus of the Navy has shifted to the complex and volatile littoral environments characterized by high background interference, emphasis is given to the capability of advanced sensor technology to resolve left/right ambiguity in the direction of arrival and in broadband adaptation methods to enhance detection performance by incorporating in situ environmental information in the processing chain. This processing was used in a series of sea trials organized and executed by the Centre, a few of which included submarine targets.	beamforming;direction of arrival;interference (communication);sonar (symantec);signal processing;triplet state	Alberto Baldacci;Georgios Haralabus	2006	2006 14th European Signal Processing Conference		synthetic aperture sonar;electronic engineering;acoustics;telecommunications;engineering;beamforming;sensor array	Robotics	86.6563909959609	-45.11202193552944	40902
d317d9daa7ee8a8b136f742af0eadaf07bae5517	sound interval detection of multiple sources based on sound directivity	microphones;sound localization;spectrogram;mobile robots;3d space;arrays;accuracy;high sound interval detection;multiple signal classification;speech recognition humanoid robots microphone arrays mobile robots signal classification;humanoid robots;sound localization technology;space use;microphone array;real noisy environment;robots;sound interval detection;signal classification;sound directivity information;low insertion rates;speech recognition;multiple sound sources;microphone arrays;multiple signal classification robots arrays microphones spectrogram music accuracy;music spectrogram;multiple signal classification sound interval detection speech recognition real noisy environment sound localization technology microphone array multiple sound sources 3d space sound directivity information music spectrogram high sound interval detection low insertion rates;music	Utterance interval detection is a bottleneck for the current speech recognition performance in robots embedded in real noisy environments. In the present work, we make use of sound localization technology using a microphone array, not only for localizing, but also for detecting sound intervals of multiple sound sources. In our previous work we have implemented and evaluated sound localization in the 3D-space using the MUSIC (MUltiple SIgnal Classification) method. In the present work, we proposed a method for detecting sound intervals based on the sound directivity information inferred from the dynamics of the MUSIC spectrogram. The proposed method achieved high sound interval detection accuracies and low insertion rates compared with the previous sound localization results.	acoustic cryptanalysis;acoustic model;algorithm;embedded system;humanoid robot;interval arithmetic;microphone;sensor;spectrogram;speech recognition	Carlos Toshinori Ishi;Liang Dong;Hiroshi Ishiguro;Norihiro Hagita	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5652016	speech recognition;acoustics;sound localization;computer science;engineering;artificial intelligence;multiple signal classification;directional sound;spectrogram;music	Robotics	86.24655960501875	-35.912394277409184	41837
be4e6b1c5430797ac1e02cd59fa752959dafb78e	dsp restoration techniques for audio	audio signal processing;digital signal processing acoustic noise cd recording signal restoration audio recording signal processing digital recording workstations multiple signal classification wiener filter;wiener filtering dsp restoration audio processing cd revolution vintage analog recording record label music signal restoration linear predictive coding;acoustic signal processing;signal restoration acoustic signal processing audio signal processing music;indexing terms;linear prediction coding;linear predictive coding;signal processing;wiener filtering;signal restoration;wiener filter;music;wiener filtering music signal restoration signal processing linear predictive coding	The CD revolution of 1984 unleashed a massive campaign of rerelease of vintage analog recordings. To their collective horror, record labels found that many of the original master recordings had deteriorated. Often the only existing copy of a recording was a vinyl pressing. This rush to release beloved music in the new digital form spawned intense interest in digital methods of restoring these old recordings. A number of DSP techniques have been developed to give new life to these recordings. This paper is a survey of some of those methods.	circuit restoration;the sims	James Anderson Moorer	2007	2007 IEEE International Conference on Image Processing	10.1109/ICIP.2007.4379940	multidimensional signal processing;sub-band coding;linear predictive coding;speech recognition;digital audio;audio signal processing;digital signal;computer science;digital signal processing;speech coding;signal processing;wiener filter;audio signal flow;statistics;signal	Robotics	84.55016435328677	-31.205156622568975	42209
533e09e91b47da2c3ff241c0cc67a9e116f4dd8c	iterative dft-domain inverse filter determination for adaptive listening room equalization	dft domain adaptive filtering listening room equalization inverse filtering filtered x;equalizers loudspeakers approximation methods approximation algorithms microphones acoustics signal processing algorithms		inverse filter;iterative method	Martin Schneider;Walter Kellermann	2012			electronic engineering;speech recognition;acoustics;computer science	Vision	83.70438164261174	-34.42623608481137	43111
5afa3d69acde4bf43dee05cacd6beb475a604c5a	children absorb higher doses of radio frequency electromagnetic radiation from mobile phones than adults	environmental factors;biological tissues;wtds wireless transmitting devices blood brain barrier bbb certification process children dosimetry exposurelimits emr electromagnetic radiation facts finite difference time domain anatomically correct tissue specific fdtd finite difference time domain rf radio frequency sam specific anthropomorphic mannequin sar specific absorption rate virtual family vf;pediatrics;specific absorption rate;hazards;dosimetry;medical devices;brain modeling;mobile communication;governmental safety certification process radiofrequency electromagnetic radiation doses environmental hazard effects mobile phone radiation absorption review computer models radiofrequency electromagnetic fields tissue dose rate specific absorption rate;reviews biological effects of fields biological tissues health hazards mobile handsets;finite difference methods;electromagnetic radiation;environmental factors hazards dosimetry pediatrics electromagnetic radiation specific absorption rate medical devices mobile communication biological tissues brain modeling finite difference methods	The greater vulnerability of children to the effects of environmental hazards has raised concerns about their exposure to and the resultant absorption of mobile phone radiation. Foster and Chou (2014) reviewed published studies that used computer models of radio-frequency electromagnetic fields to estimate and compare the tissue dose rate in the heads of children and adults using mobile phones. Their review confuses exposure with absorption, and the study results conclude erroneously that children are not more exposed than adults. We show that their review was not executed systematically. There are discrepancies between text summaries and the graphed ratios of child: adult peak special specific absorption rate, in line with the author's hypothesis that children have the same or lower tissue dose than adults. Even the underlying precept of their review is flawed, as the results of deterministic models are treated as random variables. In fact, model results are entirely determined by the underlying assumptions and the structure of the model. Models are included in their unsystematic review that do not consider differences in dielectric constants among different tissues, or across ages, while other models that consider such differences are not included. In this paper, we discuss the differences between exposure and tissue absorption and re-examine the results presented by Foster and Chou. Based upon our review, we suggest an alternative interpretation of the published literature. In an Appendix, we discuss modeling of tissue dose in the context of governmental safety certification processes.	automatic summarization;computer simulation;mobile phone;radio frequency;resultant	Robert D. Morris;L. Lloyd Morgan;Devra Davis	2015	IEEE Access	10.1109/ACCESS.2015.2478701	dosimetry;electromagnetic radiation;mobile telephony;telecommunications;hazard;specific absorption rate;finite difference method;electrical engineering	HCI	94.47127856607213	-25.241854294054452	43167
210de9f0214383e6d8bc551317cfe319f05cd874	real-time cognitive sonar system with target-optimized adaptive signal processing through multi-layer data fusion	target tracking radar tracking sonar detection correlation;spatial filters adaptive signal processing array signal processing sensor fusion sonar signal processing;multilayer data fusion real time cognitive sonar system radar applications signal processing information fusion data layers internal tracking module sensor layer transmit signal transmitted energy direction transmit beamforming signal to noise ratio snr signal to reverberation ratio srr spatial awareness spatial filters receive beampattern transmit beampattern	In this contribution a proof-of-concept of a real-time cognitive sonar system is shown and tested in simulations. In the field of radar applications the principle of a cognitive system has been intensively studied over the past years. However, cognitive sonar systems draw only little attention in the reseach community. In this paper we are showing a new approach for a cognitive sonar system, that is able to adapt its signal processing to measured parameters of particular targets. This is possible by the fusion of the information of different data layers. Data resulting from an internal tracking module is used to adapt the signal processing at sensor layer. This is done by adjusting the transmit signal and the direction of the transmitted energy via transmit beamforming. These adjustments improve, on the one hand, the signal-to-noise ratio (SNR) and the signal-to-reverberation ratio (SRR) of the target through the adaption of the transmitted signal, and, on the other hand, extend the spatial awareness by adapting the transmit beamformer, which results in a combination of two spatial filters: the receive beampattern and the transmit beampattern.	artificial intelligence;beamforming;cognition;fm broadcasting;layer (electronics);radar;real life;real-time clock;real-time transcription;simpl;sonar (symantec);signal processing;signal-to-noise ratio;simulation;spatial‚Äìtemporal reasoning	Tim Claussen;Viet Duc Nguyen	2015	2015 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)	10.1109/MFI.2015.7295834	pulse compression;electronic engineering;speech recognition;engineering;communication;beamforming;sensor array;signal	Robotics	85.57312943765338	-41.65858512454093	43206
4e6e90ae17113af0f3960b0d1e1693258611d719	application of continuous wavelet transform to the analysis of the modulus of the fractional fourier transform bands for resolving two component mixture	binary mixture;fractional fourier transform;quantitative analysis;continuous wavelet transform;article;spectral resolution	In this paper, the fractional Fourier transform (FrFT) is applied to the spectral bands of two component mixture containing oxfendazole and oxyclozanide to provide the multicomponent quantitative prediction of the related substances. With this aim in mind, the modulus of FrFT spectral bands are processed by the continuous Mexican Hat family of wavelets, being denoted by MEXH-CWTMOFrFT. Four modulus sets are obtained for the parameter a of the FrFT going from 0.6 up to 0.9 in order to compare their effects upon the spectral and quantitative resolutions. Four linear regression plots for each substance were obtained by measuring the MEXH-CWT-MOFrFT amplitudes in the application of the MEXH family to the modulus of the FrFT. This new combined powerful tool is validated by analyzing the artificial samples of the related drugs, and it is applied to the quality control of the commercial veterinary samples.	complex wavelet transform;continuous wavelet;fractional fourier transform;mexican hat wavelet;modulus of continuity;modulus robot	Erdal Din√ß;Fernando B. Duarte;Jos√© Ant√≥nio Tenreiro Machado;Dumitru Baleanu	2015	Signal, Image and Video Processing	10.1007/s11760-013-0503-9	harmonic wavelet transform;continuous wavelet transform;quantitative analysis;fractional fourier transform;calculus;mathematics;spectral resolution;statistics	Vision	84.68463643295372	-47.35849050579471	43317
de7222afbf329e04566e4014169087ad819a2709	an algorithm for computing lsp frequencies directly from the reflection coefficients	reflection coefficient		algorithm;coefficient	C. F. Chan;K. W. Law	1991			artificial intelligence;pattern recognition;reflection coefficient;computer science	PL	85.59809613329617	-29.777812181511237	44174
763d1f6fd1e4e7a85642d4c1475cc6730e1680a0	a method for computation of wideband ambiguity function and the numerical analysis of the bat's sonar signal	interpolation;wideband;sonar applications;frequency domain analysis;signal detection;wideband numerical analysis sonar detection signal processing frequency domain analysis interpolation microcomputers sonar applications signal detection insects;sonar detection;numerical analysis;signal processing;insects;frequency domain;ambiguity function;microcomputers	A method for implementing the wideband ambiguity function(WAF) is proposed. By this method the Doppler compression version of a signal is computed by frequency domain interpolation. A good agreement between calculated 3D-diagram and the theoretical expression is shown. The WAF program implemented on minicomputer allows to calculate various parameters of signal. Its application to studying 50 sonar signals emitted by a bat(Myotis mystacinus) discloses why bat uses differently structured echolocation signals during detection, identification, pursuit and capture of an insect.	ambiguity function;computation;numerical analysis;sonar (symantec)	Zhen-Biao Lin	1984		10.1109/ICASSP.1984.1172683	computer vision;synthetic aperture sonar;pulse compression;speech recognition;computer science;signal processing;mathematics;frequency domain;ambiguity function	Robotics	85.50282305307094	-38.393850746350346	44241
896175412a6c3a5c3fc8cd52658a1881005ae693	mouth state detection from low-frequency ultrasonic reflection	t technology;low frequency ultrasound;speech activity detection;lip state detection;voice activity detection;mouth state detection	This paper develops, simulates and experimentally evaluates a novel method based on non-contact low frequency ultrasound which can determine, from airborne reflection, whether the lips of a subject are open or closed. The method is capable of accurately distinguishing between open and closed lip states through the use of a low complexity detection algorithm, and is highly robust to interfering audible noise. A novel voice activity detector is implemented and evaluated using the proposed method and shown to detect voice activity with high accuracy, even in the presence of high levels of background noise. The lip state detector is evaluated at a number of angles of incidence to the mouth and under various conditions of background noise. The underlying mouth state detection technique relies upon an inaudible low frequency ultrasonic excitation, generated in front of the face of a user, either reflecting back from their face as a simple echo in the closed mouth state or resonating inside the open mouth and vocal tract, affecting the spectral response of the reflected wave when the mouth is open. The difference between echo and resonance behaviours is used as the basis for automated lip opening detection, which implies determining whether the mouth is open or closed at the lips. Apart from this, potential applications include use in voice generation prosthesis for speech impaired patients, or as a hands-free control for electrolarynx and similar rehabilitation devices. It is also applicable to silent speech interfaces and may have use for speech authentication.	acoustic cryptanalysis;activity tracker;airborne ranger;algorithm;authentication;chirp;computer engineering;diffuse reflection;experiment;filter design;frequency band;incidence matrix;lossless compression;matlab;modality (human‚Äìcomputer interaction);network interface device;resonance;sensor;silent speech interface;simulation;smartphone;smoothing;software propagation;speech recognition;speech synthesis;timit;tract (literature);transverse wave;voice activity detection	Ian Vince McLoughlin;Yan Song	2015	CSSP	10.1007/s00034-014-9904-4	voice activity detection;speech recognition;computer science;engineering	Mobile	84.94254715514803	-39.482961895771155	44317
15510091eed450df11c3c43a07a58adb333c342c	svm-based topological optimization of tetrahedral meshes	edge collapse;finite element analysis;flip;mesh optimization;svm	Finite element analysis (FEA) has been widely used in various fields of industrial product analysis. During the whole process of FEA, mesh model generation plays a key role, which directly influences the accuracy and speed of FEA. In order to generate high quality mesh, a number of topology-based mesh optimization methods have been proposed and applied. However, they are all quite time consuming. In this paper, we propose a SVM-based approach to topological optimization of tetrahedral meshes, aiming to improve the efficiency of topological mesh optimization by using machine learning technique. First, the methodology of the SVM-based topological mesh optimization is put forward. Then the specific features for three kinds of flip operations for tetrahedral meshes are identified and the corresponding SVM models are further set up. Finally three SVM-based flip operations are implemented and the approach is verified and analyzed. The experiment result shows the SVM-based mesh optimization method can improve the mesh optimization efficiency without losing mesh quality.	display resolution;edge contraction;federal enterprise architecture;finite element method;hexahedron;machine learning;mathematical optimization;polygon mesh;smoothing;support vector machine;time complexity	Xiaoshen Chen;Dewen Peng;Shuming Gao	2012		10.1007/978-3-642-33573-0_13	support vector machine;finite element method;polygon mesh;computer science;topology;tetrahedron	Visualization	84.42841140243699	-24.545887402779844	44790
4095bab67fb88de1c8ef90c34cf2af25baf11073	a probabilistic algorithm integrating source localization and noise suppression for meg and eeg data	temporal correlation;time course;source localization;bayesian inference;probabilistic algorithm;active measurement;noise suppression;bayesian method;probabilistic model;magnetoencephalography;posterior distribution;inverse method;auditory cortex;map estimation;graphical model;denoising;electroencephalography;inverse methods	We have developed a novel probabilistic model that estimates neural source activity measured by MEG and EEG data while suppressing the effect of interference and noise sources. The model estimates contributions to sensor data from evoked sources, interference sources and sensor noise using Bayesian methods and by exploiting knowledge about their timing and spatial covariance properties. Full posterior distributions are computed rather than just the MAP estimates. In simulation, the algorithm can accurately localize and estimate the time courses of several simultaneously active dipoles, with rotating or fixed orientation, at noise levels typical for averaged MEG data. The algorithm even performs reasonably at noise levels typical of an average of just a few trials. The algorithm is superior to beamforming techniques, which we show to be an approximation to our graphical model, in estimation of temporally correlated sources. Success of this algorithm using MEG data for localizing bilateral auditory cortex, low-SNR somatosensory activations, and for localizing an epileptic spike source are also demonstrated.	approximation;beamforming;bilateral filter;cerebral cortex;electroencephalography;epilepsy;estimated;graphical model;image noise;interference (communication);magnetoencephalography;propylene glycol;randomized algorithm;signal-to-noise ratio;simulation;statistical model;zero suppression	Johanna M. Zumer;Hagai Attias;Kensuke Sekihara;Srikantan S. Nagarajan	2006	NeuroImage	10.1016/j.neuroimage.2007.04.054	statistical model;speech recognition;electroencephalography;bayesian probability;computer science;machine learning;pattern recognition;noise reduction;graphical model;posterior probability;randomized algorithm;bayesian inference;statistics;magnetoencephalography	ML	83.43449320356623	-39.374762477646264	45551
5cfa2d41a61ecb792ce2dd1c889812ca6bc8df45	analytical reconstruction of the neuronal input current from spike train data	constante tiempo;neurone;cybernetique;cybernetics;corriente ionica;time constant;courant ionique;modele mathematique;systeme nerveux;integrable model;time course;nervous system;electrophysiology;modelo matematico;sistema nervioso;neurona;current drive;mathematical model;potencial accion;spike train;electrofisiologia;ionic current;action potential;electrophysiologie;neuron;potentiel action;cibernetica;constante temps	The time course of the current driving action potential generation at a neuron investigated experimentally is in general not measurable directly. In this paper an indirect method is introduced that allows estimation of this unknown current time course using only spike train data. Assuming the leaky integrator model as valid for the action potential encoding site of the investigated neuron, the unknown input current is obtained by determining (analytically) a current time course that upon injection into the leaky integrator model evokes action potential sequences identical to those observed experimentally. Applications of this current-reconstruction procedure to neuronal output data obtained from a leaky integrator model showed that the procedure allows a good estimation of the underlying input current even if the membrane time constant of the investigated neuron is not known exactly. Additionally, an application of current reconstruction to experimental data obtained from a cat muscle spindle primary afferent subject to repeated Œ≥-stimuli is demonstrated.		Friedemann Awiszus	1992	Biological Cybernetics	10.1007/BF00204119	psychology;electrophysiology;neuroscience;cybernetics;engineering;electrical engineering;mathematical model;leaky integrator;control theory;time constant;nervous system;action potential	ML	83.3283198708395	-26.23951015920137	45602
73d688b497bacbbdc6ec111e659b470e3f3b79d1	performance evaluation of a modified subband noise cancellation system in a noisy environment	performance evaluation;adaptive filtering;noise cancellation;filter banks	This paper presents a subband noise canceller with reduced residual noise. The canceller is developed by modifying and optimizing an existing multirate filter bank that is used to improve the performance of a conventional full-band adaptive filtering. The proposed system is aimed to overcome problems of slow asymptotic convergence and high residual noise incorporating with the use of oversampled filter banks for acoustic noise cancellation applications. Analysis and synthesis filters are optimized for minimum amplitude distortion. The proposed scheme offers a simplified structure that without employing cross adaptive filters or stop band filters reduces the effect of coloured components near the band edges in the frequency response of the analysis filters. Issues of increasing convergence speed and decreasing the residual noise at the system output are addressed. Performance under white and coloured environments is evaluated in terms of mean square error MSE performance. Fast initial convergence was obtained with this modification. Also a decrease in the amount of residual noise by approximately 10dB compared to an equivalent subband model without modification was reachable under actual speech and background noise.	acoustic cryptanalysis;adaptive filter;automation;digital signal processor;distortion;filter bank;frequency response;informatics;input/output;mean squared error;oversampling;performance evaluation;robotics	Ali O. Abid Noor;Salina Abdul Samad;Aini Hussain	2009			adaptive filter;electronic engineering;speech recognition;computer science;active noise control	HPC	83.87625637446823	-33.04562093652456	45794
e61c5578b9f6bc032e91abb82e672335a198e15c	a universal spectral analytical method for digital terrain modeling	partial derivatives;chebyshev polynomials;denoising;fejer summation;generalization	The method is exemplified by a portion of the Great Rift Valley and central Kenyan highlands. A DEM of this territory the matrix 480¬†√ó¬†481 with a grid spacing of 30‚Ä≥ was extracted from the global DEM SRTM30_PLUS. We evaluated various sets of expansion coefficients up to 7000 to approximate and reconstruct DEMs with and without the Fejer summation. Digital models of horizontal and vertical curvatures were computed using the first and second partial derivatives of elevation derived from the reconstructed DEMs. To evaluate the approximation accuracy, digital models of residuals differences between the reconstructed DEMs and the initial one were calculated. The test results demonstrated that the method is characterized by a good performance i.e., a distinct monotonic convergence of the approximation and a high speed of data processing. The method can become an effective alternative to common techniques of DEM processing.	digital elevation model	Igor V. Florinsky;A. N. Pankratov	2016	International Journal of Geographical Information Science	10.1080/13658816.2016.1188932	chebyshev polynomials;generalization;mathematical optimization;calculus;noise reduction;mathematics;geometry;partial derivative;cartography;statistics	EDA	88.21492344178175	-49.13997816056967	45906
42b0e3663c3a78a4a7c6d111e345a3ee78522046	fast and reliable tdoa assignment in multi-source reverberant environments	compatibility conflict graph acoustic source localization tdoa assignment synthesis of consistent graph;acoustic signal detection;direction of arrival estimation acoustic signal detection;compatibility conflict graph tdoa assignment multisource reverberant environments acoustic source localization time difference of arrivals zero cyclic sum condition fundamental loops;microphones acoustics speech estimation speech processing signal processing algorithms;direction of arrival estimation	The localization of acoustic sources based on Time Difference of Arrivals (TDOA) is very vulnerable in reverberant environments. In this paper, we propose a method to synthesize fully and partially consistent TDOA combinations. They fulfill the zero cyclic sum condition along all loops, which is a necessary condition for assigning TDOAs to an acoustic source. Our method is based on an efficient search of all sets of maximally connected compatible fundamental loops in a compatibility-conflict graph. We both prove the correctness of our algorithm and show some experimental results.	acoustic cryptanalysis;algorithm;correctness (computer science);cyclic permutation;multi-source;multilateration;serializability	Martin Kreissig;Bin Yang	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6637668	speech recognition;mathematics	Robotics	84.68881086123628	-36.60508685457294	45992
b8a01c3eace74c820e42d378b1985b64f31bb108	audio quality improvement of vehicular hands-free communication using variable step-size affine-projection algorithm	sound quality;signal processing;adaptive filter algorithm;acoustic	For a vehicular hands-free communication system, the sound quality of communication is usually degraded by noise which is known to be detrimental to system performance. In this paper, a novel adaptive filtering algorithm and an integrated system for acoustic echo and noise cancellation are presented. The proposed system includes adaptive noise cancellation, line enhancer, and echo cancellation which are based on a variable step-size affine-projection algorithm (VSS APA). The proposed VSS APA filtering algorithm is a combination of a variable step-size least-mean-square (VSS LMS) and an affine-projection algorithm (APA). The matrix of the APA allows more accurate, thorough input data and transforms the data into the structure of orthogonality, thus making the estimate of the weight vector faster and more accurate. To understand and verify the effectiveness of the proposed system, performance evaluation and comparison were conducted to compare the proposed algorithm and various traditional adaptive filtering algorithms in this application. The results demonstrated that the VSS APA has an effective performance and convergence in sound quality improvement of hands-free communication systems.	algorithm	Jian-da Wu;Shih-Lin Lin	2010	IJWMIP	10.1142/S0219691310003821	speech recognition;computer science;signal processing;sound quality;mathematics;statistics	EDA	84.67512860535906	-32.23594472111566	47303
7d05937d8b2e1085b965d6c0ad14b78cfc169728	robust doa estimation of heavily noisy gunshot signals	microphones;acoustics;arrays;direction of arrival estimation microphones estimation signal to noise ratio arrays acoustics;estimation;microphone arrays array signal processing direction of arrival estimation;consistent fundamental loop gunshot signal direction of arrival iterative least squares exhaustive search;microphones pair selection robust doa estimation heavily noisy gunshot signal direction of arrival estimation public safety troop safety sensor array signal to noise ratio;signal to noise ratio;direction of arrival estimation	Direction of Arrival (DOA) estimation of gunshots is an important asset to law-enforcement agencies and defense forces, for shooter localization is key to improving public and troop safety. Solutions vary according to scenario, application, and available resources. As the distance between the firing position and the sensor array increases, as in a typical sniper scenario, signal to noise ratio decreases and the estimation degrades. This paper proposes a gunshot DoA estimation algorithm to be used with highly noisy signals. We combine exhaustive search for selecting pairs of microphones from the array to attain the best DOA estimation results and fast response time for different shooting scenarios. We are particularly interested in highly corrupted signals for which state-of-the-art algorithms fail. Experimental results from simulated and recorded gunshot signals were used to evaluate the performance of the proposed scheme.	algorithm;brute-force search;decibel;direction of arrival;microphone;response time (technology);scsi rdma protocol;signal-to-noise ratio	Angelo M. C. R. Borzino;Jos√© Antonio Apolin√°rio;Marcello Luiz Rodrigues de Campos	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7178009	estimation;speech recognition;mathematics;signal-to-noise ratio;direction of arrival;sensor array;statistics	Robotics	84.60853916568391	-36.91718247820314	47306
34aac06dc93ca71da8cf43eccb820b6724e3e8ae	evaluation of all-pass reverberators	reverberation audio signal processing audio systems;reverberation tellurium signal processing algorithms acoustic reflection surface acoustic waves computational modeling digital filters algorithm design and analysis production acoustic waves;audio systems;reverberation;audio signal processing;schroeder reverberator;gardner reverberators;acoustics;finite impulse response filter;natural room reverberation;absorbent all pass reverberator;acoustic parameters;concert hall signal processing algorithms natural room reverberation digital complete artificial reverberators schroeder early reverberator late reverberator all pass filters schroeder reverberator gardner reverberators absorbent all pass reverberator acoustic parameters;digital complete artificial reverberators;late reverberator;signal processing;concert hall;low pass filters;signal processing algorithms;schroeder early reverberator;time frequency analysis;reflection;all pass filters	The paper presents the structure and the performance of signal processing algorithms that simulate natural room reverberation. It deals with three digital complete artificial reverberators, built up of Schroeder's early reverberator and a late reverberator built with all-pass filters: Schroeder's, Gardner's or absorbent all-pass reverberator. For each of the presented reverberation algorithms acoustic parameters are computed and compared with those of a concert hall.	acoustic cryptanalysis;algorithm;needham‚Äìschroeder protocol;signal processing;simulation	Marina Dana Topa;Norbert Toma;Victor Popescu;Vasile Topa	2007	2007 14th IEEE International Conference on Electronics, Circuits and Systems	10.1109/ICECS.2007.4510999	electronic engineering;speech recognition;acoustics;engineering	Robotics	85.54659824910031	-33.311265393865696	47405
6d915dd240e80129e63b3f27ce6f380f21d1b691	nested generalized sidelobe canceller for joint dereverberation and noise reduction	microphones;reverberation;speech noise reverberation noise reduction microphones transfer functions;transfer functions;speech;noise reduction;atf speech signal room reverberation ambient noise nested generalized sidelobe canceller gsc beamforming structure gsc beamformers speech dereverberation noise reduction operations short time fourier transform stft domain reverberation models acoustic transfer function;speech processing acoustic noise acoustic signal processing architectural acoustics array signal processing fourier transforms interference suppression reverberation;noise;noise reduction dereverberation	Speech signal is often contaminated by both room reverberation and ambient noise. In this contribution, we propose a nested generalized sidelobe canceller (GSC) beamforming structure, comprising an inner and an outer GSC beamformers (BFs), that decouple the speech dereverberation and the noise reduction operations. The BFs are implemented in the short-time Fourier transform (STFT) domain. Two alternative reverberation models are adopted. In the first, used in the inner GSC, reverberation is assumed to comprise a coherent early component and a late reverberant component. In the second, used in the outer GSC, the influence of the entire acoustic transfer function (ATF) is modeled as a convolution along the frame index in each frequency. Unlike other BF designs for this problem that must be updated in each time-frame, the proposed BF is time-invariant in static scenarios. Experiments with both simulated and recorded environments verify the effectiveness of the proposed structure.	acoustic cryptanalysis;beamforming;brainfuck;coherence (physics);convolution;gsc bus;noise reduction;short-time fourier transform;time-invariant system;transfer function	Ofer Schwartz;Sharon Gannot;Emanuel A. P. Habets	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7177941	speech recognition;reverberation;computer science;noise;speech;noise reduction;transfer function	Robotics	84.30462197469217	-35.374572296930886	47517
a1931689e541882e6fb6b431efc36c7556be7112	motion analysis system for robot traction device evaluation and design	robotics;traction;rover;terramechanics	Though much research has been conducted regarding traction of tires in soft granular terrain, little empirical data exist on the motion of soil particles beneath a tire. A novel experimentation and analysis technique has been developed to enable detailed investigation of robot interactions with granular soil. This technique, the Shear Interface Imaging Analysis method, provides visualization and analysis capability of soil shearing and flow as it is influenced by a wheel or excavation tool. The method places a half-width implement (wheel, excavation bucket, etc.) of symmetrical design in granular soil up against a transparent glass sidewall. During controlled motion of the implement, high-speed images are taken of the sub-surface soil, and are processed via optical flow software. The resulting soil displacement field is of very high fidelity and can be used for various analysis types. Identification of clusters of soil motion, shear interfaces and shearing direction/magnitude allow for analysis of the soil mechanics governing traction. The Shear Interface Imaging Analysis Tool enables analysis of robot-soil interactions in richer detail than possible before. Prior state-of-art technique relied on longexposure images that provided only qualitative insight, while the new processing technique identifies sub-millimeter gradations in motion and can do so even for high frequency changes in motion. Results are presented for various wheel types and locomotion modes: small/large diameter, rigid/compliant rim, grouser implementation, and push-roll locomotion.	bucket sort;displacement mapping;experiment;interaction;optical flow;robot;traction teampage	Scott Moreland;Krzysztof Skonieczny;David Wettergreen	2012		10.1007/978-3-642-40686-7_30	traction;simulation;computer science;robotics	Visualization	86.63297882485861	-24.715510433771	48840
13df0f9ceec0ed1093db3878d941ed2607cd4a20	surface modification tools in a virtual environment interface to a scanning probe microscope	telepresence;surface modification;virtual reality;force;scientific visualization;scanning probe microscope;atomic force microscopy;virtual environment;interactive graphics;haptic;scanning tunneling microscope;scanning tunneling microscopy;haptic interaction;teleoperation;atomic force microscope;virtual worlds	The NanoManipulator system has been expanded from a virtual-reality interface for a specific scanning tunneling microscope to include control of atomic force microscopes. The current state of the system is reviewed, and new tools extending the user's feel and control in manipulation and fabrication in the mesoscopic regime are detailed. Manipulations that could not be performed using the techniques available from commercial SPM systems are demonstrated, and the direction of ongoing research is outlined.	haptic technology;mesoscopic physics;real-time computing;solid-state drive;super paper mario;topography;tunneling protocol;virtual reality;word sense	Mark Finch;Vernon L. Chi;Russell M. Taylor;Michael R. Falvo;Sean Washburn;Richard Superfine	1995		10.1145/199404.199406	computer vision;scientific visualization;atomic force microscopy;computer science;virtual reality;scanning tunneling microscope;computer graphics (images)	HCI	86.62506925035237	-24.805014872576592	49171
08509c1436c5b243599440eac57e4b3414514053	improving the transform domain ecg denoising performance by applying interbeat and intra-beat decorrelating transforms	discrete cosine transforms electromyography electrocardiography medical signal processing interference suppression decorrelation;translation invariant;ecg registration interbeat decorrelating transforms intra beat decorrelating transforms electromyogram interference suppression emg electrocardiogram recordings transform domain wiener filtering multichannel data successive beats wiener filtering translation invariant wavelet domain signal to noise ratio reduced ripple artifacts signal transients true waveform diagnostics online parallel processing;interference suppression;electrocardiography;discrete cosine transforms;electrocardiography noise reduction signal processing wiener filter electromyography interference suppression decorrelation discrete cosine transforms wavelet domain signal to noise ratio;decorrelation;electromyography;wiener filter;signal to noise ratio;electromyogram;medical signal processing;parallel processing;electrocardiogram	A method for suppression of electromyogram (EMG) interference in electrocardiogram (EGG) recordings is presented, It combines inter-beats and intra-beats decorrelation techniques with transform domain Wiener filtering. The interbeats relations are kept by a short window DCT over multichannel data representing the successive beats, and the Wiener filtering is performed in translation-invariant wavelet domain. The method results in improved signal-to-noise ratio of the processed signals and reduced ripple artifacts around the signal transients, thus preserving the true waveform in diagnostically important signal segments. The algorithm's structure allows an on-line parallel processing and can be built in the ECG registration systems.		Atanas P. Gotchev;Nikolay Nikolaev;Karen O. Egiazarian	2001		10.1109/ISCAS.2001.920995	parallel processing;computer vision;electronic engineering;speech recognition;decorrelation;computer science;mathematics;wiener filter;signal-to-noise ratio;statistics;wiener deconvolution	Vision	83.32655723377026	-31.691701960233658	52215
4643142e9346e4f9bca8556252a6a7f289ea6728	novel gcc-phat model in diffuse sound field for microphone array pairwise distance based calibration	microphones;diffuse sound field;pairwise distance estimation;microphone array calibration;phase transform;microphone array calibration generalized cross correlation phase transform diffuse sound field pairwise distance estimation;acoustics;generalized cross correlation;arrays;estimation;microphones arrays coherence acoustics calibration mathematical model estimation;mathematical model;coherence function gcc phat model diffuse sound field microphone array pairwise distance based calibration generalized cross correlation phase transform;coherence;calibration;transforms audio signal processing calibration correlation methods microphone arrays	We propose a novel formulation of the generalized cross correlation with phase transform (GCC-PHAT) for a pair of microphones in diffuse sound field. This formulation elucidates the links between the microphone distances and the GCC-PHAT output. Hence, it leads to a new model that enables estimation of the pairwise distances by optimizing over the distances best matching the GCC-PHAT observations. Furthermore, the relation of this model to the coherence function is elaborated along with the dependency on the signal bandwidth. The experiments conducted on real data recordings demonstrate the theories and support the effectiveness of the proposed method.	bandwidth (signal processing);cross-correlation;experiment;microphone;theory	Jos√© F. Velasco;Mohammad Javad Taghizadeh;Afsaneh Asaei;Herv√© Bourlard;Carlos Julian Mart√≠n-Arguedas;Javier Mac√≠as Guarasa;Daniel Pizarro-Perez	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7178455	estimation;calibration;speech recognition;coherence;mathematical model;mathematics;statistics	Robotics	83.15239109217286	-36.34780812966471	52394
ae92e049feb33b188f8217a6ad89dc28f6e53fe9	sequential organization of speech in reverberant environments by integrating monaural grouping and binaural localization	analisis imagen;chambre reverberante;localisation source;computational auditory scene analysis;location based cues;reverberation;evaluation performance;speech processing reverberation;analisis escena;analyse scene;deteccion blanco;reverberation robustness speech analysis time frequency analysis degradation image analysis computer science filtering array signal processing speech processing;performance evaluation;voiced speech;sound localization;acoustic reverberation;source localization;evaluacion prestacion;speech processing;fuente sonora;speech segregation;speech;metodo secuencial;probabilistic approach;sequential method;sound localization binaural speech segregation computational auditory scene analysis monaural grouping sequential organization;detection cible;ear;binaural localization;binaural speech segregation;model based systems;enfoque probabilista;approche probabiliste;reverberacion acustica;camara reverberante;localizacion fuente;source sonore;reverberant environments;acoustic signal detection;localization performance sequential organization speech segregation reverberant environments monaural grouping binaural localization anechoic conditions room reverberation voiced speech location based cues;methode sequentielle;monaural grouping;robustness;image analysis;room reverberation;organizations;sequential organization;probabilistic logic;reverberation acoustique;sound source;target detection;analyse image;time frequency analysis;detection signal acoustique;localization performance;anechoic conditions;reverberation room;scene analysis	Existing binaural approaches to speech segregation place an exclusive burden on cues related to the location of sound sources in space. These approaches can achieve excellent performance in anechoic conditions but degrade rapidly in realistic environments where room reverberation corrupts localization cues. In this paper, we propose to integrate monaural and binaural processing to achieve segregation and localization of voiced speech in reverberant environments. The proposed approach builds on monaural analysis for simultaneous organization, and combines it with a novel method for generation of location-based cues in a probabilistic framework that jointly achieves localization and sequential organization. We compare localization performance to two existing methods, sequential organization performance to a model-based system that uses only monaural cues, and segregation performance to an exclusively binaural system. Results suggest that the proposed framework allows for improved source localization and robust segregation of voiced speech in environments with considerable reverberation.	binaural beats;internationalization and localization;location-based service	John Woodruff;DeLiang Wang	2010	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2010.2050087	image analysis;speech recognition;time‚Äìfrequency analysis;acoustics;sound localization;reverberation;reverberation room;computer science;organization;speech;speech processing;computational auditory scene analysis;linguistics;probabilistic logic;robustness	Vision	86.23948833060466	-36.59751399160468	52853
08190a587d338561447014619656a57b3ad1f9f1	multichannel dypsa for estimation of glottal closure instants in reverberant speech	dynamic programming;reverberation;speech processing;gci identification;dynamic programming projected phase-slope algorithm;glottal closure instants identification;larynx-synchronous processing;modern telecommunication applications;multichannel dypsa;reverberant speech;speech processing algorithms;speech	Identification of glottal closure instants (GCIs) is important in speech applications which benefit from larynx-synchronous processing. In modern telecommunication applications, speech signals are often obtained inside office rooms, with one or more microphones placed at a distance from the talker. Such speech signals are affected by reverberation due to the reflections from surrounding walls and objects, which distort the observed speech signals and degrade the performance of speech processing algorithms. This paper presents a study of the identifiability of GCIs from reverberant speech using the Dynamic Programming Projected Phase-Slope Algorithm (DYPSA) and new extensions to the multimicrophone case. Two multichannel algorithms are proposed and evaluated; in both cases, considerable performance gains over a single microphone are obtained, with detection rates improved by up to 29% in highly reverberant environments.	algorithm;distortion;dynamic programming;microphone;reflection (computer graphics);speech processing	Mark R. P. Thomas;Nikolay D. Gaubitch;Patrick A. Naylor	2007	2007 15th European Signal Processing Conference		voice activity detection;linear predictive coding;speech recognition;acoustics;computer science;speech coding;speech processing;communication	ML	84.78604764024222	-34.674132570081724	52860
2b2a317e1e5347cbc05c44337a877914416ebf24	composite complex sinusoidal modeling for the estimation of directions and spectra of incident plane waves	plane waves;frequency estimation;array signal processing;brain modeling;acoustic noise;noise reduction;information processing;signal resolution;microphone arrays direction of arrival estimation acoustic noise array signal processing signal resolution noise reduction computer errors frequency estimation information processing brain modeling;microphone arrays;computer errors;direction of arrival estimation	We have already reported that composite complex sinusoidal modeling (CCSM) is effective for array signal processing, in the sense that highest bearing resolution was achieved by CCSM than by any other existing methods time. The directivity pattern obtained by CCSM has no side lobe and gives only lines indicating the directions and the powers of incident plane waves at a concerning frequency. We propose here an improved CCSM to achieve a much more bearing estimation.		Masato Abe;Ken'iti Kido	1984		10.1109/ICASSP.1984.1172736	computer vision;speech recognition;plane wave;information processing;computer science;noise;noise reduction	Vision	87.29551421934353	-36.55547755403445	52937
59af7e59dd2af302ad9fb1f05d457973ed78ef5e	late reverberation synthesis: from radiance transfer to feedback delay networks	reverberation;feedback delay networks fdns;ieee transactions;delay lines;speech processing;room acoustics acoustic radiance transfer feedback delay networks fdns reverberation;speech;feedback delay networks;acoustic radiance transfer;transient response acoustic wave propagation architectural acoustics reverberation;delays ieee transactions acoustic measurements speech processing reverberation;room acoustics;pre recorded impulse response late reverberation synthesis feedback delay networks fdn room acoustic modeling sound energy exchange radiance transfer method rtm;delays	In room acoustic modeling, feedback delay networks (FDN) are known to efficiently model late reverberation due to their capacity to generate exponentially decaying dense impulses. However, this method relies on a careful tuning of the different synthesis parameters, either estimated from a pre-recorded impulse response from the real acoustic scene, or set manually from experience. In this paper, we present a new method, which still inherits the efficiency of the FDN structure, but aims at linking the parameters of the FDN directly to the geometry setting. This relation is achieved by studying the sound energy exchange between each delay line using the acoustic radiance transfer method (RTM). Experimental results show that the late reverberation modeled by this method is in good agreement with the virtual geometry setting.	acoustic cryptanalysis;acoustic model;analog delay line;simulation;sound quality	Hequn Bai;Ga√´l Richard;Laurent Daudet	2015	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2015.2478116	speech recognition;acoustics;reverberation;room acoustics;computer science;speech;speech processing	EDA	86.9962900492323	-32.77665622069686	53304
97a133b1256079eab0abfb0571aa438d095bbe3c	impact of camera lens aperture and the light source size on optical camera communications		In this paper, we investigate the defocused image in optical camera communications and the use three parameters including half power full width, maximum intensity, and slopes of the hazy area to characterize the blurred image. The paper outlines theoretical analysis for the blurry image using the captured image of the light source and the circle of confusion. An experimental test bed is developed to investigate the effect of width, height and slopes of the image of defocusing of the camera. Results show that for a larger aperture, which results in higher received power, the interference level between two light sources is increased due to defocusing of the camera.	crosstalk;digital single-lens reflex camera;interference (communication);testbed;the circle (file system)	Navid Bani Hassan;Jeanette M Bowles;Raghu Donga;Zabih Ghassemlooy;Alessandro Sturniolo;Stanislav Zvanovec;Pengfei Luo;Hoa Le Minh	2018	2018 11th International Symposium on Communication Systems, Networks & Digital Signal Processing (CSNDSP)	10.1109/CSNDSP.2018.8471766	camera lens;aperture;crosstalk;interference (wave propagation);lens (optics);optics;physics;circle of confusion	Vision	86.54930049817928	-40.53679379057127	53978
4ed3d4f096664627fb8a7972dad6c674f2344da3	adaptive blind system identification for speech dereverberation using a priori estimates	microphones;speech signal quality;cepstrum domain;reverberation;estimation theory;received signals;convergence;multimedia applications;blind source separation;speech processing;allpass components;speech;multimedia application;dereverberation;speech enhancement;acoustic impulse responses;channel estimation;speech dereverberation;adaptive algorithms;adaptive blind multichannel identification algorithm;room impulse response;adaptive algorithm;adaptive blind system identification;cepstral analysis;estimation;cepstrum;speech enhancement dereverberation adaptive algorithms blind channel estimation;delay speech cepstrum channel estimation estimation convergence microphones;impulse response;blind channel estimation;adaptive algorithm adaptive blind system identification speech dereverberation speech signal quality multimedia applications adaptive blind multichannel identification algorithm acoustic impulse responses allpass components received signals cepstrum domain;a priori estimate;blind system identification;speech processing blind source separation cepstral analysis estimation theory reverberation	Reverberation degrades the quality of a speech signal within an enclosed space and is undesirable for many multimedia applications. We show that the well-known adaptive blind multichannel identification algorithm employed for speech dereverberation suffers from misconvergence in the presence of bulk delays in the acoustic impulse responses. To address this, we propose to estimate the delay components using the allpass components of the received signals as well as pre-estimating the room impulse responses in the cepstrum domain. These pre-estimates are subsequently used for the initialization of the adaptive algorithm to achieve better impulse response estimates. Our proposed approach addresses the bulk delay problem and improves the convergence performance of the adaptive algorithm for blind system identification.	acoustic cryptanalysis;adaptive algorithm;all-pass filter;cepstrum;system identification;whole earth 'lectronic link	Rajan S. Rashobh;Andy W. H. Khong;Patrick A. Naylor	2010	2010 IEEE Asia Pacific Conference on Circuits and Systems	10.1109/APCCAS.2010.5774942	estimation;speech recognition;convergence;impulse response;reverberation;computer science;speech;cepstrum;speech processing;blind signal separation;estimation theory;statistics	EDA	83.82649196764511	-34.432301235072416	54100
e462c6f6af8326bbf7097fab0f178cbdf751bed1	lightweight and optimized sound source localization and tracking methods for open and closed microphone array configurations		Abstract Human‚Äìrobot interaction in natural settings requires filtering out the different sources of sounds from the environment. Such ability usually involves the use of microphone arrays to localize, track and separate sound sources online. Multi-microphone signal processing techniques can improve robustness to noise but the processing cost increases with the number of microphones used, limiting response time and widespread use on different types of mobile robots. Since sound source localization methods are the most expensive in terms of computing resources as they involve scanning a large 3D space, minimizing the amount of computations required would facilitate their implementation and use on robots. The robot‚Äôs shape also brings constraints on the microphone array geometry and configurations. In addition, sound source localization methods usually return noisy features that need to be smoothed and filtered by tracking the sound sources. This paper presents a novel sound source localization method, called SRP-PHAT-HSDA, that scans space with coarse and fine resolution grids to reduce the number of memory lookups. A microphone directivity model is used to reduce the number of directions to scan and ignore non significant pairs of microphones. A configuration method is also introduced to automatically set parameters that are normally empirically tuned according to the shape of the microphone array. For sound source tracking, this paper presents a modified 3D Kalman (M3K) method capable of simultaneously tracking in 3D the directions of sound sources. Using a 16-microphone array and low cost hardware, results show that SRP-PHAT-HSDA and M3K perform at least as well as other sound source localization and tracking methods while using up to 4 and 30 times less computing resources respectively.	computation (action);covox speech thing;human‚Äìrobot interaction;microphone device component;mobile robot;pleomorphic hyalinizing angiectatic tumor of soft parts;response time (technology);robot (device);signal processing;signal recognition particle ab:acnc:pt:ser/plas:qn;smoothing (statistical technique);source tracking	Fran√ßois Grondin;Fran√ßois Michaud	2018	CoRR		robustness (computer science);computer vision;filter (signal processing);source tracking;signal processing;artificial intelligence;microphone array;acoustic source localization;microphone;mobile robot;computer science	Robotics	86.14794926756356	-36.11488112791624	54121
1f92f878c3e8b3ba5592ccbe235fd1254e0da23f	guest editorial [i&m in ultrasound technology]		We are pleased to introduce this section regarding applications of ultrasound in measurements. Two papers are considered important and included in the section. Ultrasound remains one of the most well-known radiations used for active and passive detection. It is often used for distance measurement and obstacle ranging.		Aim√© Lay-Ekuakille;Mohamed Khalil	2018	IEEE Instrum. Meas. Mag.	10.1109/MIM.2018.8327970	biomedical engineering;electronic engineering;engineering;ultrasound;ranging	Visualization	95.25175605444916	-26.416388206479574	54493
b53fb5d96b4fe8be941d6db521bd84a4c08aef87	fast convolutive blind speech separation via subband adaptation	reverberation;sampling rate;filter bank;signal sampling;convolution;blind source separation;speech processing;speech;adaptive feedback;de mixing networks;distortion convolutive blind speech separation subband adaptation blind source separation bss reverberation speech signals adaptive feedback de mixing networks oversampled uniform filter bank dft computational cost sampling rate two input two output systems fullband adaptation separation quality;distortion;subband adaptation;two input two output systems;two input two output;feedback;adaptive signal processing;adaptive systems;speech source separation blind source separation reverberation adaptive systems feedback filter bank computational efficiency sampling methods distortion;channel bank filters;speech signals;bss;computational cost;time domain;oversampled uniform filter bank;signal sampling blind source separation convolution speech processing adaptive signal processing feedback reverberation channel bank filters;sampling methods;mix network;computational efficiency;source separation;fullband adaptation;dft;separation quality;convolutive blind speech separation	In this paper, we consider the problem of blind source separation (BSS) applied to speech signals. Due to reverberation, BSS in the time domain is usually expensive in terms of computations. We propose in this paper a subband BSS system based on the use of adaptive feedback de-mixing networks in an oversampled uniform DFT filter bank structure. We show that the computational cost can be significantly decreased if BSS is carried out in subbands due to the possibility of reducing the sampling rate. Experiments with real speech signals, conducted with two-input two-output BSS systems using oversampled 32-subband and fullband adaptation, indicate that separation quality and distortion are similar for both systems. However, the proposed subband system is more than 10 times computationally faster than the fullband one.		Fran√ßois Duplessis-Beaulieu;Beno√Æt Champagne	2003		10.1109/ICASSP.2003.1200019	adaptive filter;sampling;speech recognition;distortion;reverberation;time domain;computer science;speech;.bss;discrete fourier transform;filter bank;speech processing;feedback;blind signal separation;convolution;sampling	ML	83.97345333947351	-32.872448258948204	54927
d84d11d33372454e9e692e80a3472c85462b6833	de-noising/noise cancellation mechanism for sampled speech/voice signal	signal sampling;speech processing;band pass filter bpf voice frequency vf mean power calculation mpc de nosing framing;speech noise cancellation noise reduction band pass filters testing communication systems;receivers;interference suppression;speech voice signal sampling noise cancellation mechanism denoising noise signals receiver voice communication system speech data signal speech data signal transmission adaptive noise cancellation algorithm mean power calculation speech frame;voice communication;voice communication interference suppression receivers signal sampling speech processing	In any communication system noise always had been a major area of concern. Noise signals affect the transmitted signals during transmission. Every signal that we acquire at the receiver end of any communication system is somehow affected by noise. Noise is the unwanted part of the signal. Signals can be of various types in communication systems depending upon the requirement of the system, like signals carrying information during transmission of voice or speech or image or video. Each of these signals get affected during transmission. So for de-noising of these signals of deferent types we need different noise cancellation mechanism. In this paper we have adopted a noise cancellation mechanism for signals carrying information in voice communication. In voice communication the recorded speech data signal transmitted will be useless until and unless proper noise cancellation mechanism is adopted at the receiver end. There are so many mechanisms for such noise cancellation. A lot of research work is going on to find a complete solution to this problem. In this paper, we have adopted a new adaptive noise cancellation algorithm. This algorithm, we have proposed is based on mean power calculation of the speech signal. The average power of each speech frame is calculated. Then those frames are accepted which exhibits average power above certain threshold level.	algorithm;image noise;noise (signal processing);video	Arnab Pramanik;Rajorshee Raha	2012	2012 Ninth International Conference on Wireless and Optical Communications Networks (WOCN)	10.1109/WOCN.2012.6331907	voice activity detection;gaussian noise;effective input noise temperature;noise;g.729;speech recognition;colors of noise;computer science;noise measurement;noise;multiplicative noise;speech processing;noise figure;noise floor;carrier-to-receiver noise density	Mobile	83.49590545475677	-33.004099098884694	55062
8317120acc35a5e8c1622f920ba091aa0f2cce04	directionality-based speech enhancement for hearing aids	microphones;directional sound;hearing aids;supervised learning;hearing aids directional sound multichannel speech enhancement;multichannel speech enhancement;speech;direction of arrival;array signal processing;noise suppression;speech enhancement;linear filtering;room impulse response;behind the ear;signal to noise ratio microphones speech mathematical model coherence equations;mathematical model;speech enhancement array signal processing direction of arrival estimation hearing aids signal denoising;coherence;noise floor tracking directionality based speech enhancement hearing aids sound energy directionality multichannel linear filter estimation single channel linear filter estimation diffuse noise suppression reverberation direction of arrival estimation beamformer post filter source interference;signal to noise ratio;conservation strategies;hearing aid;direction of arrival estimation;signal denoising	In this work we describe methods for using the directionality of sound energy as a criterion to estimate single- and multichannel linear filters for suppression of diffuse noise and reverberation in a hearing aid application. We compare conservative strategies where direction of arrival is unknown, and more aggressive strategies where the proposed methods can be used to derive a fast acting post-filter for the output of a beamformer. We show that in situations where a target of interest is near to the listener while interfering sources are more distant, simple features that capture the directionality of sound energy can be used to attenuate significant undesired signal energy and can be more effective than a strategy based on noise-floor tracking.	beamforming;direction of arrival;noise floor;simple features;speech enhancement;zero suppression	John Woodruff;DeLiang Wang	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5946399	speech recognition;coherence;computer science;speech;directional sound;machine learning;linear filter;mathematical model;supervised learning;signal-to-noise ratio;direction of arrival;statistics	Robotics	84.28962172702525	-34.14640656160852	55334
b06e2733f4762bbe316ad9d866b8926a57c4d0ed	human target localization algorithm using energy operator and doppler processing		In this letter, a localization algorithm, which combines energy operator with Doppler processing, is proposed for Doppler radar human sensing applications. For this algorithm, the energy operator is first used to extract the target components of interest from radar echoes and estimate their instantaneous frequencies (IFs). Then, on the basis of the IF estimation result, Doppler processing is applied to synthesize the target movement trajectories. Compared with the traditional localization methods, the proposed algorithm can more precisely estimate the target movement trajectory. Besides, it can further avoid the frequency ambiguity issue, and thus can be very promising for multitarget sensing applications. Experimental results are shown to demonstrate the performance of the proposed algorithm.	algorithm;direction of arrival;discrete system;energy operator;noise power;noise reduction;preprocessor;radar;real-time clock;sampling (signal processing)	Xiaoyi Lin;Yipeng Ding;Xuemei Xu;Kehui Sun	2018	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2018.2798926	mathematics;artificial intelligence;computer vision;ambiguity;doppler effect;time‚Äìfrequency analysis;radar;trajectory;algorithm;doppler radar;energy operator	Robotics	85.528106828467	-39.40294156257943	55897
8de3ebe50c4c22892de6ed20ad1d10ec3b1f8da0	signal processing theory and methods [in the spotlight]	game theory;signal detection;theory and method;adaptive signal processing;cognitive radio;signal processing;filtering theory	The scope of the IEEE Signal Processing Theory and Methods (SPTM) Technical Committee has a broad span, ranging from digital filtering and adaptive signal processing to statistical signal analysis, estimation, and detection. There have also been significant advances in the estimation of sparse systems. These areas continue to play a key role in classical and timely applications. This paper discusses about solving estimation and tracking problems over cognitive networks that requires optimizing certain global cost functions in a distributed manner.	dbpedia;signal processing	Abdelhak M. Zoubir;Vikram Krishnamurthy;Ali H. Sayed	2011	IEEE Signal Process. Mag.	10.1109/MSP.2011.941987	multidimensional signal processing;adaptive filter;game theory;computer vision;cognitive radio;space-time adaptive processing;computer science;theoretical computer science;digital signal processing;machine learning;signal processing;statistical signal processing;detection theory;signal	Vision	85.93222178480065	-43.94754180334638	56723
28e153bc081c414fd6c68452f19d35ee590e8e74	the geometry of sound-source localization using non-coplanar microphone arrays	geometry;microphone arrays;optimisation;direct path propagation model;geometric model;global optimization techniques;localization mapping;nonlinear multivariate optimization problem;shaped non-coplanar microphone arrays;sound-source localization;time delay estimation;sound source localization;constrained multivariate non-linear optimization;time delay estimate	This paper addresses the task of sound-source localization from time delay estimates using arbitrarily shaped non-coplanar microphone arrays. We fully exploit the direct path propagation model and our contribution is threefold: we provide a necessary and sufficient condition for a set of time delays to correspond to a sound source position, a proof of the uniqueness of this position, and a localization mapping to retrieve it. The time delay estimation task is casted into a non-linear multivariate optimization problem constrained by necessary and sufficient conditions on time delays. Two global optimization techniques to estimate time delays and localize the sound source are investigated. We report an extensive set of experiments and comparisons with state-of-the-art methods on simulated and real data in the presence of noise and reverberations.	broadcast delay;covox speech thing;experiment;global optimization;mathematical optimization;microphone;nonlinear system;optimization problem;software propagation	Xavier Alameda-Pineda;Radu Horaud;Bernard Mourrain	2013	2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics	10.1109/WASPAA.2013.6701849	mathematical optimization;electronic engineering;acoustics;mathematics;acoustic source localization	Robotics	85.6031004704558	-36.45664849584316	57202
1881b84c82db9512d3534d943b25daa82f8a0021	fundamental limitation of frequency domain blind source separation for convolutive mixture of speech	reverberation;transfer functions frequency domain analysis speech processing acoustic convolution transient response reverberation fast fourier transforms signal sampling jamming;transfer functions;signal sampling;blind source separation;frequency domain analysis;speech processing;sampling frequency;64 ms frequency domain convolutive speech mixture blind source separation bss acoustic signal separation performance impulse response length room impulse response frame size sampling frequency room reverberation jammer signals room transfer function inverse 8 khz 32 ms;jamming;room impulse response;transient response;acoustic convolution;transfer function;frequency domain analysis blind source separation speech source separation reverberation frequency estimation microphones jamming finite impulse response filter laboratories;fast fourier transforms;impulse response;frequency domain;convolutive mixture	Despite several recent proposals to achieve Blind Source Separation (BSS) for realistic acoustic signal, separation performance is still not enough. In particular, when the length of impulse response is long, performance is highly limited. In this paper, we show it is useless to be constrained by the condition, P T , where T is the frame size of FFT and P is the length of room impulse response. From our experiments, a frame size of 256 or 512 (32 or 64 ms at a sampling frequency of 8 kHz) is best even for the long room reverberation of TR = 150 and 300 ms. We also clari ed the reason for poor performance of BSS in long reverberant environment, nding that separation is achieved chie y for the sound from the direction of jammer because BSS cannot calculate the inverse of the room transfer function both for the target and jammer signals.	acoustic cryptanalysis;blind signal separation;experiment;fast fourier transform;sampling (signal processing);source separation;transfer function	Shoko Araki;Shoji Makino;Tsuyoki Nishikawa;Hiroshi Saruwatari	2001		10.1109/ICASSP.2001.940212	speech recognition;computer science;speech processing;mathematics;blind signal separation;transfer function;frequency domain	PL	84.90102550436028	-34.568218203501104	57447
e81e74b74ff950aa4f9631966c040bd3e13ea89b	robust constrained mfmvdr filtering for single-microphone speech enhancement		The multi-frame minimum variance distortionless response (MFMVDR) filter for single-microphone speech enhancement exploits speech correlation across consecutive time frames. This filter is designed to avoid speech distortion while minimizing the total signal output power. The MFMVDR filter is very sensitive to estimation errors in the speech correlation vector, since correlated speech components may be mistakenly suppressed. Inspired by robust beamforming approaches, in this paper we propose a robust constrained MFMVDR filter for single-microphone speech enhancement by estimating the speech correlation vector that maximizes the total signal output power within a spherical uncertainty set. For the upper bound of the spherical uncertainty set, we propose to use a trained mapping function that depends on the a-priori SNR. Experimental results for different noise types and SNRs show that the proposed robust approach achieves a more accurate estimate of the speech correlation vector resulting in low speech and noise distortion but a more conservative noise reduction.	beamforming;distortion;microphone;noise reduction;signal-to-noise ratio;speech enhancement	D√∂rte Fischer;Simon Doclo	2018	2018 16th International Workshop on Acoustic Signal Enhancement (IWAENC)	10.1109/IWAENC.2018.8521308	algorithm;filter (signal processing);noise measurement;noise reduction;speech enhancement;distortion;beamforming;microphone;signal-to-noise ratio;computer science	ML	84.0171185962984	-34.41089414351905	57685
a1e7a6976e286ad1cbd92938ebd6b72336eeeb70	beamforming array technique with clustered multichannel noise covariance matrix for mechanical noise reduction		In this paper, we propose a novel multichannel noise reduction method for a mechanical noise with a time-variant impulse response. The mechanical noise source location moves depending on the status of the actuator. In accordance with the move of the noise-source location, a most suitable multichannel beamformer is selected separately at each time-frequency bin. Each multichannel beamformer is made from a corresponding multichannel noise co-variance matrix which is learned in advance. The selection criteria in the proposed method is to minimize the residual noise power in the output signal. The multichannel beamformer that minimizes the residual power after beamforming is selected. Furthermore, to reduce directional noise sources, the multichannel directional noise covariance matrix is inserted into each multichannel mechanical noise covariance matrix. Experimental results of mechanical noise reduction show that the proposed method can reduce the mechanical noise more accurately than the conventional method.	beamforming;cluster analysis;digital camera;k-means clustering;noise generator;noise power;noise reduction;signal-to-noise ratio	Masahito Togami;Takashi Sumiyoshi;Yasunari Obuchi;Yohei Kawaguchi;Hiroaki Kokubo	2010	2010 18th European Signal Processing Conference		gradient noise;gaussian noise;image noise;noise;electronic engineering;speech recognition;acoustics;value noise;noise temperature;engineering;noise measurement;noise;noise;noise figure;noise floor;noise;salt-and-pepper noise	Robotics	84.10611109389504	-38.18040360612843	57903
cc7d6495d658668f9d2e591c555ce9f6af886cb4	sound mapping in reverberant rooms by a robust direct method	microphones;reverberation;optimisation;robust direct method;srp phat;point to point;source localization;optimization sound mapping reverberant rooms robust direct method acoustic source microphones generalized cross correlation srp phat;sound mapping;acoustic signal processing;generalized cross correlation;robustness reverberation direction of arrival estimation microphone arrays time difference of arrival signal to noise ratio sampling methods grid computing acoustic beams computational efficiency;microphone array;acoustic source;position estimation;optimization;microphone arrays;reverberant rooms;optimal algorithm;microphone arrays source localization reverberation;direct method;optimisation acoustic signal processing direction of arrival estimation;direction of arrival estimation	Direct methods estimate the position of an acoustic source by sampling the environment through a set of properly placed microphones. SRP-Phat is probably the most popular direct method. It is based on computation of the generalized cross- correlation (GCC) of signals on a grid of preselected points. Anyway, in the presence of reverberation, the functional employed by SRP-Phat can be very irregular from point to point, thus making the source localization a difficult task. In this paper, a new functional is presented that regularizes the SRP- Phat approach and makes it more efficient the use of optimization algorithms to further refine the source position estimation. After a brief introduction, the proposed approach is described and compared to SRP-Phat on simulated and real data at different reverberation levels.	acoustic cryptanalysis;algorithm;computation;direct method in the calculus of variations;mathematical optimization;microphone;scsi rdma protocol;sampling (signal processing)	Albenzio Cirillo;Raffaele Parisi;Aurelio Uncini	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4517602	direct method;speech recognition;reverberation;point-to-point	Robotics	85.56739808022876	-36.41785055050888	57964
4edec21b922ce787b24a598bf9c125b8b0e16cd5	impulsive noise suppression in the case of frequency estimation by exploring signal sparsity	missing measurements;frequency estimation;sparsity;impulsive noise;speech denoising;joint estimation	The frequency estimation problem is addressed in this work in the presence of impulsive noise. Two typical scenarios are considered; that is, the received data are assumed to be uniformly sampled, i.e., without data missing for the first case and data are randomly missed for the second case. The main objective of this work is to explore the signal sparsity in the frequency domain to perform frequency estimation under the impulsive noise. Therefore, to that end, a DFT-like matrix is created in which the frequency sparsity is provided. The missing measurements are modeled by a sparse representation as well, where missing samples are set to be zeros. Based on this model, the missing pattern represented by a vector is indeed sparse since it only contains zeros and ones. The impulsive noise is remodeled as a superposition of a unknown sparse vector and a Gaussian vector because of the impulsive nature of noise. By utilizing the sparse property of the vector, the impulsive noise can be treated as a unknown parameter and hence it can be canceled efficiently. By exploring the sparsity obtained, therefore, a joint estimation method is devised under optimization framework. It renders one to simultaneously estimate the frequency, noise, and the missing pattern. Numerical studies and an application to speech denoising indicate that the joint estimation method always offers precise and consistent performance when compared to the non-joint estimation approach.	sparse matrix;spectral density estimation;zero suppression	Hongqing Liu;Yong Li;Yi Zhou;Hsin-Chiu Chang;Trieu-Kien Truong	2016	Digital Signal Processing	10.1016/j.dsp.2016.06.012	machine learning;pattern recognition;mathematics;sparsity-of-effects principle;statistics	ML	83.3249725273596	-36.63165110043928	58026
50a8e0a2a461ea14e7462a21ec304a2bee5cf6aa	cocktails, but no party: multipath-enabled private audio		We describe a private audio messaging system that uses echoes to unscramble messages at a few predetermined locations in a room. The system works by splitting the audio into short chunks and emitting them from different loudspeakers. The chunks are filtered so that as they echo around the room, they sum to noise everywhere except at a few chosen focusing spots where they exactly reproduce the intended messages. Unlike in the case of standard personal audio zones, the proposed method renders sound outside the focusing spots unintelligible. Our method essentially depends on echoes: the room acts as a mixing system such that at given points we get the desired output. Finally, we only require a modest number of loudspeakers and only a few impulse response measurements at points where the messages should be delivered. We demonstrate the effectiveness of the proposed method via objective quantitative metrics as well as informal listening experiments in a real room.	experiment;inter-process communication;loudspeaker;mixing (mathematics);multipath propagation;rendering (computer graphics);scrambler	Yu-Jeh Liu;Jonah Casebeer;Ivan Dokmanic	2018	2018 16th International Workshop on Acoustic Signal Enhancement (IWAENC)	10.1109/IWAENC.2018.8521292	multipath propagation;speech recognition;computer science;loudspeaker;impulse response;active listening;coherence (physics);intelligibility (communication);secure communication	AI	85.73907491351663	-34.6054566049001	58823
53fe438753065898f3597d8ba819f92064165a08	an adaptive microphone array for optimum beamforming and noise reduction	noise estimation;matrix inversion;iterative algorithm;microphone array;noise reduction;correlation matrix;adaptive beamforming	We present a new adaptive microphone array efficiently implemented as a multi-channel FFT-filterbank. The array design is based on a minimum variance distortionless response (MVDR) optimization criterion. MVDR beamformer weights are updated for each signal frame using an estimated spatio-spectral correlation matrix of the environmental noise field. We avoid matrix inversion by means of an iterative algorithm for weight vector computation. The beamformer performance is superior to designs based on an assumed homogeneous diffuse noise field. The new design also outperforms LMS-adaptive beamformers at the expense of a higher computational load. Additional noise reduction is achieved with the well-known beamformer/postfilter combination of the optimum multi-channel filter. An Ephraim-Malah spectral amplitude modification with minimum statistics noise estimation is employed as a postfilter. Experimental results are presented using sound recordings in a reverberant noisy room.	algorithm;beamforming;computation;fast fourier transform;filter bank;iterative method;mathematical optimization;microphone;noise reduction;whole earth 'lectronic link	Gerhard Doblinger	2006	2006 14th European Signal Processing Conference		electronic engineering;speech recognition;acoustics;adaptive beamformer;mathematics	EDA	84.05597691416857	-35.986155520952956	59880
7ed0e3065ea54444dd828c5d454b03c01e655686	underdetermined sparse source separation of convolutive mixtures with observation vector clustering	frequency dependence;speech separation;sensor phenomena and characterization;information science;convolution;blind source separation;frequency domain analysis;speech processing;speech;array signal processing;independent component analysis;source separation sensor arrays independent component analysis speech sensor phenomena and characterization calibration frequency domain analysis time frequency analysis information science frequency dependence;speech processing array signal processing blind source separation convolution;nonlinear sensor arrangements;underdetermined sparse signal separation;linear sensor array;convolutive mixtures;sensor array;120 ms underdetermined sparse source separation convolutive mixtures observation vector clustering underdetermined sparse signal separation linear sensor array speech separation nonlinear sensor arrangements nonuniform sensor arrangements;source separation;convolutive mixture;observation vector clustering;time frequency analysis;calibration;sensor arrays;underdetermined sparse source separation;120 ms;nonuniform sensor arrangements	We propose a new method for solving the underdetermined sparse signal separation problem. Some sparseness based methods have already been proposed. However, most of these methods utilized a linear sensor array (or only two sensors), and therefore they have certain limitations; e.g., they cannot separate symmetrically positioned sources. To allow the use of more than three sensors that can be arranged in a non-linear/non-uniform way, we propose a new method that includes the normalization and clustering of the observation vectors. Our proposed method can handle both underdetermined case and (over-)determined cases. We show practical results for speech separation with non-linear/non-uniform sensor arrangements. We obtained promising experimental results for the cases of 3 times 4, 4 times 5 (#sensors times #sources) in a room (RT60= 120 ms)	cluster analysis;database normalization;image sensor;neural coding;nonlinear system;source separation;sparse matrix	Shoko Araki;Hiroshi Sawada;Ryo Mukai;Shoji Makino	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1693404	independent component analysis;calibration;speech recognition;time‚Äìfrequency analysis;information science;computer science;speech;machine learning;pattern recognition;speech processing;blind signal separation;convolution;frequency domain;sensor array	Embedded	84.03849102561264	-37.13567726496604	60068
7df524ab60d1733cfc8bf8e75475d49c9f105dc8	comparison between dft-, fct-, wavelet-, and lattice filter-based noise reduction for asr	discrete wavelet transforms;recognition performance dft fct lattice filter based noise reduction speech signals automatic speech recognition noise reduction algorithms asr performance frequency domain based algorithms discrete fourier transform fast chirp transform discrete wavelet transform dwt lattice filter based algorithm wer noise free data;noise speech recognition discrete wavelet transforms discrete fourier transforms noise reduction signal processing algorithms;dwt;discrete wavelet transform;noise reduction algorithms;recognition performance;asr performance;frequency domain analysis;lattice filter based algorithm;speech recognition discrete fourier transforms discrete wavelet transforms frequency domain analysis interference suppression lattice filters;interference suppression;automatic speech recognition;fast chirp transform;lattice filters;frequency domain based algorithms;noise reduction;speech signals;discrete fourier transform;wer;speech recognition;signal processing algorithms;frequency domain;fct;discrete fourier transforms;noise free data;dft;lattice filter based noise reduction;noise	We investigate noise reduction (NR) for speech signals for automatic speech recognition (ASR). We compare four transform based noise reduction algorithms according to their influence on ASR performance. These include frequency domain based algorithms using the discrete Fourier transform (DFT), the fast chirp transform (FCT), and the discrete wavelet transform (DWT), as well as a lattice filter based algorithm. Ten different types of noise with different characteristics are used, covering a broad range from almost stationary to highly non-stationary conditions. For single speakers, on average over the different noise types, a reduction of WER of up to 5.5% is possible. The DFT, DWT, and the lattice filter based algorithms lead to an improvement up to 2% relative WER on average over all speakers and noise types. Moreover, the application of the lattice filter based algorithm to recognition of noise-free data does not cause any degradation in the recognition performance. Hence the lattice filter based NR algorithm has a potential application in the real-life ASR systems.	algorithm;automated system recovery;chirp;discrete fourier transform;discrete wavelet transform;elegant degradation;international symposium on fundamentals of computation theory;lattice phase equaliser;noise reduction;real life;speech recognition;stationary process;word error rate	Erhard Rank;Amar Al-Khayat;Tuan Van Pham;Zsolt Saffer;Michael Stark	2010	2010 IEEE RIVF International Conference on Computing & Communication Technologies, Research, Innovation, and Vision for the Future (RIVF)	10.1109/RIVF.2010.5633588	electronic engineering;speech recognition;acoustics;mathematics	EDA	83.13104163089257	-33.42100565058236	60174
a007805ba7a252faf7572d7e2d834cf4b395d9a3	noisy blind signal-jamming separation algorithm based on vbica	blind source separation;variational bayesian;noisy mixture;blind signal jamming separation;mog	Aiming at the blind signal-jamming separation (BSJS) in wireless communication environment, we propose a noisy BSJS based on Variational Bayesian Independent Component Analysis algorithm to separate the communication signal from jamming signals and noises. This algorithm takes the Kullback‚ÄìLeibler divergence between the true post distributions of source signals and the approximate ones as objective function, models sources using mixture of Gaussians, and updates parameters of the model using variational-Bayesian learning method, so as to make the estimated approximate posterior distributions close to the true ones and recover source communication signals finally. The simulation results show that the proposed algorithm is effective for the BSJS in noisy environment.	approximation algorithm;calculus of variations;independent computing architecture;independent component analysis;kullback‚Äìleibler divergence;loss function;mixture model;optimization problem;radio jamming;signal-to-noise ratio;simulation;variational principle	Yu-ling Duan;Hang Zhang	2014	Wireless Personal Communications	10.1007/s11277-013-1286-6	computer science;machine learning;pattern recognition;mathematics;blind signal separation;statistics	ML	83.06810061111929	-36.58986913024445	60270
e0d7b693d3db1dbbc81b1fc757bfe2074de62dcb	speech enhancement based conceptually on auditory evidence	white noise interference suppression speech analysis and processing;speech enhancement signal to noise ratio noise reduction noise level noise cancellation degradation military computing military aircraft signal processing additive white noise;quantization noise;prior knowledge;speech enhancement;interference suppression;speech enhancement stationary additive white noise quantising noise auditory evidence nonstationary additive white noise light noise interference signal to noise ratio snr noisy speech speech quality;speech analysis and processing;signal to noise ratio;white noise	A new idea, enhancing speech based on auditory evidence, is explored for the problem of enhancing speech degraded by stationary and nonstationary additive white noise. Distinguishing different objectives for heavy and light noise interference, two related algorithms are developed. For speech degraded by heavy noise, the improvement in signal-to-noise ratio (SNR) is as high as 12 dB; for lightly noisy speech, the improvement is modest and decreases as the SNR of the noisy speech increases. Quantizing noise is used to assess the capacity for reducing nonstationary noise using these algorithms; a significant reduction of such noise and an improvement in speech quality are achieved. The advantages of the proposed algorithms for speech enhancement include no need for prior knowledge of the noise and only a modest computational requirement. >	speech enhancement	Yan Ming Cheng;Douglas D. O'Shaughnessy	1991	IEEE Trans. Signal Processing	10.1109/78.134427	gaussian noise;speech recognition;colors of noise;quantization;computer science;noise measurement;noise;mathematics;white noise;noise floor;signal-to-noise ratio;noise;statistics;salt-and-pepper noise	Embedded	83.25720089304728	-33.494751429212386	60505
27cb3ce32930c37b5b53edb77f2c5871324e1a2e	a modal approach to soundfield reproduction in reverberant rooms	keywords loudspeakers;reverberation;filtering;transfer functions;acoustics;filters;atf parametrization;acoustic signal processing;sound reproduction;acoustic field;loudspeakers filters filtering frequency response least squares methods acoustic waves;loudspeaker reproduction region atf;conference paper;frequency response;loudspeakers;transfer function;sfr;reverberant enclosures;acoustic transfer function atf;acoustic transfer function;acoustic waves;parameter estimation;reverberant rooms;loudspeaker reproduction region atf reverberant enclosures soundfield reproduction reverberant rooms sfr reverberant acoustic environments acoustic transfer function atf parametrization;acoustic field reverberation sound reproduction acoustic signal processing transfer functions;reverberant acoustic environments;least squares methods;soundfield reproduction;soundfield reproduction sfr	In this paper, we present a novel method of soundfield reproduction (SFR) for reverberant acoustic environments. Using an efficient parametrization of the acoustic transfer function (ATF) over a region of space, we devise a method for accurate SFR over the whole of the reproduction region. This method is based on a practical method of determining the ATF between each loudspeaker and the reproduction region.	acoustic cryptanalysis;loudspeaker;modal logic;transfer function	Terence Betlehem;Thushara Dheemantha Abhayapala	2005	Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.	10.1109/ICASSP.2005.1415703	speech recognition;transfer function	Visualization	86.44109050072103	-34.29810735461253	61185
7de01050ac62d23c3c3c8337fd502cca748ac609	design of charge-balanced time-optimal stimuli for spiking neuron oscillators		In this letter, we investigate the fundamental limits on how the interspike time of a neuron oscillator can be perturbed by the application of a bounded external control input (a current stimulus) with zero net electric charge accumulation. We use phase models to study the dynamics of neurons and derive charge-balanced controls that achieve the minimum and maximum interspike times for a given bound on the control amplitude. Our derivation is valid for any arbitrary shape of the phase response curve and for any value of the given control amplitude bound. In addition, we characterize the change in the structures of the charge-balanced time-optimal controls with the allowable control amplitude. We demonstrate the applicability of the derived optimal control laws by applying them to mathematically ideal and experimentally observed neuron phase models, including the widely studied Hodgkin-Huxley phase model, and by verifying them with the corresponding original full state-space models. This work addresses a fundamental problem in the field of neural control and provides a theoretical investigation to the optimal control of oscillatory systems.	addresses (publication format);arabic numeral 0;derivation procedure;ephrin type-b receptor 1, human;experiment;hodgkin‚Äìhuxley model;huxley: the dystopia;neuron;optimal control;oscillator device component;state space;tree accumulation;verification and validation;verifying specimen	Isuru Dasanayake;Jr-Shin Li	2014	Neural Computation	10.1162/NECO_a_00643	control theory;mathematics	ML	83.31618069911596	-26.229687919913964	61866
aa056dec644dc7132ed81bbbe919df3474c2eb53	60co gamma radiation total ionizing dose combined with conducted electromagnetic interference studies in bjts			interference (communication)	Olarewaju Mubashiru Lawal;Shuhuan Liu;Zhuoqi Li;Aqil Hussain	2018	Microelectronics Reliability	10.1016/j.microrel.2018.01.020		SE	94.50356996401084	-24.35157298288432	63657
76e2c92e5b39691477595822c41eed27c94609c6	measurement of acoustic impedance density distribution in the near field of the labial horn	near field		acoustic cryptanalysis;characteristic impedance;near field communication	Kunitoshi Motoki;Pierre Badin;Nobuhiro Miki	1994			speech recognition;acoustics;computer science;acoustic impedance;near and far field	NLP	88.04709078174625	-28.643699242651408	63807
0a5bcc4f494307a2d04b20ae24ae7456bd4d3998	unified auditory functions based on bayesian topic model	microphones;robot sensing systems;reverberation;intelligent robots;signal sampling;bayes methods;acoustic generators;time frequency analysis vectors microphones robot sensing systems arrays;acoustic signal processing;failure analysis;arrays;iterative methods;source separation acoustic generators acoustic signal processing bayes methods failure analysis intelligent robots iterative methods reverberation signal sampling;vectors;source separation;time frequency analysis;robot audition system bayesian topic model based unified auditory functions robots auditory functions sound source localization cascaded framework subsystem failure environment dependent tuning iterative inference gibbs sampling reverberation times sound source separation methods reverberant environments	Existing auditory functions for robots such as sound source localization and separation have been implemented in a cascaded framework whose overall performance may be degraded by any failure in its subsystems. These approaches often require a careful and environment-dependent tuning for each subsystems to achieve better performance. This paper presents a unified framework for sound source localization and separation where the whole system is integrated as a Bayesian topic model. This method improves both localization and separation with a common configuration under various environments by iterative inference using Gibbs sampling. Experimental results from three environments of different reverberation times confirm that our method outperforms state-of-the-art sound source separation methods, especially in the reverberant environments, and shows localization performance comparable to that of the existing robot audition system.	covox speech thing;generative model;gibbs sampling;iterative method;robot;sampling (signal processing);source separation;topic model;unified framework	Takuma Otsuka;Katsuhiko Ishiguro;Hiroshi Sawada;Hiroshi G. Okuno	2012	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2012.6385787	failure analysis;speech recognition;time‚Äìfrequency analysis;acoustics;reverberation;engineering;iterative method	Robotics	84.77828341066201	-37.26720838715754	64071
8286e56ec81851c8bc13b530ca463f9b5965dd44	a hybrid algorithm for multiple parameters estimation with uca of electromagnetic vector sensors	azimuth;multiple signal classification;electromagnetics;signal processing algorithms;sensor arrays;direction of arrival estimation	In order to avoid the multi-dimensional spectrum peak search for multiple parameters estimation, a hybrid algorithm with uniform circular array (UCA) of electromagnetic vector sensors based on the beamspace transformation is proposed. In the beamspace, the azimuth angle can be split from other parameters and can be estimated without using spectral peak search. Then, the elevation estimation can be obtained with the estimated azimuth angle via a one-dimensional spectrum peak search. Finally, the polarized parameters are obtained based on the estimated azimuth and elevation angle via the engine decomposition with the modulus constraint. Its computation complexity is superior to the one of the tradition MUSIC and the existing reduced-dimensional algorithm.	computation;direction of arrival;estimation theory;hybrid algorithm;modulus robot;polarization (waves);sensor;unicode collation algorithm	Julan Xie;Xue Yang;Huiyong Li;Jinfeng Hu	2016	2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)	10.1109/APSIPA.2016.7820858	mathematical optimization;electronic engineering;speech recognition;engineering	Robotics	85.61156048508867	-38.20823032845616	64338
00fc4c049ec5d8a98ecd8246bf61fd94d45e4362	direction estimation based on sound intensity vectors	microphones;azimuth;cross correlation;time delay estimation;additive noise;model performance;arrays;estimation vectors microphones signal to noise ratio azimuth arrays;vectors;estimation;microphone array;signal processing;additive noise direction estimation sound intensity vector convolutive mixture model simple averaging method;signal to noise ratio;convolutive mixture;mixture models acoustic convolution acoustic intensity;averaging method	The direction of a sound source in an enclosure can be estimated with a microphone array and some proper signal processing. Earlier, in applications and in research the use of time delay estimation methods, such as the cross correlation, has been popular. Recently, techniques for direction estimation that involve sound intensity vectors have been developed and used in applications, e.g. in teleconferencing. Unlike in time delay estimation, these methods have not been compared widely. In this article, five methods for direction estimation in the concept of sound intensity vectors are compared with real data from a concert hall. The results of the comparison indicate that the methods that are based on convolutive mixture models perform slightly better than some of the simple averaging methods. The convolutive mixture model based methods are also more robust against additive noise.	academy;additive white gaussian noise;british undergraduate degree classification;broadcast delay;computer engineering;covox speech thing;cross-correlation;first-class function;microphone;mixture model;motion estimation;signal processing;utility functions on indivisible goods	Sakari Tervo	2009	2009 17th European Signal Processing Conference		electronic engineering;speech recognition;acoustics;mathematics	HPC	86.3457937267024	-37.126698199518344	64551
75ba2fe741553075aef389c82ffa403d88bb9cf9	3d localization of multiple audio sources utilizing 2d doa histograms	histograms;two dimensional displays;multiple signal classification;microphone arrays;direction of arrival estimation;harmonic analysis	Steered response power (SRP) techniques have been well appreciated for their robustness and accuracy in estimating the direction of arrival (DOA) when a single source is active. However, by increasing the number of sources, the complexity of the resulting power map increases, making it challenging to localize the separate sources. In this work, we propose an efficient 2D histogram processing approach which is applied on the local DOA estimates, provided by SRP, and reveals the DOA of multiple audio sources in an iterative fashion. Driven by the results, we also apply the same methodology to local DOA estimates of a known subspace method and improve its accuracy. The performance of the presented algorithms is validated with numerical simulations and real measurements with a rigid spherical microphone array in different acoustical conditions: for multiple audio sources with different angular separations, various reverberation and signal-to-noise ratio (SNR) values.	algorithm;angularjs;apache axis;beamforming;direction of arrival;iterative method;microphone;numerical analysis;signal-to-noise ratio;simulation;v-optimal histograms	Symeon Delikaris-Manias;Despoina Pavlidi;Ville Pulkki;Athanasios Mouchtaris	2016	2016 24th European Signal Processing Conference (EUSIPCO)	10.1109/EUSIPCO.2016.7760493	electronic engineering;speech recognition;acoustics;mathematics	Vision	85.27968638732567	-36.63078634061399	64877
c7f82ec6bf816adf0166aba4b32244d69a7703a8	special issue on co-prime sampling and arrays		Co-prime sampling and co-prime arrays have recently been shown to improve active and passive sensing in radar and underwater acoustics using both narrowband and wideband signal platforms. Co-prime processing provides a systematical framework for sparse sampling and array configuration with increased aperture and improved spatial resolution. Co-prime based approaches to sampling and arrays can combat ambiguity and provide unique answers to target coordinates under forced coarse sampling in time, frequency, and space. Temporal and spatial co-prime samplings make advances in direction-of-arrival (DOA) estimation, spectrum sensing, and sparse covariance sketching. They find broad applications in synthetic aperture radar (SAR), radio frequency (RF) surveillance, target localization, wideband urban radar processing, space‚Äìtime adaptive processing, and nonstationary array processing utilizing Doppler signatures and instantaneous frequency source characteristics. The goal of the Special Issue is to publish the most recent results in signal processing using co-prime sampling and arrays. Review papers on this topic are also welcome. Topics to be covered in this Special Issue include but are not limited to:	antivirus software;array processing;direction of arrival;instantaneous phase;radar;radio frequency;sampling (signal processing);signal processing;space-time adaptive processing;sparse matrix;synthetic data	Moeness G. Amin;Palghat P. Vaidyanathan;Yimin Zhang;Piya Pal	2015	Digital Signal Processing	10.1016/j.dsp.2015.07.007	telecommunications	Visualization	85.9252886550601	-43.98738296636987	65576
afeb178d2744218e20b889d6677e1c66a248892a	identification of active sources in single-channel convolutive mixtures using known source models	microphones;convolution;speech processing;hidden markov models vectors computational modeling speech source separation mathematical model microphones;signal detection;student s t mixture models tmms latent variable approach multiple source identification single channel;stochastic processes convolution microphones signal detection speech processing;time 250 ms active source identification single channel convolutive mixtures source models single sensor mixture signal analysis latent variable approach stochastic models source signal detection mixture speech data reverberant enclosure single microphone source to interference ratio sir;stochastic processes;electrical communication engineering	We address the problem of identifying the constituent sources in a single-sensor mixture signal consisting of contributions from multiple simultaneously active sources. We propose a generic framework for mixture signal analysis based on a latent variable approach. The basic idea of the approach is to detect known sources represented as stochastic models, in a single-channel mixture signal without performing signal separation. A given mixture signal is modeled as a convex combination of known source models and the weights of the models are estimated using the mixture signal. We show experimentally that these weights indicate the presence/absence of the respective sources. The performance of the proposed approach is illustrated through mixture speech data in a reverberant enclosure. For the task of identifying the constituent speakers using data from a single microphone, the proposed approach is able to identify the dominant source with up to 8 simultaneously active background sources in a room with RT60= 250 ms, using models obtained from clean speech data for a Source to Interference Ratio (SIR) greater than 2 dB.	computable function;expectation‚Äìmaximization algorithm;experiment;interference (communication);latent variable;microphone;open-source software;resilient packet ring;sensor;signal processing;sparse matrix;stochastic process	Sundar Harshavardhan;Thippur V. Sreenivas;Walter Kellermann	2013	IEEE Signal Processing Letters	10.1109/LSP.2012.2236314	speech recognition;computer science;machine learning;speech processing;mathematics;convolution;statistics;detection theory	ML	82.97392727571743	-36.674056970616675	65580
1842e44ea747845d96d9b7bb96367df67ae69a32	efficient low delay filtering for residual echo suppression	speech;finite impulse response filters;loudspeakers;echo cancellation echo postfiltering linear echo non linear echo sub band filtering fir filter;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;speech delays finite impulse response filters noise echo cancellers loudspeakers;echo cancellers;time domain analysis acoustic signal processing computational complexity convolution delay filters discrete fourier transforms echo suppression inverse transforms speech processing telecommunication terminals;gain loss control low delay filtering telecommunication terminal speech quality acoustic echo suppression adaptive echo cancellation inverse discrete fourier transform time domain convolution;delays;noise;fir filter echo cancellation echo postfiltering linear echo non linear echo sub band filtering	In telecommunications terminals speech quality is often degraded by acoustic echo. Various approaches to echo cancellation have been proposed and generally involve two separate stages, namely those of adaptive echo cancellation and, as is the focus here, residual echo suppression. Whilst computationally efficient, residual echo suppression approaches based on gain loss control have poor double talk performance. Sub-band approaches give better performance but generally introduce a significant signal delay. This paper reports new experimental work which assesses the performance of three low delay approaches to suppress residual echo through time domain convolution. Results show that a new approach, based on the inverse discrete Fourier transform, performs as well as the existing approaches for both linear and non-linear echo whilst maintaining computational efficiency and low signal delay.	acoustic cryptanalysis;algorithmic efficiency;computation;convolution;discrete fourier transform;echo suppression and cancellation;nonlinear system;while;zero suppression	Christelle Yemdji;Moctar Mossi Idrissa;Nicholas W. D. Evans;Christophe Beaugeant	2010	2010 18th European Signal Processing Conference	10.5281/zenodo.41890	electronic engineering;speech recognition;acoustics;computer science	EDA	83.78322337826239	-33.102049672939195	65716
b0ea372b1d9d4abe355525b438720da1a87f3385	spectral density estimation of ship-generated underwater acoustic noise	senses;ship noise;sensors networks;embedded systems;wsns;underwater sensor networks;underwater acoustic noise;spectral estimation;senses lab	We propose a technique to jointly characterize the power spectral density of the noise produced by a ship and the nominal sound propagation parameters (attenuation exponent and absorption coefficient) for each frequency value, over an area of interest. The technique uses a set of properly displaced recording stations and AIS data. Our preliminary results show the effectiveness of the proposed technique.	acoustic cryptanalysis;coefficient;noise power;propagation constant;slater-type orbital;software propagation;spectral density estimation	Loreto Pescosolido;Chiara Petrioli;Luigi Picari;Jo√£o Alves	2014		10.1145/2671490.2674597	underwater acoustic communication;electronic engineering;acoustics;telecommunications;engineering	EDA	85.08726877293283	-38.302311177647155	66052
00f80508cce1b9bb564154427e92f9d2754de4bb	kalman filtering for low distortion speech enhancement in mobile communication	background noise;kalman filtering;filtering;elektroteknik och elektronik;speech parameter estimation algorithm;colored noise;10 db;electrical engineering electronic engineering information engineering;speech processing;performance;kalman filters;signalbehandling;additive noise;model based approach;kalman filter;acoustic signal processing;noise suppression;speech enhancement;acoustic filters;interference suppression;land mobile radio;signal processing;acoustic noise;mobile communication;low distortion speech enhancement;10 db low distortion speech enhancement mobile communication kalman filtering model based approach noise suppression additive noise performance speech parameter estimation algorithm total audible quality;parameter estimation;kalman filters filtering speech enhancement mobile communication acoustic noise colored noise speech processing parameter estimation signal processing background noise;acoustic filters speech enhancement parameter estimation kalman filters acoustic noise interference suppression acoustic signal processing land mobile radio;total audible quality	This paper presents a model-based approach for noise suppression of speech contaminated by additive noise. A Kalman lter based speech enhancement system is presented and its performance is investigated in detail. It is shown that with a novel speech parameter estimation algorithm, it is possible to achieve 10dB noise suppression with a high total audible quality.	additive white gaussian noise;algorithm;distortion;estimation theory;kalman filter;mobile phone;speech enhancement;utility functions on indivisible goods;zero suppression	Patrick S√∂rqvist;Peter H√§ndel;Bj√∂rn E. Ottersten	1997		10.1109/ICASSP.1997.596164	kalman filter;speech recognition;computer science;signal processing;speech processing;statistics	Robotics	83.33173745493416	-33.290170952576176	66221
9ee9255c82c90d0ff915c330e1ed985f7ded5a4a	a binaural system for the suppression of late reverberation	microphones;coherence reverberation speech signal processing algorithms microphones speech recognition noise;reverberation;binaural system automatic speech recognition noise reduction snr signal to noise ratio microphone spatial decorrelation late reverberation suppression;speech;short time fourier transform speech dereverberation front end for hearing aids;speech recognition;coherence;speech recognition noise abatement reverberation;signal processing algorithms;noise	The propriety of spatial decorrelation of late reverberation has often been used in binaural systems of dereverberation [1] [2]. However, the use of a small array of two microphones limits the performance of such systems, especially at low frequencies. We present in this paper a new algorithm, derived from the classical method proposed by Bloom et al. [2] [3]. Both methods are assessed in terms of gain in signal to noise ratio (SNR), noise reduction, distortion and improvement in performances of automatic speech recognition. The proposed method leads to better noise reduction and consistent improvement in speech recognition scores.	algorithm;binaural beats;bloom filter;decorrelation;distortion;microphone;noise reduction;performance;signal-to-noise ratio;speech recognition;zero suppression	Katia Lebart;Jean-Marc Boucher;P. N. Denbigh	1998	9th European Signal Processing Conference (EUSIPCO 1998)		speech recognition;acoustics;speech processing;communication	ML	83.2478719849117	-33.93657727327656	66693
23ee9e91a8da200fe67709d33d333c1e5b2ebf7d	multiple-microphone time-varying filters for robust speech recognition	microphones;reverberation;robust speech recognition;time varying;reverberation time;digit recognition;microphone location;information filtering;delay effects;array signal processing;speech enhancement;speech source location;robustness speech recognition array signal processing microphones speech enhancement delay effects information filtering information filters noise reduction reverberation;superdirective beamforming;noise reduction;filtering theory speech enhancement speech recognition microphones array signal processing time varying filters;speech recognition;robustness;time varying filters;delay and sum;digit recognition time varying filters robust speech recognition microphone location speech enhancement noise reduction speech source location superdirective beamforming delay and sum beamforming;information filters;delay and sum beamforming;filtering theory	A multiple microphone time varying filter that is an extension of the dual-microphone speech enhancement technique of P. Aarabi et al. (see Proceedings of the IEEE Conference on Multimedia and Expo, Baltimore, Maryland, July 2003) is proposed and experimentally analyzed. The technique utilizes information regarding the locations of the speech source of interest and the microphones to compute a time varying filter that results in substantial noise reduction over other speech enhancement techniques such as delay-and-sum beamforming and superdirective beamforming. For example, digit recognition results in an environment with two speakers and a reverberation time of 0.1s show a recognition accuracy rate increase of 25.2% over delay-and-sum beamforming and an increase of 26.5% over superdirective beamforming using six microphones.	beamforming;experiment;microphone;noise reduction;proceedings of the ieee;speech enhancement;speech recognition	Calvin Yiu-Kit Lai;Parham Aarabi	2004	2004 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2004.1325965	computer vision;speech recognition;reverberation;computer science;noise reduction;robustness	Robotics	83.81164797208478	-33.934115833773596	66890
5400ba8a49e985ce6a5faab7b6393d3bcdae5357	speaker localization using direct path dominance test based on sound field directivity		Abstract Estimation of the direction-of-arrival (DoA) of a speaker in a room is important in many audio signal processing applications. Environments with reverberation that masks the DoA information are particularly challenging. Recently, a DoA estimation method that is robust to reverberation has been developed. This method identifies time-frequency bins dominated by the contribution from the direct path, which carries the correct DoA information. However, its implementation is computationally demanding as it requires frequency smoothing to overcome the effect of coherent early reflections and matrix decomposition to apply the direct-path dominance (DPD) test. In this work, a novel computationally-efficient alternative to the DPD test is proposed, based on the directivity measure for sensor arrays, which requires neither frequency smoothing nor matrix decomposition, and which has been reformulated for sound field directivity with spherical microphone arrays. The paper presents the proposed method and a comparison to previous methods under a range of reverberation and noise conditions. Result demonstrate that the proposed method shows comparable performance to the original method in terms of robustness to reverberation and noise, and is about four times more computationally efficient for the given experiment.		Boaz Rafaely;Koby Alhaiany	2018	Signal Processing	10.1016/j.sigpro.2017.08.010	robustness (computer science);directivity;control theory;mathematics;smoothing;audio signal processing;microphone;matrix decomposition;reverberation;electronic engineering	Robotics	84.42864418069101	-36.12940901059995	67023
999dc6fe906fca5eafa7f615fd4f1c5dd0b8be45	an evaluation of an adaptive multichannel system for speech enhancement with automatic phase alignment	adaptive filters speech enhancement acoustic noise spectral analysis wiener filters;frequency domain algorithm;degradation;filter output;working environment noise;speech analysis;frequency estimation;adaptive systems speech analysis speech enhancement acoustic noise phased arrays microphone arrays wiener filter degradation frequency estimation working environment noise;adaptive multichannel system;spectral densities of speech;wiener filters;speech enhancement;spectral density;intelligibility adaptive multichannel system speech enhancement automatic phase alignment environment acoustic noise estimation spectral densities of speech wiener filter frequency domain algorithm filter output signal to noise ratio informal subjective listening tests signal quality;automatic phase alignment;adaptive filters;estimation;adaptive systems;microphone array;acoustic noise;environment acoustic noise;informal subjective listening tests;wiener filter;microphone arrays;spectral analysis;signal to noise ratio;frequency domain;intelligibility;signal quality;phased arrays	This paper presents an evaluation of an adaptive multichannel system to enhancement of speech degraded by environment acoustic noise. The system input is a four microphone array connected to an automatic phase alignment unit which gives a gain of 2 to 4 dB. An estimation has been made of the spectral densities of speech and noise to be used as input to a Wiener filter, the coefficients of which are computed by a frequency domain algorithm. The signal estimated on filter output presents a total gain in the signal-to-noise ratio of about 10 dB. Informal subjective listening tests indicates an improvement in the signal quality and its intelligibility is considered very good.	speech enhancement	Silvana Cunha Costa;Benedito G. Aguiar Neto	1995		10.1109/ICASSP.1995.479826	adaptive filter;estimation;speech recognition;degradation;computer science;adaptive system;noise;mathematics;wiener filter;signal-to-noise ratio;spectral density;intelligibility;frequency domain;statistics	NLP	83.20809796798186	-34.099604225135394	67087
a4954663b59ada551f97fef6f79158059ea11805	using a planar array of mems microphones to obtain acoustic images of a fan matrix		This paper proposes the use of a signal acquisition and processing system based on an 8 √ó 8 planar array of MEMS (Microelectromechanical Systems) microphones to obtain acoustic images of a fan matrix. A 3 √ó 3 matrix of PC fans has been implemented to perform the study. Some tests to obtain the acoustic images of the individual fans and of the wholematrix have been defined and have been carried out inside an anechoic chamber.The nonstationary signals received by eachMEMSmicrophone and their corresponding spectra have been analyzed, as well as the corresponding acoustic images. The analysis of the acoustic signals spectra reveals the resonance frequency of the individual fans. The obtained results reveal the feasibility of the proposed system to obtained acoustic images of a fan matrix and of its individual fans, in this last case, in order to estimate the real position of the fan inside the matrix.	acoustic cryptanalysis;acoustic fingerprint;delimiter;fan-in;machine learning;microelectromechanical systems;microphone;resonance;the matrix	Lara del Val;Alberto Izquierdo-Fuente;Juan Jos√© Villacorta-Calvo;Luis Su√°rez	2017	J. Sensors	10.1155/2017/3209142	electronic engineering;planar array;engineering;microelectromechanical systems;resonance;acoustics;matrix (mathematics);anechoic chamber;microphone	Robotics	86.72161839765302	-35.605655703358956	67354
4946f068da9496690b5774cd684487603fbd2f1a	adaptive feedback active noise control headset: implementation, evaluation and its extensions	digital signal processing;audio signal processing;active noise control audio signal processing audio equipment signal denoising adaptive signal processing feedback;real time;indexing terms;adaptive algorithm;feedback;adaptive signal processing;single channel;design and implementation;audio equipment;real time implementation;real time measurements single channel adaptive feedback active noise control headset audio applications communication applications error microphone training signal;programmable control adaptive control feedback active noise reduction noise cancellation communication system control acoustic noise low frequency noise microphones noise level;active noise control;signal denoising	In this paper, we present design and real-time implementation of a single-channel adaptive feedback active noise control (AFANC) headset for audio and communication applications. Several important design and implementation considerations, such as the ideal position of error microphone, training signal used, selection of adaptive algorithms and structures will be addressed in this paper. Real-time measurements and comparisons are also carried out with the latest commercial headset to evaluate its performance. In addition, several new extensions to the AFANC headset are described and evaluated.	adaptive algorithm;algorithm;emoticon;headset (audio);microphone;mobile phone;online and offline;performance evaluation;real-time clock;real-time transcription	Woon-Seng Gan;Sohini Mitra;Sen M. Kuo	2005	IEEE Transactions on Consumer Electronics	10.1109/TCE.2005.1510511	adaptive filter;computer vision;electronic engineering;speech recognition;index term;audio signal processing;computer science;digital signal processing;active noise control;feedback	Visualization	85.00892821653915	-32.1279508566932	67773
92b51add8b4057549085bcf40b1ad0c33e091f5f	estimating the direct-to-reverberant energy ratio using a spherical harmonics-based spatial correlation model	speech;estimation;coherence;microphone arrays;correlation;harmonic analysis	The direct-to-reverberant ratio DRR, which describes the energy ratio between the direct and reverberant component of a soundfield, is an important parameter in many audio applications. In this paper, we present a multichannel algorithm, which utilizes the blind recordings of a spherical microphone array to estimate the DRR of interest. The algorithm is developed based on a spatial correlation model formulated in the spherical harmonics domain. This model expresses the cross correlation matrix of the recorded soundfield coefficients in terms of two spatial correlation matrices, one for direct sound and the other for reverberation. While the direct path arrives from the source, the reverberant path is considered to be a nondiffuse soundfield with varying directional gains. The direct and reverberant sound energies are estimated from the aforementioned spatial correlation model, which then leads to the DRR estimation. The practical feasibility of the proposed algorithm was evaluated using the speech corpus of the acoustic characterization of environments challenge. The experimental results revealed that the proposed method was able to effectively estimate the DRR of a large collection of reverberant speech recordings including various environmental noise types, room types and speakers.	acoustic cryptanalysis;algorithm;coefficient;cross-correlation;deficit round robin;microphone;speech corpus	Prasanga N. Samarasinghe;Thushara Dheemantha Abhayapala;Hanchi Chen	2017	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2016.2633811	estimation;speech recognition;coherence;acoustics;speech;harmonic analysis;mathematics;linguistics;correlation;statistics	AI	84.3727892161779	-35.857013280450225	68026
ca7cc89a18fcd6a01f5a649099010cb494dbafe6	multiple source localisation in the spherical harmonic domain	vectors acoustics direction of arrival estimation microphone arrays speech harmonic analysis;acoustics;speech;vectors;speech processing acoustic signal processing eigenvalues and eigenfunctions reverberation;clustering spherical harmonics multiple speaker lo calisation reverberation pseudo intensity vectors;clustering approach multiple source localisation spherical harmonic domain low complexity localisation approach reverberant environments multiple speakers eigen beams pseudo intensity vector estimation sound intensity active sound sources;microphone arrays;direction of arrival estimation;harmonic analysis	Spherical arrays facilitate processing and analysis of sound fields with the potential for high resolution in three dimensions in the spherical harmonic domain. Using the captured sound field, robust source localisation systems are required for speech acquisition, speaker tracking and environment mapping. Source localisation becomes a challenging problem in reverberant environments and under noisy conditions, leading to potentially poor performance in cocktail party scenarios. This paper evaluates the performance of a low-complexity localisation approach using spherical harmonics in reverberant environments for multiple speakers. Eigen-beams are used to estimate pseudo-intensity vectors pointing in the direction of sound intensity. This paper proposes a clustering approach in which the intensity vectors of active sound sources and strong reflections are extracted, yielding an estimate of the source direction in azimuth and inclination as an approach to source localisation.	cluster analysis;eigen (c++ library);image resolution;reflection (computer graphics);reflection mapping;speech acquisition	Christine Evers;Alastair H. Moore;Patrick A. Naylor	2014	2014 14th International Workshop on Acoustic Signal Enhancement (IWAENC)	10.1109/IWAENC.2014.6954298	electronic engineering;speech recognition;acoustics;engineering	Vision	85.5617084042509	-36.589353824145256	68561
c603e2b63339a82b9fdc80242e51a18e53042c33	dynamic blind source separation based on source-direction prediction	computer engineering;kalman filter;three sigma rule;datorteknik;deterministic techniques;direction prediction;blind source separation bss	Deterministic techniques are based on the source-directions and multipath characteristics of the reverberant environment for different source signals. However, searching for the desired directions of the time-block sequence of an acoustic signal is time consuming, and existing deterministic methods rarely consider the motion properties of the acoustic source. In this paper, a dynamic source-direction prediction method for real-time blind convolutive mixtures based on a Kalman filter is proposed. First, the convolutive mixture signals captured by the coincident array geometry are formulated, and the relationship between source-direction and source separation is developed. Second, motion prediction based on a Kalman filter is theoretically analyzed, and the motion of a source is modeled as a noise-driven position integrator with enough samples. Then, a dynamic source-direction prediction method for real-time blind source separation based on a Kalman filter is proposed to predict the directions of a time sequential signal. Combined with the local direction searching method, our proposed method has a self-correction ability according to the three-sigma rule. Finally, extensive experiments are performed with three-source convolutive mixtures of speeches in English and Chinese, whose direction varies in linear and nonlinear motions. The signal-to-distortion and signal-to-interference of the separated signals are calculated, and the experimental results demonstrate the feasibility and validity of the proposed method. We formulate the convolutive mixture signals captured by the coincident array geometry.We propose a dynamic source-direction prediction method for real-time blind source separation based on a Kalman filter.We propose a self-correction ability for source-direction prediction.Convolutive mixtures of speeches in English and Chinese, whose direction varies in linear and nonlinear motions, have been separated.The signal-to-distortion and signal-to-interference of the separated signals are calculated to demonstrate its correctness.	blind signal separation;source separation	Yangjie Wei;Yi Wang	2016	Neurocomputing	10.1016/j.neucom.2015.12.040	kalman filter;speech recognition;computer science;machine learning;blind signal separation;68‚Äì95‚Äì99.7 rule;statistics	ML	85.78955485501106	-35.95142321547322	68785
9d8a3caef65b94fbe7e61685cc32f52a24bce57b	effects of electromagnetic interferences on implantable cardiac pacemakers	electric article surveillance implantable cardiac pacemaker electromagnetic interferences;cardiology;pacemakers logic gates electromagnetic fields electromagnetic interference magnetic fields magnetic field measurement sensors;pacemakers;irnich model electromagnetic interference effects implantable cardiac pacemakers electromagnetic field strength measurement electric article surveillance systems;electromagnetic interference;pacemakers cardiology electromagnetic interference	In this paper, we investigate the effects of electromagnetic interferences (EMI) on implantable cardiac pacemakers. For the purpose, we measure the strength of electromagnetic fields arising from electric article surveillance (EAS) systems, and conduct experiments to diagnose the functionality of pacemaker in the electromagnetic fields by using Irnich-model.	artificial cardiac pacemaker;emi;experiment;interference (communication);reversion (software development)	Takahiro Okumura;Kazuyuki Kojima	2013	2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2013.6664924	electronic engineering;engineering;electrical engineering;biological engineering	Robotics	93.80119481649581	-24.355238000018733	69454
6fe34516ed095063c7f076908bf197987532989e	a microphone array for speech enhancement using multiresolution wavelet transform	speech enhancement;wavelet transform;microphone array;lts1	This paper addresses the problem of enhancing a speech signal corrupted by interfering signals. A new noise reduction algorithm based on a logarithmic microphone array and the multiresolution wavelet transform is described. The proposed processing is applied in the time-spectral domain with respect to the logarithmic subband decomposition of the spectrum of each microphone signal. The advantage of the proposed method is that both the sub-array based beamforming operation and the post ltering are performed in the same transform domain without adding FFT processing. Computer simulation results show that our approach is effective for noise reduction. The technique can be used in hands-free voice communication applications operating in an adverse environment. In particular, it can be applied to improve speech signal pick-up for voice communication terminal.	algorithm;beamforming;computer simulation;fast fourier transform;microphone;multiresolution analysis;noise reduction;rewriting;signal-to-noise ratio;speech enhancement;wavelet transform	Djamila Mahmoudi	1997			wavelet;speech recognition;acoustics;second-generation wavelet transform;wavelet packet decomposition;discrete wavelet transform	EDA	83.68628800024197	-33.23323714081544	69768
c97b81cb0ee48382d0dab62a37937faa6ea677c6	cross recurrence plot analysis based method for tdoa estimation of underwater acoustic signals	sonar equipment estimation receivers underwater acoustics acoustic measurements direction of arrival estimation trajectory;time of arrival estimation acoustic signal processing array signal processing frequency modulation hydrophones;beluga whale dynamical cross recurrence plot analysis based method tdoa estimation underwater acoustic signal crpa time difference of arrival estimation hydrophone array frequency modulated sound	In this paper, we propose to use cross recurrence plot analysis (CRPA) to estimate the time-difference of arrival (TDOA) of underwater acoustic signals arriving on an array of hydrophones. Instead of considering the signal as a whole to estimate the TDOA, like classical methods do, we first detected the series of samples that look alike on each pair of hydrophones of the array by using cross-recurrence plot analysis. The TDOA is then estimated by relying only on these common sample series. The TDOA estimator is based on quantification measures specifically designed for CRPA. The proposed method is successfully validated on real data containing frequency-modulated sounds from beluga whales.	acoustic cryptanalysis;cross-correlation;modulation;multilateration;recurrence plot;waveform	Olivier Le Bot;J√©r√¥me I. Mars;C√©dric Gervaise;Yvan Simard	2015	2015 IEEE 6th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)	10.1109/CAMSAP.2015.7465293	speech recognition;acoustics;telecommunications;engineering;fdoa	Visualization	85.04081946760336	-38.20082398035711	70613
129fb0889ac6c2a555511901f6dc614514801c3d	geometric inference of the room geometry under temperature variations	microphones;acoustics;geometry;speech;reflector localization methodology geometric inference room geometry temperature variations closed acoustic space time differences of arrival measurement tdoa time of arrival measurement microphone array geometric constraint;acoustic signal processing;array signal processing;channel estimation;arrays;speed of sound estimation;estimation;speed of sound;geometric inference;microphone array;signal processing;toa;time of arrival estimation;time of arrival;temperature measurement;microphone arrays;acoustics microphones temperature measurement signal processing arrays estimation speech;time of arrival estimation acoustic signal processing array signal processing geometry microphone arrays;ambient temperature;toa geometric inference speed of sound estimation channel estimation tdoa;geometric constraints;tdoa;time difference of arrival	Geometric inference is an approach for localizing reflectors in a closed acoustic space. It is based on a simple observation that turns time differences of arrival (TDOA) or time of arrival (TOA) measurements from the signals of a microphone array into a geometric constraint. The reflector localization methodology relies on accurate TDOA which is directly dependent on speed of sound information. Estimating the actual speed of sound at the ambient temperature therefore greatly improves the accuracy of the reflector localization in uncontrolled environments. This manuscript shows how to use the geometric inference jointly with the speed of sound estimation for a more accurate reflector localization. Simulations and experiments show the validity of the proposed approach.	acoustic cryptanalysis;computer simulation;experiment;microphone;multilateration;time of arrival;uncontrolled format string	Paolo Annibale;Jason Filos;Patrick A. Naylor;Rudolf Rabenstein	2012	2012 5th International Symposium on Communications, Control and Signal Processing	10.1109/ISCCSP.2012.6217852	electronic engineering;speech recognition;acoustics;physics	Embedded	86.4960318956489	-35.987470353198766	70740
2471537929c8afcde2b25119cecfb79c12cc2c68	perceptually motivated blind source separation of convolutive mixtures	blind source separation independent component analysis psychoacoustic models source separation frequency domain analysis speech coding acoustic sensors filter bank acoustic noise working environment noise;speech intelligibility;speech intelligibility independent component analysis blind source separation hearing audio signal processing acoustic signal processing frequency domain analysis speech recognition;audio signal processing;thesis or dissertation;blind source separation;frequency domain analysis;kb thesis scanning project 2015;acoustic signal processing;spectrum;independent component analysis;simulation perceptually motivated blind source separation convolutive mixtures perceptually motivated method permutation ambiguity frequency domain independent component analysis noisy reverberant mixing environment perceptually irrelevant frequency removal speech spectrum block based perceptual masking simultaneous frequency masking frequency domain source separation mixing matrix coherency;speech recognition;frequency domain;source separation;convolutive mixture;hearing;physical properties	A perceptually motivated method is proposed for solving the permutation ambiguity of frequency-domain independent component analysis when the mixing environment is noisy and reverberant. In this method, perceptually irrelevant frequencies are removed from the speech spectrum using block based perceptual masking (simultaneous frequency masking) and then independent component analysis is applied. After source separation in frequency domain, a physical property of the mixing matrix, i.e., the coherency in adjacent frequencies, is utilized to solve the permutation ambiguity. From the simulation results it appears that the perceptual masking avoids the permutation problem.	blind signal separation;independent component analysis;relevance;simulation;source separation;unsharp masking	Ram Mohana Reddy Guddeti;Bernard Mulgrew	2005	Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.	10.1109/ICASSP.2005.1416293	speech recognition;computer science;machine learning;frequency domain	Robotics	83.41006238863369	-36.42208889313181	70890
18af9bf950afb5cdd67c293858c920c6c6e508b4	period estimation of an almost periodic signal using persistent homology with application to respiratory rate measurement	topology;periodicity persistent homology pyro electric infrared pir sensor respiratory rate rr topological data analysis;reliability;estimation;three dimensional displays;three dimensional displays delays topology estimation sensor arrays harmonic analysis reliability;sensor arrays;delays;harmonic analysis	Time-frequency techniques have difficulties in yielding efficient online algorithms for almost periodic signals. We describe a new topological method to find the period of signals that have an almost periodic waveform. Proposed method is applied to signals received from a pyro-electric infrared sensor array for the online estimation of the respiratory rate (RR) of a person. Time-varying analog signals captured from the sensors exhibit an almost periodic behavior due to repetitive nature of breathing activity. Sensor signals are transformed into two-dimensional point clouds with a technique that allows preserving the period information. Features, which represent the harmonic structures in the sensor signals, are detected by applying persistent homology and the RR is estimated based on the persistence barcode of the first Betti number. Experiments have been carried out to show that our method makes reliable estimates of the RR.	almost periodic function;analog signal;barcode;betti number;homology (biology);homology modeling;online algorithm;persistence (computer science);persistent homology;point cloud;rapid refresh;round-robin scheduling;sensor;waveform	Fatih Erden;A. Enis √áetin	2017	IEEE Signal Processing Letters	10.1109/LSP.2017.2699924	estimation;real-time computing;harmonic analysis;reliability;control theory;mathematics;statistics	Metrics	92.77602415007652	-27.16768693992902	71360
01015d7d9248dc5bbca1b67fa80059185a8c3865	constrained multi-channel linear prediction for adaptive speech dereverberation	microphones;reverberation;prediction algorithms;speech;indexes;optimization;adaptation models	This paper presents a speech dereverberation algorithm combining adaptive multi-channel linear prediction (MCLP) with a statistical model for the undesired reverberation. More specifically, we propose to constrain the power of the MCLP-based late reverberation estimate with the late reverberant power estimated using the exponential decay model, thereby preventing excessive cancellation of the speech signal. Simulation results show that incorporating the constraint improves the performance of the adaptive dereverberation method when the prediction filters need to adapt quickly.	adaptive filter;algorithm;simulation;statistical model;time complexity	Ante Jukic;Zichao Wang;Toon van Waterschoot;Timo Gerkmann;Simon Doclo	2016	2016 IEEE International Workshop on Acoustic Signal Enhancement (IWAENC)	10.1109/IWAENC.2016.7602922	speech recognition;acoustics;computer science;communication	Arch	83.50738953050126	-34.29421050590486	72079
662fea61ba6c4b828c8b32f1839c8a91859e0df0	multi-channel active noise control system using the perturbation method with correlation removal filter	perturbation techniques acoustic correlation active noise control convergence of numerical methods filtering theory finite difference time domain analysis microphones;fdtdsp method multichannel active noise control system correlation removal filter anc systems microphones noise signals reference signals noise control filter convergence speed noise reduction frequency domain time difference simultaneous perturbation method;microphones digital signal processing information filters facsimile abstracts noise	In this paper, we verify practical effectiveness of ANC systems using the perturbation method with a correlation removal filter. Many microphones are generally needed to pick up all noise signals where some noise signals are simultaneously controlled in more spacious space. Therefore, the noise signals give correlations between reference signals and then the convergence speed of noise control filters becomes slow. The proposed system can remove the correlations by inserting a correlation removal filter between reference signals and consequently reduce the noise more quickly. Moreover, we use the frequency domain time difference simultaneous perturbation method (FDTDSP method) to update the noise control filters. Experimental results demonstrate that the ANC system using the perturbation method with a correlation removal filter is effective in the actual system.	control system;microphone;perturbation theory	T. Ninagawa;Yoshinobu Kajikawa;Yasuo Nomura	2004	2004 12th European Signal Processing Conference		gradient noise;nonlinear filter;gaussian noise;median filter;image noise;effective input noise temperature;noise;electronic engineering;acoustics;value noise;noise temperature;computer science;noise measurement;noise;control theory;noise figure;noise floor;phase noise;salt-and-pepper noise	Robotics	84.42643813296534	-33.519571827846306	72201
f7f004e462d59e8492aafe58ae0aab71c1c53c74	swarm intelligence based particle filter for alternating talker localization and tracking using microphone arrays	talker localization and tracking;journal article;microphone arrays	We address the problem of localizing and tracking alternating moving or stationary talkers using microphone arrays in a room environment. One of the main challenges is the frequent and possibly abrupt change of talker positions, which requires the algorithm to capture the active talker rapidly. In addition, the presence of interference, background noise, and room reverberation degrades the tracking performance. We propose a new algorithm that jointly exploits the advantages of the particle filter PF and particle swarm intelligence. The PF is used as a general tracking framework, which incorporates a proposed alternating source-dynamic model for recursive estimation of talker position. Unlike the conventional PF, where particles operate independently in the particle sampling stage, the use of swarm intelligence allows particles to interact with each other, thereby improving convergence toward the active talker location. In addition, the memory mechanism in swarm intelligence allows particles to remain at their previous best-fit state estimate when signals are corrupted by interference, noise, and/or reverberation. Simulations and experiments were conducted to demonstrate the effectiveness of the proposed algorithm.		Kai Wu;Vaninirappuputhenpurayil Gopalan Reju;Andy W. H. Khong;Shu Ting Goh	2017	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2017.2693566	speech recognition;acoustics	Vision	84.8474872043401	-35.66636517125705	72739
c3f8f0d67bcd86a59073aebb6002f2d6448b4ea4	acoustic imaging of sparse sources with orthogonal matching pursuit and clustering of basis vectors		We have devised a greedy method for finding solutions to the sparse Deconvolution Approach for the Mapping of Acoustic Sources inverse problem using a variant of Orthogonal Matching Pursuit. The algorithm has two stages, wherein the first stage consists of selecting a subset of the basis vectors iteratively via a regularized inverse of the point spread function, and the second stage consists of constructing point source solutions using this basis subset and its coefficients via hierarchical agglomerative clustering. We have evaluated the algorithm on both synthetic and real data, and show that the overall accuracy in terms of direction of arrival and reconstructed source power is better than four other state of the art methods.	acoustic cryptanalysis;basis (linear algebra);cluster analysis;coefficient;deconvolution;dhrystone;direction of arrival;greedy algorithm;hierarchical clustering;matching pursuit;sparse matrix	Trond F. Bergh;Ines Hafizovic;Sverre Holm	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7953314	mathematical optimization;discrete mathematics;pattern recognition;sparse approximation;matching pursuit	Vision	83.8705701139476	-37.283335667607766	72799
7eff2b35214d551e3c70b1c9e27fa23e41f5db75	what are metrologists made of?	instruments;time measurement;systematics;uncertainty;measurement uncertainty temperature measurement time measurement instruments metrology systematics uncertainty;measurement uncertainty;metrology;temperature measurement			Bryan P. Kibble	2014	IEEE Instrumentation & Measurement Magazine	10.1109/MIM.2014.6968923	uncertainty;temperature measurement;systematics;optics;metrology;physics;quantum mechanics;statistics;measurement uncertainty;time	Embedded	91.00271816421042	-24.5838609356319	72984
f0e27b11ccdeca5b26fa809f3b2a91d9ca38a9e7	vibration measurement with electrical speckle shearing pattern interferometry		Electrical speckle shearing pattern interferometry (ESSPI), being a kind of high-precision noncontact real-time measurement method in the whole field, has been used in the field of deformation measurement and harmonic vibration measurement deviating from rough object plane in the optical scale. The method can also be used in the field of nondestructive test (NDT). Two general methods, time-average methods and stroboscopic method, are studied to measure harmonic vibration deviating from object plane and corresponding mathematical models of electrical speckle shearing interfering stripes distribution are set up based on the theory of statistical optics. The vibration measuring system based on ESSPI is designed and the experiments are done to verify measurement availability of the above two methods. The experiment results with time-average method and those with stroboscopic method are compared to prove the following conclusions. The contrast of speckle stripes in electrical speckle shearing interfering stripe images with time-average method is decreased obviously with increase of the stripes level and therefore the time-average method is generally used in qualitative analysis of vibration. The speckle stripes quality in the electrical speckle shearing interfering stripe images with stroboscopic method is better than that with time-average method and the instant vibration distribution can be analyzed quantitatively with stroboscopic method too.	data striping;experiment;magnetic stripe card;mathematical model;real-time clock;stripes	Chao Jing;Zhongling Liu;Chunlei Guo;Yu Zhang;Yimo Zhang	2016	2016 International Conference on Identification, Information and Knowledge in the Internet of Things (IIKI)	10.1109/IIKI.2016.119	deformation (mechanics);computer network;nondestructive testing;shearing (physics);stroboscope;computer science;speckle pattern;interferometry;harmonic;vibration;optics	Robotics	89.42854364060625	-24.520698468793604	72996
9126b0038dbdcd39e97f82c82f8a29f4bbb168ae	pseudo-real-time low-pass filter in ecg, self-adjustable to the frequency spectra of the waves	ecg;emg noise;filtering	The electrocardiogram (ECG) acquisition is often accompanied by high-frequency electromyographic (EMG) noise. The noise is difficult to be filtered, due to considerable overlapping of its frequency spectrum to the frequency spectrum of the ECG. Today, filters must conform to the new guidelines (2007) for low-pass filtering in ECG with cutoffs of 150¬†Hz for adolescents and adults, and to 250¬†Hz for children. We are suggesting a pseudo-real-time low-pass filter, self-adjustable to the frequency spectra of the ECG waves. The filter is based on the approximation procedure of Savitzky‚ÄìGolay with dynamic change in the cutoff frequency. The filter is implemented pseudo-real-time (real-time with a certain delay). An additional option is the automatic on/off triggering, depending on the presence/absence of EMG noise. The analysis of the proposed filter shows that the low-frequency components of the ECG (low-power P- and T-waves, PQ-, ST- and TP-segments) are filtered with a cutoff of 14¬†Hz, the high-power P- and T-waves are filtered with a cutoff frequency in the range of 20‚Äì30¬†Hz, and the high-frequency QRS complexes are filtered with cutoff frequency of higher than 100¬†Hz. The suggested dynamic filter satisfies the conflicting requirements for a strong suppression of EMG noise and at the same time a maximal preservation of the ECG high-frequency components.	approximation;beckwith-wiedemann syndrome;binary golay code;biologic preservation;conflict (psychology);electrocardiography;electromyography;filter bank;frequency band;frequency response;galaxy morphological classification;hertz (hz);image noise;interval arithmetic;low-pass filter;low-power broadcasting;maximal set;pseudo brand of pseudoephedrine;real-time clock;requirement;spectral density;zero suppression	Ivaylo Christov;Tatyana Neycheva;Ramun Schmid;Todor Stoyanov;Roger Ab√§cherli	2017	Medical & Biological Engineering & Computing	10.1007/s11517-017-1625-y	electronic engineering;acoustics;low-pass filter;telecommunications;mathematics;high-pass filter;center frequency	EDA	84.63653873073255	-40.119542879121916	74968
88292565a13f66f170e9dab12f1079ada2e6825f	speech enhancement using improved generalized sidelobe canceller in frequency domain with multi-channel postfiltering	generalized sidelobe canceller;microphone array;postfilter;speech enhancement;subband feedback control;frequency domain	In this paper, we propose a speech enhancement algorithm which has the feature of interaction between adaptive beamforming and multi-channel postfilter. A novel subband feedback controller based on speech presence probability is applied to Generalized Sidelobe Canceller algorithm to obtain a more robust adaptive beamforming in adverse environment and alleviate the problem of signal cancellation. A multi-channel postfiltering is used not only to further suppress diffuse noises and some transient interferences, but also to give the speech presence probability information in each subband. Experimental results show that the proposed algorithm achieves considerable improvement on signal preservation of the desired speech in adverse noise environments, consisting of both directional and diffused noises over the comparative algorithms.	adaptive beamformer;algorithm;beamforming;control theory;speech enhancement	Kai Li;Qiang Fu;Yonghong Yan	2010			speech recognition;frequency domain;artificial intelligence;pattern recognition;speech enhancement;computer science;communication channel	Robotics	84.22994723510101	-34.0604676778595	75338
8358c99c35bcf3252ab966f190e5dce411ffa5a2	bayesian non-field-of-view target estimation incorporating an acoustic sensor	microphones;recursive estimation;bayes methods;recursive estimation acoustic transducers bayes methods microphones optical sensors;bayesian nonfield of view target estimation optical sensor recursive bayesian estimation optical observation likelihood joint observation likelihood acoustic observation likelihood interaural level difference microphones acoustic sensor;optical sensors;acoustic transducers;optical sensors acoustics mathematical model acoustic sensors estimation joints	This paper presents non-field-of-view (NFOV) target estimation incorporating an acoustic sensor, which consists of two microphones. The proposed approach derives the interaural level difference (ILD) of observations from the two microphones for different target positions and stores the ILDs as database a priori. Given a new acoustic observation on a target, an acoustic observation likelihood is created by calculating the correlation of the ILD of the new observation to the stored ILDs. A joint observation likelihood is then developed by fusing the optical and acoustic observation likelihoods, and the recursive Bayesian estimation updates and maintains belief on the target using the joint observation likelihood. The proposed approach detects a target positively using an acoustic sensor even if it is outside the field of view of the optical sensor and localizes the target accurately by estimating it within the RBE. The efficacy of the proposed approach was first validated by experimental studies. Further numerical demonstrations then show the applicability of the proposed approach to the NFOV target estimation.	acoustic cryptanalysis;internet listing display;microphone;numerical analysis;recursion;sensor	Makoto Kumon;Daisuke Kimoto;Kuya Takami;Tomonari Furukawa	2013	2013 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2013.6696844	speech recognition;acoustics;engineering;statistics	Robotics	87.14179620021959	-37.61552991071665	75726
91aab06ef523b4ddc9c8b155f854849f65916115	wireless sensor platform for cultural heritage monitoring and modeling system	air quality monitoring;computational fluid dynamics;corrosion;micro environmental monitoring;wireless sensor network	Results from three years of continuous monitoring of environmental conditions using a wireless sensor platform installed at The Cloisters, the medieval branch of the New York Metropolitan Museum of Art, are presented. The platform comprises more than 200 sensors that were distributed in five galleries to assess temperature and air flow and to quantify microclimate changes using physics-based and statistical models. The wireless sensor network data shows a very stable environment within the galleries, while the dense monitoring enables localized monitoring of subtle changes in air quality trends and impact of visitors on the microclimate conditions. The high spatial and temporal resolution data serves as a baseline study to understand the impact of visitors and building operations on the long-term preservation of art objects.	baseline (configuration management);biologic preservation;cns disorder;climate;conflict (psychology);exhibits as topic;experiment;exposure to humidity;financial risk modeling;hl7publishingsubsection <operations>;microclimate;physical object;radio communications;scalability;sensor web;statistical model;transducer;transducers;sensor (device)	Levente J. Klein;Sergio A. Bermudez;Alejandro G. Schrott;Masahiko Tsukada;Paolo Dionisi-Vici;Lucretia Kargere;Fernando J. Marianno;Hendrik F. Hamann;Vanessa L√≥pez;Marco Leona	2017		10.3390/s17091998	engineering;wireless sensor network;microclimate;air quality index;remote sensing;wireless;cultural heritage;temporal resolution;continuous monitoring	Mobile	84.33723410504359	-52.02568428552814	76524
6029aa70d7d60adf307890a9335c3e07846a6300	monaural sound-source-direction estimation using the acoustic transfer function of an active microphone	active microphone;microphones;transfer functions speech acoustic reflection radar antennas microphone arrays acoustic signal processing radar signal processing statistics direction of arrival estimation cepstral analysis;clean speech signal statistics monaural sound source direction estimation acoustic transfer function active microphone active operation acoustic signal processing parabolic reflection board signal power based method uttered speech signal power;estimation method;transfer functions;speech processing;active operation;speech;acoustic signal processing;transfer functions acoustic signal processing direction of arrival estimation microphones speech processing;uttered speech signal power;microphones direction of arrival estimation acoustic reflection;accuracy;clean speech signal statistics;monaural sound source direction estimation;cepstral analysis;estimation;radar antennas;transfer function;signal processing;signal power based method;acoustic reflection;statistics;acoustic transfer function;microphone arrays;parabolic reflection board;radar signal processing;direction of arrival estimation	This paper introduces an active microphone concept that achieves a good combination of active-operation and signal processing, where a new sound-source-direction estimation method using only a single microphone with a parabolic reflection board is proposed. A simple signal-power-based method using a parabolic antenna has been proposed in the radar field. But the signal-power-based method is not effective for finding the direction of a talking person due to the varying power of the uttered speech signals. In this paper, the sound-source-direction estimation method focuses on the acoustic transfer function instead of the signal power. The use of the parabolic reflection board leads to a difference in the acoustic transfer functions of the target direction and the non-target directions, where the active microphone rotates and observes the speech at each angle. The acoustic transfer function is estimated from the observed speech using the statistics of clean speech signals. Its effectiveness is confirmed by monaural sound-source-direction estimation experiments in a room environment.	acoustic cryptanalysis;diffuse reflection;experiment;microphone;parabolic antenna;signal processing;transfer function	Ryoichi Takashima;Tetsuya Takiguchi;Yasuo Ariki	2009	2009 12th International Conference on Information Fusion		electronic engineering;speech recognition;acoustics;noise-canceling microphone;engineering	Robotics	86.04750618474307	-35.47517313506231	77686
8c43fe7a3e5406f19a82045aa0042dcaf264f4bf	a source counting method using acoustic vector sensor based on sparse modeling of doa histogram		The number of sources present in a mixture is crucial information often assumed to be known or detected by source counting. The existing methods for source counting in underdetermined blind speech separation suffer from the overlapping between sources with low W-disjoint orthogonality. To address this issue, we propose to fit the direction-of-arrival (DOA) histogram with multiple von-Mises density (VM) functions directly and form a sparse recovery problem, where all the source clusters and the sidelobes in the DOA histogram are fitted with VM functions of different spatial parameters. We also developed a formula to perform the source counting taking advantage of the values of the sparse source vector to reduce the influence of sidelobes. Experiments are carried out to evaluate the proposed source counting method, and the results show that the proposed method outperforms two well-known baseline methods.	acoustic cryptanalysis;assumed;baseline (configuration management);compressed sensing;direction of arrival;histogram;seizures;sparse matrix;von willebrand disease	Yang Chen;Wenwu Wang;Zhe Wang;Bingyin Xia	2019	IEEE Signal Processing Letters	10.1109/LSP.2018.2879547		AI	83.39692289838499	-37.18064754419005	78654
e174473df035442ffc8e283e0504d736430e6791	detection of underwater carrier-free pulse based on time-frequency analysis	carrier free pulse;characteristics;detection;time frequency analysis	Carrier-free short pulse widely employed in UWB radar is brought into high-resolution sonar system, which has unique advantages: attaining more target information, restraining fluctuation of reverberation envelop efficiently in short-range detection and achieving accurate estimation. In essence such pulse is transiently short in time domain and wide in frequency domain, and as such it is difficult to separate signal to noise based on Fourier Transform spectrum. So as to seek for detection methods of short pulse, minor differences of energy distribution of time-frequency characteristics are presented on three time-frequency methods such as Short Time Fourier Transform, Wavelet Transform and Hilbert-Huang Transform. With these results, a tri-channel detector is established for such underwater short pulse in noise environment, which is generally suitable not only for detection module of underwater sonar system but also that of radar system.	frequency analysis;hilbert‚Äìhuang transform;image resolution;near field communication;quantum fluctuation;radar;real-time clock;real-time computing;sonar (symantec);sensor;short-time fourier transform;time‚Äìfrequency analysis;triangular function;ultra-wideband;wavelet transform;yang	Yunlu Ni;Hang Chen	2013	JNW	10.4304/jnw.8.1.205-212	pulse compression;speech recognition;time‚Äìfrequency analysis;telecommunications	Robotics	84.74533642817468	-39.56771816512685	79207
860c0a2e782529a8a2d66149f636403d450b9a48	terahertz spectroscopic uncertainty analysis for explosive mixture components determination using multi-objective micro-genetic algorithm	micro genetic algorithm;mixture;multi objective;components determination;terahertz;uncertainty analysis;genetic algorithm;terahertz spectroscopy	In practical applications, many suspicious samples may be a kind of mixture and consist of various chemical components that make the spectral analysis difficult. Various explosives and related compounds (ERC) in the mixture can be identified and the concentration of each component can be estimated based on the known spectral data of the pure explosive components. In this paper, the terahertz spectroscopic uncertainty analysis using a micro-GA has been proposed, in which the random assignment of alleles from parents to offspring is implied. An intelligent computation-based technical road-map is also provided for the analysis and optimisation of the terahertz spectroscopic combination analysis. A simulation with two given test cases for the ERC has been devised. The results of the simulation show that micro-GA and its derivatives have the potential applications in the fields of security, medicine and food industry to fast identify mixtures.	british informatics olympiad;coefficient of determination;genetic algorithm;real-time clock;real-time computing;simulation;software release life cycle;test case	Yi Chen;Yong Ma;Zheng Lu;Lixia Qiu;Jin He	2011	Advances in Engineering Software	10.1016/j.advengsoft.2011.04.011	econometrics;genetic algorithm;uncertainty analysis;computer science;engineering;terahertz radiation;forensic engineering;mixture;terahertz spectroscopy and technology	SE	84.74520550520003	-47.365939823475536	79479
c20bf24aa72d2aeb6573adb0ed871196d3660679	real-world particle filtering-based speech enhancement	gaussian noise;microphones;time varying;noise power spectral density estimation;colored noise;white gaussian noise sequence;speech;spectrum;speech enhancement;speech quality;noise measurement;noise power spectral density estimation particle filtering speech enhancement noise spectrum white gaussian noise sequence time varying gain;power spectral density;speech enhancement gaussian noise microphones particle filtering numerical methods;estimation;speech estimation noise measurement signal to noise ratio speech enhancement masking threshold;time varying gain;particle filter;particle filtering;colored noise speech enhancement particle filtering speech quality;white gaussian noise;quality measures;noise spectrum;masking threshold;signal to noise ratio;particle filtering numerical methods	This paper presents a viable particle filtering (PF) solution for single microphone speech enhancement in real-world conditions, i.e., operating at low SNR in nonstationary noise environments, while remaining computationally tractable. The enhancement takes place in the subband domain with elementary PFs in each band. To efficiently handle complex noise situations, the noise spectrum is modelled in each band as a white Gaussian noise sequence with a time-varying gain. Two solutions are proposed to estimate these time-varying average subband noise levels: they are either drawn internally by the PFs, or they are obtained by external dedicated noise power spectral density estimation - both methods are found to yield very close results. Several subband decompositions are tested, and a robust way of incorporating perceptual constraining is introduced. The assembled PF-based architecture is then compared with state-of-the-art enhancement algorithms in various conditions, and is found to outperform them according to seven objective speech quality measures.	algorithm;cobham's thesis;microphone;noise power;particle filter;signal-to-noise ratio;singular value decomposition;spectral density estimation;speech enhancement	Fr√©d√©ric Musti√®re;Miodrag Bolic;Martin Bouchard	2010	2010 2nd International Workshop on Cognitive Information Processing	10.1109/CIP.2010.5604235	gradient noise;gaussian noise;electronic engineering;speech recognition;acoustics;value noise;engineering;noise measurement	ML	83.26140737372745	-34.66767833059171	79489
d48fdf23934dffc79a194b83cbd493778cf83e03	multiple sound source tracking using low complexity directional estimation		In this paper, a method for sound source tracking by two microphones is studied. Then, it is often assumed to be implemented on DSP (Digital Signal Processor). In this case, it is required to reduce the calculation cost. In our method, a sequential updating histogram based on the instantaneous phase difference is used for estimating the sound source direction. Moreover, for attaining more tracking accuracy, the microphone width is expanded for enhancing a spatial resolution. Several experimental results in a real environment are shown to present the effectiveness of the our method.	covox speech thing;digital signal processor;instantaneous phase;microphone;source tracking	Kenta Omiya;Kenji Suyama	2017	2017 17th International Symposium on Communications and Information Technologies (ISCIT)	10.1109/ISCIT.2017.8261210	digital signal processor;real-time computing;time‚Äìfrequency analysis;source tracking;digital signal processing;computer science;image resolution;histogram;microphone;instantaneous phase	Arch	85.19355412580201	-37.68746713729478	79679
9d1e172330ebfd8b24139ee3024223a15c935271	improving plca-based score-informed source separation with invertible constant-q transforms	nmf;score informed;data representation plca based score informed source separation invertible constant q transforms probabilistic latent component analysis nonnegative matrix factorization single channel audio source separation music scores constant q tranform short time fourier transform;source separation transforms measurement probabilistic logic acoustics conferences;audio signal processing;probability;source separation plca nmf cqt stft nsgt bss eval peass score informed;cqt;peass;plca;matrix decomposition;bss eval;fourier transforms;source separation audio signal processing fourier transforms matrix decomposition probability;source separation;stft;nsgt	Probabilistic Latent Component Analysis is a widely adopted variant of Nonnegative Matrix Factorization for the purpose of single channel audio source separation. It has seen many extensions, including incorporation of prior information derived from music scores. Recent work on the invertibility of the Constant-Q Tranform make that a viable alternative to the Short-time Fourier Transform as underlying data representation. In this paper we assess several implementations for their usability in score-informed source separation. We show that results are comparable to, and in some cases better than, use of the STFT, and that exact transform invertibility is not a significant factor in this application.	data (computing);non-negative matrix factorization;short-time fourier transform;source separation;usability	Joachim Ganseman;Paul Scheunders;S. Dixon	2012	2012 Proceedings of the 20th European Signal Processing Conference (EUSIPCO)		speech recognition;machine learning;pattern recognition;mathematics	ML	83.09659400669698	-38.14444936263486	79978
77ff228e0259b64a58b1515b2e53dd37ec0a074e	optical measurement of acoustic drum strike locations		This paper presents a method for locating the position of a strike on an acoustic drumhead. Near-field optical sensors were installed underneath the drumhead of a commercially available snare drum. By implementing a time difference of arrival (TDOA) algorithm, accuracy within 2cm was achieved in approximating the location of strikes. This method could be used for drum performance analysis, timbre analysis and can form a basis for an augmented drum performance system.	acoustic cryptanalysis;algorithm;drum memory;multilateration;sensor;snare (software)	Janis Sokolovskis;Andrew W McPherson	2014			multilateration;drumhead;acoustics;drum;computer science;timbre	Robotics	86.68657975766031	-35.66447748192551	80197
7e30419bc91f324e103cc2a62c7ce1d74f7ed8bb	design and implementation of subspace-based speech enhancement under in-car noisy environments	traitement pipeline;system on a programmable chip architecture;background noise;programmable circuit;traitement signal;very large scale integration design;pipelined pastd architecture;psicoacustico;amelioration parole;perceptual filterbank;in vehicle annunciators;projection approximation subspace tracking deflation algorithm;tracking system;automobiles;filter bank;system on a programmable chip sopc in car noise psychoacoustic model pam speech enhancement subspace tracking;integrated circuit;automovil;circuit programmable;banc filtre;vehiculo caminero;clocks;approximation algorithms;vehicule routier;sopc;very large scale integration;implementation;real time;acoustic modeling;speech processing;working environment noise;gain;psychoacoustic model pam;circuit vlsi;tratamiento palabra;psychoacoustique;traitement parole;real time processing;background noise suppression;vlsi acoustic signal processing channel bank filters digital signal processing chips integrated circuit design noise speech enhancement system on chip tracking filters;circuito integrado;acoustic signal processing;metodo subespacio;riesgo accidente;tracking filters;very large scale integrated;speech enhancement;speech enhancement working environment noise psychoacoustic models computer architecture clocks background noise filter bank approximation algorithms real time systems very large scale integration;system on a chip;pipelined pastd architecture subspace based speech enhancement model in car noisy environments background noise suppression perceptual filterbank auditory gain adaptation psychoacoustic model signal subspace approach projection approximation subspace tracking deflation algorithm pastd algorithm system on a programmable chip architecture very large scale integration design pipeline computation;methode sous espace;risque accidentel;reduccion ruido;chip;algorithme;system on a programmable chip;algorithm;tratamiento tiempo real;pastd algorithm;computer architecture;integrated circuit design	In this paper, a new subspace-based speech enhancement model is presented for in-car speech enhancement. To effectively suppress background noise, this model incorporates a perceptual filterbank and an auditory gain adaptation derived from a psychoacoustic model into a signal subspace approach. The projection approximation subspace tracking deflation (PASTd) algorithm is used to track the signal subspace. For real-time processing, a system-on-a-programmable-chip architecture and a very large scale integration design of the PASTd algorithm are proposed. To realize a pipeline computation, this paper presents a pipelined PASTd architecture without data-dependent hazards. The maximum clock rate is 9.7 MHz, and the typical clock rate, which achieves the real-time requirement, is 4.6 MHz. The corresponding architecture was experimentally verified via an ALTERA EPXA10 development board.	algorithm;approximation;clock rate;computation;data dependency;degradation (telecommunications);experiment;filter bank;integrated circuit;microprocessor development board;peripheral;pipeline (computing);prototype;psychoacoustics;rate of convergence;real-time clock;signal subspace;simulation;speech enhancement;speech processing;speech recognition;system on a chip;tree structure;very-large-scale integration;wavelet packet decomposition	Chung-Hsien Yang;Jia-Ching Wang;Jhing-Fa Wang;Chung-Hsien Wu;Kai-Hsing Chang	2008	IEEE Transactions on Vehicular Technology	10.1109/TVT.2007.912158	system on a chip;embedded system;electronic engineering;speech recognition;telecommunications;computer science;engineering;signal processing;speech processing;very-large-scale integration	Robotics	83.63282048444913	-32.22926905442307	80405
074b1a28070c637053e88dc7377add55cf764499	tdoa estimation for multiple speakers in underdetermined case		In this paper we address the issue of estimating the time delay of arrival in underdetermined case. We develop a method using the excitation characteristics of the speech production. This method is based on the cross correlation of the Hilbert Envelops of linear prediction residuals derived from two microphones signals. The method has been applied to real data obtained by recording many sources captured by a pair of microphones. Experiments show that reverberation distorts the input signals, each reverberation causes an extra peak in the cross-correlation. This makes it difficult to determine which peak is the central time-delay peak and which are just reverberation sidelobes. An alternative time delay estimation method has been implemented and compared to spectrum angular methods.	angularjs;broadcast delay;cross-correlation;delay-gradient congestion control;distortion;experiment;microphone;multilateration	Mariem Bouafif;Zied Lachiri	2012			artificial intelligence;multilateration;speech recognition;underdetermined system;pattern recognition;computer science	Robotics	84.15269632849663	-36.2434066534927	81006
bacd972cd85de0c69855c5a3c52b3f67f1733c42	articulatory speech synthesis based on fractional delay waveguide filters	fractional delay filter techniques;lagrange interpolation;bidirectional delay lines;articulatory speech synthesis;degradation;interpolation;speech intelligibility;sampling rate;5 khz;speech synthesis;approximation error;filtering theory speech synthesis speech intelligibility waveguide filters delay lines interpolation signal sampling fir filters;signal sampling;delay lines;acoustic scattering;vocal tract;22 khz;oversampling;5 khz articulatory speech synthesis fractional delay waveguide filters vocal tract model tube section length fractional delay filter techniques interpolation deinterpolation filter structure bidirectional delay lines digital waveguides interpolated ports two port scattering junction degradation approximation errors lagrange interpolation vocal tract mode oversampling sampling rate high quality synthetic sounds bandwidth 22 khz;deinterpolation;fractional delay;tube section length;propagation delay;interpolated ports;digital filters;bandwidth;speech synthesis propagation delay interpolation digital filters delay lines acoustic scattering degradation approximation error lagrangian functions sampling methods;fir filters;sampling methods;vocal tract model;digital waveguides;lagrangian functions;high quality synthetic sounds;filtering theory;fractional delay waveguide filters;vocal tract mode;approximation errors;filter structure;waveguide filters;two port scattering junction	An extension to the traditional Kelly-Lochbaum vocal tract model is introduced. In the new model not only the diameter but also the length of each tube section can be continuously adjusted. This is achieved by using fractional delay filter techniques such as interpolation and deinterpolation. The filter structure consisting of bidirectional delay lines (digital waveguides) and interpolated ports that connect two or more waveguide sections together is called a fractional delay waveguide filter (FDWF). The interpolated version of the two-port scattering junction is presented and a technique for analyzing the degradation due to approximation errors in interpolation and deinterpolation is described. It is shown that when an FDWF structure with Lagrange interpolation is used a vocal tract model needs to be implemented using oversampling. For example, a sampling rate of 22 kHz is adequate for producing high-quality synthetic sounds at a 5 kHz bandwidth.	analog delay line;approximation;elegant degradation;euler‚Äìlagrange equation;fractional fourier transform;interpolation;kelly criterion;lagrange polynomial;oversampling;sampling (signal processing);speech synthesis;synthetic data;tract (literature)	Vesa V√§lim√§ki;Matti Karjalainen;Timo Kuisma	1994		10.1109/ICASSP.1994.389226	vocal tract;propagation delay;sampling;approximation error;speech recognition;oversampling;digital filter;degradation;lagrange polynomial;interpolation;waveguide filter;computer science;finite impulse response;mathematics;speech synthesis;sampling;intelligibility;bandwidth;statistics	EDA	86.40587216251717	-32.39823256423697	81213
4b3c389a382dc3f05d8b08b6d58a68db3136b8de	performance evaluation of meaning-based parameter tuning of robot audition		In this paper, meaning-based parameter tuning of robot audition is investigated. Noise reduction system often requires parameter tuning depending on the environment. The typical parameter tuning is executed by error minimization between the target signal and the filter output after noise reduction. However, the target signal is generally unforeknown in advance, and the minimized error does not assure the high recognition rate of speech recognition system. We employ speech recognition system as an evaluation function of parameter tuning to solve the problems. We implemented the system to a human-size humanoid and verified the effectiveness of the proposed method on an experimental basis.	evaluation function;execution;experiment;hearing;humanoid robot;name;noise (electronics);noise reduction;performance evaluation;population parameter;rewriting;speech recognition	Mitsuharu Matsumoto	2017	IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2017.8216488	control engineering;control theory;engineering;noise reduction;evaluation function	Robotics	85.4756108198073	-34.90107997962581	81272
b8c490ad6a2c784c46606b03e8d696856cc8011e	audio source separation using multiple deformed references	nonnegative matrix co factorization guided audio source separation;motion pictures;speech;deformable models;speech source separation motion pictures deformable models tv adaptation models matrix decomposition;information sharing audio source separation multiple audio deformed references nonnegative matrix co factorization algorithm music plus voice mixtures voice references signal to distortion ratio sdr;matrix decomposition;source separation audio signal processing matrix decomposition;tv;adaptation models;source separation	This paper deals with audio source separation guided by multiple audio references. We present a general framework where additional audio references for one or more sources of a given mixture are available. Each audio reference is another mixture which is supposed to contain at least one source similar to one of the target sources. Deformations between the sources of interest and their references are modeled in a general manner. A nonnegative matrix co-factorization algorithm is used which allows sharing of information between the considered mixtures. We run our algorithm on music plus voice mixtures with music and/or voice references. Applied on movies and TV series data, our algorithm improves the signal-to-distortion ratio (SDR) of the sources with the lowest intensity by 9 to 12 decibels with respect to original mixture.	algorithm;decibel;distortion;etsi satellite digital radio;source separation	Nathan Souvira√†-Labastie;Ana√Øk Olivero;Emmanuel Vincent;Fr√©d√©ric Bimbot	2014	2014 22nd European Signal Processing Conference (EUSIPCO)		speech recognition;computer science;multimedia;audio signal flow;communication	Graphics	83.60406857528567	-35.22755995049499	81722
0580855e0c74b58aed0f10374871d49a51557ee4	a broadband beamformer using controllable constraints and minimum variance	array signal processing;microphone arrays;speech processing;lcmv beamformers;mvdr beamformer;snr;broadband beamformer;controllable constraints;interference rejection;linear constraints;linearly constrained minimum variance;microphone arrays;microphones;minimum variance distortionless response;noise reduction;signal-to-noise ratio;speech processing applications;lcmv;mvdr;microphone arrays;controllable beamformer;frequency-domain beamforming	The minimum variance distortionless response (MVDR) and the linearly constrained minimum variance (LCMV) beamformers are two optimal approaches in the sense of noise reduction. The LCMV beamformer can also reject interferers using linear constraints at the expense of reducing the degree of freedom in a limited number of microphones. However, it may magnify noise that causes a lower output signal-to-noise ratio (SNR) than the MVDR beamformer. Contrarily, the MVDR beamformer suffers from interference in output. In this paper, we propose a controllable LCMV (C-LCMV) beamformer based on the principles of both the MVDR and LCMV beamformers. The C-LCMV approach can control a compromise between noise reduction and interference rejection. Simulation results show that the C-LCMV beamformer outperforms the MVDR beamformer in interference rejection, and the LCMV beamformer in background noise reduction.	beamforming;interference (communication);microphone;noise reduction;rejection sampling;signal-to-noise ratio;simulation	Sam Karimian-Azari;Jacob Benesty;Jesper Rindom Jensen;Mads Gr√¶sb√∏ll Christensen	2014	2014 22nd European Signal Processing Conference (EUSIPCO)		electronic engineering;speech recognition;acoustics;noise-canceling microphone;adaptive beamformer	EDA	84.39950248892737	-34.44612544060014	81991
d5b971e6ed74e391364e74037994c3d3aa7c9138	sequential and direct access of head-related transfer functions (hrtfs) for quasi-continuous angular positions	transfer functions headphones least mean squares methods sound reproduction;azimuth;least squares approximations;interpolation;least squares approximations computational complexity interpolation accuracy rendering computer graphics azimuth;head related transfer function hrtf direct access sequential hrtf least mean square perfect sequence lms based hrtf arbitrary azimuthal position sequentially recursive adaptation process system identification approach quasiinfinite azimuthal resolution angular resolution sound source stereo headphone soundfield reproduction binaural rendering quasicontinuous angular position;accuracy;computational complexity;rendering computer graphics	Binaural rendering is based on head-related transfer functions (HRTFs) to reproduce the soundfield around the listener using stereo-headphones. Especially, for the perception of moving sound sources, a high angular resolution of the measured HRTFs is needed. A continuous HRTF representation with quasi-infinite azimuthal resolution can be obtained with a system identification approach which relies on a sequentially recursive adaptation process. As a consequence, it enables by nature the sequential access of HRTFs, e.g., for the virtualization of rotating sound sources. However, so far the direct access of a HRTF of an arbitrary azimuthal position, for a sudden change of the sound source position, is not possible without knowledge of neighboring HRTFs. To overcome this limitation, we present a new implementation strategy enabling a flexible, i.e., a sequential and direct, access of `Perfect Sequence LMS based HRTFs'. We will prove that we obtain numerically the same high-quality HRTFs as before, without increase of storage requirements, and a significantly reduced computational complexity.	algorithm;angularjs;binaural beats;computational complexity theory;covox speech thing;fits;head-related transfer function;headphones;iteration;numerical analysis;quasiperiodicity;random access;real-time clock;recursion (computer science);requirement;sequential access;system identification	Christiane Antweiler;Peter Vary	2011	2011 19th European Signal Processing Conference		computer vision;speech recognition;acoustics;computer science	EDA	87.27133571399796	-33.95765866361921	82281
9d84c546a9f70fc159a1603a0279c40647c0d032	likelihood-maximizing beamforming for robust hands-free speech recognition	reverberation;array processing;robust speech recognition;optimisation;beam forming;maximum likelihood;acoustic reverberation;adaptive filtering;filtrado adaptable;maximum vraisemblance;additive noise;microfono;array signal processing speech recognition speech enhancement distortion microphone arrays noise robustness degradation additive noise reverberation process design;distant talking environments;array signal processing;indexing terms;filter and sum beamformer likelihood maximizing beamforming hands free speech recognition additive noise reverberation microphone array processing signal enhancement feature extraction feature recognition;reduccion ruido;microphone array processing;formation voie;reconocimiento voz;microphone array;feature extraction;noise reduction;traitement signal reseau;reverberacion acustica;optimisation speech recognition noise reverberation array signal processing feature extraction;reduction bruit;speech recognition;filtrage adaptatif;reconnaissance parole;beamforming;reverberation acoustique;algorithm design;adaptive filter;maxima verosimilitud;formacion haz;noise;microphone	Speech recognition performance degrades significantly in distant-talking environments, where the speech signals can be severely distorted by additive noise and reverberation. In such environments, the use of microphone arrays has been proposed as a means of improving the quality of captured speech signals. Currently, microphone-array-based speech recognition is performed in two independent stages: array processing and then recognition. Array processing algorithms, designed for signal enhancement, are applied in order to reduce the distortion in the speech waveform prior to feature extraction and recognition. This approach assumes that improving the quality of the speech waveform will necessarily result in improved recognition performance and ignores the manner in which speech recognition systems operate. In this paper a new approach to microphone-array processing is proposed in which the goal of the array processing is not to generate an enhanced output waveform but rather to generate a sequence of features which maximizes the likelihood of generating the correct hypothesis. In this approach, called likelihood-maximizing beamforming, information from the speech recognition system itself is used to optimize a filter-and-sum beamformer. Speech recognition experiments performed in a real distant-talking environment confirm the efficacy of the proposed approach.	additive white gaussian noise;algorithm;array processing;beamforming;distortion;experiment;feature extraction;microphone;speech recognition;utility functions on indivisible goods;waveform	Michael L. Seltzer;Bhiksha Raj;Richard M. Stern	2004	IEEE Transactions on Speech and Audio Processing	10.1109/TSA.2004.832988	voice activity detection;adaptive filter;speaker recognition;linear predictive coding;speech recognition;acoustics;computer science;speech coding;speech processing;acoustic model;beamforming	ML	83.66395933970949	-33.90618813271753	82435
ea1c3fbf3ebea65d8a40eeb8ce344dc46d81c9f2	real-time and near-real-time acquisition systems for measuring aliasing in small arrays based on crystal microstructures	antenna arrays real time systems multiple signal classification signal processing algorithms global positioning system direction of arrival estimation antenna measurements;signal classification crystal microstructure direction of arrival estimation;direction of arrival antennas;signal classification;motion dynamic scenario near real time acquisition systems small arrays crystal microstructures direction of arrival estimation volumetric arrays planar array music algorithm multiple signal classification algorithm lattice configurations antenna arrays static dynamic scenario;crystal microstructure;direction of arrival estimation	Planar and volumetric arrays are for their ability to mitigate aliasing in direction of arrival (DOA) estimation using the multiple signal classification (MUSIC) algorithm. The arrangements of elements within the array are based on classic array topologies and lattice configurations native to crystal microstructures. Both an eight channel switched configuration for near-real-time measurements and a simultaneous eight channel acquisition system for real-time evaluation of DOA estimations are used to evaluate these different antenna arrays for both static and motion-dynamic scenarios.	algorithm;aliasing;direction of arrival;music (algorithm);real-time clock;real-time computing	Zhenglong Xia;N. Brennan;Jean-Fran√ßois Chamberland;Gregory H. Huff	2013	2013 IEEE Radio and Wireless Symposium	10.1109/RWS.2013.6486642	embedded system;electronic engineering;real-time computing;angle of arrival;engineering;smart antenna;direction of arrival;sensor array	Embedded	86.39057742857334	-42.56803937926029	82726
4aa6d85bbbba52c05ad1548578b84d47919dc53c	hybrid bs-is particle filter based acoustic source tracking algorithm	hybrid bs is particle filter importance sampling bootstrap sampling reverberant environment moving acoustic source tracking acoustic source tracking algorithm;tracking filters acoustic signal processing particle filtering numerical methods signal sampling;signal processing algorithms reverberation estimation switches particle filters arrays	Tracking moving acoustic sources in a reverberant environment has been a challenging research goal for many years. The Bayesian Filtering approach, in particular the Bootstrap (BS) and the Importance Sampling (IS) based Particle Filter (PF) tracking algorithms, has been proposed recently and promising results have been obtained. While these two algorithms out-perform other algorithms, they can only implement the optimal importance function in respective sub-optimal form and suffer related drawbacks in tracking performances. A novel hybrid BS-IS Particle Filter based acoustic source tracking algorithm is proposed in this paper. The height of the target source is used to control a sampling switch importance function that allows the tracking algorithm to switch between using the BS based and the IS based algorithm. Numerical result shows that the proposed algorithm is able to out-perform the BS and the IS based tracking algorithms in reverberant environments.	acoustic cryptanalysis;algorithm;bootstrapping (statistics);importance sampling;microphone;numerical method;pf (firewall);particle filter;performance;sampling (signal processing);source tracking	Nannan Li;Wee Ser	2008	2008 16th European Signal Processing Conference		electronic engineering;speech recognition;engineering;control theory	Robotics	85.65932750537293	-36.9042295836635	82888
a6e490f3867ade7ed890665c3001230563a81c42	modal analysis based beamforming for nearfield or farfield speaker localization in robotics	mobile robot;series expansion;path planning;linear array;mobile robots;convex optimization;array signal processing;path planning array signal processing mobile robots modal analysis;sound source localization modal analysis beamforming nearfield speaker localization farfield speaker localization broadband beampattern synthesis mobile robot small size linear array;sound source localization;modal analysis array signal processing frequency microphone arrays mobile robots optimization methods intelligent robots analytical models delay robot sensing systems;modal analysis	This paper describes a broadband beampattern synthesis method for sound source localization in the nearfield or in the farfield of a mobile robot, with a small-size linear array. The method is based on the theory of modal analysis and involves an original convex optimization procedure which benefits from the Parseval relation. The optimized beampattern is obtained by numerically minimizing the worst-case error between the modal coefficients of the array response and those of the reference beampattern, up to a finite rank of the series expansion, over a frequency grid. Simulations illustrate the analytical development	algorithm;beamforming;best, worst and average case;coefficient;computer simulation;convex optimization;covox speech thing;human‚Äìrobot interaction;mathematical optimization;microphone;mobile robot;modal logic;numerical analysis;real-time transcription;requirement;robotics;series expansion;speech recognition	Sylvain Argentieri;Patrick Dan√®s;Philippe Sou√®res	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.281739	mobile robot;electronic engineering;convex optimization;speech recognition;acoustics;computer science;engineering;artificial intelligence	Robotics	85.5285404010024	-35.75314736248902	83631
3368470c384f30872cd01cb901086ac2cdaabf42	cvsd to lpc conversion using noise tolerant analysis	linear estimation;wideband;continuous variable;working environment noise;unbiased estimator;speech;yield estimation;delta modulation;linear prediction coding;linear predictive coding;tolerance analysis;linear predictive coding speech working environment noise costs delta modulation yield estimation wideband narrowband predictive models hardware;predictive models;speech communication;narrowband;hardware	Due to the increasing sophisitication and decreasing cost of digital hardware, an all-digital speech communication network is being considered for implementation. Subject to bandwidth limitations, present plans call for both 16 Kilobit Continuously Variable Slope Delta Modulation (CVSD) as well as 2.4 Kilobit Linear Predictive Coding (LPC) terminals. Hence the conversion of CVSD to LPC and vice versa arises naturally in this environment. This paper will focus on the CVSD to LPC conversion problem. After a brief discussion of the component system environments, a structure for the format conversion system will be proposed. Since previous work has shown that pitch and voicing decisions can be made on the CVSD observations, the presentation will focus on the identification of LPC predictor coefficients from the noisily observed CVSD data. The remainder of the paper centers on this and the coefficient correction problem, and a new class of linear estimators is shown to yield conditionally unbiased estimates of the LPC coefficients in both noisy and noiseless environments.	continuously variable slope delta modulation	J. D. Tomcik;James L. Melsa	1980		10.1109/ICASSP.1980.1170831	speech recognition;telecommunications;computer science;speech	NLP	83.14692102812383	-31.647016342928197	83950
86ebf45e3a617946b41fba5e87bba3351e0db394	music signal separation based on bayesian spectral amplitude estimator with automatic target prior adaptation	interference speech source separation spectrogram multiple signal classification estimation speech processing;music audio signal processing bayes methods higher order statistics least mean squares methods;online target signal music signal separation bayesian spectral amplitude estimator automatic target prior adaptation automatic prior adaptation generalized mmse stsa estimator nmf based dynamic interference spectrogram estimator closed form parameter estimation higher order statistics statistical model parameter hidden target signal;higher order statistics music signal separation mmse stsa estimator nmf	In this paper, we propose a new approach for addressing music signal separation based on the generalized Bayesian estimator with automatic prior adaptation. This method consists of three parts, namely, the generalized MMSE-STSA estimator with a flexible target signal prior, the NMF-based dynamic interference spectrogram estimator, and closed-form parameter estimation for the statistical model of the target signal based on higher-order statistics. The statistical model parameter of the hidden target signal can be detected automatically for optimal Bayesian estimation with online target-signal prior adaptation. Our experimental evaluation can show the efficacy of the proposed method.	estimation theory;interference (communication);non-negative matrix factorization;spectrogram;statistical model	Yuki Murota;Daichi Kitamura;Shunsuke Nakai;Hiroshi Saruwatari;Satoshi Nakamura;Yu Takahashi;Kazunobu Kondo	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6855056	minimum mean square error;minimax estimator;speech recognition;bayes estimator;computer science;pattern recognition;statistics	Robotics	82.98604562742868	-36.236815432753765	84017
aa8a0d28321c32f051659ab8cd842105962a9890	digital imaging based measurement of diesel spray characteristics	direct photographic imaging;flash light source;digital images spraying fuels high resolution imaging optical imaging image processing image analysis charge coupled devices charge coupled image sensors light sources;charge coupled image sensors;spraying;ccd camera;rails;sprays ccd image sensors diesel engines fuel systems image processing;tip penetration;quantitative diesel spray characterization;high resolution;mechanical engineering computing;image processing;digital imaging based measurement;spray characteristics;image processing system;high resolution imaging;digital imaging;spray characteristics digital imaging common rail fuel injection diesel spray;charge coupled devices;spray characteristics common rail fuel injection diesel spray digital imaging image analysis;fuel systems;spray tip velocity;ccd image sensors;common rail fuel injection rig digital imaging based measurement direct photographic imaging image processing system quantitative diesel spray characterization high resolution charge coupled device camera flashlight source optically accessible constant volume chamber macroscopic characteristic parameters tip penetration spray tip velocity average fuel area density;high resolution ccd camera;optical imaging;injection conditions;fuels;fuel injection rig;flashlight source;sprays;optically accessible chamber;common rail fuel injection;common rail fuel injection rig;ta1637 image analysis;injection conditions digital imaging diesel spray characteristics direct photographic imaging image processing system high resolution ccd camera flash light source spray images optically accessible chamber constant volume chamber tip penetration spray tip velocity fuel area density fuel injection rig;constant volume chamber;digital images spraying fuels high resolution imaging optical imaging image processing charge coupled devices charge coupled image sensors optical devices rails;image analysis;ta166 instrumentation;charged couple device;digital image	This paper presents the application of a direct photographic imaging and image processing system in the quantitative characterization of diesel sprays. A high-resolution charge-coupled device (CCD) camera with a flashlight source is used to capture images of sprays in an optically accessible constant-volume chamber. A set of macroscopic characteristic parameters of the sprays, including tip penetration, near- and far-field angles, spray-tip velocity, and average fuel area density, is derived from the images. Experimental work was undertaken on a common rail fuel injection rig. The relationships between the spray characteristics and the corresponding injection conditions are presented and discussed.	algorithm;charge-coupled device;diesel;digital image processing;digital imaging;experimental system;image resolution;process (computing);repeatability;velocity (software development)	Jiaqing Shao;Yong Yan	2008	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2008.919010	computer vision;electronic engineering;image analysis;image processing;computer science;engineering;forensic engineering;charge-coupled device;digital image;physics	Visualization	89.94518505307552	-24.90184664823184	84903
0676bdce9f200cbefac8c3995edf930e6dabf293	wideband doa estimation in dispersive medium	optimisation;underwater acoustic communication direction of arrival estimation optimisation;underwater acoustic communication;dispersion estimation vectors direction of arrival estimation arrays wideband;source directions wideband doa estimation dispersive medium direction of arrival estimation underwater acoustic applications speed profile source bandwidth soft derivative constraint optimization problem;direction of arrival estimation	The problem of direction-of-arrival (DOA) estimation in dispersive medium is considered in this work. For accurate localization of the sources in seismic and underwater acoustic applications, speed profile is estimated and employed. In contrast to this approach, we propose a new algorithm for wideband DOA estimation with unknown speed profile across the source bandwidth. This insensitivity to dispersion is accomplished by incorporating soft derivative constraint into the optimization problem. The presented simulations exhibit the effectiveness of the proposed algorithm in estimating the source directions in dispersive medium.	acoustic cryptanalysis;algorithm;direction of arrival;dispersive partial differential equation;mathematical optimization;optimization problem;simulation;ultra-wideband	Vinod V. Reddy;Boon Poh Ng;Andy W. H. Khong	2013	2013 9th International Conference on Information, Communications & Signal Processing	10.1109/ICICS.2013.6782866	underwater acoustic communication;telecommunications	Robotics	85.70184863997562	-37.05681301567599	85003
6bbf47e0456af454d619c796e92e8d46360e8d12	radio frequency identification (rfid) in medical environment: gaussian derivative frequency modulation (gdfm) as a novel modulation technique with minimal interference properties	transmission power radio frequency identification rfid system medical environment gaussian derivative frequency modulation healthcare contact free identification tracking patient safety wireless communication systems;frequency modulation biomedical measurements radiofrequency identification transponders biomedical equipment medical services;biomedical measurements;radiofrequency;frequency modulation;wireless communication systems;data communication;medical services;algorithms artifacts ecosystem equipment design equipment failure analysis information storage and retrieval normal distribution radio frequency identification device reproducibility of results sensitivity and specificity telecommunications;frequency modulated;medical device;radio frequency identification;patient safety;medical error;transponders;radiofrequency identification biomedical communication frequency modulation health care;radiofrequency identification;biomedical equipment;biomedical communication;health care	Radio Frequency Identification (RFID) systems in healthcare facilitate the possibility of contact-free identification and tracking of patients, medical equipment and medication. Thereby, patient safety will be improved and costs as well as medication errors will be reduced considerably. However, the application of RFID and other wireless communication systems has the potential to cause harmful electromagnetic disturbances on sensitive medical devices. This risk mainly depends on the transmission power and the method of data communication. In this contribution we point out the reasons for such incidents and give proposals to overcome these problems. Therefore a novel modulation and transmission technique called Gaussian Derivative Frequency Modulation (GDFM) is developed. Moreover, we carry out measurements to show the inteference properties of different modulation schemes in comparison to our GDFM.	accidental falls;diode;gaussian blur;hl7publishingsubsection <operations>;interference (communication);medical device incompatibility problem;medical devices;modulation;normal statistical distribution;patients;radio frequency identification device;radio-frequency identification;semiconductor device;semiconductors	Marie Rieche;Tomas Komensky;Peter Husar	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6090410	radio-frequency identification;frequency modulation;electronic engineering;telecommunications;computer science;engineering;transponder;biological engineering;radio frequency;health care	Embedded	93.85874494203844	-24.627920692044682	85157
aa760b18cd04901e4e324ea5482edae557e87a08	spectrum analyzers today and tomorrow: part 1 towards filterbanks-enabled real-time spectrum analysis	spectral analysers channel bank filters fourier transform spectra;radio spectrum management real time systems filter banks fast fourier transforms;fourier transform spectra;channel bank filters;fast fourier transform spectrum analyzers filterbanks enabled real time spectrum analysis spectral composition electrical waveforms acoustic waveforms optical waveforms power spectrum sa architectures;spectral analysers	This is Part 1 of a two-part article on spectrum analyzer technology and the future capabilities enabled by introducing filterbanks. A spectrum analyzer (SA) is the primary tool for studying the spectral composition of many electrical, acoustic or optical waveforms. It displays a power spectrum over a given frequency range, changing the display as the properties of the signal change. Today, it is an essential element of the engineer's toolbox. In this part, we will start by reviewing SA architectures in an historical perspective. The architectures and working principles of swept based and Fast Fourier Transform (FFT)-based SAs are discussed. Then, we zoom in on the so-called Real-Time Spectrum Analyzers (RTSA) and discuss the more significant performance criteria as a function of the measurement problem at hand. In the last section, we discuss several applications made possible by RTSA. The extension of RTSA with filterbanks is the main topic of Part 2 of this article which will appear in the December 2013 issue of the IEEE Instrumentation and Measurement Magazine.	acoustic cryptanalysis;fast fourier transform;frequency band;measurement problem;real-time clock;real-time transcription;spectral density;spectrum analyzer;stationary process	Adnan Al-Adnani;Jonathan Duplicy;Lieven Philips	2013	IEEE Instrumentation & Measurement Magazine	10.1109/MIM.2013.6616284	electronic engineering;spectrum analyzer;telecommunications;engineering;electrical engineering;signal analyzer;spectral density	Embedded	84.23592170005651	-39.6528986239278	85204
3898b07c8c0f443fb98695fc45d8be886c872989	phase-only multidimensional spatio-temporal analysis for moving sources	spatio temporal analysis;estimation theory;interpolation;multidimensional systems sensor arrays frequency estimation array signal processing motion analysis motion estimation interpolation sonar detection target tracking underwater acoustics;underwater sound;sonar source motion parameters multidimensional spatio temporal analysis phase only analysis underwater acoustic applications spatio temporal data spatial frequencies relative phase shifts interpolation moving sources parameter estimation spatial frequency rate array processing;frequency estimation;motion estimation;phase shift;array signal processing;spatio temporal data;underwater sound sonar signal processing array signal processing motion estimation interpolation estimation theory frequency estimation;sonar signal processing;underwater acoustics;spatial frequency	The estimation of source motion parameters takes a considerable importance for many areas. Especially for underwater acoustic applications where a large amount of data is available. This paper deals with the estimation of source motion parameters directly from the spatio-temporal data. A general frame for a separate estimation of the spatial frequencies and spatial freq-rate is presented, avoiding thus the dramatic interference problems. One basic idea consists in using basically the relative phase shifts without any consideration of source powers. The other consists in considering interpolation a s a basic tool for spatia-temporal analysis.	acoustic cryptanalysis;general frame;interference (communication);interpolation	Jean-Pierre Le Cadre;Olivier Tr√©mois	1994		10.1109/ICASSP.1994.389783	computer vision;underwater acoustics;speech recognition;interpolation;motion estimation;phase;spatial frequency;estimation theory;statistics	Graphics	86.42693485484253	-38.50725722747786	85317
7159caa1c615eeb6e5209f36c6c5aeb4825d2df3	abnormal sound detection by two microphones using virtual microphone technique		In this paper, we propose a new method of microphone array signal processing for detecting abnormal sounds that is applicable to monitoring elderly people at home and can be implemented on small equipment. This method consists of noise reduction based on a subspace method and sound activity detection (SAD), which is the same as voice activity detection using the signal power. The performance of noise reduction may degrade for underdetermined conditions (the number of microphones is less than that of sound sources). To resolve this issue, we previously proposed a technique of microphone array signal processing that introduced virtual microphones. In this method, signals of virtual microphones are interpolated with those of real ones. By using both real and virtual microphones, this noise reduction method can be applied for a critical / overdetermined condition. In this paper, we apply this method to the subspace method for the first time. After noise reduction, the abnormal sounds can be detected by the SAD method. We conducted an experiment and confirm that the proposed method is effective for detecting abnormal sounds in noisy environments and is robust to abnormal sound directions.	direction of arrival;interpolation;microphone;noise reduction;sensor;signal processing;simulation;ti advanced scientific computer;voice activity detection	Kouei Yamaoka;Nobutaka Ono;Shoji Makino;Takeshi Yamada	2017	2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)	10.1109/APSIPA.2017.8282079	voice activity detection;noise reduction;microphone array;acoustics;underdetermined system;signal processing;subspace topology;microphone;sound detection;computer science	EDA	84.6249892650967	-36.58683338705878	85501
bb137e578fa0209c442142fab4e874514484e5ab	outlier detection in gnss pseudo-range/doppler measurements for robust localization	global navigation satellite systems gnss;robust localization;rao blackwellization;particle filter;a contrario decision	In urban areas or space-constrained environments with obstacles, vehicle localization using Global Navigation Satellite System (GNSS) data is hindered by Non-Line Of Sight (NLOS) and multipath receptions. These phenomena induce faulty data that disrupt the precise localization of the GNSS receiver. In this study, we detect the outliers among the observations, Pseudo-Range (PR) and/or Doppler measurements, and we evaluate how discarding them improves the localization. We specify a contrario modeling for GNSS raw data to derive an algorithm that partitions the dataset between inliers and outliers. Then, only the inlier data are considered in the localization process performed either through a classical Particle Filter (PF) or a Rao-Blackwellization (RB) approach. Both localization algorithms exclusively use GNSS data, but they differ by the way Doppler measurements are processed. An experiment has been performed with a GPS receiver aboard a vehicle. Results show that the proposed algorithms are able to detect the 'outliers' in the raw data while being robust to non-Gaussian noise and to intermittent satellite blockage. We compare the performance results achieved either estimating only PR outliers or estimating both PR and Doppler outliers. The best localization is achieved using the RB approach coupled with PR-Doppler outlier estimation.	aoc2 protein, human;alcohol use inventory;anomaly detection;arabic numeral 0;assumed;attachment unit interface;cns disorder;cr rao advanced institute of mathematics, statistics and computer science;clock drift;coefficient;computation;conflict (psychology);doppler effect;estimated;experiment;fc epsilon ri + rii ab:acnc:pt:ser:qn;galileo (satellite navigation);gauss;gauss‚Äìnewton algorithm;global positioning system;gray platelet syndrome;international system of units;intestinal pseudo-obstruction;jacobian matrix and determinant;linear function;mathematical optimization;matrix regularization;multipath propagation;newton;niflumic acid;nondeterministic finite automaton;nonlinear system;normal statistical distribution;null value;numerical linear algebra;outlier;parallel computing;particle filter;poly da-dt;population parameter;pruritus ani;pseudo brand of pseudoephedrine;reagents;satellite navigation;seizures;silo (dataset);solver;uridine;velocity (software development);algorithm;travel	Salim Zair;Sylvie Le H√©garat-Mascle;Emmanuel Seignez	2016		10.3390/s16040580	electronic engineering;particle filter;telecommunications;computer science;statistics;remote sensing	ML	85.28111514813241	-42.21656854054011	85683
a9d556df15ecd99c8d5b7465bb14d24cb031ebc6	frequency estimation of satellite-based automatic identification system signals			automatic identification and data capture;spectral density estimation	Shexiang Ma;Xingjie Guo	2016	J. Comput. Meth. in Science and Engineering	10.3233/JCM-160599	computer vision;satellite;artificial intelligence;computer science;automatic identification system	Logic	84.55912013515467	-42.23584625967958	85722
6df621ddd83c6acb708f0bb1136e270eb81b22a5	delayed adaptation for improved doubletalk resilience in adaptive echo cancellers	echo cancellation;delayed adaptation;least mean squares methods;nlms adaptive echo cancellation delayed adaptation doubletalk detection;cross correlation;acoustic signal processing;nlms;doubletalk detector algorithms delayed adaptation doubletalk resilience adaptive echo cancellers near end speech nlms cross correlation;adaptive algorithm;adaptive signal processing;doubletalk detection;adaptive echo cancellation;echo suppression;least mean squares methods acoustic signal processing adaptive signal processing echo suppression;near end speech;doubletalk detector algorithms;adaptive echo cancellers;resilience echo cancellers detectors delay effects speech filters costs background noise statistics algorithm design and analysis;doubletalk resilience	This paper proposes a simple modification to adaptive echo cancellers to prevent rapid divergence due to doubletalk conditions. The proposed structure introduces a delay only into the adaptation algorithm, which compensates for doubletalk detector response time at the onset of near-end speech. The structure is described and analyzed for the NLMS and cross-correlation-based doubletalk detector algorithms. The method introduces no delay into the return path, and no additional constraints on adaptation step size arise. Simulations with ITU-T Q. 168 tests confirm that the proposed structure prevents divergence at the onset of doubletalk for near-end to echo signal ratios of-26 to -6 dB.	algorithm;bounce address;computer simulation;cross-correlation;echo (command);least mean squares filter;onset (audio);response time (technology)	James D. Gordy;Franck Beaucoup;Rafik A. Goubran	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4517593	adaptive filter;speech recognition;computer science;cross-correlation;mathematics;statistics	Robotics	83.67303849578806	-32.42050390586733	85732
a81ee74adef2c79819c9680799c1db6cb4dcc1a2	multi-stage rejection sampling (msrs): a robust srp-phat peak detection algorithm for localization of cocktail-party talkers	indexes robustness signal processing algorithms microphones correlation clustering algorithms acoustics;microphones;acoustics;peak detection microphone array source localization talker localization cocktail party srp phat steered response power region contraction volume contraction;indexes;clustering algorithms;robustness;correlation;signal processing algorithms	The Steered Response Power using the Phase Transform weight (SRP-PHAT) has been shown to be robust in noisy and reverberant conditions. Also, volume contraction has been applied effectively to trap the global maximum for densely-hilly 3-D spaces like the SRP. However, previous methods have suffered from the presence of peaks representing multiple talkers in close proximity as is likely in a conversational cocktail-party setting. We present a volume contraction algorithm called Multi-Stage Rejection Sampling (MSRS) for detection of multiple peaks in the SRP-PHAT space. Our method not only circumvents sorting - a computationally expensive step in volume contraction algorithms - but also automatically divides a search volume into sub-volumes for robust detection of multiple peaks. We discuss some modifications to the standard SRP-PHAT functional and present results using all real-room data for baseline white-noise, an eight-speaker teleconferencing setup and a fully unconstrained cocktail-party situation containing about 21 persons in the room.	algorithm;analysis of algorithms;baseline (configuration management);maxima and minima;model-specific register;rejection sampling;scsi rdma protocol;sampling (signal processing);sorting;white noise	Sarthak Khanal;Harvey F. Silverman	2015	2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)	10.1109/WASPAA.2015.7336887	database index;electronic engineering;speech recognition;acoustics;computer science;cluster analysis;correlation;robustness	Vision	85.5798007156846	-36.31030906277798	86010
5b402b36f4b18f69853aaa8207449d146aaf8718	aim: acoustic imaging on a mobile		The popularity of smartphones has grown at an unprecedented rate, which makes smartphone based imaging especially appealing. In this paper, we develop a novel acoustic imaging system using only an off-the-shelf smartphone. It is an attractive alternative to camera based imaging under darkness and obstruction. Our system is based on Synthetic Aperture Radar (SAR). To image an object, a user moves a phone along a predefined trajectory to mimic a virtual sensor array. SAR based imaging poses several new challenges in our context, including strong self and background interference, deviation from the desired trajectory due to hand jitters, and severe speaker/microphone distortion. We address these challenges by developing a 2-stage interference cancellation scheme, a new algorithm to compensate trajectory errors, and an effective method to minimize the impact of signal distortion. We implement a proof-of-concept system on Samsung S7. Our results demonstrate the feasibility and effectiveness of acoustic imaging on a mobile.	aim alliance;acoustic cryptanalysis;algorithm;aperture (software);carrier frequency;digital data;distortion;effective method;error detection and correction;experiment;gaussian blur;ibm notes;image quality;interference (communication);microphone;robertson‚Äìseymour theorem;smartphone	Wenguang Mao;Mei Wang;Lili Qiu	2018		10.1145/3210240.3210325	single antenna interference cancellation;microphone;real-time computing;computer science;distortion;sensor array;synthetic aperture radar;effective method;autofocus;trajectory	Mobile	86.60657888431598	-40.33149816789017	86085
d989e6518f0712d706d72405695dd8a519a806c9	sound field reproduction using planar and linear arrays of loudspeakers	discretisation;metodo espectral;approximation lineaire;spatial frequency domain;ambisonics;far field;reproduccion sonido;spatial fourier transform;linear arrays;fourier transform;reproduction son;signal audio;implementation;aliasing;frequency domain analysis;campo lejano;linear array;audio signal;spatial fourier transform ambisonics spatial aliasing spectral division method wave field synthesis;discretization;linear approximation;loudspeaker;exact results;champ lointain;speech;discretizacion;sound reproduction acoustic field fourier transforms loudspeakers;acoustic signal processing;sound reproduction;acoustic field;spatial aliasing;time domain analysis;linear antenna arrays;spectral division method;antenne reseau lineaire;antenne reseau plane;loudspeakers;methode domaine frequence;fourier transformation;frequency domain method;haut parleur;frequence spatiale;fourier transforms;reproduction equation;aproximacion lineal;transformation fourier;spectral method;signal acoustique;altoparlante;methode spectrale;wave field synthesis;approximation methods;loudspeakers signal synthesis production frequency domain analysis linear approximation acoustic propagation fourier transforms integral equations usability laboratories;acoustic signal;traitement signal acoustique;metodo dominio frecuencia;frecuencia espacial;spectral analysis;implementacion;planar arrays;audio acoustics;wave field synthesis sound field reproduction planar arrays linear arrays loudspeakers reproduction equation spatial frequency domain;spatial frequency;senal acustica;senal audio;sound field reproduction;repliegue espectro;transformacion fourier;acoustique audio;planar antenna arrays;repliement spectre	In this paper, we consider physical reproduction of sound fields via planar and linear distributions of secondary sources (i.e., loudspeakers). The presented approach employs a formulation of the reproduction equation in spatial frequency domain which is explicitly solved for the secondary source driving signals. Wave field synthesis (WFS), the alternative formulation, can be shown to be equivalent under equal assumptions. Unlike the WFS formulation, the presented approach does not employ a far-field approximation when linear secondary source distributions are considered but provides exact results. We focus on the investigation of the spatial truncation and discretization of the secondary source distribution occurring in real-world implementations and present a rigorous analysis of evanescent and propagating components in the reproduced sound field.	approximation;discretization;evanescent field;loudspeaker;planar (computer graphics);secondary source;truncation	Jens Ahrens;Sascha Spors	2010	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2010.2041106	fourier transform;speech recognition;acoustics;mathematics	Visualization	87.91381549351789	-32.48479936769833	86538
b40c4b6c96f99d9b6bfcc8b56813220f7e003f92	noise and range considerations for close-range radar sensing of life signs underwater	sensors;ultrasound;spectrum;low power;monitoring;radar antennas;doppler radar;noise sonar monitoring sensors doppler radar radar antennas;algorithms animals diagnosis computer assisted electrocardiography ambulatory heart rate radar reproducibility of results sensitivity and specificity signal to noise ratio swimming;close range;signal to noise ratio;noise;sonar	Close-range underwater sensing of motion-based life signs can be performed with low power Doppler radar and ultrasound techniques. Corresponding noise and range performance trade-offs are examined here, with regard to choice of frequency and technology. The frequency range examined includes part of the UHF and microwave spectrum. Underwater detection of motion by radar in freshwater and saltwater are demonstrated. Radar measurements exhibited reduced susceptibility to noise as compared to ultrasound. While higher frequency radar exhibited better signal to noise ratio, propagation was superior for lower frequencies. Radar detection of motion through saltwater was also demonstrated at restricted ranges (1‚Äì2 cm) with low power transmission (10 dBm). The results facilitate the establishment of guidelines for optimal choice in technology for the underwater measurement motion-based life signs, with respect to trade offs involving range and noise.	aquatic ecosystem;dbm;frequency band;image noise;metabolic process, cellular;microwave;monitoring, physiologic;radar;signal-to-noise ratio;software propagation;ultra high frequency;ultrasonography	Noah Hafner;Victor M. Lubecke	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6089892	spectrum;continuous-wave radar;pulse compression;electronic engineering;radar engineering details;radiology;acoustics;telecommunications;engineering;sensor;noise;low probability of intercept radar;pulse repetition frequency;ultrasound;pulse-doppler radar;signal-to-noise ratio;radar display;physics;sonar	Robotics	84.77389333495489	-41.04927904440358	86827
a00c350ec5002df551a215e4835c8f6ac22a8668	a background noise reduction technique based on sinusoidal speech coding systems	speech intelligibility;speech coding;speech enhancement;background noise speech enhancement speech coding speech processing signal processing additive noise working environment noise noise reduction vocoders mobile communication;interference suppression;linear prediction coding;random noise;linear predictive coding;noise reduction;vocoders;mobile communication;speech intelligibility speech coding random noise vocoders interference suppression linear predictive coding speech enhancement;second order statistics;harmonic excitation linear predictive coding background noise reduction technique sinusoidal speech coding systems sinusoidal based vocoder speech quality speech intelligibility mobile communications environment speech signals additive random noise signal to background noise ratio low bit rate coding speech enhancement systems	This paper describes a new technique to reduce background noise in speech signals in conjunction with a sinusoidal based vocoder in order to improve the quality and intelligibility of processed speech. In a mobile communications environment, speech signals are degraded by additive random noise. Randomness of the noise, which is often described in terms of its first and second order statistics, makes it difficult to remove without introducing background artifacts. This is particularly true for lower signal to background noise ratios. The technique described in this paper deals with the noise reduction of the vocoded speech signals without any knowledge of the signal to background noise ratio. In general, low bit rate speech coding systems do not have their own mechanism to reduce the background noise from the speech signal. This is due to the complexity of the speech signal and limitations in the scope of many speech coding systems. As a consequence, most speech enhancement systems to date have attempted to process the speech waveform directly and independently from the speech coding system, before the encoding of speech signals. In this paper, we propose a new noise reduction technique which is based upon the harmonic excitation linear predictive coding (HE-LPC) and can be applied to and integrated with any sinusoidal based speech coding algorithm.	noise reduction;speech coding	Suat Yeldener;Jack H. Rieser	2000		10.1109/ICASSP.2000.861840	voice activity detection;selectable mode vocoder;codec2;g.729;linear predictive coding;speech recognition;mobile telephony;vector sum excited linear prediction;harmonic vector excitation coding;computer science;noise measurement;speech coding;noise reduction;speech processing;psqm;intelligibility;code-excited linear prediction	EDA	83.17693694843392	-33.23885331001822	87033
d33ede95542a7066849c2994795856652321378f	electroacoustic distortions: multidimensional analysis of hearing aid transduced speech and music	hearing aids;harmonic distortion;phase noise;speech analysis;auditory system;speech enhancement;frequency response;phase distortion;multidimensional scaling;speech analysis multidimensional systems auditory system speech enhancement harmonic distortion phase distortion hearing aids frequency response bandwidth phase noise;bandwidth;data consistency;multidimensional systems;hearing aid;correlation analysis	The detrimental effects of electroacoustic distortions on quality judgement of speech and music was investigated using a posteriori techniques of multidimensional scaling. Evaluative data consisted of preference and similarity judgments from pairwise presentation of 12 hearing aids to normal listeners. Dimensions derived from proximity matrices were interpreted as electroacoustic distortions. The weighting of these distortions were analyzed and contrasted to correlational analysis. Interactions were present between the speech and music judgments. Frequency response and bandwidth were evidenced as dimensions influencing both speech and music with third harmonic distortion and internal noise being specific to speech, while transient distortions and phase distortion affected listener preception of music.	distortion;multidimensional analysis	A. Yonovitz;Barbara Jill Bickford;Joseph Lozar;Dianne R. Ferrell	1978		10.1109/ICASSP.1978.1170400	frequency response;speech recognition;multidimensional scaling;multidimensional systems;computer science;electrical engineering;phase distortion;total harmonic distortion;data consistency;phase noise;bandwidth	ML	83.79178524101064	-31.49219052156369	87633
58511fe02cdd4affb71bffd1265d54a117398af3	non-cooperative object detection in sea using acoustic sensors	border security;multi frame integration;sensors acoustic signal detection fast fourier transforms hydrophones integration;fast fourier transform acoustic sensor median cfar multi frame integration;median cfar;sensors;hydrophones;acoustics;post integration algorithm;noise boats noise measurement acoustics time frequency analysis frequency estimation;frequency estimation;false alarm rate;integration;noise measurement;fast fourier transform;early warning;sea noncooperative object detection;false alarm rate sea noncooperative object detection acoustic sensor illegal boat arrival border security australian government hydrophone median cfar post integration algorithm acoustic signal;detection rate;acoustic signal detection;fast fourier transforms;illegal boat arrival;acoustic signal;time frequency analysis;australian government;object detection;noise;acoustic sensor;boats;hydrophone	With the increase of illegal boat arrivals, the border security is becoming more and more important for Australian government. This paper is exploring the early warnings by detecting of boat generated signals received by a hydrophone. We focus on algorithm development and real boat generated signal tests. Our experiments have proved that the developed median CFAR and post integration algorithms are very robust for various different acoustic signals, which have a high detection rate while keeping a low false alarm rate.	acoustic cryptanalysis;algorithm;constant false alarm rate;experiment;object detection;sensor;signal processing;white noise	Eric Dahai Cheng;Subhash Challa;Xuanchen Tang;Xiaohu Liu	2010	2010 International Conference on Digital Image Computing: Techniques and Applications	10.1109/DICTA.2010.58	fast fourier transform;speech recognition;telecommunications;computer science	Robotics	83.99106345749436	-41.64509079279806	87838
51edc965954c68cbf57abf6787aa1122c1d0747c	a generalized data-driven speech enhancement framework for bilateral cochlear implants	noise speech cochlear implants speech enhancement distortion measurement optical wavelength conversion;data driven speech enhancement;transfer functions;speech enhancement;environment adaptive noise suppression;distortion;bilateral cochlear implants;transfer functions cochlear implants distortion signal denoising speech enhancement;generalized data driven speech enhancement;environment adaptive noise suppression bilateral cochlear implants data driven speech enhancement generalized data driven speech enhancement;generalized data driven speech enhancement framework weighted cosh distortion measures log euclidean distortion measures weighted euclidean distortion measures unilateral data driven enhancement methods noise environments head related transfer function gain tables single processor environment adaptive noise suppression algorithms bilateral cochlear implants;cochlear implants;signal denoising	This paper examines environment-adaptive noise suppression algorithms for computationally efficient or real-time implementation in bilateral cochlear implants using a single processor. A generalized framework is introduced that allows one to train suppression and head-related transfer function gain tables not only for different noise environments but also for different distortion measures. This generalization incorporates any differentiable measure with unilateral data-driven enhancement methods becoming its special cases. Specifically, the solutions for three distortion measures of Weighted-Euclidean, Log-Euclidean and Weighted-Cosh are provided. These solutions are evaluated in six commonly encountered noise environments for a wide range of directionalities.	algorithm;algorithmic efficiency;bilateral filter;cochlear implant;distortion;head-related transfer function;real-time clock;speech enhancement;zero suppression	Taher S. Mirzahasanloo;Nasser Kehtarnavaz	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6639074	speech recognition;distortion;telecommunications;computer science;transfer function	Robotics	83.86557347680784	-34.3268908852924	87916
37ecd50cd3735c66fde8a326f021f4799ecdc617	temporal orthogonal projection inversion for emi sensing of uxo	vectors noise electromagnetic interference arrays receivers sensitivity tensile stress;unexploded ordance temporal orthogonal projection inversion uxo magnetic dipole polarization buried objects electromagnetic induction spatial temporal response matrix strm time channels singular value decomposition singular vectors signal subspaces noise subspaces nonlinear inverse problem linear optimization problem singular value system topi subspace vectors emi sensor;vectors buried object detection electromagnetic devices electromagnetic induction inverse problems linear programming singular value decomposition;unexploded ordnance uxo electromagnetic induction emi magnetic dipole polarization nonlinear inversion orthogonal projection subspace	We present a new approach for inverting time-domain electromagnetic data to recover the location and magnetic dipole polarizations of a limited number of buried objects. We form the multichannel electromagnetic induction (EMI) sensor data as a spatial-temporal response matrix (STRM). The rows of the STRM correspond to measurements sampled at different time channels from one sensor and the columns correspond to measurements sampled at the same time channel from different sensors. The singular value decomposition of the STRM produces the left and right singular vectors that are related to the sensor and the temporal spaces, respectively. If the effective rank of the STRM is r, then the first r singular vectors span signal subspaces (SS), and the remaining singular vectors span the noise subspaces. The original data are projected onto the SS, and the temporal orthogonal projection inversion (TOPI) uses these data in a nonlinear inverse problem to solve for source locations of the objects. The polarizations of the targets are then obtained by solving a linear optimization problem in the original data domain. We present theoretical and numerical analyses to investigate the singular value system of the STRM and the sensitivity of the TOPI to the size of an SS. Only a few subspace vectors are required to generate locations of the objects. The results are insensitive to the exact choice of rank, and this differs from usual methods that involve selecting the number of time channels to be used in the inversion and carefully estimating associated uncertainties. The proposed approach is evaluated using the synthetic and real multistatic EMI data.	column (database);data domain;emi;linear programming;mathematical optimization;nonlinear system;numerical analysis;optimization problem;sensor;singular value decomposition;synthetic intelligence;value (ethics)	Lin-Ping Song;Douglas Oldenburg;Leonard R. Pasion;Stephen D. Billings;Laurens Beran	2015	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2014.2332992	mathematical optimization;mathematics;optics	ML	87.03342347075905	-38.92371565303604	88366
4eef222aa0c01581c74f39477ab2eecebf2ec41e	speech and crosstalk detection for robust speech recognition using a dual microphone system	crosstalk;speech activity detection;multi channel audio	This paper proposes a practical speech detection technique for robust automatic speech recognition, suitable for use under various interference conditions. This technique consists of a dual microphone system and an algorithm for processing their signals. The microphone module is placed in the workplace of the target speaker. The module consists of two symmetrical supercardioid microphones directed in opposite directions. The algorithm of target speaker detection is proposed for this scheme. This algorithm makes it possible to implement spatial filtering of speakers. Experiments with real recordings demonstrate a significant reduction of speech recognition errors for the target speaker due to suppression of acoustic crosstalk. The main advantage of the proposed technique is simplicity of its use in a wide range of practical situations.	crosstalk;microphone;speech recognition	Mikhail Stolbov;Marina Tatarnikova	2013		10.1007/978-3-319-01931-4_41	voice activity detection;speech recognition;acoustics;engineering;speech processing;communication	Mobile	84.37579269847443	-34.420829300256855	88641
3feae899084c318a93ac721cadcec24e9b2ea642	automatic bioacoustic detection of rhynchophorus ferrugineus	vegetation insects detectors acoustic emission probes noise;signal detection bioacoustics biological techniques biology computing electric sensing devices filtering theory learning artificial intelligence piezoelectric devices portable computers signal classification;real field recordings rhynchophorus ferrugineus bioacoustic automatic detector devastating pest attacking palm trees piezoelectric sensors tree trunk locomotion feeding vibrations insect signal amplification signal filtering signal classification signal parameterization machine learning portable computer	The goal of this project is to research and develop a bio-acoustic automatic detector of a devastating pest attacking palm trees, which has recently appeared in Mediterranean countries. The method is based on piezoelectric sensors that are inserted in the tree trunk and record locomotion and feeding vibrations of the insect. The obtained signals are amplified, filtered, parameterized and automatically classified by advanced machine learning methods on a portable computer. We report excellent detection results reaching 99.5% on real-field recordings.	acoustic cryptanalysis;british informatics olympiad;laptop;machine learning;palm os;piezoelectricity;portable computer;prototype;quickcheck;sensor	Ilyas Potamitis;Todor Ganchev;Nikos Fakotakis	2008	2008 16th European Signal Processing Conference		electronic engineering;simulation;engineering;communication	Robotics	84.54982413757726	-41.87422477785132	88757
ad3f3b5836129c783ebd839c8237a52e827a0cbf	speech reinforcement system for car cabin communications	echo cancellation;speech reinforcement acoustic echo cancellation noise reduction postfiltering speech enhancement;motor vehicles;automobiles;speech echo cancellers filters microphones loudspeakers vehicles acoustic noise noise cancellation noise reduction stability;speech enhancement;power spectral density;number of factors;noise reduction;automobiles speech enhancement echo suppression;echo suppression;spectral estimation;speech enhancement speech reinforcement system car cabin communications visual contact microphones car audio loudspeaker system electroacoustic coupling acoustic echo canceller echo suppression filters noise reduction stages spectral estimation method power spectral density;acoustic echo canceller	A speech reinforcement system is presented to improve communication between the front and the rear passengers in large motor vehicles. This type of communication can be difficult due to a number of factors, including distance between speakers, noise and lack of visual contact. The system described makes use of a set of microphones to pick up the speech of each passenger, then it amplifies these signals and plays them back to the cabin through the car audio loudspeaker system. The two main problems are noise amplification and electro-acoustic coupling between loudspeakers and microphones. To overcome these problems the system uses a set of acoustic echo cancellers, echo suppression filters and noise reduction stages. In this paper, the stability of a speech reinforcement system is studied. We propose a solution based on echo cancellers and residual echo suppression filters. The spectral estimation method for the power spectral density of the residual echo existing after the echo canceller is presented along with the derivation of the optimal residual echo suppression filter. Some results about the performance of the proposed system are also provided.	acoustic coupler;acoustic cryptanalysis;apple a5;apple a7;control theory;decibel;distortion;echo (command);echo (computing);echo suppression and cancellation;filter design;image noise;instability;intelligibility (philosophy);loudspeaker;microphone;modulus of continuity;modulus robot;noise (electronics);noise reduction;real-time clock;simulation;spectral density estimation;transfer function;zero suppression	Alfonso Ortega;Eduardo Lleida;Enrique Masgrau	2005	IEEE Transactions on Speech and Audio Processing	10.1109/TSA.2005.853006	speech recognition;acoustics;computer science;noise reduction;mathematics;spectral density estimation;spectral density;statistics	Robotics	84.69812081645236	-34.134765188601335	89098
82c6f0dfe3460dee0abf86027b81145db7d43767	dynamic signal combining for distributed microphone systems in car environments	car environments;microphones;teleconferencing;speech signal;distributed microphones;radiation detectors;speech;radiation detector;spectrum;speech enhancement;noise measurement;speaker recognition;speaker recognition microphones;signal mixer;background noise spectrum dynamic signal combining distributed microphone systems car environments speech signal speaker channels spectral preprocessing;speaker channels;microphones noise speech noise measurement switches gain control radiation detectors;dynamic signal combining;smooth transition;distributed microphone systems;background noise spectrum;switches;teleconferencing distributed microphones signal mixer speech enhancement;spectral preprocessing;gain control;noise	Distributed microphone systems in cars usually provide dedicated microphones for several speakers where each microphone captures the desired speech signal at the best. The signal quality may differ strongly among the speaker channels depending on the microphone position, the microphone type, the kind of background noise, and the speaker himself. When combining these signals to a weighted mix annoying switching artifacts may result. In this contribution a new dynamic signal mixer is presented that uses spectral preprocessing to compensate both for different speech signal levels and for different background noise levels and colorations. Thus, artifacts are avoided and smooth transitions can be achieved for the various speech level and the background noise spectrum at speaker changes.	colors of noise;microphone;preprocessor;ringing artifacts	Timo Matheja;Markus Buck;Achim Eichentopf	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5947502	speaker recognition;speech recognition;noise-canceling microphone;computer science;particle detector	Robotics	84.19378761117753	-34.08430340879399	89234
0df32f62a8c4bd7710b22cc10dbff26166cd1a3b	adaptive noise cancellation of coupled transmitter burst noise in speech signals for wireless handsets	time division multiple access;telephone sets;additive noise;least squares approximation;magnetic separation time division multiple access adaptive filters least squares approximation telephone sets noise;adaptive filters;magnetic separation;noise reduction;adaptive noise canceller;power reduction;type system;noise	This paper describes an application of adaptive noise cancellation (ANC) in the form of an adaptive multiple notch filter [1‚Äì3], to remove transmitter burst envelope noise that may be induced in high gain audio circuits of a wireless handset device. We exploit the periodicity of TDMA type systems where the transmitter burst envelope is stationary. Since samples of the transmitter burst envelope are correlated to the additive noise that corrupts the sampled speech, we use this as a reference input to the ANC. We may also obtain the reference input by delaying the primary input to de-correlate the speech. The system was simulated using GSM [4] transmit burst model to demonstrate the noise power reduction as a function of adaptation. Preliminary tests using the GSM transmitter burst model indicate at least ‚àí40 dB of noise reduction after ¬Ω second of convergence. The spectral noise characteristics after system convergence are analyzed. We also use a test speech signal to demonstrate the system.	additive white gaussian noise;burst error;burst noise;noise power;noise reduction;quasiperiodicity;stationary process;transmitter;type system;utility functions on indivisible goods	David S. Leeds	2002	2002 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2002.5745515	adaptive filter;gaussian noise;effective input noise temperature;computer vision;noise;speech recognition;type system;telecommunications;noise temperature;computer science;noise measurement;noise;noise;low-noise amplifier;noise reduction;noise;noise figure;noise floor;least squares;time division multiple access;noise	EDA	84.23375701291626	-32.6278235227221	89312
b401f0b183c295ad0d9d9710ebd326154eef6c71	extracting common pulse-like signals from multiple ice core time series	pulse like signals;volcanic eruptions;signal extraction;multiprocess kalman filter;eprints newcastle university;climate forcing;open access;julien gazeaux	To understand the nature and cause of natural climate variability, it is important to possess an accurate estimate of past climate forcings. Direct measurements that are reliable only exist for the past fewdecades. Therefore knowledge of prior variations has to be established based on indirect information derived fromnatural archives. The challenge has always been to find a strict objectivemethod that can identify volcanic events and offer sound amplitude estimates in these noisy records. An automatic procedure is introduced here to estimate the magnitude of strong, but short-lived, volcanic signals from a suite of polar ice core series. Rather than treating records from individual ice cores separately and then averaging their respective magnitudes, our extraction algorithm jointly handles multiple time series to identify their common, but hidden, volcanic pulses. The statistical procedure is based on a multivariate multi-state space model. Exploiting the joint fluctuations, it provides an accurate estimator of the timing, peak magnitude and duration of individual pulse-like deposition events within a set of different series. This ensures a more effective separation of the real signals from spurious noise that can occur in any individual time series, and thus a higher sensitivity to identify smaller scale events. At the same time, it provides ameasure of confidence through the posterior probability for each pulse-like event, indicating how well a pulse can be recognized against the background noise. The flexibility and robustness of our approach, as well as important underlying assumptions and remaining limitations, are discussed by applying our method to first simulated and then real world ice core time series. ¬© 2012 Elsevier B.V. All rights reserved.	algorithm;archive;heart rate variability;physical vapor deposition;simulation;state-space representation;time series	Julien Gazeaux;Deborah Batista;Caspar M. Ammann;Philippe Naveau;Cyrille J√©gat;Chaochao Gao	2013	Computational Statistics & Data Analysis	10.1016/j.csda.2012.01.024	radiative forcing;statistics	ML	83.35404796454023	-51.05007852789923	89609
0b5290e398a0a1e13864ed073f25f5683547dd7d	a fast hrrp synthesis algorithm with sensing dictionary in gtd model	conference;meeting	In the paper, a fast high-resolution range profile synthetic algorithm called orthogonal matching pursuit with sensing dictionary (OMP-SD) is proposed. It formulates the traditional HRRP synthetic to be a sparse approximation problem over redundant dictionary. As it employs a priori that the synthetic range profile (SRP) of targets are sparse, SRP can be accomplished even in presence of data lost. Besides, the computation complexity decreases from O(MNDK) flops for OMP to O(M(N + D)K) flops for OMP-SD by introducing sensing dictionary (SD). Simulation experiments illustrate its advantages both in additive white Gaussian noise (AWGN) and noiseless situation, respectively. Keywords‚ÄîGTD-based model, HRRP, orthogonal matching pursuit, sensing dictionary,.	additive white gaussian noise;algorithm;computation;dictionary;experiment;flops;image resolution;matching pursuit;openmp;simulation;sparse approximation;sparse matrix;synthetic data;synthetic intelligence;uniform theory of diffraction;utility functions on indivisible goods	Rong Fan;Qun Wan;Xiao Zhang;Hui Chen;Yipeng Liu	2012	CoRR		speech recognition;telecommunications;computer science;theoretical computer science;machine learning;mathematics;statistics	Robotics	84.15606796247086	-36.26886817892063	89732
4329e17214f32a72c532b3f7896dcf2c479844ce	performance improvement of tdoa-based speaker localization in joint noisy and reverberant conditions	signal image and speech processing;speaker localization;performance improvement;quantum information technology spintronics;sound source localization	TDOA(time difference of arrival-) based algorithms are common methods for speech source localization. The generalized cross correlation (GCC) method is the most important approach for estimating TDOA between microphone pairs. The performance of this method significantly degrades in the presence of noise and reverberation. This paper addresses the problem of 3D localization in joint noisy and reverberant conditions and a single-speaker scenario. We first propose a modification to make the GCC-PHAse transform (GCC-PHAT) method robust against environment noise. Then, we use an iterative technique that employs location estimation to improve TDOAs accuracy. Extensive experiments on both simulated and real (practical) data (in a single-source scenario) show the capability of the proposed methods to significantly improve TDOA accuracy and, consequently, source location estimates.	cross-correlation;experiment;hybrid algorithm;iterative method;microphone;multilateration;weight function	Hamid Reza Abutalebi;Hossein Momenzadeh	2011	EURASIP J. Adv. Sig. Proc.	10.1155/2011/621390	speech recognition;acoustic source localization	Vision	84.92106937281673	-36.447428014377685	90143
b3cc18678cf700993133ed7271afdf53a22cbf0e	blind speech enhancement using generalized eigenvalue decomposition	conventional blind separation blind speech enhancement generalized eigenvalue decomposition microphone array array calibration;speech enhancement eigenvalues and eigenfunctions independent component analysis microphone arrays;speech enhancement eigenvalues and eigenfunctions abstracts arrays artificial intelligence noise superluminescent diodes	A method of speech enhancement using a microphone array and the generalized eigenvalue decomposition is proposed in this paper. This method is a blind approach which does not require array calibration. The advantage of this method over the conventional blind separation based on the ICA is its fast adaptation. This is verified by a speech enhancement experiment.	array data structure;blind signal separation;decorrelation;independent computing architecture;microphone;noise reduction;speech enhancement	Futoshi Asano;Hideki Asoh	2002	2002 11th European Signal Processing Conference	10.5281/zenodo.38019	electronic engineering;speech recognition;acoustics	Robotics	84.61147632081921	-35.534796495102235	90682
f3b0d2101d72b18e9878bdc296874728ffb8571e	modeling and characteristic analysis of underwater acoustic signal of the accelerating propeller	accelerating propeller;modeling of underwater acoustic signal;chirp periodic signal;simplified fractional fourier transform;accelerating propeller modeling of underwater acoustic signal chirp periodic signal simplified fractional fourier transform	The signal feature of propeller cavitation noise during acceleration or deceleration procedure can be used to passively detect and classify moving vessels and underwater vehicles in the port regions. By analyzing the chirp periodicity of the variation of propeller wake velocity under acceleration situation, this paper presents a time domain expression of the modulation envelope signal of the accelerating propeller noise, treating the signal as a Gaussian-shaped chirp periodic pulse train with increasing trend and fluctuating pulse amplitude. The paper investigates the characteristics of simplified fractional Fourier transform (SFRFT) spectrum of the chirp periodic signal, and thus obtains the relation between the chirp periodic signal and its chirp harmonics under the conditions of underwater passive detection. Furthermore, the experimental data of the cavitation tunnel satisfy the results obtained by simulation, which verifies the correctness of the proposed signal model.	acoustic cryptanalysis;carpal tunnel syndrome;chirp;correctness (computer science);fractional fourier transform;modulation;quasiperiodicity;simulation;velocity (software development)	Yuan Feng;Ran Tao;Yue Wang	2011	Science China Information Sciences	10.1007/s11432-011-4285-9	speech recognition;chirp spread spectrum;chirp	Robotics	84.72602449285931	-39.913528201754325	90765
d693de479a79d69f86ace1e749aa2d8c0b36d526	new beamformers for waveform reconstruction of the correlated eeg sources	array signal processing;signal reconstruction;electroencephalography;signal reconstruction array signal processing electroencephalography medical signal processing;source time course estimation waveform reconstruction correlated eeg sources source locations adaptive beamformers;medical signal processing	This paper presented a method which may reasonably accurately reconstruct time courses of the correlated sources. This method first uses estimates of the source locations to construct a transformation, which removes the correlated interfering sources while retaining the desired sources. Conventional adaptive beamformers is then performed on the transformed data containing only desired sources to obtain accurate source time course estimates. Repeatedly applying the method to each of the correlated sources can accurately reconstruct all the source time courses. Theoretical analysis shows that the proposed method can remove the leakage from the other correlated sources and thus, obtain accurate source time courses estimates. Numerical experiments show that, compared to the conventional adaptive beamformers, the proposed method can reconstruct the source time courses without distortions.	distortion;electroencephalography;experiment;numerical method;spectral leakage;waveform	Junpeng Zhang;Xuyang Huo	2012	2012 5th International Conference on BioMedical Engineering and Informatics	10.1109/BMEI.2012.6512900	signal reconstruction;econometrics;speech recognition;electroencephalography;computer science	DB	82.9198748740442	-38.66798791445239	90963
6cdc82858be5444b7d8594af12b8e2b4efbe4d63	3d beam tracing based on visibility lookup for interactive acoustic modeling	visibility computation acoustic simulation room acoustics beam tracing;beam tree data structure 3d beam tracing visibility lookup interactive acoustic modeling complex 3d enclosures acoustic beam tracing iterative lookup process visibility data structure pluÃàcker parameterization iterative intersection path determination phase;acoustics;geometry;receivers;computational modeling;visibility computation;three dimensional displays;data structures;acoustic simulation;acoustic beams acoustics three dimensional displays computational modeling geometry data structures receivers;acoustic beams;room acoustics;tree data structures computational geometry solid modelling;beam tracing	We present a method for accelerating the computation of specular reflections in complex 3D enclosures, based on acoustic beam tracing. Our method constructs the beam tree on the fly through an iterative lookup process of a precomputed data structure that collects the information on the exact mutual visibility among all reflectors in the environment (region-to-region visibility). This information is encoded in the form of visibility regions that are conveniently represented in the space of acoustic rays using the PluÃàcker coordinates. During the beam tracing phase, the visibility of the environment from the source position (the beam tree) is evaluated by traversing the precomputed visibility data structure and testing the presence of beams inside the visibility regions. The PluÃàcker parameterization simplifies this procedure and reduces its computational burden, as it turns out to be an iterative intersection of linear subspaces. Similarly, during the path determination phase, acoustic paths are found by testing their presence within the nodes of the beam tree data structure. The simulations show that, with an average computation time per beam in the order of a dozen of microseconds, the proposed method can compute a large number of beams at rates suitable for interactive applications with moving sources and receivers.	acoustic cryptanalysis;beam tracing;computation (action);data structure;generalization (psychology);intersection of set of elements;iterative method;lichtenberg figure;lookup table;manuscripts;on the fly;precomputation;radiation;reflection (computer graphics);semantic parameterization;simulation;solutions;time complexity;tree (data structure);trees (plant)	Dejan Markovic;Fabio Antonacci;Augusto Sarti;Stefano Tubaro	2016	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2016.2515612	computer vision;simulation;data structure;room acoustics;computer science;theoretical computer science;beam tracing;computational model	Visualization	87.24093749826395	-34.22796501533115	91934
cc2d5c5f2661305c03290f28b4e0b15b0a623ba4	distant-talking speech recognition based on a 3-d viterbi search using a microphone array	talker localization errors;microphones;evaluation performance;metodo estadistico;beam shaping;degradation;moving talker;deteccion blanco;speech recognition algorithm;performance evaluation;modelo 3 dimensiones;neural networks;reconocimiento palabra;modele 3 dimensions;evaluacion prestacion;localization;working environment noise;mise en forme faisceau;hidden markov models speech recognition microphones acoustic transducer arrays maximum likelihood estimation search problems direction of arrival estimation;modele markov variable cachee;3 d viterbi search;additive noise;three dimensional model;statistical method;microfono;array signal processing;localizacion;speech enhancement;indexing terms;maximum likelihood estimation;three dimensional;puesta forma haz;detection cible;algorithme;hmm states;algorithm;viterbi detection;detection viterbi;localisation;hidden markov models;fixed position talker;microphone array;methode statistique;viterbi algorithm;traitement signal reseau;speech recognition;3 d trellis space;direction time sequence;search problems;acoustic transducer arrays;wiener filter;reconnaissance parole;microphone arrays;high quality speech acquisition;microphone arrays speech recognition viterbi algorithm additive noise working environment noise hidden markov models speech enhancement wiener filter degradation neural networks;target detection;talker directions;fixed position talker distant talking speech recognition 3 d viterbi search microphone array high quality speech acquisition moving talker talker localization errors speech recognition algorithm direction time sequence 3 d trellis space input frames hmm states talker directions;input frames;distant talking speech recognition;direction of arrival estimation;microphone;algoritmo	This paper focuses on microphone arrays to realize distant-talking speech recognition in real environments. In distant-talking situations, users can speak at arbitrary positions while moving. Therefore, it is very important for high quality speech acquisition using microphone arrays to localize a talker accurately. However, it is very difficult to localize a moving talker in noisy and reverberant environments. The talker localization errors result in performance degradation of speech recognition. One way to solve this problem is to integrate the speech recognition process and the talker localization into a unified framework. This paper proposes a new speech recognition algorithm based on a three-dimensional (3-D) Viterbi search. The 3-D Viterbi method extracts a direction-time sequence of parameter vectors by steering a beam to every direction in every frame, then finds the most likely path in a 3-D trellis space composed of talker directions, input frames and HMM states. This means that speech recognition and talker localization are performed simultaneously within a statistical framework. To evaluate the performance of the 3-D Viterbi method, recognition experiments for real environment data were carried out. The results confirmed that the 3-D Viterbi method drastically improves the recognition performance for the moving talker case as well as for the fixed-position talker case.	display resolution;elegant degradation;experiment;hidden markov model;microphone;speech acquisition;speech recognition;time series;trellis quantization;unified framework;viterbi algorithm	Takeshi Yamada;Satoshi Nakamura;Kiyohiro Shikano	2002	IEEE Trans. Speech and Audio Processing	10.1109/89.985542	three-dimensional space;speech recognition;degradation;index term;internationalization and localization;acoustics;viterbi algorithm;computer science;maximum likelihood;wiener filter;artificial neural network;hidden markov model;statistics	Robotics	86.29545738329149	-36.501442329054406	92784
30bbcb05c68d6247d9bee3961951eb95bc5bf75b	on robust inverse filter design for room transfer function fluctuations		Dereverberation methods based on the inverse filtering of room transfer functions (RTFs) are attractive because high deconvolution performance can be achieved. Although many methods assume that the RTFs are time-invariant, this assumption would not be guaranteed in practice. This paper deals with the problem of the sensitivity of a dereverberation algorithm based on inverse filtering. We evaluate the effect of RTF fluctuations caused by source position changes on the dereverberation performance. We focus on the filter energy with a view to making the filter less sensitive as regards these fluctuations. By adjusting three design parameters, namely, filter length, modeling delay, and regularization parameter, a dereverberation performance of up to 15 dB of the signal-to-distortion ratio could be obtained when the source position was changed with one-eighth wavelength distance, whereas conventional investigations have claimed that such a variation would cause a large degradation.	algorithm;deconvolution;distortion;elegant degradation;filter design;inverse filter;simulation;the filter;time-invariant system;transfer function;verse protocol	Takafumi Hikichi;Marc Delcroix;Masato Miyoshi	2006	2006 14th European Signal Processing Conference		mathematical optimization;electronic engineering;root-raised-cosine filter;control theory;mathematics	Visualization	84.83689000073396	-33.73112244753632	93098
3794659426ff204d5c3e6bc6e9752d28921f779e	extraction of acoustic sources through the processing of sound field maps in the ray space		Our goal is to develop a model-based approach to acoustic source extraction from microphone array data, which is suitable for both near-field and far-field sources. A signal representation based on plane-wave PW decomposition is suitable for acoustic sources in the far field as the resulting spectrum turns out to be impulsive. When the source approaches the array, however, the curvature of the wavefront causes the spectrum of the PW components to depart from impulsive behavior, thus making source extraction harder to attain. In this paper, we adopt a sound field representation based on the local estimation of the plenacoustic function along the array line. This approach consists of dividing the array into subarrays, and applying the PW analysis on individual subarrays. This has the immediate result of extending the range of validity of the far-field hypothesis, as a source that enters the near-field range of the extended array is still in the far-field range of the subarrays. PW analysis on subarrays allows us to construct the so-called sound field map in a domain of acoustic visibility called ray space. The extraction of the desired source is accomplished through spatial filtering of the sound field map. The design of the spatial filter relies on a linear minimum mean square error criterion defined on the sound field map. The effectiveness of the proposed methodology is proven through an extensive simulation campaign as well as real experiments.	acoustic cryptanalysis;experiment;mean squared error;microphone;simulation	Dejan Markovic;Fabio Antonacci;Lucio Bianchi;Stefano Tubaro;Augusto Sarti	2016	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2016.2615242	speech recognition;acoustics;telecommunications;acoustic source localization	Visualization	85.72543093949201	-37.94821404810344	93357
fc0d6e12382fa9b4e415d62c097b89d3aef4be5c	colouration in assisted reverberation systems	microphones;absorption;control systems;reverberation;reverberation time;wideband;allpass reverberator;transfer functions;probability density function;power gain;stochastic simulation;acoustic wave reflection;rayleigh distribution;architectural acoustics;acoustic signal processing;stochastic simulation technique;assisted reverberation systems;musical acoustics;colouration;stochastic processes;loudspeakers;transfer function;electronics industry;unassisted room;reverberation transfer functions microphones loudspeakers absorption control systems wideband acoustic signal detection electronics industry stochastic processes;auditorium;acoustic signal detection;musical acoustics reverberation transfer functions architectural acoustics acoustic wave reflection stochastic processes acoustic signal processing;room transfer functions;loop gain;allpass reverberator assisted reverberation systems reverberation time auditorium room transfer functions colouration sound decay stochastic simulation technique probability density function rayleigh distribution unassisted room loop gain power gain;sound decay	Assisted reverberation systems are used to electronically enhance the reverberation time of an auditorium. A limitation of such systems is that they produce enhanced room transfer functions that contain unnaturally large peaks. These peaks produce colouration of the sound decay. A stochastic simulation technique is presented that quantifies colouration by measuring the probability density function of the transfer functions and comparing it with the ideal Rayleigh distribution of an unassisted room. The technique is applied to existing reverberation systems, and to a new system which provides large increases in reverberation time without increasing the loop gain. It is shown that, for the same power gain, the new system produces a higher colouration, but that this problem may be eliminated by the use of an allpass reverberator.	all-pass filter;autowave reverberator;power gain;rayleigh‚Äìritz method;simulation	Mark A. Poletti	1994		10.1109/ICASSP.1994.389668	stochastic process;speech recognition;control system;mathematics;transfer function;statistics	EDA	85.75566829620311	-33.500380815360906	93480
cfa12563d4cb503f4ba5f6b5dc9f3f02cc8ddf05	simulation of an acoustic system using power envelope inverse filtering	power envelope;audio systems;acoustic system;acoustic fields;high quality acoustics system;power envelope inverse filtering;architectural acoustics;acoustic signal processing;signal processing acoustic fields audio systems architectural acoustics acoustic filters;impulse response acoustic system power envelope inverse filtering high quality acoustics system sound field generation system;acoustic filters;power filters reverberation multiple signal classification information filtering information filters acoustical engineering acoustics signal processing speech processing modeling;transient response;signal processing;impulse response;subjective evaluation;computer simulation;filtering theory;quantitative evaluation;transient response acoustic filters acoustic signal processing filtering theory;sound field generation system	In the present paper, we examine the development of a high-quality acoustics system called the sound field generation system (SFGS) using a power envelope inverse filtering (PEIF) proposed by the authors. PEIF is used for preprocessing of the SFGS, and we quantitatively evaluate SFGS using a real signal. When the output signal of SFGS is reproduced in the reproduction field, the effect of the SFGS is diminished due to the impulse response of reproduction field that is added to the created SFGS signal. Therefore, we attempted to reduce the influence of the reproduction field using a PEIF. In the experiment, we used five signals, namely, male speech, female speech, male vocal with music, female vocal with music, and classical music, and these signals were processed by computer simulation. We evaluated these signals by objective evaluation and subjective evaluation. In the objective evaluation, we obtained an improvement in SFGS for the results ranging from approximately 1 dB to 2 dB under 4 kHz, and up to 5 dB above 4 kHz. In the subjective evaluation, we obtained an improvement of approximately 10% to 60% in an experiment involving 52 subjects. These improvements are significant.	acoustic cryptanalysis;computer simulation;decibel;inverse filter;preprocessor	Shigekatsu Irie;Shigeki Hirobayashi	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4517612	computer simulation;speech recognition;impulse response;computer science;signal processing;transient response	Robotics	85.6100380534887	-33.61065529069128	93719
621783f922583fa58542e3cbdd032d56342e74bd	a combined microphone and camera calibration technique with application to acoustic imaging	computer vision;microphone arrays acoustic imaging calibration cameras computer vision;acoustic imaging;camera reference frame microphone calibration technique camera calibration technique acoustic imaging microphone array digital camera computer vision microphone coordinates;microphone arrays;calibration;cameras;acoustic camera microphone array array shape calibration	We present a calibration technique for an acoustic imaging microphone array, combined with a digital camera. Computer vision and acoustic time of arrival data are used to obtain microphone coordinates in the camera reference frame. Our new method allows acoustic maps to be plotted onto the camera images without the need for additional camera alignment or calibration. Microphones and cameras may be placed in an ad-hoc arrangement and, after calibration, the coordinates of the microphones are known in the reference frame of a camera in the array. No prior knowledge of microphone positions, inter-microphone spacings, or air temperature is required. This technique is applied to a spherical microphone array and a mean difference of 3 mm was obtained between the coordinates obtained with this calibration technique and those measured using a precision mechanical method.	acoustic cryptanalysis;algorithm;beamforming;calibration;clean;computer vision;covox speech thing;diameter (qualifier value);digital camera;euclidean distance;grid reference;hoc (programming language);map;microphone device component;optical computing;reference frame (video);time of arrival	Mathew Legg;Stuart Bradley	2013	IEEE Transactions on Image Processing	10.1109/TIP.2013.2268974	computer vision;camera auto-calibration;calibration;camera resectioning;computer science;optoacoustic imaging	Vision	87.27225261929836	-35.662377520464226	93842
63ee37bc1a86833a56fb9be34fd364718bc1a5ee	transient response of a vibratory roller during compaction	design engineering;asphalt;rollers machinery;compaction asphalt integrated circuits educational institutions real time systems force vibrations;compaction;feedback control vibratory roller transient response compaction asphalt pavement pavement deterioration pavement failure quality control procedure nondestructive intelligent compaction technique ic system pavement thickness asphalt mix;road building;rollers machinery asphalt compaction design engineering quality control road building;quality control	Compaction is the last, but possibly the most important, phase that an asphalt pavement goes through during construction. Adequate compaction is necessary for the long term performance of an asphalt pavement. Inadequate/improper compaction is one of the leading causes of early deterioration and failure of these pavements. Current quality control procedures also depend on destructive testing to ascertain the quality and thereby contribute to the early failure of the pavements. Non-destructive Intelligent Compaction (IC) techniques have been introduced to control the quality of construction of these pavements, but with limited success. Currently available IC systems display real-time measurements that are indicative of the pavement quality. However, these measurements are not adequately correlated with any measurements obtained from the finished pavement. One of the reasons for the poor accuracy is the lack of adequate modeling and mathematical analysis in the design of IC systems. These systems are typically built using heuristic data and are not amenable to mathematical analysis. In this paper, the dynamics of the vibratory compactor is studied and the effect of system parameters like the thickness of the pavement, type of asphalt mix, etc., on the response characteristics is determined. These measurements are then used to analyze the transient response of a vibratory roller during compaction. The response characteristics provide an insight into the requirements for feedback control and can be used as a starting point for improving the performance of IC systems.	data compaction;feedback;heuristic;real-time clock;requirement;thickness (graph theory)	Syed Asif Imran;Fares N. Beainy;Sesh Commuri;Musharraf Zaman	2012	2012 IEEE 51st IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2012.6426077	structural engineering;compaction;quality control;pavement engineering;engineering;geotechnical engineering;forensic engineering;asphalt	Embedded	86.97493895319434	-26.701595034073673	94161
2857478b2f8b34011627b5be6e76f7cec6dcc987	adaptive combination of subband adaptive filters for acoustic echo cancellation	stochastic gradient algorithm acoustic echo cancellation normalized subband adaptive filter hands free telephones teleconferencing systems speech input signal impulse response convergence rate normalized least mean square mean square error;teleconferencing;nsaf;convergence;hands free telephone;filter bank;least mean squares methods;cost function;speech input signal;stochastic gradient algorithm;acoustic echo cancellation;teleconferencing adaptive filters echo suppression least mean squares methods;convergence rate;adaptive combination;adaptive filters;hands free telephones;mean square error;teleconferencing systems;normalized subband adaptive filter nsaf;sum of squares;stochastic gradient;echo suppression;impulse response;teleconferencing system;normalized least mean square;signal to noise ratio;echo cancellers;adaptive filter;normalized subband adaptive filter;acoustic echo canceller adaptive combination normalized subband adaptive filter nsaf hands free telephone teleconferencing system;adaptive filters convergence echo cancellers filter bank steady state signal to noise ratio;acoustic echo canceller;steady state	In hands-free telephones and teleconferencing systems, acoustic echo cancellers are required, which are often implemented by adaptive filters. In these applications, the speech input signal of the adaptive filter is highly correlated and the impulse response of the echo path is very long. These characteristics will slow down the convergence rate of the adaptive filter if the well-known normalized least-mean-square (NLMS) algorithm is used. The normalized subband adaptive filter (NSAF) offers a good solution to this problem because of its decorrelating property. However, similar to the NLMS-based adaptive filter, the NSAF requires a tradeoff between fast convergence rate and small steady-state mean-square error (MSE). In this paper, we propose an adaptive combination scheme to address this tradeoff. The combination is carried out in subband domain and the mixing parameter that controls the combination is adapted by means of a stochastic gradient algorithm which employs the sum of squared subband errors as the cost function. The performance of the proposed combination scheme is evaluated in the context of acoustic echo cancellation (AEC). Experimental results show that the combination scheme can obtain both fast convergence rate and small steady-state MSE.	acoustic coupler;acoustic cryptanalysis;adaptive filter;algorithm;decorrelation;echo suppression and cancellation;gradient;least mean squares filter;loss function;mean squared error;rate of convergence;simulation;steady state;whole earth 'lectronic link	Jingen Ni;Feng Li	2010	IEEE Transactions on Consumer Electronics	10.1109/TCE.2010.5606296	adaptive filter;computer vision;electronic engineering;speech recognition;kernel adaptive filter;computer science	Mobile	83.78032562306996	-33.37304965884849	94195
7e8619200a45c8f5ccdaf6023ddd58c5629c5064	on linear and mixmax interaction models for single channel source separation	audio signal processing;source separation signal to noise ratio time frequency analysis approximation methods speech hidden markov models;audio source separation linear interaction models mixmax interaction models model based single channel source separation mixture magnitude spectrogram individual source magnitude spectrogram log domain approximation vector quantizer based single channel source separation vq based single channel source separation factorial linear vq factorial max vq code book sizes additive white noise continuous time frequency masks binary time frequency masks interference suppression;speech;approximation theory;interference suppression;minimax techniques;hidden markov models;vq;single channel;time frequency masking;approximation methods;time frequency masking source separation single channel vq;minimax techniques approximation theory audio signal processing interference suppression;signal to noise ratio;source separation;time frequency analysis	For model-based single channel source separation, one typically assumes a linear interaction model, i.e. that the mixture magnitude spectrogram is the sum of the individual source magnitude spectrograms. In the log-domain, the MIXMAX interaction model is the corresponding approximation for the linear model. Hence, one would expect similar performance for both approaches. However, in this paper we empirically show that this is not the case for vector-quantizer-based (VQ) single channel source separation. We propose factorial linear-VQ, the linear counterpart to factorial max-VQ, and compare the two methods in systematic source separation experiments. Linear-VQ performs significantly better than max-VQ for comparable code-book sizes and behaves more robustly in the presence of additive white noise. Furthermore, we compare resynthesis properties of binary and continuous time-frequency masks. While binary masks achieve a higher interference suppression, the use of continuous masks results in a consistently better signal quality.	approximation;bitwise operation;experiment;interference (communication);linear model;mathematical model;quantization (signal processing);source separation;spectrogram;utility functions on indivisible goods;variable shadowing;vector quantization;white noise;zero suppression	Robert Peharz;Franz Pernkopf	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6287864	speech recognition;time‚Äìfrequency analysis;audio signal processing;computer science;speech;pattern recognition;mathematics;signal-to-noise ratio;hidden markov model;statistics;approximation theory	Vision	83.45125940497117	-33.09690136016376	94370
4ff0de80ac239a6edb3674f7bf748848d3d47fc3	distance estimation of hidden objects based on acoustical holography by applying acoustic diffraction of audible sound	holography acoustic diffraction cameras ultrasonic imaging frequency signal design acoustic measurements ultrasonic variables measurement interference optical reflection;time of flight;1 2 m;optical reflection;ultrasound;ultrasonic imaging;signal design;ultrasonic variables measurement;optimal modulated signal;acoustic signal processing;interference;distance estimation;acoustical holography;acoustic diffraction;distance measurement;6 cm hidden object distance estimation acoustical holography acoustic diffraction audible sound range finders time of flight method ultrasound ranging systems optimal modulated signal 1 2 m 3 cm;best frequency;modulation acoustic holography acoustic measurement acoustic signal processing distance measurement;3 cm;ultrasound ranging systems;holography;range finders;audible sound;frequency;acoustic measurements;time of flight method;cameras;hidden object distance estimation;acoustic measurement;acoustic holography;6 cm;modulation	Occlusion is a problem for range finders; ranging systems using cameras or lasers cannot be used to estimate distance to an object (hidden object) that is occluded by another (obstacle). We developed a method to estimate the distance to the hidden object by applying acoustic diffraction of audible sound. Our method is based on time-of-flight (TOF), which has been used in ultrasound ranging systems. We determined the best frequency of audible sound and designed its optimal modulated signal for our system. We determined that the system estimates the distance to the hidden object as well as the obstacle. However, the measurement signal obtained from the hidden object was weak. Thus, interference from sound signals reflected from other objects or walls was not negligible. Therefore, we combined acoustical holography (AH) and TOF, which enabled a partial analysis of the reflection sound intensity field around the obstacle and hidden object. Our method was effective for ranging two objects of the same size within a 1.2 m depth range. The accuracy of our method was 3 cm for the obstacle, and 6 cm for the hidden object.	acoustic cryptanalysis;holography;interference (communication);modulation	Haruhiko Niwa;Tetsuya Ogata;Kazunori Komatani;Hiroshi G. Okuno	2007	Proceedings 2007 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2007.363823	time of flight;speech recognition;acoustics;frequency;ultrasound;interference;optics;holography;physics;quantum mechanics;modulation	Robotics	87.06846879894216	-36.22384434119817	94605
818b16035ec9dc9d9cd8edac4efe9b146672ae9a	a system approach to acoustic echo cancellation in robust hands-free teleconferencing	teleconferencing;true echo return loss enhancement acoustic echo cancellation robust hands free teleconferencing near end signal aec system performance near end interference stereophonic aec postfilter integration;acoustic echo cancellation;simulation;speech;residual echo suppression;speech enhancement;distortion;echo suppression;postfiltering;robustness;echo cancellers;residual echo estimation;speech enhancement acoustic echo cancellation residual echo estimation residual echo suppression postfiltering;filtering theory;noise;speech robustness echo cancellers noise distortion simulation;teleconferencing echo suppression filtering theory	This paper presents a system approach to the acoustic echo cancellation (AEC) problem in a noisy acoustic environment. We propose a method that makes use of the estimated near-end signal from a postfilter to further improve the AEC system performance. The cancellation performance is enhanced especially during strong near-end interference (e.g., double talk). Simulation results show that our stereophonic AEC based on the system approach with postfilter integration outperforms the one using the original robust AEC system by itself without postfilter integration. The improved performance is noted especially during double talk, where simulation results show that the true echo return loss enhancement can be boosted by as much as 10 dB.	acoustic coupler;acoustic cryptanalysis;echo suppression and cancellation;interference (communication);return loss;simulation	Jason Wung;Ted S. Wada;Biing-Hwang Juang;Bowon Lee;Mitchell D. Trott;Ronald W. Schafer	2011	2011 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)	10.1109/ASPAA.2011.6082293	electronic engineering;speech recognition;teleconference;acoustics;distortion;telecommunications;computer science;engineering;noise;speech;robustness	Robotics	83.97758092312729	-33.51094758645614	94710
6c2e03d5d73666b1e337d6ea1fd4d37e4918f80b	laplace entropy and its application to time delay estimation for speech signals	laplace entropy approximation mathematical formula joint entropy minimization gaussian signals multichannel cross correlation coefficient time difference of arrival generalized cross correlation method speech signals time delay estimation;time of arrival estimation correlation methods delays gaussian processes laplace equations speech processing;cross correlation;gaussian processes;laplace distribution time delay estimation multichannel cross correlation coefficient entropy;speech processing;time delay estimation;correlation methods;generalized cross correlation;laplace equations;entropy delay effects delay estimation reverberation microphones working environment noise speech enhancement time difference of arrival noise robustness radar tracking;multichannel cross correlation coefficient;time of arrival estimation;entropy;delays;laplace distribution;time difference of arrival	Time delay estimation (TDE) is a basic technique for numerous applications where there is a need to localize and track a radiating source. It is particularly challenging in the presence of noise and reverberation, and when the source signal is speech which is inherently nonstationary and random. The most important TDE algorithms for two sensors are based on the generalized cross-correlation (GCC) method. These algorithms perform reasonably well when reverberation or noise is not too high. In an earlier study of the authors, a more sophisticated approach was proposed. It employs more sensors and takes advantage of their delay redundancy to improve the precision of the TDOA (time difference of arrival) estimate between the first two sensors. The approach is based on the multichannel cross-correlation coefficient (MCCC) and was found more robust to noise and reverberation. In this paper, we show that this approach can also be developed on a basis of joint entropy. For Gaussian signals, we show that, in the search of the TDOA estimate, maximizing MCCC is equivalent to minimizing joint entropy. But with the generalization of the idea to non-Gaussian speech signals, the joint entropy based new multichannel TDE algorithm manifests a potential to outperform the MCCC-based method. Since there is no rigorous mathematical formula for speech entropy, we use the assumption that speech can be plausibly modeled by a Laplace distribution and develop a practical approximation of Laplace entropy for TDE of speech signals. The performance of the proposed new algorithm is investigated via simulations.	algorithm;approximation;coefficient;computer simulation;cross-correlation;decibel;joint entropy;microphone;multilateration;sensor;signal-to-noise ratio;simulation;speech synthesis;transparent data encryption	Yiteng Huang;Jacob Benesty;Jingdong Chen	2007	2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07	10.1109/ICASSP.2007.366629	entropy;speech recognition;multilateration;cross-correlation;gaussian process;speech processing;laplace distribution;mathematics;statistics	Robotics	83.29257167332409	-36.13223230050575	94744
4b9a8fa4e7d0aae213f7c53ca5db1d59017556af	moving target feature extraction for airborne high-range resolution phased-array radar	radar aeroporte;traitement signal;least squares approximations;high resolution;cost function;etude theorique;maximum likelihood;weighted least square;phased array;extraction forme;direction of arrival;radar resolution;array signal processing;blanco movil;correlation methods;maximum likelihood estimation;algorithme;radar reseau commande phase;interference suppression;algorithm;radar cross section;haute resolution;doppler effect;spatial correlation;extraccion forma;autoregressive processes;feature extraction spatial resolution frequency estimation phased arrays maximum likelihood estimation history phase estimation airborne radar radar clutter reactive power;phased array radar;feature extraction;signal processing;algorithm performance moving target feature extraction airborne high range resolution phased array radar spatially correlated ground clutter temporally correlated ground clutter hrr radar data hrr range profiles low range resolution segments hrr range bins vector auto regressive filtering ground clutter suppression parameter estimation algorithm var filtered data doppler frequency spatial signature vectors maximum likelihood estimation mle target phase history direction of arrival doa estimation array steering vector array manifold weighted least squares cost function radar cross section rcs related complex amplitude target scatterer relax high resolution feature extraction algorithm relaxation based feature extraction;alta resolucion;estudio teorico;red en fase;cible mobile;airborne radar;radar detection;radar aerotransportado;radar clutter;parameter estimation;theoretical study;high range resolution;reseau en phase;procesamiento senal;pattern extraction	We study the feature extraction of moving targets in the presence of temporally and spatially correlated ground clutter for airborne high-range resolution (HRR) phased-array radar. To avoid the range migration problems that occur in HRR radar data, we first divide the HRR range profiles into low-range resolution (LRR) segments. Since each LRR segment contains a sequence of HRR range bins, no information is lost due to the division, and hence, no loss of resolution occurs. We show how to use a vector auto-regressive (VAR) filtering technique to suppress the ground clutter. Then, a parameter estimation algorithm is proposed for target feature extraction. From the VAR-filtered data, the target Doppler frequency and the spatial signature vectors are first estimated by using a maximum likelihood (ML) method. The target phase history and direction-of-arrival (DOA) (or the array steering vector for unknown array manifold) are then estimated from the spatial signature vectors by minimizing a weighted least squares (WLS) cost function. The target radar cross section (RCS)-related complex amplitude and range-related frequency of each target scatterer are then extracted from the estimated target phase history by using RELAX, which is a relaxation-based high-resolution feature extraction algorithm. Numerical results are provided to demonstrate the performance of the proposed algorithm.	airborne ranger;algorithm;auto-tune;clutter;cross section (geometry);direction of arrival;estimation theory;feature extraction;image resolution;least squares;linear programming relaxation;loss function;numerical method;phased array;phasor;radar signal characteristics	Jian Li;Guoqing Liu;Nanzhi Jiang;Petre Stoica	2001	IEEE Trans. Signal Processing	10.1109/78.902110	phased array;speech recognition;moving target indication;computer science;signal processing;mathematics;maximum likelihood;statistics	ML	83.06503768537704	-41.94151358277526	94924
1be5dd732d18801947b8116cd91246ec4c0aed58	speech enhancement based on a perceptual modification of wiener filtering.	speech enhancement;wiener filter	A speech denoising technique based on subband noise estimation and a perceptual modification of Wiener filtering is proposed. The noisy speech is first decomposed into critical band signals by an auditory filterbank and the denoising is carried out on the subband signals. The time varying subband noise variance required for denoising is estimated by tracking the minimum variance of the subband noisy signal. Auditory masking is applied to calculate the optimum denoising gain using a Wiener filtering approach to minimize the perceived speech distortion. This denoising technique is suitable for coloured and nonstationary noise environments. It gives natural sounding speech with a very low level of musical noise.	automatic sounding;critical band;distortion;filter bank;noise reduction;speech enhancement;unsharp masking;wiener filter	Lee Lin;W. Harvey Holmes;Eliathamby Ambikairajah	2002			computer science;wiener filter	ML	83.03744059231182	-33.91426051759534	95017
17920a0d4aa93af6f4d12219f01cbce6687bf0a9	microphone array response to speaker movements	microphones;reverberation;reverberation microphones acoustic transducer arrays array signal processing direction of arrival estimation speech processing transient response matched filters adaptive signal processing filtering theory acoustic noise noise abatement;speech processing;array signal processing;noise abatement;transient response;adaptive signal processing;microphone array;microphone arrays noise reduction speech enhancement array signal processing matched filters filtering adaptive arrays speech processing tracking reverberation;acoustic noise;noise reduction;impulse response;matched filters;acoustic transducer arrays;matched filter;adaptive beamforming;impulse response tracking speaker movements microphone array response adaptive beamforming matched filtering speech dereverberation noise reduction impulse response identification identification errors;filtering theory;direction of arrival estimation	Matched ltering and adaptive beamforming are both necessary for e cient speech dereverberation and noise reduction by microphone arrays. This can be achieved by the identi cation of impulse responses. In this contribution, we show that adaptive microphone arrays are sensitive to identi cation errors of impulse responses, particularly due to speaker movements. We prove that adjusted matchedltering and permanent tracking of impulse responses are also necessary. The proposed microphone array responds well to these requirements under realistic conditions.	beamforming;matched filter;microphone;noise reduction;requirement	Yves Grenier;Sofi√®ne Affes	1997		10.1109/ICASSP.1997.599615	computer vision;speech recognition;noise-canceling microphone;computer science;speech processing;matched filter	ML	84.31053777032561	-33.88010583481142	95279
4995ed767c0de4490478517f0546e2e5e8d8a594	3-d sound intensity measurements: accuracy enhancements with virtual-instrument-based technology	microphones;uncertainty acoustics intensity microphone sensor fusion sound;bandwidth enhancements;secondary pairs;acoustic intensity measurement;virtual instrumentation;virtual instrumentation acoustic intensity measurement measurement uncertainty microphones;uncertainty;plane wave expression;paper technology;acoustics;environmental conditions;3d sound intensity measurements;plane waves;virtual instrument;primary pairs;frequency measurement;measurement uncertainty;probes;acoustic diffraction;intrinsic p p method;pressure measurement;shorter separating distance;sound;virtual instrument technology;probes microphones bandwidth acoustic transducers acoustic measurements acoustic waves pressure measurement frequency measurement acoustic diffraction paper technology;bandwidth;measurement uncertainty 3d sound intensity measurements accuracy enhancements virtual instrument technology bandwidth enhancements perpendicular microphones primary pairs secondary pairs shorter separating distance intrinsic p p method high frequency sensitivity loss plane wave expression;intensity measure;accuracy enhancements;acoustic waves;sensor fusion;high frequency sensitivity loss;acoustic measurements;high frequency;acoustic transducers;intensity;coordinate system;microphone;perpendicular microphones	"""This paper describes a method that allows accuracy and bandwidth enhancements in 3D sound intensity measurements. Commercial 3D probes are usually set up with three mutually perpendicular 1D p-p probes and, thus, arranged with six microphones; although sound intensity can be calculated with 15 independent pairs of transducers, only the three """"primary"""" pairs that are aligned with the coordinate system axes. The other 12 """"secondary"""" pairs consist of mutually perpendicular microphones, which are placed at a distance that is radic2 times shorter than the primary one. The main idea of the proposed method is to average the intensity that is measured on primary and secondary pairs. This leads to a larger bandwidth, thanks to the shorter separating distance between secondary pairs. The intrinsic p-p method high- frequency sensitivity loss is partially recovered, starting from the theoretical plane wave expression. Measurements of different axes are weighted with coefficients that are computed by optimizing the measurement uncertainty. Errors that are due to the metrological characteristics of the transducers and the effects of environmental conditions are compensated. Experimental results showed that a p-p probe arranged with half-inch microphones that are placed at a distance of 50 mm allows reliable measurements up to 2.5 kHz, whereas a commercial probe bandwidth with the same configuration is usually 1250 Hz."""	approximation error;coefficient;microphone;transducer	Giovanni Moschioni;Bortolino Saggin;Marco Tarabini	2008	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2008.919865	acoustic wave;electronic engineering;plane wave;uncertainty;acoustics;pressure measurement;coordinate system;high frequency;sensor fusion;intensity;optics;sound;bandwidth;physics;quantum mechanics;statistics;measurement uncertainty	Visualization	87.77924994918004	-35.806442831957604	95482
355a768f4df839217b03a5181ba3ccce7679edd4	influence of the waveguide propagation on the antenna performance in a car cabin.		This paper presents a novel array processing algorithm for noise reduction in a hands free car environment. The algorithm incorporates the spatial properties of the sound field in a car cabin and a constraint on allowable speech signal distortion. Our results indicate that the proposed algorithm gives substantial performance improvement of 15-20 dB in comparison with the conventional array processing which is based on a coherent model of the signal field.	acoustic cryptanalysis;algorithm;array processing;coherence (physics);distortion;mathematical optimization;mobile phone;noise reduction;signal processing;software propagation;speech enhancement;zero suppression	Leonid G. Krasny;Ali S. Khayrallah	2003			telecommunications	Robotics	84.55768506108835	-34.77388981349133	95899
dbcc3f040f8798b199fa2960d877ec504a971331	imaging activity in integrated circuits	laser voltage probe;image processing;laser scanning microscope;signal detection;laser scanning microscope image processing signal detection integrated circuits laser voltage probe;digital imaging technique imaging activity integrated circuit brain activity neuroscience image change detection video change detection scene surveillance activity localization laser scanning microscope generalized likelihood ratio test glrt framework electronic waveform laser scan location active region detection ic signal acquisition;measurement by laser beam imaging integrated circuits noise frequency modulation photonics laser beams;statistical testing image processing integrated circuits optical microscopy signal detection;integrated circuits	The need to detect and localize activity exists in a variety of fields and has broad applications ranging from brain activity for neuroscience to image/video change detection for scene surveillance. In this paper, we introduce a method for localizing activity in integrated circuits (IC) using a laser scanning microscope. Specifically, we develop an activity measure using the Generalized Likelihood Ratio Test (GLRT) framework to detect if an electronic waveform is present at a laser scan location while a test program is repeatedly run. By plotting the activity score against laser scan location, an activity image is developed showing the measured activity in different parts of the IC. We show that this technique allows detection of all active regions in an operating IC, while requiring a relatively low number of signal acquisitions.	electroencephalography;integrated circuit;waveform	Erik Matlin;Neil Troy;David Stoker	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7026177	computer vision;image processing;computer science;detection theory	Robotics	93.82868405220538	-28.115704471266035	95997
fbeed6e312ae392223ce6436549913c3e5e4ecb6	musical-noise-free blind speech extraction integrating microphone array and iterative spectral subtraction	blind speech extraction;higher order statistics;iterative spectral subtraction;microphone array	In this paper, we propose a musical-noise-free blind speech extraction method using a microphone array for application to nonstationary noise. In our previous study, it was found that optimized iterative spectral subtraction (SS) results in speech enhancement with almost no musical noise generation, but this method is valid only for stationary noise. The proposed method consists of iterative blind dynamic noise estimation by, e.g., independent component analysis (ICA) or multichannel Wiener filtering, and musicalnoise-free speech extraction by modified iterative SS, where multiple iterative SS is applied to each channel while maintaining the multichannel property reused for the dynamic noise estimators. Also, in relation to the proposed method, we discuss the justification of applying ICA to signals nonlinearly distorted by SS. From objective and subjective evaluations simulating a real-world hands-free speech communication system, we reveal that the proposed method outperforms the conventional methods. & 2014 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/3.0/).	distortion;elegant degradation;experiment;independent computing architecture;independent component analysis;iteration;iterative method;microphone;noise reduction;nonlinear system;norsk data;simulation;sound quality;speech enhancement;stationary process;wiener filter	Ryoichi Miyazaki;Hiroshi Saruwatari;Satoshi Nakamura;Kiyohiro Shikano;Kazunobu Kondo;Jonathan Blanchette;Martin Bouchard	2014	Signal Processing	10.1016/j.sigpro.2014.03.010	speech recognition;computer science	AI	83.40545497225575	-35.2719527541274	96535
7553667a0e392e93a9bfecae3e34201a0c1a1266	joint optimization of lcmv beamforming and acoustic echo cancellation	speech enhancement;speech enhancement array signal processing echo suppression least squares approximations man machine systems;integrated circuits array signal processing echo cancellers abstracts nickel acoustic distortion;generalized sidelobe canceller linearly constrained minimum variance beamforming acoustic echo cancellation full duplex hands free acoustic human machine interfaces speech enhancement least squares optimization;human machine interface;generalized sidelobe canceller;acoustic echo canceller	Full-duplex hands-free acoustic human/machine interfaces often require the combination of acoustic echo cancellation and speech enhancement in order to suppress acoustic echoes, local interference, and noise. In order to optimally exploit positive synergies between acoustic echo cancellation and speech enhancement, we present in this contribution a combined least-squares (LS) optimization criterion for the integration of acoustic echo cancellation and adaptive linearly-constrained minimum variance (LCMV) beamforming. Based on this optimization criterion, we derive a computationally efficient system based on the generalized sidelobe canceller (GSC), which effectively deals with scenarioes with time-varying acoustic echo paths and simultaneous presence of double-talk of acoustic echoes, local interference, and desired speakers.	acoustic cryptanalysis;algorithmic efficiency;beamforming;duplex (telecommunications);echo suppression and cancellation;gsc bus;interference (communication);least squares;mathematical optimization;speech enhancement;synergy	Wolfgang Herbordt;Walter Kellermann;Satoshi Nakamura	2004	2004 12th European Signal Processing Conference		electronic engineering;speech recognition;acoustics;engineering	Robotics	84.67172564146368	-35.06821974816609	96820
5d241122fb015b35fe35d35858a45847af529d7b	development of microphone-array-embedded uav for search and rescue task		This paper addresses online outdoor sound source localization using a microphone array embedded in an unmanned aerial vehicle (UAV). In addition to sound source localization, sound source enhancement and robust communication method are also described. This system is one instance of deployment of our continuously developing open source software for robot audition called HARK (Honda Research Institute Japan Audition for Robots with Kyoto University). To improve the robustness against outdoor acoustic noise, we propose to combine two sound source localization methods based on MUSIC (multiple signal classification) to cope with trade-off between latency and noise robustness. The standard Eigenvalue decomposition based MUSIC (SEVD-MUSIC) has smaller latency but less noise robustness, whereas the incremental generalized singular value decomposition based MUSIC (iGSVD-MUSIC) has higher noise robustness but larger latency. A UAV operator can use an appropriate method according to the situation. A sound enhancement method called online robust principal component analysis (ORPCA) enables the operator to detect a target sound source more easily. To improve the stability of wireless communication, and robustness of the UAV system against weather changes, we developed data compression based on free lossless audio codec (FLAC) extended to support a 16 ch audio data stream via UDP, and developed a water-resistant microphone array. The resulting system successfully worked in an outdoor search and rescue task in ImPACT Tough Robotics Challenge in November 2016.	acoustic cryptanalysis;codec;covox speech thing;data compression;embedded system;lossless compression;music (algorithm);microphone;norm (social);open-source software;real-time clock;robot;robotics;robust principal component analysis;singular value decomposition;software deployment;television antenna;unmanned aerial vehicle	Kazuhiro Nakadai;Makoto Kumon;Hiroshi G. Okuno;Kotaro Hoshiba;Mizuho Wakabayashi;Kai Washizaki;Takahiro Ishiki;Daniel Gabriel;Yoshiaki Bando;Takayuki Morito;Ryosuke Kojima;Osamu Sugiyama	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8206494	robustness (computer science);computer vision;computer science;latency (engineering);artificial intelligence;noise;data compression;microphone array;codec;robust principal component analysis;acoustic source localization	Robotics	86.65106095655722	-40.13502024875827	97329
2736f8472bce4136950c9dde6981865b73cb95de	illuminant-camera communication to observe moving objects under strong external light by spread spectrum modulation		Many algorithms of computer vision use light sources to illuminate objects to actively create situation appropriate to extract their characteristics. For example, the shape and reflectance are measured by a projector-camera system, and some human-machine or VR systems use projectors and displays for interaction. As existing active lighting systems usually assume no severe external lights to observe projected lights clearly, it is one of the limitations of active illumination. In this paper, we propose a method of energy-efficient active illumination in an environment with severe external lights. The proposed method extracts the light signals of illuminants by removing external light using spread spectrum modulation. Because an image sequence is needed to observe modulated signals, the proposed method extends signal processing to realize signal detection projected onto moving objects by combining spread spectrum modulation and spatio-temporal filtering. In the experiments, we apply the proposed method to a structured-light system under sunlight, to photometric stereo with external lights, and to insensible image embedding.	algorithm;computer vision;detection theory;experiment;modulation;movie projector;multiplexing;photometric stereo;quantum illumination;signal processing;structured light;video projector	Ryusuke Sagawa;Yutaka Satoh	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.249	modulation;computer vision;filter (signal processing);spread spectrum;photometric stereo;signal processing;standard illuminant;computer science;artificial intelligence;signal-to-noise ratio;multiplexing	Vision	86.00089816004636	-40.18246198848308	97331
2f3e2f618311437dfad20cd123e932e73615e107	indirect dominant mode rejection: a solution to low sample support beamforming	indirect dominant mode rejection idmr beamformer;low rank cg beamformer;wind direction;indirect dominant mode rejection;metodo estadistico;analisis componente principal;senal salida;clutter;beam forming;degradation;resonance;high resolution;low sample support beamforming;frequency modulation;polarimetry;variance minimale;pci beamformer;covariance matrices array signal processing conjugate gradient methods correlation methods;robust adaptive beamforming;cross correlation;robust adaptive beamforming blocking matrix conjugate gradient beamformer dominant mode rejection dmr beamformer indirect dominant mode rejection idmr beamformer low sample support beamforming minimum variance distortionless mvdr beamformer;output signal;correlation croisee;degradacion;indirect dominant mode rejection blocking matrix dmr beamformer dominant mode rejection pci beamformer principal component inverse low rank cg beamformer conjugate gradient parametric estimation sample support adaptive beam forming sampled covariance matrix residual cross correlation mvdr equation minimum variance distortionless response idmr beamformer;variancia minima;simulation;matrice covariance;simulacion;statistical method;residual cross correlation;radar equipment;array signal processing;matriz covariancia;correlation methods;conjugate gradient method;estimacion a priori;spectra;grazing angles;a priori estimation;canada;relacion senal interferencia ruido;signal to interference plus noise ratio;conjugate gradient;rejection;formation voie;parametric estimation;statistical analysis;rapport signal interference bruit;mathematical models;methode statistique;metodo gradiente conjugado;covariance matrices;efecto bloque;mvdr equation;principal component inverse;sample support adaptive beam forming;principal component analysis;dominant mode rejection;center of gravity;ontario;analyse composante principale;minimum variance distortionless response;effet bloc;estimation a priori;dominant mode rejection dmr beamformer	Under conditions of low sample support, a low-rank solution of the minimum variance distortionless response (MVDR) equations can yield a higher output signal-to-interference-plus-noise ratio (SINR) than the full-rank MVDR beamformer. In this paper, we investigate several low-rank beam- forming techniques, and we also propose a new beamformer that we refer to as the indirect dominant mode rejection (IDMR). We analyze the degradation in the output SINR caused by residual cross correlations embedded in the sampled covariance matrix due to low sample support. The IDMR beamformer is based on a parametric estimate of the covariance matrix, in which any cross correlation is canceled out. Simulations reveal that the IDMR beamformer yields a dramatic improvement in output SINR relative to the conjugate gradient (CG), principal component inverse (PCI), and dominant mode rejection (DMR) beamformers. In our investigation of the low-rank CG beamformer, we address the issue of whether the unity gain constraint in the look direction should be enforced a priori via the use of a blocking matrix or effected a posteriori through simple scaling of the beamforming vector. Remarkably, it is proven that the two methods yield exactly the same low-rank beamformer at each and every rank.	beamforming;blocking (computing);computation;computer simulation;conjugate gradient method;cross-correlation;dual modular redundancy;elegant degradation;embedded system;householder transformation;image scaling;interference (communication);principal component analysis;rejection sampling;signal-to-interference-plus-noise ratio;the matrix	Ernesto L. Santos;Michael D. Zoltowski;Muralidhar Rangaswamy	2007	IEEE Transactions on Signal Processing	10.1109/TSP.2007.893926	control theory;mathematics;conjugate gradient method;statistics;principal component analysis	Robotics	88.48904526120886	-40.68843939108013	97593
40ad96ed0b45663784977ceb31edf56ed7868119	beam-steered vertical seismic arrays for wave classification	array processing;surface energy;shafts;delay lines;earth;working environment noise;weight control;array signal processing;brain modeling;signal processing;beam steering;vertical seismic profile;earth array signal processing signal processing working environment noise weight control delay lines frequency shafts beam steering brain modeling;frequency;gradient projection method;seismic array	Vertical seismic profiling (VSP) is a technique for determining wave transmission properties of the earth. It is implemented using a surface energy source and an array of geophones placed vertically in a well shaft. The geophysical interpretation of VSP data is greatly facilitated by the use of geophone array processing or beam steering to separate the various wave types and arrival angles. Constraints are placed on the array directional response pattern to force main lobe and null locations to desired positions. The corrective gradient projection method is then used to determine the set of tap weights which minimize received power subject to the pattern constraints. The algorithm is applied to data from a simulated seismogram with crossing events and to data from a synthetic VSP seismogram for a 2-layer model. These results demonstrate that undesired events from a given direction can be effectively attenuated.		A. M. Bisbee;E. A. Quincy;D. J. Tomich	1984		10.1109/ICASSP.1984.1172506	surface energy;beam steering;frequency;signal processing;earth;vertical seismic profile	Vision	83.11309756226322	-41.5542640974586	97729
b0b98d18aea087d933315380aa54488bef2c8170	vibrational resonance in a hodgkin-huxley neuron under electromagnetic induction		In this paper, effects of electromagnetic induction on vibrational resonance phenomenon in a Hodgkin-Huxley neuron are investigated. By stimulating Hodgkin-Huxley neuron with both high-frequency signal and low-frequency weak signal, its weak signal detection capacity have been investigated under electromagnetic induction effect. Obtained results show that electromagnetic induction causes decreasing of the amplitude of vibrational resonance effect emerging depending on the amplitude of high frequency signal. Also, vibrational resonance phenomenon occurs at smaller amplitudes of high frequency signal in Hodgkin-Huxley neuron which is under electromagnetic induction effect. Finally, it is found that the best detection of the weak signal in a Hodgkin-Huxley neuron under electromagnetic induction effect is realized under an optimal electromagnetic current intensity.	detection theory;hodgkin‚Äìhuxley model;huxley: the dystopia;neuron;resonance	Veli Baysal;Ergin Yilmaz	2018	2018 26th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2018.8404591	artificial intelligence;nuclear magnetic resonance;stochastic resonance;pattern recognition;computer science;hodgkin‚Äìhuxley model;amplitude;electromagnetic induction;resonance;ac power;phenomenon;neuron	EDA	85.07261854039314	-26.420456533062893	97885
2a2aa72b56ab4cd8e793c2ce99f25a82b3d579a6	very low bit rate voice coder based on a nonlinear hearing model		A new hearing model based on the knowledge of anatomy and phychoacoustical phenomena was presented by R. F√∂ldv√°ri and Gy. √Åcs in 1996. After a short survey of older hearing models, they proved that their hearing model is able to describe true hearing experience (critical bandwidth, phase limit frequency). We suppose that the outputs of Zwicker's filters and the nonlinear transformation secured by the nonlinear hearing model is suitable for brain processing. Furthermore, we wish to point out that by realizing this method a very low bit rate vocoder and in addition an efficient speech enhancement can be achieved in cases when signal-to-noise ratio is about 0 dB.	nonlinear system;signal-to-noise ratio;speech enhancement;vocoder	Rudolf F√∂ldv√°ri;L√°szl√≥ Gyimesi	1999			speech recognition;nonlinear system;low bit;speech enhancement;computer science;bandwidth (signal processing)	Mobile	83.07439028899721	-32.6167927385972	97964
26d803327780d54316ec1e3fac0c12402956b4e2	hands-free system with low-delay subband acoustic echo control and noise reduction	echo cancellation;subband system hands free system echo cancellation speech enhancement low delay filter;low delay filter;speech processing acoustic noise acoustic signal processing adaptive filters delays echo suppression;noise suppression postfilter;speech processing;subband system;acoustic signal processing;noise suppression;time domain fir postfiltering;speech enhancement;speech distortion;delayless subband adaptive filter;noise attenuation;low delay subband acoustic echo control;adaptive filters;acoustic noise;noise reduction;speech signal processing;echo suppression;time domain;simulated car environment;real time implementation;hands free system;control systems noise reduction speech enhancement delay signal processing algorithms echo cancellers speech processing acoustic signal processing adaptive signal processing acoustic noise;adaptive filter;echo attenuation;delays;time domain fir postfiltering hands free system noise reduction echo cancellation speech signal processing noise suppression postfilter echo attenuation noise attenuation speech distortion simulated car environment low delay subband acoustic echo control delayless subband adaptive filter	Echo cancellation and noise reduction for hands-free systems are challenging tasks in speech signal processing. The presence of strong local speech and noise and a changing acoustical enclosing may severely impair the performance of the algorithms. Usually additional constraints such as a low signal delay are also requested for real time implementation. We present a hands-free system consisting of a delayless sub- band adaptive filter with a low-delay echo and noise suppression postfilter. All parameters are estimated in the subband domain, whereas the filtering takes place in the time domain. Thus, our system has a significantly lower processing delay than similar proposals. We compare its performance with respect to echo and noise attenuation and speech distortion with a state-of-the-art hands-free system in a simulated car environment.	acoustic cryptanalysis;adaptive filter;algorithm;distortion;echo suppression and cancellation;noise reduction;processing delay;signal processing;speech processing;zero suppression	Kai Steinert;Martin Sch√∂nle;Christophe Beaugeant;Tim Fingscheidt	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4517911	adaptive filter;computer vision;speech recognition;computer science;noise;speech processing;noise floor	Robotics	84.13245791804579	-33.51616390295884	98441
d4103b75f834b4bd31b53f94d8401aa29c86576b	wideband adaptive beamforming system for speech recording	speech processing;array signal processing;environmental effect;adaptive signal processing;microphone array;acoustic arrays array signal processing speech processing adaptive signal processing;wideband adaptive systems array signal processing speech microphone arrays frequency switches adaptive arrays interference scattering;microphone arrays;nonideal environmental effects wideband adaptive beamforming system speech recording signal quality microphone array undistorted recording snr gain;adaptive beamforming;acoustic arrays;speech processing array signal processing microphone arrays	An adaptive beamforming algorithm that enhances the quality of the signal recorded by a microphone array is presented. The system described here attenuates the interference from spatially scattered sources while preserving the desired signal quality in the speech frequency range. A novel method for defining additional constraints within the adaptation process and performing beamforming in parallel across several frequency bands achieves undistorted recording even with slight errors in localizing the speaker. Simulation results show nearly optimal improvement of speech quality in various noisy environments. The algorithm is modified to perform in a real environment by introducing two modes of adaptation that switch according to the speaker activity. The implementation of this modified system demonstrates SNR gain close to that of the original simulated system. It is robust to localization errors and non-ideal environmental effects.	adaptive beamformer;algorithm;beamforming;frequency band;interference (communication);internationalization and localization;microphone;signal-to-noise ratio;simulation	Sergey Timofeev;Ahmad Bahai;Pravin Varaiya	2007	2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07	10.1109/ICASSP.2007.366404	adaptive filter;speech recognition;noise-canceling microphone;computer science;adaptive beamformer;speech processing;beamforming	Robotics	84.4289218276963	-34.31135129795388	98832
0dcfc16b04ec6ca2c369f76fcc80977734c60edd	design of a wideband, constant beamwidth, array microphone for use in the near field	reverberation;wideband;acoustics;speech;near field;computerized monitoring;loudspeakers;tv;microphone arrays;microphone arrays wideband apertures frequency reverberation speech acoustics computerized monitoring loudspeakers tv;frequency;nonlinear optimization;apertures	Directional microphones have long been proposed for the removal of room reverberation. An array microphone would seem ideal for this purpose, since theoretically it can be aimed anywhere within the room. However, microphone pattern beamwidth is related to wavelength and aperture size. For a fixed-size aperture, as wavelength goes down so does beamwidth. The change in beamwidth over a decade change in wavelength would seem to be unacceptable for this application. We discuss the design of a constant beamwidth array microphone for the frequency range 300 to 3000 Hz. Because the microphone-to-talker distance is assumed to be about 3 ft while the array has a 9-ft aperture, the microphone is optimized for near field. We also discuss the use of a nonlinear optimization program for choosing the array parameters.	frequency band;mathematical optimization;microphone;near field communication;nonlinear programming;nonlinear system	F. C. Pirz	1979	The Bell System Technical Journal	10.1109/ICASSP.1979.1170681	loudspeaker;aperture;speech recognition;noise-canceling microphone;reverberation;nonlinear programming;near and far field;speech;frequency	EDA	85.57755659351356	-34.28732605008279	98917
7a87dcbfc01b6caf5111ab8dc5193cd52a0abe2d	an online em algorithm for source extraction using distributed microphone arrays	online learning;psd matrix estimation;expectation maximization;distributed arrays expectation maximization online learning psd matrix estimation;abstracts noise measurement simulation noise lead microphones arrays;distributed arrays	Expectation maximization (EM)-based clustering is applied in many recent multichannel source extraction techniques. The estimated model parameters are used to compute time-frequency masks, or estimate second order statistics (SOS) of the source signals. However, in applications with moving sources where the model parameters are time-varying, the batch EM algorithm is inapplicable. We propose an online EM-based clustering of position estimates, where the model parameters are estimated adaptively. A direct-to-diffuse ratio-based speech presence probability is used to detect noisy observations and reduce diffuse and spatially incoherent noise. The desired source signal is extracted by a multichannel Wiener filter computed using SOS estimated from the time-varying model parameters. We show that the signal of a moving source can be extracted, while reducing moving interferers and background noise.	cluster analysis;expectation‚Äìmaximization algorithm;microphone;variable shadowing;wiener filter	Maja Taseska;Emanuel A. P. Habets	2013	21st European Signal Processing Conference (EUSIPCO 2013)		speech recognition;computer science;machine learning;statistics	ML	83.46863632937374	-36.612742718724	99542
075c3aeff48ad4d5e78c60decc82314e6db71fe3	a smart-phone based system to detect warning sound for hearing impaired people		Hearing impaired people can not notice warning sounds such as sirens of emergency vehicles, horns of cars, and alarms of railroad crossings and thus can not behave properly. For example, when they walk on the road and an ambulance is approaching, they can not hear the siren and are likely to get into danger. This paper proposes a system to detect a warning sound for a pedestrian. The system detects the warning sounds as following. First, an IIR band pass filter is applied to limit to the frequency band which includes the frequency of warning sounds. Next, an IIR comb filter is applied to remove the the fundamental and the harmonic frequency components of the warning sounds. Finally, threshold processing is conducted for the amplitude ratio of the input signal to the output signal. If the amplitude ratio is below a threshold, the system notifies the user of the existence of the warning sound. This system is simple and easy to implement on smart phones which most people carry commonly every day. We conducted experiments to evaluate the performance of the proposed system. An ambulance siren and noises were synthesized with SNR-10dB, SNR 0dB and SNR 10dB and inputted to the system. The results of this experiment showed that the system can detect an ambulance siren with accuracy above 96% under noisy environments above SNR 0dB. In addition, we conducted an experiment in which an ambulance siren recorded on the road is inputted to the system. We found that the siren affected by the Doppler effect is difficult to be detected by the proposed system.	comb filter;doppler effect;experiment;frequency band;infinite impulse response;shiren the wanderer 2;signal-to-noise ratio;smartphone	Koichiro Takeuchi;Tetsuya Matsumoto;Yoshinori Takeuchi;Hiroaki Kudo;Noboru Ohnishi	2014		10.1007/978-3-319-08599-9_75	acoustics;audiology	HCI	84.85966417102955	-39.48106808578842	99632
13391cbad582f855b6956b9cc61775517196c530	on-the-spot calibration of microphone array transfer functions for robot audition	microphones;microphones arrays estimation calibration transfer functions simultaneous localization and mapping;transfer functions;transfer functions acoustic signal processing acoustics calibration geometry hearing microphone arrays slam robots;hand clap acoustic signals on the spot calibration microphone array transfer functions robot audition system geometrical calculation robot acoustics room acoustics simultaneous localization and mapping slam;arrays;estimation;simultaneous localization and mapping;calibration	This paper investigates the calibration of a microphone array based robot audition system, namely calibration of microphone array Transfer Functions (TFs). There are mainly two methods to obtain TFs: geometrical calculation and measurement. The geometrical calculation has difficulty in simulating robot- and room-acoustics such as diffraction and reflection properties of a robot's body and a room, and the measurement is accurate but time-consuming and requires expertise on acoustics. Thus, we propose fast and simple on-the-spot calibration of TFs including robot- and room-acoustics. The proposed approach first estimates microphone location and clock-difference by Simultaneous Localization And Mapping (SLAM) using hand clap acoustic signals while a human is walking around a robot. Second, TFs with robot- and room-acoustics are estimated by hand clap acoustic signals and interpolated so that the TFs can be roundly arranged at regular intervals in an online manner. In the evaluation, we calibrated TFs only by 20 hand claps (took only 20 seconds), and the TFs showed considerable improvements in sound source localization and separation compared to geometrically calculated TFs and achieved comparable performance towards the measured TFs which are calibrated by approximately 60 minute recordings.	acoustic cryptanalysis;calibration (statistics);covox speech thing;extended kalman filter;interpolation;microphone;robot;simulation;simultaneous localization and mapping	Keisuke Nakamura;Surya Ambrose;Kazuhiro Nakadai	2015	2015 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2015.7139662	estimation;electronic engineering;calibration;speech recognition;acoustics;computer science;engineering;transfer function;statistics;simultaneous localization and mapping	Robotics	86.81704001384095	-35.29634192471508	99952
24e622638788a98f5ad21e2e8ecc6b455d7426ec	a maximum likelihood estimation of vocal-tract-related filter characteristics for single channel speech separation	signal image and speech processing;acoustics;vocal tract;mathematics in music;maximum likelihood estimate;single channel;engineering acoustics	We present a new technique for separating two speech signals from a single recording. The proposed method bridges the gap between underdetermined blind source separation techniques and those techniques that model the human auditory system, that is, computational auditory scene analysis (CASA). For this purpose, we decompose the speech signal into the excitation signal and the vocal-tract-related filter and then estimate the components from the mixed speech using a hybrid model. We first express the probability density function (PDF) of the mixed speech‚Äôs log spectral vectors in terms of the PDFs of the underlying speech signal‚Äôs vocal-tract-related filters. Then, the mean vectors of PDFs of the vocal-tract-related filters are obtained using a maximum likelihood estimator given the mixed signal. Finally, the estimated vocal-tract-related filters along with the extracted fundamental frequencies are used to reconstruct estimates of the individual speech signals. The proposed technique effectively adds vocaltract-related filter characteristics as a new cue to CASA models using a new grouping technique based on an underdetermined blind source separation. We compare our model with both an underdetermined blind source separation and a CASA method. The experimental results show that our model outperforms both techniques in terms of SNR improvement and the percentage of crosstalk suppression.		Mohammad H. Radfar;Richard M. Dansereau;Abolghasem Sayadiyan	2006	EURASIP J. Audio, Speech and Music Processing	10.1155/2007/84186	vocal tract;linear predictive coding;speech recognition;acoustics;computer science;blind signal separation;maximum likelihood;physics	ML	82.93911474704626	-35.62182538502634	100233
b0659dd24ec44f8bee07b5b2a0c82e368de6eb4d	relaxed disjointness based clustering for joint blind source separation and dereverberation	reverberation;blind source separation;indium tin oxide;time frequency analysis;conferences	We propose a novel clustering technique based on a relaxed disjointness assumption for joint blind source separation (BSS) and dere-verberation. A disjointness assumption in conventional clustering techniques for BSS is that, at each time-frequency point, observed mixtures consist of a single source only. However, this is not the case in reverberant environments, which causes the performance of the conventional techniques to degrade. To deal with reverberant environments, we introduce a relaxed disjointness assumption: at each time-frequency point, dereverberated mixtures consist of a single source only. Under this assumption, the proposed algorithm alternates dereverberation and clustering-based source separation it-eratively, where clustering is performed on dereverberated mixtures. This algorithm is derived based on maximum a posteriori (MAP) fitting of a probabilistic generative model to observed reverberant mixtures. In experiments, the proposed method outperformed a state-of-the-art clustering technique in terms of a signal-to-interference ratio (SIR) by 0.6-4 dB.	algorithm;blind signal separation;cluster analysis;experiment;generative model;interference (communication);source separation	Nobutaka Ito;Shoko Araki;Takuya Yoshioka;Tomohiro Nakatani	2014	2014 14th International Workshop on Acoustic Signal Enhancement (IWAENC)	10.1109/IWAENC.2014.6954300	electronic engineering;speech recognition;telecommunications;mathematics	AI	83.5010597092767	-36.431208463251515	100313
81d95f3ae9ccb5e844db81d57c02b86dcc7cabd0	measurement, analysis and simulation of wind noise signals for mobile communication devices	noise speech noise measurement microphones acoustics databases mathematical model;websearch;noise reduction systems wind noise signals mobile communication devices wind noise statistics spectral properties temporal properties autoregresive model spectral shape description temporal statistics markov chain speech enhancement;wind noise database wind noise analysis wind noise simulation communication quality assessment;wind markov processes mobile communication speech enhancement;ikz613310;rwth publications	In this contribution, we study the characteristics of sound generated by wind and a signal model for the synthesis of wind noise signals is derived. An analysis of the statistics of wind noise recorded in a laboratory setup is carried out with respect to the spectral and temporal properties of the signals. In particular, an autoregresive model is developed for the spectral shape description and the temporal statistics are modeled by a Markov chain. These two components are combined in a model which synthesizes reproducible artificial wind noise signals. Furthermore, a database of measured wind noise signals is provided. The aim of this model and the measured audio data is to provide wind signals for the evaluation of speech enhancement and noise reduction systems.	database;markov chain;noise reduction;rewriting;simulation;speech enhancement	Christoph Matthias Nelke;Peter Vary	2014	2014 14th International Workshop on Acoustic Signal Enhancement (IWAENC)	10.1109/IWAENC.2014.6954312	gaussian noise;electronic engineering;speech recognition;colors of noise;ambient noise level;acoustics;engineering;noise measurement;noise;background noise;noise floor;noise	ML	87.80549167466444	-34.42331493529546	100591
e1b5da32d8b167d2aa1b7005cd392994194c6743	pitch estimation of stereophonic mixtures of delay and amplitude panned signals	maximum likelihood;maximum likelihood estimation;channel estimation;classification systems pitch estimation stereophonic mixtures delay amplitude panned signals automatic music transcription source separation;delays maximum likelihood estimation harmonic analysis europe channel estimation;multi channel processing;noise reduction;maximum likelihood pitch estimation multi channel processing noise reduction;delays audio signal processing;europe;pitch estimation;delays;harmonic analysis	In this paper, a novel method for pitch estimation of stereophonic mixtures is presented, and it is investigated how the performance is affected by the pan parameters of the individual signals of the mixture. The method is based on a signal model that takes into account a stereophonic mixture created by mixing multiple individual channels with different pan parameters, and is hence suited for use in automatic music transcription, source separation and classification systems. Panning is done using both amplitude differences and delays. The performance of the estimator is compared to one single-channel, two multi-channel and one multi-pitch estimator using synthetic and real signals. Experiments show that the proposed method is able to correctly estimate the pitches of a mixture of three real signals when they are separated by more than 25 degrees.	experiment;pitch detection algorithm;source separation;synthetic intelligence;transcription (software)	Martin Weiss Hansen;Jesper Rindom Jensen;Mads Gr√¶sb√∏ll Christensen	2015	2015 23rd European Signal Processing Conference (EUSIPCO)	10.1109/EUSIPCO.2015.7362340	electronic engineering;speech recognition;acoustics;engineering	Vision	83.33158992754419	-35.47359543351243	101690
513615e211957b3585b95a59d396b60895494776	digital terrain modeling with the chebyshev polynomials		Mathematical problems of digital terrain analysis include interpolation of digital elevation models (DEMs), DEM generalization and denoising, and computation of morphometric variables by calculation of partial derivatives of elevation. Traditionally, these procedures are based on numerical treatments of two-variable discrete functions of elevation. We developed a spectral analytical method and algorithm based on high-order orthogonal expansions using the Chebyshev polynomials of the first kind with the subsequent Fej√©r summation. The method and algorithm are intended for DEM analytical treatment, such as, DEM global approximation, denoising, and generalization as well as computation of morphometric variables by analytical calculation of partial derivatives. To test the method and algorithm, we used a DEM of the Northern Andes including 230,880 points (the elevation matrix 480 √ó 481). DEMs were reconstructed with 480, 240, 120, 60, and 30 expansion coefficients. The first and second partial derivatives of elevation were analytically calculated from the reconstructed DEMs. Models of horizontal curvature (kh) were then computed with the derivatives. A set of elevation and kh maps related to different number of expansion coefficients well illustrates data generalization effects, denoising, and removal of artifacts contained in the original DEM. The test results demonstrated a good performance of the developed method and algorithm. They can be utilized as a universal tool for analytical treatment in digital terrain modeling.	algorithm;approximation;chebyshev polynomials;coefficient;computation;digital elevation model;emoticon;finite difference;interpolation;map;mean squared error;morphometrics;noise reduction;numerical analysis;polynomial;qualitative comparative analysis;spectral method	Igor V. Florinsky;A. N. Pankratov	2015	CoRR		mathematical optimization;calculus;mathematics;geometry;statistics	ML	88.2225911527595	-49.071451558811845	102033
81c588f72a37089539eba13bc57b5758295d3759	separation of synchronous sources through phase locked matrix factorization	phase locking;matrix factorization;synchrony independent component analysis ica matrix factorization phase locking source separation;source separation synchronization upper bound additive noise vectors estimation;noise blind source separation jitter matrix decomposition;independent component analysis ica matrix factorization phase locking source separation synchrony;independent component analysis ica;synchrony;source separation;blind source separation synchronous source separation phase locked matrix factorization sss problem independent component analysis method statistically dependent synchronous sources two step algorithm plmf cost function additive noise phase jitter bss problem	In this paper, we study the separation of synchronous sources (SSS) problem, which deals with the separation of sources whose phases are synchronous. This problem cannot be addressed through independent component analysis methods because synchronous sources are statistically dependent. We present a two-step algorithm, called phase locked matrix factorization (PLMF), to perform SSS. We also show that SSS is identifiable under some assumptions and that any global minimum of PLMFs cost function is a desirable solution for SSS. We extensively study the algorithm on simulated data and conclude that it can perform SSS with various numbers of sources and sensors and with various phase lags between the sources, both in the ideal (i.e., perfectly synchronous and nonnoisy) case, and with various levels of additive noise in the observed signals and of phase jitter in the sources.	additive white gaussian noise;algorithm;blast phase;independent component analysis;loss function;maxima and minima;utility functions on indivisible goods;sensor (device);synovial sarcoma	Miguel S. B. Almeida;Ricardo Vig√°rio;Jos&#x00E9; M. Bioucas-Dias	2014	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2013.2297791	speech recognition;machine learning;mathematics;blind signal separation;matrix decomposition	Embedded	83.1486640006443	-36.081829717247565	102041
39d9fa8b3d2b36408c8217b37902f58e7db38d8c	adaptive noise reduction algorithm to improve r peak detection in ecg measured by capacitive ecg sensors	qrs interval;snr;active noise cancellation;affine projection sign algorithm;motion artifacts;noisy signal	Electrocardiograms (ECGs) can be conveniently obtained using capacitive ECG sensors. However, motion noise in measured ECGs can degrade R peak detection. To reduce noise, properties of reference signal and ECG measured by the sensors are analyzed and a new method of active noise cancellation (ANC) is proposed in this study. In the proposed algorithm, the original ECG signal at QRS interval is regarded as impulsive noise because the adaptive filter updates its weight as if impulsive noise is added. As the proposed algorithm does not affect impulsive noise, the original signal is not reduced during ANC. Therefore, the proposed algorithm can conserve the power of the original signal within the QRS interval and reduce only the power of noise at other intervals. The proposed algorithm was verified through comparisons with recent research using data from both indoor and outdoor experiments. The proposed algorithm will benefit a noise reduction of noisy biomedical signal measured from sensors.	adaptive filter;algorithm;experiment;noise reduction;noise-induced hearing loss;sensor (device)	Minseok Seo;Minho Choi;Jun Seong Lee;Sang Woo Kim	2018		10.3390/s18072086	capacitive sensing;electronic engineering;engineering;noise reduction	EDA	85.52044192558056	-39.69687861291577	102078
583b1de236506f5fe2195515420d1b1a1548f4a5	a two-channel adaptive microphone array with target tracking			microphone	Yoshifumi Nagata;Hiroyuki Tsuboi	1997			speech recognition;microphone array;computer science;communication channel	Robotics	84.8243590286212	-34.75574728023115	102628
e5824308e56ba9aa8ddca64be4be435272eaf0eb	amplitude modulated video camera - light separation in dynamic scenes		Controlled light conditions improve considerably the performance of most computer vision algorithms. Dynamic light conditions create varying spatial changes in color and intensity across the scene. These condition, caused by a moving shadow for example, force developers to create algorithms which are robust to such variations. We suggest a computational camera which produces images that are not influenced by environmental variations in light conditions. The key insight is that many years ago, similar difficulties were already solved in radio communication, As a result each channel is immune to interference from other radio channels. Amplitude Modulated (AM) video camera separates the influence of a modulated light from other unknown light sources in the scene, Causing the AM video camera frame to appear the same - independent of the light conditions in which it was taken. We built a prototype of the AM video camera by using off the shelf hardware and tested it. AM video camera was used to demonstrate color constancy, shadow removal and contrast enhancement in real time. We show theoretically and empirically that: 1. the proposed system can produce images with similar noise levels as a standard camera. 2. The images created by such camera are almost completely immune to temporal, spatial and spectral changes in the background light.	algorithm;computation;computational photography;computer vision;interference (communication);merge sort;modulation;pixel;prototype;smartphone;source separation;warez	Amir Kolaman;Maxim Lvov;Rami R. Hagege;Hugo Guterman	2016	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2016.402	computer vision;camera auto-calibration;three-ccd camera;pinhole camera model;computer graphics (images)	Vision	86.36296957986958	-40.423323050521994	103063
f24f0ce146f913ba0916c9660db44e270199657b	robust and low-cost cascaded non-linear acoustic echo cancellation	volterra series;microphones;echo cancellation;convergence;robust estimator;volterra series acoustic echo cancellation non linear echo;acoustic echo cancellation;acoustic echo cancellation non linear echo volterra series;microphones echo suppression loudspeakers;non linear echo;estimation;loudspeakers;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;power filter low cost cascaded nonlinear acoustic echo cancellation nonlinear environment cascaded model loudspeaker enclosure microphone system acoustical channel uplink transducers impulse response nonlinear adaptive echo canceler acoustic channel;echo suppression;impulse response;robustness;adaptation models;echo cancellers;acoustic echo canceller;loudspeakers adaptation models echo cancellers robustness estimation convergence	This paper addresses the problem of acoustic echo cancellation in non-linear environments. The first contribution relates to the use of a cascaded model which divides the loudspeaker enclosure microphone system into two main blocks; the first models the downlink transducers which are assumed to be the main source of nonlinearity. The second block includes the acoustical channel and uplink transducers which are assumed to be linear and have a comparatively longer impulse response and higher time variability. The second contribution is a new non-linear adaptive echo canceler which is based on the cascaded model and has greater robustness to changes in the acoustic channel than an existing power filter approach.	acoustic cryptanalysis;acoustic model;echo suppression and cancellation;heart rate variability;loudspeaker enclosure;microphone;multiple encryption;nonlinear system;telecommunications link;transducer	Moctar Mossi Idrissa;Christelle Yemdji;Nicholas W. D. Evans;Christophe Beaugeant;Philippe Degry	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5946335	loudspeaker;robust statistics;estimation;speech recognition;convergence;impulse response;computer science;mathematics;statistics;robustness	Robotics	84.29538607788496	-33.36590431004755	103569
0959ef1f5b079656ea76627657e64b31692fb7d0	multichannel excitation/filter modeling of percussive sounds with application to the piano	acoustic signal processing;musical instruments;instruments resonance signal synthesis signal analysis parameter estimation signal generators timbre information filtering information filters steady state;filtering and prediction theory;acoustic signal processing musical instruments music parameter estimation filtering and prediction theory;parameter estimation;music;natural sounding percussive tones percussive sounds synthetic tones percussive musical instruments vibraphones classical source filter models multichannel excitation filter model single excitation piano tones octave model parameters estimation low cost synthesis method	| This paper discusses models for sounds of percussive musical instruments such as vibraphones, pianos, and the like. In addition to classical source//lter models a `multi-channel excitation//lter model' is proposed in which a single excitation is used to generate several sounds, for example ve piano tones belonging to the same octave. Techniques for estimating the model parameters are presented along with their application to the sound of a real piano. Our experiments demonstrate that it is possible to calculate a single excitation signal which, when fed into diierent lters, generates very accurate synthetic tones. Finally, a low-cost synthesis method is also proposed that can be used to generate very natural sounding percussive tones.	automatic sounding;experiment;synthetic intelligence	Jean Laroche;Jean-Louis Meillier	1994	IEEE Trans. Speech and Audio Processing	10.1109/89.279282	pitch (music);speech recognition;acoustics;music;statistics	ML	85.2552053608413	-33.247674354341996	103852
20c9dc576b31b77878db3cf1db653b476f209f3c	the avogadro problem: summary of tests on crystal imperfections	silicon;isotopic composition;avogadro constant;single crystal;science and technology;avogadro problem;density measurement;kilogram definition;uncertainty;molar volume;single crystals;density difference;crystal perfection;testing;crystal imperfections;indexing terms;measurement uncertainty;crystals;crystal defects;si avogadro problem crystal imperfections international measurements inconsistency molar volume crystal perfection isotopic composition kilogram definition single crystals uncertainty avogadro constant density difference;crystallization;error correction;volume measurement;si;testing silicon crystals crystalline materials crystallization measurement uncertainty crystallography volume measurement error correction density measurement;crystalline materials;crystallography;constants;international measurements inconsistency;measurement uncertainty constants density measurement silicon crystal defects	International measurements of the molar volume of silicon on the basis of more than 15 different crystals have confirmed the Committee on Data for Science and Technology (CO-DATA) value of the Avogadro constant published in 1986. Only one discrepancy still exists and cannot yet be completely explained. In this paper, we summarize results of tests that relate to the perfection of the crystals used. With high probability, it turns out that imperfections of the crystal material itself and not the uncertainties of the measurement procedures are responsible fur this inconsistency. At present, the lack of exact knowledge of the degree of crystallographic perfection and, in particular, of the isotopic composition, hampers the progress of the crystal route for a new definition of the kilogram.	avogadro	Peter Becker;Ulrich Kuetgens;J. St√ºmpel	2001	IEEE Trans. Instrumentation and Measurement	10.1109/19.918204	error detection and correction;index term;uncertainty;crystal;software testing;crystallization;silicon;single crystal;avogadro constant;physics;crystallographic defect;statistics;measurement uncertainty;molar volume;science, technology and society	Embedded	91.07119862801387	-24.828307443204046	104346
04a624d61fbebb97419e622d57d474fb2ab9e027	active spike responses of analog electrical neuron: theory and experiments	neurons circuits biomembranes robustness shape control physics pulse generation resonance frequency intersymbol interference;networks circuits analogue circuits;cte mode active spike responses analog electrical fitzhugh nagumo neuron complex threshold excitation outside pulse stimulus nonlinear integrate and fire nonlinear electrical circuit;fitzhugh nagumo model;oscillations;bifurcation;oscillators;analog electrical fitzhugh nagumo neuron complex threshold excitation;integrate and fire;cte mode;outside pulse stimulus;nonlinear waves;shape;fitzhugh nagumo;synchronization;interspike interval isi;integrated circuit modeling;electrical circuit;mathematical model;analogue circuits;neurons;active spike responses;neuron;nonlinear integrate and fire;interspike interval isi nonlinear electrical circuit fitzhugh nagumo model neuron nonlinear waves;nonlinear electrical circuit;networks circuits	"""Using an analog electrical FitzHugh-Nagumo neuron including complex threshold excitation (CTE) properties, we analyze its spiking responses under pulse stimulation corresponding to oscillating threshold manifold. The system is subjected to outside pulse stimulus and can generate nonlinear integrate-and-flre and resonant responses which are typical for excitable neuronal cells (""""all-or-none""""). The answer of the neuron strongly depends on the number and the characteristics of incoming impulses (amplitude, width, strength and frequency). For certain parameters range, there is a possibility to trigger a spiking sequence with a finite number of spikes in response of a single short stimulus pulse. Thus active transformation of N incoming pulses to M outgoing spikes is possible. The predicted theoretical results are found and observed in a nonlinear electrical circuit mimicking the CTE mode, which enlighten the robustness of these phenomena."""	active and passive transformation;excitable medium;experiment;fitzhugh‚Äìnagumo model;neuron;nonlinear system;tail value at risk	St√©phane Binczak;Aur√©lien Serge Tchakoutio Nguetcho;Sabir Jacquir;Jean-Marie Bilbault;Viktor B. Kazantsev	2010	Proceedings of 2010 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2010.5537112	electronic engineering;electrical engineering;control theory;mathematics;oscillation;quantum mechanics	ML	84.95211704191864	-26.396939402611807	104504
fec919e3102c4d3ceb8574f3ad8dce074dfd108d	sparsity promoted non-negative matrix factorization for source separation and detection	sparse promotion elder care non negative matrix factorization source separation;vectors source separation sparse matrices matrix decomposition digital signal processing signal to noise ratio interference;source separation acoustic signal detection interference signal matrix decomposition;decomposition process nonnegative matrix factorization coefficients source detection nmf sound source separation acoustic based human fall detection interference	The effectiveness of non-negative matrix factorization (NMF) depends on a suitable choice of the number of bases, which is often difficult to decide in practice. This paper imposes sparseness on the factorization coefficients in order to determine the number of bases automatically during the decomposition process. The benefit of sparse promotion for NMF is demonstrated through application to sound source separation as well as acoustic-based human fall detection under strong interference.	acoustic cryptanalysis;basis function;coefficient;covox speech thing;interference (communication);neural coding;non-negative matrix factorization;source separation;sparse matrix	Yanlin Wang;Yun Li;K. C. Ho;Alina Zare;Marjorie Skubic	2014	2014 19th International Conference on Digital Signal Processing	10.1109/ICDSP.2014.6900744	speech recognition;sparse matrix;analytical chemistry;pattern recognition;blind signal separation	Vision	83.1410080637882	-37.30970972579848	104723
f3e4bc59566580fdbd00df21fdf1b7e4b152aa3e	let it bee - towards nmf-inspired audio mosaicing		A swarm of bees buzzing ‚ÄúLet it be‚Äù by the Beatles or the wind gently howling the romantic ‚ÄúGute Nacht‚Äù by Schubert ‚Äì these are examples of audio mosaics as we want to create them. Given a target and a source recording, the goal of audio mosaicing is to generate a mosaic recording that conveys musical aspects (like melody and rhythm) of the target, using sound components taken from the source. In this work, we propose a novel approach for automatically generating audio mosaics with the objective to preserve the source‚Äôs timbre in the mosaic. Inspired by algorithms for non-negative matrix factorization (NMF), our idea is to use update rules to learn an activation matrix that, when multiplied with the spectrogram of the source recording, resembles the spectrogram of the target recording. However, when applying the original NMF procedure, the resulting mosaic does not adequately reflect the source‚Äôs timbre. As our main technical contribution, we propose an extended set of update rules for the iterative learning procedure that supports the development of sparse diagonal structures in the activation matrix. We show how these structures better retain the source‚Äôs timbral characteristics in the resulting mosaic.	activation function;algorithm;iterative method;ncsa mosaic;non-negative matrix factorization;sparse matrix;spectrogram;swarm	Jonathan Driedger;Thomas Pr√§tzlich;Meinard M√ºller	2015			iterative learning control;speech recognition;machine learning;artificial intelligence;matrix decomposition;computer science;diagonal;matrix (mathematics);spectrogram;timbre;non-negative matrix factorization	ML	83.9906165385513	-37.287261794076365	105225
c5e071ce2896557fddc0041f8db722397b169330	knot-tying with four-piece fixtures	fixtures;flexible;manipulation;knots;string	We present a class of fixtures that can be disassembled into four pieces to extract the loosely-tied knot. We prove that a fixture can be designed for any particular knot such that the knot can be extracted using only simple pure translations of the four fixture sections. We explore some of the issues raised by our experimental work with these fixtures, which show that simple knots can be tied extremely quickly (less than half a second) and reliably (99% repeatability) using four-piece fixtures.	best practice;boundary knot method;form factor (design);knot polynomial;repeatability;simulation;test fixture;virtual fixture	Matthew P. Bell;Weifu Wang;Jordan Kunzika;Devin J. Balkcom	2014	I. J. Robotics Res.	10.1177/0278364914532217	string;engineering;geometry;engineering drawing;knot	Robotics	83.06633552395999	-24.134923917460636	105453
d1b5490226700d513311570a0f5fe2eb664a8924	sparse gaussian process audio source separation using spectrum priors in the time-domain		Gaussian process (GP) audio source separation is a timedomain approach that circumvents the inherent phase approximation issue of spectrogram based methods. Furthermore, through its kernel, GPs elegantly incorporate prior knowledge about the sources into the separation model. Despite these compelling advantages, the computational complexity of GP inference scales cubically with the number of audio samples. As a result, source separation GP models have been restricted to the analysis of short audio frames. We introduce an efficient application of GPs to time-domain audio source separation, without compromising performance. For this purpose, we used GP regression, together with spectral mixture kernels, and variational sparse GPs. We compared our method with LD-PSDTF (positive semi-definite tensor factorization), KL-NMF (Kullback-Leibler non-negative matrix factorization), and IS-NMF (Itakura-Saito NMF). Results show that the proposed method outperforms these techniques.	aac-ld;approximation;calculus of variations;computational complexity theory;gaussian process;global positioning system;itakura‚Äìsaito distance;kullback‚Äìleibler divergence;non-negative matrix factorization;semiconductor industry;source separation;sparse matrix;spectrogram	Pablo A. Alvarado;Mauricio A. √Ålvarez;Dan Stowell	2018	CoRR		kernel (linear algebra);computational complexity theory;prior probability;source separation;matrix decomposition;pattern recognition;spectrogram;gaussian process;artificial intelligence;non-negative matrix factorization;computer science	ML	83.19916001829849	-37.99124368140261	105907
28778c1077299e0d7697616e83fd40da4efe1aa5	classification of potato tubers based on solanine toxicant using laser-induced light backscattering imaging	laser;Œ± solanine;scattering;hplc;potato;artificial neural network	Potato tubers include two major glycoalkaloids, Œ±-solanine and Œ±-chaconine, often called ‚Äòsolanine‚Äô. Exceeding from the admissible level of solanine in potatoes, which is 200¬†mg¬†kg‚àí1 fresh weight of potato, would cause poison hazards in human beings. Herein, we propose a laser light-based non-destructive technique to recognize only Œ±-solanine toxicant in potatoes. High-performance liquid chromatography (HPLC) analysis is also performed as a destructive and reference test to verify the laser light backscattering imaging (LLBI) technique. The single layer perceptron neural networks have been used to classify healthy and toxic potatoes from each other. The results demonstrated that artificial neural networks (ANNs) classified potatoes of cv. ‚ÄòDonald‚Äô and ‚ÄòCeasar‚Äô with the accuracy of 98.66% and 99.16% and mean square error (MSE) of 0.013 and 0.003, respectively. Little is known about LLBI systems and development of this new technique is needed in agriculture and food industry.		Saeedeh Babazadeh;Parviz Ahmadi Moghaddam;Arash Sabatyan;Faroogh Sharifian	2016	Computers and Electronics in Agriculture	10.1016/j.compag.2016.09.009	botany;laser;biotechnology;computer science;machine learning;scattering;artificial neural network;quantum mechanics	Vision	85.12694228256225	-51.53254348881153	106149
8062c121bb773abddbc03792d3e6e22dfb8dcc6a	ray tracing for light and radio wave simulations			computer simulation;radio wave;ray tracing (graphics)	Arne Schmitz	2012				Networks	89.23305593029689	-27.92117861851586	106422
27e2919dc1fd1b300511e813238d384eac413f5b	online learning for template-based multi-channel ego noise estimation	databases;signal denoising learning artificial intelligence mobile robots;microphones;microwave integrated circuits;noise estimation databases robots speech microwave integrated circuits microphones;speech;mobile robots;estimation;noise suppression online template learning system template based multichannel ego noise estimation autonomous template learning system adaptive template learning system requirement elimination offline training session ego noise discrimination sound source directionality sound source diffuseness template database time variant forgetting factor parameter learning process adaptivity learning process stability single channel noise estimation system mobile robots multichannel robot audition framework;robots;learning artificial intelligence;noise;signal denoising	This paper presents a system that gives a robot the ability to diminish its own disturbing noise (i.e., ego noise) by utilizing template-based ego noise estimation, an algorithm previously developed by the authors. In pursuit of an autonomous, online and adaptive template learning system in this work, we specifically focus on eliminating the requirement of an offline training session performed in advance to build the essential templates, which represent the ego noise. The idea of discriminating ego noise from all other sound sources in the environment enables the robot to learn the templates online without requiring any prior information. Based on the directionality/diffuseness of the sound sources, the robot can easily decide whether the template should be discarded because it is corrupted by external noises, or it should be inserted into the database because the template consists of pure ego noise only. Furthermore, we aim to update the template database optimally by introducing an additional time-variant forgetting factor parameter, which provides a balance between adaptivity and stability of the learning process automatically. Moreover, we enhanced the single-channel noise estimation system to be compatible with the multi-channel robot audition framework so that ego noise can be eliminated from all signals stemming from multiple sound sources respectively. We demonstrate that the proposed system allows the robot to have the ability of online template learning as well as a high performance of noise estimation and suppression for multiple sound sources.	algorithm;automated system recovery;autonomous robot;background process;microsoft outlook for mac;noise (electronics);noise reduction;online and offline;online machine learning;signal-to-noise ratio;stationary process;stemming;zero suppression	G√∂khan Ince;Kazuhiro Nakadai;Keisuke Nakamura	2012	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2012.6385824	robot;mobile robot;computer vision;estimation;speech recognition;computer science;engineering;noise;speech;artificial intelligence	Robotics	85.34382100551613	-34.98199986990061	106555
b214c3959942b42181fe72ba8f1ddd0ffffc15c5	eeg source localization for two dipoles in the brain using a combined method	metodo cuadrado menor;methode moindre carre;electric current;brain;nonlinear least squares;systeme nerveux central;least squares method;backpropagation neural network;electroencefalografia;courant electrique;incertidumbre;uncertainty;source localization;localization;hombre;intelligence artificielle;localizacion;encefalo;problema inverso;high precision;electroencephalographie;initial value problem;sistema nervioso central;cerebro;localisation;inverse problem;encephale;cerveau;backpropagation algorithm;precision elevee;human;precision elevada;algorithme retropropagation;problema valor inicial;artificial intelligence;encephalon;incertitude;inteligencia artificial;probleme valeur initiale;electroencephalography;reseau neuronal;corriente electrica;probleme inverse;red neuronal;central nervous system;homme;neural network;algoritmo retropropagacion	Estimating the correct location of electric current source with the brain from electroencephalographic (EEG) recordings is a challenging analytic and computational problem. Specifically, there is no unique solution and solutions do not depend continuously on the data. This is an inverse problem from EEG to dipole source. In this paper we consider a method combining backpropagation neural network (BPNN) with nonlinear least square (NLS) method for source localization. For inverse problem, the BP neural network and the NLS method has its own advantage and disadvantage, so we use the BPNN to supply the initial value to the NLS method and then get the final result, here we select the Powell algorithm to do the NLS calculating. All these work are for the fast and accurate dipole source localization. The main purpose of using this combined method is to localize two dipole sources when they are locating at the same region of the brain. The following investigations are presented to show that this combined method used in this paper is an advanced approach for two dipole sources localization with high accuracy and fast calculating.	electroencephalography	Zhuoming Li;Yu Zhang;Qinyu Zhang;Masatake Akutagawa;Hirofumi Nagashino;Fumio Shichijo;Yohsuke Kinouchi	2005		10.1007/11508069_23	internationalization and localization;uncertainty;electroencephalography;computer science;inverse problem;artificial intelligence;backpropagation;central nervous system;machine learning;calculus;mathematics;electric current;non-linear least squares;least squares;initial value problem;cerebro;artificial neural network;algorithm;statistics	Robotics	90.11683755049876	-38.922457717919535	106845
018fb374170f38c6bf470450f88a667a2d49cbcd	binaural noise psd estimation for binaural speech enhancement	blocking filter binaural speech processing noise psd estimation;speech estimation signal processing algorithms signal to noise ratio speech enhancement acoustics;coherence model binaural noise psd estimation power spectral density estimation binaural speech enhancement background noise equalization cancelation binaural hearing flms algorithm fast least mean square algorithm blocking filter output error left interaural transfer function estimation right interaural transfer function estimation;speech enhancement estimation theory filtering theory least mean squares methods	In this paper we propose a novel binaural algorithm to estimate the power spectral density (PSD) of the background noise at the left and right ear separately. Inspired by equalization-cancelation considered in binaural hearing, the target speech is canceled at both left and right ears by means of the FLMS (fast least-mean square) algorithm. Assuming the ideal equalization, the output error of the blocking filter is a biased estimation of noise PSD. The estimated noise PSD is further corrected by exploiting the estimated left and right interaural transfer functions and the coherence model of the noise field. In addition to noise power estimation assessment, the estimated noise PSD is integrated in a binaural speech enhancement framework in order to evaluate the overall noise reduction performance.	algorithm;binaural beats;blocking (computing);mean squared error;noise power;noise reduction;spectral density;speech enhancement	Masoumeh Azarpour;Gerald Enzner;Rainer Martin	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6854971	speech recognition;computer science	EDA	83.53294413798649	-34.167601679694926	106945
c67cde7622f10a4b7c8b59bef081af47bdb1fed4	sensitivity maps for metal detector design	remote sensing geophysical measurement technique geology buried object detection terrestrial electricity geoelectric method metal detector theory static sensitivity map metal detector design eddy current permeability contrast graphic representation detector response standardized infinitesimal object sphere detection coil shape;detectors;magnetic flux;design tool;instruments;detector response;detection coil shape;instrumentation;graphic representation;metals;metal detector theory;remote sensing geophysical techniques terrestrial electricity geophysical equipment;instrumentacion;detector;localization;geoelectric method;element metallique;detectors coils couplings mercury metals frequency magnetic flux magnetic moments high definition video voltage permeability;detecteur;elemento metalico;conception;localizacion;buried object detection;eddy current;geophysical measurement technique;sphere;metal detector design;localisation;geology;magnetic moments;static sensitivity map;coils;sensitivity analysis;graphical representation;remote sensing;voltage;mercury metals;high definition video;diseno;analyse sensibilite;design;permeability;standardized infinitesimal object;geophysical equipment;couplings;frequency;terrestrial electricity;geophysical techniques;permeability contrast	Eddy-current or permeability-contrast based metal detectors may be characterized by static sensitivity maps, a new graphic representation that maps detector response to a standardized infinitesimal object in a static field. A sphere is shown to be a suitable standard object because its behavior describes, to within multiplicative constants, objects of arbitrary conductivity and permeability. Static sensitivity maps take full account of both the excitation and detection coil shapes. They are compact, easy to understand, closely related to industrial testing procedures, and likely to prove a useful design tool. Their usefulness is illustrated by examples based on a metal detector for which published data exist.	map	Peter P. Silvester;Dzevat Omeragic	1996	IEEE Trans. Geoscience and Remote Sensing	10.1109/36.499783	detector;optics;physics;quantum mechanics;remote sensing	Mobile	90.19328277243409	-25.03762444541661	107015
a3b42d2bcebbcaace208c3bc9b2a93be3c530a58	improved referencing schemes for 2.5d wave field synthesis driving functions	green s function methods;speech processing;speech;two dimensional displays;receivers;loudspeakers;three dimensional displays	Wave Field Synthesis allows the reconstruction of an arbitrary target sound field within a listening area by using a secondary source contour of spherical monopoles. While phase correct synthesis is ensured over the whole listening area, amplitude deviations are present besides a predefined reference curve. So far, the existence and potential shapes of this reference curve was not extensively discussed in the Wave Field Synthesis literature. This paper introduces improved driving functions for 2.5D Wave Field Synthesis. The novel driving functions allow for the control of the locations of amplitude correct synthesis for arbitrarily shaped-possibly curved-secondary source distributions. This is achieved by deriving an expressive physical interpretation of the stationary phase approximation leading to the presented unified Wave Field Synthesis framework. The improved solutions are better suited for practical applications. Additionally, a consistent classification of existing implicit and explicit 2.5D sound field synthesis solutions as special cases of the unified framework is given.	2.5d;approximation;broadcast range;secondary source;stationary process;unified framework	Gergely Firtha;Peter Fiala;Frank Schultz;Sascha Spors	2017	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2017.2689245	loudspeaker;speech recognition;acoustics;computer science;speech;speech processing;mathematics;linguistics	EDA	87.35269193312084	-34.83150685876371	107025
ef0887a3257b7eaf28d1304d355d82cf0f372483	advanced signal processing methods for quantitation of resonances in magnetic resonance spectra	nmr;least squares approximations;magnetic resonance signal processing principal component analysis least squares approximation matrix decomposition signal processing algorithms data mining gaussian noise shape measurement biomedical signal processing;magnetic resonance spectroscopy;hankel transforms;numerical algebra;total least square;magnetic resonance;signal processing;principal component analysis;biomedical signal processing;performance signal processing methods magnetic resonance spectra principal component analysis hankel total least squares based methods resonance estimation simulated data sets;hankel transforms magnetic resonance spectroscopy signal processing magnetic resonance principal component analysis least squares approximations;sista;pca;dsp	A careful comparison between principal component analysis (PCA) and Hankel total least squares (HTLS) based methods for estimating the resonances in sets of magnetic resonance (MR) spectra is presented. After a description of the methods, we compare their performance on simulated data sets and discuss their advantages and limitations.	rca spectra 70;resonance;signal processing	Yu Wang;Sabine Van Hu√øel;Leentje Vanhamme;Nicola Mastronardi;Paul Van Hecke	2000		10.1109/CBMS.2000.856877	computer science;machine learning;signal processing;statistics;principal component analysis	NLP	83.17586208180425	-45.742608444896206	107137
b0aaf4383ac936c6fafe24b9d41d58a499179a03	unified denoising and dereverberation method used in restoration of mtf-based power envelope	reverberation;speech intelligibility;noise measurement speech reverberation noise reduction signal to noise ratio frequency modulation;noisy reverberant condition denoising method dereverberation method mtf based power envelope speech enhancement background noise effect modulation transfer function;unification modulation transfer function denoising dereverberation power envelope restoration;speech enhancement;speech intelligibility reverberation signal denoising speech enhancement;signal denoising	Recent methods of speech enhancement have been proposed to suppress the effects of background noise and reverberation. The effect of background noise in these methods is regarded as additive and that of reverberation is convolutive. Therefore, methods of reducing noise and dereverberation have been applied separately in tandem. We previously unified the effects of noise and reverberation in the modulation transfer function (MTF) concept and we proposed an approach to simultaneously removing the effects of noise and reverberation. This paper further verifies our proposed approach, mathematically and quantitatively. In addition, we generalized the model to four types of real application scenarios, which corresponded to far and near field conditions under noisy reverberant conditions, based on mathematical analysis. We carried out 12,000 simulations for each according to the four application scenarios for denoising and dereverberating noisy reverberant speech, and objectively evaluated the proposed approach. The experimental results revealed that the proposed approach worked well in simultaneously denoising and dereverberating noisy reverberant speech.	circuit restoration;modulation;near field communication;noise reduction;simulation;speech enhancement;transfer function;utility functions on indivisible goods	Masashi Unoki;Xugang Lu	2012	2012 8th International Symposium on Chinese Spoken Language Processing	10.1109/ISCSLP.2012.6423499	speech recognition;acoustics;reverberation;linguistics;intelligibility	EDA	84.06427018197044	-35.222803414975196	107867
cf9d16bd93b4fcb3020688cf4816445b25f83a64	a geometrical approach to room compensation for sound field rendering applications	acoustic field;least squares approximations;loudspeakers;transient response;compensation filter;control points;fast beam tracing modeling engine;geometrical approach;least squares inversion;listening area;loudspeakers;propagation matrix;room compensation;room impulse response;room reflections;sound field rendering applications;spatial impression;soundfield rendering;geometrical acoustics;room compensation;room reflections	In this paper we propose a method for reducing the impact of room reflections in sound field rendering applications. Our method is based on the modeling of the acoustic paths (direct and reflected) from each of the loudspeakers of the rendering system, and a set of control points in the listening area. From such models we derive a propagation matrix and compute its least-squares inversion. Due to its relevant impact on the spatial impression, we focus on the early reflections part of the Room Impulse Response, which is conveniently estimated using the fast beam tracing modeling engine. A least squares problem is formulated in order to derive the compensation filter. We also demonstrate the robustness of the proposed solution against errors in geometric measurement of the hosting environment.	acoustic cryptanalysis;algorithm;beam tracing;broadcast range;computer simulation;control point (mathematics);least squares;loudspeaker;matrix regularization;reflection (computer graphics);rendering (computer graphics);software propagation	Antonio Canclini;Dejan Markovic;Lucio Bianchi;Fabio Antonacci;Augusto Sarti;Stefano Tubaro	2014	2014 22nd European Signal Processing Conference (EUSIPCO)		computer vision;simulation;acoustics;engineering	Visualization	86.61004654636534	-34.168155654699554	107994
10bc450dd2bf4d21d80458c744809023ac1228e1	a binaural short time objective intelligibility measure for noisy and enhanced speech		Objective intelligibility measures are increasingly being used to assess the performance of speech processing algorithms, e.g. for hearing aids. It has been shown that the short time objective intelligibility (STOI) measure yields good results in this respect. In this paper we propose a binaural extension of the STOI measure, which predicts binaural advantage using a modified equalization cancellation (EC) stage. The proposed method is evaluated for a range of acoustic conditions. Firstly, the method is able to predict the advantage of spatial separation between a speech target and a speech shaped noise (SSN) interferer. Secondly, the method yields results comparable to the monaural STOI measure when presented with noisy speech processed by ideal time-frequency segregation (ITFS). Finally, the method also performs well when presented with a selection of different acoustic conditions combined with beamforming as used in hearing aids.	acoustic cryptanalysis;algorithm;beamforming;binaural beats;dmz (computing);instructional television fixed service;intelligibility (philosophy);speech processing	Asger Heidemann Andersen;Jan Mark de Haan;Zheng-Hua Tan;Jesper Jensen	2015			speech recognition;intelligibility	ML	84.1713621059515	-34.77010570162386	108439
8a82243ca0156bf7ac84d7c67b6bf16a7b762c17	maximum kurtosis beamforming with the generalized sidelobe canceller	wall street journal;tracking system;indexing terms;automatic speech recognition;microphone array;speech recognition;audio visual;delay and sum;adaptive beamforming;generalized sidelobe canceller	This paper presents an adaptive beamforming application based on the capture of far-field speech data from a real single speaker in a real meeting room. After the position of a speaker is estimated by a speaker tracking system, we construct a subbanddomain beamformer in generalized sidelobe canceller (GSC) configuration. In contrast to conventional practice, we then optimize the active weight vectors of the GSC so that the distribution of an output signal is as non-Gaussian as possible. We consider kurtosis in order to measure the degree of non-Gaussianity. Our beamforming algorithms can suppress noise and reverberation without the signal cancellation problems encountered in conventional beamforming algorithms. We demonstrate the effectiveness of our proposed techniques through a series of farfield automatic speech recognition experiments on the MultiChannel Wall Street Journal Audio Visual Corpus (MC-WSJAV). The beamforming algorithm proposed here achieved a 13.6% WER, whereas the simple delay-and-sum beamformer provided a WER of 17.8%.	algorithm;beamforming;experiment;gsc bus;speech recognition;the wall street journal;tracking system;word error rate	Ken'ichi Kumatani;John W. McDonough;Barbara Rauch;Philip N. Garner;Weifeng Li;John Dines	2008			speech recognition;index term;tracking system;computer science;adaptive beamformer	ML	84.43426442389207	-34.74491361722357	108646
6fff6f676bf270eb47204081a45c53f4ec35123c	theory and design of multizone soundfield reproduction using sparse methods	microphones;reverberation;ieee transactions;multizone soundfield reproduction;transfer functions acoustic signal processing filtering theory loudspeakers microphones regression analysis reverberation signal representation;planewave decomposition multizone soundfield reproduction reverberation acoustic transfer function sparse approximation;speech processing;speech;sparse approximation;loudspeakers;loudspeakers microphones speech processing harmonic analysis approximation methods acoustic noise sparse matrices;planewave decomposition;approximation methods;acoustic transfer function;real world listening environment multizone soundfield reproduction sparse methods extended spatial region acoustic signal processing reverberant environments acoustic transfer function identification atf loudspeaker filters microphone measurements planewave decomposition optimal least squares solution reproduction error minimization sparse planewave representation;harmonic analysis	Multizone soundfield reproduction over an extended spatial region is a challenging problem in acoustic signal processing. We introduce a method of reproducing a multizone soundfield within a desired region in reverberant environments. It is based on the identification of the acoustic transfer function (ATF) from the loudspeaker over the desired reproduction region using a limited number of microphone measurements. We assume that the soundfield is sparse in the domain of planewave decomposition and identify the ATF using sparse methods. The estimates of the ATFs are then used to derive the optimal least-squares solution for the loudspeaker filters that minimize the reproduction error over the entire reproduction region. Simulations confirm that the method leads to a significantly reduced number of required microphones for accurate multizone sound reproduction, while it also facilitates the reproduction over a wide frequency range. Practical experiments are used to verify the sparse planewave representation of the reverberant soundfield in a real-world listening environment.	acoustic cryptanalysis;basis function;computer simulation;dvd region code;experiment;frequency band;function model;least squares;loudspeaker;microphone;signal processing;sparse approximation;sparse matrix;transfer function	Wenyu Jin;W. Bastiaan Kleijn	2015	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2015.2479037	loudspeaker;speech recognition;acoustics;reverberation;computer science;speech;harmonic analysis;sparse approximation;speech processing	ML	84.35354531091103	-35.740208161171815	108997
ba38eba236346784e45020865675157d251fd8db	cross array and rank-1 music algorithm for acoustic highway lane detection	microphones;azimuth observation rank 1 music algorithm acoustic highway lane detection multilane traffic monitoring system acoustic based lane detection approach chinese highway configuration cross array structure cross correlation matrix multiple signal classification algorithm parzen window based technique vehicle azimuth probability density function;acoustics;vehicle detection;acoustic detectors;sound;monitoring;roads;lane detection traffic monitoring microphone array beamforming direction of arrival estimation;traffic engineering computing acoustic signal detection road traffic signal classification statistical analysis;traffic lanes;algorithms;traffic surveillance;vehicles;detection and identification systems;monitoring vehicles acoustics roads microphones vehicle detection	A vehicle emits sound as it travels along the road, which can be used as a kind of robust feature for traffic monitoring. In this paper, an acoustic-based lane detection approach is introduced for a multilane traffic monitoring system. First, a microphone array is designed according to a typical Chinese highway configuration. The design is based on the cross-array structure, and the cross-correlation matrix from the two subarrays in the selected working frequency band is calculated for the subsequent traffic monitoring operations. Then, a cross section across the road is constructed by beamforming, in which the single-source assumption can be applied, and the passing vehicle azimuth is detected by the proposed rank-1 Multiple Signal Classification (MUSIC) algorithm. Finally, a Parzen-window-based technique is proposed to estimate the vehicle azimuth probability density function (pdf) from the individual azimuth observations. Lane centers and boundaries can be revealed from the peak and valley patterns of the estimated pdf. A prototype traffic monitoring system is developed, and several lane detection approaches are compared in both simulated and real-world environments in the developed system framework. The experimental results exhibit the efficiency of the proposed approach.	acoustic cryptanalysis;algorithm;beamforming;computational complexity theory;covox speech thing;cross section (geometry);cross-correlation;direction of arrival;experiment;frequency band;image resolution;java;kernel density estimation;left 4 dead 2;music (algorithm);microphone;online algorithm;portable document format;prototype;radar;sensor web;website monitoring;window function	Yueyue Na;Yanmeng Guo;Qiang Fu;Yonghong Yan	2016	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2016.2521661	speech recognition;telecommunications;engineering;sound	Robotics	83.90924334766729	-41.83692485284759	109266
95012c44d05d84d517953c00992c717a2dba13c2	beamformer for driving binaural speech enhancement	speech enhancement delay and sum beamformer tdoa estimation binaural hearing aids;estimation speech speech enhancement delay complexity theory discrete fourier transforms algorithm design and analysis		beamforming;binaural beats;speech enhancement	Heinrich W. L√∂llmann;Peter Vary	2012			speech recognition;acoustics;communication	NLP	83.66829893048686	-34.3067170567305	109384
34f14b1c14407c951d77eb47d706a3d36edc5f90	room acoustics measurement system design using simulation and experimental studies	eigenvalues and eigenfunctions;filtering;room design;engineering design;design engineering;simulation;measurement system;architectural acoustics;room acoustics measurement;noise measurement;acoustical engineering;signal processing;acoustic noise;image method;simulation acoustic measurements experimental study image method room acoustics;acoustic measurements acoustic noise noise measurement low pass filters signal processing filtering mesh generation eigenvalues and eigenfunctions acoustical engineering design engineering;low pass filters;mesh generation;acoustic measurements;room design inverse acoustic room problems room acoustics measurement;inverse problems acoustic measurement architectural acoustics;room acoustics;inverse acoustic room problems;inverse problems;acoustic measurement	Room acoustics is an important but difficult part of room design. Good design is achieved more on the basis of acoustic expertise than on pure engineering design. Among the reasons for this situation are the limitations due to acoustic measurement system design and the difficulties in solving inverse acoustic room problems given acoustic requirements. This paper investigates the means for improving the room acoustic measurement system and for validating simulation approaches for room acoustics design.	acoustic cryptanalysis;chinese room;engineering design process;requirement;simulation;system of measurement;systems design	Dan S. Necsulescu;Wei Zhang;W. Weiss;Jerzy Z. Sasiadek	2009	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2008.926043	filter;mesh generation;electronic engineering;speech recognition;acoustics;acoustical engineering;low-pass filter;room acoustics;computer science;inverse problem;engineering;noise measurement;signal processing;noise;system of measurement;physics	Embedded	86.04288248840314	-33.794414079846455	111302
a81ba3aa3c572040abd390ea86041c766b4c08b3	a photoplethysmographic signal isolated from an additive motion artifact by frequency translation		Acquiring a precise percentage of oxygen saturation (SpO2) from a finger-probe pulse oximeter is dependent on both artifact-free red and infrared photoplethysmoghaphic (PPG) signals. Nonetheless, in real-life situations, these PPG signals are corrupted by a motion artifact (MA) signal that is generated from either finger or hand movement. To resolve this MA interference, the cause of the adulteration of PPG signals by the MA signal is examined. The MA signal is found to behave like an additive noise. Additionally, the frequency responses of the MA and PPG signals show that these signals are in the same frequency band. Hence, instead of direct current, a sinusoidal wave alternating current is proposed to drive an LED source in order to shift the PPG frequency band away from the MA frequency band. Experimentally, a commercial finger-probe pulse oximeter is employed. To determine the performance of the presented scheme, the resulting PPG signals are compared with those from employing the old-fashioned LED-driving method. In addition, the accuracy is verified by computing the SpO2 value. The results reveal that the proposed approach successfully retains the fundamental morphologies of the PPG structures when motion occurs. Moreover, the calculated SpO2 values from the proposed technique provide an average error of approximately 1.4%, whereas the conventional method yields a mean error approximately 4.2%.	additive model;additive white gaussian noise;artifact (error);computation (action);cumulative trauma disorders;experiment;frequency band;frequency response;heterodyne;interference (communication);oxygen saturation test result;real life;utility functions on indivisible goods	Sakkarin Sinchai;Pattana Kainan;Paramote Wardkein;Jeerasuda Koseeyaporn	2018	IEEE Transactions on Biomedical Circuits and Systems	10.1109/TBCAS.2018.2829708	electronic engineering;infrared;alternating current;frequency band;direct current;computer science;interference (wave propagation);pulse (signal processing);mean squared error;sine wave	Visualization	85.17153601214264	-39.56096367014968	111527
c8de0efa863980f09c1c8f74fab76f95666dcb40	motion induced error in continuous-wave electromagnetic induction sensors		An error mechanism for continuous wave electromagnetic induction sensors has been discovered and analyzed. The error is due to the signal processing when the received signal is modulated by the relative motion between the target and the sensor. A simple modification of processing the data has been developed that mitigates this error, and the method is demonstrated with experimental data.	modulation;sensor;signal processing	Waymond R. Scott	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8518019	computer vision;electromagnetic induction;experimental data;continuous wave;signal processing;artificial intelligence;electronic engineering;electromagnetic interference;frequency modulation;computer science	Embedded	85.30618985962462	-41.721128961652944	111961
de7a00428ce3bcf7dd5c53bed3dd0abb84c50cb6	improved wideband doa estimation using modified tops (mtops) algorithm	wideband;direction of arrival estimation signal to noise ratio signal processing algorithms sensor arrays covariance matrices wideband estimation;wideband sources array signal processing direction of arrival doa estimation doa high resolution test of orthogonality of projected subspaces tops;estimation;covariance matrices;signal to noise ratio;signal processing algorithms;sensor arrays;direction of arrival estimation	Test of orthogonality of projected subspaces (TOPS) estimates directions of arrival of wideband sources by exploiting orthogonality between signal and noise subspaces in spectral domain. TOPS performs well at mid signal-to-noise ratio (SNR) range, but fares poorly at high SNR and noise-free cases. The TOPS pseudospectrum often exhibits spurious peaks at all SNR levels. This paper attempts to explain the cause of poor performance, and proposes suitable modifications to extend the effectiveness of TOPS from low SNR to noise-free case. The proposed modified-TOPS (mTOPS) achieves reduction in spurious peaks by incorporating signal-subspace projection instead of null-space projection used in TOPS. It also uses trace as performance metric, instead of loss of rank used in TOPS. The effectiveness of mTOPS has been studied via simulations.	algorithm;direction of arrival;kernel (linear algebra);pseudospectrum;signal subspace;signal-to-noise ratio;simulation;tops	Arnab K. Shaw	2016	IEEE Signal Processing Letters	10.1109/LSP.2016.2614310	estimation;speech recognition;mathematics;signal-to-noise ratio;statistics	Metrics	83.74634090210824	-38.02888404106201	112140
46c5deabec6c2758ebbd36ae96d8e8253e5dd5a4	personal audio loudspeaker array as a complementary tv sound system for the hard of hearing	beamforming	SUMMARY A directional array radiator is presented, the aim of which is to enhance the sound of the television in a particular direction and hence provide a volume boost to improve speech intelligibility for the hard of hearing. The sound radiated by the array in other directions is kept low, so as not to increase the reverberant level of sound in the listening room. The array uses 32 loudspeakers, each of which are in phase-shift enclosures to generate hypercardioid directivity, which reduces the radiation from the back of the array. The loudspeakers are arranged in 8 sets of 4 loudspeakers, each set being driven by the same signal and stacked vertically, to improve the directivity in this plane. This creates a 3D beamformer that only needs 8 digital filters to be made superdirective. The performance is assessed by means of simulations and measurements in anechoic and reverberant environments. The results show how the array obtains a high directivity in a reverberant environment.	beamforming;digital filter;in-phase and quadrature components;intelligibility (philosophy);loudspeaker;simulation;sound card;spike directivity;television	Marcos F. Sim√≥n G√°lvez;Stephen J. Elliott;Jordan Cheer	2014	IEICE Transactions		speech recognition;directional sound;beamforming	HPC	85.29680764659844	-34.49543370903018	112412
d75c4afbca8574efa578af0777e0bc7d2d1474f8	support vector machines for antenna array processing and electromagnetics	antenna arrays;support vector machines;angle of arrival;electromagnetics;support vector machine;beamforming;antenna array	Abstract Support Vector Machines (SVM) were introduced in the early 90's as a novel nonlinear solution for classification and regression tasks. These techniques have been proved to have superior performances in a large variety of real world applications due to their generalization abilities and robustness against noise and interferences. This book introduces a set of novel techniques based on SVM that are applied to antenna array processing and electromagnetics. In particular, it introduces methods for linear and nonlinear beamforming and parameter design for arrays and electromagnetic applications.	array processing;support vector machine	Manel Mart√≠nez-Ram√≥n;Christos Christodoulou	2006		10.2200/S00020ED1V01Y200604CEM005	support vector machine;machine learning;physics	Arch	88.07457007291043	-38.2495543829878	112852
2d9a6062e8f201d0071d0fb58a72e13bb4711fbc	fundamental consideration on distance estimation using acoustical standing wave	tecnologia electronica telecomunicaciones;spectrum;distance estimation;power spectrum;standing wave;range spectrum;audible sound;tecnologias;grupo a	In the research field of microwave radar, a range finding method based on standing wave is known to be effective for measuring short distances. In this paper, we focus our attention on audible sound and fundamentally examine the distance estimation method in which acoustical standing wave is used.		Noboru Nakasako;Tetsuji Uebo;Atsushi Mori;Norimitsu Ohmata	2008	IEICE Transactions	10.1093/ietfec/e91-a.4.1218	spectrum;telecommunications;electrical engineering;spectral density;quantum mechanics;standing wave	Visualization	86.6254082899962	-35.004133490067886	113138
5f12dc95e5e3547de5510700f99b543a66e2e62d	conventional and binary time series models of sonar fluctuations	prediction error;fluctuations;spectrum;time series;sonar detection;fluctuations predictive models sonar detection sonar measurements underwater acoustics acoustic noise acoustic measurements power measurement narrowband spectral analysis;acoustic noise;predictive models;spectral analysis;acoustic measurements;underwater acoustics;narrowband;evaluation model;power measurement;sonar measurements;time series model	The presence of received power fluctuations of underwater acoustic signals and noise is commonplace. This paper addresses the power fluctuations as measured at the output of a narrowband spectrum analyzer. The purpose of this paper is to develop and evaluate models of underwater sound fluctuations that can be used for short‚Äîterm predictions. Conventional time series models were used, and short-term prediction errors were between 1.3 and 2.5 riB. A new binary time series is developed and results presented. The Binary Model predicts detections (+1) and no detections (‚Äî1). The forecast of detections/no detections with the Binary Model resulted in errors as low as eight percent for some of the sonar time series.	acoustic cryptanalysis;like button;power supply;sonar (symantec);sensor;spectrum analyzer;time series	Jude Franklin;Robert J. Urick	1981		10.1109/ICASSP.1981.1171174	speech recognition;time series;mathematics;statistics	HCI	83.89666964136418	-30.26141860060419	113334
230c2daa221db7ba19422cff18ef48c1f4591fad	compact rf-photonic configuration for highly resolved and ultra-fast extraction of carrier and information of radar signal	tunable filter;information extraction;optical filters;signal resolution data mining finite impulse response filter optical filters radar detection optical modulation monitoring laser radar optical beams filtering;electro optical modulation;optical modulator;optical tuning electro optical modulation optical filters radar signal processing fir filters;fir filter;optical tuning;fir filters;radar signal processing;low rate tunable filter electro optical modulator all optical ultra fast spectral filter rf photonic configuration ultra fast carrier detection low rate detector energetic fluctuations information extraction radar signal resolution optically modulated radar signal fir filter filter spectral scan spectral filtering	A highly resolved carrier and information extraction of an optically modulated radar signal is presented. The extraction is done by passing the optical beam through a monitoring path that realizes an FIR filter. Replications of the monitoring signal realize the required spectral scan of the filter. Despite the fact that the filter configuration is fixed, each replication experiences different spectral filtering. The radar carrier is detected by observing the energetic fluctuations in a low rate detector. The RF information is extracted by positioning a low rate tunable filter at the detected carrier frequency.	carrier frequency;filter bank;finite impulse response;information extraction;modulation;radar;radio frequency	Zeev Zalevsky;Amir Shemer;Vardit Eckhouse;David Mendlovic;Shlomo Zach	2004	Proceedings of the 2004 11th IEEE International Conference on Electronics, Circuits and Systems, 2004. ICECS 2004.	10.1109/ICECS.2004.1399721	electronic engineering;low-pass filter;telecommunications;engineering;analytical chemistry;optical filter;band-stop filter;filter design;prototype filter;matched filter	Robotics	84.59444481053333	-41.84877460197321	113559
126c21542ebf3280c01e92867a7f58272e3bafef	an adaptive rational filter for interpretation of spectrometric data	data engineering;spectrum;environmental engineering;adaptive filters;biomedical engineering;deconvolution;bandwidth;application software;spectroscopy	The computer-based interpretation of spectrometric data is of great importance for applications of various kinds of spectroscopy in science, biomedical engineering, environmental engineering, and industry. It is based on the use of algorithms of (generalized) deconvolution for correcting spectrometric data, i.e., compensating for the instrumental effects and natural bandwidth effects distorting those data. Among many sophisticated methods currently used for this purpose, no one method is able to properly deal with the irregularities in the data such as the variable shape of peaks of which the interpreted spectrum is composed. In this paper, a flexible and efficient algorithm of generalized deconvolution is proposed, viz. an adaptive rational filter. It is proven to satisfactorily solve this problem by recursive adaptation of its parameters to the widths of the consecutive peaks of which the interpreted spectrum is composed, as well as to the relative distances between peaks along the wavelength axis.		Michal Wisniewski;Roman Z. Morawski;Andrzej Barwicz	2003	IEEE Trans. Instrumentation and Measurement	10.1109/TIM.2003.809066	adaptive filter;spectrum;electronic engineering;application software;spectroscopy;computer science;engineering;deconvolution;bandwidth;physics;quantum mechanics;statistics	Embedded	83.42573389010386	-46.222755958105026	113733
5a0db541febc765bf4b4bccf77222aeb98dcde52	active feedback noise control in the presence of impulsive disturbances	ducts;closed loop noise cancelling system active feedback control narrowband acoustic noise impulsive disturbances outlier detector feedback control algorithm sonic noise pulses;adaptive signal processing active noise control rejection of impulsive disturbances;estimation;patents;tv;filtration;feedback acoustic signal processing active noise control;tv estimation ducts filtration patents	The problem of active feedback control of a narrowband acoustic noise in the presence of impulsive disturbances is considered. It is shown that, when integrated with appropriately designed outlier detector, the proposed earlier feedback control algorithm called SONIC is capable of isolating and rejecting noise pulses. According to our tests this guarantees stable and reliable operation of the closed-loop noise cancelling system.	acoustic cryptanalysis;algorithm;feedback;norm (social)	Maciej Niedzwiecki;Michal Stanislaw Meller	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7178051	duct;estimation;noise;filtration;noise measurement;noise;control theory;mathematics;noise floor;statistics	Robotics	84.50771572717008	-33.59879455576388	113988
d7c85aff86edc8fae57475a87517bc70a7f5d2ad	using rational filters for digital correction of a spectrometric microtransducer	rational functions;systematic errors;quantization;error correction;signal reconstruction;computational complexity;digital filters;transducers;chemical analysis;digital signal processing;spectrometers;systematic error;information technology;mathematical model;calibration;iterative methods;low resolution;algorithms;measurement errors;pseudoinverse;spectroscopy;atomic absorption spectroscopy	The raw spectrometric data are subject to systematic errors of an instrumental type that may be reduced, provided a mathematical model of the spectrometer, or its pseudoinverse, i.e., an operator of reconstruction, is identified. The idea of identifying this operator, directly during calibration of the spectrometer, is developed in this paper. The applicability of an operator of reconstruction, having the form of a rational filter, is studied when it is used for correction of the instrumental errors introduced by a low-resolution spectrometric microtransducer (SMT) that is intended for designing a microspectrometer. Several algorithms of correction are developed and systematically studied using real-world spectra and a nonlinear mathematical model of the microtransducer, proposed by the authors in a previous publication.	algorithm;mathematical model;moore‚Äìpenrose pseudoinverse;nonlinear system	Michal Wisniewski;Roman Z. Morawski;Andrzej Barwicz	2000	IEEE Trans. Instrumentation and Measurement	10.1109/19.836307		Vision	83.22441739005956	-45.792972408105456	114094
3e404c2bba09d7b78ff85c86781b04ed00be7755	design and fabrication of 3d fingerprint targets	standards;3d printing;skin;fingerprint reader evaluation;three dimensional displays;2d pattern to 3d surface projection;feature extraction;3d fingerprint targets;2d calibration patterns;optical device fabrication;calibration	Standard targets are typically used for structural (white-box) evaluation of fingerprint readers, e.g., for calibrating imaging components of a reader. However, there is no standard method for behavioral (black-box) evaluation of fingerprint readers in operational settings where variations in finger placement by the user are encountered. The goal of this research is to design and fabricate 3D targets for repeatable behavioral evaluation of fingerprint readers. 2D calibration patterns with known characteristics (e.g., sinusoidal gratings of pre-specified orientation and frequency, and fingerprints with known singular points and minutiae) are projected onto a generic 3D finger surface to create electronic 3D targets. A state-of-the-art 3D printer (Stratasys Objet350 Connex) is used to fabricate wearable 3D targets with materials similar in hardness and elasticity to the human finger skin. The 3D printed targets are cleaned using 2M NaOH solution to obtain evaluation-ready 3D targets. Our experimental results show that: 1) features present in the 2D calibration pattern are preserved during the creation of the electronic 3D target; 2) features engraved on the electronic 3D target are preserved during the physical 3D target fabrication; and 3) intra-class variability between multiple impressions of the physical 3D target is small. We also demonstrate that the generated 3D targets are suitable for behavioral evaluation of three different (500/1000 ppi) PIV/Appendix F certified optical fingerprint readers in the operational settings.	2d computer graphics;3d computer graphics;3d printing;black box;elasticity (data store);fingerprint recognition;minutiae;printer (computing);simulation;spatial variability;wearable computer;white box (software engineering)	Sunpreet S. Arora;Kai Cao;Anil K. Jain;Nicholas G. Paulter	2016	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2016.2581306	computer vision;calibration;simulation;feature extraction;3d printing;computer science;machine learning;skin	HCI	83.02353475725263	-24.35357032364676	114180
2b61767aa73112a92407eaf5050c6d03db34419e	microphone array sub-band speech recognition	microphones;microphone arrays speech recognition speech enhancement array signal processing frequency estimation noise robustness noise reduction laboratories australia hidden markov models;acoustic signal processing microphones speech enhancement speech recognition hidden markov models spatial filters array signal processing acoustic arrays;hidden markov model;acoustic signal processing;array signal processing;speech enhancement;spatial filters;spectral density;a priori knowledge;hidden markov models;microphone array;speech recognition;dynamic weighting scheme microphone array sub band speech recognition broadband beamforming microphone array beamformer band limited sub arrays hidden markov models dynamic sub band weighting scheme auto spectral densities cross spectral densities reliability isolated digit recognition standard full band approach;acoustic arrays	This paper proposes the integration of sub-band speech recognition with a microphone array. A broadband beamforming microphone array allows for natural integration with sub-band speech recognition as the beamformer is typically implemented as a combination of band-limited sub-arrays. In this paper, rather than recombining the sub-array outputs to give a single enhanced output, we propose the fusion of separate hidden Markov models trained on each subarray frequency band. In addition, a dynamic sub-band weighting scheme is proposed in which the crossand auto-spectral densities of the microphone array inputs are used to estimate the reliability of each frequency band. The microphone array sub-band system is evaluated on an isolated digit recognition task and compared to the standard full-band approach. The results of the proposed dynamic weighting scheme are compared to those obtained using both fixed equal sub-band weights, as well as optimal sub-band weights calculated froma priori knowledge of the correct results.	bandlimiting;beamforming;frequency band;hidden markov model;markov chain;microphone;speech recognition	Iain McCowan;Sridha Sridharan	2001		10.1109/ICASSP.2001.940798	a priori and a posteriori;speech recognition;noise-canceling microphone;computer science;spectral density;hidden markov model	ML	83.00452695582985	-34.665728066476625	114303
8876ab64d8a99a89001dfec463f00dbcf51e2b17	multi-source doa estimation in a reverberant room	statistical room acoustics;multisource estimation multisource doa estimation reverberant room phase transformed weighted algorithm general cross correlation algorithm steered response power algorithm source separation statistical room acoustics approximate maximum likelihood;microphones;reverberation;direction of arrival estimation maximum likelihood estimation reverberation robustness sensor arrays data models discrete fourier transforms phase estimation acoustics microphones;max imum likelihood;approximate maximum likelihood;maximum likelihood;phase transformed weighted algorithm;source separation acoustic signal processing architectural acoustics direction of arrival estimation maximum likelihood estimation reverberation;doa estimation;architectural acoustics;acoustic signal processing;indexing terms;maximum likelihood estimation;generalized cross correlation;data model;reverberant room;steered response power algorithm;phase transformation;general cross correlation algorithm;multisource doa estimation;architectural acoustics direction of arrival estimation maximum likelihood estimation microphones;source separation;multisource estimation;room acoustics;direction of arrival estimation	In a reverberant scenario, phase transformed weighted algorithms are more robust than maximum likelihood (ML) because of the insufficiency of the data model to incorporate reverberant information. This transformation has been applied to general cross-correlation and steered response power algorithms; the latter has been shown to be more robust. For a multiple known number of sources, both algorithms have problems separating the sources that are close together because of the limitation caused by the resolution. Recently, an approach was made using simple well-known statistical room acoustics to model room reverberation, and another parametric approach called the approximate maximum likelihood was made that was designed for multi-source estimations. By combining these methods, we developed an ML algorithm that is suitable for multi-source target estimates in a reverberant room.	approximation algorithm;convergence insufficiency;cross-correlation;data model;direction of arrival;image resolution;multi-source	Andreas M. Ali;Ralph E. Hudson;Kung Yao	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4518154	speech recognition;computer science;mathematics;maximum likelihood;statistics	Robotics	83.8869962779844	-36.3245379937895	114508
75d432c76766e15bc57f17515ba9334349662a5e	spectrum-averaged harmonic path (shapa) algorithm for non-contact vital sign monitoring with ultra-wideband (uwb) radar	frequency domain processing spectrum averaged harmonic path algorithm noncontact vital sign monitoring heart rate estimation respiration rate estimation impulse radio ultrawideband radar periodic human torso movement;ultra wideband radar bioelectric potentials biomedical communication cardiology medical signal processing pneumodynamics spectral analysis ultra wideband communication;heart rate harmonic analysis monitoring ultra wideband radar interference	We introduce the Spectrum-averaged Harmonic Path (SHAPA) algorithm for estimation of heart rate (HR) and respiration rate (RR) with Impulse Radio Ultrawideband (IR-UWB) radar. Periodic movement of human torso caused by respiration and heart beat induces fundamental frequencies and their harmonics at the respiration and heart rates. IR-UWB enables capture of these spectral components and frequency domain processing enables a low cost implementation. Most existing methods of identifying the fundamental component either in frequency or time domain to estimate the HR and/or RR lead to significant error if the fundamental is distorted or cancelled by interference. The SHAPA algorithm (1) takes advantage of the HR harmonics, where there is less interference, and (2) exploits the information in previous spectra to achieve more reliable and robust estimation of the fundamental frequency in the spectrum under consideration. Example experimental results for HR estimation demonstrate how our algorithm eliminates errors caused by interference and produces 16% to 60% more valid estimates.	algorithm;blinded;estimated;hyperacute pancreatic cancer vaccine;interference (communication);radar;rapid refresh;real-time clock;respiratory rate;round-robin scheduling;time series;trunk structure;ultra-wideband;vital signs;heart rate	Van Chi Nguyen;Abdul Qadir Javaid;Mary Ann Weitnauer	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6944065	electronic engineering;telecommunications;engineering;electrical engineering	EDA	84.64104504599969	-40.92381997699468	115067
2a2cbd0d888f2be0e1f0bf0660b4caf98bff705c	the design of the voice communication in smart home care	least mean squares methods;adaptive filter smart home voice recognition noise cancelation elderly people;voice communication adaptive filters home automation least mean squares methods speaker recognition;lms adaptive filter voice communication smart home care voice control building service systems additive noise remote control xcomfort wireless systems intelligent building intelligent house;speaker recognition;adaptive filters;voice communication;home automation	This article describes implementation of comfortable voice-control of building service-systems in a Smart Home Care in a real environment with additive noise. It describes the current condition of research on the voice-operated communication in the Smart Home and the design of a comfortable remote control of building service-systems by the xComfort wireless systems in an intelligent building. An LMS adaptive filter is used for elimination of undesired disturbances in the real environment of an intelligent house in voice communication with a wireless system for removal of additional disturbance from the voice signal.	adaptive filter;additive white gaussian noise;home automation;remote control;speaker recognition;utility functions on indivisible goods	Jan Vanus;Jir√≠ Koziorek;Radim Herc√≠k	2013	2013 36th International Conference on Telecommunications and Signal Processing (TSP)	10.1109/TSP.2013.6613996	adaptive filter;speaker recognition;home automation;speech recognition;computer science	Robotics	84.07192816411282	-32.86734080716907	115094
4d2dcd35fb135bd5216b92695935f44d66fa52f4	double-talk detection in acoustic echo cancellers using zero-crossings rate	zero crossing rate;detectors;art;aec filter adaptation;crosstalk;acoustics;speech processing;filters;acoustic signal processing;low power processing;speech enhancement;time domain analysis;acoustic echo cancellers;indexes;double talk detection;speech processing acoustic signal processing crosstalk echo suppression filters;low power low resource processor double talk detection acoustic echo cancellers zero crossings rate zcr aec filter adaptation;low power processing speech enhancement zero crossing rate;echo suppression;coherence;zero crossings rate;zcr;low power low resource processor;correlation;acoustics indexes detectors art correlation coherence time domain analysis	We propose a new method to detect double-talk and control filter adaptation in an acoustic echo canceller (AEC). The method is based on computing the zero-crossings rate (ZCR) of the AEC output and comparing it against a suitably-chosen threshold. As the ZCR values falls below the threshold, double talk is declared and the AEC filter adaptation is either slowed down or halted. The zero crossings are very easy to compute by observing the sign changes of two consecutive samples from the output of the AEC. In contrast to most existing methods, the computational burden of the proposed method is minimal and it can, therefore, be conveniently implemented on a low-power, low-resource processor. This computational simplicity is enjoyed without sacrificing for any AEC performance. We will illustrate effectiveness of the proposed method by comparing against the existing state of the art and present guidelines on choosing parameters for computing the sample-by-sample ZCR.	acoustic cryptanalysis;computation;digital signal processor;discriminant;echo suppression and cancellation;low-power broadcasting;neural correlates of consciousness;tor messenger;whole earth 'lectronic link;zero-crossing rate	Muhammad Z. Ikram	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7178144	database index;detector;crosstalk;speech recognition;coherence;computer science;speech processing;correlation	Robotics	83.50968363258043	-32.41750293974452	115460
f1a2aa49c0ad0651a9011ea519261936dd9104e6	altitude measurement of low-elevation target for vhf radar based on weighted sparse bayesian learning		In this study, a novel method is proposed to deal with the problem of altitude measurement of a low-elevation target for very high frequency radars in complex terrains. The problem typically concerns about the direction-of-arrival (DOA) estimation method for closely spaced and correlated signals arose by multipath propagation, in which the multipath signal would be modulated by the rough and irregular reflecting surface, result in amplitude and phase perturbation and energy fluctuations of the receiving signals. A perturbation multipath propagation model is derived where the influence of irregular reflecting in complex terrain is taken as a random perturbation of the multipath signal. The spatial sparsity of the receiving signal is then exploited, and a weighted sparse Bayesian learning method is proposed to estimate both the random perturbation coefficients and DOA of the incident signal with high precision. Both the computer simulations and real data analysis indicate the efficiency and superior performance of the proposed method in dealing with altitude measurement in complex terrain.	radar;sparse matrix	Cunxu Li;Baixiao Chen;Minglei Yang;Yisong Zheng	2018	IET Signal Processing	10.1049/iet-spr.2016.0738	algorithm;terrain;mathematics;multipath propagation;elevation;control theory;radar;artificial intelligence;phase perturbation;perturbation (astronomy);altitude;pattern recognition;bayesian inference	Robotics	84.57951679364432	-42.63652908669102	115576
00145e13973297a7737fd3045187822729c61879	ftir spectral subtraction based on asymmetric least squares	binary mixture;least squares approximations;eigenspectra infrared spectrum spectral subtraction scaling vector asymmetric least squares;smoothing method;partial least square;spectrum;partial least squares model ftir spectral subtraction asymmetric least squares infrared absorbance spectral subtraction scaling relation sample spectrum scaling spectrum scaling vector spectral subtraction model reference peak binary mixtures eigenspectra method;spectral subtraction;least square;prediction model;least squares approximations fourier transform spectroscopy infrared spectroscopy;infrared spectroscopy;infrared;fourier transform spectroscopy;ethanol vectors sugar solvents predictive models spectroscopy smoothing methods	Based on asymmetric least squares, a new method for infrared absorbance spectral subtraction is proposed. In order to reflect the scaling relation between the sample spectrum and scaling spectrum, the proposed method uses scaling vector rather than scaling factor which is usually used in the traditional spectral subtraction model. As independent of reference peak, the method can deal with most of subtraction cases of binary mixtures. For multiple system with unknown scaling spectrum, ei-genspectra method is introduced to calculate the accurate scaling spectra. Experimental results show that difference spectra can match the real spectra well. Besides, in contrast to the results of traditional method, difference spectra obtained by this method is more similar with the real spectra. The prediction results based on partial least squares (PLS) model demonstrate that the performance of difference spectra is better than that of sample spectra in characteristic regions.	image scaling;partial least squares regression;rca spectra 70	Chaoling Yang;Silong Peng;Qiong Xie;Jiangtao Peng;Jipin Wei;Yong Hu	2011	2011 4th International Conference on Biomedical Engineering and Informatics (BMEI)	10.1109/BMEI.2011.6098621	spectrum;infrared spectroscopy;infrared;fourier transform spectroscopy;mathematics;predictive modelling;optics;least squares;quantum mechanics;statistics	Vision	82.95522926185697	-48.15144033537153	116240
12a585dfdf9d1fd2f99d8b020824401fc333bb9b	removal of reflection from window image by blind image separation with simultaneous diagonalization of low and high halfbands				Mahdi Khosravy;Mohammad Reza Alsharif;Katsumi Yamashita	2010			computer vision;artificial intelligence;computer science	Vision	83.86438766691418	-38.19186051003412	116398
00bfb165b1c4dbd1f5dfbf42608ff0f8a1c71546	multiple acoustic source localization based on multiple hypotheses testing using particle approach	microphones;multiple hypotheses;microwave integrated circuits;acoustic testing acoustic measurements microphone arrays microwave integrated circuits reverberation position measurement acoustic noise noise measurement particle measurements time difference of arrival;reverberation;atmospheric measurements;particle measurements;data likelihood model;acoustics;time difference of arrival estimation;acoustic feature estimation;measurement hypothesis;multiple acoustic source localization;acoustic signal processing;prior knowledge;microphones acoustic source localization multiple hypotheses testing particle approach acoustic feature estimation measurement association model data likelihood model measurement hypothesis;data association;noise measurement;particle approach;data likelihood time difference of arrival estimation multiple acoustic source localization data association multiple hypotheses;acoustic testing;microphones acoustic signal processing;arrays;acoustic source localization;acoustic noise;position measurement;data likelihood;multiple hypotheses testing;microphone arrays;acoustic measurements;measurement association model;time difference of arrival	Localization of multiple acoustic sources in a non-ideal environment has a number of difficulties, among which are accurate acoustic feature estimation for multiple sources and association uncertainty between measurements and their corresponding sources. This paper focuses more on the latter and proposes an algorithm based on a multiple-hypothesis framework for both a measurement model and a measurement association model to localize multiple sources. A conditional data likelihood model based on a measurement hypothesis is proposed and implemented using particles. Simulation results demonstrate that the proposed algorithm is capable of localizing the positions of multiple sources with a small number of microphones without any prior knowledge when the amount of reverberation is moderate.	acoustic cryptanalysis;algorithm;microphone;simulation	Yeongseon Lee;Ted S. Wada;Biing-Hwang Juang	2010	2010 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2010.5496229	speech recognition;reverberation;noise measurement;multilateration;noise;acoustic source localization	Robotics	87.05462242322301	-37.53739026689345	117539
d7bd26e15ae84740abe93b87b852c7a555b4b48a	echo cancellation for bone conduction transducers	acoustic echo cancellation;bone conduction transducers	Bone conducting transducers are attractive technologies for voice communication systems. Bone vibrators (BVs), typically located on the condyle bone, allow users to listen while leaving their outer ears open, enhancing situational awareness. Meanwhile, bone conduction microphones (BCMs), often located on the temple, increase the transmitted signal to noise ratio because they are relatively insensitive to ambient airborn environmental noise. A communication headset consisting of a BV and a BCM is a natural combination of these promising technologies. The prospect of acoustic coupling between the BVs and BCMs results in acoustic echo if full-duplex communication is used. To our knowledge, such a bone conducting echo path has yet to be characterized. Here, the echo path's linearity, stationarity, and time span are investigated and an echo canceller using bon conducting transducers is presented.	acoustic coupler;acoustic cryptanalysis;bone scintigraphy;duplex (telecommunications);echo suppression and cancellation;headset (audio);microphone;signal-to-noise ratio;stationary process;transducer	Mohammadhossein Behgam;Steven L. Grant	2014	2014 48th Asilomar Conference on Signals, Systems and Computers	10.1109/ACSSC.2014.7094742	speech recognition;acoustics;engineering;communication	HCI	85.104906039858	-39.210887080832116	118449
8cdd67cea63f0ed85a119a188cb7469d211891a9	multi-speaker voice activity detection using ica and beampattern analysis	time frequency;independent component analysis;higher order statistics;speech signal processing algorithms frequency domain analysis direction of arrival estimation microphones clustering algorithms error analysis;voice activity detection;time frequency analysis independent component analysis reverberation signal denoising speaker recognition;sir multispeaker voice activity detection ica beampattern analysis speech signal noise characteristics time frequency plane higher order statistics independent component analysis clean speech estimation highly reverberant conditions	Voice activity detection is a necessary preprocessing step for many applications like channel identification or speech recognition. The problem can be solved even under noisy conditions by exploiting characteristics of speech and noise signals. However, when more speakers are active simultaneously, these methods are generally unreliable, since multiple speech signals may overlap completely in the time-frequency plane. Here, a new approach is suggested which is applicable in multi-speaker scenarios also, owing to its incorporation of higher order statistics. Here, independent component analysis is used to obtain estimates of the clean speech and the angles of incidence for each speaker. Subsequently, these estimates can help to correctly identify the active speaker and perform voice activity detection. The suggested approach is robust to noise as well as to interfering speech and can detect the presence of single speakers in mixtures of speech and noise, even under highly reverberant conditions at 0dB SIR.	algorithm;error message;exploit (computer security);incidence matrix;independent computing architecture;independent component analysis;powered speakers;preprocessor;source separation;speech recognition;voice activity detection	S. Maraboina;Dorothea Kolossa;P. K. Bora;Reinhold Orglmeister	2006	2006 14th European Signal Processing Conference		voice activity detection;speech recognition;acoustics;engineering;speech processing;communication	ML	84.30975155967869	-36.347718643996224	118625
dfb174e3de68a534d21beaac5373bffb4808ad8d	waveform analysis of uwb gpr antennas	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;ultra wideband;ground penetrating radar;uk phd theses thesis;life sciences;time domain;electromagnetic interference;frequency domain;uk research reports;waveform analysis;medical journals;source wavelet;requirement specification;bow tie antenna;europe pmc;biomedical research;bioinformatics	Ground Penetrating Radar (GPR) systems fall into the category of ultra-wideband (UWB) devices. Most GPR equipment covers a frequency range between an octave and a decade by using short-time pulses. Each signal recorded by a GPR gathers a temporal log of attenuated and distorted versions of these pulses (due to the effect of the propagation medium) plus possible electromagnetic interferences and noise. In order to make a good interpretation of this data and extract the most possible information during processing, a deep knowledge of the wavelet emitted by the antennas is essential. Moreover, some advanced processing techniques require specific knowledge of this signal to obtain satisfactory results. In this work, we carried out a series of tests in order to determine the source wavelet emitted by a ground-coupled antenna with a 500 MHz central frequency.	antenna device component;audio signal processing;frequency band;gram-positive rods (bacteria);head injuries, penetrating;kriging;megahertz;software propagation;ultra-wideband;version;waveform;wavelet	Fernando I. Rial;Henrique Lorenzo;Manuel Pereira;Julia Armesto	2009		10.3390/s90301454	electromagnetic interference;electronic engineering;ground-penetrating radar;telecommunications;time domain;computer science;bioinformatics;engineering;electrical engineering;ultra-wideband;frequency domain	Robotics	84.59041607411876	-39.71854323283019	119434
1321f7f798d16beb3476c48ca0ded1a9de687570	robust parametrization for non-destructive evaluation of composites using ultrasonic signals	analysis by synthesis;cepstral distances robust parametrization nondestructive evaluation composites ultrasonic signals carbon fiber reinforced polymers isotropic homogeneous materials signal interpretation parametrization techniques feature extraction;ultrasonics signal processing feature extraction nondestructive evaluation;ultrasonic materials testing;feature extraction cepstrum signal processing ultrasonic variables measurement optimization;ultrasonic variables measurement;acoustic signal processing;ultrasonic applications;nondestructive evaluation;structural complexity;non destructive evaluation;numerical model;cepstrum;feature extraction;signal processing;classification system;optimization;ultrasonic materials testing acoustic signal processing feature extraction fibre reinforced composites ultrasonic applications;ultrasonics;fibre reinforced composites	Anticipating and characterizing damages in layered carbon fiber-reinforced polymers is a challenging problem. Non-destructive evaluation using ultrasonic signals is a well-established method to obtain physically relevant parameters to characterize damages in isotropic homogeneous materials. However, ultrasonic signals obtained from composites require special care in signal interpretation due to their structural complexity. In this paper, some enhancements on the interpretation are done by adapting classical parametrization techniques to extract relevant features from the ultrasonic signals. Thus, a cepstral-based feature extractor is firstly designed and optimized by using a classification system based on cepstral distances. Then, this feature extractor is applied in an analysis-by-synthesis scheme which, by using a numerical model of the specimen, infers the values of the damage parameters.	biological specimen;cepstrum;mathematical model;numerical analysis;optical fiber;randomness extractor;speech coding	Nicolas Bochud;√Ångel M. G√≥mez;Guillermo Rus-Carlborg;Jos√© L. Carmona;Antonio M. Peinado	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5946850	structural complexity;speech recognition;nondestructive testing;feature extraction;computer science;cepstrum;speech coding;signal processing	Robotics	93.0244644487676	-24.04994643736968	119980
b880fa86b93395435658363eb3579ac1028c359e	adaptive filtering exploiting band-limited property of sound field in the wave domain	microphones;acoustic signal processing;sound reproduction;space time frequency representation wave domain adaptive filtering;time frequency analysis acoustic signal processing adaptive filters computational complexity echo suppression loudspeakers microphones sound reproduction;adaptive filters;loudspeakers;sound field space time frequency representation band limited property computational complexity reduction wave domain adaptive filtering microphones massive multichannel sound reproduction massive loudspeakers echo cancellation highly immersive full duplex communication;computational complexity;echo suppression;arrays adaptive filters abstracts microphones;time frequency analysis	Massive multichannel sound reproduction is necessary for highly immersive full-duplex communication. Efficient echo cancellation between massive loudspeakers and microphones is indispensable, and wave-domain adaptive filtering reduces the computational complexity drastically. We propose to further reduce this complexity by exploiting the band-limited property that the sound field has in the space-time-frequency representation. Experimental evaluations support the applicability of the proposed method.	acoustic cryptanalysis;adaptive filter;bandlimiting;computational complexity theory;duplex (telecommunications);echo suppression and cancellation;elegant degradation;evanescent field;loudspeaker;microphone;simulation;time‚Äìfrequency representation	Satoru Emura;Yusuke Hiwasaki;Hitoshi Ohmuro	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6637723	loudspeaker;adaptive filter;computer vision;speech recognition;time‚Äìfrequency analysis;computer science;directional sound;computational complexity theory	Robotics	84.83121611328497	-36.88435017773496	122104
86ec2f99a128487a778a27a80ecf211bc6c9e0ef	optimization of an acoustic echo canceller combined with adaptive gain control	echo cancellation;echo cancellers wideband gain control frequency telephony programmable control adaptive control adaptive filters costs acoustic applications;optimisation;low frequency;real time;speech processing;adaptive control;acoustic signal processing;telephony;real time measurements optimization acoustic echo canceller adaptive gain control hands free algorithms wide band telephone systems computing resources adaptive filter wide band application simple room model single dsp;echo suppression;adaptive filter;gain control;acoustic echo canceller;acoustic signal processing optimisation gain control echo suppression telephony speech processing adaptive control	This contribution deals with the application of hands-free algorithms in wide-band telephone systems with limited computing resources. The basis is the combination of an acoustic echo canceller and an adaptive gain control method. The paper describes how the effect of the echo canceller can be optimized without increasing the computational expense. This is achieved by extending the length of the adaptive filter at the cost of a reduced affected frequency range. The study shows to which extent one can concentrate on the low frequency portion of the acoustic echoes in a wide-band application, if a suitable additional gain control method is available. The optimization is accomplished using a simple room model. Real-time measurements were carried out using an implementation of the complete hands-free system on a single DSP.	acoustic cryptanalysis;echo suppression and cancellation	Peter Heitk√§mper	1995		10.1109/ICASSP.1995.479488	adaptive filter;automatic gain control;adaptive control;telecommunications;computer science;speech processing;low frequency;telephony	Robotics	84.15995344789742	-33.23987742803505	123083
95330584bc1364087ba16dbe7916eb42eb919355	acoustic holography ‚Äî a robot application		Acoustic holography is a technique to visualize the sound field propagating from a sound source. It is used to analyse and locate sources of noise, and even allows to predict the propagation of sound in the environment. However, this technique involves simultaneous measurements of up to 256 microphones, arranged in an array. We propose an alternative approach with 4 or less microphones which are re-positioned using an articulated robot arm. Provided the measurement conditions are stable, this alternative approach with consecutive measurements allows to make use of acoustic holography to investigate various sources of noise. The case of fan noise is demonstrated where the focus is put on practical aspects conducting near-field acoustic holography experiments using a robot arm, as well as post-processing measurement data. As a result, 2 complimenting techniques, static and dynamic near-field acoustic holography, are introduced and their merits are discussed.	acoustic cryptanalysis;articulated robot;covox speech thing;experiment;holography;microphone;robotic arm;software propagation;video post-processing	Martin Kefer;Qi Lu	2016	2016 IEEE International Conference on Real-time Computing and Robotics (RCAR)	10.1109/RCAR.2016.7784045	electronic engineering;speech recognition;acoustics;engineering;acoustic source localization	Robotics	86.69163653351978	-35.446491599001575	124966
2149c918e194029983ce6be7b4bf3e0f246f16c2	monolithic folded pendulum accelerometers for seismic monitoring and active isolation systems	coupling;tiltmeter;instruments;high resolution;sismo;instrumentation;seismology;position measurement accelerometers seismometers seismology remote sensing pendulums gravitational wave detectors;isolation;surveillance;low frequency;tiltmeter monolithic folded pendulum accelerometers seismic monitoring active isolation systems force balance accelerometers mirror isolation system interferometric gravitational wave detectors in vacuum mechanical quality factor folded pendulum geometry cross axis residual coupling capacitance position sensor noise equivalent inertial displacement root mean square geophysical instrumentation;instrumentacion;deplacement;seisme;quality factor;frequence;geometry;geometrie;clinometre;accelerometre;couplage;earthquakes;low noise;haute resolution;isolement;vigilancia;frecuencia;tiltmeter accelerometer pendulum;monitoring;onde;gravitational wave detectors;clinometro;seismometers;remote sensing;bruit;position measurement;basse frequence;alta resolucion;accelerometers monitoring low frequency noise mirrors detectors q factor geometry capacitance capacitive sensors mechanical sensors;accelerometer;geometria;root mean square;pendulums;frequency;accelerometers;waves;displacements;pendulum;acelerometro;tiltmeters;noise;gravitational wave detector	A new class of very low noise low-frequency force-balance accelerometers is presented. The device has been designed for advanced mirror isolation systems of interferometric gravitational wave detectors. The accelerometer consists of a small monolithic folded pendulum with 2 s of natural period and an in-vacuum mechanical quality factor of 3000. The folded pendulum geometry, combined with the monolithic design, allows a unique 0.01% cross-axis residual coupling. Equipped with a high-resolution capacitance position sensor, it is capable of a noise-equivalent inertial displacement of 1-nm root mean square integrated over all the frequencies above 0.01 Hz. The main features of this new accelerometer are here reviewed. New possible applications of monolithic folded pendula in geophysical instrumentation are discussed.	apache axis;displacement mapping;folded reed‚Äìsolomon code;image resolution;mean squared error;monolithic kernel;numerical analysis;optic axis of a crystal;sensor	Alessandro Bertolini;Riccardo DeSalvo;Francesco Fidecaro;Akiteru Takamori	2004	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2005.861006	pendulum;tiltmeter;optics;accelerometer;physics;quantum mechanics;remote sensing	Robotics	90.38907382990911	-24.906750720855253	125007
694baa2767ac70d8f202ae2473045952bbb45e02	an iot-based traceability system for greenhouse seedling crops		This paper presents the design of the Internet of Things (IoT)-based greenhouse traceability model for the tracking and recordkeeping of seedlings and other agricultural products in the germination and growth stages. Traced products are generally of high quality and high commercial value, making the voluntary adoption of traceability processes for the market in processed products and trade in fresh products more common today. The transmission of diseases to humans, along with the cases of chemical poisoning, provided the motive for changes in trade relations between the countries and in the manner of assessing consumer safety. The model allows the tracking of variables, such as luminosity, humidity, temperature, and water consumption, thereby revealing overall water use, growth patterns of the plants, and the timeline for harvest of produce. The system enables automated control of the indoor environment of the greenhouse using an irrigation system or temperature control and presents the main outline of internal traceability of agricultural products from seed to final produce. By means of an IoT platform, this greenhouse design finally facilitates a novel analysis of the behavior of a number of species that comprise the local agriculture in one region of Colombia.		Carlos Andr&#x00E9;s Gonz&#x00E1;lez-Amarillo;Juan Carlos Corrales-Mu&#x00F1;oz;Miguel &#x00C1;ngel Mendoza-Moreno;Angela mar&#x00ED;a Gonz&#x00E1;lez Amarillo;Ahmed Faeq Hussein;N. Arunkumar;Gustavo Ramirez-Gonz&#x00E1;lez	2018	IEEE Access	10.1109/ACCESS.2018.2877293	traceability;agricultural engineering;process control;agriculture;timeline;irrigation;greenhouse;water use;crop;computer science;distributed computing	Robotics	86.13305753462366	-50.28329698754548	125535
80afdcbbfcc5e241ef368da5df6eff56696de3d6	on low-complexity simulation of multichannel room impulse responses	image sampling;microphones;low complexity rir method;reverberation;spectral sampling;communication system;wireless channels;multi input multi output system multichannel room impulse response low complexity rir method next generation communication system rigid boundaries free field plenacoustic spectrum wave equation spatial aliasing spectral sampling wall reflection low complexity simulation algorithm virtual free field sources image source model;image source model;wave equations;low complexity;room impulse response multi input multi output systems plenacoustic function plenacoustic spectrum;architectural acoustics;acoustic signal processing;spectrum;spatial aliasing;multi input multi output;free field plenacoustic spectrum;next generation communication system;wave equation;room impulse response;transient response;multichannel room impulse response;loudspeakers;partial differential equations;multi input multi output system;wall reflection;fourier transforms;next generation;humans;sampling methods reflection fourier transforms microphones loudspeakers partial differential equations image sampling signal processing algorithms reverberation humans;virtual free field sources;sampling methods;signal processing algorithms;plenacoustic spectrum;plenacoustic function;wireless channels acoustic signal processing architectural acoustics image sampling mimo communication transient response wave equations;reflection;mimo communication;low complexity simulation algorithm;rigid boundaries;multi input multi output systems	In this letter, we present a method for low-complexity simulation of multichannel room impulse responses (RIRs). Low-complexity RIR methods will become inevitable in next generation communication systems having massive amounts of microphones/loudspeakers. For a room with rigid boundaries, we show that proper sampling of the free-field plenacoustic spectrum results in the solution of the wave equation at any position in the room. We show that the spatial aliasing introduced by spectral sampling represents the wall reflections. These wall reflections are usually modelled, at least in low-complexity simulation algorithms, by the creation of virtual free-field sources outside the room, an image source model commonly referred to as the image method. The image method requires O(N3) operations per receiver position, whereas the newly proposed method requires only O(NlogN) operations per receiver position.	algorithm;aliasing;coefficient;computation;experiment;image impedance;loudspeaker;microphone;next-generation network;open-source software;reflection (computer graphics);sampling (signal processing);series expansion;simulation;voronoi diagram	Jorge Martinez;Richard Heusdens	2010	IEEE Signal Processing Letters	10.1109/LSP.2010.2051049	wave equation;speech recognition;telecommunications;computer science	Vision	86.57065616557993	-38.018140132959424	125745
8629d95d5099ab7793e67345c63b6567bbeea28a	characterization of auditory evoked potentials recorded in radiofrequency fields	auditory evoked potentials;cellular radio;electroencephalography;low-pass filters;medical signal processing;mobile handsets;signal sampling;gsm modulation;acquisition system behavior;auditory evoked potentials recording;frequency 50 hz to 216.7 hz;low-pass filtering;mobile phone;parasitic components;radiofrequency fields;sampling frequency;spurious frequencies	This paper deals with the analysis of auditory evoked potentials recorded in presence of radiofrequency fields emitted by a mobile phone. During measurements, spurious frequencies appear on the one hand at 50, 100, 150 Hz but and on the other hand around 83.3, 133.4 and 216.7 Hz. The first ones are due to the mains and that at 216.7 Hz comes from the GSM modulation. We show that the two others (83.3 and 133.4 Hz) are related to the 216.7 Hz component and to the sampling frequency. In order to get rid of these parasitic components, a low-pass filtering is applied before further analysis. A study of the acquisition system behavior in the band [0; 40 Hz] is carried out to conclude on the validity of this analysis.	low-pass filter;mobile phone;modulation;radio frequency;remote control;sampling (signal processing)	E. Maby;S. Chailloug;P. Marquis;R√©gine Le Bouquin-Jeann√®s	2002	2002 11th European Signal Processing Conference		electronic engineering;acoustics;telecommunications;engineering	ML	84.66400986573362	-39.622033405423124	126857
a90ce522af20ea6c6214dd4d3a42afd093607190	stereophonic acoustic echo suppression based on wiener filter in the short-time fourier transform domain	microphones;echo cancellation;musical noise reduction open loop stereophonic acoustic echo suppression method wiener filter short time fourier transform domain open loop saes method teleconferencing system stft domain echo path impulse response identification adaptive filter echo spectra estimation stereo signal weighting function spectral modification technique noise reduction echo removal microphone signal signal to echo ratio ser;teleconferencing;fourier transform;tracking ability a priori signal to echo ratio convergence rate stereophonic acoustic echo cancellation stereophonic acoustic echo suppression;wiener filters;convergence rate;materials;short time fourier transform;stereophonic acoustic echo suppression;wiener filters adaptive filters echo suppression fourier transforms microphones signal denoising teleconferencing transient response;transient response;adaptive filters;stereophonic acoustic echo cancellation;a priori signal to echo ratio;estimation;signal processing;noise reduction;fourier transforms;tracking ability;echo suppression;impulse response;wiener filter;weight function;microphones signal processing algorithms estimation materials fourier transforms echo cancellers;signal processing algorithms;echo cancellers;computer simulation;adaptive filter;signal denoising	An open-loop stereophonic acoustic echo suppression (SAES) method without preprocessing is presented for teleconferencing systems, where the Wiener filter in the short-time Fourier transform (STFT) domain is employed. Instead of identifying the echo path impulse responses with adaptive filters, the proposed algorithm estimates the echo spectra from the stereo signals using two weighting functions. The spectral modification technique originally proposed for noise reduction is adopted to remove the echo from the microphone signal. Moreover, a priori signal-to-echo ratio (SER) based Wiener filter is used as the gain function to achieve a trade-off between musical noise reduction and computational load for real-time operations. Computer simulation shows the effectiveness and the robustness of the proposed method in several different scenarios.	acoustic coupler;acoustic cryptanalysis;adaptive filter;algorithm;computation;computer simulation;condition number;echo (computing);echo suppression and cancellation;loss function;mathematical optimization;microphone;noise reduction;preprocessor;real-time clock;short-time fourier transform;signal-to-noise ratio;the matrix;wiener filter;zero suppression	Feiran Yang;Ming Wu;Jun Yang	2012	IEEE Signal Processing Letters	10.1109/LSP.2012.2187446	computer simulation;adaptive filter;fourier transform;computer vision;speech recognition;computer science;signal processing;mathematics;wiener filter;statistics;wiener deconvolution	Vision	83.66002095289686	-34.42985004185563	126941
357d229507a0a293e553fbfa29b4750ccab9336c	joint source localization and dereverberation by sound field interpolation using sparse regularization		In this paper, source localization and dereverberation are formulated jointly as an inverse problem. The inverse problem consists in the interpolation of the sound field measured by a set of microphones by matching the recorded sound pressure with that of a particular acoustic model. This model is based on a collection of equivalent sources creating either spherical or plane waves. In order to achieve meaningful results, spatial, spatio-temporal and spatio-spectral sparsity can be promoted in the signals originating from the equivalent sources. The inverse problem consists of a large-scale optimization problem that is solved using a first order matrix-free optimization algorithm. It is shown that once the equivalent source signals capable of effectively interpolating the sound field are obtained, they can be readily used to localize a speech sound source in terms of Direction of Arrival (DOA) and to perform dereverberation in a highly reverberant environment.	acoustic cryptanalysis;acoustic model;algorithm;covox speech thing;direction of arrival;interpolation;mathematical optimization;microphone;optimization problem;sparse matrix	Niccolo Antonello;Enzo De Sena;Marc Moonen;Patrick A. Naylor;Toon van Waterschoot	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8462451	interpolation;mathematical optimization;acoustic model;sound pressure;inverse problem;computer science;regularization (mathematics);plane wave;optimization problem;direction of arrival	Robotics	84.33618562946013	-36.94484789072397	127401
dcf321df4ef040845173930ec10ae86f5af8de7c	microphone-array hearing aids with binaural output. ii. a two-microphone adaptive system	chambre reverberante;microphones;array processing;behavioral measurement;hearing aids;speech intelligibility;500 hz;monaural amplification;filtre reponse impulsion finie;anechoic room;normal hearing;sound localization;binaural listening;adaptive filtering;filtrado adaptable;acoustic variables measurement;localization;speech processing;finite impulse response filter;fuente sonora;mesure acoustique;auditory system;performance comparison;noise hearing aids microphones acoustic transducer arrays array signal processing direction of arrival estimation speech intelligibility speech processing filtering theory acoustic signal processing acoustic variables measurement adaptive signal processing;speech;audition binaurale;acoustic signal processing;procesador panel;microfono;array signal processing;localizacion;frequency measurement;binaural hearing;indexing terms;array processor;reduccion ruido;two microphone adaptive system;frequency spectrum;microphone array hearing aids;processeur tableau;filtro respuesta impulsion acabada;localisation;adaptive signal processing;reverberant room;anechoic chamber;microphone array;binaural hearing aids;lowpass highpass cutoff frequency;noise reduction;adaptive arrays;camara reverberante;adaptive system;reduction bruit;merging;chambre anechoique;source sonore;hearing aids microphone arrays speech array signal processing cutoff frequency auditory system merging frequency conversion acoustic measurements frequency measurement;spatial filtering;binaural output;binaural adaptive system;medida acustica	For pt.I see ibid., vol.5, no.6, p.529-42, 1997. This work is aimed at developing a design for the use of a microphone array with binaural hearing aids. The goal of such a hearing aid is to provide both the spatial-filtering benefits of the array and the natural benefits to sound localization ability and speech intelligibility that result from binaural listening. The present study examines a design in which two ear-level omnidirectional microphones constitute the array. The merging of array processing with binaural listening is accomplished by dividing the frequency spectrum, devoting the lowpass part to binaural processing and the highpass part to adaptive array processing. Acoustic and behavioral measurements were made in an anechoic chamber and in a moderately reverberant room to assess the trade-off between sound localization and speech reception as the cutoff frequency was varied. A lowpass/highpass cutoff frequency of 500 Hz provided an improvement of 40 percentage points in sentence intelligibility over unaided listening for normal-hearing listeners, while still allowing adequate localization performance. Comparison of this binaural adaptive system to traditional amplification configurations with normal-hearing listeners showed improvements in speech reception in noise in a mildly reverberant room of approximately 3 dB over simple binaural amplification and 5 dB over monaural amplification.	adaptive system;binaural beats;microphone	Daniel P. Welker;Julie E. Greenberg;Joseph G. Desloge;Patrick M. Zurek	1997	IEEE Trans. Speech and Audio Processing	10.1109/89.641299	adaptive filter;computer vision;speech recognition;acoustics;computer science;adaptive system;speech processing	Arch	84.82554225012005	-33.9899136145432	127480
1b8487a53ac8ce307ce7e2eef566e006e7efda95	harmonic coherent demodulation for improving sound coding in cochlear implants	hearing acoustic signal processing bioacoustics cochlear implants demodulation;temporal pitch coding;acoustic analysis;filter bank;bioacoustics;pitch synchronized coherent demodulation strategy;coherent demodulation;signal analysis;speech processing;speech analysis;auditory system;harmonic single sideband encoder;speech;acoustic signal processing;demodulation cochlear implants frequency auditory system computational intelligence society power harmonic filters filter bank speech processing signal analysis bandwidth;demodulation;fine structure;f0 synchronized coherent demodulation sound coding cochlear implants hearing temporal fine structure speech music perception pitch synchronized coherent demodulation strategy harmonic single sideband encoder dynamic carrier estimation approach temporal pitch coding acoustic analysis;power harmonic filters;music perception;temporal fine structure;bandwidth;single sideband demodulation;single sideband demodulation coherent demodulation cochlear implants speech analysis modulation;dynamic carrier estimation approach;sound coding;f0 synchronized coherent demodulation;frequency;encoding;cochlear implant;cochlear implants;hearing;fundamental frequency;computational intelligence society;modulation;harmonic analysis	The paper presents a promising application of the coherent demodulation technique to improving hearing with cochlear implants. It has been a challenge to encode temporal fine structure (TFS) in cochlear implants for better speech and music perception. We propose a pitch-synchronized coherent demodulation strategy‚ÄîHarmonic Single Sideband Encoder (HSSE)‚Äîto efficiently encode TFS cues. A dynamic carrier estimation approach based on harmonic detection was chosen to enhance temporal pitch coding in cochlear implants. Acoustic analysis results showed that the HSSE strategy preserves temporal fine structure cues including fundamental frequency (F0) information as well. The coding of temporal fine structure cues in cochlear implants could be potentially improved with the F0-synchronized coherent demodulation.	acoustic cryptanalysis;carrier recovery;cochlear implant;coherence (physics);encode;encoder;single-sideband modulation;team foundation server	Xing Li;Kaibao Nie;Les E. Atlas;Jay T. Rubinstein	2010	2010 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2010.5494908	speech recognition;computer science;speech;fine structure;frequency;carrier recovery;signal processing;harmonic analysis;filter bank;speech processing;fundamental frequency;demodulation;bandwidth;bioacoustics;encoding;modulation	Robotics	83.59227124642277	-31.23012884817603	128278
1cd957b8e4a226dbc705f5d493c17425e171e70c	a phase-aware single channel speech enhancement technique using separate bayesian estimators for voiced and unvoiced regions with digital hearing aid application	bayesian estimators;mmse estimator;speech enhancement;digital hearing aid	The modern digital hearing aids suffer from the problem of degradation of perceived signal quality and intelligibility of audio signal when signal to noise ratio (SNR) of the input signal becomes very low. In this work, a speech enhancement algorithm is proposed where the magnitude spectrum of clean speech is estimated by using two separate Bayesian estimators derived from two different cost functions. For the voiced regions, the perceptually motivated adaptive Œ≤-order weighted minimum mean square error (MMSE) estimator is used and the phase structure of the voiced region is also reconstructed using a harmonic model of speech. On the other hand, for the unvoiced segments, Bayesian estimator with modified Itakura-Saito (MIS) cost function is utilized for estimating the magnitude spectrum of clean unvoiced signal. The proposed algorithm is simulated under different non-stationary noisy environments at various signal to noise ratio values. The experimental results show that the proposed speech enhancement framework performs better than other standard benchmark methods in terms of several quality and intelligibility assessment metrics of perceived audio signal.	algorithm;benchmark (computing);elegant degradation;intelligibility (philosophy);itakura‚Äìsaito distance;loss function;mean squared error;noise reduction;signal-to-noise ratio;speech enhancement;stationary process	Suman Samui;Indrajit Chakrabarti;Soumya K. Ghosh	2015	2015 17th International Conference on E-health Networking, Application & Services (HealthCom)	10.1109/HealthCom.2015.7454521	speech recognition;acoustics;engineering;communication	ML	83.18407117006355	-34.27917533608282	128461
3556d8a671aef0c4a8a3fcca08e497f6f05ebe49	i-divergence-based dereverberation method with auxiliary function approach	audio signal processing;auxiliary function method;auxiliary function method dereverberation musical audio signal i divergence;dereverberation;i divergence;indexing terms;musical instruments;musical audio signal;convergence guaranteed parameter estimation algorithm i divergence based dereverberation method auxiliary function approach musical audio signal itakura saito divergence based formulation direct sound suppression problem music spectrum model;parameter estimation;parameter estimation audio signal processing musical instruments;harmonic analysis	This paper presents a dereverberation method based on I-divergence minimization, which is particularly suitable for music signals. Existing dereverberation methods, including one designed for music, sometimes distort instrument sounds and make staccato-like tones. The problems with the Itakura-Saito-divergence-based formulation of the existing methods are 1) their tendency to excessive suppression of direct sound and 2) the difficulty of incorporating and optimizing sophisticated source models suitable for music signals. The proposed I-divergence-based method can mitigate these problems. Employing the I-divergence measure enables us to avoid the direct sound suppression problem and to use powerful music spectrum models without complicating its optimization. We develop a convergence-guaranteed parameter estimation algorithm based on the auxiliary function approach. Experimental results reveal the effectiveness of the proposed dereverberation method.	algorithm;distortion;estimation theory;itakura‚Äìsaito distance;mathematical optimization;zero suppression	Naoki Yasuraoka;Hirokazu Kameoka;Takuya Yoshioka;Hiroshi G. Okuno	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5946417	speech recognition;index term;audio signal processing;computer science;harmonic analysis;mathematics;estimation theory;statistics	Vision	83.9517864332639	-34.086187241857324	128607
6427ef6f1ad6f2f0a91968cbeb6ede4b6aa42ad3	narrowband passive sonar tracking		Passive sonar sensors are the main source of information for a submerged submarine. Modern sonar systems like ISUS 90 offer a number of acoustic antennas and combined signal processing for broadband and narrowband detection and analysis of target noise. While broadband detection is often used to obtain an overview of the targets surrounding the own ship, narrowband processing enables the detection of target characteristic frequency lines, often produced by vibrations of the propulsion systems on surface ships which are radiated into the water. Narrowband processing is therefore essential for target analysis and classification. Frequency line information can be used to separate targets closely spaced in bearing, e.g. during target crossing situations, which can not be resolved by the broadband passive sonar information alone. In addition, target bearing histories containing frequency line information may be used in the Target Motion Analysis module to infer about target course, speed and range without an own-boat manoeuvre. Therefore, narrowband passive sonar tracking provides an additional valuable source of information and enhances the capabilities of a submarine sonar and combat system. In this paper we present multi-target tracking results for narrowband passive sonar based on a multi-hypothesis tracking approach. The tracking system is designed to automatically track all detectable frequency lines of multiple targets, while at the same time minimizing the number of false tracks.	acoustic cryptanalysis;algorithm;information source;normal mode;sonar (symantec);sensor;signal processing;statistical classification;target motion analysis;tracking system	Kevin Brinkmann;J√∂rg Hurka	2010			acoustics;narrowband;sonar;computer science	Robotics	84.53485977216792	-41.82557816375825	128698
23203a142fccf280e3fd122990877b2f5fed0736	3d binaural sound reproduction using a virtual ambisonic approach	high quality interpolation;human localization capability;virtual ambisonic approach;time varying;interpolation;audio signal processing;head movement;source number independence;transfer functions;time varying filters sound reproduction transfer functions audio signal processing virtual reality headphones;integral equations;3d binaural sound reproduction;virtual sound source signal;head tracking;filters;virtual reality;sound reproduction;source number independence 3d binaural sound reproduction virtual ambisonic approach headphone virtual sound source signal head related transfer function human localization capability head movement head tracking high quality interpolation time varying interpolation human localization accuracy room simulation computational efficiency time invariant head related transfer function filter;time invariant head related transfer function filter;head related transfer function;human localization accuracy;loudspeakers;partial differential equations;acoustic noise;time varying interpolation;loudspeakers integral equations acoustic noise interpolation filters transfer functions humans holography partial differential equations electronic music;room simulation;headphone;holography;humans;time varying filters;headphones;computational efficiency;electronic music	A Convincing binaural sound reprodudion via headphones requires fofllfer the virfual sound source signals wifh head relafed transfer funcfions (HRTFs). Furfhermore, humnns are able lo improve fheir locdimfion capabilifies by smoll unconscious head movemenfs. Therefore it is imporfant fa incorporate head-tracking. This yields fheproblem of high-quality, rime-varying interpolation between dvferent HRTFs A funher improvemenf of humnns Iocalizafion accuracy can be done by considering room simulafion yielding a huge nmounf of virtual sound sources. To increase the computafional eflciency offhe proposed sysfem a virfual Ambisonic approach is used, fhaf resulfs in a bank offimeinvarinnf HRTFJXfer independenf of fhe number of sources Io encode	binaural beats;covox speech thing;encode;headphones;interpolation	Markus Noisternig;Thomas Musil;Alois Sontacchi;Robert H√∂ldrich	2003		10.1109/VECIMS.2003.1227050	loudspeaker;speech recognition;audio signal processing;interpolation;electronic music;head-related transfer function;noise;virtual reality;transfer function;holography;integral equation;partial differential equation	PL	86.6335112811814	-33.816567633371974	128848
0fc165814392cbbc550110b2ef14870e468f08a3	scream and gunshot detection and localization for audio-surveillance systems	inf;false reject rate;video surveillance;audio signal processing;gunshot detection systems acoustic signal detection event detection acoustic noise microphone arrays video surveillance time difference of arrival acoustic arrays least squares approximation real time systems;surveillance system;image classification;signal arrival scream detection gunshot detection localization scream audiosurveillance systems audio based video surveillance anomalous audio events acoustic source video camera linear correction localization algorithm microphone array signal classifier audio features;tel;automatic detection;microphone array;video surveillance acoustic signal detection audio signal processing image classification;least square;acoustic signal detection;real time implementation;time difference of arrival	This paper describes an audio-based video surveillance system which automatically detects anomalous audio events in a public square, such as screams or gunshots, and localizes the position of the acoustic source, in such a way that a video-camera is steered consequently. The system employs two parallel GMM classifiers for discriminating screams from noise and gunshots from noise, respectively. Each classifier is trained using different features, chosen from a set of both conventional and innovative audio features. The location of the acoustic source which has produced the sound event is estimated by computing the time difference of arrivals of the signal at a microphone array and using linear-correction least square localization algorithm. Experimental results show that our system can detect events with a precision of 93% at a false rejection rate of 5% when the SNR is 10dB, while the source direction can be estimated with a precision of one degree. A real-time implementation of the system is going to be installed in a public square of Milan.	acoustic cryptanalysis;closed-circuit television;microphone;real-time clock;real-time computing;rejection sampling;scream (cipher);selection algorithm;signal-to-noise ratio	Giuseppe Valenzise;Luigi Gerosa;Marco Tagliasacchi;Fabio Antonacci;Augusto Sarti	2007	2007 IEEE Conference on Advanced Video and Signal Based Surveillance	10.1109/AVSS.2007.4425280	computer vision;contextual image classification;speech recognition;audio signal processing;computer science;multilateration;machine learning;least squares	Robotics	83.90106680555779	-41.68759866612416	128922
8583dcf604374de0614b85b9ec3f8006093d205c	influence of different impulse response measurement signals on music-based sound source localization	robot audition;multiple signal classification music;sound source localization;acoustic transfer function;impulse response measurement techniques			Takuya Suzuki;Hiroaki Otsuka;Wataru Akahori;Yoshiaki Bando;Hiroshi G. Okuno	2017	JRM	10.20965/jrm.2017.p0072	speech recognition;acoustics;perceptual-based 3d sound localization;acoustic source localization;communication	Metrics	86.13779767453242	-34.95635689696121	129260
8fc057db556446c25a8704847a7eb0cfd3dadccb	mouth-clicks used by blind expert human echolocators ‚Äì signal description and model based signal synthesis		Echolocation is the ability to use sound-echoes to infer spatial information about the environment. Some blind people have developed extraordinary proficiency in echolocation using mouth-clicks. The first step of human biosonar is the transmission (mouth click) and subsequent reception of the resultant sound through the ear. Existing head-related transfer function (HRTF) data bases provide descriptions of reception of the resultant sound. For the current report, we collected a large database of click emissions with three blind people expertly trained in echolocation, which allowed us to perform unprecedented analyses. Specifically, the current report provides the first ever description of the spatial distribution (i.e. beam pattern) of human expert echolocation transmissions, as well as spectro-temporal descriptions at a level of detail not available before. Our data show that transmission levels are fairly constant within a 60¬∞ cone emanating from the mouth, but levels drop gradually at further angles, more than for speech. In terms of spectro-temporal features, our data show that emissions are consistently very brief (~3ms duration) with peak frequencies 2-4kHz, but with energy also at 10kHz. This differs from previous reports of durations 3-15ms and peak frequencies 2-8kHz, which were based on less detailed measurements. Based on our measurements we propose to model transmissions as sum of monotones modulated by a decaying exponential, with angular attenuation by a modified cardioid. We provide model parameters for each echolocator. These results are a step towards developing computational models of human biosonar. For example, in bats, spatial and spectro-temporal features of emissions have been used to derive and test model based hypotheses about behaviour. The data we present here suggest similar research opportunities within the context of human echolocation. Relatedly, the data are a basis to develop synthetic models of human echolocation that could be virtual (i.e. simulated) or real (i.e. loudspeaker, microphones), and which will help understanding the link between physical principles and human behaviour.	angularjs;base;chiroptera;computation;computational model;database;description;echolocation;emission - male genitalia finding;head-related transfer function;inference;level of detail;loudspeaker;mathematical model;microphone;modulation;radiation pattern;resultant;synthetic data;transmission (bittorrent client);exponential	Lore Thaler;Galen M. Reich;Xinyu Zhang;Dinghe Wang;Graeme E. Smith;Tao Zeng;Raja Syamsul Azmir Raja Abdullah;Mikhail Cherniakov;Chris J. Baker;Daniel Kish;Michail Antoniou	2017		10.1371/journal.pcbi.1005670	spatial distribution;attenuation;bioinformatics;transfer function;biology;spatial analysis;bioacoustics;computational model;speech recognition;human echolocation;level of detail;pattern recognition;artificial intelligence	AI	87.12607067959176	-32.832043040961786	130342
7c523990b153b16da7ec085d70529ddaf721cfee	hf radio-frequency interference mitigation	degradation;interference mitigation;high frequency band;high frequency hf radar;data stream;real time;signal detection;time domain complex signal;frequency estimation;spectrum;phase parameters;ionosphere;hafnium radio frequency radiofrequency interference interference elimination frequency estimation degradation signal processing amplitude estimation phase estimation time domain analysis;radio systems;radiofrequency interference;journal;time domain analysis;interference suppression;hf radiofrequency interference mitigation;radio frequency;rfi;radio frequency interference;phase estimation;signal processing;delay doppler ionograms;snr data;amplitude estimation;artificial interference;radar signal processing high frequency hf radar interference suppression ionogram;time domain;signal reconstruction;oblique incident ionospheric detection;radiocommunication;ionogram;signal to noise ratio;snr data hf radiofrequency interference mitigation high frequency band radio systems interference elimination signal processing interference reconstruction frequency estimation amplitude estimation phase parameters artificial interference time domain complex signal data stream oblique incident ionospheric detection delay doppler ionograms rfi signal to noise ratio;high frequency;interference elimination;radar signal processing;interference reconstruction;time domain analysis amplitude estimation frequency estimation interference suppression radiocommunication radiofrequency interference signal detection signal reconstruction;hafnium	The dense radio-frequency interference (RFI) distributed on the spectrum in the high-frequency band greatly degrades the performance of radio systems and makes it urgent to find an effective and speedy method to eliminate the interferences. The interference mitigation method introduced in this letter is implemented before any further signal processing. It reconstructs the interference by the exactly estimated frequency, amplitude, and phase parameters in the signal spectrum and then subtracts the artificial interference from the input time-domain complex signal. The procedure steps of the method are illustrated in detail. The data stream of continuous oblique-incident ionospheric detection has been processed effectively and rapidly in real time. Several delay-Doppler ionograms severely contaminated by RFI are selected and presented. Comparisons of the original and mitigated ionograms and the signal-to-noise ratio (SNR) data show that the RFIs are eliminated perfectly and that the SNR is greatly improved.	frequency band;interference (communication);oblique projection;radio frequency;signal processing;signal-to-noise ratio;spectral density	Gang Chen;Zhengyu Zhao;Guoqiang Zhu;Yujie Huang;Ting Li	2010	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2009.2039340	signal reconstruction;electromagnetic interference;spectrum;ionogram;degradation;telecommunications;time domain;computer science;signal processing;high frequency;ionosphere;hafnium;radio frequency;physics;remote sensing	Arch	83.84693642475558	-42.55717047343465	130523
74587bdc0de125d024983c5a1066c4d50423968d	enhancement of speech degraded by coherent and incoherent noise using a cross-spectral estimator	spectre puissance;microphones;speech processing;tratamiento palabra;traitement parole;wiener filters;microfono;speech enhancement;indexing terms;power spectrum;correlated noise components speech enhancement coherent noise incoherent noise cross spectral estimator noise reduction hands free communications microphones uncorrelated noise wiener filtering coherence function cross power spectrum estimation;experimental result;espectro potencia;estimator;reduccion ruido;acoustic correlation;filtre wiener;estimador;interference suppression;acoustic correlation speech enhancement microphones interference suppression wiener filters filtering theory spectral analysis acoustic noise;acoustic noise;noise reduction;systeme mains libres;reduction bruit;resultado experimental;coherence;spectral estimation;wiener filter;coherencia;hands free system;spectral analysis;resultat experimental;filtro wiener;speech enhancement degradation working environment noise noise reduction speech processing wiener filter microphones bit rate quantization frequency;filtering theory;microphone;estimateur	This correspondence deals with the problem of noise reduction for hands-free communications when two microphones are in use. We consider two methods usually adopted in the case of uncorrelated noises. The first one is based on the coherence function and the second on Wiener filtering. We propose to modify the previous methods by including a cross power spectrum estimation to take the presence of some correlated noise components into account. Objective results show a significant improvement in comparison with the basic structures.	coherence (physics);microphone;noise reduction;spectral density estimation	R√©gine Le Bouquin-Jeann√®s;Ahmad Akbari Azirani;G√©rard Faucon	1997	IEEE Trans. Speech and Audio Processing	10.1109/89.622576	estimator;speech recognition;index term;coherence;acoustics;computer science;noise;noise reduction;speech processing;mathematics;spectral density estimation;wiener filter;spectral density;statistics	EDA	83.32660987620733	-34.26478439607252	131106
1d6e67bc400c31519e12f2b9ce5fc5399c67f1ce	adaptive temporal matched filtering for noise suppression in fiber optic distributed acoustic sensing	rayleigh scattering;wiener filters;adaptive temporal filtering;fiber optic sensors;matched filters;structural health monitoring;vibration detection	Distributed vibration sensing based on phase-sensitive optical time domain reflectometry ( œï -OTDR) is being widely used in several applications. However, one of the main challenges in coherent detection-based œï -OTDR systems is the fading noise, which impacts the detection performance. In addition, typical signal averaging and differentiating techniques are not suitable for detecting high frequency events. This paper presents a new approach for reducing the effect of fading noise in fiber optic distributed acoustic vibration sensing systems without any impact on the frequency response of the detection system. The method is based on temporal adaptive processing of œï -OTDR signals. The fundamental theory underlying the algorithm, which is based on signal-to-noise ratio (SNR) maximization, is presented, and the efficacy of our algorithm is demonstrated with laboratory experiments and field tests. With the proposed digital processing technique, the results show that more than 10 dB of SNR values can be achieved without any reduction in the system bandwidth and without using additional optical amplifier stages in the hardware. We believe that our proposed adaptive processing approach can be effectively used to develop fiber optic-based distributed acoustic vibration sensing systems.	acoustic cryptanalysis;carrier recovery;decorrelation;dental intrusion;dental whitening;digital data;expectation‚Äìmaximization algorithm;experiment;eye;fiber optic cables;fiber optic technology;finite impulse response;frequency response;greater than;large;matched filter;noise reduction;optical amplifier;optical fiber;optical fiber cable;optical time-domain reflectometer;parallel computing;passive optical network;preprocessor;processing (action);real-time transcription;sensor;signal averaging;signal-to-noise ratio;super high material cd;time-domain reflectometry;tracing (software);vibration - physical agent;zero suppression;spiromustine	Ibrahim √ñl√ßer;Ahmet √ñnc√º	2017		10.3390/s17061288	fading;engineering;electronic engineering;filter (signal processing);optical time-domain reflectometer;signal averaging;distributed acoustic sensing;fiber optic sensor;frequency response;matched filter	EDA	85.88176355605974	-40.23062570646672	131450
7e6e23d8ef0cd965df406d85fd59b775c3940f3e	2.5d localized sound zone generation with a circular array of fixed-directivity loudspeakers		This paper provides an analytical approach to generating localized sound zone close to loudspeakers in the horizontal plane using a circular array of fixed-directivity loudspeakers and an additional loudspeaker based on sound source dimension mismatch. A circular loudspeaker array and an additional loudspeaker located on the array center are simultaneously produced in mutual opposite phase. As a result, the propagated sound pressure at the reference circle for 2.5-dimensional sound field synthesis is completely cancelled, but that near the circular array is not compensated and localized sound zone generation is realized. The driving signals of the circular array of fixed-directivity loudspeakers and the produced sound pressures are analytically derived. The results of computer simulations indicate the effectiveness of the proposal. By taking the acoustic source-receiver reciprocity into account, the proposed filter coefficients of loudspeakers are also directly used for close-talking microphone array with directional microphones in the horizontal plane.	2.5d;acoustic cryptanalysis;coefficient;computer simulation;covox speech thing;loudspeaker;microphone	Takuma Okamoto	2018	2018 16th International Workshop on Acoustic Signal Enhancement (IWAENC)	10.1109/IWAENC.2018.8521366		Arch	86.85552797960025	-35.055703103491986	131493
319ed6a6f74a807a276f04b859d450291b77abf8	a bowed string physical model including finite-width thermal friction and hair dynamics		In light of the promising results obtained by driving a lowcomplexity digital waveguide (DW) violin model with synthetic bowing gestures , we currently explore the possibilities of combining DW and finite-difference time-domain (FDTD) frameworks to construct refined, yet efficient physical models of string quartet instruments. We extend previous approaches by combining a finite-width bow-string interaction model with a dynamic friction model based on simulating heat diffusion along the width of the bow. Bow hair dynamics are incorporated in the bow-string interaction, which includes two transversal string polarizations. The bridge termination is realized using an efficient, passive digital reflectance matrix obtained from fitting admittance measurements. In this paper we present and discuss the current status and future directions of our modeling work.	digimon world;dreamwidth;finite-difference time-domain method;polarization (waves);simulation;synthetic intelligence	Esteban Maestre;Carlos Spa;Julius O. Smith	2014			simulation;engineering;optics;engineering drawing	HCI	86.86219706999671	-24.654152123020868	131581
bb0169240716a53868d6325fb5184abf9604662e	regularization approaches for synthesizing hrtf directivity patterns	microphones;white noise gain wng beamforming head related transfer functions hrtfs regularization virtual artificial head;ieee transactions;cost function;speech;microphones robustness cost function white noise power generation ieee transactions speech;regularization;white noise gain wng;virtual artificial head;head related transfer functions hrtfs;power generation;robustness;beamforming;microphone arrays filters least squares approximations;white noise;human auditory system regularization approaches hrtf directivity patterns artificial heads head related transfer functions virtual artificial head microphone array narrowband least squares cost function spatial directivity pattern white noise gain beamformer design procedures filter coefficients hrtf synthesis filter design transfer functions random deviations frequency bands spectral resolution	As an alternative to traditional artificial heads, it is possible to synthesize individual head-related transfer functions (HRTFs) using a so-called virtual artificial head (VAH), consisting of a microphone array with an appropriate topology and filter coefficients optimized using a narrowband least squares cost function. The resulting spatial directivity pattern of such a VAH is known to be sensitive to small deviations of the assumed microphone characteristics, e.g., gain, phase and/or the positions of the microphones. In many beamformer design procedures, this sensitivity is reduced by imposing a white noise gain (WNG) constraint on the filter coefficients for a single desired look direction. In this paper, this constraint is shown to be inappropriate for regularizing the HRTF synthesis with multiple desired directions and three alternative different regularization approaches are proposed and evaluated. In the first approach, the measured deviations of the microphone characteristics are taken into account in the filter design. In the second approach, the filter coefficients are regularized using the mean WNG for all directions. The third approach additionally takes into account several frequency bins into both the optimization and the regularization. The different proposed regularization approaches are compared using analytic and measured transfer functions, including random deviations. Experimental results show that the approach using multiple frequency bands mimicking the spectral resolution of the human auditory system yields the best robustness among the considered regularization approaches.	beamforming;coefficient;filter design;frequency band;head-related transfer function;least squares;loss function;mathematical optimization;matrix regularization;microphone;radiation pattern;real life;white noise	Eugen Rasumow;Martin Hansen;Steven van de Par;Dirk Puschel;Volker Mellert;Simon Doclo;Matthias Blau	2016	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2015.2504874	electricity generation;regularization;speech recognition;acoustics;computer science;speech;machine learning;linguistics;white noise;beamforming;statistics;robustness	EDA	84.5876559327087	-35.398661715533414	131629
52c2494b9e7fd1e67c6059ce979c4681f348345d	multiple sources' direction finding by using reliable component on phase difference manifold and kernel density estimator	kernel;vectors direction of arrival estimation speech processing;manifolds;sensors;speech processing;speech;vectors manifolds direction of arrival estimation estimation sensors kernel speech;vectors;estimation;direction of arrival estimation;bandwidth determination multiple sources direction finding reliable component phase difference manifold kernel density estimator direction of arrival estimation 3 dimensional array configuration multiple speech signal time frequency representation parameterized closed surface phase difference vector pseudo inverse mapping algorithm kernel density algorithm arbitrary array sensor cell selection	This paper proposes a novel direction-of-arrival estimation method in a general 3-dimensional array configuration for multiple speech signals uttered simultaneously. The method is based on sparseness in the time-frequency representation of speech signal and is applicable to an underdetermined case where the sources outnumber sensors. At first, we introduce a parameterized closed surface to which we refer the phase difference manifold. This is defined in the space of phase difference vectors between sensors in order to provide the one-to-one correspondence between the induced phase difference on this sphere and a propagating direction vector of the source. Instead using the conventional pseudo-inverse mapping algorithm, the selection of phase difference vectors located or closely located on the phase difference manifold as a set of reliable observations. Finally, the author's method utilizing kernel density algorithm is generalized for arbitrary array sensors case. The conducted experiments demonstrate that the method utilizing the reliable cell selection and the kernel density estimator with appropriate bandwidth determination performed effectively.	algorithm;direction finding;direction of arrival;experiment;kernel (operating system);kernel density estimation;neural coding;one-to-one (data model);sensor;time‚Äìfrequency representation	Ken Fujimoto;Ning Ding;Nozomu Hamada	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6288449	mathematical optimization;estimation;kernel;speech recognition;manifold;sensor;speech;pattern recognition;speech processing;mathematics;direction of arrival;variable kernel density estimation;statistics	Robotics	83.95379882704333	-37.01212299416481	131725
6bc48d9e71c4252e8514c580dc27b373dd85806d	comparison of a diffracting and a non-diffracting circular acoustic array	new technology;nondiffracting circular acoustic array;localization accuracy;signal processing methods;phase difference;acoustic diffracting array;singular value decomposition;acoustic diffraction acoustic arrays underwater acoustics acoustic devices phased arrays acoustic signal detection surveillance underwater tracking teleconferencing acoustic signal processing;acoustic signal processing;array signal processing;acoustic source localization;automatic detection;directional point spread functions;point spread function;signal processing;free field localization arrays;acoustic wave diffraction;phase differences;free field array;underwater acoustics;array signal processing acoustic signal processing acoustic wave diffraction;free field array nondiffracting circular acoustic array acoustic source localization free field localization arrays array beam forming signal processing methods acoustic diffracting array singular value decomposition localization accuracy directional point spread functions phase differences;array beam forming	Localization of acoustic sources has been an area of research starting primarily with underwater acoustics. Recently, localization of sources in air has become a topic of interest for automatic detection, surveillance and tracking for military applications. Other application include novel teleconference devices, specifically automatic focusing on the person currently speaking. Current technology relies on free-field localization arrays, and there is a plethora of literature on array beam-forming of these arrays. This paper introduces a new technology of diffracting arrays and novel signal processing methods for characterization of these arrays and localization of acoustic sources. The theory and experimental implementation of an acoustic diffracting array (ADA) is presented, including singular value decomposition and the effect of robustness. The results indicate that ADA results in increased localization accuracy, and more directional point spread functions due to increased magnitude and phase differences compared to a free-field array	acoustic cryptanalysis;nonlinear acoustics;signal processing;singular value decomposition;towed array sonar	Jamie Carneal;Miles Johnson;Philip Gillett	2006	2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings	10.1109/ICASSP.2006.1661160	underwater acoustics;signal processing;point spread function;acoustic source localization;singular value decomposition	Robotics	85.94174606347208	-36.39159808107123	131841
e2e466b701bff014b272bfe2768dd0e8b9d577a4	mobile noncontact monitoring of heart and lung activity	biomedical monitoring;magnetic induction;ecg;heart;capacitive ecg;lungs;biomagnetism;magnetic bioimpedance monitoring;nonlinear signal coupling model;lung;electrocardiography;monitoring;signal processing;stability analysis;biomedical signal processing;nonlinear signal coupling model mobile noncontact monitoring heart lung magnetic bioimpedance monitoring capacitive electrocardiogram ecg personal healthcare stability analysis adaptive noise canceller;signal denoising biomagnetism electrocardiography lung medical signal processing patient monitoring;patient monitoring;adaptive noise canceller;signal processing capacitive ecg magnetic induction heart lungs monitoring;mobile noncontact monitoring;capacitive electrocardiogram;mobile application;medical signal processing;electrocardiogram;signal denoising;heart lungs bioimpedance electrocardiography couplings magnetic recording medical services prototypes stability analysis noise measurement;personal healthcare	This paper describes two methods for noncontact monitoring of heart and lung activity, namely magnetic bioimpedance monitoring and capacitive electrocardiogram (ECG) recording. In principle, both methods bear the potential for mobile application in a personal healthcare scenario. To illustrate their performance, prototypes for both methods have been developed and first results are presented. Finally, the fundamental drawbacks and limitations of these methods are discussed, including a detailed stability analysis of the capacitively coupled ldquoright legrdquo in capacitive ECG measurements with mismatching electrode capacities and the development of an adaptive noise canceller for magnetic bioimpedance monitoring based on a nonlinear signal coupling model.	adhesives;body dysmorphic disorders;cardiopulmonary;electrocardiography;excretory function;interference (communication);medical devices;mobile app;morphologic artifacts;movement;nonlinear system;patients;sensor;software prototyping;structure of parenchyma of lung;textiles;algorithm;electrode	Matthias Steffen;Adrian Aleksandrowicz;Steffen Leonhardt	2007	IEEE Transactions on Biomedical Circuits and Systems	10.1109/TBCAS.2008.915633	electromagnetic induction;biomagnetism;electronic engineering;von neumann stability analysis;engineering;electrical engineering;signal processing;remote patient monitoring;biological engineering;heart;physics;quantum mechanics	ML	93.75497996514322	-24.550389832154455	132018
cbb1adfe1cd437d1275eaafb263198a773b2aa7f	application of optimal settings of the lms adaptive filter for speech signal processing	adaptive filters;adaptive signal processing;least mean squares methods;mathematics computing;noise abatement;program verification;speech processing;time warp simulation;voice communication;dsk tms320c6713;dtw criterion;lms adaptive filter;matlab software;additive noise suppression;dynamic time warping;least mean square algorithm;optimal adjustment parameters;quality assessment;speech signal processing;voice communication;dtw criterion (dynamic time warping);lms adaptive filter (least mean square);noise canceller	"""EA E F B F F A F A E F B F F A F EA F F A CF C C F E E A E E BB F E C EA E C CE C F E F F CE FAE F F AE E B F EB F E F E A F A E B F F A A C C F B F A F F F D F B CE A C E F EA F ! CA F A E B EA F """" F F E C AE# C EDF B AE E F F E B F F A F E# A F $ F % A F CF E B CA D B F E A # C F E E F AE E B F EB E F FA CF A E F B # F F A F EA F B E F FA CF A E F B F F A F EA F C F E E A # E AE C D F E & & E F# A B F F E E ' ()*+,-.( ABC D B F F A / F """" A 0 ! CA F A E / C ! A 0 E C C A"""	adaptive filter;earliest deadline first scheduling;emoticon;least mean squares filter;signal processing;speech processing	Jan Vanus;V√≠tezslav St√Ωskala	2010			adaptive filter;speech recognition;multidelay block frequency domain adaptive filter;kernel adaptive filter;computer science;control system;machine learning;root-raised-cosine filter;speech processing;filter design;recursive least squares filter	DB	84.75504327781388	-32.02536602000033	132074
d5b1e868982f63d234fa52b7d6f0ae1100d0948f	classification of objects' surface by acoustic transfer function	robot sensing systems;sensor phenomena and characterization;transfer functions;acoustic testing;transfer functions robot sensing systems sensor phenomena and characterization underwater acoustics optical sensors acoustic sensors acoustical engineering acoustic testing costs acoustic beams;transfer function;shape classification;acoustical engineering;optical sensors;acoustic sensors;acoustic beams;underwater acoustics	Objects surfaces are classified by calculat ing t h e acoust ic t ransfer function between an echo from a reference plane and t h a t from an object t o be tested. A method t o obtain t h i s t r a n s f e r function is presented. Experiment on simple shape c lass i f ica t ion show t h a t phase charac te r i s t ic i n t h e t ransfer function is useful. Future possibi l i ties of ul t rasonic sensing i n robot ics is a lso d is cussed.	acoustic cryptanalysis;transfer function	Ken Sasaki;Masaharu Takano	1992		10.1109/IROS.1992.594488	electronic engineering;speech recognition;acoustics;surface acoustic wave sensor;acoustical engineering;engineering;transfer function	Vision	87.8908776554568	-36.26204524974386	132223
f34df6c14502777a936de3e2bd5850273fe1e068	performance evaluation of 3d sound field reproduction system using a few loudspeakers and wave field synthesis	microphones;performance evaluation;localization capabilities;sound localization;speech;acoustic signal processing;arrays;accuracy;localization capabilities performance evaluation 3d sound field reproduction system wave field synthesis audio visual system loudspeaker array;reproductive system;loudspeakers;three dimensional displays;loudspeakers microphone arrays audio visual systems control system synthesis system testing acoustical engineering agricultural engineering agriculture virtual reality teleconferencing;audio visual;wave field synthesis;loudspeaker array;3d sound field reproduction system;localization test sound field reproduction wave field synthesis;localization test;white noise;sound field reproduction;loudspeakers acoustic signal processing;audio visual system	A conventional 3D sound field reproduction system using wave field synthesis places a lot of loudspeakers around the listener. However, since such a system is very expensive and loudspeakers come into the listener's field of vision, it is very difficult to construct an audio-visual system with it. We developed and evaluated a 3D sound field reproduction system using eight loudspeakers placed at the vertex of cube and wave field synthesis. We compared the sound localization of a loudspeaker array with that of seventeen loudspeakers placed around the listener and found that their localization capabilities of twelve directions were good.	futures studies;loudspeaker;performance evaluation;surround sound	Munenori Naoe;Toshiyuki Kimura;Yoko Yamakata;Michiaki Katsumoto	2008	2008 Second International Symposium on Universal Communication	10.1109/ISUC.2008.35	speech recognition;acoustics;engineering;directional sound;communication	Visualization	86.36069587970613	-34.42991956809666	132774
4bf34d25c534c6dc712f4250938e653bac4f0d95	360 degree selective laser trabeculoplasty in mexican population	open angle glaucoma;statistical analysis;selective laser trabeculoplasty			Josue Roberto-Lozano;Mariya V. Kalashnikova;Gustavo Velasco-Gallegos;Junzo Watada	2012	JACIII	10.20965/jaciii.2012.p0540	artificial intelligence;optometry;selective laser trabeculoplasty;computer science;pattern recognition;population	Robotics	85.38949442821641	-47.814075474250046	133308
038551424714ad1a8ae39fd16dbea80c0d51d93b	sparse doa estimation of wideband sound sources using circular harmonics		Sparse signal models are in the focus of recent developments in narrowband DOA estimation. Applying these methods to localizing audio sources, however, is challenging due to the wideband nature of the signals. The common approach of processing all frequency bands separately and fusing the results is costly and can introduce errors in the solution. We show how these problems can be overcome by decomposing the wavefield of a circular microphone array and using circular harmonic coefficients instead of time-frequency data for sparse DOA estimation. As a result, we present the superresolution localization method WASCHL (Wideband Audio Sparse Circular Harmonics Localizer) that is inherently frequency-coherent and highly efficient from a computational point of view.	beamforming;coefficient;coherence (physics);computation;direction of arrival;frequency band;microphone;point of view (computer hardware company);sparse matrix;super-resolution imaging	Clemens Hage;Tim Habigt;Martin Kleinsteuber	2014	CoRR		speech recognition;acoustics;sparse approximation	ML	84.80811267330762	-36.7273136052509	133615
1027c8fe1c117b05e9d5eb314b5670f048c5cebd	model-based speech enhancement with improved spectral envelope estimation via dynamics tracking	kalman filtering;noise distorted short time spectral amplitude;vector quantization vq;performance evaluation;speech synthesis;vector quantization vq codebook mapping harmonic noise model hnm kalman filter speech analysis speech synthesis;speech analysis;kalman filters;dynamics tracking;model based approach;temporal trajectory tracking;speech;kalman filter;analysis synthesis framework;acoustic signal processing;model based speech enhancement;musical tones problem;speech enhancement;maximum likelihood estimation;noise measurement;speech speech enhancement noise measurement noise harmonic analysis kalman filters;acoustic parameters;spectral envelope estimation;speech reconstruction;maximum likelihood estimate;harmonic noise model;system identification;maximum likelihood estimator;system design;musical tones problem model based speech enhancement spectral envelope estimation dynamics tracking model based approach noisy speech enhancement analysis synthesis framework speech reconstruction model parameter estimation temporal trajectory tracking noise distorted short time spectral amplitude harmonic noise model acoustic parameters hnm analysis kalman filtering system identification codebook mapping scheme maximum likelihood estimator performance evaluation;noisy speech enhancement;experimental validation;target tracking acoustic signal processing kalman filters maximum likelihood estimation performance evaluation signal reconstruction spectral analysis speech enhancement speech synthesis;signal reconstruction;vector quantizer;codebook mapping scheme;parameter estimation;target tracking;spectral analysis;model parameter estimation;hnm analysis;noise;harmonic noise model hnm;codebook mapping;line spectrum frequencies;harmonic analysis	In this work, we present a model-based approach to enhance noisy speech using an analysis-synthesis framework. Target speech is reconstructed with model parameters estimated from noisy observations. In particular, spectral envelope is estimated by tracking its temporal trajectories in order to improve the noise-distorted short-time spectral amplitude. Initially, we propose an analysis-synthesis framework for speech enhancement based on harmonic noise model (HNM). Acoustic parameters such as pitch, spectral envelope, and spectral gain are extracted from HNM analysis. Spectral envelope estimation is improved by tracking its line spectrum frequency trajectories through Kalman filtering. System identification of Kalman filter is achieved via a combined design of codebook mapping scheme and maximum-likelihood estimator with parallel training data. Complete system design and experimental validations are given in details. Through performance evaluation based on a study of spectrogram, objective measures and a subjective listening test, it is demonstrated that the proposed approach achieves significant improvement over conventional methods in various conditions. A distinct advantage of the proposed method is that it successfully tackles the ‚Äúmusical tones‚Äù problem.	acoustic cryptanalysis;algorithm;codebook;estimation theory;kalman filter;performance evaluation;pitch (music);spectral density;spectral efficiency;spectrogram;speech enhancement;stellar classification;system identification;systems design	Ruofei Chen;Cheung-Fat Chan;Hing-Cheung So	2012	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2011.2177821	kalman filter;speech recognition;acoustics;computer science;harmonic analysis;pattern recognition;mathematics;maximum likelihood;speech synthesis;statistics	Vision	83.1500981868171	-34.996629935999565	133963
13a273086fbb95d35e47e9d9cf084b3dee44d463	on the poor robustness of sound equalization in reverberant environments	microphones;reverberation;acoustic signal processing reverberation architectural acoustics equalisers microphones;robustness microphones acoustical engineering filters reverberation frequency response degradation speech information technology acoustic waves;architectural acoustics;acoustic signal processing;equalisers;source positions robustness sound equalization reverberant environments microphone position reverberant room equalized room response ill posed problem;ill posed problem	This paper examines the sensitivity of sound equalization to source or microphone position changes in a reverberant room. It is demonstrated that even small displacements from the reference (equalization) point, of the order of a tenth of the acoustic wavelength, can cause large degradations in the equalized room response. The general theory developed in this paper, which implies that the sound equalization in practical environments may be an ill-posed problem, is verified by the simulation results averaged over different source and microphone positions.	acoustic cryptanalysis;microphone;simulation;well-posed problem	Biljana D. Radlovic;Robert C. Williamson;Rodney A. Kennedy	1999		10.1109/ICASSP.1999.759812	speech recognition;reverberation	Graphics	85.18383226872001	-33.78958842601211	134591
bd12c60a097ed32104aebd49e7bea8ace96310cd	audio servo for robotic systems with pinnae	diffraction reflection model audio servo robotic system artificial pinnae horizontal sound localization vertical sound localization auditory information binaural information interaural time difference interaural intensity difference auditory robot;interaural intensity difference;sound localization;spectral analysis robots acoustic signal processing;interaural time difference;acoustic signal processing;reflection model;robots;pinna notch;audio servo sound localization spectral cues pinna notch;audio servo;spectral analysis;frequency domain;servomechanisms robots ear microphones auditory system frequency domain analysis shape animals humans mechanical engineering;spectral cues	Sound localization is one of important abilities for robots which utilize auditory information. Binaural information such as interaural time difference (ITD) or interaural intensity difference(IID) is effective for horizontal sound localization. In order to extend this ability to vertical sound localization, spectral cues were utilized in this paper instead of increasing number of microphones. Spectral cues were the information about the vertical position of the sound source on frequency domain. Since spectral cues strongly depended on the shape of pinnae, artificial pinnae for auditory robots were designed based on diffraction-reflection model. A method to detect spectral cues was also developed. By utilizing them, a controller which made the robot orient to the sound source was proposed. Results of an experiment showed the validity of the proposed method.	binaural beats;covox speech thing;microphone;robot;servo;stellar classification	Makoto Kumon;Tomoko Shimoda;Ryuichi Kohzawa;Ikuro Mizumoto;Zenta Iwai	2005	2005 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2005.1545092	robot;speech recognition;interaural time difference;acoustics;sound localization;computer science;engineering;perceptual-based 3d sound localization;frequency domain	Robotics	86.40056515780918	-34.692938756272184	134714
d3ae7f13e762b2fbaa2cb00bfa19e7a3e7bf9016	preestimation-based array interpolation approach to coherent source localization using multiple sparse subarrays	forward backward;interpolation;pesavento formulation;coherent source decorrelation;source localization;coherent source decorrelation preestimation based array interpolation approach coherent source localization multiple sparse subarray pesavento formulation lau formulation skip noise prewhitening virtual uniform linear array forward backward spatial smoothing noise floor reduction;skip noise prewhitening;interpolation array signal processing;coherent source localization;array signal processing;preestimation based array interpolation;sparse uniform linear subarrays ulsas coherent source localization forward backward spatial smoothing fbss preestimation based array interpolation;uniform linear array;sparse uniform linear subarrays ulsas;interpolation direction of arrival estimation smoothing methods noise reduction vectors signal resolution position measurement decorrelation multiple signal classification geometry;arrays;multiple signal classification;estimation;forward backward spatial smoothing;forward backward spatial smoothing fbss;lau formulation;field of view;virtual uniform linear array;multiple sparse subarray;preestimation based array interpolation approach;noise floor reduction;direction of arrival estimation;noise;covariance matrix	In application to coherent source localization using multiple sparse uniform linear subarrays (ULSAs), the array interpolation technique with Lau or Pesavento formulation causes unacceptable interpolation errors over the entire field of view because of high sparseness of ULSAs. In this letter, we propose a modified array interpolation approach by specifying a union of nonoverlapping narrow subsectors as the in-sector to cover only the source locations preestimated roughly on an assumption that at least a single ULSA is available for coherent source localization. Furthermore, we skip noise prewhitening and employ more subarrays of the virtual uniform linear array (VULA) for forward-backward spatial smoothing (FBSS) that plays a key role in noise floor reduction as well as coherent source decorrelation.	coherent;decorrelation;interpolation;neural coding;noise floor;smoothing;sparse matrix	Bo Li;Bin Xu;Yeshu Yuan	2009	IEEE Signal Processing Letters	10.1109/LSP.2008.2008950	covariance matrix;mathematical optimization;estimation;field of view;interpolation;noise;multiple signal classification;mathematics;statistics	Vision	86.8177752605256	-38.74907254686539	134897
b5125cda55f112bb9482d2c0aa2c482cb3423bbc	the potential for aircraft noise reduction through active suppression from a ground-based system	noise suppression;numerical calculation;frequency spectrum;active acoustic control;noise reduction;aircraft noise reduction	The feasibility of devising ground-based active noise suppression systems for aircraft which are on the ground and in the air is considered. Detailed numerical calculations are given for various geometries involving an aircraft, sound cancelling sources, reference microphones as well as correction microphones. The calculations are for broadband noise based on a frequency spectrum typical of a jet aircraft. For an aircraft on the ground (during engine run-up and during takeoff from a runway), calculations indicate that noise suppression is both feasible and practical. For an aircraft in the air, while noise suppression is feasible, it is not necessarily practical due to the fact that the most advantageous locations for the suppressing control sources are midway between the ground and the flight path. However, this may not preclude a limited application for very confined areas and for aircraft at relatively low altitudes.	noise reduction;zero suppression	W. A. Kinney;Geoffrey B. Smith	2008	Mathematics and Computers in Simulation	10.1016/j.matcom.2007.12.005	frequency spectrum;noise;ambient noise level;acoustics;noise;noise reduction;noise floor	EDA	86.17309414892678	-38.732271280660036	135529
199adb1fb2dcb2fefbaa281f018e53368677b87a	hrtf magnitude modeling using a non-regularized least-squares fit of spherical harmonics coefficients on incomplete data	regularization head related transfer functions spherical harmonics interpolation extrapolation;normalized mean square error hrtf magnitude modeling spherical harmonics coefficients incomplete data head related transfer functions acoustic transfer function sound source human ear drums discrete source positions spherical harmonics decompositions flexible hrtf representation measurement data retrieval regularized least squares fit lower order straightforward nonregularized least squares fit;transfer functions acoustic generators acoustic signal processing data structures estimation theory harmonics information retrieval least squares approximations mean square error methods;harmonic analysis ear data models transfer functions acoustics estimation extrapolation	Head-related transfer functions (HRTFs) represent the acoustic transfer function from a sound source at a given location to the ear drums of a human. They are typically measured from discrete source positions at a constant distance. Spherical harmonics decompositions have been shown to provide a flexible representation of HRTFs. Practical constraints often prevent the retrieval of measurement data from certain directions, a circumstance that complicates the decomposition of the measured data into spherical harmonics. A least-squares fit of coefficients is a potential approach to determining the coefficients of incomplete data. However, a straightforward non-regularized fit tends to give unrealistic estimates for the region were no measurement data is available. Recently, a regularized least-squares fit was proposed, which yields well-behaved results for the unknown region at the expense of reducing the accuracy of the data representation in the known region. In this paper, we propose using a lower-order non-regularized least-squares fit to achieve a well-behaved estimation of the unknown data. This data then allows for a high-order non-regularized least-squares fit over the entire sphere. We compare the properties of all three approaches applied to modeling the magnitudes of the HRTFs measured from a manikin. The proposed approach reduces the normalized mean-square error by approximately 7 dB in the known region and 11 dB in the unknown region compared to the regularized fit.	acoustic cryptanalysis;coefficient;covox speech thing;data (computing);head-related transfer function;least squares;mean squared error	Jens Ahrens;Mark R. P. Thomas;Ivan Tashev	2012	Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference		mathematical optimization;speech recognition;mathematics;statistics	Graphics	86.94491337102878	-33.63511789872243	135587
5f171e934c9c31f2d9869357674b7dec915b49d9	non-invasive uwb sensing of astronauts' breathing activity	electromagnetic phenomena;wavelet analysis;software;metals;astronauts;sensors;thorax;electromagnetic compatibility;ultra wide bandwidth;signal processing computer assisted;time factors;radiated susceptibility;extraterrestrial environment;signal processing;respiration;space missions;radiated emission;fourier analysis;electricity;breath detection;humans;spectral analysis;monitoring physiologic;computer simulation	The use of a UWB system for sensing breathing activity of astronauts must account for many critical issues specific to the space environment. The aim of this paper is twofold. The first concerns the definition of design constraints about the pulse amplitude and waveform to transmit, as well as the immunity requirements of the receiver. The second issue concerns the assessment of the procedures and the characteristics of the algorithms to use for signal processing to retrieve the breathing frequency and respiration waveform. The algorithm has to work correctly in the presence of surrounding electromagnetic noise due to other sources in the environment. The highly reflecting walls increase the difficulty of the problem and the hostile scenario has to be accurately characterized. Examples of signal processing techniques able to recover breathing frequency in significant and realistic situations are shown and discussed.	algorithm;chest;clutter;contactless smart card;emi;electromagnetic environment;emergent metacognition index;interference (communication);movement;numerical analysis;oxygen;regulation;requirement;respiratory rate;rest;signal processing;simulation;specification;spectral density estimation;systems design;terrestrial television;ultra-wideband;walls of a building;waveform;standards characteristics	Marco Baldi;Graziano Cerri;Franco Chiaraluce;Lorenzo Eusebi;Paola Russo	2014		10.3390/s150100565	computer simulation;embedded system;electronic engineering;simulation;telecommunications;respiration;engineering;electrical engineering;signal processing;electricity;fourier analysis;physics;thorax;electromagnetic compatibility	HCI	84.68611486282042	-41.0650124720928	136339
877616eda19a99d118f19a27f67f8ca326b9c0a1	detection and time-of-arrival estimation of underwater acoustic signals	detectors;probability;clustering expectation maximization viterbi algorithm detection in low snr time of arrival estimation acoustic detection;underwater acoustic communication expectation maximisation algorithm signal detection time of arrival estimation;transient analysis;hidden markov models;hidden markov models time of arrival estimation transient analysis clustering algorithms detectors probability underwater acoustics;time of arrival estimation;signal to noise ratio time of arrival estimation underwater acoustic signal detection toa estimation detection threshold clustering approach expectation maximization viterbi algorithm noise statistics;clustering algorithms;underwater acoustics	We focus on detection and time-of-arrival (ToA) estimation of underwater acoustic signals of unknown structure. The common practice to use a detection threshold may fail when the assumed channel model is mismatched or when noise transients exist. We propose to detect and evaluate the ToA by labeling samples of observed data as `signal' or `noise'. Then, signal is detected when enough samples are labeled as `signal', and ToA is estimated according to the position of the first `signal'-related sample. We take a clustering approach, thereby obviating the need for a detection threshold and training. Our method combines a constrained expectation-maximization (EM) with the Viterbi algorithm, and becomes handy when channel conditions are rough, noise statistics is hard to estimate, and signal-to-noise ratio is low. Numerical and experimental results show that, at the cost of some additional complexity, our proposed algorithm outperforms common benchmark methods in terms of detection and false alarm rates, and in terms of accuracy of ToA estimation.	acoustic cryptanalysis;benchmark (computing);channel (communications);cluster analysis;expectation‚Äìmaximization algorithm;handy board;hidden markov model;mixture model;numerical analysis;numerical linear algebra;signal-to-noise ratio;state transition table;stochastic matrix;viterbi algorithm	Roee Diamant;Ryan Kastner;Michele Zorzi	2016	2016 IEEE 17th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)	10.1109/SPAWC.2016.7536820	speech recognition;computer science;pattern recognition;statistics	Robotics	83.20743227420465	-36.683073814870596	136767
b646e42cf9ca49f33033f04ff1f1bd500430f1ee	polarization sensitive parafac beamforming for near-field/far-field signals using co-centered orthogonal loop and dipole pairs	least mean squares methods;noncircular soi polarization sensitive parafac beamforming cocentered orthogonal loop dipole pairs parallel factor analysis polarization sensitive array cocentered orthogonal loop and dipole vector antennas cold vector antennas far field source signals near field source signals joint interference suppression signal of interest soi steering vector array covariance matrix eigenvalue smoothing regularization minimum mean squared error criterion regularization factor;array signal processing;interference suppression;vectors arrays interference dipole antennas array signal processing eigenvalues and eigenfunctions;covariance matrices;least mean squares methods array signal processing covariance matrices dipole antenna arrays interference suppression;dipole antenna arrays;near field array signal processing cold vector antenna polarization sensitive array noncircular	A parallel factor analysis (PARAFAC) based beamformer using a polarization sensitive array of co-centered orthogonal loop and dipole (COLD) vector antennas is proposed for near-field or far-field source signals. While joint suppression of the interferences in the direction, polarization, and range domains is achieved, the beamformer needs only one of the following source knowledge (maybe inaccurate) about signal of interest (SOI): direction, polarization, and range. The beamformer is robust to the error in the sample estimates of SOI steering vector and array covariance matrix via eigenvalue smoothing regularization. A minimum mean squared error criterion for choosing adaptively the regularization factor in eigenvalue smoothing is also presented for noncircular SOI. Simulation results are included to illustrate the performance of the proposed beamformer.	beamforming;factor analysis;matrix regularization;mean squared error;polarization (waves);simulation;smoothing;zero suppression	Yougen Xu;Jingyan Ma;Zhiwen Liu	2013	2013 IEEE China Summit and International Conference on Signal and Information Processing	10.1109/ChinaSIP.2013.6625415	electronic engineering;analytical chemistry;adaptive beamformer;optics;physics	Robotics	88.45772577626695	-40.437989615590766	136945
cb451caf46c87a72bfd3629b23aacda487bee63b	dual-channel cosine function based itd estimation for robust speech separation	binary time-frequency mask;cosine function;delay-and-sum beamforming	In speech separation tasks, many separation methods have the limitation that the microphones are closely spaced, which means that these methods are unprevailing for phase wrap-around. In this paper, we present a novel speech separation scheme by using two microphones that does not have this restriction. The technique utilizes the estimation of interaural time difference (ITD) statistics and binary time-frequency mask for the separation of mixed speech sources. The novelties of the paper consist in: (1) the extended application of delay-and-sum beamforming (DSB) and cosine function for ITD calculation; and (2) the clarification of the connection between ideal binary mask and DSB amplitude ratio. Our objective quality evaluation experiments demonstrate the effectiveness of the proposed method.	beamforming;clarify;conflict (psychology);dual;estimated;evaluation;experiment;lithium;manuscripts;microphone;multi-channel memory architecture;noise reduction;regulatory submission;revision procedure;gemcitabine	Xuliang Li;Zhaogui Ding;Weifeng Li;Qingmin Liao	2017		10.3390/s17061447	engineering;electronic engineering;amplitude;binary number;beamforming;interaural time difference;communication channel;trigonometric functions	ML	83.81187131340545	-35.33028973747557	137055
c7af70e6608c6cae6527d7715cd84030c7241d6d	a novel variable resolution global spectral method on the sphere	non divergent barotropic vorticity equation;spherical harmonics;variable resolution method;centre for atmospheric oceanic sciences;boyd vandeven filter;global spectral method;helmholtz equations	Highlights? HTBT is a re-parametrization map on the sphere, preserves differential operators. ? Variable resolution global spectral method is generated through re-parametrization. ? Resolution is finer over the tropics and decreases smoothly away from it. ? Spectral coefficients are computed through FFT and Gaussian quadrature methods. ? Boyd-Vandeven filter helps to retain the higher order accuracy of the method. A variable resolution global spectral method is created on the sphere using High resolution Tropical Belt Transformation (HTBT). HTBT belongs to a class of map called reparametrisation maps. HTBT parametrisation of the sphere generates a clustering of points in the entire tropical belt; the density of the grid point distribution decreases smoothly in the domain outside the tropics. This variable resolution method creates finer resolution in the tropics and coarser resolution at the poles. The use of FFT procedure and Gaussian quadrature for the spectral computations retains the numerical efficiency available with the standard global spectral method. Accuracy of the method for meteorological computations are demonstrated by solving Helmholtz equation and non-divergent barotropic vorticity equation on the sphere.	spectral method	S. Janakiraman;Ravi S. Nanjundiah;A. S. Vasudeva Murthy	2012	J. Comput. Physics	10.1016/j.jcp.2011.12.023	classical mechanics;calculus;mathematics;geometry;helmholtz equation;physics;quantum mechanics;spherical harmonics	Theory	88.23894757776377	-49.2475515588065	137252
4f7abe8ef9c4a0fe42f2c09ae2df00aff149ebb6	a study of the ambiguity problem in footstep bearing estimation using tri-axial geophone	azimuth;covariance matrix analysis ambiguity problem footstep bearing estimation tri axial geophone human footstep signal angle estimation walking pattern evaluation;legged locomotion;sensors;indexes;surface wave;covariance matrices;seismometers;signal processing;indexation;gait analysis;signal processing covariance matrices gait analysis seismometers;azimuth sensors covariance matrix legged locomotion indexes direction of arrival estimation surface waves;surface waves;direction of arrival estimation;covariance matrix	This paper investigates the ambiguities that exist in the bearing estimate of human footstep signals acquired using a single tri-axial geophone. Estimated angles for a series of footsteps from three different walking patterns are evaluated. It is observed that there are two kinds of ambiguities, viz., energy and wave polarization. A systematic study of these ambiguities are presented using covariance matrix analysis (CMA) as the base algorithm. Existing techniques to resolve these ambiguities are analysed with their limitations.	algorithm;cma-es;matrix analysis;polarization (waves);triangular function;viz: the computer game	Divya Venkatraman;Vinod V. Reddy;Andy W. H. Khong	2011	2011 8th International Conference on Information, Communications & Signal Processing	10.1109/ICICS.2011.6173512	speech recognition;surface wave;computer science;signal processing;statistics	Robotics	85.7910858328817	-40.9870096621152	137307
b61645e4fcec36003bdeff3732f904939762a728	generative adversarial networks for recovering missing spectral information		Ultra-wideband (UWB) radar systems nowadays typically operate in the low-frequency spectrum to achieve pene¬≠tration capability. However, this spectrum is also shared by many other communication systems, leading to tremendous interference in a large number of frequency bands. Although avoiding these frequency bands is a natural solution, the resulting frequency gaps not only lower the signal-to-noise ratio in the received radar signals but the fragmented radar spectrum also creates severe sidelobes, which can destroy the original features of the targets of interest. In this paper, we propose to recover this missing spectral information via a generative adversarial network, called SARGAN, which learns the relationship between original and missing-frequency-band signals by observing numerous possible training pairs in a clever way. Initial results shows that this approach is promising in tackling this challenging problem: our recovered signals achieve on average more than 18 dB gain in the signal-to-noise ratio when up to 90% of the operating spectrum is missing. Moreover, the proposed SARGAN accomplishes this performance level without any prior knowledge of the locations of the missing frequency bands.		Dung N. Tran;Trac D. Tran;Lam H. Nguyen	2018	2018 IEEE Radar Conference (RadarConf18)		generative grammar;machine learning;frequency domain;communications system;radar imaging;artificial intelligence;mathematics;radar;synthetic aperture radar;interference (wave propagation);radio spectrum;pattern recognition	Mobile	84.00105952577121	-42.83196561810932	137764
a0bb7babea6c9da13ac52f08f737963182aa85d3	three-dimensional electromagnetic articulograph based on a nonparametric representation of the magnetic field	magnetic field;three dimensional			Tokihiko Kaburagi;Kohei Wakamiya;Masaaki Honda	2002				HCI	88.43610245926374	-27.930659770276293	138445
0eb20d183eec51e4ae77de026ea3b67d3a5bf9f7	svd-ica: a new tool to enhance the separation between signal and noise subspaces	vectors independent component analysis sensor fusion singular value decomposition source separation;normalized wavelet matrix multi sensor signal processing singular value decomposition signal separation noise subspace svd ica data orthogonal matrix propagation vector independent component analysis;mars abstracts	In multisensor signal processing (geophysics, underwater acoustic, etc.), the Singular Value Decomposition (SVD) is a useful tool to perform a separation of the initial dataset into two complementary subspaces. The SVD of the data matrix {x,i} provides two orthogonal matrices that convey information on propagation vectors and normalized wavelets. The constraint imposed by the orthogonality's condition for the propagation vectors introduce errors in the signal subspace. To relax this condition, another matrix of normalized wavelet is calculated exploiting the concept of Independent Component Analysis (ICA). Efficiency of this new separation tool using the combined SVD-ICA procedure is shown on realistic dataset.	acoustic fingerprint;independent computing architecture;independent component analysis;signal processing;signal subspace;singular value decomposition;software propagation;unit propagation;wavelet	Valeriu Vrabie;J√©r√¥me I. Mars	2002	2002 11th European Signal Processing Conference		speech recognition;machine learning;pattern recognition;mathematics	ML	83.55345625996321	-37.47593060259081	139057
a69db56d20a1b94a47e968f7b6f56a48cfcf2417	optimal fluorescence waveband determination for detecting defective cherry tomatoes using a fluorescence excitation-emission matrix	algoritmos;fluorescence image;interpretacao de imagem assistida por computador;spectrometry fluorescence;republica da coreia;image interpretation computer assisted;microscopia de fluorescencia;quality sorting;republic of korea;analise de alimentos;microscopy fluorescence;espectrometria de fluorescencia;algorithms;fruit;food analysis;cherry tomato;frutas;lycopersicon esculentum;hyperspectral image;defect detection	A multi-spectral fluorescence imaging technique was used to detect defective cherry tomatoes. The fluorescence excitation and emission matrix was used to measure for defects, sound surface and stem areas to determine the optimal fluorescence excitation and emission wavelengths for discrimination. Two-way ANOVA revealed the optimal excitation wavelength for detecting defect areas was 410 nm. Principal component analysis (PCA) was applied to the fluorescence emission spectra of all regions at 410 nm excitation to determine the emission wavelengths for defect detection. The major emission wavelengths were 688 nm and 506 nm for the detection. Fluorescence images combined with the determined emission wavebands demonstrated the feasibility of detecting defective cherry tomatoes with >98% accuracy. Multi-spectral fluorescence imaging has potential utility in non-destructive quality sorting of cherry tomatoes.	cuticle;ethanol 0.62 ml/ml topical gel;excitation;fluorescence imaging;frequency band;hyperactive behavior;image processing;magnetic resonance imaging;menthol 5.8 mg oral lozenge;microsoft windows 98;multispectral image;numerous;principal component analysis;rotten tomatoes;sensor;software bug;sorting;ventricular septal defects;wavelength	In-Suck Baek;Moon S. Kim;Hoosoo Lee;Wang Hee Lee;Byoung-Kwan Cho	2014		10.3390/s141121483	chemistry;computer science;analytical chemistry	Vision	85.03586469214694	-47.74160220541432	140165
37c10898433537cd4513e0441aea7e66739f8a1f	assessing human exposure to electromagnetic fields from wireless power transmission systems	inductive power transmission;electromagnetic fields;frequency 100 khz to 50 mhz human exposure assessment wireless power transmission systems reactive near field wireless power transmission system wpt systems electric fields body tissue direct health hazards indirect risks interference medical implants safety guidelines fundamental coupling mechanisms electromagnetic near fields full wave solvers higher quality human models dosimetric methods wpt frequency range numerical simulation;numerical analysis;wireless power computer aided analysis human exposure numerical simulation specific absorption rate sar;numerical analysis biological effects of fields electromagnetic fields electromagnetic interference inductive power transmission;electromagnetic interference;safety power transmission wireless communication standards power transmission computer aided engineering specific absorption rate;biological effects of fields	The strong reactive near-field wireless power transmission (WPT) systems induce electric fields in the body tissue of persons in their close vicinity. This may pose potential direct health hazards or indirect risks via interference with medical implants. In this paper, the safety guidelines and the fundamental coupling mechanisms of the human body with the electromagnetic near fields of WPT are reviewed as well as the methodology and the instrumentation for the demonstration of the safety of such systems operating between 100 kHz and 50 MHz. Based on this review, the advantages and shortcomings of state-of-the-art numerical and experimental techniques are discussed and applied to a generic WPT operating at 8 MHz. Finally, current research needs are identified which include: 1) the extension of safety guidelines for coverage of persons with implants; 2) more computationally efficient full-wave solvers; 3) higher quality human models which cover different population groups and include improved models of nerve tissue; 4) experimental dosimetric methods for the WPT frequency range; and 5) product standards to demonstrate safety of specific WPT.	algorithmic efficiency;design of experiments;frequency band;interference (communication);numerical analysis;power supply	Andreas Christ;Mark Douglas;Jagadish Nadakuduti;Niels Kuster	2013	Proceedings of the IEEE	10.1109/JPROC.2013.2245851	electromagnetic interference;electronic engineering;electromagnetic field;telecommunications;numerical analysis;engineering;electrical engineering;physics;quantum mechanics	Mobile	93.93021179086355	-24.36147435070838	140965
c84c9a9f292db481e3f5694a286501149ac37d3c	biodevices based on shape-memory polymers - current capabilities and challenges	shape memory polymer	Shape-memory polymers are active materials with thermomechanical coupling and a high capability to recover from high levels of deformation, which, combined with their low cost and density has favoured the appearance of numerous applications, particularly those linked to the Medical Industry. In many cases, these materials are of medical standard, which increases the chances of obtaining biocompatible devices. In the last decade enormous progress has been made on many areas, regarding these materials, such as synthesis, characterization, activation and others, aimed at improving their applicability. However, various spheres of action still remain that require more in depth research to promote the production start-up of various shape-memory polymer-based devices that have had laboratory validation. This work sets out the potential these materials provide for developing biodevices and the main advances achieved. Also shown are various medical devices just being developed, as well current study needs and	polymer;speech synthesis	Andr√©s D√≠az Lantada;Pilar Lafont Morgado;H√©ctor Lorenzo-Yustos;Vicente Lorenzo Esteban;Julio Mu√±oz Garc√≠a;Jos√© Luis Mu√±oz Sanz;Javier Echavarri Otero;Juan Manuel Mu√±oz-Guijosa	2009			shape-memory polymer;computer science	HCI	87.9719591305417	-24.648682130996505	141193
a88f4cec8bcf1a96a3c84557f1d8de7695597bf9	a phase-based time-frequency masking for multi-channel speech enhancement in domestic environments		This paper introduces a novel time-frequency masking approach for speech enhancement, based on the consistency of the phase of the cross-spectrum observed at multiple microphones. The proposed approach is derived from solutions commonly adopted in spatial source separation and can be used as a post-filter in traditional multi-channel speech enhancement schemes. Since it is not based on a modeling of the coherence of diffuse noise, the proposed method complements traditional post-filters implementations, targeting non diffuse/coherent sources. It is particularly effective in domestic scenarios where microphones in a given room capture interfering coherent sources active in adjacent rooms. An experimental analysis on the DIRHA-GRID corpus shows that the proposed method considerably improves the signal-to-interference-ratio and can be used on top of state-ofthe-art multi-channel speech enhancement methods.	coherence (physics);corpus linguistics;interference (communication);microphone;source separation;speech enhancement	Alessio Brutti;Antigoni Tsiami;Athanasios Katsamanis;Petros Maragos	2016		10.21437/Interspeech.2016-150	speech recognition;artificial intelligence;pattern recognition;computer science;time‚Äìfrequency analysis;masking (art);speech enhancement;communication channel	Vision	84.020424592412	-35.469078081006835	141534
2568121e7e3d78d491838efa4ed12fa2acd5b2f1	the size matching and scaling method: a synthesis method for the design of mesoscale cellular structures	computer aided design;cellular structure;optimisation;design process;rapid prototyping;computer aided manufacturing;design;finite element analysis;high performance;cellular manufacturing	Mesoscale lattice structures are a type of cellular structure with support element lengths on the order of magnitude of centimeters. These types of structures are engineered for high performance and are used particularly in industries where low weight and high strength are desired. However, these structures are difficult to design because they often contain thousands of support elements. To design mesoscale lattice structures, current synthesis methods generally require some form of rigorous, multi-variable optimization that can slow or halt the design process. In this paper, we present a new, highly efficient, method for the design of mesoscale lattice structures, the Size Matching and Scaling method. This method eliminates the need for time-consuming optimization by using a combination of a solid-body finite element analysis and a library of pre-defined lattice configurations to generate a structure's lattice topology. In addition, we explore several methods for determining the best lattice diameter values for the lattice topology. Various 2-D and 3-D examples will be used to test and validate the method.	2.5d;active set method;converge;effective method;electronic filter topology;finite element method;halting problem;mathematical optimization;particle swarm optimization;scalability	Patrick S. Chang;David W. Rosen	2010	2010 International Conference on Manufacturing Automation	10.1080/0951192X.2011.650880	structural engineering;design;simulation;design process;engineering;computer aided design;engineering drawing;computer-aided manufacturing;mechanical engineering	EDA	84.97938283539874	-24.671495096373093	141711
c13cd98b7965cd64177775b657e49c053b9b0c97	super-resolved time-of-flight sensing via fri sampling theory	multi path;global positioning system hafnium compounds data structures boolean functions optical fibers signal resolution time frequency analysis;finite rate of innovation;time of flight imaging;time of flight imaging finite rate of innovation multi path sampling theory super resolution;photon counting image resolution optical sensors parameter estimation;super resolution;lidar sensor super resolved time of flight sensing fri sampling theory optical time of flight sensors optical signal multi echo backscatter image formation model parameter estimation dirac impulses photon counting;sampling theory	Optical time-of-flight (ToF) sensors can measure scene depth accurately by projection and reception of an optical signal. The range to a surface in the path of the emitted signal is proportional to the delay time of the light echo or the reflected signal. In practice, a diverging beam may be subject to multi-echo backscatter, and all these echoes must be resolved to estimate the multiple depths. In this paper, we propose a method for super-resolution of optical ToF signals. Our contributions are twofold. Starting with a general image formation model common to most ToF sensors, we draw a striking analogy of ToF systems with sampling theory. Based on our model, we reformulate the ToF super-resolution problem as a parameter estimation problem pivoted around the finite-rate-of-innovation framework. In particular, we show that super-resolution of multi-echo backscattered signal amounts to recovery of Dirac impulses from low-pass measurements. Our theory is corroborated by analysis of data collected from a photon counting, LiDAR sensor, showing the effectiveness of our non-iterative and computationally efficient algorithm.	algorithm;algorithmic efficiency;backscatter (email);dirac delta function;estimation theory;image formation;iterative method;low-pass filter;sampling (signal processing);sensor;signal reflection;super-resolution imaging	Ayush Bhandari;Andrew M. Wallace;Ramesh Raskar	2016	2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2016.7472430	computer vision;computer science;superresolution	Robotics	86.9219209448178	-38.876352644767906	142610
c5c1918e2ce021676fd04615d1b03a944448b104	image reconstruction under contact impedance effect in micro electrical impedance tomography sensors		Contact impedance has an important effect on micro electrical impedance tomography (EIT) sensors compared to conventional macro sensors. In the present work, a complex contact impedance effect ratio <italic>Œæ</italic> is defined to quantitatively evaluate the effect of the contact impedance on the accuracy of the reconstructed images by micro EIT. Quality of the reconstructed image under various <italic>Œæ</italic> is estimated by the phantom simulation to find the optimum algorithm. The generalized vector sampled pattern matching (GVSPM) method reveals the best image quality and the best tolerance to <italic>Œæ</italic>. Moreover, the images of yeast cells sedimentary distribution in a multilayered microchannel are reconstructed by the GVSPM method under various mean magnitudes of contact impedance effect ratio |<italic>Œæ</italic>|. The result shows that the best image quality that has the smallest voltage error <italic>U<sub>E</sub></italic> = 0.581 is achieved with measurement frequency <italic>f</italic> = 1 MHz and mean magnitude |<italic>Œæ</italic>| = 26. In addition, the reconstructed images of cells distribution become improper while <italic>f</italic> < 10 kHz and mean value of |<italic>Œæ</italic>| > 2400.	cardiography, impedance;characteristic impedance;electromagnetically induced transparency;image quality;iterative reconstruction;kilohertz;megahertz;nominal impedance;pattern matching;phantom reference;phantoms, imaging;quantitative impedance;sampling - surgical action;simulation;algorithm;electric impedance;sensor (device);tomography;voltage	Xiayi Liu;Jiafeng Yao;Tong Zhao;Hiromichi Obara;Yahui Cui;Masahiro Takei	2018	IEEE Transactions on Biomedical Circuits and Systems	10.1109/TBCAS.2018.2816946	iterative reconstruction;voltage;electronic engineering;tomography;electrical impedance tomography;acoustics;microchannel;imaging phantom;computer science;image quality;electrical impedance	Visualization	92.36177638490246	-24.22754490129246	143266
401f68caf45216e9d1f4e9db84ec182fc4431dab	acquisition and representation of 2d and 3d data from turbulent flows and flames	inorganic organic physical and analytical chemistry;general and miscellaneous mathematics computing and information science;measurement by laser beam;flames;fires fluid flow measurement gas lasers light scattering engines density measurement velocity measurement temperature measurement optical coupling laser beams;computer graphics;light scattering;computers computerized models computer programs 1987 1989;fluid flow;turbulence computerised picture processing data acquisition flames flow measurement light scattering measurement by laser beam;scattering;data acquisition system;data representation;three dimensional;computer graphic;laser light scattering;oxidation;three dimensional calculations;data representations laser light scattering two dimensional measurements turbulent flows flames three dimensional measurements;data acquisition systems;computerised picture processing;chemical reactions;thermochemical processes 400800 combustion pyrolysis high temperature chemistry;turbulent flow;flow measurement;analytical chemistry;chemical reaction;data acquisition;combustion;turbulence;two dimensional calculations	Laser light scattering techniques for making two- and three-dimensional measurements in turbulent flows and flames are outlined, and examples of data representations are shown. Limitations and problems in displaying data are discussed.<<ETX>>	light field;turbulence	Marshall B. Long;Kevin Lyonns;Joseph K. Lam	1989	Computer	10.1109/2.35198	simulation;data acquisition;fluid dynamics	Graphics	90.29884008881297	-25.169480148931452	143872
28317adeaac916d0c7f0b3d09d4699285ac8af6d	parallel implementations of beamforming design and filtering for microphone array applications		One of the main limitations of microphone array algorithms for audio applications has been their high computational cost in real acoustic environments when real-time signal processing is absolutely required. Regarding audio/speech signal processing, beamforming algorithms have been used for the recovery of acoustic signals from their observations when they are corrupted by noise, reverberation and other interfering signals. In order to reduce their high computational load, frequency-based filtering have been used to achieve a real time application. Our research focuses on the use of different multicore/manycore platforms in order to achieve a real time beamforming application in the time domain. Efficient algorithms has been proposed and tested in several devices and results have shown that GPU implementation of beamforming design and filtering outperforms multicore implementation in computational cost terms. The performance obtained suggests that GPU implementation paves the way for low-cost real-time audio beamforming applications.	acoustic cryptanalysis;acoustic fingerprint;algorithm;algorithmic efficiency;beamforming;best, worst and average case;cuda;central processing unit;computational complexity theory;filter design;graphics processing unit;library (computing);manycore processor;microphone;multi-core processor;parallel computing;real-time clock;real-time locating system;real-time transcription;signal processing;speech processing;speedup;unix signal	Jorge Lorente;Gema Pi√±ero;Antonio M. Vidal;Jose A. Belloch;Alberto Gonz√°lez	2011	2011 19th European Signal Processing Conference		multidimensional signal processing;electronic engineering;real-time computing;speech recognition;audio signal processing;computer science;digital signal processing;beamforming	HPC	85.03619415779153	-36.90674515222037	143879
6ed60b7ca32caabb8724f00e5f91731a2ff1dc7c	ild preservation in the multichannel wiener filter for binaural hearing aid applications	wiener filters;approximation theory;distortion;hearing aids;ild preservation;binaural hearing aid applications;bounded symmetrical approximation;interaural level difference;localization cue distortion;maximum-tolerated binaural-cue distortion;multichannel wiener filter;noise reduction;symmetrical frontal angles;hearing-aids;binaural;noise reduction;speech processing;wiener filter	This work presents a new method for noise reduction in binaural hearing aid applications that preserves the interaural level difference. A bounded symmetrical approximation of the logarithm is employed to estimate the interaural level difference, resulting in identical values for symmetrical (left/right) frontal angles. It proposes a new cost function to be used in association with the multichannel Wiener filter technique to provide a trade-off between noise reduction and distortion of the localization cues. Simulations of a binaural setup and comparisons with a previously developed technique show that the new method gives a signal to noise ratio improvement of up to 9.6 dB better than the baseline technique, for the same maximum-tolerated binaural-cue distortion.	approximation;baseline (configuration management);binaural beats;computer simulation;distortion;internet listing display;loss function;noise reduction;signal-to-noise ratio;wiener filter	M√°rcio Holsbach Costa;Patrick A. Naylor	2014	2014 22nd European Signal Processing Conference (EUSIPCO)		speech recognition;acoustics;mathematics;audiology	EDA	83.84247622964173	-34.797553687745314	144297
5344b508a31ec6d30fd9aa3fcbed5249389e154f	microphone array for 2d sound localization and capture	type system;humanoid robot;mobile robot;sound localization;pressure distribution	This paper describes two circular microphone arrays and a square microphone array which can be used for sound localization and sound capture. Sound capture by microphone array is achieved by Sum and Delay Beam Former (SDBF). Simulation of sound pressure distribution of 32 & 128ch circular microphone array and 128ch square microphone array are shown. According to simulation results, dedicated PCI 128-channel simultaneous input board and Firewire (IEEE1394) 32-channel board are developed with maximum sampling rate of 44.1kHz and 11.025kHz sample respectively.		Satoshi Kagami;Hiroshi Mizoguchi;Yuki Tamai;Takeo Kanade	2004		10.1007/11552246_5	mobile robot;electronic engineering;speech recognition;type system;acoustics;sound localization;noise-canceling microphone;computer science;engineering;humanoid robot;artificial intelligence;pressure coefficient	Robotics	87.24133275291521	-35.606245855028455	145180
53515304f0c19d9a003aaa5d8f52436e203f4190	improvement in estimation accuracy of a sound source direction by a frequency domain binaural model with information on listener's head movement in a conversation	source separation accelerometers acoustic signal processing hearing aids magnetic field measurement magnetic sensors;hearing aids;multiple speaker conversation sound source direction estimation accuracy improvement frequency domain binaural model sound source separation binaural hearing aids sound source tracking acoustic signal processing nonverbal information speaker position head movement rotational angle inertial sensor accelerometer angular velocity sensor magnetic has sensor;magnetic heads;frequency domain analysis;magnetic heads estimation face frequency domain analysis hearing aids ear accelerometers;ear;estimation;face;accelerometers	Estimation of sound source directions and separation of sound sources are implemented on many products widely, and binaural hearing aids are one of its applications. In a conversation using a binaural hearing aid, continuous tracking of sound sources with acoustics signals are sometimes complicated because sound sources move dynamically. In order to make the tracking of sound sources simple, it is considered to be helpful to use non-verbal information in communication. Since a user's body movement, including a head, corresponds to speakers' positions, it is possible to estimate communication zone where sound sources locate by a head direction. In this paper, a head movement in a conversation, as non-verbal information in communication, is measured and discussed. A rotational angle of a head movement is estimated by an inertial sensor which has an accelerometer, angular velocity sensor, and a magnetic field sensor with attaching to left ear position. A relationship between a head movement and directions of sound sources during a conversation by multiple speakers is presented. The results indicate a possibility for estimating a communication zone.	angularjs;binaural beats;covox speech thing;experiment;motion capture;velocity (software development)	Yoshifumi Chisaki;Shogo Tanaka	2014	Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific	10.1109/APSIPA.2014.7041784	speech recognition;binaural recording;acoustics;engineering;head-related transfer function;head shadow;acoustic source localization;audiology	Robotics	86.46222464181658	-35.40153419612756	145968
4c2561d3c097644be3e962ceadd2b076f0d47c04	estimating power spectral density of unmanned aerial vehicle rotor noise using multisensory information		A method to accurately estimate the power spectral density (PSD) of an unmanned aerial vehicle (UAV) is proposed, in anticipation of being used for a UAV-mounted audio recording system that clearly captures target sound while suppressing rotor noise. The method utilises UAV rotor characteristics as well as microphone recorded signals to combat practical limitations seen in a previous study. The proposed method was evaluated on a simulation platform modelled after the UAV used in the previous study. Results showed that the proposed method was able to estimate the rotor noise PSD to within 1.3-3.3 dB log spectral distortion (LSD) regardless of the presence of surrounding sound sources.		Benjamin Yen;Yusuke Hioka;Brian R. Mace	2018	2018 26th European Signal Processing Conference (EUSIPCO)	10.23919/EUSIPCO.2018.8553140	acoustics;rotor (electric);distortion;sound recording and reproduction;microphone;spectral density;computer science	EDA	85.28636866467704	-39.10242686845822	146148
d82072aa2f967e5fd848e7156f1411edfa55c632	noise reduction by paired-microphones using spectral subtraction	microphones;front end;noise reduction microphone arrays working environment noise acoustic noise speech recognition adaptive arrays microwave integrated circuits speech enhancement computer simulation linear predictive coding;acoustic signal processing;array signal processing;lpc log spectral envelope distortions noise reduction paired microphones spectral subtraction front end processor speech recognition systems subtractive microphone array noisy speech signal nonstationary noise sudden noise ss methods;interference suppression;spectral subtraction;microphone array;acoustic noise;noise reduction;speech recognition;spectral analysis microphones speech recognition acoustic noise acoustic transducer arrays array signal processing acoustic signal processing interference suppression;acoustic transducer arrays;spectral analysis;computer simulation	This paper proposes a method of noise reduction by pairedmicrophones as a front-end processor for speech recognition systems. This method estimates noises using a subtractive microphone array and subtracts them from the noisy speech signal using the Spectral Subtraction (SS). Since this method can estimate noises analytically and frame by frame, it is easy to estimate noises not depending on these acoustic properties. Therefore, this method can also reduce non stationary noises, for example sudden noises when a door has just closed, which can not be reduced by other SS methods. The results of computer simulations and experiments in a real environment show that this method can reduce LPC log spectral envelope distortions.	acoustic cryptanalysis;computer simulation;distortion;experiment;front-end processor;lpc;microphone;naruto shippuden: clash of ninja revolution 3;noise reduction;speech recognition;stationary process;stellar classification	Mitsunori Mizumachi;Masato Akagi	1998		10.1109/ICASSP.1998.675436	computer simulation;gradient noise;gaussian noise;image noise;effective input noise temperature;computer vision;noise;speech recognition;colors of noise;dark-frame subtraction;value noise;noise temperature;computer science;noise measurement;front and back ends;noise;noise;noise reduction;noise figure;noise floor;noise;salt-and-pepper noise	Robotics	83.75053244680139	-34.40454764619741	146588
03e317d97c0da8c4b62c784185310a1d29317cc0	multi-channel maximum likelihood pitch estimation	reverberation;multi channel audio pitch estimation microphone arrays;frequency estimation;speech;maximum likelihood estimation;channel estimation;reverberation maximum likelihood estimation microphone arrays;reverberation multichannel maximum likelihood pitch estimation parametric model fundamental frequency signal to noise ratio microphone characteristics;multi channel audio;microphone arrays;noise maximum likelihood estimation channel estimation frequency estimation speech harmonic analysis;pitch estimation;noise;harmonic analysis	In this paper, a method for multi-channel pitch estimation is proposed. The method is a maximum likelihood estimator and is based on a parametric model where the signals in the various channels share the same fundamental frequency but can have different amplitudes, phases, and noise characteristics. This essentially means that the model allows for different conditions in the various channels, like different signal-to-noise ratios, microphone characteristics and reverberation. Moreover, the method does not assume that a certain array structure is used but rather relies on a more general model and is hence suited for a large class of problems. Simulations with real signals shows that the method outperforms a state-of-the-art multi-channel method in terms of gross error rate.	computer simulation;microphone;parametric model;pitch detection algorithm;signal-to-noise ratio	Mads Gr√¶sb√∏ll Christensen	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6287903	speech recognition;noise-canceling microphone;reverberation;noise;speech;harmonic analysis;mathematics;maximum likelihood;estimation theory	Robotics	83.34138064479296	-35.36437174314291	146613
a2ff9df71adcf0ae4743e4b498fc7ca6b2776053	a simple method for estimating the impulse responses of loudspeakers	acoustic signal processing transient response architectural acoustics loudspeakers parameter estimation anechoic chambers acoustic;architectural acoustics;acoustic signal processing;acoustic path estimation impulse responses estimation loudspeakers signal processing applications anechoic chamber;transient response;loudspeakers;signal processing;anechoic chambers acoustic;impulse response;parameter estimation;loudspeakers microphones anechoic chambers acoustic measurements signal processing numerical simulation acoustic applications echo cancellers councils virtual reality;numerical simulation	In this paper we consider the problem of estimating the impulse responses of loudspeakers. This is an important problem since loudspeaker impulse responses constitute a vital component in some signal processing applications such as correction of loudspeaker characteristics. Up to now the most accurate but also most expensive method has been to estimate the impulse responses from measurements taken in an anechoic chamber. We present a method that allows good estimation of loudspeaker impulse responses in an ordinary echoic environment. This is accomplished by estimating the acoustic path of the room using a second loudspeaker with a known impulse response. Numerical simulations are carried out in order to study the performance of the suggested method. Index Terms ‚Äî Loudspeaker, impulse response, estimation, acoustics.	acoustic cryptanalysis;loudspeaker;numerical linear algebra;signal processing;simulation	Per √Öhgren;Petre Stoica	2003	IEEE Trans. Consumer Electronics	10.1109/TCE.2003.1261170	loudspeaker;computer vision;electronic engineering;speech recognition;impulse response;computer science;engineering;signal processing;estimation theory;transient response	Metrics	85.87865485665174	-33.81266054288886	147754
29eca07d135d050e8dde1aae7de7a9a535017172	development and analysis of distributed acoustic echo cancellation microphone system	diaphonie;simulation ordinateur;distributed system;systeme reparti;crosstalk;teleconference;adaptive filtering;filtrado adaptable;telephone;microfono;experimental result;teleconferencia;supresion;sistema repartido;diafonia;double talk detection;resultado experimental;echo;eco;teleconferencing system;filtrage adaptatif;simulacion computadora;resultat experimental;telefono;computer simulation;adaptive filter;acoustic echo cancellations;acoustic echo canceller;suppression;microphone	Abstract   Acoustic echo cancellation using an adaptive transversal filter and the least mean square algorithm is the most effective technique of reducing acoustic echoes in a hands-free telephone system. However, a very high-order adaptive filter and multiple echo paths for each microphone result in difficulties in algorithm convergence and hardware implementation. This paper presents a distributed system which performs acoustic echo cancellation in the microphone unit. Each acoustic echo cancellation microphone unit has two closely spaced directional microphones pointing in opposite directions and a much lower order adaptive filter than in the earlier systems. Computer simulations were conducted based on real speech data collected from a typical conference room. Finally, a robust double-talk detector, which identifies three modes of operation, was developed and tested in real-time	acoustic cryptanalysis;echo suppression and cancellation;microphone	Sen M. Kuo;Zhibing Pan	1994	Signal Processing	10.1016/0165-1684(94)90002-7	computer simulation;adaptive filter;computer vision;electronic engineering;telecommunications;noise-canceling microphone;computer science;engineering	Mobile	84.12485141793198	-32.36058631953915	148467
dfad99fe6d9bbba16d089a0c8779894b3d749446	a modulation property of time-frequency derivatives of filtered phase and its application to aperiodicity and fo estimation		We introduce a simple and linear SNR (strictly speaking, periodic to random power ratio) estimator (0 dB to 80 dB without additional calibration/linearization) for providing reliable descriptions of aperiodicity in speech corpus. The main idea of this method is to estimate the background random noise level without directly extracting the background noise. The proposed method is applicable to a wide variety of time windowing functions with very low sidelobe levels. The estimate combines the frequency derivative and the time-frequency derivative of the mapping from filter center frequency to the output instantaneous frequency. This procedure can replace the periodicity detection and aperiodicity estimation subsystems of recently introduced open source vocoder, YANG vocoder. Source code of MATLAB implementation of this method will also be open sourced.	fo (complexity);instantaneous phase;matlab;modulation;noise (electronics);open-source software;quasiperiodicity;signal-to-noise ratio;speech corpus;vocoder;window function;yang	Hideki Kawahara;Ken-Ichi Sakakibara;Masanori Morise;Hideki Banno;Tomoki Toda	2017		10.21437/Interspeech.2017-436	center frequency;control theory;modulation;artificial intelligence;background noise;computer science;window function;estimator;pattern recognition;time‚Äìfrequency analysis;linearization;instantaneous phase	EDA	84.38658515223145	-31.961912791278337	149280
729f4327d8eacccacf2350026b0011bf368324f1	structure from sound with incomplete data		In this paper, we consider the problem of jointly localizing a microphone array and identifying the direction of arrival of acoustic events. Under the assumption that the sources are in the far field, this problem can be formulated as a constrained low-rank matrix factorization with an unknown column offset. Our focus is on handling missing entries, particularly when the measurement matrix does not contain a single complete column. This case has not received attention in the literature and is not handled by existing algorithms, however it is prevalent in practice. We propose an iterative algorithm that works with pairwise differences between the measurements eliminating the dependence on the unknown offset. We demonstrate state-of-the-art performance both in terms of accuracy and versatility.	acoustic cryptanalysis;algorithm;direction of arrival;iterative method;microphone	Miranda Krekovic;Gilles Baechler;Ivan Dokmanic;Martin Vetterli	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8462559	iterative method;mathematical optimization;artificial intelligence;noise measurement;computer science;microphone array;pattern recognition;matrix (mathematics);offset (computer science);matrix decomposition;pairwise comparison;direction of arrival	Robotics	84.77612038451426	-37.11419470887754	149777
7dc843eaa1ffe6962035e9f3b9705116141d727f	pole-zero approximations for head-related transfer functions using a logarithmic error criterion	design algorithm;least squares error criterion pole zero approximations head related transfer functions logarithmic error criterion human free field to eardrum transfer functions binaural acoustic fields synthesis headphones computational complexity standard pole zero designs squared difference designed frequency response desired frequency response design algorithm error criterion complex logarithms log magnitude error phase error pole zero model orders;pole zero model orders;traitement signal;human free field to eardrum transfer functions;difraccion onda;z transformation;degradation;frequency synthesizers;algoritmo busqueda;reproduccion sonido;reproduction son;sound synthesis;transfer functions;least square error;arithmetic acoustic signal processing acoustic field transfer functions frequency response computational complexity headphones signal synthesis approximation theory error analysis poles and zeros;synthese son;algorithme recherche;pole zero approximations;search algorithm;transformation z;acoustic signal processing;sound reproduction;squared difference;acoustic field;transformacion z;metodo polo cero;complex logarithms;champ libre;casque ecouteur;error criterion;biomembranes;head related transfer functions;least squares error criterion;frequency response;approximation theory;poles and zeros;sintesis sonido;error analysis;standard pole zero designs;designed frequency response;log magnitude error;head related transfer function;ear;casco auricular;computational complexity;transfer function;diffraction onde;phase error;signal processing;desired frequency response;campo libre;methode pole zero;arithmetic;headphone;fonction transfert;binaural acoustic fields synthesis;humans;head;free field;signal synthesis;acoustic waves;headphones;tete;wave diffraction;signal processing algorithms;pole zero method;transfer functions headphones signal processing algorithms acoustic waves biomembranes ear degradation humans computational complexity frequency synthesizers	Pole-zero approximations of human free-field-to-eardrum transfer functions-i.e., head-related transfer functions (HRTFs)-can be used to synthesize binaural acoustic fields over headphones with fewer parameters, and therefore, lower computational complexity than is typically achieved by all-zero approximations. While standard pole-zero designs minimize the squared difference between the desired and designed frequency responses, the synthesis of binaural acoustic fields is more likely to be sensitive to relative, rather than absolute, differences in the HRTF approximations. The paper proposes a new design algorithm that minimizes an error criterion based on complex logarithms. As a result, both log-magnitude and phase errors are minimized. Slight modifications to the proposed algorithm result in one for which the phase error can be ignored. A comparison of this modified algorithm to others that have been developed to minimize the log-magnitude error shows implementation advantages without sacrificing performance. In achieving comparable errors, application of the proposed algorithm to the HRTF approximation results in pole-zero model orders smaller than those required for approximating the HRTFs using a least-squares error criterion.	approximation;transfer function	Michael A. Blommer;Gregory H. Wakefield	1997	IEEE Trans. Speech and Audio Processing	10.1109/89.568734	speech recognition;acoustics;computer science;calculus;signal processing;mathematics;transfer function;statistics	Visualization	85.78804168643303	-33.04387671551977	150349
4892f0579e977d5682cbdd5a84179c21fb40a233	novel schemes for nonlinear acoustic echo cancellation based on filter combinations	echo cancellation;nonlinear filters;kernel;degradation;colored noise;combination of filters;probability density function;acoustics;nonlinear acoustic echo cancellation;nonlinear acoustics echo suppression filtering theory laplace equations;speech;indexing terms;data mining;nonlinear acoustics;speech input signals nonlinear acoustic echo cancellation filter combinations channel generation nonlinear echo signal power nonlinear echo cancellers laplacian colored noise;laplace equations;adaptive filters;adaptive signal processing;laplacian colored noise;channel generation;signal processing;multimedia communication;filter combinations;echo suppression;nonlinear echo cancellers;robustness;combination of filters adaptive filters volterra filters nonlinear acoustic echo cancellation;nonlinear echo signal power;echo cancellers;speech input signals;adaptive filter;nonlinear acoustics echo cancellers nonlinear filters adaptive filters kernel signal processing multimedia communication degradation adaptive signal processing robustness;filtering theory;volterra filters;noise;acoustic echo canceller	Nonlinear acoustic echo cancellers (NLAEC) are becoming increasingly important in hands-free applications. However, in some situations, an NLAEC is inferior to a linear AEC, especially when the channel generates a negligible (or no) nonlinear echo. In general, the ratio of the linear to nonlinear echo signal power is unknown a priori, and will vary over time, thus making it difficult to know if an NLAEC would improve or degrade the cancellation. In this paper, we present two novel solutions to this problem based on the adaptive combination of linear and nonlinear echo cancellers. Both solutions perform efficiently regardless of the level of nonlinear echo. The benefits and robustness of both schemes are illustrated by experiments using Laplacian colored noise and speech input signals.	acoustic cryptanalysis;acoustic model;colors of noise;echo (command);echo suppression and cancellation;experiment;laplacian matrix;nonlinear system	Luis Antonio Azpicueta-Ruiz;Marcus Zeller;Jer√≥nimo Arenas-Garc√≠a;Walter Kellermann	2009	2009 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2009.4959553	adaptive filter;speech recognition;computer science;signal processing;mathematics	Robotics	83.87414115355953	-33.37875814275854	150448
92c6ff682c4d050093c67b3ef4bee6894c6132f7	analysis of rate constraints for mwf-based noise reduction in acoustic sensor networks	available bandwidth;microphones;distributed estimation;wiener filters acoustic signal processing distributed sensors microphones noise abatement rate distortion theory;speech;wiener filters;microphones speech performance gain acoustic sensors zinc noise noise reduction;acoustic signal processing;rate constraint analysis communication link centralized multichannel wiener filter microphone signals spatially distributed microphone nodes acoustic sensor network mwf based noise reduction;noise abatement;sensor network;rate distortion theory acoustic sensor networks distributed estimation;distributed sensors;rate distortion theory;spatial distribution;noise reduction;performance gain;zinc;wiener filter;acoustic sensors;acoustic sensor networks;noise	In an acoustic sensor network, consisting of spatially distributed microphone nodes, a significant noise reduction can be achieved using the centralized multi-channel Wiener filter (MWF), requiring all available microphone signals in the entire network. However the limited bandwidth of the communication link typically does not al low to transmit all microphone signals between the different nodes. Recently, a distributed node-specific MWF-based noise reduction scheme has been presented, where each node only transmits a filtered combination of its microphone signals. In this paper, the performance gain of the centralized MWF and the distributed node-specific MWF-based scheme are analyzed as a function of the available band width of the communication link.	acoustic cryptanalysis;centralized computing;microphone;noise reduction;wiener filter	Toby Christian Lawin-Ore;Simon Doclo	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5946392	speech recognition;noise-canceling microphone;computer science;noise;speech;noise reduction;zinc;wiener filter;statistics	Mobile	84.52022681224952	-35.22860110463989	150627
2ccd81ebc498cd1a2cbece53a7f3657612d344e7	microphone array position calibration in the frequency domain using a single unknown source	microphones;microphones arrays calibration frequency measurement position measurement cost function mathematical model;cost function;reverberant domains microphone array position calibration frequency domain single unknown source reverberant room wide band single source model based polynomials simple block coordinate descent algorithm time domain methods;frequency measurement;arrays;position measurement;reverberation acoustic radiators microphone arrays;mathematical model;calibration;reverberation array position calibration modal interpolation	We study the problem of microphone array localization in a strongly reverberant room, where time of arrivals (TOA) or time difference of arrivals (TDOA) cannot always be measured precisely. Instead, we use frequency-domain measurements to calibrate the array position, based on the modes of the room, excited by a wide-band single source, that can be unknown. By using the fact that each measured mode can be decomposed as a sum of model-based polynomials, we build a cost function whose minimum indicates the positions of the microphones. A simple Block Coordinate Descent algorithm can be used to minimize this cost function. Numerical results indicate that this algorithm converges to the right solution, and therefore that using frequency measurements for position calibration is a valid concept for dense arrays, as an alternative to time-domain methods in reverberant domains.	algorithm;coordinate descent;loss function;microphone;multilateration;numerical method;polynomial;time of arrival	Thibault Nowakowski;Laurent Daudet;Julien de Rosny	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7177985	calibration;speech recognition;computer science;mathematical model;mathematics;statistics	Robotics	85.29361775490345	-36.43366275054669	150824
561827e4ea8c9c0f2edc4ecbc011651d019f01e3	wola noise cancelling performance	wiener filters filtering theory handicapped aids hearing aids iterative methods mean square error methods quadratic programming;iterative scheme wola noise cancelling performance digital hearing aids weighted overlap add structure short time wiener filter bark domain fft bins nyquist rate optimal minimum mean square error filtering mse real valued filter impulse response quadratic programming noise signal speech signal signal processing structure window function weighted optimal solution;speech vectors time domain analysis noise cancellation optimization	The goal of noise cancelling for hearing aids is to remove the noise in the corrupted speech so that the hearing impaired can better understand and participate in a conversation. Most digital hearing aids use a Weighted Overlap-Add (WOLA) structure [1] to implement the noise cancelling algorithm. Often, it is attempted to build a short time Wiener filter with a WOLA either in the FFT or in the Bark domain. Such a filter results in real valued gains to the FFT bins of the input signal and can be easily implemented in the WOLA structure. These real valued gains are also symmetrical with respect to the Nyquist rate, which results in a real valued impulse response from the filter.	algorithm;computer performance;experiment;fast fourier transform;iterative method;maxima and minima;nyquist rate;overlap‚Äìadd method;quadratic programming;whole earth 'lectronic link;wiener filter	Guido Schuster;Reto Ansorge	2008	2008 16th European Signal Processing Conference		mathematical optimization;electronic engineering;speech recognition;mathematics;wiener filter	Robotics	83.8990365597092	-34.16330054111469	151192
5bba37dfebda16b30ec1730e152100d03893b105	sound source localization for video surveillance camera	video surveillance acoustic generators filtering theory microphones security;background noise conditions sound source localization video surveillance camera video analytics surveillance applications sound scene analysis security risks low complexity method two microphone estimation source localization problem low complexity solution generalized cross correlation with phase transform method gcc phat method band selective processing inter frame filtering gcc phat objective function peak detection audio bandwidth microphone spacing angle resolution processing delay multimicrophone configuration spatial sound localization microphone pairs robust sound direction estimation;microphones;video surveillance;acoustic generators;noise measurement;adaptive filters;estimation;signal to noise ratio;cameras microphones adaptive filters estimation noise measurement signal to noise ratio;security;filtering theory;cameras	While video analytics used in surveillance applications performs well in normal conditions, it may not work as accurately under adverse circumstances. Taking advantage of the complementary aspects of video and audio can lead to a more effective analytics framework resulting in increased system robustness. For example, sound scene analysis may indicate potential security risks outside field-of-view, pointing the camera in that direction. This paper presents a robust low-complexity method for two-microphone estimation of sound direction. While the source localization problem has been studied extensively, a reliable low-complexity solution remains elusive. The proposed direction estimation is based on the Generalized Cross-Correlation with Phase Transform (GCC-PHAT) method. The novel aspects of our approach include band-selective processing and inter-frame filtering of the GCC-PHAT objective function prior to peak detection. The audio bandwidth, microphone spacing, angle resolution, processing delay and complexity can all be adjusted depending on the application requirements. The described algorithm can be used in a multi-microphone configuration for spatial sound localization by combining estimates from microphone pairs. It has been implemented as a real-time demo on a modified TI DM8127 IP camera. The default 16 kHz audio sampling frequency requires about 5 MIPS processing power in our fixed-point implementation. The test results show robust sound direction estimation under a variety of background noise conditions.	algorithm;closed-circuit television;cross-correlation;fixed-point arithmetic;ip camera;loss function;microphone;motion estimation;optimization problem;processing delay;real-time clock;real-time computing;requirement;sampling (signal processing);video content analysis	Jacek Stachurski;Lorin Netsch;Randy Cole	2013	2013 10th IEEE International Conference on Advanced Video and Signal Based Surveillance	10.1109/AVSS.2013.6636622	adaptive filter;computer vision;estimation;speech recognition;noise-canceling microphone;computer science;noise measurement;information security;signal-to-noise ratio;statistics	Robotics	83.3571522149982	-39.95735025734066	152169
e569f954f9ba2811e9c689d9343135c65c9b1e65	benefits of dolphin inspired sonar for underwater object identification	dolphins;bio inspired;sonar	The sonar of dolphins has developed over many years of evolution and has achieved excellent performance levels. With this inspiration, wideband acoustic methods for underwater sensing are being developed. In this paper we explore what we expect to gain from the wide bio-inspired beampattern of such a sonar. The system employed here (the BioSonar) uses wideband sensors based on dolphin sonar, covering a frequency band from around 30kHz to 150kHz and having a frequency dependent beamwidth considerably larger than that of conventional imaging sonars. We highlight the benefits of the transducers' beamwidth, indicating how these properties may be exploited to give improved sonar performance.	dolphin;sonar	Yan Pailhas;Chris Capus;Keith E. Brown;David M. Lane	2013		10.1007/978-3-642-39802-5_4	synthetic aperture sonar;acoustics;engineering;marine engineering;communication	Robotics	85.54954490750437	-42.08660092679022	152446
f44f3c064a904a6e9d09ddffa182b19f7a516576	source localization with acoustic intensity flux matched-field processing	matched field processing;high resolution;acoustic intensity flux;source localization;vectors acoustics program processors arrays sonar equipment oceans acoustic measurements;acoustic signal processing;array signal processing;source localization matched field processing acoustic intensity flux vertical vector sensor array;vertical vector sensor array source localization acoustic intensity flux matched field processing mfp method beamforming method ocean waveguide wave propagation bartlett processors;sensor array;array signal processing acoustic signal processing;vector field;wave propagation;vertical vector sensor array	Matched field processing (MFP) is generalized beamforming method which utilizes the physics of wave propagation in the ocean waveguide to estimate the range, depth and azimuth of the sources or inversion the waveguide. Traditional MFP only uses the pressure information of the sound field. The vector sensor measures the pressure and three orthogonal components of the particle velocity simultaneously. A novel MFP method based on vertical vector-sensor array for location is proposed. Three Bartlett processors are put forward based on matching acoustic intensity flux. The performance of this algorithm is examined in simulation example. They can suppress side-lobes effectively with high resolution. And the fusion algorithm for the newly Bartlett processors is introduced in to take full advantage of the vector field. Furthermore, the combine processors have a more promising performance. Hence, the method base on matching acoustic intensity flux brings a new way for MFP.	acoustic cryptanalysis;algorithm;bartlett's bisection theorem;beamforming;central processing unit;simulation;software propagation;velocity (software development)	Wangsheng Lin;Guolong Liang;Yan Wang;Jianfei Ji	2011	2011 International Conference on Wireless Communications and Signal Processing (WCSP)	10.1109/WCSP.2011.6096927	electronic engineering;speech recognition;acoustics;engineering;acoustic source localization;sensor array	Robotics	86.5386967772167	-37.370612594789165	152608
af49a7746e30933610956ff769b56de247e40a2c	variational bayes state space model for acoustic echo reduction and dereverberation	asynchronous kalman smoother dereverberation echo reduction variational bayes;teleconferencing room variational bayes state space model dereverberation digital to analog converter noise reduction simultaneous optimization acoustic echo reduction filters second state space model noiseless multichannel speech signals kalman smoother parameter optimization acoustic echo signal speech reverberation background noise;table lookup signal to noise ratio arrays speech;speech;variational techniques acoustic noise acoustic signal processing analogue digital conversion bayes methods echo optimisation reverberation speech processing;arrays;signal to noise ratio;table lookup	In this paper, we propose a simultaneous optimization technique for speech dereverberation, acoustic echo reduction, and noise reduction, which can be utilized even when an analog-to-digital (A/D) converter and a digital-to-analog (D/A) converter are not synchronized. The proposed method utilizes a state-space model in which acoustic echo reduction filters are regarded as a time-varying state-vector due to asynchrony of the A/D converter and the D/A converter. In addition to the state-space model for acoustic echo reduction filters, the proposed method utilizes an additional state-space model in which noiseless multichannel speech signals are regarded as a state vector. By using the second state-space model, we can update the dereverberation filter under noisy environments. To optimize two types of state space models, the proposed method utilizes the variational Bayes framework. Two Kalman smoother based parameter optimization stages are performed alternatively. The proposed method is evaluated by using recorded data in a real teleconferencing room. The experimental results show that the proposed method can reduce acoustic echo signal, speech reverberation, and background noise more effectively than the conventional method by authors even when the A/D converter and the D/A converter are asynchronous.	acoustic cryptanalysis;analog-to-digital converter;asynchronous i/o;digital-to-analog converter;kalman filter;mathematical optimization;noise reduction;quantum state;state space;state-space representation;variational principle	Masahito Togami	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7177940	speech recognition;computer science;speech;signal-to-noise ratio	EDA	83.99124825729658	-35.244972019460256	152771
3b70a8c503c33ff962345ded4a0c130bda2a3a35	acoustic echo cancellation using sub-adaptive filter	acoustic signal processing;adaptive filters;echo suppression;filtering theory;acoustic echo cancellation;double talk detector;echo path change detector;optimal step-size parameter;step-size parameter control;subadaptive filter;double-talk detection;sub-adaptive filter;adaptive signal processing;adaptive filter	In this paper, we propose an acoustic echo cancellation (AEC) using a sub-adaptive filter. In the AEC, the step-size parameter of the adaptive filter must be varied according to the situations where a double talk and an echo path change occur. The proposed AEC can appropriately control the step-size parameter even if the double talk and the echo path change simultaneously occur because the optimal step-size parameter can be obtained according to the output of the sub-adaptive filter and the echo path change detector is controlled through the double talk detector. Hence, the proposed AEC can realize superior convergence property to the conventional one. Simulation results demonstrate that the proposed AEC can achieve higher ERLE and faster convergence than the conventional one.	acoustic cryptanalysis;adaptive filter;echo suppression and cancellation;norm (social);simulation;vergence	Satoshi Ohta;Yoshinobu Kajikawa;Yasuo Nomura	2006	2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07	10.1109/ICASSP.2007.366622	adaptive filter;computer vision;speech recognition;computer science	Robotics	84.23239037383081	-33.52578386441311	153797
7eeb9cc01daa724a0c5766cb9eb823d2a58f9a94	robust design of farrow-structure-based steerable broadband beamformers with sparse tap weights via convex optimization	signal image and speech processing;acoustics;mathematics in music;engineering acoustics	The Farrow-structure-based steerable broadband beamformer (FSBB) is particularly useful in the applications where sound source of interest may move around a wide angular range. However, in contrast with conventional filter-andsum beamformer, the passband steerability of FSBB is achieved at the cost of high complexity in structure, i.e., highly increased number of tap weights. Moreover, it has been shown that the FSBB is sensitive to microphone mismatches, and robust FSBB design is of interest to practical applications. To deal with the aforementioned problems, this paper studies the robust design of the FSBB with sparse tap weights via convex optimization by considering some a priori knowledge of microphone mismatches. It is shown that although the worst-case performance (WCP) optimization has been successfully applied to the design of robust filter-and-sum beamformers with boundedmicrophonemismatches, it may become unapplicable to robust FSBB design due to its over-conservativeness nature. When limited knowledge of mean and variance of microphone mismatches is available, a robust FSBB design approach based on the worst-case mean performance optimization with the passband response variance (PRV) constraint is devised. Unlike the WCP optimization design, this approach performs well with the capability of passband stability control of array response. Finally, the robust FSBB design with sparse tap weights has been studied. It is shown that there is redundancy in the tap weights of FSBB, i.e., robust FSBB design with sparse tap weights is viable, and thus leads to low-complexity FSBB.		Tiannan Wang;Huawei Chen	2015	EURASIP J. Audio, Speech and Music Processing	10.1186/s13636-015-0060-y	speech recognition;acoustics;physics	ML	84.58360258233253	-34.71482074625302	155236
95627097205f1dbee38b187d5dbc125d65197247	resolvability of music algorithm in solving multiple-dipole biomagnetic localization from spatiotemporal mcg data	relative position;magnetocardiography;classification algorithm;magnetic field;genie biomedical;sensors;forward model;analisis cuantitativo;localization;appareil circulatoire pathologie;cramer rao lower bound;hombre;campo magnetico;localizacion;problema inverso;methode calcul;signal noise ratio;algorithme;metodo calculo;algorithm;aparato circulatorio patologia;champ magnetique;localisation;matrices;biomedical engineering;inverse problem;analyse quantitative;cardiovascular disease;human;dipole electrique;quantitative analysis;algorithme music;evaluation;ingenieria biomedica;evaluacion;multiple;quantitative method;magnetocardiographie;probleme inverse;computing method;dipolo electrico;covariance matrix;inverse problems;homme;magnetocardiografia;algoritmo;electric dipole	The MUSIC (MUltiple SIgnal Classification) algorithm is a recently proposed method in solving multiple dipole localization problem from spatio-temporal magnetocardiograph (MCG) data. There are many factors that may effect the resolvability of MUSIC method in solving MCG inverse problem. For example, the number and space arrangement of sensors, the signal-noise ratio (SNR) of measurement data, the relative position of dipole to the sensors, the direction of dipole. In the case of multiple dipoles are assumed, the distance and time correlation between the dipoles may take a great effect on the solution accuracy. We need a quantitative method to evaluate the resolvability of MUSIC algorithm. In this paper spherically symmetric conductor model is applied as the forward model. The statistical performance of the MUSIC algorithm is discussed by using the MUSIC error covariance matrix. The Cramer-Rao Lower Bound (CRLB) on localization errors for MCG current source dipole models is presented. The performance of MUSIC algorithm is compared with the ultimate performance corresponding to the CRLB. The numerical studies with simulated MCG data are presented in two cases: one dipole is assumed and two dipoles are assumed. From our analysis and simulations, we can conclude that, for uncorrelated dipole signals, the MUSIC algorithm has an excellent performance. For correlated dipole signals, however, the MUSIC cannot achieve the CRLB. Our numerical analysis also demonstrate the degradation of the MUSIC efficiency when the time correlation between two dipoles increases even for high values of the number of sensors and SNR. We also see that localization error is not simply a function of the relative distance between the two dipoles, but rather a complex function of absolute dipole position and orientation.	algorithm	Jiange Chen;Noboru Niki;Yutaka Nakaya;Hiroshi Nishitani;Y. M. Kang	1998		10.1117/12.310924	electronic engineering;artificial intelligence;calculus;mathematics	Robotics	89.96401267858731	-38.90022306052202	156760
145a212ad29b6adede49cbb8be2b64dfa46b6a7d	air-coupled ultrasound time-of-flight estimation for shipping container cargo verification	embedded sensor systems;leading edge envelope line fit;sensor system;new technology;ultrasonic imaging acoustic signal processing embedded systems freight containers time of arrival estimation;time of flight;estimation method;shipping container cargo verification;ultrasound;ultrasonic imaging;real time;envelope half peak intercept ultrasound time of light estimation air coupled ultrasound interior imaging shipping container cargo verification embedded sensor systems transportation security delay estimation leading edge envelope line fit;acoustic signal processing;ultrasound time of light estimation;indexing terms;envelope half peak intercept;embedded systems;freight containers;acoustic fingerprint security ultrasound shipping delay estimation;time of arrival estimation;air coupled ultrasound interior imaging;matched filter;ultrasonic imaging containers temperature sensors matched filters acoustic reflection interference testing costs data security fingerprint recognition;acoustic fingerprint;security;delay estimation;transportation security;shipping	The falling cost of embedded sensor systems has opened up the possibility of in-transit air-coupled ultrasound interior imaging of shipping container cargo. This new technology could allow for real-time cargo integrity verification and improved shipping and transportation security. This paper takes the initial steps in developing a temperature invariant descriptor by comparing three time-of-flight (TOF) estimation methods from the literature using in situ data. The methods compared are matched filter, leading edge envelope line fit, and a simple envelope half-peak intercept. The results show that the simple half-peak intercept method provided the most consistent TOF estimate with respect to overlapping pulse data.	embedded system;matched filter;real-time transcription;visual intercept	Patrick McVittie;Les E. Atlas	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4517980	embedded system;time of flight;index term;telecommunications;computer science;information security;ultrasound;matched filter	Robotics	89.58675860130062	-36.52134663791772	156952
fc19fdda021fed19991aba99ff71e01a1607b22f	multichannel double-talk detector based on fundamental frequency estimation	microphones;multichannel double talk detection fundamental frequency estimation multichannel acoustic echo cancellation;frequency estimation decorrelation microphones echo cancellers loudspeakers indexes;teleconferencing adaptive filters decorrelation echo suppression frequency estimation loudspeakers microphones notch filters signal detection;frequency estimation;indexes;loudspeakers;multichannel double talk detector multichannel decorrelation frequency tracking adaptive second order notch filter double talk detection echo cancellation multichannel audio teleconferencing system multichannel video teleconferencing system loudspeaker microphone undesired acoustic coupling reduction multichannel acoustic echo canceller fundamental frequency estimation;decorrelation;echo cancellers	Multichannel acoustic echo cancellers aim at reducing the undesired acoustic coupling among microphones and loudspeakers in multichannel audio/video teleconferencing systems. In this scenario, double-talk refers to the situation in which there is an active speaker both in the remote room and in the local room. The detection of double-talk is one of the main issues to be faced in such systems to ensure a correct echo cancellation. Indeed, filters coefficients update has to be suppressed during double-talk in order to prevent the filter from diverging because of the presence of the local speaker. In this paper, a novel approach for double-talk detection is discussed based on the estimation of the fundamental frequency of the residual error signals through adaptive second-order notch filters. More specifically, simultaneous speaker activity in the remote and local rooms is revealed by exploiting the same frequency tracking introduced for multichannel decorrelation. Several experiments have been carried out to prove the effectiveness of the proposed approach also making comparison with other solutions of the state of the art.	acoustic coupler;acoustic cryptanalysis;coefficient;decorrelation;echo (computing);echo suppression and cancellation;estimation theory;experiment;loudspeaker;microphone;powered speakers;spectral density estimation;voice activity detection	Stefania Cecchi;Laura Romoli;Francesco Piazza	2016	IEEE Signal Processing Letters	10.1109/LSP.2015.2502761	loudspeaker;database index;computer vision;speech recognition;decorrelation;computer science	Vision	82.9198727146406	-34.91894143859227	158771
288939c329da535648bf98dd09fb80abb340b949	measurement of paint coating thickness by thermal transient method	thickness measurement paints coatings spatial resolution velocity measurement size measurement head high resolution imaging cooling image processing;time dependent;spatially resolved full frame 2 d scan;paint coating thickness measurement;image processing;paints;thermal parameters;nondestructive testing ndt;heat source;image processing system;nondestructive testing paint coating thickness measurement thermal transient method accurate laminary determination spatially resolved full frame 2 d scan inspected metallic surface quality industrial environment heat source thermal imaging system image processing system time dependent cooling behavior thermal parameters;coatings;high resolution imaging;size measurement;thickness measurement image processing infrared imaging nondestructive testing paints;accurate laminary determination;active infrared;thermal imaging;infrared imaging;thickness measurement active infrared ir thermography coating quality nondestructive testing ndt thermal imaging;field of view;thermal imaging system;surface layer;industrial environment;thermal transient method;coating quality;head;time dependent cooling behavior;metallic surface;velocity measurement;active infrared ir thermography;thickness measurement;inspected metallic surface quality;nondestructive testing;cooling;spatial resolution	This paper is concerned with the accurate laminary determination of the thickness of coatings on metallic surfaces. The development goal was to devise a system that allows for highly spatially resolved full-frame 2-D scans that conventional systems are not able to provide. Furthermore, it is able to allow for a sufficiently large physical separation between the measuring head and the inspected surface to accommodate industrial environments that provide a high operating velocity and is able to detect quality problems of square millimeter in size. The system consists of a heat source that introduces a thermal transient to the surface layer of the specimen, a thermal imaging system to acquire the time-dependent cooling behavior, and an image processing system to determine thermal parameters indicative of surface quality and/or coating thickness. The results clearly show that a thickness resolution of better than 50 mum can reliably be obtained at a scanning velocity of 0.37 m/s, covering a field of view (FOV) of approximately 200 times 140 mm2.	biological specimen;computer cooling;field of view in video games;full-frame digital slr;image processing;thickness (graph theory);velocity (software development)	Florian Maier;Bernhard G. Zagar	2009	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2008.2006125	computer vision;image resolution;field of view;surface layer;nondestructive testing;image processing;optics;head;physics	Visualization	89.33988653451901	-24.564553384894083	158874
122c3b521dcacd8728c80b09fc4b3b6a50cad760	pso-based estimation for tdoa with estimated initial values in a reverberant environment			multilateration;phase-shift oscillator	Tian-Xi Wu;Yu-Hsiang Yu;Tsung-Ying Sun	2015		10.3233/978-1-61499-522-7-31	multilateration;acoustics;speech recognition;computer science	EDA	85.30745295210498	-36.29807702758744	159066
83d64088e3e582ddefa18ecb5bc594f5d5d772fe	temperature profiling of pulverized coal flames using multicolor pyrometric and digital imaging techniques	coal-fired combustion test facility;pulverized coal;optical filtering device;pulverized coal flames;image processing;digital imaging techniques;temperature measurement;flames;charge-coupled device (ccd) camera;pyrometers;optical splitting device;temperature distribution;optical filters;cameras;imaging-based multicolor pyrometric system;charge-coupled device camera;charge-coupled devices;combustion process data;coal;multicolor pyrometry;multicolor pyrometric techniques;combustion flame;temperature profiling;charged couple device;digital image;ccd camera;high resolution	This paper presents an imaging-based multicolor pyrometric system for the monitoring of temperature and its distribution in a coal-fired flame. A novel optical splitting/filtering device is designed and used to split the light of flame into three beams at three selected wavelengths as required in the multicolor principle. A high-resolution charge-coupled device camera is employed to collect the three beams of the light of flame. The three resulting images provide the basis for the determination of temperature and its distribution in the flame field. The system is evaluated on a 0.5-MW/sub th/ coal-fired combustion test facility under various combustion conditions. Results obtained demonstrate that the system is capable of measuring the temperature and its distribution concurrently in the flame field. Quantitative relationships between the measured results and the main combustion process data are also discussed.	charge-coupled device;digital imaging;image resolution	Gang Lu;Yong Yan	2006	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2006.876393		Visualization	89.93681325816068	-24.93297964149226	159370
9c70012d1494f70237e26d1ebcd8c6b04b6c7ab6	wideband and isotropic room acoustics simulation using 2-d interpolated fdtd schemes	acoustique architecturale;modelizacion;frequency dependence;evaluation performance;interpolation;fdtd method;condiciones limites;finite difference time domain modeling;acoustic propagation;waveguide;wideband;nonstaggered grid;performance evaluation;impedancia acustica;finite difference time domain fdtd methods acoustic impedance acoustic propagation acoustic signal processing architectural acoustics digital filters;condition aux limites;reflectivity;numerical method;methode difference finie domaine temps;dependance frequence;boundary conditions;facteur reflexion;rectilinear grid;acoustics;evaluacion prestacion;interpolated wideband scheme isotropic room acoustics simulation 2d interpolated fdtd schemes finite difference time domain modeling rectilinear grid nonstaggered grid digital impedance filter formulation locally reacting surface theory;wide band;simulation;acustica sala;finite difference time domain;simulacion;architectural acoustics;acoustic signal processing;indexing terms;digital filter;time domain analysis;wideband acoustics finite difference methods time domain analysis reflectivity frequency surface impedance digital filters filtering theory boundary conditions;large bande;modelisation;finite difference time domain fdtd methods;impedance acoustique;interpolated wideband scheme;locally reacting surface theory;reflectance;metodo numerico;filtro numerico;boundary condition;guide onde;finite difference time domain analysis;digital filters;isotropic room acoustics simulation;interpolation acoustic signal processing filtering theory finite difference time domain analysis;2d interpolated fdtd schemes;acoustic impedance;banda ancha;traitement signal acoustique;surface impedance;frequency;acustica arquitectural;guia onda;modeling;room acoustics;acoustique salle;methode numerique;digital impedance filter formulation;filtering theory;finite difference methods;filtre numerique;coeficiente reflexion	In this paper, a complete method for finite-difference time-domain modeling of rooms in 2-D using compact explicit schemes is presented. A family of interpolated schemes using a rectilinear, nonstaggered grid is reviewed, and the most accurate and isotropic schemes are identified. Frequency-dependent boundaries are modeled using a digital impedance filter formulation that is consistent with locally reacting surface theory. A structurally stable and efficient boundary formulation is constructed by carefully combining the boundary condition with the interpolated scheme. An analytic prediction formula for the effective numerical reflectance is given, and a stability proof provided. The results indicate that the identified accurate and isotropic schemes are also very accurate in terms of numerical boundary reflectance, and outperform directly related methods such as Yee's scheme and the standard digital waveguide mesh. In addition, one particular scheme-referred to here as the interpolated wideband scheme-is suggested as the best scheme for most applications.	characteristic impedance;finite-difference time-domain method;interpolation;numerical analysis;regular grid;simulation	Konrad Kowalczyk;Maarten van Walstijn	2010	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2009.2023645	digital filter;acoustics;boundary value problem;calculus;mathematics;reflectivity	Visualization	87.53754674096739	-32.698818258247385	160993
59e1f18c2d3b2c7961e7d068e0c4170aee961ff2	a unified convolutional beamformer for simultaneous denoising and dereverberation		This paper proposes a method for estimating a convolutional beamformer that can perform denoising and dereverberation simultaneously in an optimal way. The application of dereverberation based on weighted prediction error (WPE) followed by denoising based on a minimum variance distortionless response beamformer (MVDR) has conventionally been considered a promising approach, however, the optimality of this approach is not guaranteed. To realize the optimal integration of denoising and dereverberation, we present a method that unifies WPE and a variant of MVDR, namely a minimum power distortionless response beamformer (MPDR), into a single convolutional beamformer, and we optimize it based on a single unified optimization criterion. The proposed beamformer is referred to as a Weighted Power minimization Distortionless response beamformer (WPD). Experiments show that the proposed method substantially improves the speech enhancement performance in terms of both objective speech enhancement measures and automatic speech recognition (ASR).		Tomohiro Nakatani;Keisuke Kinoshita	2018	CoRR			AI	84.02831682181841	-34.82002462962587	161426
42d3f7541f85d9cc60df6b20f356ef66a2547206	blind deconvolution of ultrasonic signals in nondestructive testing applications	traitement signal;ensayo no destructivo;signal estimation;detection signal;blind deconvolution;ultrason;essai non destructif;ultrasound;ultrasonic materials testing;signal detection;ultrasonic wave;indexing terms;ultrasonic transducers;desconvolucion;acoustic convolution ultrasonic materials testing ultrasonic transducers deconvolution;deteccion senal;acoustic convolution;ultrasonido;non destructive test;signal processing;estimacion senal;deconvolution nondestructive testing optical materials materials testing laser noise surface waves surface emitting lasers ultrasonic transducers ultrasonic imaging convolution;deconvolution;signal acoustique;acoustic signal;procesamiento senal;estimation signal;senal acustica;nondestructive testing;signal estimation ultrasonic signals nondestructive testing applications laser ultrasonic wave generation test material surface air coupled transducer convolution blind deconvolution distortion function	Advanced nondestructive testing techniques use a laser to generate ultrasonic waves at the surface of a test material. An air-coupled transducer receives the ultrasound that is the convolution of the signal leaving the test material and the distortion function. Blind deconvolution methods are applied to estimate the signal leaving the material.	blind deconvolution;convolution;distortion;transducer	Asoke K. Nandi;Detlef M√§mpel;Burkhard Roscher	1997	IEEE Trans. Signal Processing	10.1109/78.575716	nondestructive testing;computer science;signal processing;ultrasonic testing	Visualization	87.4207163709015	-36.744520959483445	161660
16a1500b3b20311709cc19f233ef66d8ffd3f044	energy demodulation of two-component am-fm signals with application to speaker separation	mixture signal;demodulation frequency estimation amplitude estimation application software differential equations communication channels speech processing linear systems yield estimation power engineering and energy;linear systems;signal processing demodulation frequency modulation amplitude modulation speech processing computational complexity differential equations mathematical operators;frequency modulation;application software;voice modulated fm signals;speech processing;differential equation;frequency estimation;amplitude modulation;low complexity;energy demodulation;speaker separation;yield estimation;mathematical operators;power engineering and energy;nonlinear differential energy operators energy demodulation two component am fm signals speaker separation efficient low complexity algorithm voice modulated fm signals differential equation mixture signal;demodulation;computational complexity;nonlinear differential energy operators;efficient low complexity algorithm;signal processing;amplitude estimation;differential equations;communication channels;two component am fm signals	In this paper, an efficient low-complexity algorithm is presented for the separation and demodulation of two-component AM-FM signals and applied to the separation of voice-modulated FM signals. The proposed algorithm is based on the generating differential equation of the mixture signal and nonlinear differential energy operators.	am broadcasting;fm broadcasting	Balasubramaniam Santhanam;Petros Maragos	1996		10.1109/ICASSP.1996.550787	speech recognition;telecommunications;computer science;signal processing;speech processing;mathematics;blind signal separation;differential equation	AI	83.19798540649988	-30.87436279099528	162727
17642f943f8dcb4d0ce27aa937cc5af86c88dec7	direction of arrival estimation in reverberant rooms using a resource-constrained wireless sensor network	wideband;wireless sensor networks acoustic signal processing direction of arrival estimation speech processing transforms;surveillance;speech processing;doa estimation;speech;direction of arrival;wsn;acoustic signal processing;direction of arrival estimation wireless sensor networks phase estimation acoustic applications buildings surveillance monitoring wideband speech portable computers;wireless sensor network;steered response power phase transform algorithm direction of arrival estimation reverberant room resource constrained wireless sensor network wsn acoustic source wideband speech signal;reverberant room;monitoring;design and implementation;portable computers;phase estimation;wideband speech signal;phase transformation;transforms;acoustic source;success rate;wireless sensor networks;buildings;steered response power phase transform algorithm;smart environment;resource constrained wireless sensor network;direction of arrival estimation;acoustic applications	A WSN capable of estimating the direction of arrival (DOA) of an acoustic source can be utilized in building surveillance, habitat monitoring or smart environment applications. In this paper, we discuss the design and implementation of a WSN that can provide an accurate DOA estimate of a single acoustic source placed in a moderately reverberant room by using only four strictly resource-constrained Berkeley Mica2 motes. We provide experimental results on the performance of our WSN in estimating the DOA of a wideband speech signal placed at different positions in the room. Using the Steered-Response-Power Phase-Transform (SRP-PHAT) algorithm along with an additional refining stage, our WSN can successfully estimate the source DOA at an 89% average success rate when the RMS DOA error margin allowed on the estimates is set to 5deg. Our results show that DOA estimation can be achieved using wireless platforms that are not as powerful as iPAQs or laptops, which were the platforms previously employed in the literature for similar purposes.	acoustic cryptanalysis;algorithm;direction of arrival;elegant degradation;habitat;laptop;modal logic;multithreading (computer architecture);network packet;real-time clock;relevance;reliability engineering;sampling (signal processing);sensor;smart environment;speech processing;thread (computing)	Murat Arabaci;Robin N. Strickland	2007	IEEE International Conference on Pervasive Services	10.1109/PERSER.2007.4283886	electronic engineering;speech recognition;wireless sensor network;acoustics;computer science;engineering;speech processing	Mobile	85.28966128245062	-35.32018152497501	163174
9d2d27c099ed2124e72e1dfce56d7fe86354b5a8	assessment of random and systematic errors in millimeter-wave dielectric measurement using open resonator and fourier transform spectroscopy systems	systematic error;ceramics;measurement system;permittivity measurement;polymers millimetre wave measurement measurement errors dielectric loss measurement fourier transform spectroscopy dielectric resonators permittivity measurement ceramics;dielectric resonators;dielectric loss measurement;millimeter wave measurements dielectric measurements fourier transforms electrochemical impedance spectroscopy frequency measurement length measurement millimeter wave technology permittivity measurement discrete fourier transforms dielectric loss measurement;millimetre wave measurement;60 ghz random errors assessment systematic errors assessment millimeter wave dielectric measurement open resonator permittivity loss tangent ceramics polymers measurement systems frequency variation techniques dispersive fourier transform spectroscopy system cavity length variation technique;millimeter wave;polymers;fourier transform spectroscopy;measurement errors	Assessment of random and systematic errors is performed for the first time on the real part of permittivity (/spl epsiv/') and loss tangent (tan/spl delta/) of ceramics and polymers using two different measurement systems. Data measured from the full cavity length and the frequency variation techniques using the 60 GHz open resonator system and the millimeter-wave dispersive Fourier transform spectroscopy system (DFTS) are compared and analyzed. Data measured by the frequency variation technique were seen to be more accurate than those measured by the full cavity length variation technique with lower random errors for the specimens measured. The /spl epsiv/' of the specimens measured by the frequency variation technique followed closely with those measured by the millimeter-wave DFTS system with a slight difference of about 0.02%. Finally, for all the specimens measured in this paper, the DFTS system was seen to provide much better accuracy for /spl epsiv/' values. The frequency variation technique from the open resonator system generated the best tan/spl delta/.	dispersive partial differential equation;os-tan;resonance;sampling (signal processing);system of measurement	Mohammed N. Afsar;Anusha Moonshiram;Yong Wang	2004	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2004.831145	ceramic;electronic engineering;systematic error;system of measurement;fourier transform spectroscopy;extremely high frequency;optics;physics;statistics;observational error	Visualization	91.13760935216726	-24.809424215044007	163231
422fba7996391b4335f3341e6a7a9e7ac9a6c8c1	an adaptive filtering method to calculate hrtf	adaptive filters transfer functions loudspeakers frequency filtering ear art;crosstalk adaptive filters adaptive signal processing transfer functions acoustic signal processing loudspeakers acoustic intensity;crosstalk;transfer functions;acoustic signal processing;adaptive filters;head related transfer function;adaptive signal processing;loudspeakers;acoustic intensity;filtered x method adaptive filtering method hrtf virtual 3d sound technology acoustic environment directional impression head related transfer function loudspeakers sound pressure field cross talk;adaptive filter	The objective of virtual 3D sound technology is to convey to the listener an accurate impression of an acoustic environment. This is accomplished by conveying a realistic directional impression of sounds. Most of the successful techniques for doing this are based on the head related transfer function (HRTF). If loudspeakers are used to create the desired sound pressure field, then the cross talk associated with them will need to be compensated for. We present a method that can be used to calculate the required HRTFs using an adaptive filtering method based on the filtered X method of Widrow (1985).	adaptive filter;head-related transfer function	John W. Norris	1998		10.1109/MMSP.1998.738927	adaptive filter;computer vision;speech recognition;computer science;directional sound	Vision	85.9469944365353	-33.94128285382326	163328
453015a80c897aa1e37ec02a6bfd4e1343f5a4d7	detection of overlapping speech in meeting recordings using the modified exponential fitting test	eigenvalues and eigenfunctions;reverberation;speech recognition eigenvalues and eigenfunctions estimation theory frequency domain analysis matrix algebra;reverberation overlapping speech detection meeting recordings speech recognition techniques source number estimation techniques ordered profile spatial correlation matrix eigenvalues exponential fitting test eft frequency domain implementation broadband speech signals correction factor;speech;fitting;eigenvalues and eigenfunctions speech noise reverberation fitting correlation;correlation;noise	Detection of overlapping speech in meeting recordings is a challenging problem due to both the nature of the conversation itself and the surrounding environment. Accurate identification of these sections of the recording is a crucial first step for speech recognition techniques as their non-detection leads to severe degradation in performance. A possible approach to solving this problem is the use of source number estimation techniques based on the ordered profile of the spatial correlation matrix eigenvalues. In this paper we propose two approaches for detecting overlapping speech based on the Exponential Fitting Test (EFT) a source number estimation technique proposed in [1]. Firstly we propose a frequency domain implementation of the EFT, which is more appropriate when dealing with the broadband speech signals encountered in meetings. We then propose a second approach in which a correction factor is added to allow for the presence of reverberation. The performances of the proposed schemes are evaluated and compared to that of the original EFT using real meeting recordings.	curve fitting;electronic funds transfer;elegant degradation;performance;sensor;speech recognition;time complexity;turing test	Angela Quinlan;Futoshi Asano	2007	2007 15th European Signal Processing Conference		electronic engineering;speech recognition;acoustics;computer science	NLP	83.82396004002406	-35.98914690347365	163352
5ad5b05845921ff8bc50e4e2e4fb59acf2bbd1e4	a robust null-steering beamformer for acoustic feedback cancellation for a multi-microphone earpiece		To reduce acoustic feedback in hearing aids, adaptive filters are commonly used to estimate the feedback contribution in the microphone(s). While theoretically allowing for perfect feedback cancellation, in practice the solution is typically biased due to the closed-loop acoustical system. For an earpiece with multiple integrated microphones and loudspeakers, we propose to use a fixed beamformer to cancel the acoustic feedback. By steering a spatial null in the direction of the hearing aid loudspeaker we show that theoretically perfect feedback cancellation can be achieved. To increase the robustness, the null-steering beamformer is computed based on multiple measured acoustic feedback paths. Experimental results using an earpiece with two microphones in the vent and a third microphone in the concha show that the proposed robust null-steering beamformer substantially and robustly increases the added stable gain while maintaining a high perceptual quality.	asg software solutions;adaptive filter;audio feedback;beamforming;coefficient;least squares;loudspeaker;mathematical optimization;mega man zx;microphone;optimization problem;zero-forcing precoding	Henning F. Schepker;Linh Thi Thuc Tran;Sven Nordholm;Simon Doclo	2016			robustness (computer science);loudspeaker;audio feedback;microphone;acoustics;hearing aid;adaptive filter;computer science	Mobile	84.5704174776487	-34.05014222946635	164071
9734f9ffdafeb761fbdb003fbc89ff92c334a5bc	design and simulation of a green bi-variable mono-parametric shm node and early seismic warning algorithm for wave identification and scattering		Early seismic warning systems are key for safe future scalable infrastructures. In this work, a dual variable i.e. vibration and line of sight (LOS) based structure health monitoring (SHM) node is designed to sense tilt angle for early seismic warning and wave scattering detection. The SHM node, consisting of high-precision five bi-axis tiltmeters and five Blue-Violet laser diodes transmitter/receiver/reflector(LDTRR) assembly, has been designed and simulated in Proteus 7ISIS, MATLAB 7 and drafted in AutoCAD. In AutoCAD, a four LDTRR assembly is oriented at the bottom of building and its four co-planer reflectors have been orthogonally placed at effective radii with respect to the characteristic wavelengths of P, S, and Rayleigh whilst Love seismic waves, and one reflector is placed at the bottom of building. PV umbrella with a Li-ion battery has been used for green ergonomic shape. The time plots from real tiltmeter sensor nodes and data acquired from the proposed SHM node show similar behavior and results. The derived parameters of wavelength S, i.e. seismic parameter F,varied linearly from safe to hazardous seismic conditions. The variation from safe seismic to hazardous seismic transition of randomly simulated environment, also varied network traffic in GPS module as per defined threshold of sensor variables in Proteus ISIS Electronics Design Automation (EDA) engine. As per early warning evaluation functions (EWEF), the proposed design for early seismic warning algorithm (ESWA) can be a cost-effective analytics resource for any scalable SHM solution for observation range within 5km+ radius at low cost and 20km at moderate/high cost.	algorithm;autocad;computer-aided design;diode;displacement mapping;electronic design automation;embedded system;global positioning system;human factors and ergonomics;isis;matlab;network traffic control;optic axis of a crystal;parametric oscillator;proteus;randomness;rayleigh‚Äìritz method;scalability;seismic analysis;simulation;super high material cd;transmitter;velocity (software development);virtual reality;while	Farid Touati;Hasan Tariq;Damiano Crescini;Adel Ben Manouer	2018	2018 14th International Wireless Communications & Mobile Computing Conference (IWCMC)	10.1109/IWCMC.2018.8450277	electronics;seismic wave;transmitter;algorithm;tiltmeter;wavelength;semiconductor laser theory;computer science;warning system;vibration	Robotics	89.28640332225656	-27.79398575807604	164140
2a45c28515dd65bc68c367decb2540859261c2ab	sequence clean-based source csdm retrieval algorithm for multiple targets at nonlinear mfp	sequence clean;tecnologia electronica telecomunicaciones;mfp;tecnologias;grupo a;mvdr	This paper proposes a method for estimating the number and locations of multiple targets distributed in the ocean. This is achieved by calculating the cross spectral density matrix (CSDM) generated from individual sound sources and applying them to a minimum variance distortionless response (MVDR), a nonlinear processor. The individual CSDMs are calculated by separating and extracting a Sequence CLEAN-based data vector from the CSDM of the data vector received from multiple targets. Numerical simulations demonstrate that the proposed method improves the MVDR performance in the case of multiple targets.	algorithm;clean	Hyeong-Uk Lee;Tae-Gyun Lim;Chan-Sik Hwang	2005	IEICE Transactions	10.1093/ietfec/e88-a.7.1767	real-time computing;speech recognition;telecommunications	Vision	84.66326498096343	-36.065910668058365	164398
9525857eea33a7c6688574166b9822c9429be92a	source analysis and separation using spatial filtering and time frequency distribution in array signal processing under complicated environments	array processing;time frequency analysis array signal processing source separation spatial filters;source analysis;time frequency;array signal processing;spatial filters;signal extraction source analysis source separation time frequency distribution array signal processing time frequency domain tfd;arrays time frequency analysis direction of arrival estimation filtering array signal processing vectors;spatial filtering;time frequency distribution source analysis source separation spatial filtering;source separation;time frequency analysis;time frequency distribution	The paper proposes a method to analyze the sources. Under complicated environments, for example, there are different types of sources existing in the far field or more than one source in the same direction, common array processing methods do not consider these situations. But they will bring difficulty when we want to acquire the characteristics of these sources. Some sources may be indistinguishable in space, but they may be distinguishable in time-frequency domain, which we can use while analyzing the sources. The paper adopts spatial filtering and time frequency distribution (TFD) to deal with these situations. Spatial filtering can keep the sources in a particular direction from being interrupted by sources in other directions and extract the original signals in that direction, while TFD is used to analyze the extracted signals in time-frequency domain to get some information of signals of the sources, such as the frequency range. Simulation results prove the effectiveness of the method.	signal processing	Wenyan Liu;Xiaotao Huang;Tong Jin	2011		10.1109/WCSP.2011.6096787	electronic engineering;speech recognition;telecommunications;computer science;sensor array	HPC	84.50683515273579	-38.2542848511602	164805
0f1b61ab895c9b31271b493024b3c70c320d45c9	head related transfer function representation of directional sound for spatial acoustic events modeling	sub band analysis synthesis;3d sounds;transfer functions ear audio systems signal synthesis interpolation convolution estimation error signal generators multimedia systems teleconferencing;directional sound;audio systems;signal generators;teleconferencing;interpolation;audio signal processing;immersive audio systems;transfer functions;convolution;acoustic signal processing;multimedia systems;estimation errors;sound arrival directions;head related transfer function;ear;signal representation;sub band analysis synthesis head related transfer function representation directional sound spatial acoustic events modeling 3d sounds immersive audio systems sound arrival directions hrtf data estimation errors signal to deviation ratio horizontal plane;hrtf data;signal synthesis;estimation error;horizontal plane;individual difference;signal representation audio signal processing acoustic signal processing;head related transfer function representation;signal to deviation ratio;spatial acoustic events modeling	This article describes the representation of spatial sound using a limited number of HRTFs. The HRTFs are significant functions for generating 3D sounds for immersive audio systems. The HRTFs, however, are not only functions of sound arrival directions but are also variable due to listeners' individual differences. Thus generation of the individual HRTFs using a few HRTF data records is desired. This report investigates a possibility in generating HRTFs for an individual subject from a database and a limited number of measured individual HRTFs. The estimation errors which are observed in the generated HRTFs can be evaluated by the signal to deviation ratio (SDR). A present example using 4 subjects' HRTFs shows that individual HRTFs in the horizontal plane can be synthesised with SDR greater than about 6 dB. Sub-band analysis/synthesis for the HRTFs is under study.	acoustic cryptanalysis;function representation;head-related transfer function	Mikio Toyama;Michiki Uchiyama;Hiroaki Nomura	1999		10.1109/MMSP.1999.793824	speech recognition;teleconference;audio signal processing;interpolation;computer science;horizontal plane;directional sound;head-related transfer function;transfer function;convolution;signal generator	HCI	86.53969382578684	-33.00896403551341	165067
8ed31ca4f094fa1995d62f23b43681af6e49c3a7	reduction of nonstationary acoustic noise in speech using lms adaptive noise cancelling	microphones;lms algorithm;transfer functions;working environment noise;least squares approximation;noise suppression;speech enhancement;signal noise ratio;adaptive filters;transfer function;acoustic noise;noise reduction;noise cancellation;adaptive noise canceller;signal to noise ratio;acoustic noise speech enhancement least squares approximation noise cancellation noise reduction microphones working environment noise adaptive filters transfer functions signal to noise ratio	Nonstationary acoustic noise with energy possibly equal to or greater than the speech is suppressed using a two microphone implementation of adaptive noise cancellation. The primary noise added to the speech is reduced by subtracting a filtered version of the second microphone reference noise. The reference noise filter is adaptively up dated using the Widrow-Hoff LMS algorithm [1]. The effectiveness of noise suppression depends directly on the ability of the filter to estimate the transfer function relating the primary and reference noise channels. A study of the filter length required to achieve a desired noise reduction level in a hard-walled room is presented. Results demonstrating noise reduction in excess 10dB in an environment with 0dB signal noise ratio are presented.	acoustic cryptanalysis	Dennis Pulsipher;Steven F. Boll;Craig K. Rushforth;LaMar Timothy	1979		10.1109/ICASSP.1979.1170761	gradient noise;gaussian noise;effective input noise temperature;noise spectral density;computer vision;noise;speech recognition;colors of noise;value noise;noise-canceling microphone;noise temperature;computer science;noise measurement;noise;transfer function;noise figure;noise floor;signal-to-noise ratio;noise;salt-and-pepper noise	NLP	83.72103489398287	-33.674059628001736	165795
cafacefd27112a8aa5486dc9373aa9e3c4de23dd	the effects of ambient sounds on the quality of 3d virtual sound space	immersive sound space;realistic telecommunication interaction;human computer interaction;virtual auditory display system;virtual reality acoustic signal processing auditory displays human computer interaction rendering computer graphics sound reproduction;ventilation system sound;magnetic heads;virtual reality;virtual reality technique;vad system;acoustic signal processing;sound reproduction;auditory displays;noise measurement;virtual auditory display system ambient sound 3d virtual sound space quality immersive sound space virtual reality technique realistic telecommunication interaction ventilation system sound sound direction reproduction optimum rendering algorithm vad system;ambient sound;3d virtual sound space quality;generic point;virtual auditory display;optimum rendering algorithm;head;acoustic noise 1f noise background noise frequency virtual reality auditory displays magnetic heads ear libraries noise figure;rendering computer graphics;sound direction reproduction;noise	Immersive sound spaces which are synthesized using virtual reality techniques have recently been developed to realize highly realistic telecommunication interactions. In real world soundscapes the sounds we usually listen to include background or ‚Äúambient‚Äù sounds such as the sounds of the ventilation system in a room. However, current virtual auditory display systems generate point sound sources which are often attributed to specific object locations. Therefore, it is possible to reproduce sound direction, but no information about the sound space is included. As a result, the sound output is often dry and unnatural. In this research, a rendering method for ambient sounds and its effects are investigated. An optimum rendering algorithm of ambient sounds is proposed and its effects on the quality of sound space are examined.	algorithm;auditory display;interaction;rendering (computer graphics);virtual reality	Satoshi Yairi;Yukio Iwaya;Maori Kobayashi;Makoto Otani;Y√¥iti Suzuki;Takeru Chiba	2009	2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIH-MSP.2009.267	speech recognition;ambient noise level;computer science;noise measurement;noise;sound masking;generic point;virtual reality;head	Visualization	86.11066943251552	-33.744213005699855	166760
193ff255ec1315de6ef465ddcc0c4ce3f5cd3346	on the potential for artificial bandwidth extension of bone and tissue conducted speech: a mutual information study	microphones;inear microphone mutual information gaussian mixture models bandwidth extension bone conducted speech;speech;frequency 2 khz artificial bandwidth extension tissue conducted speech bone conducted speech hearing protection devices noisy environments radio communication speech capture microphone signal occluded ear canal signal to noise ratio mutual information gaussian mixture model speech signal;bones;speech mutual information bandwidth microphones signal to noise ratio bones;bandwidth;mutual information;signal to noise ratio;speech processing bandwidth allocation bone ear gaussian processes hearing microphones mixture models speech intelligibility	To enhance the communication experience of workers equipped with hearing protection devices and radio communication in noisy environments, alternative methods of speech capture have been utilized. One such approach uses speech captured by a microphone in an occluded ear canal. Although high in signal-to-noise ratio, bone and tissue conducted speech has a limited bandwidth with a high frequency roll-off at 2 kHz. In this paper, the potential of using various bandwidth extension techniques is investigated by studying the mutual information between the signals of three uniquely placed microphones: inside an occluded ear, outside the ear and in front of the mouth. Using a Gaussian mixture model approach, the mutual information of the low and high-band frequency ranges of the three microphone signals at varied levels of signal-tonoise ratio is measured. Results show that a speech signal with extended bandwidth and high signal-to-noise ratio may be achieved using the available microphone signals.	bandwidth extension;microphone;mixture model;mutual information;roll-off;signal-to-noise ratio;speech synthesis	Rachel E. Bouserhal;Tiago H. Falk;J√©r√©mie Voix	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7178944	voice activity detection;speech recognition;speech;speech processing;mathematics;mutual information;signal-to-noise ratio;bandwidth;statistics	Robotics	84.73512320399857	-35.24467925494743	167372
a5d221b433d3e4218245330c4964766967d4055d	on the non-uniqueness problem and the semi-blind source separation	semi blind source separation blind source separation multi channel acoustic echo cancellation;microphones;echo reduction;multi channel acoustic echo cancellation;mixing condition;blind source separation;frequency domain analysis;acoustics;far end mixing conditions;independent component analysis;data mining;time domain analysis;semi blind source separation;batch wise adaptation;echo reduction non uniqueness problem semi blind source separation batch wise adaptation independent component analysis source separation multichannel acoustic echo cancellation far end reference signals batch online adaptation algorithm far end mixing conditions de mixing matrix;adaptive algorithm;independent component analysis blind source separation echo suppression;batch online adaptation algorithm;echo suppression;multichannel acoustic echo cancellation;decorrelation;far end reference signals;frequency domain;source separation;source separation independent component analysis echo cancellers frequency domain analysis microphones frequency response signal processing decorrelation blind source separation filters;acoustic echo canceller;non uniqueness problem;de mixing matrix	Semi-blind source separation (SBSS) is a special case of the well-known source separation problem when some partial knowledge of the source signals is available to the system. In particular, a batch-wise adaptation in the frequency domain based on the independent component analysis (ICA) can be effectively used to jointly perform source separation and multi-channel acoustic echo cancellation (MCAEC) without double-talk detection. However, the non-uniqueness problem due to the correlated far-end reference signals still affects the SBSS approach. In this paper, we analyze the structure of the SBSS de-mixing matrix and the behavior of a batch on-line adaptation algorithm under two most common far-end mixing conditions. We show that with a proper constraint on the de-mixing matrix, high echo reduction can be achieved just as the misalignment remains relatively low even for the worst-case scenario of single far-end talker and also without any pre-processing procedure to decorrelate the far-end signals.	acoustic cryptanalysis;algorithm;blind signal separation;echo suppression and cancellation;independent computing architecture;independent component analysis;online and offline;preprocessor;semiconductor industry;source separation;whole earth 'lectronic link;worst-case scenario	Francesco Nesta;Ted S. Wada;Shigeki Miyabe;Biing-Hwang Juang	2009	2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics	10.1109/ASPAA.2009.5346539	speech recognition;acoustics;computer science;machine learning;blind signal separation;frequency domain	ML	83.16154785113102	-35.57011524362839	167581
0dde9b7b1e3aab2dcef6456dde1d2237fbbdc575	parametric wave field coding for precomputed sound propagation	reverberation time;occlusion;diffraction;convolution;scattering;exclusion;environmental effects;wave equation;obstruction;early decay time;parametric reverb;impulse response;room acoustics;dsp	The acoustic wave field in a complex scene is a chaotic 7D function of time and the positions of source and listener, making it difficult to compress and interpolate. This hampers precomputed approaches which tabulate impulse responses (IRs) to allow immersive, real-time sound propagation in static scenes. We code the field of time-varying IRs in terms of a few perceptual parameters derived from the IR's energy decay. The resulting parameter fields are spatially smooth and compressed using a lossless scheme similar to PNG. We show that this encoding removes two of the seven dimensions, making it possible to handle large scenes such as entire game maps within 100MB of memory. Run-time decoding is fast, taking 100Œºs per source. We introduce an efficient and scalable method for convolutionally rendering acoustic parameters that generates artifact-free audio even for fast motion and sudden changes in reverberance. We demonstrate convincing spatially-varying effects in complex scenes including occlusion/obstruction and reverberation, in our system integrated with Unreal Engine 3‚Ñ¢.	acoustic cryptanalysis;acoustic fingerprint;interpolation;lossless compression;megabyte;portable network graphics;precomputation;real-time clock;robertson‚Äìseymour theorem;scalability;software propagation;unreal development kit	Nikunj Raghuvanshi;John Snyder	2014	ACM Trans. Graph.	10.1145/2601097.2601184	computer vision;wave equation;speech recognition;social exclusion;acoustics;impulse response;room acoustics;digital signal processing;convolution;optics;diffraction;scattering;quantum mechanics;computer graphics (images)	Graphics	87.63524468484889	-33.74339635342251	167716
0ea3cb833a4a758a25a69ae387895ac2694e1a69	narrowband detection in ocean with impulsive noise using an acoustic vector sensor array	generalized likelihood ratio test	This paper presents the formulation and analysis of some methods for narrowband detection of underwater acoustic sources in impulsive noise using an array of acoustic vector sensors. Since the array signal vector is unknown due to the unknown location of the source, detection is based on the generalized likelihood ratio test which involves estimation of the signal vector. Different detectors use different signal models which yield different signal estimators. It is shown that the truncated subspace detector (TSD), which uses a truncated normal mode model, yields the best performance.	acoustic cryptanalysis;approximation algorithm;mean squared error;modal logic;monte carlo method;normal mode;portable document format;sensor;signal-to-noise ratio;simulation;tsd;viz: the computer game	V. N. Hari;G. V. Anand;P. V. Nagesha;A. Benjamin Premkumar	2012	2012 Proceedings of the 20th European Signal Processing Conference (EUSIPCO)		electronic engineering;speech recognition;acoustics;sensor array;physics	Robotics	86.01577610391666	-37.39059981641973	167956
29108cd1f28e3dd89de6115619896a7f21df8f9e	a digital filter bank for spectral matching	background noise;microphones;digital filters filter bank speech processing pattern matching channel bank filters frequency bandwidth loudspeakers microphones background noise;filter bank;speech processing;time window;digital filter;loudspeakers;channel bank filters;pattern matching;digital filters;distance metric;bandwidth;frequency	A new digital filter bank design is proposed for the processing of speech waveforms where spectral pattern matching techniques are applicable. Outputs in decibels from the 30 channels of the filter bank are computed every 12 ms. Care has been taken to select a time window and filter center frequency and bandwidth values that take into account the acoustic characteristics of speech. A distance metric is proposed for comparing a spectral frame with previously derived reference patterns. The metric incorporates procedures for crude speaker/microphone normalization, signal level normalization, background noise normalization, and procedures for emphasizing differences in the region of spectral peaks.	digital filter;filter bank	Dennis H. Klatt	1976		10.1109/ICASSP.1976.1170107	adaptive filter;speech recognition;digital filter;low-pass filter;computer science;root-raised-cosine filter;filter bank;speech processing;band-stop filter;filter design;prototype filter;high-pass filter;half-band filter;m-derived filter	Vision	83.12110756216444	-33.47821160591889	168152
73b6d44fec1aac1afd76946504d3abcf2334f7e4	compensation of the differential floating capacitance between dual microelectrodes	diaphonie;microelectrodes;common mode rejection rate;stray capacitance;compensacion;tasa rechazo modo comun;differential mode compensation dual microelectrodes differential floating capacitance compensation circuit biological signal recording stray capacitance crosstalk simulation common mode compensation;bioelectric potentials;senior citizens;common mode compensation;crosstalk;legged locomotion;membrane potentials;capacite flottante;etude experimentale;taux rejection mode commun;hip;foot;models biological;differential capacity;differential amplifiers;amplificateur differentiel;electric impedance;capacite differentielle;amplificador diferencial;glass;differential mode compensation;biological signal recording;microelectrodo;kinetic theory;electric circuit;diafonia;compensation;differential amplifier;medical signal processing microelectrodes biomedical electrodes compensation crosstalk capacitance differential amplifiers bioelectric potentials;tecnica;humans;capacitance;biomedical electrodes;compensation circuit;circuit electrique;electric conductivity;capacitance microelectrodes foot humans pathology senior citizens hip crosstalk legged locomotion kinetic theory;electric conductivity electric impedance glass membrane potentials microelectrodes models biological;differential floating capacitance;estudio experimental;pathology;capacidad diferencial;medical signal processing;crosstalk simulation;technique;dual microelectrodes;microelectrode;circuito electrico	A circuit for compensating the floating differential capacitance appearing between two recording microelectrodes is presented. It is shown how this floating capacitance can be neutralized so that current in any microelectrode can be injected without any significant crosstalk picked up by the other.	choose (action);crosstalk;differential capacitance;dual;electric capacitance;microelectrodes	Simon Gagn√©;Udaya S. Ganguly;Sylvain Comtois	2000	IEEE Transactions on Biomedical Engineering	10.1109/10.828155	control engineering;electronic engineering;neuroscience;microelectrode;engineering;electrical engineering;physics;quantum mechanics	Visualization	93.20442908629498	-25.453073951396593	168711
255df037ac4e43d916c9d784aea08162a31a0ca4	doa estimation for a multi-frequency signal using widely-spaced sensors	conference publication;speech processing;cross power spectrum cps;signal processing delay estimation direction of arrival estimation phase estimation sensors;speech;direction of arrival;receivers;estimation;direction of arrival estimation estimation receivers signal to noise ratio speech speech processing;signal to noise ratio;direction of arrival estimation;bandpass signal doa estimation multifrequency signal widely spaced sensor subsample time delay estimation cross power spectrum cps unwrapped phase estimation phase unwrapping method direction of arrival estimation;phase unwrapping	The estimation of sub-sample time-delay from the phase of the cross-power spectrum (CPS) of signals received by widely-spaced receivers requires unwrapped phase. Conventional phase unwrapping methods require a continuous CPS that starts at zero frequency or at a frequency with a known unwrapped phase. A novel phase unwrapping method is proposed herein that is capable of carrying out the task without these requirements. The proposed method is applied to direction-of-arrival (DOA) estimation for a bandpass signal - a case that conventional methods are unable to handle. Analytical performance and experimental results confirm the effectiveness of the proposed method.	direction of arrival;instantaneous phase;kernel density estimation;requirement;sampling (signal processing);sensor;spectral density	Tarig Ballal;Chris J. Bleakley	2010	2010 18th European Signal Processing Conference		electronic engineering;speech recognition;telecommunications;engineering	EDA	84.40735900707828	-37.91242820154732	169413
8ded151db989dcb6d193d8d21cd60e6cc833c3c3	acoustic vector-sensor beamforming in the presence of flow noise	cross correlation;acoustics;acoustic modeling;linear array;doa estimation;direction of arrival;acoustic signal processing;array signal processing;pressure sensor;left right;spatial correlation;estimation;sensor array;direction of arrival estimation acoustic signal processing acoustic transducers array signal processing;correlation;noise sensor arrays array signal processing correlation acoustics estimation;sensor arrays;acoustic transducers;direction of arrival estimation;noise;covariance matrix;numerical simulation	Passive sonar arrays are often used to find submerged vessels by measuring their radiated signal. Acoustic vector-sensor (AVS) arrays, which are normally towed by the ship at the ends of long cables, have been proven to be very effective for target direction of arrival (DOA) estimation. The flow noise, arising from the flow of water over the vector-sensor or its housing when the array is towed, is often a major source of interference to the towed array as it is usually directly coupled to the array sensing elements. In this paper, we obtain a closed-form expression for the spatial correlations of all the components of an AVS array in a flow-noise field. We apply the noise correlation model to DOA estimation using a uniform linear AVS array beamforming. The flow-noise impact on the beamforming capabilities is evaluated via numerical simulations.	acoustic cryptanalysis;acoustic fingerprint;beamforming;direction of arrival;interference (communication);numerical analysis;sonar (symantec);sensor;simulation;towed array sonar	Nan Zou;Ing Nam Goh;Arye Nehorai	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5947030	computer simulation;covariance matrix;estimation;spatial correlation;speech recognition;noise;cross-correlation;pressure sensor;mathematics;beamforming;direction of arrival;correlation;sensor array;statistics	EDA	86.29375219637836	-37.52046310664093	170317
010b6e32f7c5841568dbe61a08c76d7d73187349	super-resolution time delay estimation in multipath environments	sinusoidal parameter estimation problem;super resolution time delay estimation;mean square errors;multiple signal classification algorithm;conference_paper;signal to noise ratios;time delay estimation;delay effects delay estimation signal resolution multiple signal classification signal processing algorithms discrete fourier transforms data models parameter estimation classification algorithms mean square error methods;delay effects;multipath environments;indexing terms;active system;sequential quadratic programming;multiple signal classification;signal resolution delay estimation multipath channels signal classification mean square error methods;mean square error;music algorithm;signal classification;classification algorithms;signal to noise ratios super resolution time delay estimation multipath environments active system passive systems sinusoidal parameter estimation problem multiple signal classification algorithm cramer rao bound mean square errors;mean square error methods;signal resolution;super resolution;passive systems;eigenanalysis;multipath channels;parameter estimation;cramer rao bound;signal to noise ratio;signal processing algorithms;discrete fourier transforms;muitipath environments;article;delay estimation;data models	The problem of super-resolution time delay estimation in multipath environments is addressed in this paper. Two cases, active and passive systems, are considered. The time delay estimation is first converted into a sinusoidal parameter estimation problem. Then the sinusoidal parameters are estimated by generalizing the multiple signal classification (MUSIC) algorithm for single-experiment data. The proposed method, referred to as the MUSIC-type algorithm, approximates the Cramer-Rao bound (CRB) in terms of the mean square errors (MSKs) for different signal-to-noise ratios (SNRs) and separations of multipath components. Simulation results show that the MUSIC-type algorithm performs better than the classical correlation approach and the conventional MUSIC method for the closely spaced components in multipath environments.	algorithm;broadcast delay;estimation theory;music (algorithm);mean squared error;multipath propagation;multiplicative noise;signal-to-noise ratio;simulation;super-resolution imaging;time complexity	Feng-Xiang Ge;Dongxu Shen;Yingning Peng;Victor O. K. Li	2004	2004 IEEE Wireless Communications and Networking Conference (IEEE Cat. No.04TH8733)	10.1109/WCNC.2004.1311345	speech recognition;computer science;multiple signal classification;delay spread;sequential quadratic programming;statistics	Visualization	83.18116468717385	-35.77751293750533	170832
6d0077d6e779ac5c590653697c88f56be1de2657	spatial multizone soundfield reproduction	cylindrical harmonic expansions;cylindrical harmonic expansions spatial multizone soundfield reproduction angular window functions;multizone;probability density function;acoustics;speech processing;electroacoustic transducers;sound reproduction;acoustic field;data mining;window functions;windows;sound reproduction acoustic field error analysis;global co;angular window functions;conference paper;arrays;keywords cylindrical harmonic expansions;error analysis;cylindrical harmonic expansions soundfield reproduction multizone;loudspeakers;ieee;loudspeakers acoustical engineering audio systems least squares methods acoustic signal processing array signal processing headphones harmonic analysis australia frequency;radial distance;spatial multizone soundfield reproduction;fundamental limits;soundfield reproduction;potential applications;signal processing cylindrical harmonic expansions;harmonic analysis	Spatial multizone soundfield reproduction is a difficult problem, which has many potential applications. This paper provides a framework to recreate 2D spatial multizone soundfields using an array of loudspeakers. We derive the desired global soundfield by translating individual desired soundfields to a single global co-ordinate system and applying appropriate angular window functions. We reveal some of the fundamental limits of 2D multizone soundfield reproduction. We show that the ability of multizone reproduction is dependent on (i) maximum radius of multizones, (ii) window length (size, and nature), and (iii) radial distance to the furthermost zone. We illustrate the framework by designing and simulating a two dimensional two zone soundfield.	angularjs;dvd region code;loudspeaker;radial (radio);radial basis function;simulation;spatial analysis;window function	Yan Jennifer Wu;Thushara Dheemantha Abhayapala	2009	2009 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2009.4959528	loudspeaker;probability density function;polar coordinate system;speech recognition;computer science;harmonic analysis;speech processing;mathematics;window function	Robotics	86.95831963392979	-34.084616910109474	170868
d04e2bb0ca06a4dd8d0c5076f74f9899c267706d	delay-induced order in pulse-coupled bifurcating neurons	equivalent circuit;chaotic behavior;threshold base signal;neural nets;bifurcation;chaos;delay effect;bifurcation neurons delay chaos switches orbits delay effects;integrate and fire;sinusoidal base signal;delay effects;coupled system;orbits;integrate and fire behavior;delay circuits;equivalent circuits;electronic engineering computing;delay induced order;neurons;neural nets bifurcation delay circuits electronic engineering computing equivalent circuits;equivalent circuit delay induced order pulse coupled bifurcating neurons chaotic behavior integrate and fire behavior sinusoidal base signal threshold base signal delay effect;pulse coupled bifurcating neurons;switches	This paper studies dynamics of pulse-coupled bifurcating neurons with delay. Before the coupling, the neuron can exhibit chaotic/periodic behavior by repeating integrate-and-fire behavior between the threshold and sinusoidal base signal. After the coupling, the system can exhibit various bifurcation phenomena. Especially, we have found an interesting phenomenon: chaotic behavior of single neuron can be changed into periodic behavior of coupled system by a delay effect. This delay-induced order and related bifurcation can be analyzed precisely using the mapping procedure. Presenting a simple equivalent circuit, basic phenomena are confirmed experimentally.	bifurcation theory;biological neuron model;chaos theory;equivalent circuit;experiment;map;program composition notation	Kozo Hisamatsu;Toshimichi Saito	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596846	equivalent circuit;computer science;control theory;mathematics;artificial neural network	Robotics	84.87445470070664	-26.420146332836808	171149
27e917dd1378eee5e36c609af1a25114723894e5	an adaptive filter with gain and time-shift parameters for echo cancellation	microphones;convergence;transfer functions;shape;echo cancellers;delays	In this paper, we propose a simple yet effective parametric adaptive filter (PAF) and demonstrate its excellent performance in acoustic echo cancellation applications. Specifically, the proposed PAF decomposes an adaptive filter into three components: a normalized finite impulse response filter, a gain factor and a time-shift factor. With a novel update scheme for the PAF, these three components can be adjusted with different step-size respectively. Therefore, the novel adaptive filter with a parametric structure is suitable to track an acoustic echo path, the change of which mainly happens to the gain and time-shift while the ‚Äúbasic shape‚Äù of the transfer function keeps relatively stable. It is also important to point out that the proposed PAF is a general platform of adaptive filtering, and the conventional method can be considered as a special case of this general platform. Experiments based on measured impulse response in realistic environment show that the proposed PAF outperforms the conventional method on convergence rate in echo cancellation application when dealing with channel changes caused by adjustments of system gain and delay.	acoustic cryptanalysis;adaptive filter;echo suppression and cancellation;experiment;finite impulse response;rate of convergence;transfer function	Zhiping Zhang;Zhiqiang Wu	2016	2016 10th International Symposium on Chinese Spoken Language Processing (ISCSLP)	10.1109/ISCSLP.2016.7918464	adaptive filter;convergence;kernel adaptive filter;telecommunications;shape;computer science;control theory;transfer function	Mobile	84.41139778537458	-33.568494981337096	171469
75335a0284a9cebad33d91c4836d95184ea73723	source and listener directivity for interactive wave-based sound propagation	plane wave decomposition;frequency domain analysis;acoustics;virtual reality;helmholtz equation interactive wave based sound propagation dynamic data driven source directivity virtual environments computer games directional source representation elementary spherical harmonic sources sh sources propagated sound field encoding sh decomposition listener position precomputed sh sound field weighted sum plane wave decomposition approach higher order derivatives dynamic hrtf based listener directivity online frequency domain wave based sound propagation algorithm offline frequency domain wave based sound propagation algorithm valve source game engine realistic acoustic effects sound amplification diffraction low passing spatial sound;runtime;directivity;spatial sound;computational modeling;ear;runtime mathematical model equations acoustics frequency domain analysis computational modeling ear;mathematical model;helmholtz equations;helmholtz equation;computer games;virtual reality acoustic wave propagation computer games helmholtz equations;sound propagation;acoustic wave propagation	We present an approach to model dynamic, data-driven source and listener directivity for interactive wave-based sound propagation in virtual environments and computer games. Our directional source representation is expressed as a linear combination of elementary spherical harmonic (SH) sources. In the preprocessing stage, we precompute and encode the propagated sound fields due to each SH source. At runtime, we perform the SH decomposition of the varying source directivity interactively and compute the total sound field at the listener position as a weighted sum of precomputed SH sound fields. We propose a novel plane-wave decomposition approach based on higher-order derivatives of the sound field that enables dynamic HRTF-based listener directivity at runtime. We provide a generic framework to incorporate our source and listener directivity in any offline or online frequency-domain wave-based sound propagation algorithm. We have integrated our sound propagation system in Valve's Source game engine and use it to demonstrate realistic acoustic effects such as sound amplification, diffraction low-passing, scattering, localization, externalization, and spatial sound, generated by wave-based propagation of directional sources and listener in complex scenarios. We also present results from our preliminary user study.	acoustic cryptanalysis;algorithm;basis function;encode;frequency band;frequency response;game engine;generic drugs;head-related transfer function;interactivity;kilohertz;mitral valve prolapse syndrome;nucleic acid hybridization;nyquist rate;online and offline;pc game;precomputation;preprocessor;run time (program lifecycle phase);silo (dataset);software propagation;spherical power:invlen:pt:eye.left:qn;usability testing;virtual reality;wavelet;weight function	Ravish Mehra;Lakulish Antani;Sunyoung Kim;Dinesh Manocha	2014	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2014.38	speech recognition;critical distance;directional sound;virtual reality;helmholtz equation;acoustic source localization	Visualization	88.5600110181695	-33.70355062544377	171551
e48a4b317a811af8cba35f06ecf16e395874e9b6	design of a 13.56 mhz segmented helmholtz coil for rf exposure testing of biologics to simulated rfid readers	rfid safety;rf exposure testing;capacitancia;identificacion por radiofrecuencia;securite;bobine inductance;rf testing;blood products safety;biological effects of radiation;rfid reader;antenne;1356 mhz rfid;bobina inductancia;identification par radiofrequence;biologics rf testing;safe operation;large helmholtz coil;inductor;biologics;blood;occupational safety;safety;rfid readers;radio frequency identification;antenna;capacitance;rf safety testing;lecteur rfid;antena;effet biologique rayonnement;sangre;seguridad;sang;blood safety;capacite electrique;segmented helmholtz coil;13 56 mhz rfid	The design methodology of a large 13.56 MHz Helmholtz coil with central magnetic field strength of H0 = 5.0 amperes/m is described. This apparatus is for use in protocol testing evaluating any thermal or non-thermal effects on blood and blood product samples that might be caused by long-term exposure to the fields produced by the 13.56 MHz RFID reader antennas. The Helmholtz coil was initially constructed as one continuous inductor; however, stray capacitance prevented it from resonating above 10.17 MHz. It was then successfully reconstructed as a four-segment Helmholtz coil by following methods used in designing Helmholtz coils for use in magnetic resonance imaging. Complete design, construction and testing details of the segmented Helmholtz coil and its RF drive system are given both to enable duplication and as a design guide for similar large Helmholtz coils. Occupational safety recommendations are made to enable safe operation. An application to blood products RF safety testing is discussed.	causality;communications protocol;functional data analysis;helmholtz machine;radio frequency;radio-frequency identification;resonance	Clive P. Hohberger;Boris Y. Tsirline	2009	IJRFITA	10.1504/IJRFITA.2009.023483	electronic engineering;astronomy;telecommunications;engineering;electrical engineering;antenna;occupational safety and health	Networks	93.22809501393375	-25.134103881738334	172168
15a46e51eab9e110ceb1cf3b61856defbb68bf0b	binaural multichannel wiener filter with directional interference rejection	microphones;binaural linearly constrained minimum variance algorithm;hearing aids;directional interference rejection;interference signal to noise ratio microphones auditory system speech acoustics;acoustics;auditory system;speech;wiener filters;speech enhancement;interference;single channel wiener post filter;acoustic scenario;spectral filtering;interference suppression;wiener filters hearing aids interference suppression speech enhancement;reverberant environment;binaural cues;binaural multichannel wiener filter;spectral information;spatial filtering;lcmv and mwf beamforming;noisy environment;hearing devices;signal to noise ratio;interference cancellation;spectral information binaural multichannel wiener filter directional interference rejection acoustic scenario hearing devices noisy environment reverberant environment spatial filtering spectral filtering binaural linearly constrained minimum variance algorithm single channel wiener post filter;noise;interference cancellation hearing aids binaural cues lcmv and mwf beamforming noise	In this paper we consider an acoustic scenario with a desired source and a directional interference picked up by hearing devices in a noisy and reverberant environment. We present an extension of the binaural multichannel Wiener filter (BMWF), by adding an interference rejection constraint to its cost function, in order to combine the advantages of spatial and spectral filtering while mitigating directional interferences. We prove that this algorithm can be decomposed into the binaural linearly constrained minimum variance (BLCMV) algorithm followed by a single channel Wiener post-filter. The proposed algorithm yields improved interference rejection capabilities, as compared with the BMWF. Moreover, by utilizing the spectral information on the sources, it is demonstrating better SNR measures, as compared with the BLCMV.	acoustic cryptanalysis;algorithm;binaural beats;interference (communication);loss function;rejection sampling;signal-to-noise ratio;wiener filter	Elior Hadad;Daniel Marquardt;Simon Doclo;Sharon Gannot	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7178048	single antenna interference cancellation;speech recognition;noise;speech;interference;signal-to-noise ratio;spatial filter	Robotics	83.95829977460117	-34.88473830210775	172860
7dc69f5d6825639eb9e008c3d3b0814542a6a068	stereophonic hands-free communication system based on microphone array fixed beamforming: real-time implementation and evaluation	signal image and speech processing;acoustics;beamforming technique;mathematics in music;computational savings;real time implementations;engineering acoustics;hands free communications;fixed beamforming;acoustic echoes;microphone arrays;subjective listening test	In this article, the authors propose an optimally designed fixed beamformer (BF) for stereophonic acoustic echo cancelation (SAEC) in real hands-free communication applications. Several contributions related to the combination of beamforming and echo cancelation have appeared in the literature so far, but, up to the authors‚Äô knowledge, the idea of using optimal fixed BFs in a real-time SAEC system both for echo reduction and stereophonic audio rendering is first addressed in this contribution. The employment of such designed BFs allows positively addressing both issues, as the several simulated and real tests seem to confirm. In particular, the stereo-recording quality attainable through the proposed approach has been preliminarily evaluated by means of subjective listening tests. Moreover, the overall system robustness against microphone array imperfections and noise presence has been experimentally evaluated. This allowed the authors to implement a real hands-free communication system in which the usage of the proposed beamforming technique has proven its superiority with respect to the usual two-microphone one in terms of echo reduction, and guaranteeing a comparable spatial image. Moreover, the proposed framework requires a low computational cost increment with regard to the baseline approach, since only few extra filtering operations with short filters need to be executed. Nevertheless, according to the performed simulations, the BF-based SAEC configuration seems to not require the signal decorrelation module, resulting in an overall computational saving.	acoustic cryptanalysis;algorithmic efficiency;baseline (configuration management);beamforming;brainfuck;decorrelation;echo suppression and cancellation;experiment;microphone;real-time clock;real-time web;simulation	Matteo Pirro;Stefano Squartini;Laura Romoli;Francesco Piazza	2012	EURASIP J. Audio, Speech and Music Processing	10.1186/1687-4722-2012-26	speech recognition;acoustics;physics	Robotics	84.24823913683069	-34.626492138659486	172922
ed9ae980a8cac2f517e94a2e801712655e64121c	unified approach for audio source separation with multichannel factorial hmm and doa mixture model	microphones;signal to distortion ratios audio source separation hmm doa mixture model blind source separation dereverberation audio event detection direction of arrival estimation multichannel signals multichannel factorial hidden markov model spatial correlation matrix plane wave assumption;reverberation audio signal processing blind source separation correlation methods direction of arrival estimation hidden markov models matrix algebra;arrays;hidden markov models;hidden markov models correlation direction of arrival estimation time frequency analysis arrays microphones source separation;correlation;source separation;time frequency analysis;doa estimation blind source separation voice activity detection dereverberation;direction of arrival estimation	We deal with the problems of blind source separation, dereverberation, audio event detection and direction-of-arrival (DOA) estimation. We previously proposed a generative model of multichannel signals called the multichannel facto rial hidden Markov model, which allows us to simultaneously solve these problems through a joint optimization problem formulation. In this approach, we modeled the spatial cor relation matrix of each source as a weighted sum of the spatial correlation matrices corresponding to all possible DOAs. However, it became clear through real environment experiments that the estimate of the spatial correlation matrix tended to deviate from the actual correlation matrix since the plane wave assumption does not hold due to reverber ation and noise components. To handle such deviations, we propose introducing a prior distribution over the spatial correlation matrices called the DOA mixture model instead of using the weighted sum model. The experiment showed that the proposed method provided 1.94 [dB] improvement compared with our previous method in terms of the the signal-to-distortion ratios of separated signals.	blind signal separation;direction of arrival;distortion;experiment;generative model;hidden markov model;markov chain;mathematical optimization;mixture model;optimization problem;source separation;weight function	Takuya Higuchi;Hirokazu Kameoka	2015	2015 23rd European Signal Processing Conference (EUSIPCO)	10.1109/EUSIPCO.2015.7362743	speech recognition;pattern recognition;mathematics;blind signal separation;statistics	Vision	82.98150112410889	-36.57683256990448	173070
6b292ccfa1efaab8a7d65be7b8634d648e267e54	combined noise and echo reduction in hands-free systems: a survey	filtering;filtrage;amelioration parole;speech signal;mobile radiocommunication;two channel sound pick ups combined noise echo reduction systems mobile radio hands free systems speech signal mono channel sound pick ups;speech processing;filtrado;telephone sets;tratamiento palabra;traitement parole;wiener filters;suppression echo;two channel sound pick ups;speech enhancement;noise reduction acoustic noise telephony loudspeakers couplings echo cancellers telephone sets noise cancellation speech enhancement research and development;radiocommunication service mobile;telephony;reduccion ruido;algorithme;algorithm;research and development;land mobile radio;loudspeakers;acoustic noise;noise reduction;mobile radio;noise cancellation;reduction bruit;echo suppression;couplings;radiocomunicacion servicio movil;echo cancellers;combined noise echo reduction systems;wiener filters echo suppression speech enhancement land mobile radio acoustic noise;hands free systems;mono channel sound pick ups;algoritmo	The modern telecommunications field is concerned with freedom and, in this context, hands-free systems offer subscribers the possibility of talking more naturally, without using a handset. This new type of use leads to new problems which were negligible in traditional telephony, namely the superposition of noise and echo on the speech signal. To solve these problems and provide a quality that is sufficient for telecommunications, combined reduction of these disturbances is required. This paper presents a summary of the solutions retained for this dual reduction in the context of mono-channel and two-channel sound pick-ups.	image noise;quantum superposition	R√©gine Le Bouquin-Jeann√®s;Pascal Scalart;G√©rard Faucon;Christophe Beaugeant	2001	IEEE Trans. Speech and Audio Processing	10.1109/89.966084	loudspeaker;filter;speech recognition;acoustics;telecommunications;computer science;active noise control;noise;noise reduction;speech processing;coupling;telephony	EDA	83.72066072814218	-33.0482694418141	173264
8bdae198ce395257d3f84b1d54ffa5992b8f8982	restoration of randomly blurred images by the wiener filter	picture processing fast fourier transforms filtering and prediction theory iterative methods matrix algebra noise;circulant matrix;picture processing;matrix algebra;filtering and prediction theory;fast fourier transform;iterative methods;point spread function;fast fourier transforms;impulse response;wiener filter;frequency domain;circulant matrix approximation randomly blurred images wiener filter noisy point spread functions additive detective noise iterative frequency domain fast fourier transform;noise;image restoration wiener filter speech processing signal processing algorithms adaptive signal processing adaptive filters lattices digital filters additive noise statistics	Fourier transform reconstruction with limited data is often encountered in tomographic imaging problems. Conventional techniques, such as FFT-based methods, the spatial-support-limited extrapolation method, and the maximum entropy method, have not been optimal in terms of both Gibbs ringing reduction and resolution enhancement. In this correspondence, a new method based on object modeling and parameter estimation is proposed to achieve superresollrtion reconstruction.	circuit restoration;estimation theory;extrapolation;fast fourier transform;gibbs sampling;principle of maximum entropy;randomness;ringing (signal);wiener filter	Ling Guan;Rabab Kreidieh Ward	1989	IEEE Trans. Acoustics, Speech, and Signal Processing	10.1109/29.17544	computer vision;fast fourier transform;mathematical optimization;electronic engineering;deconvolution;root-raised-cosine filter;mathematics;wiener filter;filter design;statistics;wiener deconvolution	Vision	87.17303025973926	-36.614376747610855	173398
dacd138fe3a2c29c1dd832eb57c23b9b950f1919	development of an automatic vickers hardness testing system using image processing technology	image processing technology;measuring machine;medicion automatica;image processing;methode mesure;diamond pyramid indenter;automatic testing;surface roughness;japanese industrial standard jis b 7725;automatic test equipment;materials testing;automatic measurement;mesure automatique;indexing terms;rough polished specimens;traitement image;vickers hardness;rough surfaces;machine parts;machine design;machine mesure;ensayo dureza;hardness test;vickers hardness number;indexation;measuring methods;system testing;cities and towns;electrical resistance measurement;durete vickers;automatic testing system testing image processing materials testing rough surfaces surface roughness electrical resistance measurement cities and towns etching equations;automatic test equipment hardness testing image processing;automatic vickers hardness testing system;japanese industrial standard jis b 7725 automatic vickers hardness testing system image processing technology mechanical characteristics machine parts machine design vickers hardness number surface area diamond pyramid indenter indentation image data rough polished specimens;etching;maquina medida;mechanical characteristics;surface area;indentation image data;hardness testing;essai durete	The mechanical characteristics of machines or machine parts depend on the properties of the materials from which they are made. Hardness is an especially important index for machine design. The Vickers hardness number of a test material is defined by the surface area of the indentation made in the surface of a test specimen by a diamond pyramid indenter. Diagonal lines that indicate the indentation size are usually several micrometers to several hundred micrometers long, depending on the hardness of the material. Conventional automatic Vickers hardness testing systems have been applied only to specular-polished specimens. A new fully automatic Vickers hardness testing system has been developed that emulates visual Vickers hardness testing in terms of accuracy and that automatically sets the threshold level of the image processor to suit indentation image data. It can be applied not only to the testing of rough-polished specimens while meeting the measurement accuracy specified in Japanese Industrial Standard (JIS) B 7725, but can also process one indentation within 20 s, including the indenting, focusing and image processing time.	image processing	Takao Sugimoto;Tadao Kawaguchi	1997	IEEE Trans. Industrial Electronics	10.1109/41.633474	indentation hardness;meyer hardness test;image processing;computer science;engineering;forensic engineering;engineering drawing;vickers hardness test;knoop hardness test	Robotics	88.38795237124589	-25.776382684164478	174024
9ff1b5a7d6c1aa58e1fe6a8204d2e22ae1af7af9	svd-based optimal filtering technique for noise reduction in hearing aids using two microphones	signal image and speech processing;hearing aids;speech intelligibility;enhancement;diffuse noise;optimal filtering;room;speech;quantum information technology spintronics;svd based technique;noise reduction;array;ratio;beamforming;compression;sista;hearing aid	We introduce a new SVD-based (singular value decomposition) strategy for noise reduction in hearing aids. This technique is evaluated for noise reduction in a behind-the-ear (BTE) hearing aid where two omnidirectional microphones are mounted in an endfire configuration. The behaviour of the SVD-based technique is compared to a two-stage adaptive beamformer for hearing aids developed by Vanden Berghe and Wouters (1998). The evaluation and comparison is done with a performance metric based on the speech intelligibility index (SII). The speech and noise signals are recorded in reverberant conditions with a signal-to-noise ratio of 0 dB and the spectrum of the noise signals is similar to the spectrum of the speech signal. The SVD-based technique works without initialization nor assumptions about a look direction, unlike the two-stage adaptive beamformer. Still, for different noise scenarios, the SVD-based technique performs as well as the two-stage adaptive beamformer, for a similar filter length and adaptation time for the filter coefficients. In a diffuse noise scenario, the SVD-based technique performs better than the two-stage adaptive beamformer and hence provides a more flexible and robust solution under speaker position variations and reverberant conditions.	adaptive beamformer;beamforming;coefficient;intelligibility (philosophy);microphone;noise reduction;signal-to-noise ratio;singular value decomposition	Jean-Baptiste Maj;Marc Moonen;Jan Wouters	2002	EURASIP J. Adv. Sig. Proc.	10.1155/S1110865702000690	speech recognition;computer science;speech;adaptive beamformer;noise reduction;ratio;beamforming;compression;intelligibility	HPC	84.15471208586001	-34.73647737567293	174351
234092626bfea5bfdab7643906c39476792cc229	methods for deconvolving sparse positive delta function series	inorganic organic physical and analytical chemistry;x ray fluorescence analysis;nonlinear filters;detectors;x ray emission;degradation;processing;nonlinear least squares;general and miscellaneous mathematics computing and information science;instruments;seismology;delta function;data processing;signals;chemical analysis;peaks;mathematics computers;iterative methods;nondestructive analysis;vectors;point spread function;geosciences;geophysics seismology tectonics 1980 1989;signal restoration;wiener filter;iteration method;x ray emission analysis 400103 radiometric radiochemical procedures 1987;analytical chemistry;functions;least squares methods;signal restoration vectors degradation chemical analysis instruments least squares methods detectors nonlinear filters wiener filter laboratories	Sparse delta function series occur as data in many chemical analysis and seismic methods. This original data is often sufficiently degraded by the recording instrument response that the individual delta function peaks are difficult to distinguish and measure. A method, which has been used to measure these peaks, is to fit a parameterized model by a nonlinear least squares fitting algorithm. The deconvolution approaches described here have the advantage of not requiring a parameterized point spread function, nor do they expect a fixed number of peaks. Two new methods will be presented. The maximum power technique will be reviewed. A maximum a posteriori technique will be introduced. Results on both simulated and real data by the two methods will be presented. The characteristics of the data can determine which method gives superior results.	dirac delta function;sparse matrix	H. Joel Trussell;L. A. Schwalbe	1981		10.1109/ICASSP.1981.1171318	econometrics;data processing;computer science;mathematics;iterative method;statistics	AI	83.41264598685555	-46.28946594234615	174934
fd513a47f4d0bfb26f6d5a782c31a794ab694b89	generation of isolated wideband sound fields using a combined two-stage lasso-ls algorithm	wideband arrays optimization algorithm design and analysis least squares methods;isolated audio signals isolated wideband sound field generation combined two stage lasso ls algorithm personal soundfields multiple listeners multizone systems speaker positions active speakers two stage pressure matching optimization wideband sound sources least absolute shrinkage selection operator regularized least squares algorithm variable total speaker weight powers mean squared error;optimisation;least squares approximations;multizone;audio signal processing;wideband;wideband isolated sound fields lasso least squares multizone;acoustics;manganese;arrays;least squares;vectors;mean square error methods;optimisation audio signal processing least squares approximations mean square error methods;optimization;isolated sound fields;lasso;algorithm design and analysis	The prohibitive number of speakers required for the reproduction of isolated soundfields is the major limitation preventing solution deployment. This paper addresses the provision of personal soundfields (zones) to multiple listeners using a limited number of speakers with an underlying assumption of fixed virtual sources. For such multizone systems, optimization of speaker positions and weightings is important to reduce the number of active speakers. Typically, single stage optimization is performed, but in this paper a new two-stage pressure matching optimization is proposed for wideband sound sources. In the first stage, the least-absolute shrinkage and selection operator (Lasso) is used to select the speakers' positions for all sources and frequency bands. A second stage then optimizes reproduction using all selected speakers on the basis of a regularized least-squares (LS) algorithm. The performance of the new, two-stage approach is investigated for different reproduction angles, frequency range and variable total speaker weight powers. The results demonstrate that using two-stage Lasso-LS optimization can give up to 69 dB improvement in the mean squared error (MSE) over a single-stage LS in the reproduction of two isolated audio signals within control zones using e.g. 84 speakers.	algorithm;beamforming;dvd region code;experiment;frequency band;lasso;least squares;mathematical optimization;mean squared error;multi-user;powered speakers;selectivity (electronic);software deployment	Nasim Radmanesh;Ian S. Burnett	2013	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2012.2227736	speech recognition;acoustics;audio signal processing;computer science;manganese;machine learning;lasso;least squares	Vision	84.81922450092269	-35.73165332770642	176153
a5c82d15765aed363e0d6f963f4482593ce5fa79	trapped victim detection by pseudo-noise radar	victim detection;ultra wideband radar;field trial;ultra wideband;pseudo noise;motion detection	Radar based detection of earthquake survivors exploits the modulation of the backscattered signal by body motions of the victim. The most challenging task is the detection of respiration activity of an unconscious person. The principle of breathing motion detection by radar is explained and the major handicaps as well as appropriate counter measures are discussed. The possible structure of a survivor detection radar system is considered and some results from field trials are summarized.	modulation;radar	J√ºrgen Sachs;Marko Helbig;Ralf Herrmann;Martin Kmec;Kai Schilling;E. Zaikov;Peter Rauschenbach	2011		10.1145/2185216.2185289	continuous-wave radar;electronic engineering;radar engineering details;radar lock-on;geography;telecommunications;low probability of intercept radar;pulse-doppler radar;remote sensing	Robotics	84.6819222424084	-41.43103745370698	176913
359d0d18fd6e632f57b1f691965748c84f85216f	cramer-rao bounds for source localization in shallow ocean with generalized gaussian noise	gaussian noise;array signal processing;direction-of-arrival estimation;sonar signal processing;cramer-rao bounds;direction-of-arrival variance;generalized gaussian noise;range-depth estimator;shallow ocean;underwater acoustic source localization	Localization of underwater acoustic sources is a problem of great interest in the area of ocean acoustics. There exist several algorithms for source localization based on array signal processing. It is of interest to know the theoretical performance limits of these estimators. In this paper we develop expressions for the Cramer-Rao-Bound (CRB) on the variance of direction-of-arrival (DOA) and range-depth estimators of underwater acoustic sources in a shallow range-independent ocean for the case of generalized Gaussian noise. We then study the performance of some of the popular source localization techniques, through simulations, for DOA/range-depth estimation of underwater acoustic sources in shallow ocean by comparing the variance of the estimators with the corresponding CRBs.	acoustic cryptanalysis;adaptive beamformer;algorithm;beamforming;direction of arrival;portable document format;signal processing;simulation	N. C. Pramod;G. V. Anand	2006	2006 14th European Signal Processing Conference		gaussian noise;electronic engineering;speech recognition;acoustics;engineering	Robotics	86.08860745896281	-37.40071359042839	177284
49dc3993f32d73d6624759fd4e5e4b25194e2d98	models for blind speech dereverberation: a subband all-pole filtered block stationary autoregressive process	acoustic signal processing;audio equipment;audio signal processing;autoregressive processes;channel estimation;estimation theory;filtering theory;reverberation;speech processing;acoustic environment;blind speech dereverberation;channel estimates;gramophone horn;inverse filtering;parametric modelling;single all-pole filter;single channel blind dereverberation;single-band block stationary ar process;subband all-pole filtered block stationary autoregressive process	Single channel blind dereverberation of speech acquired in an acoustic environment is approached using parametric modelling and estimation theory to obtain channel estimates; inverse filtering is then applied to derevererate the speech. Models previously used in such an approach deal with relatively simple scenarios such as a gramophone horn modelled with 70 parameters; the weakness of those models, however, is in their attempt to simultaneously model the full channel spectrum by a single all-pole filter. Not only does this lead to a large computational load, it is not parsimonious, nor is it scalable such that the algorithm can be applied to higher dimensional problems. A better approach uses subbands; in this paper, a subband all-pole filter models the channel while the source is still represented by a single-band block stationary AR process. An example is given of blindly dereverberating a signal observed through the aforementioned gramophone horn, demonstrating an equally robust, but more flexible and scalable model.	acoustic cryptanalysis;algorithm;autoregressive model;computation;estimation theory;inverse filter;occam's razor;scalability;stationary process	James R. Hopgood	2005	2005 13th European Signal Processing Conference		electronic engineering;speech recognition;acoustics;computer science	ML	83.15009514871149	-35.431162519125174	178099
00bde36ffb01d5f15ad7489671116338ef560df8	srp-phat methods of locating simultaneous multiple talkers using a frame of microphone array data	microphones;optimisation;gaussian processes;microphone arrays acoustic noise reverberation position measurement clustering algorithms integrated circuit modeling acoustical engineering data engineering power engineering and energy optimization methods;phase transform;acoustic position measurement;speech processing;acoustic radiators;gmm;speech;acoustic signal processing;srp phat method;stochastic region contraction;src srp phat method large aperture microphone array steered response power phase transform gaussian mixture model gmm global optimization stochastic region contraction;arrays;gaussian mixture model;acoustic position measurement acoustic radiators microphones acoustic arrays;steered response power;microphone array;phase transformation;position measurement;global optimization;optimisation acoustic arrays acoustic signal processing gaussian processes microphone arrays;microphone arrays;src;signal to noise ratio;acoustic arrays;large aperture microphone array	Two new methods for locating multiple sound sources using a single segment of data from a large-aperture microphone array are presented. Both methods employ the proven-robust steered response power using the phase transform (SRP-PHAT) as a functional. To cluster the data points into highly probable regions containing global peaks, the first method fits a Gaussian mixture model (GMM), whereas the second one sequentially finds the points with highest SRP-PHAT values that most likely represent different clusters. Then the low-cost global optimization method, stochastic region contraction (SRC), is applied to each cluster to find the global peaks. We test the two methods using real data from five simultaneous talkers in a room with high noise and reverberation. Results are presented and discussed.	data point;fits;global optimization;google map maker;mathematical optimization;microphone;mixture model;scsi rdma protocol;sample rate conversion;stochastic gradient descent	Hoang Do;Harvey F. Silverman	2010	2010 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2010.5496133	speech recognition;computer science;generalized method of moments;speech;mixture model;gaussian process;speech processing;mathematics;proto-oncogene tyrosine-protein kinase src;signal-to-noise ratio;statistics;global optimization	Robotics	85.56609268391486	-36.45712239036813	178236
1352133a1f554eaba11699e1dadbb79d8c3eb8bc	joint noise cancellation and dereverberation using multi-channel linearly constrained minimum variance filter		Speech acquired from an array of distant microphones is affected by ambient noise and reverberation. Single channel linearly constrained minimum variance (LCMV) filters have been proposed to remove ambient noise. In this paper, an algorithm for joint noise cancellation and dereverberation using a multi channel LCMV filter in the frequency domain is proposed. A single channel LCMV filter which accounts for the inter frame correlation is applied on each channel to remove the early reverberation component. A modified spectral subtraction method is also proposed to remove the late reverberation component present in the speech signal. Experimental results on joint noise cancellation and dereverberation indicate a reasonable improvement over conventional speech enhancement methods. Additional experiments on distant speech recognition are also conducted to illustrate the significance of the method.	algorithm;experiment;microphone;speech enhancement;speech recognition	Karan Nathwani;Rajesh Mahanand Hegde	2013			artificial intelligence;speech recognition;minimum-variance unbiased estimator;pattern recognition;active noise control;computer science;communication channel	ML	83.80547955713534	-35.01149262841012	178416
993e84f613ae5d6601f808af5f924f72ba8db877	noise reduction in swallowing muscle activity measurement based on mixture gaussian distribution model	swallowing sensor sheet noise electromyography		noise reduction	Nobuyuki Ohmori;Chihiro Murasawa;Jumpei Aizawa;Hideya Momose;Yoshito Koyama;Hiroshi Kurita;Hiroaki Yoshida;Masayoshi Kamijo	2017	JACIII	10.20965/jaciii.2017.p0109	speech recognition;computer science	AI	87.94620527926878	-28.687172371802216	178653
90f3728120c8cdea9f88773975fa56b5c169dfb8	spectral subtraction with adaptive averaging of the gain function	signalbehandling;spectral subtraction;signal processing	The handsfree mode is convenient when using a mobile phone in a vehicle. This mode brings the microphone away from the talker‚Äôs mouth. As a consequence the speech signal picked up has low Signal to Noise Ratio. Thus, to improve the SNR a noise reduction method is employed. The proposed method is an improvement of the well-known spectral subtraction method which uses one SNR-dependent gain function to suppress the noise. The proposed method reduces the residual noise artifacts by using an adaptive averaging of the gain function. The adaptation is controlled by a spectral discrepancy measure, which is obtained by comparing the averaged noise spectrum and the current input signal spectrum. Experiments show a noise reduction of 10 dB with good noise quality and significantly low residual noise distortion. Sound results are presented at http://www.its.hk-r.se/research	algorithm;colors of noise;decibel;discrepancy function;distortion;experiment;microphone;mobile phone;noise reduction;signal-to-noise ratio;sound quality;spectral density;stationary process;whole earth 'lectronic link	Harald Gustafsson;Sven Nordholm;Ingvar Claesson	1999			pulp canal;pattern recognition;artificial intelligence;acoustics;subtraction;signal processing;abutment;computer science	ML	84.03557017974072	-34.01584823859424	178724
7b12c6a18bca3f826581d32d7bc4dbe85d735503	particle filters and beamforming for eeg source estimation	brain electrical source localization;hidden markov models brain electrical source localization filtering and state estimation;array signal processing;qa75 electronic computers computer science;uncorrelated brain sources particle filters eeg source estimation inverse problem geometrical localization 3d localization active brain zones spatial filter beamforming oscillation estimation;hidden markov models;hidden markov models brain models electroencephalography estimation computational modeling atmospheric measurements;filtering and state estimation;electroencephalography;particle filtering numerical methods array signal processing electroencephalography medical signal processing;medical signal processing;particle filtering numerical methods	This is a proof of concept work that proposes a solution to the inverse problem of EEG source estimation by combining two techniques, namely a Particle Filter (PF) for geometrical (3D) localization of the most active brain zones (expressed by two dipoles) and a beamformer (BF) as a spatial filter for estimation of the oscillations that have originated the recorded EEG data. The estimation is reliable for uncorrelated brain sources.	beamforming;brain implant;brainfuck;cobham's thesis;electroencephalography;particle filter;randomness;variational principle	Petia Georgieva;Lyudmila Mihaylova;Nidhal Bouaynaya;Lakhmi C. Jain	2012	The 2012 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2012.6252516	speech recognition;electroencephalography;computer science;machine learning;hidden markov model	Robotics	83.42870903852513	-39.26787815161111	179590
96f2a668f11490fa809d4bbc865b293a2af16c9b	localization based separation of mixed audio signals with binary masking of hilbert spectrum	energy resolution;microphones;binary masking;empirical mode decomposition localization based separation mixed audio signals binary masking hilbert spectrum audio signal separation stereo mixtures time frequency domain;degradation;audio signal processing;information science;time frequency;time frequency domain;energy resolution time frequency analysis signal resolution information science source separation humanoid robots microphones fourier transforms power harmonic filters degradation;spectrum;hilbert spectrum;humanoid robots;power harmonic filters;fourier transforms;stereo mixtures;signal resolution;audio signal separation;localization based separation;source separation;time frequency analysis audio signal processing source separation;mixed audio signals;time frequency analysis;empirical mode decomposition	This paper presents a method of audio signal separation from stereo mixtures using binary masking in time-frequency (TF) domain based on the spatial location of the audio sources. The TF representation of audio signal is obtained by Hubert spectrum (HS). The Hubert transformation together with empirical mode decomposition (EMD) produces HS which is a fine-resolution TF representation of any nonlinear and non-stationary signal. The sources are localized in the space of time and intensity differences between two microphones' signals. The separation is performed by masking the target signal in TF domain considering that the sources are disjoint orthogonal. The experimental results of the proposed method show a noticeable improvement of separation efficiency	hilbert spectrum;hilbert‚Äìhuang transform;microphone;nonlinear system;separation logic;stationary process	Md. Khademul Islam Molla;Keikichi Hirose	2006	2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings	10.1109/ICASSP.2006.1661218	speech recognition;time‚Äìfrequency analysis;information science;computer science;mathematics	Robotics	83.03724130720114	-37.452709184529546	180037
ab49cb3326ff643c3b9abd2ec8877e02f580f6e3	design of a time-domain acoustic contrast control for broadband input signals in personal audio systems	audio systems;time domain analysis audio signals audio systems filtering theory fourier transforms frequency domain analysis inverse transforms;frequency domain analysis;time domain analysis;personal audio systems acoustic contrast control frequency response consistency response variation loudspeaker array;fourier transforms;audio signals;acoustics frequency control finite impulse response filters frequency response loudspeakers arrays speech;inverse transforms;filtering theory;sound quality improvement time domain acoustic contrast control approach broadband input signal personal audio system frequency domain analysis inverse fourier transform optimum broadband contrast performance frequency response consistency	The acoustic contrast control (ACC) approach provides a simple strategy to focus sound on a designed target area in a personal audio system. All of the traditional ACC approaches have been designed in the frequency domain, and then transformed into the time domain through the application of an inverse Fourier transform. Therefore, the broadband contrast performance of the traditional ACC approach is not optimum. Especially, when the length of the control filter is short, the traditional approach may have poor contrast performance at non-control frequencies. This study proposes a novel method that can achieve the optimum broadband contrast performance, which also maintains a good frequency-response consistency by introducing the response variation constraints to improve sound quality. Experimental results demonstrate the effectiveness of the new method.	acoustic cryptanalysis;acoustic fingerprint;frequency response;sound quality	Yefeng Cai;Ming Wu;Jun Yang	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6637665	fourier transform;speech recognition;computer science;audio signal;mathematics;audio crossover;audio signal flow;audio analyzer;frequency domain;discrete frequency domain	Robotics	84.25028888830563	-33.49662604368627	180295
0d03dec6fa88c9041181bd66b4f66416fb6a0a4f	reduction of the dispersion error in the triangular digital waveguide mesh using frequency warping	multidimensional system;architectural acoustics;acoustic signal processing;triangular mesh;indexing terms;musical instruments;three dimensional;finite difference method;musical acoustics;waveguide theory;finite difference time domain analysis;frequency acoustic waveguides waveguide junctions finite impulse response filter acoustic propagation instruments multidimensional systems acoustic waves acoustic signal processing computational modeling;architectural acoustics acoustic wave propagation musical instruments musical acoustics finite difference time domain analysis mesh generation acoustic waveguides waveguide theory;time domain;acoustic delay lines;wave propagation;mesh generation;acoustic waveguides;acoustic wave propagation;acoustic spaces dispersion error triangular digital waveguide mesh frequency warping two dimensional wave propagation three dimensional wave propagation musical instruments	The digital waveguide mesh has been successfully used for simulation of two-dimensional (2-D) and three-dimensional (3-D) wave propagation in musical instruments and acoustic spaces. Nevertheless, digital waveguide mesh algorithms suffer from dispersion which increases with frequency. In this letter, we show how the dispersion error of the triangular digital waveguide mesh can be reduced by frequency warping. By using this technique, the worst-case dispersion error of 0.6% is obtained, whereas in the original triangular mesh it is about 6.5%.	3d computer graphics;acoustic cryptanalysis;algorithm;best, worst and average case;bilinear transform;polygon mesh;simulation;software propagation	Lauri Savioja;Vesa V√§lim√§ki	1999	IEEE Signal Processing Letters	10.1109/97.744624	three-dimensional space;waveguide;mesh generation;index term;multidimensional systems;wave propagation;time domain;computer science;finite difference method;triangle mesh;musical acoustics;mathematics	Visualization	87.09136988149112	-32.99418000209226	180296
b4b9936bbdbc5b8bb4b730512648f5f271f1a5bf	towards a singing voice attenuation system using active noise control	singing voice;passive noise control;active noise control	We have been investigating on the possibility of controlling singing voice using active noise control technology. We proposed a novel structure for conduction pipes with absorption material lining into which the singer can sing into. We compared the efficiency of ANC with conventional conduction path pipes, and found that the new structure enhances the ANC performance depending on the phonetic content.	named pipe	Keisuke Matsuura;Kazuhiro Kondo	2015	2015 IEEE 4th Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2015.7398631	speech recognition;acoustics;audiology	Robotics	85.44525849272866	-34.00404735387552	180646
60e6120a60d97d2d65c7ef833512be9df26795d4	convolutive audio source separation using robust ica and reduced likelihood ratio jump		Audio source separation is the task of isolating sound sources that are active simultaneously in a room captured by a set of microphones. Convolutive audio source separation of equal number of sources and microphones has a number of shortcomings including the complexity of frequency-domain ICA, the permutation ambiguity and the problem‚Äôs scalabity with increasing number of sensors. In this paper, the authors propose a multiple-microphone audio source separation algorithm based on a previous work of Mitianoudis and Davies [1]. Complex FastICA is substituted by Robust ICA increasing robustness and performance. Permutation ambiguity is solved using the Likelihood Ration Jump solution, which is now modified to decrease computational complexity in the case of multiple microphones.	algorithm;algorithmic efficiency;computation;computational complexity theory;cost efficiency;fastica;independent computing architecture;kinect;microphone;sensor;sound card;source separation	Dimitrios Mallis;Thomas Sgouros;Nikolaos Mitianoudis	2016		10.1007/978-3-319-44944-9_20	speech recognition;pattern recognition	AI	83.33666088559487	-36.90556661893531	180912
4fb74bed46028935ba180ca5e69dc8218b38fa1b	distance-dependent head-related transfer functions measured with high spatial resolution using a spark gap	databases;spark gaps;azimuth;high resolution;transfer functions spatial resolution sparks acoustic measurements loudspeakers azimuth humans laboratories acoustic noise magnetic heads;resolution spatiale;resolucion espacial;transfer functions;acoustic sound source;directividad;speech processing;mesure acoustique;database;base dato;analisis objetivos;attenuation;acoustic filters;spark gap;transfer functions acoustic measurement headphones spark gaps;frequency response;directivity;reponse frequence;point source;haute resolution;respuesta frecuencia;head related transfer function;evaluation subjective;azimut;directivite;transfer function;funcion traspaso;alta resolucion;sparks;estimacion parametro;base de donnees;descargador;head related transfer functions hrtfs;signal acoustique;eclateur;medida acustica;fonction transfert;elevation;acoustic signal;parameter estimation;estimation parametre;headphones;distance dependent head related transfer functions;subjective evaluation;acoustic measurements;analyse objective;objective analysis;senal acustica;acoustic filters distance dependent head related transfer functions high spatial resolution spark gap acoustic sound source;spark gap acoustic applications acoustic filters acoustic measurements head related transfer functions hrtfs;acoustic applications;acoustic measurement;evaluacion subjetiva;high spatial resolution;spatial resolution	A measurement of head-related transfer functions (HRTFs) with high spatial resolution was carried out in this study. HRTF measurement is difficult in the proximal region because of the lack of an appropriate acoustic point source. In this paper, a modified spark gap was used as the acoustic sound source. Our evaluation experiments showed that the spark gap was more like an acoustic point source than others previously used from the viewpoints of frequency response, directivity, power attenuation, and stability. Using this spark gap, high spatial resolution HRTFs were measured at 6344 spatial points, with distances from 20 to 160 cm, elevations from -40deg to 90deg, and azimuths from 0deg to 360deg. Based on these measurements, an HRTF database was obtained and its reliability was confirmed by both objective and subjective evaluations.	acoustic cryptanalysis;approximation algorithm;covox speech thing;experiment;frequency response;head-related transfer function	Tianshu Qu;Zheng Xiao;Mei Gong;Ying Huang;Xiaodong Li;Xihong Wu	2009	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2009.2020532	spark gap;image resolution;acoustics;telecommunications;computer science;speech processing;transfer function	Visualization	86.07738073466837	-33.63705106396821	181363
759bdcf0696029ea8a534ea020a962fd239b368d	the careful double vision of self		A method and apparatus are described for fusing a plurality of signals, corresponding to mean and covariance estimates, into a single signal when the given signal estimates are correlated to an unknown degree. The core components of the method and apparatus are (1) capability to express the means and covariances of the set of signals in inverse form in a common coordinate frame and (2) capability to form a signal determined by a convex combination of the means and covariances, so expressed. The set of estimates to be fused may comprise previously fused estimates as well as measurements of a physical system. The signal derived from the fused result can be transmitted and used to physically respond to the measured state of the system of interest.	gordon mccalla;judy array	Judy Kay;Gordon I. McCalla	2003	I. J. Artificial Intelligence in Education		algorithm;artificial intelligence;machine learning;physical system;covariance;inverse;computer science;convex combination	AI	92.01173696004561	-36.97217642650032	181375
aa3fe00c53cd1e117a44d0fbfe58da479cf4057d	application of frequency shifting in in-car communication systems		A known approach for stabilizing acoustic feedback loops is to include time-varying processing in the signal path. Therefore, we present a subband-based implementation of a phase modulation filter that allows arbitrary frequency shifts, comment on some limitations of the method, and discuss practical implementation aspects. Listening tests are conducted in order to derive the parameter range in which the introduced frequency shift is not audible to listeners. Special test scenarios are set up to cover the intended use of the algorithm in an in-car communication (ICC) system and confirm that background noise and the direct speech components are masking the frequency shift to some extent. Experiments with an ICC system in a test car show that persistent howling occurs only after considerable increase of the system gain, but also strong artifacts are introduced. This leads to the conclusion that in the ICC context, the proposed method is particularly suited for signal decorrelation which is an important part of techniques for feedback prevention.		Jochen Withopf;Sebastian Rohde;Gerhard Schmidt	2014			electronic engineering;telecommunications;computer science;communication	OS	84.90052322961161	-32.170908228924795	181773
82db1b0f246a712d1024450853bf9414d8024767	spotforming: spatial filtering with distributed arrays for position-selective sound acquisition	source extraction;spaced microphones spatial filtering distributed arrays position selective sound acquisition hands free capture spot of interest soi power spectral density psd matrices time varying psd matrices near field propagation model suboptimal filters speech signal extraction;signal detection source extraction distributed arrays spatial filtering psd matrix estimation;signal detection;speech processing bayes methods matrix algebra microphones spatial filters;psd matrix estimation;speech acoustics ieee transactions speech processing microphone arrays detectors;spatial filtering;distributed arrays	Hands-free capture of speech often requires extraction of sources from a certain spot of interest (SOI), while reducing interferers and background noise. Although state-of-the-art spatial filters are fully data-dependent and computed using the power spectral density (PSD) matrices of the desired and the undesired signals, the existing solutions to extract sources from a SOI are only partially data-dependent. Estimating the time-varying PSD matrices from the data is a challenging problem, especially in dynamic and quickly time-varying acoustic scenes. Hence, the spot signal statistics are often pre-computed based on a near-field propagation model, resulting in suboptimal filters. In this work, we propose a fully data-dependent spatial filtering framework for extraction of speech signals that originate from a SOI. To achieve position-based spatial selectivity, distributed arrays are used, which offer larger spatial diversity compared to arrays of closely spaced microphones. The PSD matrices of the desired and the undesired signals are updated at each time-frequency bin by using a minimum Bayes risk detector that is based on a probabilistic model of narrowband position estimates. The proposed framework is applicable in challenging multitalk situations, without requiring any prior information, except the geometry, location, and orientation of the arrays.	acoustic cryptanalysis;data dependency;detection theory;interference (communication);low-rank approximation;microphone;precomputation;selectivity (electronic);software propagation;sparse matrix;spectral density;statistical model	Maja Taseska;Emanuel A. P. Habets	2016	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2016.2540815	speech recognition;spatial filter;detection theory	ML	83.69354942290832	-36.68892518364818	182247
505a429417ff37732c938f388998165082c1ff80	improving power spectral density estimation of unmanned aerial vehicle rotor noise by learning from non-acoustic information		A method to accurately estimate an unmanned aerial vehicle's (UAV) rotor noise power spectral density (PSD) is proposed, as part of the development of an effective UAV-mounted audio recording system that clearly captures the desired sound signals. Based on a previous study, the method seeks to improve rotor noise PSD estimation accuracy and robustness by utilising UAV rotor characteristics and microphone signals. Simulation results showed PSD estimation accuracy to within 1.3-3.3 dB log spectral distortion regardless of the presence of surrounding sound sources.	acoustic fingerprint;aerial photography;distortion;microphone;noise power;r.o.t.o.r.;simulation;spectral density estimation;unmanned aerial vehicle	Benjamin Yen;Hisashi Uematsu;Brian R. Mace	2018	2018 16th International Workshop on Acoustic Signal Enhancement (IWAENC)	10.1109/IWAENC.2018.8521324	rotor (electric);robustness (computer science);acoustics;microphone;noise power;spectral density;sound recording and reproduction;distortion;computer science	Robotics	85.3009998198112	-38.968934066018555	182749
daa3875517fc99c1748b79252b340e77f7913e03	improved angular resolution for spatial smoothing techniques	and forward;array signal processing;covariance matrices;array covariance matrices doa estimation direction of arrival estimation forward backward technique forward only technique array processing angular resolution spatial smoothing techniques coherent arrivals coherent signals;spatial resolution smoothing methods sensor arrays covariance matrix signal resolution narrowband direction of arrival estimation apertures degradation approximation methods	Spatial smoothing techniques are used to estimate the directions of coherent arrivals. The performance of these techniques deteriorates rapidly as the coherent arrivals become closely spaced. In this correspondence, we examine the resolution performance of the existing forward-only and forwardlbackward spatial smoothing techniques. We also show that the resolution for coherent signals can be improved by squaring array covariance matrices before forming smoothed array covariance matrices.	angularjs;coherence (physics);n-gram;numerical integration;smoothing	Jian Li	1992	IEEE Trans. Signal Processing	10.1109/78.175754	econometrics;statistics	Vision	86.31845970564986	-38.20918582170944	182832
40085832aa1ae01f29719eba372aa2085c0aa4f8	acoustic-based passive pointing system for distant screens	microphones;frequency 18 khz to 24 khz acoustic based passive pointing system distant large screens acoustic position estimation technology gravity sensor smartphone television set loudspeakers microphone pitch angle digital signage;acoustic position measurement;acoustics;gravity;smart phones;delay effects;acoustic signal processing;acoustic application;radionavigation;accuracy;delay estimation acoustic application acoustic position measurement;estimation;loudspeakers;microphones loudspeakers acoustics estimation gravity accuracy delay effects;smart phones acoustic signal processing large screen displays loudspeakers pointing systems radionavigation;large screen displays;pointing systems;delay estimation	This paper presents a passive pointing system for a distant screen based on an acoustic position estimation technology in conjunction with a gravity sensor on a smartphone. The system is designed to interact with a distant large screen such as a television set at home or digital signage in public. The system consists of a screen, two loudspeakers set around the screen, and a smartphone as a pointing device having a microphone and a gravity sensor inside. The position of the pointer is theoretically determined by the position and direction. This smartphone-based system approximates the position and direction by the two-dimensional position of the microphone horizontally and the pitch angle from the gravity sensor vertically. In this paper, we report experiments to evaluate the performance of the system. The loudspeakers of the system radiate burst signal from 18 to 24 kHz. The position of the smartphone is estimated at a frame rate of 15 Hz with a latency of 0.4 second. The accuracy of the pointer was measured as an angle error below 10 degrees for 100% of all frames. We confirmed that it has enough accuracy to point to each region which is divided area in the screen for applications such as quiz or questionnaire on digital signage.	acoustic cryptanalysis;digital signage;experiment;loudspeaker;microphone;pointer (computer programming);pointing device;radiate;smartphone;television set	Toshiharu Horiuchi;Shinya Takayama;Tsuneo Kato	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6288222	loudspeaker;estimation;speech recognition;gravity;position sensor;mathematics;accuracy and precision;statistics	Mobile	87.18308139024208	-35.15876115619236	183204
f7bf5cddb0150a0b779786de6dc2d7fb5935cc0f	estimating synchronization signal phase	digital watermarking;data processing;distortion	To read a watermark from printed images requires that the watermarking system read correctly after affine distortions. One way to recover from affine distortions is to add a synchronization signal in the Fourier frequency domain and use this synchronization signal to estimate the applied affine distortion. Using the Fourier Magnitudes one can estimate the linear portion of the affine distortion. To estimate the translation one must first estimate the phase of the synchronization signal and then use phase correlation to estimate the translation. In this paper we provide a new method to measure the phase of the synchronization signal using only the data from the complex Fourier domain. This data is used to compute the linear portion, so it is quite convenient to estimate the phase without further data manipulation. The phase estimation proposed in this paper is computationally simple and provides a significant computational advantage over previous methods while maintaining similar accuracy. In addition, the phase estimation formula gives a general way to interpolate images in the complex frequency domain.	analog television;computation;digital watermarking;distortion;interpolation;phase correlation;printing;quantum phase estimation algorithm	Robert G. Lyons;John D. Lord	2015		10.1117/12.2083390	computer vision;distortion;data processing;telecommunications;digital watermarking;computer science;theoretical computer science	Robotics	87.44699587480623	-33.870339362452114	184577
2f9077a95724ba888e14c648d896ba55331ab911	a remote identification system based on passive identifiers	teledetection;description systeme;system description;alarm;magnetic field;quartz;radiation detection;ruido;campo magnetico;cuarzo;passive tagging;deteccion a distancia;detection rayonnement;champ magnetique;marcacion;remote sensing;identification;alarme;bruit;marquage;quartz crystals;identificacion;descripcion sistema;coded labels;alarma;deteccion radiacion;noise;tagging	Abstract   A system is presented that enables automatic remote identification of persons or goods using tagging with passive devices. A well-defined area is interrogated by a magnetic field that is periodically switched on and off. Presence of a tagged object is detected and its identity established by measuring the natural response of the tag during the transmission silence. The tag or identifier consists of a main resonant circuit, the coil of which provides magnetic coupling, and several quartz crystals that determine its identity. High reliability and insensitivity to interference are ensured due to the high quality factors involved. The use of passive identifiers provides a robust and low-cost system that can serve in a wide range of applications.	identifier	H. J. Butterweck;A. C. P. van Meer;Jean H. F. Ritzerfeld	1992	Signal Processing	10.1016/0165-1684(92)90121-C	identification;magnetic field;telecommunications;noise;particle detector	ML	92.28894954730575	-25.130771392515452	184847
c8d28870fd3c70c88c04bd4ef8a65cf3211ddc86	design and implementation of a microphone array system with flexible array geometry	microphones;acoustics;array signal processing;arrays;arrays microphones conferences array signal processing acoustics matlab;matlab;conferences	In this paper, a microphone array system capable of real-time capture of distant sound or speech with the help of large aperture microphone arrays will be discussed. The system consists of a platform for the placement of microphones, a multi channel signal processing unit, microphone PCBs, and a control (and user) computer. The platform with the dimensions of 2m √ó 2m let the placement of any 1D and 2D microphone arrays with maximum number of 3000 microphones. It has the ability of rotation in azimuth and elevation. The system has the hardware and firmware background to form five beams in the directions of five different angles at the same time. The system is tested using a 1D linear array and a 2D randomly placed array and the source separation is achieved using beamforming. The results of this work are also reported in the paper.	beamforming;firmware;microphone;printed circuit board;randomness;real-time clock;signal processing;source separation	H. Agirman;S. Karakutuk;E. Gonendik	2014	2014 22nd Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2014.6830664	phantom power;speech recognition;noise-canceling microphone;sensor array	Robotics	87.06251218649888	-35.5868742573775	185331
781ac3172cc626ad53bf4d79e2d71b940a3dc953	separation of speech sources using an acoustic vector sensor	perceptual quality;speech separation;bepress selected works;real time;speech processing;speech processing acoustic transducers direction of arrival estimation sensor arrays source separation;speech;perceptual evaluation of speech quality;signal to interference ratio;time frequency analysis speech microphones source separation direction of arrival estimation arrays force;separation;using;sensor;separation speech sources using acoustic vector sensor;listening tests acoustic vector sensor directional characteristics frequency domain direction of arrival estimation real time speech source separation perceptual evaluation of speech quality;mean opinion score;acoustic;vector;sources;frequency domain;source separation;sensor arrays;acoustic transducers;acoustic vector sensor;direction of arrival estimation	This paper investigates how the directional characteristics of an Acoustic Vector Sensor (AVS) can be used to separate speech sources. The technique described in this work takes advantage of the frequency domain direction of arrival estimates to identify the location, relative to the AVS array, of each individual speaker in a group of speakers and separate them accordingly into individual speech signals. Results presented in this work show that the technique can be used for real-time separation of speech sources using a single 20ms frame of speech, furthermore the results presented show that there is an average improvement in the Signal to Interference Ratio (SIR) for the proposed algorithm over the unprocessed recording of 15.1 dB and an average improvement of 5.4 dB in terms of Signal to Distortion Ratio (SDR) over the unprocessed recordings. In addition to the SIR and SDR results, Perceptual Evaluation of Speech Quality (PESQ) and listening tests both show an improvement in perceptual quality of 1 Mean Opinion Score (MOS) over unprocessed recordings.	acoustic cryptanalysis;algorithm;direction of arrival;distortion;etsi satellite digital radio;interference (communication);pesq;real-time clock	Muawiyath Shujau;Christian Ritz;Ian S. Burnett	2011	2011 IEEE 13th International Workshop on Multimedia Signal Processing	10.1109/MMSP.2011.6093797	mean opinion score;speech recognition;signal-to-interference ratio;vector;computer science;sensor;speech;speech processing;frequency domain	Arch	84.31431140599035	-35.622650708724215	186153
ad1d4cd4f20afe795cb1d5a34a0549a194b3e1ee	geometrically constrained trinicon-based relative transfer function estimation in underdetermined scenarios	voice activity control relative transfer function estimation speech extraction linearly constrained minimum variance beamformer lcmv beamformer rtf estimation geometrically constrained concept gc trinicon concept multiple speaker scenarios microphone signals coarse reference information direction of arrival doa;transfer functions;estimation speech noise microphones direction of arrival estimation acoustics barium;relative transfer function estimation blind source separation bss linearly constrained minimum variance lcmv generalized sidelobe canceller gsc;geometry;array signal processing;speech enhancement;direction of arrival estimation;transfer functions array signal processing direction of arrival estimation geometry speech enhancement	Speech extraction in a reverberant enclosure using a linearly-constrained minimum variance (LCMV) beamformer usually requires reliable estimates of the relative transfer functions (RTFs) of the desired source to all microphones. In this contribution, a geometrically constrained (GC)-TRINICON concept for RTF estimation is proposed. This approach is applicable in challenging multiple-speaker scenarios and in underdetermined situations, where the number of simultaneously active sources outnumbers the number of available microphone signals. As a most practically relevant and distinctive feature, this concept does not require any voice-activity-based control mechanism. It only requires coarse reference information on the target direction of arrival (DoA). The proposed GC-TRINICON method is compared to a recently proposed subspace method for RTF estimation relying on voice-activity control. Experimental results confirm the effectiveness of GC-TRINICON in realistic conditions.	beamforming;direction of arrival;garbage collection (computer science);microphone;transfer function;video camera tube	Klaus Reindl;Shmulik Markovich Golan;Hendrik Barfuss;Sharon Gannot;Walter Kellermann	2013	2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics	10.1109/WASPAA.2013.6701822	electronic engineering;speech recognition;acoustics;mathematics;transfer function	Vision	85.07027882865407	-36.14489567036362	186596
4793ee45a551adc3b868b3827818251ce501230d	fast target classification using sonar	target classification;two dimensions;real time;ultrasonic transducers;maximum likelihood estimation;sonar target recognition;maximum likelihood estimate;transmitters interference maximum likelihood estimation delay sonar measurements coordinate measuring machines intelligent robots robot sensing systems digital signal processing hardware;pattern classification;on the fly;echo;encoding pattern classification sonar target recognition echo maximum likelihood estimation ultrasonic transducers;encoding;maximum likelihood estimation sonar target localisation echoes double pulse coding pattern classification sensing module	This paper describes a new sonar system that can perform target localisation in two dimensions and classification into planes, concave corners and convex edges with no extra time overhead. That is, the sensor transmits on two transmitters a short time apart, thereby collecting echoes in virtually the same time as a single transmitter system. Moreover, the time separation of the transmitted pulses acts to identify the particular sonar system so that interference from other systems can be rejected. The sensor combines two previous sonar research efforts on double pulse coding [2] and classification [1] in a real time DSP based sensing module that is also smaller than previous sensors. Since the classification is performed with such a short delay between transmitter firings, the sensor could be deployed on moving platforms to achieve on-the-fly mapping. This paper describes the sonar hardware, the Maximum Likelihood Estimation (MLE) classification approach and experimental results.	armstrong's axioms;concave function;digital signal processing;digital signal processor;interference (communication);overhead (computing);real-time computing;rejection sampling;sonar (symantec);sensor;statistical classification;technical support;transducer;transmitter	Andrew Heale;Lindsay Kleeman	2001		10.1109/IROS.2001.977184	computer vision;synthetic aperture sonar;electronic engineering;speech recognition;engineering;maximum likelihood;statistics	Robotics	85.83682739287507	-41.70760555588048	186743
c252ff8b751f8cdec43b46fd311b24f3ce5711be	experimental study of dual microphone systems	fuses;noise cancellation;cardiology;sun;signal to noise ratio;noise reduction	In this paper, we compare and evaluate the various noise cancellation schemes available in what we term a dual microphone system. A dual microphone system (DMS) is a composite directional audio-capturing device which consists of two microphones, each microphone having possibly different directional characteristics, e.g., omnidirectional, bidirectional or cardioid. By recasting the various combinations of two microphones for a DMS into a coherent and familiar framework of generalized sidelobe canceller (GSC), we subsequently derive the expected noise reduction of various structures under incoherent, coherent and diffuse noise fields, followed by a series of experiments in a typical office environment. These results are indicative of the achievable reduction of noise in real applications. The relationship and differences between the various methods are also discussed	bi-directional text;coherence (physics);experiment;gsc bus;microphone;noise reduction	Jianfeng Chen;Louis Shue;Koksoon Phua;Hanwu Sun	2004	2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)		fuse;computer vision;telecommunications;noise-canceling microphone;computer science;active noise control;noise reduction;signal-to-noise ratio	Robotics	88.13781999598213	-35.49490875881543	187869
e349ac193c912cb2643d27980f3ba1f4b6356e60	population-split genetic algorithm for retrieval of ultrafast laser parameters	frequency resolved optical gating;genetic algorithm;pulse retrieving;ultrafast lasers	Authors modify the traditional or standard genetic algorithm by splitting the initial population. This crucial step is an imitation of sexual and asexual reproduction mechanism in the life cycle of many plants or animals. Asexual reproduction shall happen in only one population, which is fitter of the two. This evolution guarantees that the converging direction can be controlled properly. This technique is proposed and used to deal with complicated and noisy spectrograms generated by a Frequency Resolved Optical Gating (FROG) apparatus for characterization of ultrafast laser pulses. The results show that this technique can more easily retrieve complex laser pulse parameters than previous approaches.	genetic algorithm	S. F. Shu;C. L. Pan;C. T. Sun	2003	Neural Parallel & Scientific Comp.		biology;electronic engineering;optics;communication	NLP	88.95466798340442	-29.969855803628633	187954
a84acdd249c617b9d292398c46787ce3f96a4b9e	a minimum variance partially distortionless response filter for single-channel noise reduction		This paper deals with the problem of single-channel noise reduction. Thanks to the eigenvalue decomposition, we arrange the eigenvalues of the speech correlation matrix in such a way that all the spectral mode signal-to-noise ratios (SNRs) of the noisy speech are ordered in a descending manner. By maintaining no speech distortion in the spectral modes with high input SNRs while allowing some degree of speech distortion in the modes with low input SNRs, we develop a minimum variance partially distortionless response (MVPDR) filter. We first formulate the problem and derive this filter within the general filtering framework. Then, the MVPDR filter is applied to the single-channel noise reduction problem in both the time and time-frequency domains. In comparison with the minimum variance distortionless response (MVDR) filter based on the subspace decomposition, the developed MVPDR filter can provide much more freedom for controlling the compromise between noise reduction and speech distortion to achieve higher speech quality. Simulations are conducted and preliminary results justify the advantages of the deduced MVPDR filter.	channel (communications);computer simulation;distortion;finite impulse response;noise (electronics);noise reduction;signal-to-noise ratio	Xianghui Wang;Jingdong Chen;Jacob Benesty	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7953101	algorithm;artificial intelligence;salt-and-pepper noise;filter (signal processing);root-raised-cosine filter;covariance matrix;noise measurement;distortion;pattern recognition;noise reduction;speech recognition;signal-to-noise ratio;mathematics	Robotics	83.59415068358861	-35.13969653584521	187984
dead1c496873edbb84ae35d68ee21f9887890c80	estimation of time-varying room impulse responses of multiple sound sources from observed mixture and isolated source signals		This paper proposes a method for online estimation of time-varying room impulse responses (RIR) between multiple isolated sound sources and a far-field mixture. The algorithm is formulated as adaptive convolutive filtering in short-time Fourier transform (STFT) domain. We use the recursive least squares (RLS) algorithm for estimating the filter parameters due to its fast convergence rate, which is required for modeling rapidly changing RIRs of moving sound sources. The proposed method allows separation of reverberated sources from the far-field mixture given that their close-field signals are available. The evaluation is based on measuring unmixing performance (removal of reverberated source) using objective separation criteria calculated between the ground truth recording of the preserved sources and the unmixing result obtained with the proposed algorithm. We compare online and offline formulations for the RIR estimation and also provide evaluation with blind source separation algorithm only operating on the mixture signal.	algorithm;blind signal separation;ground truth;online and offline;rate of convergence;recursion;recursive least squares filter;short-time fourier transform;source separation	Joonas Nikunen;Tuomas Virtanen	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8462535	mathematical optimization;fourier transform;rate of convergence;time‚Äìfrequency analysis;blind signal separation;recursive least squares filter;short-time fourier transform;computer science;reverberation;filter (signal processing)	Vision	83.50706051308828	-35.52080619769571	188056
29bc51add37a46d0063762c97ce6b5c96f394629	three-dimensional digital waveguide mesh simulation of cylindrical vocal tract analogs	speech synthesis;acoustics;solid modeling acoustic measurements resonant frequency frequency measurement apertures acoustic waveguides;frequency measurement;time domain analysis;waveguide theory;resonant frequency;solid modeling;speech synthesis three dimensional digital waveguide mesh simulation cylindrical vocal tract analogs 3d time domain acoustic modeling techniques 1d solutions 2d solutions human voice variability problematic benchmark acrylic cylindrical vocal tract model acoustic measurement x ray data resonant frequencies;waveguide theory speech synthesis time domain analysis;human voice;acoustic measurements;speech synthesis acoustics human voice;acoustic waveguides;apertures	3D time-domain acoustic modeling techniques have the potential to produce more accurate simulation of the vocal tract than previously implemented 1D or 2D solutions, although the variability of human voice renders it a problematic benchmark for validation of its resynthesis. This study uses acoustic measurement of acrylic cylindrical vocal tract models derived from X-Ray data to assess the validity of comparable 3D digital waveguide mesh simulations. It is found that for more simple structures the 3D digital waveguide mesh is able to reproduce the acoustic behavior up to 10 kHz with only slight errors in resonant frequencies. As the simulated structures become more geometrically complex, this shifting becomes more severe.	acoustic cryptanalysis;acoustic model;benchmark (computing);concatenation;numerical analysis;rendering (computer graphics);sampling (signal processing);simulation;spatial variability;tract (literature);volatility	Matt Speed;Damian T. Murphy;David M. Howard	2013	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2012.2224342	waveguide;aperture;speech recognition;human voice;acoustics;resonance;solid modeling;speech synthesis	Visualization	87.16954031493614	-32.89686500087842	188247
3739b8f790ad5761ff286c264bf23cfb896a7ac6	research of an electric laser system based on the non-diffracting beam	tunnel boring machine;non diffracting beam;digital image processing;image processing;attitude angle measurement;electronic laser system	A novel electronic laser system is proposed. Based on the principle of the non-diffracting beam, a new method for measuring attitude angle has been developed in this paper, in combination with image processing technology. The system constitution and the measuring principle of the electronic laser system are introduced. As the non-diffracting beam is composed of Bessel fringe ring, the anti-interference ability and the measurement sensitivity is greatly improved by center location of the non-diffracting beam in digital image processing technology, compared with barycenter method. The electronic laser system is applicable to attitude angle measurement of the tunnel boring machine in tunnel construction and other similar occasions.		Hui Chen;Bin Zhao	2009		10.1007/978-3-642-10817-4_33	structural engineering;computer vision;electronic engineering;laser beam quality;image processing;computer science;engineering;digital image processing;beam parameter product	Robotics	89.3658097947285	-24.633090215493535	188495
a4ab6d80f033a2b79891ae7322a3e223708b0432	single acoustic-channel speech enhancement based on glottal correlation using non-acoustic sensor		This paper describes a single acoustic‚Äìchannel speech enhancement, utilizing an auxiliary non-acoustic sensor. Unlike classical algorithms, which make use of the knowledge from acoustic signal alone, the glottal correlation (GCORR) algorithm takes advantage of non-acoustic throat sensors such as the general electromagnetic motion sensor (GEMS). The non‚Äìacoustic sensor provides a measure of the glottal excitation function that is relatively immune to background acoustic noise. Thus, inspired by human speech production mechanisms, the GCORR algorithm extracts the desired speech signal from noisy acoustic mixture using statistical correlation between the speech and its excitation. The algorithm leads to a significant reduction of wide‚Äìband noise, even when the SNR is very low. The improvement in the quality of the speech is demonstrated in terms of an objective evaluation.	acoustic cryptanalysis;algorithm;motion detector;sensor;signal-to-noise ratio;speech enhancement	Rongqiang Hu;David V. Anderson	2004			speech recognition;excitation function;noise;excitation;correlation;computer science;speech enhancement;communication channel;speech production	AI	84.52548959736158	-35.23017725117863	189645
a6d266e6096269e14b483995d00e4d6938a5369d	a deconvolution method for the characterization of distributed sources via linear prediction	correlation;estimation;prediction algorithms;deconvolution	This paper deals with high resolution bearing estimation in urban radiocommunication scenarii. Indeed, in such environments, scatterers local to the emitter engender diffuse paths that deteriorate the performances of conventional subspace-based algorithms. A deconvolution technique, involving Linear Prediction methods, is designed to characterize so called distributed sources by returning the mean angle and the angular spreading of the signal angular power density. Two ways of implementation are proposed in two extreme cases of diffuse paths correlations. Simulation results show that this proposed method provides satisfaying results compared to the Cramer Rao-Bound and moreover outperform more famous subspace-based algorithms.	algorithm;angularjs;call of duty: black ops;deconvolution;direction of arrival;image resolution;kerrison predictor;lambert's cosine law;performance;simulation;stationary process	Thouraya Abdellatif;Pascal Larzabal;Henri Clergeot	2000	2000 10th European Signal Processing Conference		econometrics;mathematical optimization;mathematics;blind deconvolution;statistics	EDA	85.29747971695919	-45.0459304410331	189805
228193b78a2306c4cd272e7bba94f56e831d0dfb	simple detector of pulse wave beats	detectors band pass filters interference noise uncertainty power harmonic filters;detectors;band pass filters;uncertainty;interference;uncertainty pulse wave fiducial point detection;power harmonic filters;pulse wave signal beat point detection nonlinear transformations adaptive threshold;medical signal processing bioelectric potentials medical signal detection;noise	Various methods for detecting the fiducial points of the pulse wave signals are discussed. A new simple detector of the fiducial points based on the application of the first derivative operator, set of nonlinear transformations and adaptive threshold is described. The efficiency of various detectors of the beat points of pulse wave signal in the presence of interferences of various origins and intensities was estimated. It is demonstrated that the suggested detector provides the minimum level of uncertainty in the determining time position of pulse wave beats.	fiducial marker;nonlinear system;preprocessor;probabilistic turing machine;sensor	Aleksandr A. Fedotov;Sergey A. Akulov	2014	2014 7th International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2014.7002803	detector;uncertainty;acoustics;computer science;noise;band-pass filter;interference;optics;pulse wave;physics;statistics	Robotics	83.35744372673098	-40.06254491112306	190504
38ed732b8a1fe44dfdd889c849af3357e61e7bd6	continuous transmission frequency modulation detection under variable sonar-target speed conditions	deviation;ultrasonic ranging sensor;correction;motion;doppler effect;sound;ctfm;doppler shift;humans;ultrasonics;range profile	As a ranging sensor, a continuous transmission frequency modulation (CTFM) sonar with its ability for range finding and range profile formation works effectively under stationary conditions. When a relative velocity exists between the target and the sonar, the echo signal is Doppler-shifted. This situation causes the output of the sensor to deviate from the actual target range, thus limiting its applications to stationary conditions only. This work presents an approach for correcting such a deviation. By analyzing the Doppler effect during the propagation process, the sensor output can be corrected by a Doppler factor. To obtain this factor, a conventional CTFM system is slightly modified by adding a single tone signal with a frequency that locates out-of-sweep range of the transmitted signal. The Doppler factor can be extracted from the echo. Both verification experiments and performance tests are carried out. Results indicate the validity of the proposed approach. Moreover, ranging precision under different processing setups is discussed. For adjacent multiple targets, the discrimination ability is influenced by displacement and velocity. A discrimination boundary is provided through an analysis.	displacement mapping;doppler effect;embedded system;embedding;experiment;fast fourier transform;feature extraction;flaw hypothesis methodology;matching;modulation;nyquist‚Äìshannon sampling theorem;online and offline;psychologic displacement;real-time clock;real-time computing;requirement;sonar (symantec);sampling (signal processing);sampling - surgical action;scott continuity;selective calling;sensor;software propagation;stationary process;synaptic transmission;ultrasonics (sound);velocity (software development);verification of theories;disease transmission;subsection - htmllinktype;transmission process	Yang Wang;Jun Yang	2013		10.3390/s130303549	electronic engineering;acoustics;doppler effect;telecommunications;engineering;physics;quantum mechanics	Robotics	85.0722742923003	-39.85441360770107	191396
c56f8c297aad7b64325958eb1a0406ce29b1f33f	influence of light scattering in colorant layers on reflection spectra of tertiary color images	light scattering;color image		rca spectra 70	Osamu Ide	2001			spectral color;spectral line;color image;light scattering;physics;optics	Vision	83.51784631558361	-47.24005864327156	191602
59b19c8839158070a09d32b218434dd64dd6f177	multiple source localization using estimation consistency in the time-frequency domain		The extraction of multiple Direction-of-Arrival (DoA) information from estimated spatial spectra can be challenging when such spectra are noisy or the sources are adjacent. Smoothing or clustering techniques are typically used to remove the effect of noise or irregular peaks in the spatial spectra. As we will explain and show in this paper, the smoothing-based techniques require prior knowledge of minimum angular separation of the sources and the clustering-based techniques fail on noisy spatial spectrum. A broad class of localization techniques give direction estimates in each Time Frequency (TF) bin. Using this information as input, a novel technique for obtaining robust localization of multiple simultaneous sources is proposed using Estimation Consistency (EC) in the TF domain. The method is evaluated in the context of spherical microphone arrays. This technique does not require prior knowledge of the sources and by removing the noise in the estimated spatial spectrum makes clustering a reliable and robust technique for multiple DoA extraction from estimated spatial spectra. The results indicate that the proposed technique has the strongest robustness to separation with up to 10¬∞ median error for 5¬∞ to 180¬∞ separation for 2 and 3 sources, compared to the baseline and the state-of-the-art techniques.	angularjs;baseline (configuration management);cluster analysis;consistency model;direction of arrival;microphone;smoothing	Sina Hafezi;Alastair H. Moore;Patrick A. Naylor	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7952209	spectral line;robustness (computer science);mathematical optimization;artificial intelligence;bin;statistics;cluster analysis;pattern recognition;smoothing;microphone;noise measurement;time‚Äìfrequency analysis;mathematics	Vision	83.9550694328961	-36.870349227892234	191737
80b5942671ce0d4c3e9e67310f400ada754505e2	a simple adaptive filtering technique for speech enhancement	signal generators;transfer functions;speech analysis;prediction algorithms;noise generators;speech enhancement;adaptive filters speech enhancement speech analysis prediction algorithms signal generators transfer functions noise generators statistics decorrelation delay;adaptive filters;statistics;decorrelation;adaptive filter	A simple technique for speech enhancement has been developed which does not require that speech and noise inputs be available separately. An adaptive predictor DPCM algorithm is used to derive the reference input to an adaptive filter. The DPCM algorithm generates a signal which is correlated with the original speech waveform but uncorrelated with the noise. The system has been shown to enhance perceptual speech quality, particularly at low input SNRs.	adaptive filter;algorithm;kerrison predictor;speech enhancement;waveform	L. William Varner;Thomas A. Miller;Thomas E. Eger	1983		10.1109/ICASSP.1983.1171956	adaptive filter;computer vision;speech recognition;computer science;speech coding;speech processing;mathematics;statistics	ML	82.9285704001207	-32.57668350432335	192046
4db0aed34873127abfd8706bd0070ef33a932d90	tracking wide-band rapidly moving targets	maximum likelihood;gaussian processes;target tracking doppler shift gaussian processes maximum likelihood estimation particle filtering numerical methods;supersonic source wide band rapidly moving target tracking doppler shift beam forming techniques hessian likelihood function maximum likelihood solution gaussian approximation particle filtering applications subsonic source;hessian likelihood function;target tracking wideband doppler shift sensor arrays narrowband frequency acoustic beams degradation gaussian approximation filtering;wide band rapidly moving target tracking;maximum likelihood estimation;supersonic source;gaussian approximation;particle filter;maximum likelihood solution;subsonic source;particle filtering applications;doppler shift;beam forming techniques;target tracking;likelihood function;particle filtering numerical methods	A method is derived for passively locating wide-band targets (typically acoustic targets) which may be moving at speeds sufficient to produce significant Doppler shift. The method involves a generalisation of standard beam forming techniques. It is shown that conventional beam forming techniques have less discrimination in the direction of motion of the sources, whereas the proposed technique exhibits no such degradation. The derivative and Hessian of the likelihood function can be used for locating the maximum likelihood solution or for deriving a Gaussian approximation to the likelihood function for particle filtering applications. The expressions are applicable for subsonic and supersonic sources	acoustic cryptanalysis;approximation;beamforming;doppler effect;elegant degradation;hessian;particle filter;subsonic	Paul D. Teal	2006	2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings	10.1109/ICASSP.2006.1661117	mathematical optimization;control theory;mathematics;maximum likelihood;statistics	Robotics	86.11901219800544	-37.605380946517506	192131
0b6f646b032e835f392ca158dcdac2973cb567d1	reverberant sound localization with a robot head based on direct-path relative transfer function	microphones;transfer functions;acoustics;speech;binaural hearing;robots;sound source localization;mathematical model;time frequency analysis	This paper addresses the problem of sound-source localization (SSL) with a robot head, which remains a challenge in real-world environments. In particular we are interested in locating speech sources, as they are of high interest for human-robot interaction. The microphone-pair response corresponding to the direct-path sound propagation is a function of the source direction. In practice, this response is contaminated by noise and reverberations. The direct-path relative transfer function (DP-RTF) is defined as the ratio between the direct-path acoustic transfer function (ATF) of the two microphones, and it is an important feature for SSL. We propose a method to estimate the DP-RTF from noisy and reverberant signals in the short-time Fourier transform (STFT) domain. First, the convolutive transfer function (CTF) approximation is adopted to accurately represent the impulse response of the microphone array, and the first coefficient of the CTF is mainly composed of the direct-path ATF. At each frequency, the frame-wise speech auto- and cross-power spectral density (PSD) are obtained by spectral subtraction. Then a set of linear equations is constructed by the speech auto- and cross-PSD of multiple frames, in which the DP-RTF is an unknown variable, and is estimated by solving the equations. Finally, the estimated DP-RTFs are concatenated across frequencies and used as a feature vector for SSL. Experiments with a robot, placed in various reverberant environments, show that the proposed method outperforms two state-of-the-art methods.	acoustic cryptanalysis;approximation;charge trap flash;coefficient;concatenation;feature vector;human‚Äìrobot interaction;linear equation;microphone;robot;short-time fourier transform;software propagation;spectral density;stellar classification;transfer function	Xiaofei Li;Laurent Girin;Fabien Badeig;Radu Horaud	2016	2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2016.7759437	robot;speech recognition;time‚Äìfrequency analysis;acoustics;sound localization;computer science;engineering;speech;mathematical model;transfer function;acoustic source localization	Robotics	85.93636296523994	-35.73493636517683	192703
6880bc917f29007bab244eec048d84e91bc12fb4	an adaptive microphone array with good sound quality using auxiliary fixed beamformers and its dsp implementation	microphones;sound quality;digital signal processing;speech intelligibility;hysteresis;signal direction;frequency response digital signal processing chips array signal processing direction of arrival estimation acoustic transducer arrays microphones adaptive signal processing speech intelligibility speech recognition voice communication;auxiliary fixed beamformers;microphone arrays adaptive arrays digital signal processing robustness interference hysteresis oral communication speech recognition frequency response attenuation;speech recognition rate;array signal processing;attenuation;directivity pattern;interference;target signal path;frequency response;sensitivity;adaptation mode control;dsp implementation;adaptive signal processing;speech communications;microphone array;voice communication;high frequency components;adaptive arrays;speech recognition;digital signal processing chips;robustness;speech communication;acoustic transducer arrays;microphone arrays;oral communication;high frequency;flat frequency response;total output;hysteresis elimination;adaptive microphone array;direction of arrival estimation;directivity pattern adaptive microphone array sound quality auxiliary fixed beamformers dsp implementation target signal path high frequency components total output adaptation mode control hysteresis elimination signal direction sensitivity speech intelligibility speech communications speech recognition rate flat frequency response	This paper presents an adaptive microphone array using two auxiliary fixed beamfomers for good sound quality. One auxiliary fixed beamfomer is introduced in the target signal path to avoid suppression of high-frequency components in the total output. The other auxiliary fixed beamfomer is used for adaptation-mode control to eliminate the hysteresis in the relationship between signal direction and sensitivity. Both auxiliary fixed beamfomers bring about good sound quality, which improve intelligibility in speech communications and speech recognition rate. The proposed microphone array is implemented on a DSP system, which demonstrates flat frequency response and less hysteresis in its directivity pattern.	digital signal processor;frequency response;hysteresis;intelligibility (philosophy);microphone;radiation pattern;sound quality;speech recognition;zero suppression	Osamu Hoshuyama;Akihiko Sugiyama	1999		10.1109/ICASSP.1999.759851	attenuation;adaptive filter;frequency response;speech recognition;sensitivity;hysteresis;computer science;speech;digital signal processing;high frequency;sound quality;interference;intelligibility;robustness	Robotics	84.6501300164116	-33.96442576955599	193134
d4cefe19e1b1817b332a64c30485b6619f8d1e02	broadband array of electromagnetic induction sensors for detecting buried landmines	single dipole transmit coil;metals;landmine detection;sensors;data collection;frequency 300 hz to 90 khz broadband electromagnetic induction sensors buried landmines detection metal clutter single dipole transmit coil quadrapole receive coils array frequency domain data collection;metal detector electromagnetic induction emi mine landmine;sensor arrays landmine detection electromagnetic induction electromagnetic interference coils prototypes detectors frequency domain analysis object detection buried object detection;shape;coils;emi;electromagnetic induction;buried landmines detection;metal clutter;broadband electromagnetic induction sensors;metal detectors electromagnetic induction geophysical equipment geophysical techniques landmine detection;metal detectors;electromagnetic interference;geophysical equipment;space frequency;mine;couplings;frequency domain;quadrapole receive coils array;frequency 300 hz to 90 khz;landmine;metal detector;geophysical techniques	A broadband electromagnetic induction (EMI) sensor is developed to help discriminate between buried landmines and metal clutter. The detector uses a single dipole transmit coil and an array of three quadrapole receive coils. The sensor operates in the frequency domain and collects data at 21 logarithmically spaced frequencies from 300 Hz to 90 kHz. Experimental results are presented for several targets.	clutter;emi;sensor	Waymond R. Scott	2008	IGARSS 2008 - 2008 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2008.4779006	electromagnetic induction;emi;electromagnetic interference;shape;sensor;coupling;frequency domain;physics;statistics;remote sensing;data collection	Embedded	83.32649548706816	-41.61799930521342	193188
dbf322f3aa7126cdfb6ce4a4edbcc2f2539b2ef1	estimation of the noise correlation matrix	microphones;voice activity detector;signalbehandling;multi microphone;speech;beamformer response error noise correlation matrix estimation multichannel noise reduction methods voice activity detector vad single channel noise psd estimators microphone pair segmental snr;matrix algebra;speech enhancement;correlation methods;single channel;estimation;signal processing;noise reduction;noise correlation matrix;multi microphone speech enhancement noise correlation matrix;discrete fourier transform;correlation;speech enhancement correlation methods matrix algebra signal denoising;signal to noise ratio;correlation matrix;discrete fourier transforms;correlation speech discrete fourier transforms estimation microphones signal to noise ratio;signal denoising	To harvest the potential of multi-channel noise reduction methods, it is crucial to have an accurate estimate of the noise correlation matrix. Existing algorithms either assume speech absence and exploit a voice activity detector (VAD), or make use of additional assumptions like a diffuse noise field. Therefore, these algorithms are limited with respect to their tracking speed and the type of noise fields for which they can estimate the correlation matrix. In this paper we present a new method for noise correlation matrix estimation that makes no assumptions about the type of noise field, nor uses a VAD. The presented method exploits the existence of accurate single-channel noise PSD estimators, as well as the availability of one noise reference per microphone pair. For spatially and temporally non-stationary noise fields, the proposed method leads to improved performance compared to widely used state-of-the-art reference methods in terms of both segmental SNR and beamformer response error.	algorithm;beamforming;microphone;noise (electronics);noise reduction;signal-to-noise ratio;stationary process;voice activity detection	Richard Christian Hendriks;Timo Gerkmann	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5947414	gradient noise;gaussian noise;computer vision;covariance matrix;estimation;speech recognition;value noise;computer science;noise measurement;speech;discrete fourier transform;signal processing;noise;noise reduction;mathematics;signal-to-noise ratio;correlation;statistics;salt-and-pepper noise	Robotics	83.40306542318405	-35.802692101516044	193614
abf63647a0d36d84b41b769ef0a24626263feaf1	color images visible under uv light	uv light;gamut mapping;high concentrate;spectrum;under uv light;color images;fluorescent ink images;3d representation;prediction model;fluorescent emission spectrum;juxtaposed halftoning;spectral prediction model;color image	The present contribution aims at creating color images printed with fluorescent inks that are only visible under UV light. The considered fluorescent inks absorb light in the UV wavelength range and reemit part of it in the visible wavelength range. In contrast to normal color printing which relies on the spectral absorption of light by the inks, at low concentration fluorescent inks behave additively, i.e. their light emission spectra sum up. We first analyze to which extent different fluorescent inks can be superposed. Due to the quenching effect, at high concentrations of the fluorescent molecules, the fluorescent effect diminishes. With an ink-jet printer capable of printing pixels at reduced dot sizes, we reduce the concentration of the individual fluorescent inks and are able to create from the blue, red and greenish-yellow inks the new colorants white and magenta. In order to avoid quenching effects, we propose a color halftoning method relying on diagonally oriented pre-computed screen dots, which are printed side by side. For gamut mapping and color separation, we create a 3D representation of the fluorescent ink gamut in CIELAB space by predicting halftone fluorescent emission spectra according to the spectral Neugebauer model. Thanks to gamut mapping and juxtaposed halftoning, we create color images, which are invisible under daylight and have, under UV light, a high resemblance with the original images.	color	Roger D. Hersch;Philipp Donz√©;Sylvain Chosson	2007	ACM Trans. Graph.	10.1145/1276377.1276471	spectrum;computer vision;color image;subtractive color;computer science;optoelectronics;machine learning;predictive modelling;optics;spectral color	Graphics	83.06399598731143	-47.40173840746228	193662
72493cedf042ad0e3e02f62e789369d8891ff988	a hybrid coherent-incoherent method of modulation filtering for single channel speech separation	filtering;speech separation affine projection coherent modulation filtering instantaneous frequency;speech separation;voiced speech separation hybrid coherent incoherent method modulation filtering single channel speech separation subband carrier time dependent spectral center of gravity demodulation interference signal elimination adaptive affine projection filter parallel incoherent system;affine projection;frequency modulation;speech processing;instantaneous frequency;speech;speech filtering interference adaptive filters frequency modulation signal to noise ratio;interference;adaptive filters;coherent modulation filtering;signal to noise ratio;speech processing modulation;modulation	Single Channel Speech Separation has been the objective of extensive research in recent years. In this paper, we propose a hybrid system of coherent and incoherent modulation filtering for separation of the target speech from the interference. In the proposed system, subband envelopes are determined using a coherently detected subband carrier based on the time-dependent spectral Center-Of-Gravity (COG) demodulation and then the interference signal is eliminated by applying the adaptive Affine Projection (AP) filter to the subband envelop. The reference signal for the adaptive AP filter is provided by a parallel incoherent system of modulation filtering. Our evaluations, based on several objective measures, indicate that the proposed system extracts the majority of target speech signal segments with minimal interference, outperforming previous systems in voiced speech separation.	adaptive filter;coherence (physics);experiment;holographic principle;hybrid system;interference (communication);modulation	Azar Mahmoodzadeh;Hamid Sheikhzadeh;Hamid Reza Abutalebi;Hamid Soltanian-Zadeh	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6287883	filter;frequency modulation;adaptive filter;instantaneous phase;speech recognition;telecommunications;computer science;speech;speech processing;mathematics;interference;signal-to-noise ratio;modulation	Robotics	83.82777099831584	-34.61090115538064	193722
5265983e222724890acbac42f6a09befd27f6d38	a real-time noise suppression filter for speech enhancement and robust channel vocoding	background noise;filter bank;spectral decomposition;real time;speech analysis;additive noise;noise suppression;speech enhancement;noise robustness;maximum likelihood estimate;channel bank filters;acoustic noise;vocoders;speech enhancement noise robustness acoustic noise background noise speech analysis vocoders filter bank channel bank filters real time systems additive noise;real time implementation;real time systems	A real time implementation of a system for enhancement of speech in additive acoustic noise is described. The technique used is to perform a spectral decomposition of noisy speech via channel vocoder filter bank analysis and to attenuate each spectral component depending on how much the measured speech plus noise power exceeds an estimate of the background noise. A two state model for the speech event (speech absent or speech present) is applied in determining the maximum likelihood estimator of the speech power. This model has resulted in a new class of suppression curves which permits a tradeoff of noise suppression against speech distortion. Experiments utilizing the real time implementation have shown that the noise can be made imperceptible by proper choice of the suppression factor. Integration of the noise suppression filter into the analysis section of a narrowband vocoder is described. This combined system represents an integrated robust vocoder structure where acoustic noise can be suppressed prior to pitch estimation and determination of the modulator gains.	real-time clock;speech enhancement;vocoder;zero suppression	Robert J. McAulay;Marilyn L. Malpass	1980		10.1109/ICASSP.1980.1170873	gradient noise;selectable mode vocoder;speech recognition;value noise;computer science;noise measurement;noise;filter bank;mathematics;background noise;maximum likelihood;noise floor;matrix decomposition;salt-and-pepper noise	Vision	83.03935418498232	-33.38123095457653	194499
1d488aca00727f6dbf5e5cf4af2e7fb7d121cd70	amplitude and phase estimator for real-time biomedical spectral doppler applications	blood flow apes dsp implementation sonogram spectral doppler;digital signal processing doppler effect sonogram spectrogram vectors real time systems;spectral analysis amplitude estimation biomedical ultrasonics blood flow measurement doppler effect fast fourier transforms phase estimation;fixed point dsp implementation amplitude and phase estimator apes real time biomedical spectral doppler application echo doppler investigation moving blood ultrasound energy doppler effect spectral estimator blood velocity assessment spectral analysis fast fourier transform fft good quality sonogram	In a typical echo-Doppler investigation the moving blood is periodically insonated by the transmitting bursts of ultrasound energy. The echoes, shifted in frequency according to the Doppler effect, are received, coherently demodulated and processed through a spectral estimator. The detected frequency shift can be exploited for blood velocity assessment. The spectral analysis is typically performed by the conventional Fast Fourier Transform (FFT), but, recently, the application of the Amplitude and Phase EStimator (APES) was proved to produce a good quality sonogram based on a reduced number of transmissions. Unfortunately, the much higher calculation effort needed by APES hampers its use in real-time applications. In this work, a fixed point DSP implementation of APES is presented. A spectral estimate - based on 32 transmissions - occurs in less than 120Œºs. Results obtained on echo-Doppler investigations on a volunteer are presented.	digital signal processor;doppler effect;fast fourier transform;fixed point (mathematics);real-time clock;spectral density estimation;transmitter;velocity (software development)	Stefano Ricci;Riccardo Matera;Alessandro Dallai	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6854584	telecommunications	Embedded	84.50874281759279	-40.38364481375705	194772
45cedf004287f5c5e419057f23606ed5407a72c5	improved bearing estimation in ocean by nonlinear wavelet denoising under non-gaussian noise conditions	mean square error methods;signal denoising;wavelet transforms;mse;music;snr;bearing estimation;mean square errors;median interpolation;nongaussian noise environment;nongaussian noise conditions;nonlinear wavelet denoising;passive localization;signal-to-noise ratio;subspace intersection method;underwater acoustic sources;wavelet transform	Bearing estimation of underwater acoustic sources is an important aspect of passive localization in the ocean. The performance of all bearing estimation techniques degrades under conditions of low signal-to-noise ratio (SNR) at the sensor array. The degradation may be arrested by denoising the array data before performing the task of bearing estimation. In the last few years, there has been considerable progress in the use of the wavelet transform for denoising signals. It is known that the traditional wavelet transform, which is a linear transformation, can be used for denoising signals in Gaussian noise; but this method is not suitable if the noise is strongly non-Gaussian. Statistical measurements of ocean acoustic ambient noise data indicate that the noise may have a significantly non-Gaussian heavy-tailed distribution in some environments. In this work, we have explored the possibility of employing nonlinear wavelet denoising [1, 2], a robust technique based on median interpolation, to improve the performance of bearing estimation techniques in ocean in a strongly non-Gaussian noise environment. We propose the application of nonlinear wavelet denoising to the noisy signal at each sensor in the array to boost the SNR before performing bearing estimation by known techniques such as MUSIC and Subspace Intersection Method [3]. Simulation results are presented to show that denoising leads to a significant reduction in the mean square errors (MSE) of the estimators, and enhancement of resolution of closely spaced sources.	acoustic cryptanalysis;elegant degradation;interpolation;mean squared error;noise reduction;nonlinear system;signal-to-noise ratio;simulation;wavelet transform;white noise	N. C. Pramod;G. V. Anand	2005	2005 13th European Signal Processing Conference			EDA	86.11525571552544	-37.295841236768915	194948
a39a614ec41073113c7fcc819f511f2bf0f248f9	subband-based adaptive decorrelation filtering for co-channel speech separation	traitement signal;multirate system;adaptive filtering;filtrado adaptable;convergence of numerical methods;speech processing;canal transmision;computational complexity adaptive filters adaptive signal processing filtering theory speech processing decorrelation convergence of numerical methods;acustica sala;signal to interference ratio subband based adaptive decorrelation filtering co channel speech separation filtering algorithm input signals decomposition frequency subbands adaptive decorrelation filtering algorithm subband signals processing experimental results fullband adf separation performance convergence rate reduced computational complexity;tratamiento palabra;traitement parole;decorrelation adaptive filters finite impulse response filter convergence computational complexity signal processing speech processing filtering algorithms least squares approximation microphones;convergence rate;systeme multicadence;adaptive filters;adaptive signal processing;subbanda;canal transmission;computational complexity;transmission channel;signal processing;subband;decorrelation;separation source;filtrage adaptatif;source separation;procesamiento senal;sistema cadencia multiple;sous bande;room acoustics;acoustique salle;filtering theory	A subband-based adaptive decorrelation filtering algorithm (SBADF) is proposed for co-channel speech separation. The SBADF decomposes the input signals into several frequency subbands, and uses the adaptive decorrelation filtering algorithm (ADF) to process the signals in each subband independently. The processed subband signals are then combined for each channel to form the separated speech. Experimental results show that while the fullband ADF can achieve better separation performance after reaching convergence, the SBADF has the advantage of improved convergence rate and reduced computational complexity by a factor of approximately two.	decorrelation	Jonathan Huang;Kuan-Chieh Yen;Yunxin Zhao	2000	IEEE Trans. Speech and Audio Processing	10.1109/89.848221	adaptive filter;computer vision;speech recognition;acoustics;computer science;signal processing;speech processing	Visualization	83.77070885659903	-33.07568286458025	195875
afbcf5015db7c8eea56bd71bb6923942b0041972	robust real-time implementation of adaptive feedback cancellation using noise injection algorithm on smartphone		We propose a low latency smartphone-based application that demonstrates the real-time operation to cancel the negative effects of acoustic feedback arising from the coupling between the speaker and the microphone of the smartphone or similar device utilizing the robust Noise Injection (NI) method. We make use of multiple noise injections of short duration to estimate the filter coefficients of an appropriate order between the speaker and the microphone, in order to perform the feedback cancellation effectively in real-time. Our motive behind the development of this application is to perform an effective acoustic feedback cancellation irrespective of the position of speaker and the microphone on the platform under consideration. With the proposed application, we can estimate the transfer function between speaker and microphone in the changing room acoustics making the feedback cancellation very effective. A real-time implementation on an Android-based smartphone is presented in this paper.	algorithm;real-time clock;smartphone	Parth Mishra;Serkan Tokgoz;Issa M. S. Panahi	2018	Proc. Meetings on Acoustics	10.1121/2.0000836	acoustics;audio feedback;physics;android (operating system);adaptive feedback cancellation;latency (engineering);transfer function;filter design;control engineering;room acoustics;microphone	HCI	85.12716698706214	-31.9415982042999	196669
d65a87fad2686a0781216e453406d4b370af4bd6	supervised source localization using diffusion kernels	microphones;manifold learning source localization acoustic localization diffusion geometry diffusion kernel;azimuth;kernel;microphone arrays acoustic signal processing calibration;source localization;microphone array supervised source localization diffusion kernels linear systems calibration acoustic source localization source signal;acoustics;training;acoustic signal processing;manifold learning;vectors;training acoustics vectors kernel microphones azimuth position measurement;position measurement;diffusion kernel;microphone arrays;calibration;diffusion geometry;acoustic localization	Recently, we introduced a method to recover the controlling parameters of linear systems using diffusion kernels. In this paper, we apply our approach to the problem of source localization in a reverberant room using measurements from a single microphone. Prior recordings of signals from various known locations in the room are required for training and calibration. The proposed algorithm relies on a computation of a diffusion kernel with a specially-tailored distance measure. Experimental results in a real reverberant environment demonstrate accurate recovery of the source location.	algorithm;computation;kernel (operating system);linear system;microphone	Ronen Talmon;Israel Cohen;Sharon Gannot	2011	2011 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)	10.1109/ASPAA.2011.6082267	electronic engineering;kernel;calibration;speech recognition;acoustics;computer science;mathematics;nonlinear dimensionality reduction;azimuth;physics	Vision	85.68536266088628	-36.35623563520031	196721
501df442828afacc7e09698ff72d24ccc7edd5d4	eeg-based auditory attention decoding using steerable binaural superdirective beamformer		During the last decades significant progress in multi-microphone speech enhancement algorithms has been made for hearing aids. However, the performance of many algorithms depends on identifying the target speaker to be enhanced. To identify the target speaker from single-trial EEG recordings in an acoustic scenario with two competing speakers, an auditory attention decoding (AAD) method was recently proposed. This AAD method however requires the clean speech signals of both the attended and the unattended speaker as reference signals for decoding. Since in practice only microphone signals, containing several undesired acoustic components, are available, in this paper we explore the potential of using steerable binaural superdirective beamformer for generating appropriate reference signals for decoding. The experimental results show that using steerable superdirective beamformer output signals improves the decoding performance compared to using the noisy microphone signals as reference signals.	acoustic cryptanalysis;algorithm;beamforming;binaural beats;electroencephalography;microphone;speech enhancement;steerable filter	Ali Aroudi;Daniel Marquardt;Simon Doclo	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8462278	speech recognition;noise measurement;decoding methods;binaural recording;electroencephalography;microphone;artificial intelligence;pattern recognition;speech enhancement;computer science	ML	84.10969911274383	-35.06955247944897	197384
0eff2296c52e2751b6ddd029737e37c1700b7e83	a sparse spherical harmonic-based model in subbands for head-related transfer functions		Several functional models for head-related transfer function (HRTF) have been proposed based on spherical harmonic (SH) orthogonal functions, which yield an encouraging performance level in terms of log-spectral distortion (LSD). However, since the properties of subbands are quite different and highly subjectdependent, the degree of SH expansion should be adapted to the subband and the subject, which is quite challenging. In this paper, a sparse spherical harmonic-based model termed SSHM is proposed in order to achieve an intelligent frequency truncation. Different from SH-based model (SHM) which assigns the degree for each subband, SSHM constrains the number of SH coefficients by using an l1 penalty, and automatically preserves the significant coefficients in each subband. As a result, SSHM requires less coefficients at the same SD level than other truncation methods to reconstruct HRTFs . Furthermore, when used for interpolation, SSHM gives a better fitting precision since it naturally reduces the influence of the fluctuation caused by the movement of the subject and the processing error. The experiments show that even using about 40% less coefficients, SSHM has a slightly lower LSD than SHM. Therefore, SSHM can achieve a better tradeoff between efficiency and accuracy.	coefficient;distortion;experiment;head-related transfer function;interpolation;quantum fluctuation;sparse matrix;super high material cd;truncation	Xiaoke Qi;Jianhua Tao	2016		10.21437/Interspeech.2016-987	mathematical optimization;speech recognition;machine learning	ML	87.3038533386807	-33.49080492840613	199068
beddcb80ba114ae8872eb1ae518a8072dc58dd3e	mode and time delay estimation for non-destructive evaluation systems	maximum likelihood;model analysis;time delay estimation;delay effects;delay effects delay estimation reflection maximum likelihood estimation signal processing algorithms ultrasonic transducer arrays maximum likelihood detection hardware robustness fuel processing industries;maximum likelihood estimation;non destructive evaluation;fuel processing industries;maximum likelihood detection;robustness;signal processing algorithms;reflection;delay estimation;hardware;ultrasonic transducer arrays	This paper describes the development of a multi-path and multimode propagation model for NDE. The mode content of a multipath is estimated using Maximum Likelihood (ML) estimation based on a receiving array delay vector. The model analysis allows a defect to be located by employing both the mode estimates and a ML estimation of the shear and longitudinal propagation angles. Some aspects of the attendant processing hardware are also discussed.	broadcast delay	J. Pearson;C. J. Macleod;Tariq S. Durrani	1982		10.1109/ICASSP.1982.1171615	speech recognition;computer science;mathematics;maximum likelihood;statistics	EDA	86.85879147744072	-37.36445440643823	199442
081bdc8865458a9437b7c02f5f5aedbd55f378dc	a stereo echo canceller implemented using a stereo shaker and a duo-filter control system	second order;echo cancellation;control systems;teleconferencing;degradation;audio signal processing;convergence;audio signal processing teleconferencing echo suppression acoustic signal processing adaptive filters;two way conversation;acoustic signal processing;double talk control;teleconferencing stereo echo canceller stereo shaker duo filter control system daily teleconferencing non uniqueness problem continually running adaptive filter fixed filter double talk control second order stereo projection algorithm stereo voice switch two way conversation conference room;control system;stereo shaker;adaptive filters;stereo voice switch;echo cancellers control systems adaptive filters teleconferencing switches projection algorithms convergence degradation humans laboratories;stereo echo canceller;second order stereo projection algorithm;echo suppression;duo filter control system;humans;daily teleconferencing;switches;conference room;echo cancellers;projection algorithms;continually running adaptive filter;fixed filter;adaptive filter;non uniqueness problem	Stereo echo cancellation has been achieved and used in daily teleconferencing. To overcome the nonuniqueness problem, a stereo shaker is introduced in eight frequency bands and adjusted so as to be inaudible and not affect stereo perception. A duo-filter control system including a continually running adaptive filter and a fixed filter is used for double-talk control. A second-order stereo projection algorithm is used in the adaptive filter. A stereo voice switch is also included. This stereo echo canceller was tested in two-way conversation in a conference room, and the strength of the stereo shaker was subjectively adjusted. A misalignment of 20 dB was obtained in the teleconferencing environment, and changing the talker‚Äôs position in the transmission room did not affect the cancellation. This echo canceller is now used daily in a high-presence teleconferencing system and has been demonstrated to more than 300 attendees.	adaptive filter;algorithm;control system;echo suppression and cancellation;frequency band;loss of significance	Suehiro Shimauchi;Shoji Makino;Youichi Haneda;Akira Nakagawa;Sumitaka Sakauchi	1999		10.1109/ICASSP.1999.759806	adaptive filter;computer vision;speech recognition;computer science;control system	Robotics	85.12710331882782	-33.75099494834837	199698
d6d829004861d90091c7e7c1961aa6a9cc0b19b1	plasma sterilization of anthrax pathogen in water mist	d value;ct;ct plasma sterilization anthrax pathogen advanced oxidation process d value;advanced oxidation process;plasma sterilization;mango anthrax pathogen plasma sterilization water mist miyazaki prefecture agricultural food industry livestock product apple dielectric barrier discharge plasma generated;sterilisation microbiological agricultural products biotechnology farming microorganisms;anthrax pathogen;plasmas discharges electric humidity pathogens electron tubes water generators	Miyazaki prefecture in Japan promotes agricultural food industry in recent year. One of the activities is promotion of agricultural and livestock products. However, Miyazaki prefecture is very far from large-scale consumption areas such as Tokyo and Osaka. To keep freshness of agricultural and livestock products during their transport is a serious problem from a viewing of putrefaction due to blight outbreak. Apple Mango has been a very famous and representative product in Miyazaki prefecture and it has successfully continued to make a good profit. However, fruit rot disease such as Anthrax Pathogen after harvest is serious [1] [2] [3]. Therefore, a sterilization technique is strongly required. We here generated the dielectric barrier discharge plasma in water mist, which may possible to sterilize the whole of greengrocery because of its high diffusibility. We examined fungicidal activity against Colletotrichum sp.	discharger;mango;plasma active;replay attack;software rot	Masaru Tominaga;Toshiyuki Tanaka;Tatsuya Sakoda;Norikazu Mizoguchi;Yoshiyuki Kushima	2015	2015 IIAI 4th International Congress on Advanced Applied Informatics	10.1109/IIAI-AAI.2015.244	environmental engineering;biotechnology;engineering;waste management	AI	86.29635796431235	-51.66533421020562	199892
